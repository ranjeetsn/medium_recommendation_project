{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import requests\n",
    "import os\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "api_key = os.getenv(\"X_RapidAPI_Key_CB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = {\n",
    "\t\"X-RapidAPI-Key\": api_key,\n",
    "\t\"X-RapidAPI-Host\": \"medium2.p.rapidapi.com\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "writers_username = ['actsusanli', 'williamkoehrsen', 'radecicdario', 'jamescalam', 'benjaminobi', 'andre-ye', 'rebeccalvickery', 'solclover', 'bgweber', '_jphwang']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_user_id(username: str)->str:\n",
    "    \"\"\"\n",
    "    Return medium user_id for the input username\n",
    "    \n",
    "    Parameters:\n",
    "    - username (str): The medium username of the user\n",
    "\n",
    "    Returns:\n",
    "    - user_id (str): The unique user_id of the user\n",
    "    \"\"\"\n",
    "    \n",
    "    url = f\"https://medium2.p.rapidapi.com/user/id_for/{username}\"\n",
    "\n",
    "    response = requests.get(url, headers=headers)\n",
    "\n",
    "    try:\n",
    "        json_data = response.json()\n",
    "        print(json_data)\n",
    "        return json_data['id']\n",
    "    except Exception as e:\n",
    "        print(f\"Error parsing JSON: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def user_id_list(username_list: list)->list:\n",
    "    \"\"\"\n",
    "    Return the list of user_ids for the list of usernames\n",
    "    \n",
    "    Parameters:\n",
    "    - username_list (list): The list of usernames\n",
    "\n",
    "    Returns:\n",
    "    - user_id_list (list): The list of user_ids for the usernames\n",
    "    \"\"\"\n",
    "    user_id_list = list()\n",
    "    for username in username_list:\n",
    "        user_id_list.append(get_user_id(username))\n",
    "\n",
    "    return user_id_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_followers_data(writer_username: str, after_follower_id: str = None, count:int = 25)->dict:\n",
    "    \"\"\"\n",
    "    For a writers username returns their followers user ids\n",
    "    \n",
    "    Parameters:\n",
    "    - writer_username (str): Username of the writer\n",
    "    - after_follower_id (int): Get the next 25 \n",
    "    \n",
    "    Return:\n",
    "    - writer_data (dict): \n",
    "    \"\"\"\n",
    "\n",
    "    url = f\"https://medium2.p.rapidapi.com/user/{writer_username}/followers\"\n",
    "\n",
    "    if after_follower_id is None:\n",
    "        querystring = {\"count\":str(count)}\n",
    "    else:\n",
    "        querystring = {\"count\":str(count), \"after\":after_follower_id}\n",
    "\n",
    "    response = requests.get(url, headers=headers, params=querystring)\n",
    "\n",
    "    try:\n",
    "        writer_data = response.json()\n",
    "        return writer_data\n",
    "    except Exception as e:\n",
    "        print(f\"Error parsing JSON: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_writers(story_field: str, count: int = 50,\n",
    "\t\t\t\t\theaders=headers) -> list:\n",
    "\t\"\"\"\n",
    "\tFor a specific area of interest, return the user_ids of the top writers\n",
    "\tas ranked by Medium.\n",
    "\n",
    "\tParameters:\n",
    "\t- story_field (str): string that represents the field (examples: machine-learning,\n",
    "\t\tartificial-intelligence, data-science)\n",
    "\t- count (int) - the number of writer user_ids to return\n",
    "\t- headers - the API headers to use in the API request\n",
    "\n",
    "\tReturns:\n",
    "\t- writer_ids\n",
    "\t\"\"\"\n",
    "\t# set the url using the story field\n",
    "\turl = f\"https://medium2.p.rapidapi.com/top_writers/{story_field}\"\n",
    "\n",
    "\tquerystring = {\"count\":f\"{str(count)}\"}\n",
    "\n",
    "\tresponse = requests.get(url, headers=headers, params=querystring)\n",
    "\n",
    "\twriter_ids = response.json()\n",
    "\treturn writer_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_user_info(user_id: str, headers=headers) -> dict:\n",
    "\t\"\"\"\n",
    "\tFor a specific user, return personal information about the writer,\n",
    "\t\tincluding name, bio, followers and follower count.\n",
    "\n",
    "\tParameters:\n",
    "\t- user_id (str) - the user_id that will contain the relevant personal\n",
    "\t\tinformation of the writer.\n",
    "\t- headers - the API headers to use in the API request\n",
    "\n",
    "\tReturns:\n",
    "\t- writer_ids\n",
    "\t\"\"\"\n",
    "\turl = f\"https://medium2.p.rapidapi.com/user/{user_id}\"\n",
    "\n",
    "\tresponse = requests.get(url, headers=headers)\n",
    "\n",
    "\tuser_info = response.json()\n",
    "\treturn user_info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Top Writers and Their Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the top 50 writers in the Artificial Intelligence field\n",
    "top_ai_writers =  # get_top_writers('artificial-intelligence', count=50, headers=headers)\n",
    "with open('top_ai_writer_ids.pkl', 'wb') as ai_file:\n",
    "\tpickle.dump(top_ai_writers, ai_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the top 50 writers in Machine Learning\n",
    "top_ml_writers = # get_top_writers('machine-learning', count=50, headers=headers)\n",
    "with open('top_ml_writer_ids.pkl', 'wb') as ml_file:\n",
    "\tpickle.dump(top_ml_writers, ml_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_ten_ai_writers = dict()\n",
    "\n",
    "# Retrieve the personal information of the top 10 writers in AI\n",
    "for writer in top_ai_writers['top_writers'][:10]:\n",
    "\ttop_ten_ai_writers[writer] = get_user_info(writer, headers=headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_ten_ml_writers = dict()\n",
    "\n",
    "# Retrieve the personal information of the top 10 writers in ML\n",
    "for writer in top_ml_writers['top_writers'][:10]:\n",
    "\ttop_ten_ml_writers[writer] = get_user_info(writer, headers=headers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dump Writer Info To Pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('top_ai_writer_info.pkl', 'wb') as ai_file:\n",
    "\tpickle.dump(top_ten_ai_writers, ai_file)\n",
    "\n",
    "with open('top_ml_writer_info.pkl', 'wb') as ml_file:\n",
    "\tpickle.dump(top_ten_ml_writers, ml_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./pkl_files/top_ml_writer_info.pkl', 'rb') as ml_file:\n",
    "\tml_writers = pickle.load(ml_file)\n",
    "\n",
    "with open('./pkl_files/top_ai_writer_info.pkl', 'rb') as ai_file:\n",
    "\tai_writers = pickle.load(ai_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Followers for Top Writers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to retrieve followers of writer\n",
    "def retrieve_writer_followers(writer_dict: dict):\n",
    "\tfor writer in writer_dict.keys():\n",
    "\t\tfollower_info = None\n",
    "\t\t# check to see if writer already has a list of follower ids\n",
    "\t\tfollowers = writer_dict[writer].get('followers', None)\n",
    "\t\tafter_follower_id = followers[-1]\n",
    "\t\tfor i in range(20):\n",
    "\t\t\tif after_follower_id is None:\n",
    "\t\t\t\tfollower_info = get_followers_data(writer_username=writer)\n",
    "\t\t\t\tafter_follower_id = follower_info['next']\n",
    "\t\t\t\twriter_dict[writer]['followers'] = follower_info['followers']\n",
    "\t\t\telse:\n",
    "\t\t\t\tresponse = get_followers_data(writer_username=writer,\n",
    "\t\t\t\t\t\t\t\t\tafter_follower_id=after_follower_id)\n",
    "\t\t\t\tafter_follower_id = response['next']\n",
    "\t\t\t\twriter_dict[writer]['followers'] += response['followers']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pareto_investor 043317c43dd5\n",
      "ignacio.de.gregorio.noblejas 04309e2cef08\n",
      "sheilateozy 45256b119fe1\n",
      "anmol3015 0f42c9652cda\n",
      "inchristiely 044e80535091\n",
      "jacobistyping 11ffbcedde9\n",
      "nikhiladithyan 1c299fd98275\n",
      "iampaulrose 052c8a5a77a9\n",
      "miptgirl 16a5493931b6\n",
      "fareedkhandev 0da520a74e5e\n"
     ]
    }
   ],
   "source": [
    "retrieve_writer_followers(ml_writers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Top Articles for Writers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_articles(writer_dict: dict, article_list: list, headers=headers):\n",
    "\tif article_list is None:\n",
    "\t\tarticle_list = list()\n",
    "\tfor writer in writer_dict.keys():\n",
    "\t\turl = f\"https://medium2.p.rapidapi.com/user/{writer}/top_articles\"\n",
    "\t\tresponse = requests.get(url=url, headers=headers)\n",
    "\t\tarticles = response.json()\n",
    "\t\twriter_dict[writer]['top_articles'] = articles\n",
    "\t\tarticle_list.append(articles)\n",
    "\treturn article_list.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_articles = list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37a2cbe8bd15\n",
      "9b351e8113e9\n",
      "fca9db1c7da0\n",
      "d80580992695\n",
      "14176fcb5743\n",
      "630ab5ffdf27\n",
      "e10ad955760c\n",
      "8c8e5b7182ef\n",
      "15a29a4fc6ad\n",
      "b856005e5ecd\n"
     ]
    }
   ],
   "source": [
    "article_copy = get_top_articles(ml_writers, all_articles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_articles = article_copy.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37a2cbe8bd15\n",
      "9b351e8113e9\n",
      "8c8e5b7182ef\n",
      "8a910484fe84\n",
      "14176fcb5743\n",
      "76398be9016\n",
      "b0fbe613be9d\n",
      "4beacba7dc8a\n",
      "fb44e21903f3\n",
      "5d33decdf4c4\n"
     ]
    }
   ],
   "source": [
    "ai_articles = get_top_articles(ai_writers, all_articles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add articles to writer information\n",
    "for el in ml_articles:\n",
    "\tarticles = el['top_articles']\n",
    "\tml_writers[el['id']]['top_articles'] = articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add articles to writer information\n",
    "for el in ai_articles:\n",
    "\tarticles = el['top_articles']\n",
    "\tif el['id'] in ai_writers.keys():\n",
    "\t\tai_writers[el['id']]['top_articles'] = articles\n",
    "\telse:\n",
    "\t\tpass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "476"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_writers = set(list(ml_writers.keys()) + list(ai_writers.keys()))\n",
    "\n",
    "len(ml_writers['14176fcb5743']['followers'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_writers = dict()\n",
    "\n",
    "for writer in combined_writers:\n",
    "\tif writer in ml_writers.keys():\n",
    "\t\ttop_writers[writer] = ml_writers[writer]\n",
    "\telse:\n",
    "\t\ttop_writers[writer] = ai_writers[writer]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_article_info(article: str, article_dict: dict, headers=headers):\n",
    "\t'''\n",
    "\tFunction to retrieve the article information for each writers' top\n",
    "\tarticles\n",
    "\t'''\n",
    "\turl = f\"https://medium2.p.rapidapi.com/article/{article}\"\n",
    "\tresponse = requests.get(url=url, headers=headers)\n",
    "\tinfo = response.json()\n",
    "\tarticle_dict[article] = info\n",
    "\treturn info\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iterate through all of the writers to retrieve and add\n",
    "# their top articles\n",
    "article_dict = dict()\n",
    "writer_art_list = list()\n",
    "for writer in top_writers.keys():\n",
    "\twriter_articles = dict()\n",
    "\tfor article in top_writers[writer]['top_articles']:\n",
    "\t\tinfo = get_article_info(article, article_dict)\n",
    "\t\twriter_articles[article] = info\n",
    "\twriter_art_list.append(writer_articles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34c195a93d41 fca9db1c7da0\n",
      "8c339f8fb602 fca9db1c7da0\n",
      "0d11918ee0b3 e10ad955760c\n",
      "ea2e2261fcbf e10ad955760c\n",
      "54948a3da389 e10ad955760c\n",
      "750d5520b20b e10ad955760c\n",
      "e50392d5e7f3 e10ad955760c\n",
      "4a80d94a7851 e10ad955760c\n",
      "f566e3fdcbc5 e10ad955760c\n",
      "05da6551637c e10ad955760c\n",
      "58ed12a492dc e10ad955760c\n",
      "936934fea7d0 e10ad955760c\n",
      "5d39cff63d52 76398be9016\n",
      "5e142b8931e6 76398be9016\n",
      "92296297a541 76398be9016\n",
      "fcad692b1456 76398be9016\n",
      "9ef2ea904986 76398be9016\n",
      "bf4cb36751ea 76398be9016\n",
      "7b104513834e 76398be9016\n",
      "cd3a824ba81f 76398be9016\n",
      "68896a42b991 76398be9016\n",
      "5204dd12bc73 76398be9016\n",
      "6a7ab0b04d35 d80580992695\n",
      "e8b0172b9581 d80580992695\n",
      "792181d2464a d80580992695\n",
      "cb7975befa53 d80580992695\n",
      "d30fa1b701f6 d80580992695\n",
      "a97c4639c183 d80580992695\n",
      "b0935bf96ee2 d80580992695\n",
      "68ffa12f8885 d80580992695\n",
      "81909c97e7d2 d80580992695\n",
      "f4104ce25e0b d80580992695\n",
      "0f27c5684804 8a910484fe84\n",
      "fe0a5a72bed5 8a910484fe84\n",
      "16e93bc3cb05 8a910484fe84\n",
      "63eba8ec76a1 8a910484fe84\n",
      "e1e04de813a0 8a910484fe84\n",
      "c6a008a4fb67 8a910484fe84\n",
      "914c14819bcf 8a910484fe84\n",
      "f004bd43e60b 8a910484fe84\n",
      "262c355fdff1 8a910484fe84\n",
      "c27c2166efec 8a910484fe84\n",
      "6ad21c4cfa99 4beacba7dc8a\n",
      "8088ec559681 4beacba7dc8a\n",
      "0991c54be605 4beacba7dc8a\n",
      "55ef2bdc4d4a 4beacba7dc8a\n",
      "fbdcf256f6bc 4beacba7dc8a\n",
      "d952c5716930 4beacba7dc8a\n",
      "0765f71dee3e 4beacba7dc8a\n",
      "fb3f7e0d9deb 4beacba7dc8a\n",
      "948fce739c61 4beacba7dc8a\n",
      "b0911e3faf6b 4beacba7dc8a\n",
      "0826b977bb5a 630ab5ffdf27\n",
      "3be015341e5e 630ab5ffdf27\n",
      "a8f2b9faad1d 630ab5ffdf27\n",
      "547e3edc7a36 630ab5ffdf27\n",
      "597a768f6509 630ab5ffdf27\n",
      "edd9949df58b 630ab5ffdf27\n",
      "815da93996a 630ab5ffdf27\n",
      "c1fe776c108f 630ab5ffdf27\n",
      "9418515a315a 630ab5ffdf27\n",
      "ae06c6f24827 630ab5ffdf27\n",
      "ded34fccd16a b856005e5ecd\n",
      "f612398f06c2 b856005e5ecd\n",
      "969af38516b2 b856005e5ecd\n",
      "e9390e2b9ed8 b856005e5ecd\n",
      "16d4e64e6eb1 b856005e5ecd\n",
      "3e71f406338b b856005e5ecd\n",
      "2675c73080ff b856005e5ecd\n",
      "9a083d3811df b856005e5ecd\n",
      "f3ebc8c42da3 b856005e5ecd\n",
      "c26d08a55809 b856005e5ecd\n",
      "c06edaa78534 b0fbe613be9d\n",
      "9a5aaa01e437 b0fbe613be9d\n",
      "1f62a6cbdaef b0fbe613be9d\n",
      "d088c69be2fb b0fbe613be9d\n",
      "3594ee338467 b0fbe613be9d\n",
      "44c6d6f7c2f6 b0fbe613be9d\n",
      "f574bb9a405e b0fbe613be9d\n",
      "904db5ebeefa b0fbe613be9d\n",
      "02ead9cc2532 b0fbe613be9d\n",
      "f6f3c38656b9 b0fbe613be9d\n",
      "6921c4f43c2a 14176fcb5743\n",
      "b467aa07365e 14176fcb5743\n",
      "5afc5b228cb3 14176fcb5743\n",
      "71196de661cb 14176fcb5743\n",
      "27e9975cce9c 14176fcb5743\n",
      "da3e4b1ac900 14176fcb5743\n",
      "572cd5758aa6 14176fcb5743\n",
      "865c0b54d1cb 14176fcb5743\n",
      "6e8d6357da20 14176fcb5743\n",
      "92741d8fb067 14176fcb5743\n",
      "a2ce57de0b02 9b351e8113e9\n",
      "818b2a8ad33e 9b351e8113e9\n",
      "680450c472c 9b351e8113e9\n",
      "4cc9cf343185 9b351e8113e9\n",
      "6d59742ee635 9b351e8113e9\n",
      "158587d68dfe 9b351e8113e9\n",
      "d49b7a88ec2e 9b351e8113e9\n",
      "81af3d4be61c 9b351e8113e9\n",
      "e7f55b0514a1 9b351e8113e9\n",
      "01deab746b42 9b351e8113e9\n",
      "83e870b5f0e4 5d33decdf4c4\n",
      "a4ff1b694707 5d33decdf4c4\n",
      "c0954c410f8f 5d33decdf4c4\n",
      "fb0c1f1f2972 5d33decdf4c4\n",
      "5edf898909e7 5d33decdf4c4\n",
      "ddbf9b5039a1 5d33decdf4c4\n",
      "620a84c14408 5d33decdf4c4\n",
      "f67bb6e5317a 5d33decdf4c4\n",
      "b2316bcc4c0f 5d33decdf4c4\n",
      "f1e31af2257a 5d33decdf4c4\n",
      "2eb0d15d6d77 8c8e5b7182ef\n",
      "40f61887f107 8c8e5b7182ef\n",
      "abb6f463e3cb 8c8e5b7182ef\n",
      "1c0e84854e4e 8c8e5b7182ef\n",
      "fc25899ff745 8c8e5b7182ef\n",
      "9fe3b230f547 8c8e5b7182ef\n",
      "1899e0b4b098 8c8e5b7182ef\n",
      "0bbfd98ac496 8c8e5b7182ef\n",
      "a506114d7a46 8c8e5b7182ef\n",
      "bf026cd7e80f 8c8e5b7182ef\n",
      "be50cc308056 37a2cbe8bd15\n",
      "82653b2b36e2 37a2cbe8bd15\n",
      "bcee41843775 37a2cbe8bd15\n",
      "5272ff33c5cd 37a2cbe8bd15\n",
      "211b2207b566 37a2cbe8bd15\n",
      "2b8eb1e86f25 37a2cbe8bd15\n",
      "681c04c2a74f 37a2cbe8bd15\n",
      "329ca6732470 37a2cbe8bd15\n",
      "1add43659444 37a2cbe8bd15\n",
      "c33063302058 37a2cbe8bd15\n",
      "afd97fce8fb5 15a29a4fc6ad\n",
      "c5b9faa7a950 15a29a4fc6ad\n",
      "3a10838b150d 15a29a4fc6ad\n",
      "9d42488dc327 15a29a4fc6ad\n",
      "8cf7da132259 15a29a4fc6ad\n",
      "851578fa10ce 15a29a4fc6ad\n",
      "d7486d88c541 15a29a4fc6ad\n",
      "eaf5469b83b0 15a29a4fc6ad\n",
      "e3b3e99e4fca 15a29a4fc6ad\n",
      "c288b48918af 15a29a4fc6ad\n",
      "5137fdafb355 fb44e21903f3\n",
      "b3e8446773b9 fb44e21903f3\n",
      "bb4d6a735fc1 fb44e21903f3\n",
      "e6dd223d6ae0 fb44e21903f3\n",
      "84e568626e89 fb44e21903f3\n",
      "4eaff6178983 fb44e21903f3\n",
      "4ff7e5973b05 fb44e21903f3\n",
      "e23bfa19bf16 fb44e21903f3\n",
      "16ed78293975 fb44e21903f3\n",
      "c6b672104721 fb44e21903f3\n"
     ]
    }
   ],
   "source": [
    "# iterate through all retrieved articles and assign articles to their\n",
    "# respective author in new dictionary\n",
    "updated_articles = dict()\n",
    "for article in article_dict.keys():\n",
    "\tauthor = article_dict[article]['author']\n",
    "\tinfo = article_dict[article]\n",
    "\tif author not in updated_articles.keys():\n",
    "\t\tupdated_articles[author] = [info]\n",
    "\telse:\n",
    "\t\tupdated_articles[author].append(info)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save writer-article dictionary to pickle file\n",
    "with open('./writer_article_info.pkl', 'wb') as wa_file:\n",
    "\tpickle.dump(updated_articles, wa_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save dictionary of all writers to pickle file\n",
    "with open('./combined_writers.pkl', 'wb') as comb_file:\n",
    "\tpickle.dump(top_writers, comb_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iterate through all writers in the writer dictionary and\n",
    "# add the information about their top articles\n",
    "test_writers = top_writers.copy()\n",
    "for writer in test_writers.keys():\n",
    "\ttest_writers[writer]['top_articles'] = updated_articles[writer]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': '6921c4f43c2a',\n",
       "  'title': 'Midjourney V6 New Prompting Technique\\u200a—\\u200aIntroduction to “The 4W1H” 🎨',\n",
       "  'subtitle': 'Elevate Your Prompt Writing Structure & Skills',\n",
       "  'author': '14176fcb5743',\n",
       "  'publication_id': '48e972f5c24e',\n",
       "  'published_at': '2023-12-27 13:01:24',\n",
       "  'last_modified_at': '2024-01-24 02:48:22',\n",
       "  'tags': ['midjourney',\n",
       "   'artificial-intelligence',\n",
       "   'creativity',\n",
       "   'design',\n",
       "   'art'],\n",
       "  'topics': ['design'],\n",
       "  'claps': 2487,\n",
       "  'voters': 382,\n",
       "  'word_count': 1369,\n",
       "  'responses_count': 25,\n",
       "  'reading_time': 6.666037735849057,\n",
       "  'url': 'https://bootcamp.uxdesign.cc/midjourney-v6-new-prompting-technique-introduction-to-the-4w1h-6921c4f43c2a',\n",
       "  'unique_slug': 'midjourney-v6-new-prompting-technique-introduction-to-the-4w1h-6921c4f43c2a',\n",
       "  'image_url': 'https://miro.medium.com/1*2QvnFaQZQzbV04MAZcfUJQ.png',\n",
       "  'lang': 'en',\n",
       "  'is_series': False,\n",
       "  'is_locked': True,\n",
       "  'is_shortform': False,\n",
       "  'top_highlight': 'By breaking down the elements of your artwork into What, Who, When, Where, and How, you will assist Midjourney in gaining a deeper understanding of your creative thoughts.'},\n",
       " {'id': 'b467aa07365e',\n",
       "  'title': '9 Midjourney V6. Prompting Technique You Need to Know 🎨',\n",
       "  'subtitle': 'Relearn Prompt Writing to Take Your AI Art to the Next Level!',\n",
       "  'author': '14176fcb5743',\n",
       "  'publication_id': '48e972f5c24e',\n",
       "  'published_at': '2024-01-19 13:01:48',\n",
       "  'last_modified_at': '2024-02-12 10:11:21',\n",
       "  'tags': ['midjourney',\n",
       "   'artificial-intelligence',\n",
       "   'creativity',\n",
       "   'design',\n",
       "   'art'],\n",
       "  'topics': ['artificial-intelligence', 'design', 'programming'],\n",
       "  'claps': 1143,\n",
       "  'voters': 132,\n",
       "  'word_count': 1887,\n",
       "  'responses_count': 10,\n",
       "  'reading_time': 9.070754716981131,\n",
       "  'url': 'https://bootcamp.uxdesign.cc/9-midjourney-v6-prompting-technique-you-need-to-know-b467aa07365e',\n",
       "  'unique_slug': '9-midjourney-v6-prompting-technique-you-need-to-know-b467aa07365e',\n",
       "  'image_url': 'https://miro.medium.com/1*EgyE5HYnjwDhLjJR04NPcw.png',\n",
       "  'lang': 'en',\n",
       "  'is_series': False,\n",
       "  'is_locked': True,\n",
       "  'is_shortform': False,\n",
       "  'top_highlight': ''},\n",
       " {'id': '5afc5b228cb3',\n",
       "  'title': 'One Magical Midjourney Prompt to Elevate Your Creativity!',\n",
       "  'subtitle': 'Level Up Your AI Image with this One Word',\n",
       "  'author': '14176fcb5743',\n",
       "  'publication_id': '48e972f5c24e',\n",
       "  'published_at': '2023-11-13 13:02:01',\n",
       "  'last_modified_at': '2023-12-19 09:34:03',\n",
       "  'tags': ['midjourney',\n",
       "   'artificial-intelligence',\n",
       "   'creativity',\n",
       "   'design',\n",
       "   'art'],\n",
       "  'topics': ['design'],\n",
       "  'claps': 830,\n",
       "  'voters': 85,\n",
       "  'word_count': 1186,\n",
       "  'responses_count': 14,\n",
       "  'reading_time': 6.225471698113208,\n",
       "  'url': 'https://bootcamp.uxdesign.cc/one-magical-midjourney-prompt-to-elevate-your-creativity-5afc5b228cb3',\n",
       "  'unique_slug': 'one-magical-midjourney-prompt-to-elevate-your-creativity-5afc5b228cb3',\n",
       "  'image_url': 'https://miro.medium.com/1*9LYsteVtPZ629V14eYA17A.png',\n",
       "  'lang': 'en',\n",
       "  'is_series': False,\n",
       "  'is_locked': True,\n",
       "  'is_shortform': False,\n",
       "  'top_highlight': 'Prompt: [ People ], picking a [ Food ], bright studio light, [ Color ] background, minimalist, miniature food photography, soft color blending --ar 3:4'},\n",
       " {'id': '71196de661cb',\n",
       "  'title': '20+ Incredible Midjourney Prompts You Must Try!',\n",
       "  'subtitle': 'Elevate Your AI Arts with These Creative Prompts',\n",
       "  'author': '14176fcb5743',\n",
       "  'publication_id': '48e972f5c24e',\n",
       "  'published_at': '2023-11-06 13:01:59',\n",
       "  'last_modified_at': '2024-01-18 01:36:25',\n",
       "  'tags': ['midjourney',\n",
       "   'artificial-intelligence',\n",
       "   'creativity',\n",
       "   'art',\n",
       "   'design'],\n",
       "  'topics': ['artificial-intelligence', 'design'],\n",
       "  'claps': 1112,\n",
       "  'voters': 160,\n",
       "  'word_count': 1278,\n",
       "  'responses_count': 20,\n",
       "  'reading_time': 6.722641509433963,\n",
       "  'url': 'https://bootcamp.uxdesign.cc/x20-incredible-midjourney-prompts-you-must-try-71196de661cb',\n",
       "  'unique_slug': 'x20-incredible-midjourney-prompts-you-must-try-71196de661cb',\n",
       "  'image_url': 'https://miro.medium.com/1*aYQLn2P3QdFqB-d8UdfZNA.png',\n",
       "  'lang': 'en',\n",
       "  'is_series': False,\n",
       "  'is_locked': True,\n",
       "  'is_shortform': False,\n",
       "  'top_highlight': 'Prompt: Blacklight planet in the galaxy, fancy dreamy'},\n",
       " {'id': '27e9975cce9c',\n",
       "  'title': 'Midjourney Comprehensive Guide: Commands, Features and Tricks here!',\n",
       "  'subtitle': 'How to Use Midjourney to Elevate Your Images and Creativity',\n",
       "  'author': '14176fcb5743',\n",
       "  'publication_id': '48e972f5c24e',\n",
       "  'published_at': '2023-07-30 13:02:32',\n",
       "  'last_modified_at': '2024-01-04 03:03:59',\n",
       "  'tags': ['midjourney',\n",
       "   'artificial-intelligence',\n",
       "   'creativity',\n",
       "   'design',\n",
       "   'future'],\n",
       "  'topics': ['design'],\n",
       "  'claps': 1085,\n",
       "  'voters': 193,\n",
       "  'word_count': 1998,\n",
       "  'responses_count': 18,\n",
       "  'reading_time': 9.489622641509433,\n",
       "  'url': 'https://bootcamp.uxdesign.cc/a-comprehensive-midjourney-guide-commands-features-and-tricks-here-27e9975cce9c',\n",
       "  'unique_slug': 'a-comprehensive-midjourney-guide-commands-features-and-tricks-here-27e9975cce9c',\n",
       "  'image_url': 'https://miro.medium.com/1*jARZCchLet3ZIpvMvN01Qg.png',\n",
       "  'lang': 'en',\n",
       "  'is_series': False,\n",
       "  'is_locked': True,\n",
       "  'is_shortform': False,\n",
       "  'top_highlight': 'Using the same seed number will produce a similar style.'},\n",
       " {'id': 'da3e4b1ac900',\n",
       "  'title': 'Top 12 Visual Design Trends for 2024 That Boost Engagement (Part 2)',\n",
       "  'subtitle': 'The Hottest Creative Styles to Captivate Audiences This Year',\n",
       "  'author': '14176fcb5743',\n",
       "  'publication_id': '*Self-Published*',\n",
       "  'published_at': '2024-02-18 13:01:39',\n",
       "  'last_modified_at': '2024-02-18 13:01:39',\n",
       "  'tags': ['midjourney',\n",
       "   'artificial-intelligence',\n",
       "   'creativity',\n",
       "   'design',\n",
       "   'make-money'],\n",
       "  'topics': ['design'],\n",
       "  'claps': 336,\n",
       "  'voters': 18,\n",
       "  'word_count': 1327,\n",
       "  'responses_count': 5,\n",
       "  'reading_time': 7.007547169811321,\n",
       "  'url': 'https://medium.com/@inchristiely/top-12-visual-design-trends-for-2024-that-boost-engagement-part-2-da3e4b1ac900',\n",
       "  'unique_slug': 'top-12-visual-design-trends-for-2024-that-boost-engagement-part-2-da3e4b1ac900',\n",
       "  'image_url': 'https://miro.medium.com/1*AUCseY5Vt4MMvTlUwf6zpA.png',\n",
       "  'lang': 'en',\n",
       "  'is_series': False,\n",
       "  'is_locked': True,\n",
       "  'is_shortform': False,\n",
       "  'top_highlight': ''},\n",
       " {'id': '572cd5758aa6',\n",
       "  'title': 'Top 12 Visual Design Trends for 2024 That Boost Engagement',\n",
       "  'subtitle': 'The Hottest Creative Styles to Captivate Audiences This Year',\n",
       "  'author': '14176fcb5743',\n",
       "  'publication_id': '48e972f5c24e',\n",
       "  'published_at': '2024-02-17 13:01:57',\n",
       "  'last_modified_at': '2024-02-17 21:52:30',\n",
       "  'tags': ['design', 'creativity', 'art', 'midjourney', 'make-money-online'],\n",
       "  'topics': ['design'],\n",
       "  'claps': 410,\n",
       "  'voters': 26,\n",
       "  'word_count': 1313,\n",
       "  'responses_count': 2,\n",
       "  'reading_time': 6.904716981132076,\n",
       "  'url': 'https://bootcamp.uxdesign.cc/top-12-visual-design-trends-for-2024-that-boost-engagement-572cd5758aa6',\n",
       "  'unique_slug': 'top-12-visual-design-trends-for-2024-that-boost-engagement-572cd5758aa6',\n",
       "  'image_url': 'https://miro.medium.com/1*D0D5XzAIxQ7ywOYPVNbyag.png',\n",
       "  'lang': 'en',\n",
       "  'is_series': False,\n",
       "  'is_locked': True,\n",
       "  'is_shortform': False,\n",
       "  'top_highlight': ''},\n",
       " {'id': '865c0b54d1cb',\n",
       "  'title': 'Midjourney V6 Alpha is Now the Default with Improvements to Details, Contrast and Coherence🔥',\n",
       "  'subtitle': 'Prepared for NEW “describe” and “Character Consistency” Coming Soon!',\n",
       "  'author': '14176fcb5743',\n",
       "  'publication_id': '48e972f5c24e',\n",
       "  'published_at': '2024-02-15 13:02:01',\n",
       "  'last_modified_at': '2024-02-15 23:48:39',\n",
       "  'tags': ['midjourney',\n",
       "   'artificial-intelligence',\n",
       "   'creativity',\n",
       "   'design',\n",
       "   'art'],\n",
       "  'topics': ['design', 'programming'],\n",
       "  'claps': 163,\n",
       "  'voters': 11,\n",
       "  'word_count': 1155,\n",
       "  'responses_count': 2,\n",
       "  'reading_time': 5.758490566037736,\n",
       "  'url': 'https://bootcamp.uxdesign.cc/midjourney-v6-alpha-is-now-the-default-with-improvements-to-details-contrast-and-coherence-865c0b54d1cb',\n",
       "  'unique_slug': 'midjourney-v6-alpha-is-now-the-default-with-improvements-to-details-contrast-and-coherence-865c0b54d1cb',\n",
       "  'image_url': 'https://miro.medium.com/1*wybK0zuHORyKn8YH0AAELQ.png',\n",
       "  'lang': 'en',\n",
       "  'is_series': False,\n",
       "  'is_locked': True,\n",
       "  'is_shortform': False,\n",
       "  'top_highlight': ''},\n",
       " {'id': '6e8d6357da20',\n",
       "  'title': 'Midjourney V6 Essential- Transform Style with “Remix” 🎨',\n",
       "  'subtitle': 'A Structure to follow with Visual Examples and Usage',\n",
       "  'author': '14176fcb5743',\n",
       "  'publication_id': '48e972f5c24e',\n",
       "  'published_at': '2024-02-12 13:01:48',\n",
       "  'last_modified_at': '2024-02-12 22:20:55',\n",
       "  'tags': ['midjourney',\n",
       "   'artificial-intelligence',\n",
       "   'creativity',\n",
       "   'design',\n",
       "   'art'],\n",
       "  'topics': ['design'],\n",
       "  'claps': 416,\n",
       "  'voters': 25,\n",
       "  'word_count': 1279,\n",
       "  'responses_count': 5,\n",
       "  'reading_time': 6.576415094339622,\n",
       "  'url': 'https://bootcamp.uxdesign.cc/midjourney-v6-essential-transform-style-with-remix-6e8d6357da20',\n",
       "  'unique_slug': 'midjourney-v6-essential-transform-style-with-remix-6e8d6357da20',\n",
       "  'image_url': 'https://miro.medium.com/1*SrQ7YHs4cumUYkm1j5Kxfw.png',\n",
       "  'lang': 'en',\n",
       "  'is_series': False,\n",
       "  'is_locked': True,\n",
       "  'is_shortform': False,\n",
       "  'top_highlight': ''},\n",
       " {'id': '92741d8fb067',\n",
       "  'title': 'Ultimate Guide to Using Midjourney Website Alpha! 💻',\n",
       "  'subtitle': 'Image Generation, Batch download and Smart Organisation with Ease!',\n",
       "  'author': '14176fcb5743',\n",
       "  'publication_id': '48e972f5c24e',\n",
       "  'published_at': '2024-02-09 13:01:32',\n",
       "  'last_modified_at': '2024-02-09 21:42:14',\n",
       "  'tags': ['midjourney',\n",
       "   'artificial-intelligence',\n",
       "   'creativity',\n",
       "   'design',\n",
       "   'art'],\n",
       "  'topics': ['design'],\n",
       "  'claps': 584,\n",
       "  'voters': 55,\n",
       "  'word_count': 1139,\n",
       "  'responses_count': 7,\n",
       "  'reading_time': 6.44811320754717,\n",
       "  'url': 'https://bootcamp.uxdesign.cc/ultimate-guide-to-using-midjourney-website-alpha-92741d8fb067',\n",
       "  'unique_slug': 'ultimate-guide-to-using-midjourney-website-alpha-92741d8fb067',\n",
       "  'image_url': 'https://miro.medium.com/1*wkYFlLubAFBU-8aWHkqtfQ.png',\n",
       "  'lang': 'en',\n",
       "  'is_series': False,\n",
       "  'is_locked': True,\n",
       "  'is_shortform': False,\n",
       "  'top_highlight': ''}]"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_writers['14176fcb5743']['top_articles']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_values(['14176fcb5743', 'inchristiely', 'Christie C.', '🎨 AI Art Educator & Creator | 5 x Top Writer | Master Midjourney❤️Turn AI Art into Cash 💰👉🏻 https://bit.ly/MidjourneyPrompt', 56048, 121, 19, 'https://miro.medium.com/1*yuFGmpFZLaaqPADFQ7pOTw.jpeg', '', True, True, '2023-01-04 07:53:34', False, ['art', 'design', 'creativity', 'artificial-intelligence', 'future'], True, False, 'https://www.buymeacoffee.com/inchristie', 'https://miro.medium.com/1*zSvLnsT4bqSA_CqA5ms2sA.png', '', ['00008456a9f0', '0000a6571897', '00032ca4b88c', '00045a935c88', '0004b0e05369', '0006c15d8338', '000c187af99b', '000eb90e70d8', '00116aa9884a', '00149b7421b2', '001564222f42', '00160071cea3', '00180712c53d', '001aa2fef563', '001d3500f024', '002324d8d54e', '0023a4a5cccf', '00245ad345da', '0024d33e6c7d', '0026b2c6e32d', '002b3b17db23', '002e56e573db', '002f357f1a1c', '00301e37f53a', '0031244c509e', '0034535aa881', '00348dfc8976', '0036dfd4faf4', '0037f86827fc', '00388d34235e', '003a91d0f9a1', '003e441c0874', '003f7ff5f599', '003fe511835f', '0041541f90e4', '004279a3a73e', '0045f7ba4422', '0046ffb589fe', '004a8030a14f', '004aff8458fb', '004daca42132', '004e20cb72b3', '005144e861bb', '0055540ed1c8', '0056cb1a6eaf', '0058b5cae97b', '005956b07565', '005a95dd3e00', '005b0e23b5d5', '005e8316fae9', '0064a097f654', '00651cee34db', '00660fd05fa7', '00688c9cb4b6', '006a2946b9b9', '006be6184a29', '006d5db8f610', '007091a67938', '007248b58676', '0076c2a4fccc', '00777a15e411', '007ea42d4cc5', '007f75dc5b13', '007fe78a3458', '0081b869b24d', '00828a580394', '008336b15cb2', '0086caac613e', '0086ebd600be', '008ad0baf6ff', '008b7bf66892', '008bd264da31', '008cb99a7973', '008e42d846db', '009390c0458d', '0097be63ad9b', '009a07908d63', '009a793747ae', '009daf38588f', '009ee6c6d2d7', '00a07f50ac66', '00a338135b96', '00a6814e9fb8', '00a7f4726d5b', '00abad96696a', '00ad050899b5', '00af43322bed', '00b86c239ae9', '00b8eada8b79', '00b9a33bb81f', '00bedca4ccd6', '00bf37dfa958', '00bf54d77b79', '00c10cc7fc78', '00c3d47c9bdc', '00c70b8be752', '00c864ade3db', '00ca80653208', '00cd031344d6', '00cd0905c7a9', '00d0c88bf952', '00d626d8279f', '00da4ebaf9e6', '00dd762aef3b', '00de22ec4707', '00dfb9d3a6ba', '00e279792601', '00e64025302f', '00e8f72cbac1', '00e974fe1be5', '00e97ebedb8a', '00ebb2df916a', '00ee2b300b93', '00f1dddb885d', '00f24bcd7bd7', '00f29e780193', '00f2d8152332', '00f3825d8b3a', '00f91a736e7a', '00f9656b27a7', '00fc6797fe4b', '00fcb9e6c880', '0100bfad1385', '0102838e5346', '010285d248a0', '01054c60a74b', '010740fb5f37', '0109e784bcf3', '010c2c4a5e25', '0115c36ef483', '0115c4d222bc', '0119c2b70e94', '011ac46681d4', '011c896e89a2', '0122867c5794', '01247722f2d2', '012b181e1fba', '012cbb376227', '012fdb5da8ec', '0130f859c87c', '013141d04d67', '0132641e0bd2', '0139c54af843', '013a93929819', '0140b0fcc755', '0142dce745d6', '0143b7013542', '01446399ce9a', '014670628993', '014791450ac1', '0147ce94e2c1', '01480dc32f54', '0148ce17a280', '014ab4e7800a', '014b50f2b8a9', '014c7dcc1805', '014d1f452bc8', '014d530d567c', '014efbc1c2ff', '015426ced173', '0158b5dca221', '015d2558fb2e', '015dbcb25f80', '015fb2f70943', '0160350ca03d', '01611624d56b', '016248200680', '01663a4bdf0c', '016bc359f30c', '016e2f04b248', '017686580bb5', '01782b701a24', '017974e6b3bb', '0179a5ea3099', '017b2b5950b7', '017beb27a328', '017dd141af02', '017fdc964e67', '0180d9a03889', '01821004b009', '01881ecb24b2', '018b35c4d3dc', '018bb99f378e', '018c1b2876b5', '018e38713fca', '0197500bd26c', '01987da15355', '019bfb4cf3ff', '019c80d76690', '01a1ba538f61', '01a6eed31abb', '01a81a9a1134', '01a9c1259fcc', '01a9d29e11d0', '01ad1d61b5e2', '01ae5a74d887', '01aff610f2c5', '01b0fa936fca', '01b12abe8016', '01b20a505427', '01b59d1c170a', '01bace87a8ca', '01bbf69759fd', '01c016e994f9', '01c090982695', '01c2c1fff3a7', '01d173ab023a', '01d592a3b772', '01d64214e662', '01d6ca04e85f', '01d9c405c912', '01d9cc1c64d3', '01dab43fcca6', '01dc6815573d', '01debae60774', '01e22e257aad', '01e5530ef612', '01e76051e5c1', '01ea7518f437', '01eb5edb6a57', '01ec1a0c6bf3', '01ec83891f8e', '01f0841afdf5', '01f21095700f', '01f41843a8eb', '01f918c8ca17', '01faad01498c', '01ff5e54d902', '0200be746bf6', '0202f7d65d9e', '0203ae1ce789', '0205d9c2fbf4', '0209e4300043', '020b33c0820c', '020b8507aeb0', '020c3a9002e5', '020ed720c5ee', '020f9dcc253c', '0212a3c23533', '021355eb0717', '0213b0ab0980', '0213d25f83a0', '0215ad7ba320', '0216cd8af098', '021750e3b2b9', '02176f2d6293', '02197edcb979', '021a5907125c', '021d519b5bc3', '021ec30c749e', '0221ae9122c4', '0222ca211b33', '022a3f515cba', '022e978e0155', '0231ff0dbc3a', '023559818fbc', '02357e0b8347', '0239d6bfe7fd', '023f4705461f', '02453bf6fb4f', '024976a0ff7c', '0249960b42f0', '024d46d48ec8', '0254c3fc1245', '0255a6b87784', '0257c7496d5f', '0258cd7dd371', '02597f14885e', '025c47d6e1fb', '025dd53e105c', '025df2df9a37', '025e3eb1f404', '026498e585a6', '02654ae74f51', '026cd15d4c81', '026d06779866', '026f0b914ddd', '026f620d992f', '027028d9bde3', '0273d8927bef', '0274127db0fa', '02755bb63273', '0276082a3a87', '027657869777', '027b9b59cb41', '027c98ccc223', '02816671a5e7', '028770318e79', '0287accaaf1d', '028b27877c10', '028cbd441505', '02942f450ffe', '029482385112', '02975fb9e397', '029b35f74526', '029b77d8edc5', '02a00a2d45c3', '02a46ec65eda', '02a4afe1c62f', '02a53fac2eb5', '02af5b038892', '02b0cba4f85e', '02b22a27378a', '02b471d26b4b', '02b5114c779a', '02b5c8f6c7bf', '02b5d0a9dea7', '02b847074ab7', '02b8509caa67', '02b99eb02d96', '02bbd17887c1', '02bed666ac14', '02c49d343b8e', '02c6e523d977', '02c963384c80', '02c9c79d1812', '02ca76513457', '02ce0f83f004', '02d6b32e6591', '02d7581eb08b', '02e055ad3d54', '02e057389c47', '02e46356161d', '02e6cab3305f', '02e793cf0306', '02eabc5afc9b', '02eaf3040291', '02eef590a42c', '02f9493e4478', '02f982b6308e', '02fe3a80da7b', '03005888c3ee', '03009c312966', '03011804df2a', '0301f0276167', '030207032d8b', '0304608d6585', '030b3b29d1d4', '0312c2e01765', '03133540481d', '03138f5ff046', '0315db4cbe86', '031c9b856d55', '031ca58f8742', '031ce2fc805a', '031e45ac1bd6', '031febdd6afe', '032447a310fa', '032580f1cb46', '032c92283903', '032d8a21f407', '0332239585f9', '0334334523f2', '033dddc0e361', '03401f344e2a', '0343c6cde955', '0344c819f9fc', '03470591377f', '0348267ad688', '03487d9e6ab6', '034b64e5bbf2', '034da96e10dc', '034f2c13e874', '03561c8d445b', '0356a6d54d75', '03587a17e4f1', '0358fb7e422b', '035e5ae9177b', '0362aca28985', '0362f4faf050', '0368e0999892', '036ada4f9da0', '036c957356d8', '036ecf5a78de', '037352fe2d13', '0375742afb7f', '03778713d516', '037a8786167e', '037c22fae1ce', '037cf47840d3', '037dfc0eaffb', '037e56d957e3', '03809bbd4626', '03815a1f922d', '03839b49b297', '038616bedd81', '03880d7392d7', '038881c812d8', '038a09a9c2c1', '038ac12ed38b', '038c023a62bf', '038e46d6da63', '038edce6cec6', '0394aaa1403a', '03954ee233b7', '039568695bb5', '0396e51ec32d', '039e1349ed1d', '03a3c9504dff', '03ac41fac508', '03ac9a983caa', '03af4c0aa53f', '03b0e8ccce84', '03b31424b5a4', '03b3549b5abf', '03b4a1b945c1', '03b52ef93f2c', '03b54aaa3027', '03b9cff66a17', '03ba95901a24', '03bc0f18c610', '03bcb370b730', '03bff1292d9c', '03c167203c08', '03c1c3820c90', '03c2df878679', '03c5ef696031', '03c77847c9a6', '03ca893966eb', '03cc3c502760', '03d06374eaac', '03d6b850b7b5', '03d71dd7fca1', '03d778a58360', '03d7b2786a8c', '03d7d3416226', '03d8ea1ba078', '03d93b246494', '03da2b9ffebc', '03dfd549f1aa', '03e454892701', '03e527c257f9', '03e667074fb8', '03e714ce1e2a', '03efbae57fbc', '03f2be916786', '03f381560951', '03f3abdfa2aa', '03f4ccc0289c', '03f811a2765f', '03f9d334c243', '03fa389c69ac', '03fc2e37c371', '040180bca2cc', '0404526e704b', '04059ff14c46', '040692a0066c', '0407e146f755', '0408a97d7661', '0408febca528', '0409b232ec6e', '040b368f8924', '040b73d4cbfb', '0410469b15fa', '0416970847cc', '04192f6ae7b7', '04194339257e', '041a215c25fb', '041d24ea93ee', '041d615444f5', '0421dfe57484', '0424cd3b13bb', '0428ee002a03', '042e1dbf2616', '04300428355f', '04320f7be488', '0434b6c60a39', '04384c3f6ee2', '043fcaeb2430', '043fe8379c89', '043ff8992ec6', '04417a0f362d', '044473c7fcc2', '04452136d200', '044550146f67', '044e80535091'], [{'id': '6921c4f43c2a', 'title': 'Midjourney V6 New Prompting Technique\\u200a—\\u200aIntroduction to “The 4W1H” 🎨', 'subtitle': 'Elevate Your Prompt Writing Structure & Skills', 'author': '14176fcb5743', 'publication_id': '48e972f5c24e', 'published_at': '2023-12-27 13:01:24', 'last_modified_at': '2024-01-24 02:48:22', 'tags': ['midjourney', 'artificial-intelligence', 'creativity', 'design', 'art'], 'topics': ['design'], 'claps': 2487, 'voters': 382, 'word_count': 1369, 'responses_count': 25, 'reading_time': 6.666037735849057, 'url': 'https://bootcamp.uxdesign.cc/midjourney-v6-new-prompting-technique-introduction-to-the-4w1h-6921c4f43c2a', 'unique_slug': 'midjourney-v6-new-prompting-technique-introduction-to-the-4w1h-6921c4f43c2a', 'image_url': 'https://miro.medium.com/1*2QvnFaQZQzbV04MAZcfUJQ.png', 'lang': 'en', 'is_series': False, 'is_locked': True, 'is_shortform': False, 'top_highlight': 'By breaking down the elements of your artwork into What, Who, When, Where, and How, you will assist Midjourney in gaining a deeper understanding of your creative thoughts.'}, {'id': 'b467aa07365e', 'title': '9 Midjourney V6. Prompting Technique You Need to Know 🎨', 'subtitle': 'Relearn Prompt Writing to Take Your AI Art to the Next Level!', 'author': '14176fcb5743', 'publication_id': '48e972f5c24e', 'published_at': '2024-01-19 13:01:48', 'last_modified_at': '2024-02-12 10:11:21', 'tags': ['midjourney', 'artificial-intelligence', 'creativity', 'design', 'art'], 'topics': ['artificial-intelligence', 'design', 'programming'], 'claps': 1143, 'voters': 132, 'word_count': 1887, 'responses_count': 10, 'reading_time': 9.070754716981131, 'url': 'https://bootcamp.uxdesign.cc/9-midjourney-v6-prompting-technique-you-need-to-know-b467aa07365e', 'unique_slug': '9-midjourney-v6-prompting-technique-you-need-to-know-b467aa07365e', 'image_url': 'https://miro.medium.com/1*EgyE5HYnjwDhLjJR04NPcw.png', 'lang': 'en', 'is_series': False, 'is_locked': True, 'is_shortform': False, 'top_highlight': ''}, {'id': '5afc5b228cb3', 'title': 'One Magical Midjourney Prompt to Elevate Your Creativity!', 'subtitle': 'Level Up Your AI Image with this One Word', 'author': '14176fcb5743', 'publication_id': '48e972f5c24e', 'published_at': '2023-11-13 13:02:01', 'last_modified_at': '2023-12-19 09:34:03', 'tags': ['midjourney', 'artificial-intelligence', 'creativity', 'design', 'art'], 'topics': ['design'], 'claps': 830, 'voters': 85, 'word_count': 1186, 'responses_count': 14, 'reading_time': 6.225471698113208, 'url': 'https://bootcamp.uxdesign.cc/one-magical-midjourney-prompt-to-elevate-your-creativity-5afc5b228cb3', 'unique_slug': 'one-magical-midjourney-prompt-to-elevate-your-creativity-5afc5b228cb3', 'image_url': 'https://miro.medium.com/1*9LYsteVtPZ629V14eYA17A.png', 'lang': 'en', 'is_series': False, 'is_locked': True, 'is_shortform': False, 'top_highlight': 'Prompt: [ People ], picking a [ Food ], bright studio light, [ Color ] background, minimalist, miniature food photography, soft color blending --ar 3:4'}, {'id': '71196de661cb', 'title': '20+ Incredible Midjourney Prompts You Must Try!', 'subtitle': 'Elevate Your AI Arts with These Creative Prompts', 'author': '14176fcb5743', 'publication_id': '48e972f5c24e', 'published_at': '2023-11-06 13:01:59', 'last_modified_at': '2024-01-18 01:36:25', 'tags': ['midjourney', 'artificial-intelligence', 'creativity', 'art', 'design'], 'topics': ['artificial-intelligence', 'design'], 'claps': 1112, 'voters': 160, 'word_count': 1278, 'responses_count': 20, 'reading_time': 6.722641509433963, 'url': 'https://bootcamp.uxdesign.cc/x20-incredible-midjourney-prompts-you-must-try-71196de661cb', 'unique_slug': 'x20-incredible-midjourney-prompts-you-must-try-71196de661cb', 'image_url': 'https://miro.medium.com/1*aYQLn2P3QdFqB-d8UdfZNA.png', 'lang': 'en', 'is_series': False, 'is_locked': True, 'is_shortform': False, 'top_highlight': 'Prompt: Blacklight planet in the galaxy, fancy dreamy'}, {'id': '27e9975cce9c', 'title': 'Midjourney Comprehensive Guide: Commands, Features and Tricks here!', 'subtitle': 'How to Use Midjourney to Elevate Your Images and Creativity', 'author': '14176fcb5743', 'publication_id': '48e972f5c24e', 'published_at': '2023-07-30 13:02:32', 'last_modified_at': '2024-01-04 03:03:59', 'tags': ['midjourney', 'artificial-intelligence', 'creativity', 'design', 'future'], 'topics': ['design'], 'claps': 1085, 'voters': 193, 'word_count': 1998, 'responses_count': 18, 'reading_time': 9.489622641509433, 'url': 'https://bootcamp.uxdesign.cc/a-comprehensive-midjourney-guide-commands-features-and-tricks-here-27e9975cce9c', 'unique_slug': 'a-comprehensive-midjourney-guide-commands-features-and-tricks-here-27e9975cce9c', 'image_url': 'https://miro.medium.com/1*jARZCchLet3ZIpvMvN01Qg.png', 'lang': 'en', 'is_series': False, 'is_locked': True, 'is_shortform': False, 'top_highlight': 'Using the same seed number will produce a similar style.'}, {'id': 'da3e4b1ac900', 'title': 'Top 12 Visual Design Trends for 2024 That Boost Engagement (Part 2)', 'subtitle': 'The Hottest Creative Styles to Captivate Audiences This Year', 'author': '14176fcb5743', 'publication_id': '*Self-Published*', 'published_at': '2024-02-18 13:01:39', 'last_modified_at': '2024-02-18 13:01:39', 'tags': ['midjourney', 'artificial-intelligence', 'creativity', 'design', 'make-money'], 'topics': ['design'], 'claps': 336, 'voters': 18, 'word_count': 1327, 'responses_count': 5, 'reading_time': 7.007547169811321, 'url': 'https://medium.com/@inchristiely/top-12-visual-design-trends-for-2024-that-boost-engagement-part-2-da3e4b1ac900', 'unique_slug': 'top-12-visual-design-trends-for-2024-that-boost-engagement-part-2-da3e4b1ac900', 'image_url': 'https://miro.medium.com/1*AUCseY5Vt4MMvTlUwf6zpA.png', 'lang': 'en', 'is_series': False, 'is_locked': True, 'is_shortform': False, 'top_highlight': ''}, {'id': '572cd5758aa6', 'title': 'Top 12 Visual Design Trends for 2024 That Boost Engagement', 'subtitle': 'The Hottest Creative Styles to Captivate Audiences This Year', 'author': '14176fcb5743', 'publication_id': '48e972f5c24e', 'published_at': '2024-02-17 13:01:57', 'last_modified_at': '2024-02-17 21:52:30', 'tags': ['design', 'creativity', 'art', 'midjourney', 'make-money-online'], 'topics': ['design'], 'claps': 410, 'voters': 26, 'word_count': 1313, 'responses_count': 2, 'reading_time': 6.904716981132076, 'url': 'https://bootcamp.uxdesign.cc/top-12-visual-design-trends-for-2024-that-boost-engagement-572cd5758aa6', 'unique_slug': 'top-12-visual-design-trends-for-2024-that-boost-engagement-572cd5758aa6', 'image_url': 'https://miro.medium.com/1*D0D5XzAIxQ7ywOYPVNbyag.png', 'lang': 'en', 'is_series': False, 'is_locked': True, 'is_shortform': False, 'top_highlight': ''}, {'id': '865c0b54d1cb', 'title': 'Midjourney V6 Alpha is Now the Default with Improvements to Details, Contrast and Coherence🔥', 'subtitle': 'Prepared for NEW “describe” and “Character Consistency” Coming Soon!', 'author': '14176fcb5743', 'publication_id': '48e972f5c24e', 'published_at': '2024-02-15 13:02:01', 'last_modified_at': '2024-02-15 23:48:39', 'tags': ['midjourney', 'artificial-intelligence', 'creativity', 'design', 'art'], 'topics': ['design', 'programming'], 'claps': 163, 'voters': 11, 'word_count': 1155, 'responses_count': 2, 'reading_time': 5.758490566037736, 'url': 'https://bootcamp.uxdesign.cc/midjourney-v6-alpha-is-now-the-default-with-improvements-to-details-contrast-and-coherence-865c0b54d1cb', 'unique_slug': 'midjourney-v6-alpha-is-now-the-default-with-improvements-to-details-contrast-and-coherence-865c0b54d1cb', 'image_url': 'https://miro.medium.com/1*wybK0zuHORyKn8YH0AAELQ.png', 'lang': 'en', 'is_series': False, 'is_locked': True, 'is_shortform': False, 'top_highlight': ''}, {'id': '6e8d6357da20', 'title': 'Midjourney V6 Essential- Transform Style with “Remix” 🎨', 'subtitle': 'A Structure to follow with Visual Examples and Usage', 'author': '14176fcb5743', 'publication_id': '48e972f5c24e', 'published_at': '2024-02-12 13:01:48', 'last_modified_at': '2024-02-12 22:20:55', 'tags': ['midjourney', 'artificial-intelligence', 'creativity', 'design', 'art'], 'topics': ['design'], 'claps': 416, 'voters': 25, 'word_count': 1279, 'responses_count': 5, 'reading_time': 6.576415094339622, 'url': 'https://bootcamp.uxdesign.cc/midjourney-v6-essential-transform-style-with-remix-6e8d6357da20', 'unique_slug': 'midjourney-v6-essential-transform-style-with-remix-6e8d6357da20', 'image_url': 'https://miro.medium.com/1*SrQ7YHs4cumUYkm1j5Kxfw.png', 'lang': 'en', 'is_series': False, 'is_locked': True, 'is_shortform': False, 'top_highlight': ''}, {'id': '92741d8fb067', 'title': 'Ultimate Guide to Using Midjourney Website Alpha! 💻', 'subtitle': 'Image Generation, Batch download and Smart Organisation with Ease!', 'author': '14176fcb5743', 'publication_id': '48e972f5c24e', 'published_at': '2024-02-09 13:01:32', 'last_modified_at': '2024-02-09 21:42:14', 'tags': ['midjourney', 'artificial-intelligence', 'creativity', 'design', 'art'], 'topics': ['design'], 'claps': 584, 'voters': 55, 'word_count': 1139, 'responses_count': 7, 'reading_time': 6.44811320754717, 'url': 'https://bootcamp.uxdesign.cc/ultimate-guide-to-using-midjourney-website-alpha-92741d8fb067', 'unique_slug': 'ultimate-guide-to-using-midjourney-website-alpha-92741d8fb067', 'image_url': 'https://miro.medium.com/1*wkYFlLubAFBU-8aWHkqtfQ.png', 'lang': 'en', 'is_series': False, 'is_locked': True, 'is_shortform': False, 'top_highlight': ''}]])"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_writers['14176fcb5743'].values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "# save dictionary of writer information and articles to json format\n",
    "json_string = json.dumps(list(test_writers.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('writer_info.json', 'w') as json_file:\n",
    "\tjson_file.write(json_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['fca9db1c7da0', 'e10ad955760c', '76398be9016', 'd80580992695', '8a910484fe84', '4beacba7dc8a', '630ab5ffdf27', 'b856005e5ecd', 'b0fbe613be9d', '14176fcb5743', '9b351e8113e9', '5d33decdf4c4', '8c8e5b7182ef', '37a2cbe8bd15', '15a29a4fc6ad', 'fb44e21903f3'])"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_writers.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fca9db1c7da0': {'id': 'fca9db1c7da0',\n",
       "  'username': 'sheilateozy',\n",
       "  'fullname': 'Sheila Teo',\n",
       "  'bio': 'Data Scientist, https://www.linkedin.com/in/sheila-teo/',\n",
       "  'followers_count': 2111,\n",
       "  'following_count': 16,\n",
       "  'publication_following_count': 2,\n",
       "  'image_url': 'https://miro.medium.com/1*UmlZGQsNhuv9kgQL6pFslA.gif',\n",
       "  'twitter_username': '',\n",
       "  'is_writer_program_enrolled': True,\n",
       "  'allow_notes': True,\n",
       "  'medium_member_at': '2023-10-11 08:44:50',\n",
       "  'is_suspended': False,\n",
       "  'top_writer_in': [],\n",
       "  'has_list': False,\n",
       "  'is_book_author': False,\n",
       "  'tipping_link': 'https://ko-fi.com/sheilateo',\n",
       "  'bg_image_url': 'https://miro.medium.com/1*UXNs5AmGon4xRSXANOKA8Q.jpeg',\n",
       "  'logo_image_url': '',\n",
       "  'followers': ['0037690620ed',\n",
       "   '01545acdd5dc',\n",
       "   '02533e82cf32',\n",
       "   '037cf47840d3',\n",
       "   '049a24575f76',\n",
       "   '0563ca85f1ce',\n",
       "   '05c249a233a3',\n",
       "   '068120eb5c86',\n",
       "   '06f27e3e4b56',\n",
       "   '072e8a5bae3f',\n",
       "   '07776a6be87b',\n",
       "   '07e34a659436',\n",
       "   '07e34f7c7d05',\n",
       "   '0898d770aaec',\n",
       "   '0ba16e169f1b',\n",
       "   '0be7589e82af',\n",
       "   '0dc84e997489',\n",
       "   '0e4e43c296c3',\n",
       "   '0e6b445bc2e9',\n",
       "   '0fc25c6ddce0',\n",
       "   '100130cb5f3a',\n",
       "   '1003f78bff66',\n",
       "   '103571b2301',\n",
       "   '104e6f2dee35',\n",
       "   '107eab148cd8',\n",
       "   '10809e49a0f7',\n",
       "   '1087988dcd14',\n",
       "   '109ddee8ed19',\n",
       "   '10ae5a4cc69c',\n",
       "   '10c1fb4676a1',\n",
       "   '10eb1b294a6',\n",
       "   '1111526cc8d9',\n",
       "   '114ee25a8885',\n",
       "   '1150d1a23b0b',\n",
       "   '117b87d0509',\n",
       "   '118f611b37fc',\n",
       "   '11a205eeb0d3',\n",
       "   '11b11f39b8fb',\n",
       "   '11b1cbb9ab3d',\n",
       "   '11dfa21b9e31',\n",
       "   '11f50604c552',\n",
       "   '120b07b1f1f0',\n",
       "   '124060e7a368',\n",
       "   '1256da67d66',\n",
       "   '125b209df9f5',\n",
       "   '127fb4d5f1ab',\n",
       "   '12930cbf4f5a',\n",
       "   '12935397bcf1',\n",
       "   '129d238e441e',\n",
       "   '12c56d867282',\n",
       "   '12d49d6fc8ee',\n",
       "   '12d6a2ec97b',\n",
       "   '12d864e71039',\n",
       "   '131667fa818f',\n",
       "   '133715b59c87',\n",
       "   '1342b6fa9bb0',\n",
       "   '136f00a1f051',\n",
       "   '13892a868dbe',\n",
       "   '139fbc5cfbf7',\n",
       "   '13a4b7fe75a2',\n",
       "   '13a6702a9106',\n",
       "   '13d29f45618b',\n",
       "   '13e1ae0324de',\n",
       "   '146800b81a98',\n",
       "   '1472fefa2726',\n",
       "   '14838626365d',\n",
       "   '148858854d0',\n",
       "   '148ae689f366',\n",
       "   '14a98065ff0c',\n",
       "   '14d86166ad6f',\n",
       "   '14f32acf3397',\n",
       "   '14f8f5fdd30a',\n",
       "   '1503d896d5c1',\n",
       "   '152e2571f73a',\n",
       "   '1568d8ee7a9c',\n",
       "   '158d53902311',\n",
       "   '158f61e51274',\n",
       "   '15b09c0562f5',\n",
       "   '15b154ae2cb5',\n",
       "   '15fa374f76be',\n",
       "   '160206a233f3',\n",
       "   '160a3611ba78',\n",
       "   '16262d07c8aa',\n",
       "   '167fdfa41b1b',\n",
       "   '1691bc75f4fc',\n",
       "   '169f538dfde3',\n",
       "   '16a020cbbac3',\n",
       "   '16ed9209e469',\n",
       "   '1702b0484189',\n",
       "   '17135ea3595b',\n",
       "   '171a8da6d4d2',\n",
       "   '171cf339abc2',\n",
       "   '17787488936a',\n",
       "   '178c2dfb46d6',\n",
       "   '17a2958eebfd',\n",
       "   '17a5424ab02',\n",
       "   '17ad088d7611',\n",
       "   '17c9b888001c',\n",
       "   '17cf7e8c9fa3',\n",
       "   '17de20885fbe',\n",
       "   '18b5fd193c7d',\n",
       "   '18cd1cb8c387',\n",
       "   '18cf1c56822f',\n",
       "   '18f2a4792ef9',\n",
       "   '190879219c69',\n",
       "   '19255e7b9fca',\n",
       "   '192b451c44f',\n",
       "   '1946dacfd581',\n",
       "   '196cc1a76416',\n",
       "   '197e8422e0fc',\n",
       "   '198a0ec09f66',\n",
       "   '19b91c977f65',\n",
       "   '19cad4233712',\n",
       "   '19dd0c8d4ef2',\n",
       "   '19e594cea92b',\n",
       "   '1a0960a5e5d8',\n",
       "   '1a2b4a164606',\n",
       "   '1a37e73e13fa',\n",
       "   '1a45027479b1',\n",
       "   '1a52a163e688',\n",
       "   '1a795dd733ff',\n",
       "   '1a8d9a7a1154',\n",
       "   '1aac0378d08',\n",
       "   '1ad971c986a3',\n",
       "   '1b025a36076d',\n",
       "   '1b143d93cae3',\n",
       "   '1b17cba977ce',\n",
       "   '1b33a6992e38',\n",
       "   '1b3581d77e59',\n",
       "   '1b5776dcec20',\n",
       "   '1b62bbd4b8fa',\n",
       "   '1b66a948a46b',\n",
       "   '1b7726fe6e23',\n",
       "   '1b8c1ccb940',\n",
       "   '1b95f0abfc7',\n",
       "   '1baa04e6c10f',\n",
       "   '1bab0eebf8ad',\n",
       "   '1bf3eeb4c176',\n",
       "   '1c21c9489490',\n",
       "   '1c2de135b506',\n",
       "   '1c31311b814a',\n",
       "   '1c38d2ae2cab',\n",
       "   '1c4c52460647',\n",
       "   '1c7f1b2ec141',\n",
       "   '1c80cc183550',\n",
       "   '1c8c2c95b65c',\n",
       "   '1d45745cf04d',\n",
       "   '1d61a22bf84d',\n",
       "   '1d61b6484f68',\n",
       "   '1d86cc7c988f',\n",
       "   '1d8c997e56f',\n",
       "   '1df725bf1e10',\n",
       "   '1e21b01857b7',\n",
       "   '1e5d59c39633',\n",
       "   '1e5e1d6f9246',\n",
       "   '1e9c63609dd8',\n",
       "   '1ea5b0068b9e',\n",
       "   '1eb044daad32',\n",
       "   '1ec0ef32ba5e',\n",
       "   '1f0bdba77b61',\n",
       "   '1f12cc676340',\n",
       "   '1f1f2fe2d8e',\n",
       "   '1f2002b4afd5',\n",
       "   '1f30e2517d7d',\n",
       "   '1f38862a373a',\n",
       "   '1f49a76b5dbf',\n",
       "   '1f6a2872d3ba',\n",
       "   '1f806cbd06a3',\n",
       "   '1f80c20e1605',\n",
       "   '1f992c278206',\n",
       "   '1fbad54a1a4c',\n",
       "   '1fcbe0e72',\n",
       "   '1fdad61879a',\n",
       "   '1ff84ce5d71e',\n",
       "   '20056822c5e9',\n",
       "   '201f51730529',\n",
       "   '2038a4578a09',\n",
       "   '207988005f34',\n",
       "   '20c7c7250e7d',\n",
       "   '20d6e3bd4448',\n",
       "   '20dee3a5f3f7',\n",
       "   '20fde2e682fe',\n",
       "   '21110cd779c1',\n",
       "   '211e57773b60',\n",
       "   '2147d2141871',\n",
       "   '215a921e117e',\n",
       "   '216f4a9f397d',\n",
       "   '21d7e3ed77b9',\n",
       "   '21db5ec686ec',\n",
       "   '21f9aef0706d',\n",
       "   '221953517d77',\n",
       "   '2223f1eeeb6b',\n",
       "   '2227b9abe4b3',\n",
       "   '222a54770ce4',\n",
       "   '22336e9a638d',\n",
       "   '22a1bd45b190',\n",
       "   '22a1eee94b17',\n",
       "   '22f809b0f6e',\n",
       "   '232cc30fcdd4',\n",
       "   '232dafee93a7',\n",
       "   '2345c09bd515',\n",
       "   '235a8e13f0aa',\n",
       "   '238ff338127f',\n",
       "   '23cb27b3d676',\n",
       "   '23d591f8c62b',\n",
       "   '23e230a7bb62',\n",
       "   '23ed4c1c194c',\n",
       "   '240e5ff0bdac',\n",
       "   '241431e40959',\n",
       "   '2421dae9756',\n",
       "   '242546687286',\n",
       "   '245f97293f28',\n",
       "   '2462c40cc0fc',\n",
       "   '24739a967b10',\n",
       "   '24a30481245b',\n",
       "   '24bf3cb876e',\n",
       "   '250cd24cecf6',\n",
       "   '254e653181d2',\n",
       "   '2552d67b635a',\n",
       "   '2574477c96c5',\n",
       "   '2595a8e1f019',\n",
       "   '25969546056',\n",
       "   '259e270544a1',\n",
       "   '25b72c578216',\n",
       "   '260d3636c103',\n",
       "   '2620a9fe68a6',\n",
       "   '263e67b31f76',\n",
       "   '26541584aaf3',\n",
       "   '26713aebf55c',\n",
       "   '26a6c3a2b11f',\n",
       "   '26b873a96c43',\n",
       "   '26d875208aed',\n",
       "   '274124d7b5ea',\n",
       "   '275d1c3753b1',\n",
       "   '27a640854747',\n",
       "   '27a676387455',\n",
       "   '27ac89d76183',\n",
       "   '27aee7ba01e3',\n",
       "   '27b16783c35c',\n",
       "   '27e82070ebf5',\n",
       "   '27ed17c95fc5',\n",
       "   '27ffaffe620b',\n",
       "   '28195d56dc07',\n",
       "   '282b4abd098c',\n",
       "   '283b9d3bdb9d',\n",
       "   '28472f176d5',\n",
       "   '2851eb8b7dc0',\n",
       "   '2860529375ec',\n",
       "   '286f17319b8e',\n",
       "   '28addfa604a2',\n",
       "   '28ce6a616ea9',\n",
       "   '28d17c8eb2dc',\n",
       "   '28e67395edbd',\n",
       "   '2916cb3fd236',\n",
       "   '294aebc97b51',\n",
       "   '296748b0175',\n",
       "   '297e51245852',\n",
       "   '29924788dea8',\n",
       "   '299a399693a7',\n",
       "   '29bce29af83f',\n",
       "   '29caff485c5',\n",
       "   '29f459525caa',\n",
       "   '2a02e436f9b3',\n",
       "   '2a6a5aa51240',\n",
       "   '2a8736afd5e6',\n",
       "   '2a94df6eb624',\n",
       "   '2ab4498735cb',\n",
       "   '2ab9f98db92d',\n",
       "   '2b25f8105a4a',\n",
       "   '2b2a855a4b9c',\n",
       "   '2b82e19db3be',\n",
       "   '2b8a3d6203ce',\n",
       "   '2bd41a7eb4b9',\n",
       "   '2be3f6dbd3d3',\n",
       "   '2bee5569e17b',\n",
       "   '2bf6f536f700',\n",
       "   '2c0961f12de7',\n",
       "   '2c193c2c51d1',\n",
       "   '2c3ed7d9a734',\n",
       "   '2c5dcda349ee',\n",
       "   '2c5e5df36874',\n",
       "   '2c6c716b2ec3',\n",
       "   '2c6ff54608e5',\n",
       "   '2c78890cb2e9',\n",
       "   '2c8c7efbe7af',\n",
       "   '2ced48fdc5f1',\n",
       "   '2d23c4ccfadc',\n",
       "   '2d36a6f5a4dc',\n",
       "   '2d4ea74beed4',\n",
       "   '2d736468ba7a',\n",
       "   '2d7c383b0d6c',\n",
       "   '2d8396ccfa7f',\n",
       "   '2d93b58a0f8a',\n",
       "   '2dac3478a8f9',\n",
       "   '2db491df47db',\n",
       "   '2dd95a8da342',\n",
       "   '2deeb387b27c',\n",
       "   '2df2ad7c8ded',\n",
       "   '2e36d844f63e',\n",
       "   '2e487ebbd7c3',\n",
       "   '2e6c787baa97',\n",
       "   '2e909231046',\n",
       "   '2e98d2b47491',\n",
       "   '2eb6ed025385',\n",
       "   '2ef5137cfb52',\n",
       "   '2f45238d380a',\n",
       "   '2f53ccfa3e70',\n",
       "   '2f6e0afd9b17',\n",
       "   '2f721b484b71',\n",
       "   '2f974295d555',\n",
       "   '2fb7d7a5d437',\n",
       "   '2fb9bbb8395e',\n",
       "   '2fc7128b61b9',\n",
       "   '2fd662cff65',\n",
       "   '2ff751b6b28',\n",
       "   '300932814274',\n",
       "   '300af2335ef0',\n",
       "   '300b3068b9cb',\n",
       "   '306033f095fc',\n",
       "   '30618acc174f',\n",
       "   '3065e94428b1',\n",
       "   '307cf3fed8f3',\n",
       "   '309411915414',\n",
       "   '30c6bb8d8b33',\n",
       "   '30d9ebb5d14e',\n",
       "   '30e8701d3b7',\n",
       "   '30fea69a5379',\n",
       "   '311ef44807a0',\n",
       "   '312ddc2f5661',\n",
       "   '31392b352019',\n",
       "   '314bad222d98',\n",
       "   '317d2c36c3c2',\n",
       "   '3188c8c51a1f',\n",
       "   '31a22280e522',\n",
       "   '31c90dbaa414',\n",
       "   '31ccf6b63c65',\n",
       "   '31e6df7c31c4',\n",
       "   '31ee22931ebc',\n",
       "   '31f0b60f589d',\n",
       "   '3210cdfd89bb',\n",
       "   '3230c8577683',\n",
       "   '327fba308cb4',\n",
       "   '32bcdad9a02e',\n",
       "   '32c9a5daf94',\n",
       "   '32d828f85104',\n",
       "   '3341760cfecc',\n",
       "   '336d298be9f9',\n",
       "   '339d7693bd23',\n",
       "   '33ae616e4a2e',\n",
       "   '340173c1cae3',\n",
       "   '340da48444ef',\n",
       "   '34110f02021a',\n",
       "   '342a310f3603',\n",
       "   '3446bd7a71a5',\n",
       "   '34536064487c',\n",
       "   '3454f558c8b2',\n",
       "   '34712f78e59',\n",
       "   '34bc0bc70527',\n",
       "   '34dbcc04c55',\n",
       "   '34ef93e174ca',\n",
       "   '352367b2bcd9',\n",
       "   '3526b8a1aba6',\n",
       "   '3531b65ca266',\n",
       "   '353ff8c26606',\n",
       "   '355ab04cdc6f',\n",
       "   '35667da67e95',\n",
       "   '3568102908d8',\n",
       "   '3584ae2be8ef',\n",
       "   '35ae5a8b0332',\n",
       "   '35cdff80635a',\n",
       "   '35dadf373281',\n",
       "   '35e5c85cdc03',\n",
       "   '35ffcc9a155c',\n",
       "   '36382e46bd27',\n",
       "   '364813830cb5',\n",
       "   '366799ba6166',\n",
       "   '3691db96637a',\n",
       "   '36986ee89fda',\n",
       "   '36b8d5ca089b',\n",
       "   '36d01147dfd6',\n",
       "   '371cc54053d5',\n",
       "   '375810cbf7d1',\n",
       "   '3758607015c5',\n",
       "   '37fb6215fe2c',\n",
       "   '384235bf4a78',\n",
       "   '3867bd959df2',\n",
       "   '3888ba015d84',\n",
       "   '3891c05f2401',\n",
       "   '389c460042dc',\n",
       "   '38a45bc85ba3',\n",
       "   '38a73e03a2bd',\n",
       "   '39012ebeb6da',\n",
       "   '3911a2da7f7e',\n",
       "   '39425e737d54',\n",
       "   '3958ce7b0a09',\n",
       "   '39877fc04ab5',\n",
       "   '39ba49470d23',\n",
       "   '39df77437b5b',\n",
       "   '3a068833f0fd',\n",
       "   '3a1cb0d15387',\n",
       "   '3a21b0b6405',\n",
       "   '3a924a04bfba',\n",
       "   '3a9b7cd8496',\n",
       "   '3abb5812d43',\n",
       "   '3acbcc8f28e1',\n",
       "   '3aeb7384083a',\n",
       "   '3af7ecdedae0',\n",
       "   '3b0dc9811625',\n",
       "   '3b28c383478e',\n",
       "   '3b4256bd37e6',\n",
       "   '3b487b2e2c93',\n",
       "   '3ba706b3ee54',\n",
       "   '3bab7d566179',\n",
       "   '3c0070fe8a54',\n",
       "   '3c92223562e1',\n",
       "   '3c97e67e041d',\n",
       "   '3cb440764fc4',\n",
       "   '3cdb183ec4dd',\n",
       "   '3ce4a2ed76cc',\n",
       "   '3ce611a70687',\n",
       "   '3ced08c4ede3',\n",
       "   '3cf698f9e01c',\n",
       "   '3cfa1c83a95f',\n",
       "   '3d1c8db21fb0',\n",
       "   '3d2d6f48d179',\n",
       "   '3d2db6a2946b',\n",
       "   '3d3ccfe5cc64',\n",
       "   '3d4c5d91eeec',\n",
       "   '3d57921f2742',\n",
       "   '3d8dbeb9314d',\n",
       "   '3d8debdc3363',\n",
       "   '3d977f4ac15d',\n",
       "   '3da8a61ca6cb',\n",
       "   '3e15660c4ff4',\n",
       "   '3e3a830c73c5',\n",
       "   '3e601e922108',\n",
       "   '3e6a4844f16d',\n",
       "   '3e78a66bf655',\n",
       "   '3eb3947a724e',\n",
       "   '3ee7a93a472b',\n",
       "   '3f026fd617e6',\n",
       "   '3f049b1bc69c',\n",
       "   '3f55d7d7a3e7',\n",
       "   '3f6a1df33fab',\n",
       "   '3f6e94323f54',\n",
       "   '3f75236f0633',\n",
       "   '3fd893534d6b',\n",
       "   '3fe660c24e52',\n",
       "   '3ffb2d20574b',\n",
       "   '40098a41cd9f',\n",
       "   '4011848f12e9',\n",
       "   '405196932e0f',\n",
       "   '40676f3c5d7c',\n",
       "   '406a12c95a7e',\n",
       "   '407124b7da5b',\n",
       "   '40b7b5b6d321',\n",
       "   '40c8a23b90d5',\n",
       "   '40db095ecc2c',\n",
       "   '40f92e632e65',\n",
       "   '41264972aeef',\n",
       "   '413f41a58494',\n",
       "   '4155e4e99a67',\n",
       "   '417779fee024',\n",
       "   '41aff52b2f70',\n",
       "   '41befeaee0c7',\n",
       "   '41ce34b894f4',\n",
       "   '41e8a9e4637d',\n",
       "   '42079a49c8ec',\n",
       "   '4232a5f9e599',\n",
       "   '424084974977',\n",
       "   '4262bbc4b8a8',\n",
       "   '42697edb950f',\n",
       "   '426e2cacc658',\n",
       "   '4271399e5ae6',\n",
       "   '4288a53c86e0',\n",
       "   '42908a5658b5',\n",
       "   '42aeca1e18e5',\n",
       "   '42c72ed7472c',\n",
       "   '42cfbfcb8473',\n",
       "   '434998b874db',\n",
       "   '438997c02baf',\n",
       "   '43bc52d139e5',\n",
       "   '43ca83f33c10',\n",
       "   '43e36df2cffa',\n",
       "   '43fe3cbae1ca',\n",
       "   '441585203bff',\n",
       "   '444530f6f78e',\n",
       "   '447ba43dbd76',\n",
       "   '447c330e1b84',\n",
       "   '4489283c8ab1',\n",
       "   '44bffcff5d54',\n",
       "   '44c5e5fbd36d',\n",
       "   '44dc4c6cf3db',\n",
       "   '44ee7bb7b54f',\n",
       "   '450d641f20f8',\n",
       "   '4514ad7050a',\n",
       "   '45256b119fe1'],\n",
       "  'top_articles': [{'id': '34c195a93d41',\n",
       "    'title': 'How I Won Singapore’s GPT-4 Prompt Engineering Competition',\n",
       "    'subtitle': 'A deep dive into the strategies I learned for harnessing the power of Large Language Models (LLMs)',\n",
       "    'author': 'fca9db1c7da0',\n",
       "    'publication_id': '7f60cf5620c9',\n",
       "    'published_at': '2023-12-29 00:29:22',\n",
       "    'last_modified_at': '2024-01-29 06:15:01',\n",
       "    'tags': ['data-science',\n",
       "     'artificial-intelligence',\n",
       "     'prompt-engineering',\n",
       "     'editors-pick',\n",
       "     'technology'],\n",
       "    'topics': ['artificial-intelligence', 'data-science'],\n",
       "    'claps': 11406,\n",
       "    'voters': 2300,\n",
       "    'word_count': 5571,\n",
       "    'responses_count': 157,\n",
       "    'reading_time': 22.722641509433963,\n",
       "    'url': 'https://towardsdatascience.com/how-i-won-singapores-gpt-4-prompt-engineering-competition-34c195a93d41',\n",
       "    'unique_slug': 'how-i-won-singapores-gpt-4-prompt-engineering-competition-34c195a93d41',\n",
       "    'image_url': 'https://miro.medium.com/1*RAI4cBXe1_zaxVykHz79oA.jpeg',\n",
       "    'lang': 'en',\n",
       "    'is_series': False,\n",
       "    'is_locked': True,\n",
       "    'is_shortform': False,\n",
       "    'top_highlight': 'Use System Prompts to provide instructions that you want the LLM to remember when responding throughout the entire chat.'},\n",
       "   {'id': '8c339f8fb602',\n",
       "    'title': 'Stacked Ensembles for Advanced Predictive Modeling With H2O.ai and Optuna',\n",
       "    'subtitle': 'And how I placed top 10% in Europe’s largest machine learning competition with them!',\n",
       "    'author': 'fca9db1c7da0',\n",
       "    'publication_id': '7f60cf5620c9',\n",
       "    'published_at': '2023-12-18 16:05:44',\n",
       "    'last_modified_at': '2023-12-29 16:32:23',\n",
       "    'tags': ['machine-learning',\n",
       "     'data-science',\n",
       "     'deep-learning',\n",
       "     'ensemble-learning',\n",
       "     'python'],\n",
       "    'topics': ['machine-learning', 'data-science'],\n",
       "    'claps': 462,\n",
       "    'voters': 104,\n",
       "    'word_count': 3134,\n",
       "    'responses_count': 11,\n",
       "    'reading_time': 12.376415094339624,\n",
       "    'url': 'https://towardsdatascience.com/stacked-ensembles-for-advanced-predictive-modeling-with-h2o-ai-and-optuna-8c339f8fb602',\n",
       "    'unique_slug': 'stacked-ensembles-for-advanced-predictive-modeling-with-h2o-ai-and-optuna-8c339f8fb602',\n",
       "    'image_url': 'https://miro.medium.com/1*5FM14YZopRvGK9baJR0OtQ.png',\n",
       "    'lang': 'en',\n",
       "    'is_series': False,\n",
       "    'is_locked': True,\n",
       "    'is_shortform': False,\n",
       "    'top_highlight': ''}]},\n",
       " 'e10ad955760c': {'id': 'e10ad955760c',\n",
       "  'username': 'nikhiladithyan',\n",
       "  'fullname': 'Nikhil Adithyan',\n",
       "  'bio': 'Founder @BacktestZone (https://www.backtestzone.com/), a no-code backtesting platform | Top Writer | Connect with me on LinkedIn: https://bit.ly/3yNuwCJ',\n",
       "  'followers_count': 7044,\n",
       "  'following_count': 41,\n",
       "  'publication_following_count': 11,\n",
       "  'image_url': 'https://miro.medium.com/1*fiFn4AhPBi-CG-cKxHk2zQ.jpeg',\n",
       "  'twitter_username': '',\n",
       "  'is_writer_program_enrolled': True,\n",
       "  'allow_notes': True,\n",
       "  'medium_member_at': '2024-01-03 15:38:18',\n",
       "  'is_suspended': False,\n",
       "  'top_writer_in': ['artificial-intelligence', 'technology'],\n",
       "  'has_list': True,\n",
       "  'is_book_author': False,\n",
       "  'tipping_link': 'https://paypal.me/veerabadran75?country.x=IN&locale.x=en_GB',\n",
       "  'bg_image_url': 'https://miro.medium.com/1*NVIBpx9wZp0Xq9KkSPU58w.png',\n",
       "  'logo_image_url': '',\n",
       "  'followers': ['00149b7421b2',\n",
       "   '00183ef79cce',\n",
       "   '00418aadfc4b',\n",
       "   '00555da4d13e',\n",
       "   '005c18b43c6c',\n",
       "   '009733c9ec1e',\n",
       "   '00a78a6007f4',\n",
       "   '00adf31ab408',\n",
       "   '00b8eada8b79',\n",
       "   '00c31001fec0',\n",
       "   '00cb490f7bee',\n",
       "   '00f2d8152332',\n",
       "   '0109e784bcf3',\n",
       "   '0143c3cfd773',\n",
       "   '01a9c1259fcc',\n",
       "   '01cf0debc091',\n",
       "   '01e22e257aad',\n",
       "   '01eb5edb6a57',\n",
       "   '01ec1a0c6bf3',\n",
       "   '01faad01498c',\n",
       "   '0215bf12b71b',\n",
       "   '022a74088f12',\n",
       "   '028b27877c10',\n",
       "   '029482385112',\n",
       "   '03133540481d',\n",
       "   '0315db4cbe86',\n",
       "   '032e23fb0d6c',\n",
       "   '0344c819f9fc',\n",
       "   '0345651c406a',\n",
       "   '03609e9ab716',\n",
       "   '036ecf5a78de',\n",
       "   '0375cf039b1f',\n",
       "   '037e56d957e3',\n",
       "   '03bff1292d9c',\n",
       "   '03d778a58360',\n",
       "   '03f6ee79f36c',\n",
       "   '045559435124',\n",
       "   '0458ac9ef3fd',\n",
       "   '0476caa94dfc',\n",
       "   '0488cb6529c7',\n",
       "   '04b04fd923ef',\n",
       "   '04b1c11cd996',\n",
       "   '04b7ceab9f78',\n",
       "   '04ca33ca0707',\n",
       "   '04e94eb13d69',\n",
       "   '051276cc78f1',\n",
       "   '053ddfdb3053',\n",
       "   '0556c608c8b7',\n",
       "   '056d17f08df8',\n",
       "   '057ae7cd2ddd',\n",
       "   '057c43d907f2',\n",
       "   '058a6d5a31c2',\n",
       "   '0591cd50fcdb',\n",
       "   '05a7512b66cd',\n",
       "   '05cf15363a93',\n",
       "   '05e507811d9f',\n",
       "   '060a20697ec0',\n",
       "   '0612100996f6',\n",
       "   '0649acc497b0',\n",
       "   '064ece55104e',\n",
       "   '064f9190c730',\n",
       "   '069e39a538ec',\n",
       "   '06ffa3d84351',\n",
       "   '071c8132ccd0',\n",
       "   '071da920fdde',\n",
       "   '0726c6a08a55',\n",
       "   '073133dbe904',\n",
       "   '07630528f351',\n",
       "   '07a32ae77163',\n",
       "   '07c53b240b01',\n",
       "   '08097d4c62a1',\n",
       "   '081e7c5a55c6',\n",
       "   '0863583a2017',\n",
       "   '0866c1a979c3',\n",
       "   '086801ed3994',\n",
       "   '08c62e60b692',\n",
       "   '092d376d06b1',\n",
       "   '09335f825c05',\n",
       "   '093b94338898',\n",
       "   '096d447a462e',\n",
       "   '09abeab74b1b',\n",
       "   '09b6ac590e29',\n",
       "   '09b7fba39f2e',\n",
       "   '09edfe95038a',\n",
       "   '0a5b4b6bf759',\n",
       "   '0a8cc69ddb75',\n",
       "   '0a9f4e679fe2',\n",
       "   '0aa919e64d91',\n",
       "   '0abce5a499cf',\n",
       "   '0ac981d0a6a1',\n",
       "   '0af0a1b91b37',\n",
       "   '0b1f7a361970',\n",
       "   '0b2021d26409',\n",
       "   '0b234e69a7f9',\n",
       "   '0b36e4263392',\n",
       "   '0b37349d902a',\n",
       "   '0b8ff2210469',\n",
       "   '0b94187ee8f5',\n",
       "   '0b96f6886a09',\n",
       "   '0bbd1d8ab904',\n",
       "   '0bc872ce959b',\n",
       "   '0bf1aaa7789b',\n",
       "   '0c12ddd398a9',\n",
       "   '0c36b68c3f11',\n",
       "   '0c4a6fad5f96',\n",
       "   '0c602f4e893a',\n",
       "   '0c834d1c219f',\n",
       "   '0c8d56eda234',\n",
       "   '0ccd347285af',\n",
       "   '0cec65fa12b8',\n",
       "   '0ced55597187',\n",
       "   '0cf3cf1c1015',\n",
       "   '0d1aa9ca5728',\n",
       "   '0d2949696dc1',\n",
       "   '0d6a560df67d',\n",
       "   '0d7815861d2c',\n",
       "   '0d89ecd05943',\n",
       "   '0d9c480487a9',\n",
       "   '0dc20688cac0',\n",
       "   '0dd63eaaa48f',\n",
       "   '0e365ad5e60a',\n",
       "   '0e4aa70f7594',\n",
       "   '0e5faf098978',\n",
       "   '0e61305155f2',\n",
       "   '0e7588d35f8d',\n",
       "   '0e7dc74f4b5f',\n",
       "   '0e809eb771c1',\n",
       "   '0eacbe3178a1',\n",
       "   '0ec324fbcb05',\n",
       "   '0ed0e5a8ca2f',\n",
       "   '0efa91bc2ac7',\n",
       "   '0f14b25034eb',\n",
       "   '0f68be24fe5d',\n",
       "   '0f6f08d3268f',\n",
       "   '0fdacfb5e0a2',\n",
       "   '0fdd58b66321',\n",
       "   '1002708bb2dd',\n",
       "   '1017ec31ff47',\n",
       "   '1041042eecf4',\n",
       "   '104405037911',\n",
       "   '1047a13dcf84',\n",
       "   '10497a096abc',\n",
       "   '105a25458d59',\n",
       "   '105a3c72085a',\n",
       "   '10626c7bdc67',\n",
       "   '106745496231',\n",
       "   '106ae4eb88b0',\n",
       "   '107492e4f8c5',\n",
       "   '107e751f0199',\n",
       "   '1087a3cf4a0f',\n",
       "   '108e08d9c994',\n",
       "   '1096b7e06ce2',\n",
       "   '109ddee8ed19',\n",
       "   '109ff6d51065',\n",
       "   '10a06830076d',\n",
       "   '10a305a6c9d5',\n",
       "   '10aacc6f7e3d',\n",
       "   '10b81a106444',\n",
       "   '10be897e1662',\n",
       "   '10cceacb79a5',\n",
       "   '10cf78ee0cba',\n",
       "   '10cfc8f4b0ce',\n",
       "   '10d0fed7e76f',\n",
       "   '10d64fbe4bc5',\n",
       "   '10d971fe0375',\n",
       "   '10dd161d7772',\n",
       "   '10de7cb84f80',\n",
       "   '10dff6eeed00',\n",
       "   '10e8b71566e',\n",
       "   '10eb8bf345c1',\n",
       "   '10ed7cb7442e',\n",
       "   '10f581b06f04',\n",
       "   '10fecb0972ba',\n",
       "   '110b2339d711',\n",
       "   '110da4763449',\n",
       "   '1125918679ba',\n",
       "   '113ee8fc4182',\n",
       "   '114bb975ae25',\n",
       "   '116d7b59a07d',\n",
       "   '1172fd6dc56',\n",
       "   '1191aae9fbe7',\n",
       "   '11939f12eb7e',\n",
       "   '119461a67189',\n",
       "   '119668a80479',\n",
       "   '11ac10147fb0',\n",
       "   '11ac44078875',\n",
       "   '11af8c1ee005',\n",
       "   '11ba4de99946',\n",
       "   '11c63cf0ce56',\n",
       "   '11c675ef5930',\n",
       "   '11ea806b0a0a',\n",
       "   '11ebdbfd3d01',\n",
       "   '11f57056ef35',\n",
       "   '11f622ac4fc5',\n",
       "   '11ff1013b4d6',\n",
       "   '1200b2182238',\n",
       "   '120395cb5552',\n",
       "   '1203ff17e2d6',\n",
       "   '120718656361',\n",
       "   '120ba2a15cbf',\n",
       "   '120e9fd3086',\n",
       "   '1215a1073da7',\n",
       "   '122e0b588f5f',\n",
       "   '123aeb8f2a65',\n",
       "   '124da67fdbab',\n",
       "   '12524c2bcf45',\n",
       "   '1256da67d66',\n",
       "   '125eb60c78ff',\n",
       "   '12665ee42fe5',\n",
       "   '126dcdd739e9',\n",
       "   '1276a2ab058c',\n",
       "   '1279b2ff18e1',\n",
       "   '12892a109be6',\n",
       "   '128da2b4ec36',\n",
       "   '129a68b12a3b',\n",
       "   '129fb2cd056f',\n",
       "   '12a204627804',\n",
       "   '12a3be4b5805',\n",
       "   '12a4a68006b7',\n",
       "   '12a9f08aed7b',\n",
       "   '12ad037c4c7e',\n",
       "   '12b889180aa8',\n",
       "   '12e327e575dc',\n",
       "   '12e73c0f1931',\n",
       "   '12ea0ea3cf20',\n",
       "   '12ef6616161c',\n",
       "   '12f50c61038f',\n",
       "   '12fa3dfc9fcf',\n",
       "   '12ffa859e07d',\n",
       "   '1301ed5b36e6',\n",
       "   '13072b8d22f3',\n",
       "   '130800821d36',\n",
       "   '130c9927dfaf',\n",
       "   '130d0f4fb9c9',\n",
       "   '13244b92ff7a',\n",
       "   '133229767165',\n",
       "   '1334d2e5afe',\n",
       "   '1340f0cb9bfe',\n",
       "   '135253871a3b',\n",
       "   '135607d83f67',\n",
       "   '1365178c7535',\n",
       "   '136902642b64',\n",
       "   '136b8d469bf9',\n",
       "   '136cf1142fed',\n",
       "   '137b395910dc',\n",
       "   '137c131485da',\n",
       "   '13a40599fb71',\n",
       "   '13a64b26206d',\n",
       "   '13bca66e9a0b',\n",
       "   '13ce2c4c46a7',\n",
       "   '13d279556fc2',\n",
       "   '13e90ef9aef',\n",
       "   '13ecc6bcd7ee',\n",
       "   '13ee5c5ac2b1',\n",
       "   '13fdeefac3ba',\n",
       "   '141161644192',\n",
       "   '142a5b944941',\n",
       "   '142cd54f2047',\n",
       "   '1430456ad365',\n",
       "   '143184ecac7b',\n",
       "   '14446d982b66',\n",
       "   '1447748d95d3',\n",
       "   '1448d7661cec',\n",
       "   '1448e970c28',\n",
       "   '145c5b968234',\n",
       "   '14657854cafa',\n",
       "   '14671773ef5',\n",
       "   '146b1ef463a9',\n",
       "   '14762f2b17f2',\n",
       "   '148ae689f366',\n",
       "   '148b4f785641',\n",
       "   '148c1be58442',\n",
       "   '148e65c6a81a',\n",
       "   '14950b04f4d9',\n",
       "   '14aadbfe102a',\n",
       "   '14ca2b0807e8',\n",
       "   '14cd2b5df6f5',\n",
       "   '14d767c71e5b',\n",
       "   '14d7cdda8afa',\n",
       "   '14d8d59ae35c',\n",
       "   '14d9991e7944',\n",
       "   '14e31690cede',\n",
       "   '14f13d7da131',\n",
       "   '15117a3e232c',\n",
       "   '15127b43c5cd',\n",
       "   '152ed5acea22',\n",
       "   '1530d465dbcc',\n",
       "   '1537c3b25c80',\n",
       "   '154e49eaa3ce',\n",
       "   '1565865a39bc',\n",
       "   '156675d1f1f0',\n",
       "   '156763787e80',\n",
       "   '156d7df54349',\n",
       "   '157174a5390c',\n",
       "   '15745a47dc7',\n",
       "   '1578151e227b',\n",
       "   '15898626fa82',\n",
       "   '158a8cec6718',\n",
       "   '15966a0e203a',\n",
       "   '1596aa39d815',\n",
       "   '1597a5e848ab',\n",
       "   '159a50f05cb3',\n",
       "   '159a81fabf0c',\n",
       "   '15a6ca4c955e',\n",
       "   '15cbb5ae0eeb',\n",
       "   '15d1985b3bbd',\n",
       "   '15d1c06b368d',\n",
       "   '15d24f1029cd',\n",
       "   '15e3b066f9b8',\n",
       "   '160c0bac9012',\n",
       "   '160c3e933453',\n",
       "   '162493f72268',\n",
       "   '164497287266',\n",
       "   '1651eb9a4ba0',\n",
       "   '165c408ed9b',\n",
       "   '1675f455ff19',\n",
       "   '167cfb793ee3',\n",
       "   '1684cc3963b5',\n",
       "   '168ade45dce2',\n",
       "   '168b985e91b0',\n",
       "   '168e9003ef74',\n",
       "   '168f8fc4a832',\n",
       "   '169b5527fee1',\n",
       "   '169c5dc9497d',\n",
       "   '169fe19d8df8',\n",
       "   '16aadebc2fce',\n",
       "   '16afe74ef984',\n",
       "   '16c33b9713c8',\n",
       "   '16c3b3f94a5f',\n",
       "   '16c57ca9ba40',\n",
       "   '16c5dd564002',\n",
       "   '16c9194b3c3f',\n",
       "   '16cf86c4bbb5',\n",
       "   '16d00810ad30',\n",
       "   '16e17a3a28cc',\n",
       "   '16e7e8d8f18e',\n",
       "   '1704096afcd4',\n",
       "   '17082f91e32b',\n",
       "   '170cee3dbfa6',\n",
       "   '1715f386c47c',\n",
       "   '17177ddb9346',\n",
       "   '171e4625019d',\n",
       "   '172e53866d46',\n",
       "   '172f2b2a4ee7',\n",
       "   '174458d9b787',\n",
       "   '1744f4151595',\n",
       "   '1752ebf3bdc7',\n",
       "   '175387949708',\n",
       "   '17642c8a9218',\n",
       "   '17645ab95c5a',\n",
       "   '176530335ccb',\n",
       "   '176670e9c6c6',\n",
       "   '176917181194',\n",
       "   '17761ba6e006',\n",
       "   '17819ac3102a',\n",
       "   '178e1694ea41',\n",
       "   '17994169720',\n",
       "   '179cd0885a2',\n",
       "   '179f8d32ccd2',\n",
       "   '17a0fb103d7f',\n",
       "   '17a99636e7',\n",
       "   '17b8c87426a7',\n",
       "   '17bb2a364fb7',\n",
       "   '17be8e0d12cf',\n",
       "   '17befc1a93a6',\n",
       "   '17c9b888001c',\n",
       "   '17cbfaad6866',\n",
       "   '17cc489b125d',\n",
       "   '17ccdcaeabd7',\n",
       "   '17cd9a55c071',\n",
       "   '17ce2d37c16a',\n",
       "   '17da3bb741d5',\n",
       "   '17f94d50271b',\n",
       "   '17fbaeb73b20',\n",
       "   '17fdd7a7ba0d',\n",
       "   '18043d4355ed',\n",
       "   '18094fd27d29',\n",
       "   '1817385bb13f',\n",
       "   '181aec70f893',\n",
       "   '18298843b89',\n",
       "   '182cf34c2fae',\n",
       "   '182dda462ef2',\n",
       "   '1833532cf8d1',\n",
       "   '1834a87307ce',\n",
       "   '18363c9fee64',\n",
       "   '184bc2662bb8',\n",
       "   '185e09e3fc6d',\n",
       "   '18661e81f319',\n",
       "   '186766706a9e',\n",
       "   '18687e7631d7',\n",
       "   '187277a001df',\n",
       "   '188549d9b8e3',\n",
       "   '18885432cdf0',\n",
       "   '1895c8dbf967',\n",
       "   '189823b30cbd',\n",
       "   '18a35891105a',\n",
       "   '18a42b5dd85',\n",
       "   '18a5ebc26249',\n",
       "   '18a6db16996d',\n",
       "   '18b055c50d64',\n",
       "   '18b0daa4388e',\n",
       "   '18c34ef669f',\n",
       "   '18ccd143350e',\n",
       "   '18d3d3c27b7a',\n",
       "   '18dae231b60e',\n",
       "   '18e4c0f348aa',\n",
       "   '18f732948dd1',\n",
       "   '190a292777d4',\n",
       "   '1915afa5a5a5',\n",
       "   '19249b2351ae',\n",
       "   '192f273107b',\n",
       "   '19330404384e',\n",
       "   '1936048e08d6',\n",
       "   '194e1c158333',\n",
       "   '195e6a161649',\n",
       "   '1975ecf7d15a',\n",
       "   '19762c6c7b10',\n",
       "   '19880a76e030',\n",
       "   '19a6d67c6a9b',\n",
       "   '19b94f6f208a',\n",
       "   '19c249cb2aed',\n",
       "   '19cad4233712',\n",
       "   '19d03c669023',\n",
       "   '19dd0b03b71d',\n",
       "   '19efbf6cb6f6',\n",
       "   '19fff93cd315',\n",
       "   '1a05438d6247',\n",
       "   '1a08496ec3b0',\n",
       "   '1a0874fdea94',\n",
       "   '1a0b9d57826f',\n",
       "   '1a26226717de',\n",
       "   '1a2dbd8414a4',\n",
       "   '1a3b96579e7c',\n",
       "   '1a45027479b1',\n",
       "   '1a4fda812580',\n",
       "   '1a54ec526cbc',\n",
       "   '1a5629a9ff57',\n",
       "   '1a56f4f58b2b',\n",
       "   '1a6406209265',\n",
       "   '1a7661f07732',\n",
       "   '1a7942f3d9c6',\n",
       "   '1a7b4287ab33',\n",
       "   '1a7c5a422267',\n",
       "   '1a7df6a63fda',\n",
       "   '1a820d25020c',\n",
       "   '1a88e27a1ddd',\n",
       "   '1a8b67b2893',\n",
       "   '1a8c08538833',\n",
       "   '1a8d81e694d6',\n",
       "   '1a9139423b61',\n",
       "   '1a9306eba2ef',\n",
       "   '1a938bc96fb2',\n",
       "   '1a9fc03d760',\n",
       "   '1aa619e0550a',\n",
       "   '1ac0a52421bc',\n",
       "   '1ac1934bbae4',\n",
       "   '1ad89d63ee8e',\n",
       "   '1ae72e97012c',\n",
       "   '1ae7d378b06f',\n",
       "   '1aebe0c0a8a6',\n",
       "   '1b117e0b92f6',\n",
       "   '1b294bd607be',\n",
       "   '1b2a3414cad7',\n",
       "   '1b383ca79080',\n",
       "   '1b45b966c576',\n",
       "   '1b4b58394e85',\n",
       "   '1b4c85e51842',\n",
       "   '1b4efcfaa2af',\n",
       "   '1b50da98b884',\n",
       "   '1b6443bd8f4c',\n",
       "   '1b6d45ecfbfd',\n",
       "   '1b6de1e895ac',\n",
       "   '1b7422879ee0',\n",
       "   '1b9cb41e4b74',\n",
       "   '1bb06c75646e',\n",
       "   '1bb609adeb79',\n",
       "   '1bba907b9ad2',\n",
       "   '1bd5603396d1',\n",
       "   '1bdc477b8179',\n",
       "   '1bf13f7b4824',\n",
       "   '1bf37f7800f9',\n",
       "   '1bf4dad54f64',\n",
       "   '1bf9683fd634',\n",
       "   '1bfe56776905',\n",
       "   '1c150c2e8bb9',\n",
       "   '1c20f09ad277',\n",
       "   '1c299fd98275'],\n",
       "  'top_articles': [{'id': '0d11918ee0b3',\n",
       "    'title': 'Create a Stock Chatbot with your own CSV Data',\n",
       "    'subtitle': 'An Explorative Study with Python',\n",
       "    'author': 'e10ad955760c',\n",
       "    'publication_id': '32881626c9c9',\n",
       "    'published_at': '2024-02-15 05:08:49',\n",
       "    'last_modified_at': '2024-02-15 10:22:46',\n",
       "    'tags': ['programming',\n",
       "     'artificial-intelligence',\n",
       "     'data-science',\n",
       "     'technology',\n",
       "     'python'],\n",
       "    'topics': ['machine-learning', 'data-science'],\n",
       "    'claps': 67,\n",
       "    'voters': 10,\n",
       "    'word_count': 2140,\n",
       "    'responses_count': 0,\n",
       "    'reading_time': 9.275471698113208,\n",
       "    'url': 'https://medium.datadriveninvestor.com/create-a-stock-chatbot-with-your-own-csv-data-0d11918ee0b3',\n",
       "    'unique_slug': 'create-a-stock-chatbot-with-your-own-csv-data-0d11918ee0b3',\n",
       "    'image_url': 'https://miro.medium.com/0*DCZrugG03DH7dlty',\n",
       "    'lang': 'en',\n",
       "    'is_series': False,\n",
       "    'is_locked': False,\n",
       "    'is_shortform': False,\n",
       "    'top_highlight': ''},\n",
       "   {'id': 'ea2e2261fcbf',\n",
       "    'title': 'Stock Market Sentiment Prediction with OpenAI and Python',\n",
       "    'subtitle': 'An interesting exploration of the power of LLMs in stock analysis',\n",
       "    'author': 'e10ad955760c',\n",
       "    'publication_id': '5517fd7b58a6',\n",
       "    'published_at': '2024-02-04 18:46:05',\n",
       "    'last_modified_at': '2024-02-06 03:51:20',\n",
       "    'tags': ['programming',\n",
       "     'artificial-intelligence',\n",
       "     'technology',\n",
       "     'python',\n",
       "     'data-science'],\n",
       "    'topics': ['programming'],\n",
       "    'claps': 691,\n",
       "    'voters': 147,\n",
       "    'word_count': 2496,\n",
       "    'responses_count': 4,\n",
       "    'reading_time': 10.3688679245283,\n",
       "    'url': 'https://levelup.gitconnected.com/stock-market-sentiment-prediction-with-openai-and-python-ea2e2261fcbf',\n",
       "    'unique_slug': 'stock-market-sentiment-prediction-with-openai-and-python-ea2e2261fcbf',\n",
       "    'image_url': 'https://miro.medium.com/0*PDMtUUdUatJPSaZ_',\n",
       "    'lang': 'en',\n",
       "    'is_series': False,\n",
       "    'is_locked': False,\n",
       "    'is_shortform': False,\n",
       "    'top_highlight': ''},\n",
       "   {'id': '54948a3da389',\n",
       "    'title': 'Stock Price Prediction with Quantum Machine Learning in Python',\n",
       "    'subtitle': 'An overview of the challenges and opportunities',\n",
       "    'author': 'e10ad955760c',\n",
       "    'publication_id': '32881626c9c9',\n",
       "    'published_at': '2024-01-23 05:41:09',\n",
       "    'last_modified_at': '2024-02-13 13:27:06',\n",
       "    'tags': ['machine-learning',\n",
       "     'data-science',\n",
       "     'programming',\n",
       "     'artificial-intelligence',\n",
       "     'python'],\n",
       "    'topics': ['machine-learning', 'programming'],\n",
       "    'claps': 1581,\n",
       "    'voters': 332,\n",
       "    'word_count': 3687,\n",
       "    'responses_count': 21,\n",
       "    'reading_time': 16.013207547169813,\n",
       "    'url': 'https://medium.datadriveninvestor.com/stock-price-prediction-with-quantum-machine-learning-in-python-54948a3da389',\n",
       "    'unique_slug': 'stock-price-prediction-with-quantum-machine-learning-in-python-54948a3da389',\n",
       "    'image_url': 'https://miro.medium.com/0*xGjBwo2cGCdAky8J',\n",
       "    'lang': 'en',\n",
       "    'is_series': False,\n",
       "    'is_locked': False,\n",
       "    'is_shortform': False,\n",
       "    'top_highlight': \"These quantum systems (particles or circuits) do some interesting things. They can be in different states at the same time (superposition), connect in a special way (entanglement), and even go through barriers they shouldn't (tunneling).\"},\n",
       "   {'id': '750d5520b20b',\n",
       "    'title': 'Use ChatGPT to get All-Time views on your Medium Stories',\n",
       "    'subtitle': \"An untold secret to get what Medium doesn't provide to its authors\",\n",
       "    'author': 'e10ad955760c',\n",
       "    'publication_id': '5517fd7b58a6',\n",
       "    'published_at': '2024-01-23 04:00:48',\n",
       "    'last_modified_at': '2024-01-23 04:00:48',\n",
       "    'tags': ['data-science',\n",
       "     'artificial-intelligence',\n",
       "     'chatgpt',\n",
       "     'medium',\n",
       "     'blogging'],\n",
       "    'topics': ['programming'],\n",
       "    'claps': 210,\n",
       "    'voters': 12,\n",
       "    'word_count': 957,\n",
       "    'responses_count': 1,\n",
       "    'reading_time': 4.311320754716981,\n",
       "    'url': 'https://levelup.gitconnected.com/use-chatgpt-to-get-all-time-views-on-your-medium-stories-750d5520b20b',\n",
       "    'unique_slug': 'use-chatgpt-to-get-all-time-views-on-your-medium-stories-750d5520b20b',\n",
       "    'image_url': 'https://miro.medium.com/0*-LgsPM4boW7h0zGE',\n",
       "    'lang': 'en',\n",
       "    'is_series': False,\n",
       "    'is_locked': False,\n",
       "    'is_shortform': False,\n",
       "    'top_highlight': ''},\n",
       "   {'id': 'e50392d5e7f3',\n",
       "    'title': 'Implementing a Forex Hedging Strategy with Python',\n",
       "    'subtitle': 'A step-by-step guide to creating a risk-averse portfolio',\n",
       "    'author': 'e10ad955760c',\n",
       "    'publication_id': '32881626c9c9',\n",
       "    'published_at': '2024-01-14 06:06:59',\n",
       "    'last_modified_at': '2024-02-05 16:31:54',\n",
       "    'tags': ['finance', 'data-science', 'python', 'programming', 'technology'],\n",
       "    'topics': ['data-science', 'programming'],\n",
       "    'claps': 157,\n",
       "    'voters': 31,\n",
       "    'word_count': 2943,\n",
       "    'responses_count': 6,\n",
       "    'reading_time': 12.905660377358492,\n",
       "    'url': 'https://medium.datadriveninvestor.com/implementing-a-forex-hedging-strategy-with-python-e50392d5e7f3',\n",
       "    'unique_slug': 'implementing-a-forex-hedging-strategy-with-python-e50392d5e7f3',\n",
       "    'image_url': 'https://miro.medium.com/0*kPeEbruJtv9UxubJ',\n",
       "    'lang': 'en',\n",
       "    'is_series': False,\n",
       "    'is_locked': False,\n",
       "    'is_shortform': False,\n",
       "    'top_highlight': ''},\n",
       "   {'id': '4a80d94a7851',\n",
       "    'title': 'How to use Deep Learning for Real-Time Trading Decisions',\n",
       "    'subtitle': 'A hands-on guide to building a deep learning model with Python and APIs',\n",
       "    'author': 'e10ad955760c',\n",
       "    'publication_id': '5517fd7b58a6',\n",
       "    'published_at': '2024-01-09 16:01:00',\n",
       "    'last_modified_at': '2024-02-05 05:21:53',\n",
       "    'tags': ['technology',\n",
       "     'artificial-intelligence',\n",
       "     'data-science',\n",
       "     'python',\n",
       "     'programming'],\n",
       "    'topics': ['machine-learning', 'data-science'],\n",
       "    'claps': 514,\n",
       "    'voters': 111,\n",
       "    'word_count': 2891,\n",
       "    'responses_count': 5,\n",
       "    'reading_time': 11.959433962264152,\n",
       "    'url': 'https://levelup.gitconnected.com/how-to-use-deep-learning-for-real-time-trading-decisions-4a80d94a7851',\n",
       "    'unique_slug': 'how-to-use-deep-learning-for-real-time-trading-decisions-4a80d94a7851',\n",
       "    'image_url': 'https://miro.medium.com/0*1j53jWdN1Yh1UPwj',\n",
       "    'lang': 'en',\n",
       "    'is_series': False,\n",
       "    'is_locked': False,\n",
       "    'is_shortform': False,\n",
       "    'top_highlight': ''},\n",
       "   {'id': 'f566e3fdcbc5',\n",
       "    'title': 'Using AI + Dividends to Manage Risk',\n",
       "    'subtitle': 'A practical case-study using Python and APIs',\n",
       "    'author': 'e10ad955760c',\n",
       "    'publication_id': '5517fd7b58a6',\n",
       "    'published_at': '2023-12-19 13:47:41',\n",
       "    'last_modified_at': '2024-01-08 04:18:07',\n",
       "    'tags': ['data-science',\n",
       "     'artificial-intelligence',\n",
       "     'python',\n",
       "     'programming',\n",
       "     'finance'],\n",
       "    'topics': ['data-science', 'programming'],\n",
       "    'claps': 129,\n",
       "    'voters': 11,\n",
       "    'word_count': 1303,\n",
       "    'responses_count': 0,\n",
       "    'reading_time': 6.1169811320754715,\n",
       "    'url': 'https://levelup.gitconnected.com/using-ai-dividends-to-manage-risk-f566e3fdcbc5',\n",
       "    'unique_slug': 'using-ai-dividends-to-manage-risk-f566e3fdcbc5',\n",
       "    'image_url': 'https://miro.medium.com/0*yYSJhO5S8bBWDF1A',\n",
       "    'lang': 'en',\n",
       "    'is_series': False,\n",
       "    'is_locked': False,\n",
       "    'is_shortform': False,\n",
       "    'top_highlight': ''},\n",
       "   {'id': '05da6551637c',\n",
       "    'title': 'Real-Time Options Analysis with Python',\n",
       "    'subtitle': 'A Python case study to dive deep into the options realm using APIs',\n",
       "    'author': 'e10ad955760c',\n",
       "    'publication_id': '32881626c9c9',\n",
       "    'published_at': '2023-12-19 10:19:54',\n",
       "    'last_modified_at': '2023-12-19 10:23:43',\n",
       "    'tags': ['finance', 'technology', 'programming', 'data-science', 'python'],\n",
       "    'topics': ['data-science', 'programming'],\n",
       "    'claps': 366,\n",
       "    'voters': 72,\n",
       "    'word_count': 2247,\n",
       "    'responses_count': 6,\n",
       "    'reading_time': 9.312578616352202,\n",
       "    'url': 'https://medium.datadriveninvestor.com/real-time-options-analysis-with-python-05da6551637c',\n",
       "    'unique_slug': 'real-time-options-analysis-with-python-05da6551637c',\n",
       "    'image_url': 'https://miro.medium.com/0*zBAobsC5ItBX5f28',\n",
       "    'lang': 'en',\n",
       "    'is_series': False,\n",
       "    'is_locked': False,\n",
       "    'is_shortform': False,\n",
       "    'top_highlight': ''},\n",
       "   {'id': '58ed12a492dc',\n",
       "    'title': 'An Algo Trading Strategy which made +8,371%: A Python Case Study',\n",
       "    'subtitle': 'Backtesting of a simple breakout trading strategy with APIs and Python',\n",
       "    'author': 'e10ad955760c',\n",
       "    'publication_id': '5517fd7b58a6',\n",
       "    'published_at': '2023-11-28 20:54:51',\n",
       "    'last_modified_at': '2023-11-30 03:21:05',\n",
       "    'tags': ['finance', 'programming', 'python', 'data-science', 'technology'],\n",
       "    'topics': ['programming'],\n",
       "    'claps': 2814,\n",
       "    'voters': 844,\n",
       "    'word_count': 1564,\n",
       "    'responses_count': 53,\n",
       "    'reading_time': 6.85188679245283,\n",
       "    'url': 'https://levelup.gitconnected.com/an-algo-trading-strategy-which-made-8-371-a-python-case-study-58ed12a492dc',\n",
       "    'unique_slug': 'an-algo-trading-strategy-which-made-8-371-a-python-case-study-58ed12a492dc',\n",
       "    'image_url': 'https://miro.medium.com/0*NVcgICnCBFvG0gM7',\n",
       "    'lang': 'en',\n",
       "    'is_series': False,\n",
       "    'is_locked': False,\n",
       "    'is_shortform': False,\n",
       "    'top_highlight': \"Before moving to the coding part, it's essential to have a good background on the strategy we're going to build in this article. Our trading strategy follows the principle of simplicity yet a very effective breakout strategy.\"},\n",
       "   {'id': '936934fea7d0',\n",
       "    'title': 'Finding the Best Sector to Invest in using Python',\n",
       "    'subtitle': 'Navigating the task of picking the right sector using APIs',\n",
       "    'author': 'e10ad955760c',\n",
       "    'publication_id': '5517fd7b58a6',\n",
       "    'published_at': '2023-11-13 00:17:43',\n",
       "    'last_modified_at': '2023-11-13 00:17:43',\n",
       "    'tags': ['finance', 'python', 'data-science', 'programming', 'technology'],\n",
       "    'topics': ['programming'],\n",
       "    'claps': 276,\n",
       "    'voters': 49,\n",
       "    'word_count': 1043,\n",
       "    'responses_count': 4,\n",
       "    'reading_time': 4.6358490566037736,\n",
       "    'url': 'https://levelup.gitconnected.com/finding-the-best-sector-to-invest-in-using-python-936934fea7d0',\n",
       "    'unique_slug': 'finding-the-best-sector-to-invest-in-using-python-936934fea7d0',\n",
       "    'image_url': 'https://miro.medium.com/0*ldsDKhn0hLacv7S8',\n",
       "    'lang': 'en',\n",
       "    'is_series': False,\n",
       "    'is_locked': False,\n",
       "    'is_shortform': False,\n",
       "    'top_highlight': ''}]},\n",
       " '76398be9016': {'id': '76398be9016',\n",
       "  'username': 'machine-learning-made-simple',\n",
       "  'fullname': 'Devansh',\n",
       "  'bio': 'Writing about AI, Math, the Tech Industry and whatever else interests me. Join my cult to gain inner peace and to support my crippling chocolate milk addiction',\n",
       "  'followers_count': 13172,\n",
       "  'following_count': 21,\n",
       "  'publication_following_count': 2,\n",
       "  'image_url': 'https://miro.medium.com/1*xiFRgHfgfMR7S111UB2hMw.jpeg',\n",
       "  'twitter_username': 'Machine01776819',\n",
       "  'is_writer_program_enrolled': True,\n",
       "  'allow_notes': True,\n",
       "  'medium_member_at': '',\n",
       "  'is_suspended': False,\n",
       "  'top_writer_in': ['artificial-intelligence', 'technology'],\n",
       "  'has_list': False,\n",
       "  'is_book_author': False,\n",
       "  'tipping_link': None,\n",
       "  'bg_image_url': '',\n",
       "  'logo_image_url': '',\n",
       "  'followers': ['00245ad345da',\n",
       "   '0048135eab64',\n",
       "   '0078a8c1aefd',\n",
       "   '00850ccafbce',\n",
       "   '009733c9ec1e',\n",
       "   '00abad96696a',\n",
       "   '00b0ad7585f2',\n",
       "   '00b8eada8b79',\n",
       "   '010f43fe49da',\n",
       "   '012072537565',\n",
       "   '012fdb5da8ec',\n",
       "   '0143c3cfd773',\n",
       "   '01504d6c22ed',\n",
       "   '01a9bec2ec7a',\n",
       "   '01ae33f2ac2d',\n",
       "   '01b0fa936fca',\n",
       "   '01bace87a8ca',\n",
       "   '01cf0debc091',\n",
       "   '02196c29640d',\n",
       "   '02331c9dd59d',\n",
       "   '0239c84a897c',\n",
       "   '024bf4648d4b',\n",
       "   '02593edd9dcf',\n",
       "   '028b27877c10',\n",
       "   '02af2813611b',\n",
       "   '02b5114c779a',\n",
       "   '02d65605dc46',\n",
       "   '02ed07da7b7f',\n",
       "   '03011804df2a',\n",
       "   '03133540481d',\n",
       "   '0344c819f9fc',\n",
       "   '03609e9ab716',\n",
       "   '036ecf5a78de',\n",
       "   '03ace9b06076',\n",
       "   '03af4c0aa53f',\n",
       "   '03b52ef93f2c',\n",
       "   '03bfe8127859',\n",
       "   '03d778a58360',\n",
       "   '03e21728b8a8',\n",
       "   '03f381560951',\n",
       "   '03fa389c69ac',\n",
       "   '03fa533aee11',\n",
       "   '04244f3a8620',\n",
       "   '042595bf2506',\n",
       "   '0428ee002a03',\n",
       "   '045559435124',\n",
       "   '04642341d47b',\n",
       "   '047f817e27eb',\n",
       "   '04840369bb54',\n",
       "   '0488cb6529c7',\n",
       "   '048979b866f1',\n",
       "   '048a85367977',\n",
       "   '049d89885fc2',\n",
       "   '049dbabe955a',\n",
       "   '04aeafb19e7d',\n",
       "   '04ca33ca0707',\n",
       "   '04de3baaed46',\n",
       "   '04e94eb13d69',\n",
       "   '0566c7ccfcde',\n",
       "   '056d17f08df8',\n",
       "   '0584981f45f3',\n",
       "   '058a6d5a31c2',\n",
       "   '05ab8b6b8d41',\n",
       "   '05adb06b8cd6',\n",
       "   '05adcd2d9f9c',\n",
       "   '05f95e3e7f07',\n",
       "   '05f9be6f76f4',\n",
       "   '060a20697ec0',\n",
       "   '063991ed8967',\n",
       "   '06711d3536d6',\n",
       "   '06d85f1c2b18',\n",
       "   '07111536eaca',\n",
       "   '071da920fdde',\n",
       "   '071f8b7c3185',\n",
       "   '072e8a5bae3f',\n",
       "   '073133dbe904',\n",
       "   '0737076c49cf',\n",
       "   '0796a7fb1e29',\n",
       "   '07afd6d7805b',\n",
       "   '07c46abd2124',\n",
       "   '08097d4c62a1',\n",
       "   '083144fb1453',\n",
       "   '0858cc0b2f80',\n",
       "   '0859720c1d98',\n",
       "   '0880c44e0fa4',\n",
       "   '0885e95b332c',\n",
       "   '08b04d69f5d3',\n",
       "   '08dae4d6ce0c',\n",
       "   '09084aba3069',\n",
       "   '092578aef198',\n",
       "   '092eabcdc76d',\n",
       "   '09335f825c05',\n",
       "   '09527aa11a8e',\n",
       "   '095b039c6a5e',\n",
       "   '096aac71040e',\n",
       "   '09758690eda2',\n",
       "   '099e6dc72d34',\n",
       "   '09a8766aaaf5',\n",
       "   '09ab165a53a1',\n",
       "   '09b6ac590e29',\n",
       "   '09b7fba39f2e',\n",
       "   '09b91e9a51d8',\n",
       "   '09c4b362c0b1',\n",
       "   '09edfe95038a',\n",
       "   '09f9da79e5ea',\n",
       "   '0a2138521ee0',\n",
       "   '0a4cd9e9ac12',\n",
       "   '0a595e69a341',\n",
       "   '0a6ef4e42d38',\n",
       "   '0a797c5f56f4',\n",
       "   '0a7c7f0fb687',\n",
       "   '0a8cc69ddb75',\n",
       "   '0a90a192a60b',\n",
       "   '0aa2f714a20e',\n",
       "   '0aaf7a1f8af3',\n",
       "   '0ac13385b33f',\n",
       "   '0ac966a8bd62',\n",
       "   '0ac981d0a6a1',\n",
       "   '0ad63b3e1667',\n",
       "   '0ae5d0106fcb',\n",
       "   '0b002a16f7e9',\n",
       "   '0b0328e71501',\n",
       "   '0b08fe198ecf',\n",
       "   '0b1799ea38fd',\n",
       "   '0b1f054d198f',\n",
       "   '0b36e4263392',\n",
       "   '0b4f09a465e8',\n",
       "   '0b5bf4e33e99',\n",
       "   '0b8df69c12a1',\n",
       "   '0b94187ee8f5',\n",
       "   '0bab51088d33',\n",
       "   '0bbd1d8ab904',\n",
       "   '0bc872ce959b',\n",
       "   '0c36b68c3f11',\n",
       "   '0c78341218b8',\n",
       "   '0c8f27bed63f',\n",
       "   '0c9a285d8aa0',\n",
       "   '0ccd347285af',\n",
       "   '0cf3cf1c1015',\n",
       "   '0cf4a3893e1e',\n",
       "   '0d0b59432c4c',\n",
       "   '0d0ba2aadf6a',\n",
       "   '0d2949696dc1',\n",
       "   '0d6a560df67d',\n",
       "   '0d8f1fe315cb',\n",
       "   '0da7d7ee6581',\n",
       "   '0da9d5a107d6',\n",
       "   '0dabd06d5be7',\n",
       "   '0db3187dbee7',\n",
       "   '0dc1178bb4ae',\n",
       "   '0e056b60f960',\n",
       "   '0e12f8cc4094',\n",
       "   '0e1ddea3c222',\n",
       "   '0e365ad5e60a',\n",
       "   '0e385486428a',\n",
       "   '0e4aa70f7594',\n",
       "   '0e528912b7e1',\n",
       "   '0e5faf098978',\n",
       "   '0e61305155f2',\n",
       "   '0e61f3697d54',\n",
       "   '0e7333803136',\n",
       "   '0e9143737a66',\n",
       "   '0e9390f24154',\n",
       "   '0eaa2d1f652f',\n",
       "   '0ead86edbcde',\n",
       "   '0ec9b1440c55',\n",
       "   '0ece284497ac',\n",
       "   '0ed0e5a8ca2f',\n",
       "   '0ed9e3188b2c',\n",
       "   '0edc0a7f6f5c',\n",
       "   '0ee10dcfd60f',\n",
       "   '0ef5cda439ef',\n",
       "   '0efa91bc2ac7',\n",
       "   '0f05103506ea',\n",
       "   '0f0f0fb9d0c3',\n",
       "   '0f11c2541a42',\n",
       "   '0f1be1d24f0b',\n",
       "   '0f46b9ae4a04',\n",
       "   '0f4af9e138b2',\n",
       "   '0f66665e5e2f',\n",
       "   '0f6d6cbe137e',\n",
       "   '0f79c5a201bf',\n",
       "   '0f808968a147',\n",
       "   '0f87308c2676',\n",
       "   '0f8df923c1cf',\n",
       "   '0f99396a4238',\n",
       "   '0f9de8e7ec40',\n",
       "   '0fd3168dcaeb',\n",
       "   '0fdf387c3e80',\n",
       "   '0fec2acc9023',\n",
       "   '0ff632cf8f64',\n",
       "   '1004744b3d9d',\n",
       "   '1005dd904472',\n",
       "   '10086105f0e',\n",
       "   '10166297dd88',\n",
       "   '102708faa39a',\n",
       "   '102e065fecbf',\n",
       "   '1031f84d0331',\n",
       "   '10325487d561',\n",
       "   '10391e16ee3d',\n",
       "   '104582ea935e',\n",
       "   '104905fc0eb8',\n",
       "   '10497a096abc',\n",
       "   '1056f1939a9c',\n",
       "   '105d3157afbb',\n",
       "   '105e6602fb79',\n",
       "   '106ab1768282',\n",
       "   '106ad996b5b0',\n",
       "   '107afd595d5a',\n",
       "   '1084b84ad4b1',\n",
       "   '1089cb2d4def',\n",
       "   '108ba1a104e9',\n",
       "   '108d018c90ac',\n",
       "   '108e08d9c994',\n",
       "   '1093cc9740c1',\n",
       "   '10a04b52f96c',\n",
       "   '10a0588efdcc',\n",
       "   '10a0845ff59a',\n",
       "   '10a213ff07af',\n",
       "   '10a2e714187d',\n",
       "   '10a98e0d1aa7',\n",
       "   '10acd77843da',\n",
       "   '10ae111c26ad',\n",
       "   '10af60fce41c',\n",
       "   '10b34745d318',\n",
       "   '10c1b187f6b5',\n",
       "   '10c6330f3732',\n",
       "   '10c81e2d8c73',\n",
       "   '10ced7cc0adb',\n",
       "   '10cf78ee0cba',\n",
       "   '10d981cf90a1',\n",
       "   '10ddf62ed50e',\n",
       "   '10e135f00548',\n",
       "   '10e5bb7a4365',\n",
       "   '10e76aaec395',\n",
       "   '10ebd32cc8b3',\n",
       "   '10ecea099ead',\n",
       "   '10ed7cb7442e',\n",
       "   '10eda1780c75',\n",
       "   '10ee9d37a7e8',\n",
       "   '10f00002abe9',\n",
       "   '10f40a9170fe',\n",
       "   '10f581b06f04',\n",
       "   '10fb23b3bee3',\n",
       "   '110c1be11776',\n",
       "   '1112acd9db11',\n",
       "   '11141f7cd6f2',\n",
       "   '1114e0175910',\n",
       "   '112595ff514d',\n",
       "   '11345e0bf161',\n",
       "   '11371e613c14',\n",
       "   '113974f8d4b4',\n",
       "   '113bf76ff1a',\n",
       "   '113cb083255',\n",
       "   '113f96a7a7bd',\n",
       "   '11417711e21d',\n",
       "   '11424c740f68',\n",
       "   '114916af26d8',\n",
       "   '114931f619db',\n",
       "   '114bb975ae25',\n",
       "   '114e60595d0e',\n",
       "   '114f0aa4623b',\n",
       "   '11538402f739',\n",
       "   '115b849287db',\n",
       "   '1162dda214c6',\n",
       "   '116839144c0',\n",
       "   '11703f2b0ce4',\n",
       "   '117187099f80',\n",
       "   '117614d7351b',\n",
       "   '117bf3a41e7d',\n",
       "   '117bfae0f005',\n",
       "   '1181e07cd9a1',\n",
       "   '118bb7dc0477',\n",
       "   '118bd69444c6',\n",
       "   '118ebc021124',\n",
       "   '1191def18f93',\n",
       "   '1192b7f503d7',\n",
       "   '119461a67189',\n",
       "   '1195e19385bb',\n",
       "   '11999502f8b',\n",
       "   '119d1e33d352',\n",
       "   '11a205eeb0d3',\n",
       "   '11a2fa76aefe',\n",
       "   '11a527b10562',\n",
       "   '11a5949399e6',\n",
       "   '11a795e745bf',\n",
       "   '11ad2f1a2b03',\n",
       "   '11b41b6d2835',\n",
       "   '11b43c3e970',\n",
       "   '11ba0d53ceb8',\n",
       "   '11c05e5a20ca',\n",
       "   '11c63cf0ce56',\n",
       "   '11cdced0a017',\n",
       "   '11cdd801eccd',\n",
       "   '11d8058eb9ea',\n",
       "   '11dbc4dfae1e',\n",
       "   '11df8902d05c',\n",
       "   '11e35a346c3e',\n",
       "   '11e843554f38',\n",
       "   '11eacdc48ae9',\n",
       "   '11eb7d7cc5fa',\n",
       "   '11ffbcedde9',\n",
       "   '120069f70cf9',\n",
       "   '12011bb19ac',\n",
       "   '1208d2bd1622',\n",
       "   '120cd22f2829',\n",
       "   '120d2dffcf57',\n",
       "   '121075f29909',\n",
       "   '1219ebb4a2d5',\n",
       "   '12239af16eba',\n",
       "   '122d358e9115',\n",
       "   '1244ca1a46fc',\n",
       "   '1245b2558ef6',\n",
       "   '12463be44f5c',\n",
       "   '124a13252ce5',\n",
       "   '12524c2bcf45',\n",
       "   '1256da67d66',\n",
       "   '125ca5a54318',\n",
       "   '12665ee42fe5',\n",
       "   '12672530e4de',\n",
       "   '126871c8ff62',\n",
       "   '1274e13f39bb',\n",
       "   '1276a2ab058c',\n",
       "   '127cf59ceed8',\n",
       "   '128292b14e94',\n",
       "   '12892a109be6',\n",
       "   '128da2b4ec36',\n",
       "   '12965b1f3043',\n",
       "   '129a68b12a3b',\n",
       "   '129bcc7b180d',\n",
       "   '12a10fca9d4',\n",
       "   '12a204627804',\n",
       "   '12a755f69afb',\n",
       "   '12aef9d4fe3d',\n",
       "   '12af2fc1fdec',\n",
       "   '12af922d24f3',\n",
       "   '12aff0ba9d3a',\n",
       "   '12b59ceaf220',\n",
       "   '12b7091e3364',\n",
       "   '12b9520c02dd',\n",
       "   '12bca38baee5',\n",
       "   '12c028880dc5',\n",
       "   '12c08568b82b',\n",
       "   '12c6c929d80f',\n",
       "   '12c75379f1ad',\n",
       "   '12cb708263e1',\n",
       "   '12d4f460619f',\n",
       "   '12ed60efa12b',\n",
       "   '12ef6616161c',\n",
       "   '12ef7526501a',\n",
       "   '12f4fd561fe9',\n",
       "   '12f66864a02b',\n",
       "   '12fe1112eca2',\n",
       "   '13072b8d22f3',\n",
       "   '13108208ab61',\n",
       "   '131262f2a4f7',\n",
       "   '1312fc25d6e6',\n",
       "   '131fb1a21558',\n",
       "   '13208034df59',\n",
       "   '132c56a9c859',\n",
       "   '13310c008c37',\n",
       "   '1333c9e32da6',\n",
       "   '133d3f4b7ccf',\n",
       "   '13486bf3a1b9',\n",
       "   '1362a73c20b1',\n",
       "   '13631e75f7d0',\n",
       "   '13674bca0b0a',\n",
       "   '136dcdbe2a42',\n",
       "   '137d742f3555',\n",
       "   '138262efa2c',\n",
       "   '138733817eb1',\n",
       "   '1399dfdb36cb',\n",
       "   '139d1032ac0f',\n",
       "   '139fd46a1369',\n",
       "   '13a8e7eb8403',\n",
       "   '13b44e01c144',\n",
       "   '13b47e22b97d',\n",
       "   '13b4d4ab56e0',\n",
       "   '13bc316e54bb',\n",
       "   '13bc6493de24',\n",
       "   '13bd5da01eba',\n",
       "   '13bfc78745d1',\n",
       "   '13c15661794',\n",
       "   '13c6aa178f9d',\n",
       "   '13c9629a819',\n",
       "   '13d87283b1a4',\n",
       "   '13dbfa3b5d26',\n",
       "   '13e70bc01d75',\n",
       "   '13edf09cc584',\n",
       "   '1402ef3dea9f',\n",
       "   '1408fd6d617b',\n",
       "   '1409baa12d0f',\n",
       "   '140c501ab0d6',\n",
       "   '140dd4b99877',\n",
       "   '140de45b1451',\n",
       "   '1410c5dde5cd',\n",
       "   '14123530f40b',\n",
       "   '141fa70b60b6',\n",
       "   '1425ca5452a9',\n",
       "   '142efcc8ae62',\n",
       "   '1430456ad365',\n",
       "   '14339dfba183',\n",
       "   '1436b3cafb37',\n",
       "   '1438095df1b2',\n",
       "   '1438e31f5790',\n",
       "   '143cf8bdec76',\n",
       "   '14446d982b66',\n",
       "   '1446f7985c3f',\n",
       "   '1456e2f4af2d',\n",
       "   '145d68b7e763',\n",
       "   '1463f99e1448',\n",
       "   '1466d644be6',\n",
       "   '14675ef5274a',\n",
       "   '146b1ef463a9',\n",
       "   '146b6374754c',\n",
       "   '146c4c9e2b2b',\n",
       "   '1483cf2362c5',\n",
       "   '148acfe082b4',\n",
       "   '148ae689f366',\n",
       "   '148d6186796a',\n",
       "   '148d7868860b',\n",
       "   '148f89a6e09e',\n",
       "   '14950b04f4d9',\n",
       "   '149fab625acc',\n",
       "   '14aedbb84633',\n",
       "   '14b9613965b2',\n",
       "   '14c27455c7f5',\n",
       "   '14cc8a286ca5',\n",
       "   '14cd2b5df6f5',\n",
       "   '14d8d59ae35c',\n",
       "   '14daabbff886',\n",
       "   '14dc598ac6cd',\n",
       "   '14e1259615cd',\n",
       "   '14e395f7b4f7',\n",
       "   '14ea69d890d1',\n",
       "   '14f00925915a',\n",
       "   '14f318f615fa',\n",
       "   '14f3506df0e1',\n",
       "   '14f7ae40e2b9',\n",
       "   '14fffa259939',\n",
       "   '15066556a612',\n",
       "   '150aaf6fae67',\n",
       "   '150db2d06b6b',\n",
       "   '1514fd02d580',\n",
       "   '152044ffd753',\n",
       "   '1525bd8e203',\n",
       "   '152614a2c5c3',\n",
       "   '152c79d6dfa8',\n",
       "   '1530bb9a58ad',\n",
       "   '15337fc7a138',\n",
       "   '15350b98729a',\n",
       "   '153ad8140309',\n",
       "   '154ee71049ac',\n",
       "   '154f70790aee',\n",
       "   '1551ebd5d15e',\n",
       "   '15548f2194d5',\n",
       "   '1558b31e331d',\n",
       "   '155bab1468e4',\n",
       "   '155c350d8457',\n",
       "   '155fbd48d66b',\n",
       "   '1567e853a40a',\n",
       "   '1568d8ee7a9c',\n",
       "   '156aad031c80',\n",
       "   '156f6a0a1d83',\n",
       "   '157d49680b1',\n",
       "   '1583f065cb02',\n",
       "   '1584c3544312',\n",
       "   '1587bfaab12',\n",
       "   '158911408414',\n",
       "   '15915f0d00',\n",
       "   '159477815101',\n",
       "   '159cda144d61',\n",
       "   '15a5c9f89e7b'],\n",
       "  'top_articles': [{'id': '5d39cff63d52',\n",
       "    'title': 'Understanding Google’s GPT Killer- The Pathways Architecture',\n",
       "    'subtitle': 'The reason why their model Bard will be much more than a language model',\n",
       "    'author': '76398be9016',\n",
       "    'publication_id': '9758482ba857',\n",
       "    'published_at': '2023-02-18 11:44:10',\n",
       "    'last_modified_at': '2023-04-27 03:18:12',\n",
       "    'tags': ['machine-learning',\n",
       "     'artificial-intelligence',\n",
       "     'technology',\n",
       "     'programming',\n",
       "     'data-science'],\n",
       "    'topics': ['artificial-intelligence', 'machine-learning'],\n",
       "    'claps': 315,\n",
       "    'voters': 70,\n",
       "    'word_count': 2156,\n",
       "    'responses_count': 4,\n",
       "    'reading_time': 9.335849056603774,\n",
       "    'url': 'https://medium.com/geekculture/understanding-googles-gpt-killer-the-pathways-architecture-5d39cff63d52',\n",
       "    'unique_slug': 'understanding-googles-gpt-killer-the-pathways-architecture-5d39cff63d52',\n",
       "    'image_url': 'https://miro.medium.com/0*TPGsdVpfJ5-bmA9Z.jpeg',\n",
       "    'lang': 'en',\n",
       "    'is_series': False,\n",
       "    'is_locked': False,\n",
       "    'is_shortform': False,\n",
       "    'top_highlight': ''},\n",
       "   {'id': '5e142b8931e6',\n",
       "    'title': 'Improve Neural Networks by using Complex Numbers',\n",
       "    'subtitle': 'Can Complex Functions be the next breakthrough in Computer Vision?',\n",
       "    'author': '76398be9016',\n",
       "    'publication_id': '9758482ba857',\n",
       "    'published_at': '2022-11-17 00:59:57',\n",
       "    'last_modified_at': '2023-04-26 21:31:16',\n",
       "    'tags': ['machine-learning',\n",
       "     'artificial-intelligence',\n",
       "     'technology',\n",
       "     'data-science',\n",
       "     'self-improvement'],\n",
       "    'topics': ['machine-learning'],\n",
       "    'claps': 577,\n",
       "    'voters': 116,\n",
       "    'word_count': 1846,\n",
       "    'responses_count': 6,\n",
       "    'reading_time': 8.466037735849056,\n",
       "    'url': 'https://medium.com/geekculture/improve-neural-networks-by-using-complex-numbers-5e142b8931e6',\n",
       "    'unique_slug': 'improve-neural-networks-by-using-complex-numbers-5e142b8931e6',\n",
       "    'image_url': 'https://miro.medium.com/1*huvbsdKFNJp45SoOcgwmHw.png',\n",
       "    'lang': 'en',\n",
       "    'is_series': False,\n",
       "    'is_locked': False,\n",
       "    'is_shortform': False,\n",
       "    'top_highlight': 'Recently, someone in my LinkedIn network shared this very interesting paper with me. Titled, \"CoShNet: A Hybrid Complex Valued Neural Network using Shearlets\", this paper proposes the use of complex functions in a hybrid neural network. If you are very confused by those words, don\\'t worry I was too. In this article, I will explain the idea of hybrid neural networks and how they can be used to improve traditional Convolutional Neural Networks. Then we will cover how using Complex Functions can be used to boost the performance of these models even further. This is going to be a very fun one.'},\n",
       "   {'id': '92296297a541',\n",
       "    'title': 'How Amazon makes Machine Learning Trustworthy',\n",
       "    'subtitle': 'With all the discussion around Bias in ChatGPT and Machine Learning, these techniques might be very helpful',\n",
       "    'author': '76398be9016',\n",
       "    'publication_id': '9758482ba857',\n",
       "    'published_at': '2022-12-12 11:48:18',\n",
       "    'last_modified_at': '2023-05-06 19:42:01',\n",
       "    'tags': ['machine-learning',\n",
       "     'artificial-intelligence',\n",
       "     'technology',\n",
       "     'data-science',\n",
       "     'programming'],\n",
       "    'topics': ['artificial-intelligence', 'machine-learning'],\n",
       "    'claps': 41,\n",
       "    'voters': 13,\n",
       "    'word_count': 1776,\n",
       "    'responses_count': 1,\n",
       "    'reading_time': 8.05188679245283,\n",
       "    'url': 'https://medium.com/geekculture/how-amazon-makes-machine-learning-trustworthy-92296297a541',\n",
       "    'unique_slug': 'how-amazon-makes-machine-learning-trustworthy-92296297a541',\n",
       "    'image_url': 'https://miro.medium.com/0*_ej-xHk4ROErgvkz',\n",
       "    'lang': 'en',\n",
       "    'is_series': False,\n",
       "    'is_locked': False,\n",
       "    'is_shortform': False,\n",
       "    'top_highlight': 'Machine Learning has swept the world recently. Thanks to all the amazing results companies have been rushing to adopt Data-Driven decision-making into their processes. Given all the amazing demos by DALLE, StableDiffusion, and now ChatGPT, more and more people are waking up to the potential of AI. However, some people have been raising concerns about the potential for harm that these models have. Recently, ChatGPT has gained some attention, because users have discovered that it can generate some spicy outputs. Take a look at how ChatGPT can identify good scientists based on their race and gender.'},\n",
       "   {'id': 'fcad692b1456',\n",
       "    'title': 'Why Tree-Based Models Beat Deep Learning on Tabular Data',\n",
       "    'subtitle': 'A much-needed reality check for AI Researchers and Engineers caught up in the hype around Deep Learning',\n",
       "    'author': '76398be9016',\n",
       "    'publication_id': '9758482ba857',\n",
       "    'published_at': '2022-08-27 00:08:15',\n",
       "    'last_modified_at': '2023-05-01 22:04:24',\n",
       "    'tags': ['data-science',\n",
       "     'artificial-intelligence',\n",
       "     'machine-learning',\n",
       "     'technology',\n",
       "     'programming'],\n",
       "    'topics': ['artificial-intelligence', 'machine-learning', 'data-science'],\n",
       "    'claps': 609,\n",
       "    'voters': 179,\n",
       "    'word_count': 1691,\n",
       "    'responses_count': 5,\n",
       "    'reading_time': 7.581132075471698,\n",
       "    'url': 'https://medium.com/geekculture/why-tree-based-models-beat-deep-learning-on-tabular-data-fcad692b1456',\n",
       "    'unique_slug': 'why-tree-based-models-beat-deep-learning-on-tabular-data-fcad692b1456',\n",
       "    'image_url': 'https://miro.medium.com/1*TXcH3Sgw-prj4DrM0GUmWQ.png',\n",
       "    'lang': 'en',\n",
       "    'is_series': False,\n",
       "    'is_locked': False,\n",
       "    'is_shortform': False,\n",
       "    'top_highlight': \"This was the first reason that the authors shared that Deep Learning Neural Networks couldn't compete with Random Forests. Simply put, when it comes to non-smooth functions/decision boundaries, Neural Networks struggle to create the best-fit functions. Random Forests do much better with weird/jagged/irregular patterns.\"},\n",
       "   {'id': '9ef2ea904986',\n",
       "    'title': 'How to learn Machine Learning in 2022',\n",
       "    'subtitle': 'A step by step guide to getting into machine learning',\n",
       "    'author': '76398be9016',\n",
       "    'publication_id': '9758482ba857',\n",
       "    'published_at': '2022-01-20 21:23:05',\n",
       "    'last_modified_at': '2022-12-11 22:13:47',\n",
       "    'tags': ['machine-learning',\n",
       "     'artificial-intelligence',\n",
       "     'data-science',\n",
       "     'programming',\n",
       "     'technology'],\n",
       "    'topics': ['machine-learning'],\n",
       "    'claps': 236,\n",
       "    'voters': 69,\n",
       "    'word_count': 1426,\n",
       "    'responses_count': 3,\n",
       "    'reading_time': 6.431132075471698,\n",
       "    'url': 'https://medium.com/geekculture/how-to-learn-machine-learning-in-2022-9ef2ea904986',\n",
       "    'unique_slug': 'how-to-learn-machine-learning-in-2022-9ef2ea904986',\n",
       "    'image_url': 'https://miro.medium.com/1*18fasTe1sOKBcDoyYY5Nbw.png',\n",
       "    'lang': 'en',\n",
       "    'is_series': False,\n",
       "    'is_locked': False,\n",
       "    'is_shortform': False,\n",
       "    'top_highlight': ''},\n",
       "   {'id': 'bf4cb36751ea',\n",
       "    'title': 'Why some CEOs hate Remote Work',\n",
       "    'subtitle': 'Is it truly a lack of productivity or is it something more?',\n",
       "    'author': '76398be9016',\n",
       "    'publication_id': '32881626c9c9',\n",
       "    'published_at': '2024-02-17 06:42:03',\n",
       "    'last_modified_at': '2024-02-18 09:45:38',\n",
       "    'tags': ['business',\n",
       "     'technology',\n",
       "     'programming',\n",
       "     'software-development',\n",
       "     'culture'],\n",
       "    'topics': ['work'],\n",
       "    'claps': 242,\n",
       "    'voters': 9,\n",
       "    'word_count': 1072,\n",
       "    'responses_count': 0,\n",
       "    'reading_time': 4.595283018867924,\n",
       "    'url': 'https://medium.datadriveninvestor.com/why-some-ceos-hate-remote-work-bf4cb36751ea',\n",
       "    'unique_slug': 'why-some-ceos-hate-remote-work-bf4cb36751ea',\n",
       "    'image_url': 'https://miro.medium.com/0*00ERjm7K0uAn-blF.jpeg',\n",
       "    'lang': 'en',\n",
       "    'is_series': False,\n",
       "    'is_locked': False,\n",
       "    'is_shortform': False,\n",
       "    'top_highlight': 'The remote work vs in-person debate seems to be more divisive than ever.'},\n",
       "   {'id': '7b104513834e',\n",
       "    'title': 'Google’s High-Performance Computing Expert shares his thoughts on how to use AI',\n",
       "    'subtitle': 'Partnering with AI to reimagine problem-solving: the ‘intelligence’ that is artificial may be our own',\n",
       "    'author': '76398be9016',\n",
       "    'publication_id': '*Self-Published*',\n",
       "    'published_at': '2024-02-15 17:11:21',\n",
       "    'last_modified_at': '2024-02-15 17:11:21',\n",
       "    'tags': ['machine-learning',\n",
       "     'technology',\n",
       "     'artificial-intelligence',\n",
       "     'data-science',\n",
       "     'philosophy'],\n",
       "    'topics': ['artificial-intelligence'],\n",
       "    'claps': 2,\n",
       "    'voters': 2,\n",
       "    'word_count': 3079,\n",
       "    'responses_count': 0,\n",
       "    'reading_time': 12.002201257861635,\n",
       "    'url': 'https://machine-learning-made-simple.medium.com/googles-high-performance-computing-expert-shares-his-thoughts-on-how-to-use-ai-7b104513834e',\n",
       "    'unique_slug': 'googles-high-performance-computing-expert-shares-his-thoughts-on-how-to-use-ai-7b104513834e',\n",
       "    'image_url': 'https://miro.medium.com/1*b9LTaujSPgYWZL-qD3Zf1Q.jpeg',\n",
       "    'lang': 'en',\n",
       "    'is_series': False,\n",
       "    'is_locked': False,\n",
       "    'is_shortform': False,\n",
       "    'top_highlight': ''},\n",
       "   {'id': 'cd3a824ba81f',\n",
       "    'title': 'Interesting Content in AI, Software, Business, and Tech- 02/14/2024',\n",
       "    'subtitle': 'Content to help you keep up with Machine Learning, Deep Learning, Data Science, Software Engineering, Finance, Business, and more',\n",
       "    'author': '76398be9016',\n",
       "    'publication_id': '*Self-Published*',\n",
       "    'published_at': '2024-02-14 19:33:45',\n",
       "    'last_modified_at': '2024-02-14 19:33:45',\n",
       "    'tags': ['machine-learning',\n",
       "     'artificial-intelligence',\n",
       "     'software-development',\n",
       "     'technology',\n",
       "     'business'],\n",
       "    'topics': ['artificial-intelligence', 'programming'],\n",
       "    'claps': 62,\n",
       "    'voters': 7,\n",
       "    'word_count': 2592,\n",
       "    'responses_count': 0,\n",
       "    'reading_time': 10.331132075471698,\n",
       "    'url': 'https://machine-learning-made-simple.medium.com/interesting-content-in-ai-software-business-and-tech-02-14-2024-cd3a824ba81f',\n",
       "    'unique_slug': 'interesting-content-in-ai-software-business-and-tech-02-14-2024-cd3a824ba81f',\n",
       "    'image_url': 'https://miro.medium.com/1*b9LTaujSPgYWZL-qD3Zf1Q.jpeg',\n",
       "    'lang': 'en',\n",
       "    'is_series': False,\n",
       "    'is_locked': False,\n",
       "    'is_shortform': False,\n",
       "    'top_highlight': ''},\n",
       "   {'id': '68896a42b991',\n",
       "    'title': 'Understanding Space-Based Architecture for efficient Data Processing',\n",
       "    'subtitle': 'A possible game-changer for edge AI, real-time supply chain analysis, and more',\n",
       "    'author': '76398be9016',\n",
       "    'publication_id': '*Self-Published*',\n",
       "    'published_at': '2024-02-12 06:10:32',\n",
       "    'last_modified_at': '2024-02-12 06:10:32',\n",
       "    'tags': ['machine-learning',\n",
       "     'artificial-intelligence',\n",
       "     'data-science',\n",
       "     'technology',\n",
       "     'programming'],\n",
       "    'topics': ['machine-learning', 'data-science', 'programming'],\n",
       "    'claps': 143,\n",
       "    'voters': 5,\n",
       "    'word_count': 1519,\n",
       "    'responses_count': 0,\n",
       "    'reading_time': 6.5654088050314465,\n",
       "    'url': 'https://machine-learning-made-simple.medium.com/understanding-space-based-architecture-for-efficient-data-processing-68896a42b991',\n",
       "    'unique_slug': 'understanding-space-based-architecture-for-efficient-data-processing-68896a42b991',\n",
       "    'image_url': 'https://miro.medium.com/0*DNzgMaNXu8TWw4zj.png',\n",
       "    'lang': 'en',\n",
       "    'is_series': False,\n",
       "    'is_locked': False,\n",
       "    'is_shortform': False,\n",
       "    'top_highlight': ''},\n",
       "   {'id': '5204dd12bc73',\n",
       "    'title': 'Why Data is an Incomplete Representation of Reality',\n",
       "    'subtitle': 'A look at some major limitations of Data',\n",
       "    'author': '76398be9016',\n",
       "    'publication_id': '*Self-Published*',\n",
       "    'published_at': '2024-02-10 01:37:21',\n",
       "    'last_modified_at': '2024-02-10 01:37:21',\n",
       "    'tags': ['machine-learning',\n",
       "     'artificial-intelligence',\n",
       "     'technology',\n",
       "     'data-science',\n",
       "     'mathematics'],\n",
       "    'topics': ['artificial-intelligence'],\n",
       "    'claps': 336,\n",
       "    'voters': 18,\n",
       "    'word_count': 4016,\n",
       "    'responses_count': 2,\n",
       "    'reading_time': 16.28805031446541,\n",
       "    'url': 'https://machine-learning-made-simple.medium.com/why-data-is-an-incomplete-representation-of-reality-5204dd12bc73',\n",
       "    'unique_slug': 'why-data-is-an-incomplete-representation-of-reality-5204dd12bc73',\n",
       "    'image_url': 'https://miro.medium.com/0*WQ0fY_kNLiVHfH0E.png',\n",
       "    'lang': 'en',\n",
       "    'is_series': False,\n",
       "    'is_locked': False,\n",
       "    'is_shortform': False,\n",
       "    'top_highlight': ''}]},\n",
       " 'd80580992695': {'id': 'd80580992695',\n",
       "  'username': 'anmol3015',\n",
       "  'fullname': 'Anmol Tomar',\n",
       "  'bio': '150K+ Views | Top AI writer | Sr. Data Scientist | Mentor. Want to kick off your career in Data Science? Get in touch with me: anmol3015@gmail.com',\n",
       "  'followers_count': 19854,\n",
       "  'following_count': 40,\n",
       "  'publication_following_count': 18,\n",
       "  'image_url': 'https://miro.medium.com/1*3ke50mn93msKlBWFCufnDQ.jpeg',\n",
       "  'twitter_username': '',\n",
       "  'is_writer_program_enrolled': True,\n",
       "  'allow_notes': True,\n",
       "  'medium_member_at': '',\n",
       "  'is_suspended': False,\n",
       "  'top_writer_in': [],\n",
       "  'has_list': True,\n",
       "  'is_book_author': False,\n",
       "  'tipping_link': 'https://paypal.me/Anmol3015?country.x=IN&locale.x=en_GB',\n",
       "  'bg_image_url': '',\n",
       "  'logo_image_url': '',\n",
       "  'followers': ['0008a90f7d7f',\n",
       "   '00117ef3e7b2',\n",
       "   '001479440872',\n",
       "   '00149b7421b2',\n",
       "   '001564222f42',\n",
       "   '002125e32c14',\n",
       "   '002ad9a41d6c',\n",
       "   '00418aadfc4b',\n",
       "   '0051a417ab48',\n",
       "   '0055540ed1c8',\n",
       "   '005b0e23b5d5',\n",
       "   '005c18b43c6c',\n",
       "   '00852dc4a8f8',\n",
       "   '0086caac613e',\n",
       "   '00893934aacb',\n",
       "   '008ad3b517ed',\n",
       "   '008ddd676829',\n",
       "   '009733c9ec1e',\n",
       "   '00a78a6007f4',\n",
       "   '00abad96696a',\n",
       "   '00acf1eebe34',\n",
       "   '00adf31ab408',\n",
       "   '00b8eada8b79',\n",
       "   '00bedca4ccd6',\n",
       "   '00d0c88bf952',\n",
       "   '00e64025302f',\n",
       "   '00ee2b300b93',\n",
       "   '00f29e780193',\n",
       "   '0103bac3e4c5',\n",
       "   '0109e784bcf3',\n",
       "   '010aff80b0a3',\n",
       "   '0115c36ef483',\n",
       "   '01237873b7d5',\n",
       "   '0132e668bef5',\n",
       "   '0143c3cfd773',\n",
       "   '01462edfc899',\n",
       "   '0148b7845755',\n",
       "   '0148ce17a280',\n",
       "   '0150b85c82d0',\n",
       "   '015d51a58568',\n",
       "   '01663a4bdf0c',\n",
       "   '018a1e42e660',\n",
       "   '018b35c4d3dc',\n",
       "   '018bf5c2865c',\n",
       "   '019f96270dad',\n",
       "   '01a6eed31abb',\n",
       "   '01a9d29e11d0',\n",
       "   '01aa82adde90',\n",
       "   '01abcc58edd1',\n",
       "   '01c016e994f9',\n",
       "   '01c090982695',\n",
       "   '01cf0debc091',\n",
       "   '01d758d3b9ef',\n",
       "   '01db58af4bc4',\n",
       "   '01dc6815573d',\n",
       "   '01dfdc67abb4',\n",
       "   '01e22e257aad',\n",
       "   '01f9a5e00200',\n",
       "   '02039eefc38c',\n",
       "   '020c63ec4b35',\n",
       "   '02147b72ccdc',\n",
       "   '0222ca211b33',\n",
       "   '02453bf6fb4f',\n",
       "   '025332284feb',\n",
       "   '02593edd9dcf',\n",
       "   '025acb6083ff',\n",
       "   '02628641dd9b',\n",
       "   '026660425fde',\n",
       "   '026c20ce6dc4',\n",
       "   '027028d9bde3',\n",
       "   '027afa6fc5a2',\n",
       "   '0286c1223c5a',\n",
       "   '028b27877c10',\n",
       "   '029482385112',\n",
       "   '029b35f74526',\n",
       "   '029d2d09a30e',\n",
       "   '029d685664b8',\n",
       "   '02a53fac2eb5',\n",
       "   '02a94771b11f',\n",
       "   '02bbd17887c1',\n",
       "   '02c13b34624f',\n",
       "   '02c25cbf385b',\n",
       "   '02cf374e2ba8',\n",
       "   '02e055ad3d54',\n",
       "   '02f044f6db79',\n",
       "   '02f9493e4478',\n",
       "   '02f983d6472c',\n",
       "   '03005888c3ee',\n",
       "   '03011804df2a',\n",
       "   '0309a4505896',\n",
       "   '030ca7dd7768',\n",
       "   '0311876815d1',\n",
       "   '0312c2e01765',\n",
       "   '03133540481d',\n",
       "   '0316d7e5df44',\n",
       "   '032a08f6c8d8',\n",
       "   '033047e9ac9b',\n",
       "   '0334334523f2',\n",
       "   '033f2535d2dd',\n",
       "   '0344c819f9fc',\n",
       "   '0345651c406a',\n",
       "   '034ff0c468c0',\n",
       "   '03609e9ab716',\n",
       "   '036ecf5a78de',\n",
       "   '0375cf039b1f',\n",
       "   '037865109bb7',\n",
       "   '037e56d957e3',\n",
       "   '037f41f997a2',\n",
       "   '0386ea48a367',\n",
       "   '038ebf7c20c8',\n",
       "   '038f29de771a',\n",
       "   '039d545b9016',\n",
       "   '03ace9b06076',\n",
       "   '03af4c0aa53f',\n",
       "   '03b3549b5abf',\n",
       "   '03bc0f18c610',\n",
       "   '03bc9df9f99b',\n",
       "   '03c20bb966cb',\n",
       "   '03c4eaf9b98d',\n",
       "   '03c5ef696031',\n",
       "   '03d06374eaac',\n",
       "   '03d71dd7fca1',\n",
       "   '03d778a58360',\n",
       "   '03d812148b66',\n",
       "   '03da2b9ffebc',\n",
       "   '03e94dc60823',\n",
       "   '03f6ee79f36c',\n",
       "   '03fa533aee11',\n",
       "   '040378117356',\n",
       "   '0409b4c901e0',\n",
       "   '040b73d4cbfb',\n",
       "   '0424cd3b13bb',\n",
       "   '042595bf2506',\n",
       "   '04391e0aa938',\n",
       "   '04500c057f2b',\n",
       "   '045559435124',\n",
       "   '0458ac9ef3fd',\n",
       "   '0460ef2f61ce',\n",
       "   '0477a75bb9f4',\n",
       "   '047ed5d6d18c',\n",
       "   '047f2880f4db',\n",
       "   '04840369bb54',\n",
       "   '0485b6f6e008',\n",
       "   '0490fb781ab6',\n",
       "   '0497232ef34d',\n",
       "   '049a9b5e71ee',\n",
       "   '049d89885fc2',\n",
       "   '04b0c95a3a3d',\n",
       "   '04c629da31af',\n",
       "   '04ca33ca0707',\n",
       "   '04db86866d5d',\n",
       "   '04dc545e0691',\n",
       "   '04e086d7161b',\n",
       "   '04e3c82cd53e',\n",
       "   '04e94eb13d69',\n",
       "   '04f3cbce8589',\n",
       "   '04f6f444672f',\n",
       "   '04fcaf4d395d',\n",
       "   '0506dd348542',\n",
       "   '051276cc78f1',\n",
       "   '051b52bfd42b',\n",
       "   '051b7c6a2cfb',\n",
       "   '054fe8607270',\n",
       "   '0556c608c8b7',\n",
       "   '055bc85b4fc1',\n",
       "   '0566fd552a56',\n",
       "   '056856b1689b',\n",
       "   '056e5471733d',\n",
       "   '05850d4ae453',\n",
       "   '0589ca8d247d',\n",
       "   '058a6d5a31c2',\n",
       "   '0591cd50fcdb',\n",
       "   '05a6c588847f',\n",
       "   '05a70a945bd6',\n",
       "   '05a7254d12d4',\n",
       "   '05b524828f43',\n",
       "   '05bc4c99c7fe',\n",
       "   '05bcb1594473',\n",
       "   '05cf15363a93',\n",
       "   '05e4b494b715',\n",
       "   '05e507811d9f',\n",
       "   '05e7dc2eb43d',\n",
       "   '05eaf182d754',\n",
       "   '05ec127105b9',\n",
       "   '05f04bbf6efd',\n",
       "   '05f9be6f76f4',\n",
       "   '060a20697ec0',\n",
       "   '0612100996f6',\n",
       "   '0614f6c1d39e',\n",
       "   '061f697e5109',\n",
       "   '06376237b3a2',\n",
       "   '063991ed8967',\n",
       "   '06402132e7a6',\n",
       "   '064ece55104e',\n",
       "   '065dde52b681',\n",
       "   '066982244fb5',\n",
       "   '067264ce16ff',\n",
       "   '0674c31c694f',\n",
       "   '0678e99488bc',\n",
       "   '0684a980a2af',\n",
       "   '06884c56bae9',\n",
       "   '0695ce306bf1',\n",
       "   '069a8d977d42',\n",
       "   '069a9346ae53',\n",
       "   '069b4fb3facd',\n",
       "   '069fbbba4be6',\n",
       "   '06aa8c8a3b3c',\n",
       "   '06b37e86523a',\n",
       "   '06bd84cf4a47',\n",
       "   '06c3f84d3307',\n",
       "   '06d375f1f359',\n",
       "   '06db96942202',\n",
       "   '06e3ffa6d3be',\n",
       "   '06ebe02a4823',\n",
       "   '06f1311e6f6f',\n",
       "   '06ffa3d84351',\n",
       "   '07062e00b174',\n",
       "   '071da920fdde',\n",
       "   '071e6f1cbf50',\n",
       "   '07222e081d1e',\n",
       "   '072e8a5bae3f',\n",
       "   '073133dbe904',\n",
       "   '074264ba0bf2',\n",
       "   '075d8e06a67c',\n",
       "   '0771da6b2e1a',\n",
       "   '07738f7780df',\n",
       "   '077e89faa79c',\n",
       "   '078382e2a114',\n",
       "   '0785dc1e0664',\n",
       "   '0785fb89fab4',\n",
       "   '0796a7fb1e29',\n",
       "   '079b6affa801',\n",
       "   '07a7fe9b6483',\n",
       "   '07af8bc5014b',\n",
       "   '07c53b240b01',\n",
       "   '07c8e96adb74',\n",
       "   '07ce6e7c0c60',\n",
       "   '07d44247ce39',\n",
       "   '07e0d3b6de6d',\n",
       "   '07e15e3afe97',\n",
       "   '07e5e8be249e',\n",
       "   '07f377e4b159',\n",
       "   '07fe5bb99114',\n",
       "   '0801eb2c6e11',\n",
       "   '0811f79277e9',\n",
       "   '0812ed415b21',\n",
       "   '081e7c5a55c6',\n",
       "   '082132634134',\n",
       "   '083144fb1453',\n",
       "   '083e51763511',\n",
       "   '083e7638f614',\n",
       "   '08519f3e01ee',\n",
       "   '085bec289fdd',\n",
       "   '0871368b476a',\n",
       "   '0880c44e0fa4',\n",
       "   '089e5299fa44',\n",
       "   '08bc6dd9d533',\n",
       "   '08bdfa8e1c15',\n",
       "   '08c62e60b692',\n",
       "   '08cfb59dc65b',\n",
       "   '08dfb1d3d332',\n",
       "   '08e525e13b8c',\n",
       "   '08ec0ba82340',\n",
       "   '08f9eedb994a',\n",
       "   '092686d9364a',\n",
       "   '092eabcdc76d',\n",
       "   '09335f825c05',\n",
       "   '093b94338898',\n",
       "   '0942daae186e',\n",
       "   '0944d426a9f0',\n",
       "   '094efbc8db65',\n",
       "   '0959e162bd12',\n",
       "   '095acf723068',\n",
       "   '095b039c6a5e',\n",
       "   '095f5c36215a',\n",
       "   '0960c8b08350',\n",
       "   '09809939bbbc',\n",
       "   '098e2378ef88',\n",
       "   '09abeab74b1b',\n",
       "   '09ae3edc9722',\n",
       "   '09b6ac590e29',\n",
       "   '09b7fba39f2e',\n",
       "   '09b91e9a51d8',\n",
       "   '09c2478f2e4b',\n",
       "   '09c4b362c0b1',\n",
       "   '09c7cc1c97f2',\n",
       "   '09ca82c5f9c4',\n",
       "   '09ced9f9f27f',\n",
       "   '09d0ad5c9557',\n",
       "   '09e24d94fc99',\n",
       "   '09ec7f530ce6',\n",
       "   '09edfe95038a',\n",
       "   '09f7b15139d0',\n",
       "   '09f9da79e5ea',\n",
       "   '09fb4e4bbc45',\n",
       "   '09fd4ecd6ef1',\n",
       "   '0a0c931f79ce',\n",
       "   '0a1019150c3e',\n",
       "   '0a18575bfefc',\n",
       "   '0a2f66d10ad1',\n",
       "   '0a45ac530630',\n",
       "   '0a492ed4f5e5',\n",
       "   '0a5023a0b43b',\n",
       "   '0a629ade9cc3',\n",
       "   '0a72a5b8439f',\n",
       "   '0a730db66a62',\n",
       "   '0a7c7f0fb687',\n",
       "   '0a8cc69ddb75',\n",
       "   '0a90a192a60b',\n",
       "   '0a993390b99e',\n",
       "   '0a9f4e679fe2',\n",
       "   '0aa3c84294dc',\n",
       "   '0aaf8e99c8c7',\n",
       "   '0ab51ae3a996',\n",
       "   '0aba98fc28ab',\n",
       "   '0abce5a499cf',\n",
       "   '0ac966a8bd62',\n",
       "   '0ad0b5fc65d7',\n",
       "   '0ad74c7ab506',\n",
       "   '0ad8210dbae1',\n",
       "   '0adb82f247f1',\n",
       "   '0ae118657c98',\n",
       "   '0ae208a19173',\n",
       "   '0ae7fff06995',\n",
       "   '0af0a1b91b37',\n",
       "   '0af4fe01c5c5',\n",
       "   '0af5f373313c',\n",
       "   '0af919cf690e',\n",
       "   '0afa8541b1f3',\n",
       "   '0afede805da8',\n",
       "   '0b002a16f7e9',\n",
       "   '0b047ea2a2e2',\n",
       "   '0b08fe198ecf',\n",
       "   '0b176a2545af',\n",
       "   '0b1f054d198f',\n",
       "   '0b2021d26409',\n",
       "   '0b2557c251f7',\n",
       "   '0b2c41bc18cd',\n",
       "   '0b36e4263392',\n",
       "   '0b37349d902a',\n",
       "   '0b40b721eae7',\n",
       "   '0b4174323f76',\n",
       "   '0b72546edb87',\n",
       "   '0b8df69c12a1',\n",
       "   '0b907f3143c6',\n",
       "   '0b915a500f12',\n",
       "   '0b94187ee8f5',\n",
       "   '0b96f6886a09',\n",
       "   '0b9d32aa10ca',\n",
       "   '0ba0965e59f6',\n",
       "   '0bb85f2a0b3b',\n",
       "   '0bbd1d8ab904',\n",
       "   '0bc67fdc146b',\n",
       "   '0bc872ce959b',\n",
       "   '0bd8cab24359',\n",
       "   '0bda1b9f7b67',\n",
       "   '0be2721d665f',\n",
       "   '0be27622ce75',\n",
       "   '0be7589e82af',\n",
       "   '0be797753069',\n",
       "   '0bef35450b17',\n",
       "   '0c06d8c818a1',\n",
       "   '0c181b8a4219',\n",
       "   '0c1e0b204b77',\n",
       "   '0c336a372b85',\n",
       "   '0c36b68c3f11',\n",
       "   '0c451e675ee4',\n",
       "   '0c4a6fad5f96',\n",
       "   '0c5502b3eacb',\n",
       "   '0c68fc4a1f71',\n",
       "   '0c88344e2cb0',\n",
       "   '0c8d56eda234',\n",
       "   '0c95c287b9fb',\n",
       "   '0c9a285d8aa0',\n",
       "   '0ca0e30eb989',\n",
       "   '0ca7116f2051',\n",
       "   '0cacbce72e83',\n",
       "   '0cad9fecf547',\n",
       "   '0cb1b0a018a6',\n",
       "   '0cb7befea44a',\n",
       "   '0cbb8de08159',\n",
       "   '0cc781fc9c71',\n",
       "   '0cc92b608b1c',\n",
       "   '0ccd347285af',\n",
       "   '0cdd4824636e',\n",
       "   '0ce543c936f4',\n",
       "   '0cf3cf1c1015',\n",
       "   '0cf4a3893e1e',\n",
       "   '0cf6e8e54951',\n",
       "   '0cf8aa357435',\n",
       "   '0d0092c96a67',\n",
       "   '0d02a526311b',\n",
       "   '0d11d07c746e',\n",
       "   '0d129e227831',\n",
       "   '0d1ca3c5d9ea',\n",
       "   '0d2354f73708',\n",
       "   '0d2ad0649a8a',\n",
       "   '0d3ae394438c',\n",
       "   '0d3c37452856',\n",
       "   '0d58ac7ba0d4',\n",
       "   '0d5bc1b7a8a5',\n",
       "   '0d689a970b60',\n",
       "   '0d6a560df67d',\n",
       "   '0d70c3ed6b4f',\n",
       "   '0d898122bb61',\n",
       "   '0d8d9fefb8f3',\n",
       "   '0d97ec07f549',\n",
       "   '0d99fcffdf8b',\n",
       "   '0d9eab495b3c',\n",
       "   '0dbb707642fa',\n",
       "   '0dc1cec049d3',\n",
       "   '0dc20688cac0',\n",
       "   '0dc84f4b423a',\n",
       "   '0dd63eaaa48f',\n",
       "   '0ddfa32e316f',\n",
       "   '0de64a90c1e2',\n",
       "   '0de7c4c3383f',\n",
       "   '0de8dcf65882',\n",
       "   '0dec4770a795',\n",
       "   '0df96ea30c43',\n",
       "   '0e0086d25374',\n",
       "   '0e12f8cc4094',\n",
       "   '0e15d5c7830d',\n",
       "   '0e228301ded4',\n",
       "   '0e2d9ed2bfc9',\n",
       "   '0e2f34049763',\n",
       "   '0e365ad5e60a',\n",
       "   '0e3685e789fa',\n",
       "   '0e3773902b2d',\n",
       "   '0e40f77ac6a3',\n",
       "   '0e4aa70f7594',\n",
       "   '0e4acb68928f',\n",
       "   '0e4f2698d2b5',\n",
       "   '0e555c4e0354',\n",
       "   '0e591da70804',\n",
       "   '0e5faf098978',\n",
       "   '0e61f3697d54',\n",
       "   '0e7dc74f4b5f',\n",
       "   '0e883fad2ed1',\n",
       "   '0e8a43feb507',\n",
       "   '0e8fc6b09e89',\n",
       "   '0e9390f24154',\n",
       "   '0eacbe3178a1',\n",
       "   '0ec548320a3f',\n",
       "   '0eca275c588c',\n",
       "   '0ed0e5a8ca2f',\n",
       "   '0ed5b971913f',\n",
       "   '0edc6763e4b8',\n",
       "   '0edcecd1d5d4',\n",
       "   '0eebb404158d',\n",
       "   '0ef16e1d45ff',\n",
       "   '0ef3c1eababb',\n",
       "   '0efa91bc2ac7',\n",
       "   '0effedba9ec5',\n",
       "   '0f067f35dc76',\n",
       "   '0f11c2541a42',\n",
       "   '0f27b22b653f',\n",
       "   '0f42c9652cda'],\n",
       "  'top_articles': [{'id': '6a7ab0b04d35',\n",
       "    'title': 'Don’t use loc/iloc with Loops In Python, Instead, Use This!',\n",
       "    'subtitle': 'Run your loops at a 60X faster speed',\n",
       "    'author': 'd80580992695',\n",
       "    'publication_id': '29038077e4c6',\n",
       "    'published_at': '2024-01-24 01:46:17',\n",
       "    'last_modified_at': '2024-01-30 10:42:58',\n",
       "    'tags': ['python',\n",
       "     'data-science',\n",
       "     'data-analysis',\n",
       "     'programming',\n",
       "     'loops-in-python'],\n",
       "    'topics': ['data-science', 'programming'],\n",
       "    'claps': 1311,\n",
       "    'voters': 331,\n",
       "    'word_count': 679,\n",
       "    'responses_count': 10,\n",
       "    'reading_time': 2.9455974842767296,\n",
       "    'url': 'https://medium.com/codex/dont-use-loc-iloc-with-loops-in-python-instead-use-this-6a7ab0b04d35',\n",
       "    'unique_slug': 'dont-use-loc-iloc-with-loops-in-python-instead-use-this-6a7ab0b04d35',\n",
       "    'image_url': 'https://miro.medium.com/1*SyvWzmE0YT19onb4ODlYrw.jpeg',\n",
       "    'lang': 'en',\n",
       "    'is_series': False,\n",
       "    'is_locked': True,\n",
       "    'is_shortform': False,\n",
       "    'top_highlight': 'loc and iloc are meant to access multiple elements(series/dataframe) at the same time, potentially to perform vectorized operations.'},\n",
       "   {'id': 'e8b0172b9581',\n",
       "    'title': 'Say Goodbye to Loops in Python, and Welcome Vectorization!',\n",
       "    'subtitle': 'Use Vectorization\\u200a—\\u200aa super-fast alternative to loops in Python',\n",
       "    'author': 'd80580992695',\n",
       "    'publication_id': '29038077e4c6',\n",
       "    'published_at': '2023-12-28 02:01:32',\n",
       "    'last_modified_at': '2023-12-29 08:28:02',\n",
       "    'tags': ['data-science',\n",
       "     'programming',\n",
       "     'python',\n",
       "     'data-analysis',\n",
       "     'python-programming'],\n",
       "    'topics': ['data-science', 'programming'],\n",
       "    'claps': 4313,\n",
       "    'voters': 1310,\n",
       "    'word_count': 966,\n",
       "    'responses_count': 55,\n",
       "    'reading_time': 4.595283018867924,\n",
       "    'url': 'https://medium.com/codex/say-goodbye-to-loops-in-python-and-welcome-vectorization-e8b0172b9581',\n",
       "    'unique_slug': 'say-goodbye-to-loops-in-python-and-welcome-vectorization-e8b0172b9581',\n",
       "    'image_url': 'https://miro.medium.com/0*OMVt9wKbfIPJIB_5.jpeg',\n",
       "    'lang': 'en',\n",
       "    'is_series': False,\n",
       "    'is_locked': True,\n",
       "    'is_shortform': False,\n",
       "    'top_highlight': \"Vectorization is the technique of implementing (NumPy) array operations on a dataset. In the background, it applies the operations to all the elements of an array or series in one go (unlike a 'for' loop that manipulates one row at a time).\"},\n",
       "   {'id': '792181d2464a',\n",
       "    'title': 'Top 10 Data Visualizations of 2023 Worth Looking at!',\n",
       "    'subtitle': 'Level Up Your Visualization Game!',\n",
       "    'author': 'd80580992695',\n",
       "    'publication_id': '29038077e4c6',\n",
       "    'published_at': '2023-12-27 01:01:42',\n",
       "    'last_modified_at': '2023-12-29 08:28:09',\n",
       "    'tags': ['data-science',\n",
       "     'data-visualization',\n",
       "     'data',\n",
       "     'visualization',\n",
       "     'data-analysis'],\n",
       "    'topics': ['data-science'],\n",
       "    'claps': 993,\n",
       "    'voters': 297,\n",
       "    'word_count': 794,\n",
       "    'responses_count': 13,\n",
       "    'reading_time': 3.1962264150943396,\n",
       "    'url': 'https://medium.com/codex/top-10-data-visualizations-of-2023-worth-looking-at-792181d2464a',\n",
       "    'unique_slug': 'top-10-data-visualizations-of-2023-worth-looking-at-792181d2464a',\n",
       "    'image_url': 'https://miro.medium.com/1*qcQcxcTncHwVMBExIY5oZg.png',\n",
       "    'lang': 'en',\n",
       "    'is_series': False,\n",
       "    'is_locked': True,\n",
       "    'is_shortform': False,\n",
       "    'top_highlight': ''},\n",
       "   {'id': 'cb7975befa53',\n",
       "    'title': 'Follow this 10-Step Template for an Awesome Data Analysis!',\n",
       "    'subtitle': 'Pic Credit: Unsplash',\n",
       "    'author': 'd80580992695',\n",
       "    'publication_id': '78073def27b8',\n",
       "    'published_at': '2023-09-21 01:02:53',\n",
       "    'last_modified_at': '2024-01-27 19:11:28',\n",
       "    'tags': ['data-analysis',\n",
       "     'data-science',\n",
       "     'data-visualization',\n",
       "     'python',\n",
       "     'programming'],\n",
       "    'topics': ['data-science'],\n",
       "    'claps': 553,\n",
       "    'voters': 100,\n",
       "    'word_count': 1106,\n",
       "    'responses_count': 4,\n",
       "    'reading_time': 5.473584905660378,\n",
       "    'url': 'https://python.plainenglish.io/follow-this-10-step-template-for-an-awesome-data-analysis-cb7975befa53',\n",
       "    'unique_slug': 'follow-this-10-step-template-for-an-awesome-data-analysis-cb7975befa53',\n",
       "    'image_url': 'https://miro.medium.com/1*jwsGPNhgEMmjIaKH4u2HcA.jpeg',\n",
       "    'lang': 'en',\n",
       "    'is_series': False,\n",
       "    'is_locked': False,\n",
       "    'is_shortform': False,\n",
       "    'top_highlight': ''},\n",
       "   {'id': 'd30fa1b701f6',\n",
       "    'title': 'Don’t Start Your SQL Queries with the ‘Select’ Statement',\n",
       "    'subtitle': 'Follow this right approach to write your SQL queries',\n",
       "    'author': 'd80580992695',\n",
       "    'publication_id': '7f60cf5620c9',\n",
       "    'published_at': '2022-12-05 23:31:35',\n",
       "    'last_modified_at': '2022-12-08 20:35:19',\n",
       "    'tags': ['sql',\n",
       "     'programming',\n",
       "     'data-science',\n",
       "     'data-analysis',\n",
       "     'relational-databases'],\n",
       "    'topics': ['data-science', 'programming'],\n",
       "    'claps': 1921,\n",
       "    'voters': 569,\n",
       "    'word_count': 876,\n",
       "    'responses_count': 41,\n",
       "    'reading_time': 4.3556603773584905,\n",
       "    'url': 'https://towardsdatascience.com/dont-start-your-sql-queries-with-select-clause-d30fa1b701f6',\n",
       "    'unique_slug': 'dont-start-your-sql-queries-with-select-clause-d30fa1b701f6',\n",
       "    'image_url': 'https://miro.medium.com/1*ok4j2wjoNtVrYKhpENbgGw.jpeg',\n",
       "    'lang': 'en',\n",
       "    'is_series': False,\n",
       "    'is_locked': True,\n",
       "    'is_shortform': False,\n",
       "    'top_highlight': \"Don't Start Your SQL Queries with the 'Select' Statement\"},\n",
       "   {'id': 'a97c4639c183',\n",
       "    'title': 'Don’t Write Another Line Of Code In Python Until You’ve Seen These Mistakes!',\n",
       "    'subtitle': 'Let’s start writing cleaner codes in Python',\n",
       "    'author': 'd80580992695',\n",
       "    'publication_id': '*Self-Published*',\n",
       "    'published_at': '2024-02-13 01:47:25',\n",
       "    'last_modified_at': '2024-02-13 01:47:25',\n",
       "    'tags': ['python', 'programming', 'data-science', 'analytics', 'coding'],\n",
       "    'topics': ['programming'],\n",
       "    'claps': 151,\n",
       "    'voters': 16,\n",
       "    'word_count': 757,\n",
       "    'responses_count': 2,\n",
       "    'reading_time': 3.056603773584906,\n",
       "    'url': 'https://anmol3015.medium.com/dont-write-another-line-of-code-in-python-until-you-ve-seen-these-mistakes-a97c4639c183',\n",
       "    'unique_slug': 'dont-write-another-line-of-code-in-python-until-you-ve-seen-these-mistakes-a97c4639c183',\n",
       "    'image_url': 'https://miro.medium.com/1*VBK3top74w5boIFOeOOtNw.jpeg',\n",
       "    'lang': 'en',\n",
       "    'is_series': False,\n",
       "    'is_locked': True,\n",
       "    'is_shortform': False,\n",
       "    'top_highlight': ''},\n",
       "   {'id': 'b0935bf96ee2',\n",
       "    'title': 'Pandas Crash Course: Top 30 Functions for ANY Data Analysis',\n",
       "    'subtitle': 'Become a Pro in using Pandas for Data Science',\n",
       "    'author': 'd80580992695',\n",
       "    'publication_id': '*Self-Published*',\n",
       "    'published_at': '2024-02-06 01:47:21',\n",
       "    'last_modified_at': '2024-02-06 01:47:21',\n",
       "    'tags': ['python',\n",
       "     'pandas',\n",
       "     'data-science',\n",
       "     'data-analysis',\n",
       "     'programming'],\n",
       "    'topics': ['data-science', 'programming'],\n",
       "    'claps': 421,\n",
       "    'voters': 63,\n",
       "    'word_count': 1271,\n",
       "    'responses_count': 3,\n",
       "    'reading_time': 7.046226415094339,\n",
       "    'url': 'https://anmol3015.medium.com/pandas-crash-course-top-30-functions-for-any-data-analysis-b0935bf96ee2',\n",
       "    'unique_slug': 'pandas-crash-course-top-30-functions-for-any-data-analysis-b0935bf96ee2',\n",
       "    'image_url': 'https://miro.medium.com/1*VBK3top74w5boIFOeOOtNw.jpeg',\n",
       "    'lang': 'en',\n",
       "    'is_series': False,\n",
       "    'is_locked': True,\n",
       "    'is_shortform': False,\n",
       "    'top_highlight': ''},\n",
       "   {'id': '68ffa12f8885',\n",
       "    'title': 'Data Visualization Tips to have a long-lasting Impact on Your Audience',\n",
       "    'subtitle': 'Let’s start with the Bar Chart',\n",
       "    'author': 'd80580992695',\n",
       "    'publication_id': '*Self-Published*',\n",
       "    'published_at': '2024-01-30 01:52:20',\n",
       "    'last_modified_at': '2024-01-30 14:39:16',\n",
       "    'tags': ['data-visualization',\n",
       "     'data-science',\n",
       "     'data',\n",
       "     'visualization',\n",
       "     'data-analysis'],\n",
       "    'topics': ['data-science'],\n",
       "    'claps': 126,\n",
       "    'voters': 28,\n",
       "    'word_count': 736,\n",
       "    'responses_count': 1,\n",
       "    'reading_time': 3.827358490566038,\n",
       "    'url': 'https://anmol3015.medium.com/data-visualization-tips-to-have-a-long-lasting-impact-on-your-audience-68ffa12f8885',\n",
       "    'unique_slug': 'data-visualization-tips-to-have-a-long-lasting-impact-on-your-audience-68ffa12f8885',\n",
       "    'image_url': 'https://miro.medium.com/1*NhCWYLw5Qd0o8vYZA6lyKA.png',\n",
       "    'lang': 'en',\n",
       "    'is_series': False,\n",
       "    'is_locked': True,\n",
       "    'is_shortform': False,\n",
       "    'top_highlight': ''},\n",
       "   {'id': '81909c97e7d2',\n",
       "    'title': 'Don’t Underestimate the Power of Matplotlib, It can create Animations Too!',\n",
       "    'subtitle': 'The untapped potential of matplotlib',\n",
       "    'author': 'd80580992695',\n",
       "    'publication_id': '29038077e4c6',\n",
       "    'published_at': '2024-01-17 01:32:14',\n",
       "    'last_modified_at': '2024-01-24 12:29:53',\n",
       "    'tags': ['python-programming',\n",
       "     'python',\n",
       "     'visualization',\n",
       "     'data-science',\n",
       "     'data-visualization'],\n",
       "    'topics': ['data-science', 'programming'],\n",
       "    'claps': 147,\n",
       "    'voters': 37,\n",
       "    'word_count': 836,\n",
       "    'responses_count': 2,\n",
       "    'reading_time': 3.988050314465409,\n",
       "    'url': 'https://medium.com/codex/dont-underestimate-the-power-of-matplotlib-it-can-create-animations-too-81909c97e7d2',\n",
       "    'unique_slug': 'dont-underestimate-the-power-of-matplotlib-it-can-create-animations-too-81909c97e7d2',\n",
       "    'image_url': 'https://miro.medium.com/1*Zg5A9B0Mr8cTE5a8u7N7_A.jpeg',\n",
       "    'lang': 'en',\n",
       "    'is_series': False,\n",
       "    'is_locked': True,\n",
       "    'is_shortform': False,\n",
       "    'top_highlight': ''},\n",
       "   {'id': 'f4104ce25e0b',\n",
       "    'title': 'Top 10 coding mistakes committed by Data Scientists\\u200a—\\u200aA Dramatic Version',\n",
       "    'subtitle': 'Hey there, fellow Data Scientists! Let’s spill the tea on some common mistakes we data scientists tend to do while dancing with the code…',\n",
       "    'author': 'd80580992695',\n",
       "    'publication_id': '29038077e4c6',\n",
       "    'published_at': '2023-12-25 01:01:37',\n",
       "    'last_modified_at': '2024-01-01 08:33:33',\n",
       "    'tags': ['data-science', 'data', 'python', 'data-analysis'],\n",
       "    'topics': ['data-science'],\n",
       "    'claps': 50,\n",
       "    'voters': 18,\n",
       "    'word_count': 898,\n",
       "    'responses_count': 2,\n",
       "    'reading_time': 3.588679245283019,\n",
       "    'url': 'https://medium.com/codex/top-10-coding-mistakes-committed-by-data-scientists-a-dramatic-version-f4104ce25e0b',\n",
       "    'unique_slug': 'top-10-coding-mistakes-committed-by-data-scientists-a-dramatic-version-f4104ce25e0b',\n",
       "    'image_url': 'https://miro.medium.com/1*BeHAZ9ATRAfXS5RLRJD1ZQ.jpeg',\n",
       "    'lang': 'en',\n",
       "    'is_series': False,\n",
       "    'is_locked': True,\n",
       "    'is_shortform': False,\n",
       "    'top_highlight': ''}]},\n",
       " '8a910484fe84': {'id': '8a910484fe84',\n",
       "  'username': 'moneytent',\n",
       "  'fullname': 'Money Tent',\n",
       "  'bio': 'Money Tent offers cutting-edge online money-making strategies for beginners to leverage before they lose their appeal. 🤑 https://highticketaisystem.gr8.com/',\n",
       "  'followers_count': 3516,\n",
       "  'following_count': 587,\n",
       "  'publication_following_count': 170,\n",
       "  'image_url': 'https://miro.medium.com/1*9yy_yVBXWinFF-U3HOXnsQ.jpeg',\n",
       "  'twitter_username': '',\n",
       "  'is_writer_program_enrolled': True,\n",
       "  'allow_notes': True,\n",
       "  'medium_member_at': '2024-01-01 23:02:45',\n",
       "  'is_suspended': False,\n",
       "  'top_writer_in': ['artificial-intelligence',\n",
       "   'bitcoin',\n",
       "   'art',\n",
       "   'startup',\n",
       "   'social-media',\n",
       "   'finance',\n",
       "   'business',\n",
       "   'productivity'],\n",
       "  'has_list': True,\n",
       "  'is_book_author': False,\n",
       "  'tipping_link': None,\n",
       "  'bg_image_url': '',\n",
       "  'logo_image_url': 'https://miro.medium.com/1*9yy_yVBXWinFF-U3HOXnsQ.jpeg',\n",
       "  'followers': ['00033482febc',\n",
       "   '0037f86827fc',\n",
       "   '0058b5cae97b',\n",
       "   '008a14be34ba',\n",
       "   '00a6814e9fb8',\n",
       "   '00afa85f7006',\n",
       "   '00b42c5ef175',\n",
       "   '00d0c88bf952',\n",
       "   '00f1dddb885d',\n",
       "   '00f72e37bb2a',\n",
       "   '0174441cc019',\n",
       "   '01e9cb002545',\n",
       "   '02003ebe3684',\n",
       "   '0224fb58572d',\n",
       "   '0256fc0ed932',\n",
       "   '02bbd17887c1',\n",
       "   '034f59d2a2b6',\n",
       "   '037cf47840d3',\n",
       "   '03aaa66474f1',\n",
       "   '03b057f52bd1',\n",
       "   '044550146f67',\n",
       "   '048dfaf96e7e',\n",
       "   '04ca33ca0707',\n",
       "   '051b52bfd42b',\n",
       "   '0531f58c99e8',\n",
       "   '05587ddfe14b',\n",
       "   '056856b1689b',\n",
       "   '057714105984',\n",
       "   '0595f1354b83',\n",
       "   '05f70b847a3f',\n",
       "   '060e34850c11',\n",
       "   '064f954fe971',\n",
       "   '069622bc84ac',\n",
       "   '07138f3f4f4b',\n",
       "   '0728c366269d',\n",
       "   '072e8a5bae3f',\n",
       "   '07577d08a134',\n",
       "   '076891e390d9',\n",
       "   '0779702f21ca',\n",
       "   '079a0707aa7f',\n",
       "   '07bc8cceadce',\n",
       "   '07beec0f2f9d',\n",
       "   '0843bb5b758f',\n",
       "   '0859720c1d98',\n",
       "   '089bdc60e29f',\n",
       "   '08dba4ed509c',\n",
       "   '092844e2f30e',\n",
       "   '095a53a03ca0',\n",
       "   '098659f21f81',\n",
       "   '09bb1fb6ffab',\n",
       "   '09d7e9f07670',\n",
       "   '09daca38177a',\n",
       "   '09fcdb026a45',\n",
       "   '0a069ab8cbab',\n",
       "   '0a3413e96cd9',\n",
       "   '0a3f9e6be2f8',\n",
       "   '0a71701c1f16',\n",
       "   '0a83a151bcba',\n",
       "   '0a90a192a60b',\n",
       "   '0ab51ae3a996',\n",
       "   '0af0a1b91b37',\n",
       "   '0af919cf690e',\n",
       "   '0b1f054d198f',\n",
       "   '0b24d3fbc420',\n",
       "   '0b4109140f91',\n",
       "   '0b4174323f76',\n",
       "   '0b5fd6bd5a03',\n",
       "   '0b8df69c12a1',\n",
       "   '0b9784fb8b24',\n",
       "   '0baccaec36b0',\n",
       "   '0bd688a41f7f',\n",
       "   '0c0a64b7ec00',\n",
       "   '0c12ddd398a9',\n",
       "   '0c26ac239045',\n",
       "   '0c336a372b85',\n",
       "   '0c356e469cce',\n",
       "   '0c378e262c08',\n",
       "   '0c67f6fa3a50',\n",
       "   '0c78c4065a7c',\n",
       "   '0ca0e30eb989',\n",
       "   '0cc9edb91ae8',\n",
       "   '0ce7ee075ab6',\n",
       "   '0ce8ba38a668',\n",
       "   '0d987c64f15c',\n",
       "   '0d9eab495b3c',\n",
       "   '0ddc94655f11',\n",
       "   '0deb5e24f63d',\n",
       "   '0e0400d3fcd8',\n",
       "   '0e7b83d31a94',\n",
       "   '0f66665e5e2f',\n",
       "   '0fc9547e5459',\n",
       "   '0ffc0e31e90f',\n",
       "   '100130cb5f3a',\n",
       "   '100d11cc17cf',\n",
       "   '102719bbd80a',\n",
       "   '10477dafd107',\n",
       "   '104e646bc412',\n",
       "   '105d85848b6f',\n",
       "   '10dafbb8f9ed',\n",
       "   '10ef20a49b20',\n",
       "   '10ef52991cce',\n",
       "   '110aa441511c',\n",
       "   '111abdc8597c',\n",
       "   '111f0d923ec4',\n",
       "   '11390e26fcee',\n",
       "   '113a7dab1d0b',\n",
       "   '1147172dea90',\n",
       "   '1151a4a42fe',\n",
       "   '115a0327b7db',\n",
       "   '116f4c7b331f',\n",
       "   '117f5e0fefd0',\n",
       "   '1199efd054cc',\n",
       "   '11a9f07abe65',\n",
       "   '11b259719a4e',\n",
       "   '11c902584fad',\n",
       "   '11cb531ecaca',\n",
       "   '11df028bb3e4',\n",
       "   '120638365899',\n",
       "   '1206b5bbaa68',\n",
       "   '120b96548c1e',\n",
       "   '123084f9fc3e',\n",
       "   '12386b812ae2',\n",
       "   '1248ff600851',\n",
       "   '124de873349f',\n",
       "   '1268d1d76696',\n",
       "   '12935397bcf1',\n",
       "   '12b082a45167',\n",
       "   '12b10e60ba31',\n",
       "   '12c9c6e69219',\n",
       "   '12d5ee54f204',\n",
       "   '12fab0c76517',\n",
       "   '12fe9a458f18',\n",
       "   '13427956f2c0',\n",
       "   '1359a197b804',\n",
       "   '13680fd88d78',\n",
       "   '136c9cffa503',\n",
       "   '138514ea62fb',\n",
       "   '1411ffcbfa31',\n",
       "   '145198a68a7a',\n",
       "   '146617e4a70d',\n",
       "   '146e6d3f25b4',\n",
       "   '147a8bfad845',\n",
       "   '14a3144d269c',\n",
       "   '14b13505eda7',\n",
       "   '14b3fc0220c0',\n",
       "   '14c5b08cf17',\n",
       "   '14d041158109',\n",
       "   '14d8b357989d',\n",
       "   '14de63c59548',\n",
       "   '14e1817de632',\n",
       "   '14eab1dd6424',\n",
       "   '14f120e1564d',\n",
       "   '1501be77274d',\n",
       "   '1508b2950480',\n",
       "   '152d01cf5366',\n",
       "   '1533743cbf43',\n",
       "   '153d11b35ae0',\n",
       "   '154b6f65b5d2',\n",
       "   '156434759360',\n",
       "   '156afe5e4d63',\n",
       "   '156fc80e039d',\n",
       "   '15807fc9a47f',\n",
       "   '158f7e51cc97',\n",
       "   '159bd7a0aba0',\n",
       "   '15b5e5f3fa89',\n",
       "   '15c8059486a3',\n",
       "   '15e8cfa6d3e5',\n",
       "   '160c1dca9497',\n",
       "   '160c3e933453',\n",
       "   '1623d32ad7ef',\n",
       "   '1636d2b9a579',\n",
       "   '1642eb709ad8',\n",
       "   '165a8f78d5d3',\n",
       "   '166051d364b5',\n",
       "   '1663be6269a9',\n",
       "   '167ecb82d68e',\n",
       "   '1680a0e810df',\n",
       "   '169b5527fee1',\n",
       "   '16a3bd179934',\n",
       "   '16b803f25ef0',\n",
       "   '16b82c6226a3',\n",
       "   '16be7b4df189',\n",
       "   '16cf86c4bbb5',\n",
       "   '16f6f9e9526b',\n",
       "   '16f87b48e521',\n",
       "   '16f8fc4a8401',\n",
       "   '1714236db33',\n",
       "   '1720ae7eedf6',\n",
       "   '173193dcbb89',\n",
       "   '174b55300a2c',\n",
       "   '175c78661c14',\n",
       "   '175dcf68867e',\n",
       "   '176dc8906a9e',\n",
       "   '177909de38c1',\n",
       "   '17a37cbddd39',\n",
       "   '17adf5976348',\n",
       "   '17c9b888001c',\n",
       "   '17cf3d1415da',\n",
       "   '17e959d359df',\n",
       "   '17fa7e0153b2',\n",
       "   '1803805c77b2',\n",
       "   '181ef9f27d3b',\n",
       "   '1851d2a78ea3',\n",
       "   '18569621a13d',\n",
       "   '185a78e53465',\n",
       "   '186fd6f3862d',\n",
       "   '187454129b21',\n",
       "   '188fb17d2a9a',\n",
       "   '18b5fd193c7d',\n",
       "   '18bfe7b73079',\n",
       "   '18ca47a3b58b',\n",
       "   '18d5ca8ba0b7',\n",
       "   '18d643bc4ff',\n",
       "   '18f4feaa9055',\n",
       "   '18f8179749aa',\n",
       "   '190701cd8e55',\n",
       "   '190a0152d163',\n",
       "   '19102fd72a1b',\n",
       "   '191205fd2b83',\n",
       "   '1926a6a50553',\n",
       "   '192894eda087',\n",
       "   '192d500c2037',\n",
       "   '192f273107b',\n",
       "   '193c8fe1216d',\n",
       "   '193d5293d86d',\n",
       "   '194a2cf83a10',\n",
       "   '198dbd70dab8',\n",
       "   '19b943acac85',\n",
       "   '19bec707f668',\n",
       "   '19c48e1cb4d',\n",
       "   '19d9bc63c5cd',\n",
       "   '1a0128abb718',\n",
       "   '1a08aa9e3319',\n",
       "   '1a3098de0a9b',\n",
       "   '1a3b96579e7c',\n",
       "   '1a45027479b1',\n",
       "   '1a591e4045f6',\n",
       "   '1a66f2a506d6',\n",
       "   '1a6c907c866d',\n",
       "   '1a7ca6a8a584',\n",
       "   '1a9d0ade124c',\n",
       "   '1a9d597026ad',\n",
       "   '1ac51e917ea4',\n",
       "   '1ad3ea01f229',\n",
       "   '1ad8472d54d5',\n",
       "   '1ae33b44e139',\n",
       "   '1ae6ad5e7500',\n",
       "   '1b003bd9c76b',\n",
       "   '1b01aed1c28c',\n",
       "   '1b1e4e7462b9',\n",
       "   '1b441028792e',\n",
       "   '1b47528b974f',\n",
       "   '1b602356e00a',\n",
       "   '1bc75b87121d',\n",
       "   '1bcd1d1d9692',\n",
       "   '1c164c57c62',\n",
       "   '1c1688bba39a',\n",
       "   '1c3aa2e3f5ad',\n",
       "   '1c6ae2507d79',\n",
       "   '1c717a4b7e69',\n",
       "   '1c852f2150de',\n",
       "   '1c92573badf2',\n",
       "   '1c93cd415904',\n",
       "   '1ca805bfad03',\n",
       "   '1cd781320e0c',\n",
       "   '1ced124e73bf',\n",
       "   '1cf3dc79c0c2',\n",
       "   '1cf9d28e489e',\n",
       "   '1d034a88f476',\n",
       "   '1d21eeccd0b0',\n",
       "   '1d2622e8c426',\n",
       "   '1d3008221c9f',\n",
       "   '1d3de95f0c8d',\n",
       "   '1d45745cf04d',\n",
       "   '1d539dcea779',\n",
       "   '1d580bedf99e',\n",
       "   '1d592573ae2e',\n",
       "   '1d628872458b',\n",
       "   '1dca3eb4a9b',\n",
       "   '1dfba74b8e38',\n",
       "   '1e0596113909',\n",
       "   '1e12e8714fe3',\n",
       "   '1e186f3b1d66',\n",
       "   '1e2328276b45',\n",
       "   '1e2ab2ceca96',\n",
       "   '1e6ee27d98d7',\n",
       "   '1e78bbfa4c40',\n",
       "   '1e7b754ddfb7',\n",
       "   '1eca48e2f360',\n",
       "   '1ed2a7fdc51e',\n",
       "   '1ee9e21d81f1',\n",
       "   '1f12cc676340',\n",
       "   '1f258bd730b4',\n",
       "   '1f2d52d9d0ac',\n",
       "   '1f2d9e7d0316',\n",
       "   '1f383c1dbc3b',\n",
       "   '1f54bc596185',\n",
       "   '1f5a6f2a54f2',\n",
       "   '1f7ceb52aee4',\n",
       "   '1f8064d580f1',\n",
       "   '1f84767b53b4',\n",
       "   '1f88e403969a',\n",
       "   '1f99d30fb314',\n",
       "   '1fa19d456476',\n",
       "   '1fb2397e19c8',\n",
       "   '1fbdaeb2034e',\n",
       "   '1fbed2f5de27',\n",
       "   '1fddf914e9a1',\n",
       "   '1fe4a5483123',\n",
       "   '1fe7fdbbb163',\n",
       "   '1ff8316858ac',\n",
       "   '200120969dcb',\n",
       "   '202f266df938',\n",
       "   '20350e09206a',\n",
       "   '20648e209844',\n",
       "   '208063e05c01',\n",
       "   '2080e011ccca',\n",
       "   '20a2cfe0fed6',\n",
       "   '20aa8aed80f1',\n",
       "   '20b79c599968',\n",
       "   '20d6e3bd4448',\n",
       "   '20dab1af4aea',\n",
       "   '20e7de872bde',\n",
       "   '20e8cacd3ad8',\n",
       "   '210f5d3d988c',\n",
       "   '21108c163e1a',\n",
       "   '2124b73d7163',\n",
       "   '213e9b8de70a',\n",
       "   '2157841c88d8',\n",
       "   '21771ee845de',\n",
       "   '21874bddc42d',\n",
       "   '218762d90d7a',\n",
       "   '219a92e19a30',\n",
       "   '21b513401f0a',\n",
       "   '21d6252c887',\n",
       "   '21d924ff6453',\n",
       "   '21f9f6197983',\n",
       "   '21ff4c399ad9',\n",
       "   '2208dde97554',\n",
       "   '2216d6c50efa',\n",
       "   '223a3da3f614',\n",
       "   '22637714fe54',\n",
       "   '22778e9477fd',\n",
       "   '228cee543e0f',\n",
       "   '22a62e30e66e',\n",
       "   '22a68b261959',\n",
       "   '22b2924fa021',\n",
       "   '22d7be5ab2bd',\n",
       "   '22fa8e0706a2',\n",
       "   '22fdba8e9e1',\n",
       "   '230df01f2853',\n",
       "   '231a9bf8c453',\n",
       "   '231d4f5f82e6',\n",
       "   '2324e7a49e5',\n",
       "   '23334685ddce',\n",
       "   '23548908f7f5',\n",
       "   '235ae9e2e3be',\n",
       "   '23688dbd8e56',\n",
       "   '2370b0f1a60d',\n",
       "   '23746c14a4e7',\n",
       "   '238ff338127f',\n",
       "   '2392f42c8dab',\n",
       "   '2393def7ebea',\n",
       "   '23961a546c42',\n",
       "   '23cac33a4c88',\n",
       "   '23cb75defc59',\n",
       "   '23ce4fe15e50',\n",
       "   '23ced463eaa0',\n",
       "   '23e42a9af663',\n",
       "   '23e567b44ca7',\n",
       "   '23eb7ddba1bf',\n",
       "   '23efdf773dff',\n",
       "   '240e539d380e',\n",
       "   '24160b7aab71',\n",
       "   '241bb0e4df08',\n",
       "   '241bfa696b95',\n",
       "   '24354173364a',\n",
       "   '2445458ef93f',\n",
       "   '245b517aadf8',\n",
       "   '245f97293f28',\n",
       "   '2495a4d2261a',\n",
       "   '24b1fa2a34d5',\n",
       "   '24bcb168fc30',\n",
       "   '24cccd583027',\n",
       "   '24d0aeea2b01',\n",
       "   '24d14d229f4e',\n",
       "   '24dacfa0878',\n",
       "   '24f45a632f8d',\n",
       "   '2507d1c21b0d',\n",
       "   '252bbb8cd9c0',\n",
       "   '2540d463867b',\n",
       "   '2561a6f574fa',\n",
       "   '258f47eef673',\n",
       "   '25bb85753d8b',\n",
       "   '25bb9091da36',\n",
       "   '26102b16366a',\n",
       "   '261550026005',\n",
       "   '2620735eb873',\n",
       "   '26297cafbc53',\n",
       "   '264de57813c5',\n",
       "   '2656034f37fb',\n",
       "   '2669c26c6aa1',\n",
       "   '2687e60dd8a3',\n",
       "   '26a7c53cdfeb',\n",
       "   '26c3cac14244',\n",
       "   '26cf037a13b0',\n",
       "   '26d62d2c249',\n",
       "   '26ef26737319',\n",
       "   '275317555009',\n",
       "   '277bc1500111',\n",
       "   '277c23ecb259',\n",
       "   '2780594a54bf',\n",
       "   '2781dfd7fa70',\n",
       "   '27a51228359a',\n",
       "   '27b9aa40c013',\n",
       "   '27b9ebadeffd',\n",
       "   '27b9f821d695',\n",
       "   '27c236a2910f',\n",
       "   '27d8ce7f8baa',\n",
       "   '27e10cc9403e',\n",
       "   '27e9b2b0808a',\n",
       "   '27f12b743540',\n",
       "   '280a043623ff',\n",
       "   '2835c641e826',\n",
       "   '283b802971d6',\n",
       "   '2861e955555b',\n",
       "   '287159fdabd4',\n",
       "   '287ee954fcc4',\n",
       "   '28ab15d23c42',\n",
       "   '28b2e267298a',\n",
       "   '28b474b687d0',\n",
       "   '28d035ec04e5',\n",
       "   '28d8469606b3',\n",
       "   '28da4530d057',\n",
       "   '28ed826da52',\n",
       "   '290561de353c',\n",
       "   '290d92909854',\n",
       "   '29159032cca4',\n",
       "   '291ff1b40a6b',\n",
       "   '29330afc50de',\n",
       "   '2936448931b1',\n",
       "   '294fe5672f56',\n",
       "   '2975da578665',\n",
       "   '297697fd643a',\n",
       "   '297cd08ccd1e',\n",
       "   '298e0a9699ff',\n",
       "   '29924788dea8',\n",
       "   '29a4c36880f3',\n",
       "   '29a879548196',\n",
       "   '29a8f83c0536',\n",
       "   '29ae86a3d26e',\n",
       "   '29bdaafd07de',\n",
       "   '29cb69d1485d',\n",
       "   '29d60abfed79',\n",
       "   '29e2d870979b',\n",
       "   '29fd76167286',\n",
       "   '2a038b5d5072',\n",
       "   '2a06ef8cef4f',\n",
       "   '2a0d61ba5fae',\n",
       "   '2a2d239a3efc',\n",
       "   '2a3799322eb',\n",
       "   '2a3c51de57f1',\n",
       "   '2a5085a0f5cf',\n",
       "   '2a54c4fd75cc',\n",
       "   '2a82f6c52245',\n",
       "   '2a8dc74d8645',\n",
       "   '2a8ee28e3ec1',\n",
       "   '2aa56d490803',\n",
       "   '2aa797446d41',\n",
       "   '2abe0f9649db',\n",
       "   '2ae5ed6f5977',\n",
       "   '2ae6f0c761f2',\n",
       "   '2af153f271c8',\n",
       "   '2af1e1287cfe',\n",
       "   '2b06021c0c0c',\n",
       "   '2b1dda17e85a',\n",
       "   '2b4f6377b56c',\n",
       "   '2b520b55d919',\n",
       "   '2b80046465ce',\n",
       "   '2b98fdeca26f',\n",
       "   '2bb807302f43',\n",
       "   '2bcf7599cb3e',\n",
       "   '2be041200c84',\n",
       "   '2be546d98b11',\n",
       "   '2bf1b3831bbf',\n",
       "   '2bf7ee176f66',\n",
       "   '2c0633465534',\n",
       "   '2c0da07c5a7a',\n",
       "   '2c103d7c1ac1',\n",
       "   '2c22a3e01083',\n",
       "   '2c4bdb08857f',\n",
       "   '2c5d82c4cbd1',\n",
       "   '2cab26c4d394',\n",
       "   '2cabde17ee7f'],\n",
       "  'top_articles': [{'id': '0f27c5684804',\n",
       "    'title': 'Want to be Rich? DON’T Start a Side Hustle.',\n",
       "    'subtitle': 'Why Side Hustles Won’t Transform Your Life, But This Five-Step Formula Will',\n",
       "    'author': '8a910484fe84',\n",
       "    'publication_id': '*Self-Published*',\n",
       "    'published_at': '2023-12-03 22:29:33',\n",
       "    'last_modified_at': '2024-01-06 16:38:33',\n",
       "    'tags': ['side-hustle',\n",
       "     'business',\n",
       "     'entrepreneurship',\n",
       "     'make-money-online',\n",
       "     'marketing'],\n",
       "    'topics': ['startups'],\n",
       "    'claps': 244,\n",
       "    'voters': 30,\n",
       "    'word_count': 791,\n",
       "    'responses_count': 8,\n",
       "    'reading_time': 3.368238993710692,\n",
       "    'url': 'https://medium.com/@moneytent/want-to-be-rich-dont-start-a-side-hustle-0f27c5684804',\n",
       "    'unique_slug': 'want-to-be-rich-dont-start-a-side-hustle-0f27c5684804',\n",
       "    'image_url': 'https://miro.medium.com/1*th_mKOVG4094x6gq7xlF8w.png',\n",
       "    'lang': 'en',\n",
       "    'is_series': False,\n",
       "    'is_locked': False,\n",
       "    'is_shortform': False,\n",
       "    'top_highlight': \"You can't, not yet. Create the Minimum Viable Product (MVP), the simplest version of your solution.\"},\n",
       "   {'id': 'fe0a5a72bed5',\n",
       "    'title': 'The New AI Side Hustle That’s Making $1,579+/Day',\n",
       "    'subtitle': 'Unlocking a Goldmine: The Underrated AI Side Hustle',\n",
       "    'author': '8a910484fe84',\n",
       "    'publication_id': '*Self-Published*',\n",
       "    'published_at': '2024-02-02 22:01:42',\n",
       "    'last_modified_at': '2024-02-02 22:01:42',\n",
       "    'tags': ['ai',\n",
       "     'side-hustle',\n",
       "     'artificial-intelligence',\n",
       "     'make-money-online',\n",
       "     'machine-learning'],\n",
       "    'topics': ['artificial-intelligence', 'marketing'],\n",
       "    'claps': 13,\n",
       "    'voters': 5,\n",
       "    'word_count': 646,\n",
       "    'responses_count': 0,\n",
       "    'reading_time': 2.821069182389937,\n",
       "    'url': 'https://medium.com/@moneytent/the-new-ai-side-hustle-thats-making-1-579-day-fe0a5a72bed5',\n",
       "    'unique_slug': 'the-new-ai-side-hustle-thats-making-1-579-day-fe0a5a72bed5',\n",
       "    'image_url': 'https://miro.medium.com/1*CY891-DC6oRRgoZ0tA_Glw.png',\n",
       "    'lang': 'en',\n",
       "    'is_series': False,\n",
       "    'is_locked': False,\n",
       "    'is_shortform': False,\n",
       "    'top_highlight': ''},\n",
       "   {'id': '16e93bc3cb05',\n",
       "    'title': 'Top AI tools for UI Designers',\n",
       "    'subtitle': 'Leveraging AI in UI/UX Design: A Creative Revolution',\n",
       "    'author': '8a910484fe84',\n",
       "    'publication_id': '*Self-Published*',\n",
       "    'published_at': '2024-02-02 21:01:42',\n",
       "    'last_modified_at': '2024-02-02 21:01:42',\n",
       "    'tags': ['ui', 'ui-design', 'ai', 'artificial-intelligence', 'ai-tools'],\n",
       "    'topics': ['design'],\n",
       "    'claps': 6,\n",
       "    'voters': 1,\n",
       "    'word_count': 881,\n",
       "    'responses_count': 0,\n",
       "    'reading_time': 3.7078616352201257,\n",
       "    'url': 'https://medium.com/@moneytent/top-ai-tools-for-ui-designers-16e93bc3cb05',\n",
       "    'unique_slug': 'top-ai-tools-for-ui-designers-16e93bc3cb05',\n",
       "    'image_url': 'https://miro.medium.com/1*npLf3N72udSPw7mlAfi6Aw.png',\n",
       "    'lang': 'en',\n",
       "    'is_series': False,\n",
       "    'is_locked': False,\n",
       "    'is_shortform': False,\n",
       "    'top_highlight': ''},\n",
       "   {'id': '63eba8ec76a1',\n",
       "    'title': 'BEST AI Tools for Content Creators in 2024!',\n",
       "    'subtitle': 'Harnessing the Power of AI for Unparalleled Content Creation',\n",
       "    'author': '8a910484fe84',\n",
       "    'publication_id': '*Self-Published*',\n",
       "    'published_at': '2024-02-02 20:01:01',\n",
       "    'last_modified_at': '2024-02-02 20:01:01',\n",
       "    'tags': ['ai',\n",
       "     'content-creation',\n",
       "     'artificial-intelligence',\n",
       "     'youtube',\n",
       "     'machine-learning'],\n",
       "    'topics': ['artificial-intelligence'],\n",
       "    'claps': 26,\n",
       "    'voters': 4,\n",
       "    'word_count': 685,\n",
       "    'responses_count': 0,\n",
       "    'reading_time': 2.968238993710692,\n",
       "    'url': 'https://medium.com/@moneytent/best-ai-tools-for-content-creators-in-2024-63eba8ec76a1',\n",
       "    'unique_slug': 'best-ai-tools-for-content-creators-in-2024-63eba8ec76a1',\n",
       "    'image_url': 'https://miro.medium.com/1*t7NwUxee8giAMPWqdIFqJA.png',\n",
       "    'lang': 'en',\n",
       "    'is_series': False,\n",
       "    'is_locked': False,\n",
       "    'is_shortform': False,\n",
       "    'top_highlight': ''},\n",
       "   {'id': 'e1e04de813a0',\n",
       "    'title': 'How To Build a Website FAST Using AI',\n",
       "    'subtitle': 'Dive into the Future of Web Design\\u200a—\\u200aEffortless, Quick, and Tailored to Your Brand with AI',\n",
       "    'author': '8a910484fe84',\n",
       "    'publication_id': '*Self-Published*',\n",
       "    'published_at': '2024-02-02 19:01:40',\n",
       "    'last_modified_at': '2024-02-02 19:01:40',\n",
       "    'tags': ['website',\n",
       "     'ai',\n",
       "     'artificial-intelligence',\n",
       "     'machine-learning',\n",
       "     'no-code'],\n",
       "    'topics': ['marketing', 'design'],\n",
       "    'claps': 7,\n",
       "    'voters': 1,\n",
       "    'word_count': 794,\n",
       "    'responses_count': 0,\n",
       "    'reading_time': 3.3795597484276727,\n",
       "    'url': 'https://medium.com/@moneytent/how-to-build-a-website-fast-using-ai-e1e04de813a0',\n",
       "    'unique_slug': 'how-to-build-a-website-fast-using-ai-e1e04de813a0',\n",
       "    'image_url': 'https://miro.medium.com/1*6k1FnAPWYG52bRsZOGIhYA.png',\n",
       "    'lang': 'en',\n",
       "    'is_series': False,\n",
       "    'is_locked': False,\n",
       "    'is_shortform': False,\n",
       "    'top_highlight': ''},\n",
       "   {'id': 'c6a008a4fb67',\n",
       "    'title': 'Making AI Mobile App Using One Tool For FREE!',\n",
       "    'subtitle': 'Embracing the No-Code Revolution: Crafting Digital Dreams Without Coding',\n",
       "    'author': '8a910484fe84',\n",
       "    'publication_id': '*Self-Published*',\n",
       "    'published_at': '2024-02-02 18:01:53',\n",
       "    'last_modified_at': '2024-02-02 18:01:53',\n",
       "    'tags': ['ai',\n",
       "     'apps',\n",
       "     'artificial-intelligence',\n",
       "     'ai-tools',\n",
       "     'mobile-app-development'],\n",
       "    'topics': ['artificial-intelligence'],\n",
       "    'claps': 9,\n",
       "    'voters': 2,\n",
       "    'word_count': 807,\n",
       "    'responses_count': 0,\n",
       "    'reading_time': 3.428616352201258,\n",
       "    'url': 'https://medium.com/@moneytent/making-ai-mobile-app-using-one-tool-for-free-c6a008a4fb67',\n",
       "    'unique_slug': 'making-ai-mobile-app-using-one-tool-for-free-c6a008a4fb67',\n",
       "    'image_url': 'https://miro.medium.com/1*VvGvvUL8RVPPMV-DextZ_w.png',\n",
       "    'lang': 'en',\n",
       "    'is_series': False,\n",
       "    'is_locked': False,\n",
       "    'is_shortform': False,\n",
       "    'top_highlight': ''},\n",
       "   {'id': '914c14819bcf',\n",
       "    'title': 'This Free ChatGPT SEO Script Is Worth Millions',\n",
       "    'subtitle': 'Transforming a YouTube Script into a Captivating Medium Article',\n",
       "    'author': '8a910484fe84',\n",
       "    'publication_id': '*Self-Published*',\n",
       "    'published_at': '2024-02-02 17:02:00',\n",
       "    'last_modified_at': '2024-02-02 17:02:00',\n",
       "    'tags': ['chatgpt', 'seo', 'ai', 'artificial-intelligence', 'script'],\n",
       "    'topics': ['programming'],\n",
       "    'claps': 2,\n",
       "    'voters': 2,\n",
       "    'word_count': 744,\n",
       "    'responses_count': 0,\n",
       "    'reading_time': 3.190880503144654,\n",
       "    'url': 'https://medium.com/@moneytent/this-free-chatgpt-seo-script-is-worth-millions-914c14819bcf',\n",
       "    'unique_slug': 'this-free-chatgpt-seo-script-is-worth-millions-914c14819bcf',\n",
       "    'image_url': 'https://miro.medium.com/1*S9B7W4HAhxAdazIrjnY0Kg.png',\n",
       "    'lang': 'en',\n",
       "    'is_series': False,\n",
       "    'is_locked': False,\n",
       "    'is_shortform': False,\n",
       "    'top_highlight': ''},\n",
       "   {'id': 'f004bd43e60b',\n",
       "    'title': 'Copy My $400/Day Affiliate Marketing Strategy',\n",
       "    'subtitle': 'Unveiling the Secrets to Successful Affiliate Marketing\\u200a—\\u200aA Journey from Trials to Triumph',\n",
       "    'author': '8a910484fe84',\n",
       "    'publication_id': '*Self-Published*',\n",
       "    'published_at': '2024-02-02 16:01:42',\n",
       "    'last_modified_at': '2024-02-02 16:01:42',\n",
       "    'tags': ['affiliate-marketing',\n",
       "     'make-money-online',\n",
       "     'marketing',\n",
       "     'passive-income',\n",
       "     'side-hustle'],\n",
       "    'topics': ['marketing'],\n",
       "    'claps': 71,\n",
       "    'voters': 5,\n",
       "    'word_count': 630,\n",
       "    'responses_count': 1,\n",
       "    'reading_time': 2.760691823899371,\n",
       "    'url': 'https://medium.com/@moneytent/copy-my-400-day-affiliate-marketing-strategy-f004bd43e60b',\n",
       "    'unique_slug': 'copy-my-400-day-affiliate-marketing-strategy-f004bd43e60b',\n",
       "    'image_url': 'https://miro.medium.com/1*uyYHVDRN_ShVQLttoJQrmQ.png',\n",
       "    'lang': 'en',\n",
       "    'is_series': False,\n",
       "    'is_locked': False,\n",
       "    'is_shortform': False,\n",
       "    'top_highlight': ''},\n",
       "   {'id': '262c355fdff1',\n",
       "    'title': '15 AI Tools That Will Make You Rich in 2024\\u200a—\\u200aGame Changer AI Tools in 2024!',\n",
       "    'subtitle': '15 Game-Changing AI Tools to Watch in 2024',\n",
       "    'author': '8a910484fe84',\n",
       "    'publication_id': '*Self-Published*',\n",
       "    'published_at': '2024-02-02 15:01:50',\n",
       "    'last_modified_at': '2024-02-02 15:01:50',\n",
       "    'tags': ['ai',\n",
       "     'ai-tools',\n",
       "     'artificial-intelligence',\n",
       "     'make-money-online',\n",
       "     'rich'],\n",
       "    'topics': ['artificial-intelligence'],\n",
       "    'claps': 56,\n",
       "    'voters': 7,\n",
       "    'word_count': 1184,\n",
       "    'responses_count': 0,\n",
       "    'reading_time': 4.85125786163522,\n",
       "    'url': 'https://medium.com/@moneytent/15-ai-tools-that-will-make-you-rich-in-2024-game-changer-ai-tools-in-2024-262c355fdff1',\n",
       "    'unique_slug': '15-ai-tools-that-will-make-you-rich-in-2024-game-changer-ai-tools-in-2024-262c355fdff1',\n",
       "    'image_url': 'https://miro.medium.com/1*7pH8oVdb0fyfQF7kOxU7Ew.png',\n",
       "    'lang': 'en',\n",
       "    'is_series': False,\n",
       "    'is_locked': False,\n",
       "    'is_shortform': False,\n",
       "    'top_highlight': ''},\n",
       "   {'id': 'c27c2166efec',\n",
       "    'title': 'Building a Video Content Agency with AI (in 2024)',\n",
       "    'subtitle': 'How AI Can Revolutionize Content Creation for Your Business',\n",
       "    'author': '8a910484fe84',\n",
       "    'publication_id': '*Self-Published*',\n",
       "    'published_at': '2024-02-02 14:01:43',\n",
       "    'last_modified_at': '2024-02-02 14:01:43',\n",
       "    'tags': ['content-creation',\n",
       "     'ai',\n",
       "     'artificial-intelligence',\n",
       "     'video-marketing',\n",
       "     'ai-tools'],\n",
       "    'topics': ['artificial-intelligence', 'marketing'],\n",
       "    'claps': 2,\n",
       "    'voters': 2,\n",
       "    'word_count': 716,\n",
       "    'responses_count': 0,\n",
       "    'reading_time': 3.0852201257861633,\n",
       "    'url': 'https://medium.com/@moneytent/building-a-video-content-agency-with-ai-in-2024-c27c2166efec',\n",
       "    'unique_slug': 'building-a-video-content-agency-with-ai-in-2024-c27c2166efec',\n",
       "    'image_url': 'https://miro.medium.com/1*3DFy3Mv7EVTxdikDGXLgcQ.png',\n",
       "    'lang': 'en',\n",
       "    'is_series': False,\n",
       "    'is_locked': False,\n",
       "    'is_shortform': False,\n",
       "    'top_highlight': ''}]},\n",
       " '4beacba7dc8a': {'id': '4beacba7dc8a',\n",
       "  'username': 'jordan_gibbs',\n",
       "  'fullname': 'Jordan Gibbs',\n",
       "  'bio': 'AI developer and CTO @ Elevora.ai. Striving to empower the job seeker. https://www.linkedin.com/in/jordan--gibbs',\n",
       "  'followers_count': 2825,\n",
       "  'following_count': 21,\n",
       "  'publication_following_count': 0,\n",
       "  'image_url': 'https://miro.medium.com/1*A1IH-oySSaC8eRBAxDhWxQ.jpeg',\n",
       "  'twitter_username': '',\n",
       "  'is_writer_program_enrolled': True,\n",
       "  'allow_notes': True,\n",
       "  'medium_member_at': '2023-10-02 15:30:40',\n",
       "  'is_suspended': False,\n",
       "  'top_writer_in': ['artificial-intelligence'],\n",
       "  'has_list': True,\n",
       "  'is_book_author': False,\n",
       "  'tipping_link': None,\n",
       "  'bg_image_url': '',\n",
       "  'logo_image_url': '',\n",
       "  'followers': ['0019523196a0',\n",
       "   '00245ad345da',\n",
       "   '00b8eada8b79',\n",
       "   '00de22ec4707',\n",
       "   '00ee7b0dad26',\n",
       "   '00fc9159087d',\n",
       "   '012072ebf80c',\n",
       "   '0132e668bef5',\n",
       "   '023b7e632975',\n",
       "   '025441c4cf72',\n",
       "   '027c98ccc223',\n",
       "   '029482385112',\n",
       "   '02ab3f8c2463',\n",
       "   '02e055ad3d54',\n",
       "   '02f9493e4478',\n",
       "   '0304608d6585',\n",
       "   '032c92283903',\n",
       "   '0334334523f2',\n",
       "   '038dbc9a4dc8',\n",
       "   '03af4c0aa53f',\n",
       "   '03bff1292d9c',\n",
       "   '03d778a58360',\n",
       "   '03f381560951',\n",
       "   '03f9d334c243',\n",
       "   '0424cd3b13bb',\n",
       "   '04468e827406',\n",
       "   '0477a75bb9f4',\n",
       "   '047dbce543a9',\n",
       "   '04ca33ca0707',\n",
       "   '04f3cbce8589',\n",
       "   '056d17f08df8',\n",
       "   '05d9a8ffa098',\n",
       "   '05eab01a40a6',\n",
       "   '05f3e0bcb25a',\n",
       "   '068120eb5c86',\n",
       "   '06ed2b97276f',\n",
       "   '06f27e3e4b56',\n",
       "   '073e714db1fc',\n",
       "   '07e34a659436',\n",
       "   '07e7bf250bb5',\n",
       "   '083e7638f614',\n",
       "   '0843bb5b758f',\n",
       "   '0859720c1d98',\n",
       "   '088f29eca1f7',\n",
       "   '08b19ca94ec0',\n",
       "   '08dba4ed509c',\n",
       "   '09083880f3c8',\n",
       "   '093df78709d8',\n",
       "   '096cf59672b7',\n",
       "   '09b670e3fd83',\n",
       "   '09d4327a6fad',\n",
       "   '0a154975b575',\n",
       "   '0a90a192a60b',\n",
       "   '0b143c059d96',\n",
       "   '0b1f054d198f',\n",
       "   '0b561f262df9',\n",
       "   '0b5bf4e33e99',\n",
       "   '0b704bbf7425',\n",
       "   '0b8df69c12a1',\n",
       "   '0b96f6886a09',\n",
       "   '0bb85f2a0b3b',\n",
       "   '0bd0612d2173',\n",
       "   '0c3928cdbcb5',\n",
       "   '0c602f4e893a',\n",
       "   '0c6f1ce98e82',\n",
       "   '0d11d07c746e',\n",
       "   '0d987c64f15c',\n",
       "   '0e44dcf60b26',\n",
       "   '0e5faf098978',\n",
       "   '0e61305155f2',\n",
       "   '0e7f1d070feb',\n",
       "   '0e809eb771c1',\n",
       "   '0eaa2d1f652f',\n",
       "   '0efade735fc9',\n",
       "   '0f07cdf46e5a',\n",
       "   '100d11cc17cf',\n",
       "   '10217378f8ae',\n",
       "   '10497a096abc',\n",
       "   '1099a8e09893',\n",
       "   '10da79f4f3c5',\n",
       "   '10ed7cb7442e',\n",
       "   '10fb881b36b',\n",
       "   '110603087767',\n",
       "   '112dc99800bf',\n",
       "   '1135ea13d766',\n",
       "   '113a659a0eba',\n",
       "   '113ee8fc4182',\n",
       "   '11411721d3ac',\n",
       "   '116cd92b18bd',\n",
       "   '117614d7351b',\n",
       "   '118a538985c1',\n",
       "   '118e49d35c1c',\n",
       "   '119948be9f9a',\n",
       "   '11a7447d5cbe',\n",
       "   '11ad0b5c25e0',\n",
       "   '11b11f39b8fb',\n",
       "   '11b356630b85',\n",
       "   '11b4f7d8260f',\n",
       "   '11b8283c51b',\n",
       "   '12073752a37e',\n",
       "   '120dd6eb5582',\n",
       "   '1223d38d6bcd',\n",
       "   '1227a718f42',\n",
       "   '12386b812ae2',\n",
       "   '123c1bb2707b',\n",
       "   '124e90ab5427',\n",
       "   '1250ae99666',\n",
       "   '1266a9912319',\n",
       "   '1267a9c507fc',\n",
       "   '126c736782b2',\n",
       "   '12892a109be6',\n",
       "   '128c16c49be2',\n",
       "   '128c77608712',\n",
       "   '128d7bca8a0e',\n",
       "   '12930cbf4f5a',\n",
       "   '12935397bcf1',\n",
       "   '12b637b0185c',\n",
       "   '12b74d19ca7b',\n",
       "   '12d2234e9c2f',\n",
       "   '130952f7b11a',\n",
       "   '1332ed212be8',\n",
       "   '1347c65edbaf',\n",
       "   '1351a1511ae5',\n",
       "   '13607428292d',\n",
       "   '1392b61a5faa',\n",
       "   '13b47e22b97d',\n",
       "   '13bed9618c1a',\n",
       "   '13c11e44e895',\n",
       "   '142438a52753',\n",
       "   '14291a05946f',\n",
       "   '143a8702d1c1',\n",
       "   '14506e1536ee',\n",
       "   '145504c6595b',\n",
       "   '146617e4a70d',\n",
       "   '148ae689f366',\n",
       "   '149f126bf619',\n",
       "   '14ae73fc7ed2',\n",
       "   '14d767c71e5b',\n",
       "   '14d8d59ae35c',\n",
       "   '14f32acf3397',\n",
       "   '14f8f5fdd30a',\n",
       "   '151a51e05277',\n",
       "   '15344080a6b0',\n",
       "   '1553f04b3e98',\n",
       "   '15a6ca4c955e',\n",
       "   '15a89e9098d9',\n",
       "   '15af1dafee50',\n",
       "   '15b99082f5dc',\n",
       "   '15bcb5d7f95f',\n",
       "   '15fc70f30b89',\n",
       "   '16431623f2c8',\n",
       "   '165c408ed9b',\n",
       "   '168e830183f5',\n",
       "   '168f8fc4a832',\n",
       "   '169f538dfde3',\n",
       "   '16a37a532f76',\n",
       "   '16b803f25ef0',\n",
       "   '17036a19900a',\n",
       "   '1714de088cbe',\n",
       "   '171c99df6d78',\n",
       "   '17412cb3b899',\n",
       "   '175bca526e05',\n",
       "   '175c599d4056',\n",
       "   '179087195b25',\n",
       "   '17ad088d7611',\n",
       "   '17c56d2a9093',\n",
       "   '17de20885fbe',\n",
       "   '18032e6a3754',\n",
       "   '1803805c77b2',\n",
       "   '182dda462ef2',\n",
       "   '184e5f4aa328',\n",
       "   '186e4b3f42b8',\n",
       "   '1880328b8932',\n",
       "   '188425237594',\n",
       "   '18b5fd193c7d',\n",
       "   '1900c139749b',\n",
       "   '19028595a0f4',\n",
       "   '1909af4381f4',\n",
       "   '195e415b6ec6',\n",
       "   '19626edc2919',\n",
       "   '196a5be50cfc',\n",
       "   '1973ac8cbb13',\n",
       "   '197c4c07bc5f',\n",
       "   '197e8422e0fc',\n",
       "   '1999b7bfe0a4',\n",
       "   '19cad4233712',\n",
       "   '19dc2ab82780',\n",
       "   '19dd0c8d4ef2',\n",
       "   '1a02447fe0ee',\n",
       "   '1a0768416919',\n",
       "   '1a0960a5e5d8',\n",
       "   '1a0b9d57826f',\n",
       "   '1a2a250c3361',\n",
       "   '1a2b1d62179d',\n",
       "   '1a3b96579e7c',\n",
       "   '1a3f36030083',\n",
       "   '1a45027479b1',\n",
       "   '1a4d09ccc198',\n",
       "   '1a873ac1c89c',\n",
       "   '1a924cd3fea4',\n",
       "   '1a92ee6e82e1',\n",
       "   '1a94a3ae79ed',\n",
       "   '1abbd0905117',\n",
       "   '1ac51e917ea4',\n",
       "   '1ace9011274e',\n",
       "   '1ad4a0a657b8',\n",
       "   '1afebc9a1fae',\n",
       "   '1b12b005afd5',\n",
       "   '1b2706d8257e',\n",
       "   '1b33aa167d41',\n",
       "   '1b4ea5309e73',\n",
       "   '1b50da98b884',\n",
       "   '1b5227650e8b',\n",
       "   '1b5f737463b0',\n",
       "   '1b6a361ddc4e',\n",
       "   '1b95cd9b902',\n",
       "   '1bb57aaf4a7a',\n",
       "   '1bf38e2d99c8',\n",
       "   '1c2ff0f33206',\n",
       "   '1c4474380e78',\n",
       "   '1c4f009c7dd9',\n",
       "   '1c5837b7652',\n",
       "   '1c6ae2507d79',\n",
       "   '1c80cc183550',\n",
       "   '1c8561903f2f',\n",
       "   '1ca1e322ae1c',\n",
       "   '1ccf8cfb8a57',\n",
       "   '1d21b18fec36',\n",
       "   '1d23d5874e8c',\n",
       "   '1d26aaf6bfe0',\n",
       "   '1d28b4c45cd0',\n",
       "   '1d626849f27c',\n",
       "   '1d6ba7822aee',\n",
       "   '1d78fe3c36e0',\n",
       "   '1d7bad55a943',\n",
       "   '1d9794c49ecc',\n",
       "   '1da3bb548a4a',\n",
       "   '1e0d597d0c2f',\n",
       "   '1e100285f678',\n",
       "   '1e24877c01d2',\n",
       "   '1e2a7205fa74',\n",
       "   '1e2ea32699c9',\n",
       "   '1e2eb5aebe32',\n",
       "   '1e622422882a',\n",
       "   '1e6ee27d98d7',\n",
       "   '1ea6c7d72eda',\n",
       "   '1ec99afcc84d',\n",
       "   '1ed2d05ac66e',\n",
       "   '1ed4b895b7ee',\n",
       "   '1f05ccb65fec',\n",
       "   '1f186d8be645',\n",
       "   '1f3f61ba3560',\n",
       "   '1f41562dade4',\n",
       "   '1f4b4746b5f4',\n",
       "   '1f51efdfd7ce',\n",
       "   '1f616989b52c',\n",
       "   '1fdb912de1d8',\n",
       "   '1ff89eefeb1a',\n",
       "   '2035327154b0',\n",
       "   '204856eba095',\n",
       "   '205f8c5f85a5',\n",
       "   '20605f70a1d2',\n",
       "   '20a5e1c6d23c',\n",
       "   '20aa3b119b59',\n",
       "   '20bdf8cec61c',\n",
       "   '20dee3a5f3f7',\n",
       "   '20e86feef109',\n",
       "   '20ebea967cca',\n",
       "   '20f301d29766',\n",
       "   '20fde2e682fe',\n",
       "   '210eba8a78f2',\n",
       "   '2117e388789f',\n",
       "   '215508e0aa50',\n",
       "   '2168e574e196',\n",
       "   '2189aae8a40e',\n",
       "   '219f49e1db53',\n",
       "   '21aea62a4573',\n",
       "   '21ba63296bba',\n",
       "   '21c22f952514',\n",
       "   '21d605c307b4',\n",
       "   '21ff8d1516ac',\n",
       "   '220ec6cfadf8',\n",
       "   '22148684093f',\n",
       "   '2218dc71372f',\n",
       "   '2266f5c359ba',\n",
       "   '22b91061d924',\n",
       "   '22dd2a7deedf',\n",
       "   '22e1e7a4e653',\n",
       "   '22ea52cfbdb3',\n",
       "   '22eee72b5e5c',\n",
       "   '23437d204440',\n",
       "   '2371bff33f91',\n",
       "   '2382732d7a',\n",
       "   '238ff338127f',\n",
       "   '2391a1861327',\n",
       "   '23d2d6f1eb4f',\n",
       "   '23d6ebf7a5ed',\n",
       "   '23f918f56990',\n",
       "   '24007e874111',\n",
       "   '241233b17c65',\n",
       "   '2421dae9756',\n",
       "   '242a31cf95e0',\n",
       "   '244f5948a1d6',\n",
       "   '245f97293f28',\n",
       "   '248ad5fb5360',\n",
       "   '24e29a7f751',\n",
       "   '24eab832f59b',\n",
       "   '24ec72f762e1',\n",
       "   '25055b7e934d',\n",
       "   '250f87bea626',\n",
       "   '251918c705b6',\n",
       "   '251c0b712309',\n",
       "   '251cd43544d8',\n",
       "   '256aaa59769e',\n",
       "   '256dda648e88',\n",
       "   '2574477c96c5',\n",
       "   '25887dc3b187',\n",
       "   '25a5693fd164',\n",
       "   '25af0712a495',\n",
       "   '25db2ab70539',\n",
       "   '260116fba67f',\n",
       "   '261e9f86a5e0',\n",
       "   '26444899face',\n",
       "   '264f50efc5d6',\n",
       "   '2689c3c2bcfa',\n",
       "   '26adf8cb2786',\n",
       "   '26bcdf2754cd',\n",
       "   '26c134bd8b2c',\n",
       "   '26e0b9679003',\n",
       "   '26f9a188611a',\n",
       "   '2706a691f110',\n",
       "   '2719cf2a14a6',\n",
       "   '271acacbe4e4',\n",
       "   '275317555009',\n",
       "   '27578260ba1d',\n",
       "   '2776547d45ca',\n",
       "   '27a640854747',\n",
       "   '27b0392ed36a',\n",
       "   '27b4b96e898e',\n",
       "   '27b9f821d695',\n",
       "   '27ca38566333',\n",
       "   '27f3a60cce6f',\n",
       "   '28066ace2215',\n",
       "   '280a043623ff',\n",
       "   '2815101c57c0',\n",
       "   '2835c641e826',\n",
       "   '283f8453fa03',\n",
       "   '288a753dcc24',\n",
       "   '288fd3500ff5',\n",
       "   '289d72cfcda1',\n",
       "   '28a455009bc1',\n",
       "   '28b5b78daf87',\n",
       "   '28c6957d75bf',\n",
       "   '28ec2b4b1a30',\n",
       "   '28fdde3d622',\n",
       "   '290bdaf3a69f',\n",
       "   '290ef877fc44',\n",
       "   '2916cb3fd236',\n",
       "   '292685635b56',\n",
       "   '29464ca504e6',\n",
       "   '29488730c6c4',\n",
       "   '295c8fee6522',\n",
       "   '296513a4afca',\n",
       "   '298e0a9699ff',\n",
       "   '29924788dea8',\n",
       "   '2995e520f606',\n",
       "   '299a399693a7',\n",
       "   '299f8cae0427',\n",
       "   '29d19b1643ad',\n",
       "   '29da85bf65db',\n",
       "   '29dc98ad2faf',\n",
       "   '29ebaaf19858',\n",
       "   '2a17ece7f7e5',\n",
       "   '2a29f144794d',\n",
       "   '2a40df912a0f',\n",
       "   '2a45fc147f6',\n",
       "   '2a4ef8434b04',\n",
       "   '2a6a5aa51240',\n",
       "   '2a77d7088ced',\n",
       "   '2a980aa7b2ee',\n",
       "   '2a9ec7546ef6',\n",
       "   '2aa7ec94c6e2',\n",
       "   '2ab362665240',\n",
       "   '2ac90f5ff962',\n",
       "   '2ad04739dff8',\n",
       "   '2afc45efcded',\n",
       "   '2b6897ccb2c5',\n",
       "   '2b7562b0c897',\n",
       "   '2b82e19db3be',\n",
       "   '2ba3fd2d4877',\n",
       "   '2bc081bc50fd',\n",
       "   '2c0961f12de7',\n",
       "   '2c0b70485dfa',\n",
       "   '2c10949e19d5',\n",
       "   '2c34a2a8f361',\n",
       "   '2c3ed7d9a734',\n",
       "   '2c6165afc21a',\n",
       "   '2c79753a968',\n",
       "   '2c857a6457b0',\n",
       "   '2ca23410be38',\n",
       "   '2ca55aa8be95',\n",
       "   '2cb771d80c7b',\n",
       "   '2d021fbf3116',\n",
       "   '2d0b2dd3df41',\n",
       "   '2d1de22d631',\n",
       "   '2d242fe5eb7e',\n",
       "   '2d6d5e1ed023',\n",
       "   '2d7c9e3833f8',\n",
       "   '2da57975650b',\n",
       "   '2df1e1151222',\n",
       "   '2df3e6bf40b9',\n",
       "   '2e1ea84ac2f3',\n",
       "   '2e2c77256d87',\n",
       "   '2e2d58950dd',\n",
       "   '2e469336a28f',\n",
       "   '2e70f0e0f29f',\n",
       "   '2e86eb8de2e4',\n",
       "   '2ea31ac04479',\n",
       "   '2efa15a1a981',\n",
       "   '2f12a7592bf7',\n",
       "   '2f2256a62645',\n",
       "   '2f2f63046c95',\n",
       "   '2f41a5a11fab',\n",
       "   '2f4b8cba08d1',\n",
       "   '2f6e0afd9b17',\n",
       "   '2f6f35f782cc',\n",
       "   '2f730c010fd1',\n",
       "   '2fb99ac3fb59',\n",
       "   '2fbe0751fb',\n",
       "   '2fe98203db7e',\n",
       "   '3013d842bee7',\n",
       "   '3024a5283047',\n",
       "   '302ff6bec193',\n",
       "   '303ddf752d5b',\n",
       "   '304a5f78d079',\n",
       "   '304c4ee1dd7a',\n",
       "   '305765aaa6d4',\n",
       "   '306f1a7f82a9',\n",
       "   '30bf0507dfa8',\n",
       "   '30ccdebd25f',\n",
       "   '30dec37415ef',\n",
       "   '310df235913f',\n",
       "   '311ef44807a0',\n",
       "   '312f5b35f512',\n",
       "   '31318ba55b5f',\n",
       "   '31403ebc6248',\n",
       "   '314e797a1af7',\n",
       "   '316a68b4bdf8',\n",
       "   '31b52c1a52f4',\n",
       "   '31ba03ef95bd',\n",
       "   '31bd1214dbd0',\n",
       "   '31e6df7c31c4',\n",
       "   '31e908a5686',\n",
       "   '31f5c49af3d4',\n",
       "   '3205053e08ff',\n",
       "   '321008c3d8da',\n",
       "   '324dcd1aad7e',\n",
       "   '327b842d037e',\n",
       "   '327fba308cb4',\n",
       "   '32943baf3bbf',\n",
       "   '32a00a248a90',\n",
       "   '32c9a5daf94',\n",
       "   '32ca42167989',\n",
       "   '33061f563fd9',\n",
       "   '3315dd32b2e5',\n",
       "   '331ceaf45165',\n",
       "   '33254af0289f',\n",
       "   '333c92d49ec5',\n",
       "   '334e778558cc',\n",
       "   '33536e8490ac',\n",
       "   '336721e8fcc1',\n",
       "   '33794cc05bad',\n",
       "   '339f38ed8f5',\n",
       "   '33ba827228c0',\n",
       "   '33e9a300d284',\n",
       "   '33f751feab36',\n",
       "   '33fee2e288bc',\n",
       "   '34002baad336',\n",
       "   '3446bd7a71a5',\n",
       "   '34488aa31c2f',\n",
       "   '34536064487c',\n",
       "   '3474df17a10a',\n",
       "   '3476cf414edb',\n",
       "   '347c439364f4',\n",
       "   '349065bb72e6',\n",
       "   '34a7b39fbfa7',\n",
       "   '34ad7ae37017',\n",
       "   '34b1b1795d08',\n",
       "   '350f190db46c',\n",
       "   '351be4cfb8d7',\n",
       "   '352d588eb51d',\n",
       "   '3546699af944',\n",
       "   '354ed468e63b',\n",
       "   '357f5eae7cf6'],\n",
       "  'top_articles': [{'id': '6ad21c4cfa99',\n",
       "    'title': 'Forget Prompt Engineering, ChatGPT Can Write Perfect Prompts for You',\n",
       "    'subtitle': 'I enabled ChatGPT to write optimal, research-based prompts so anyone can be an expert prompt engineer.',\n",
       "    'author': '4beacba7dc8a',\n",
       "    'publication_id': '*Self-Published*',\n",
       "    'published_at': '2024-01-13 20:28:42',\n",
       "    'last_modified_at': '2024-01-13 20:28:42',\n",
       "    'tags': ['chatgpt',\n",
       "     'artificial-intelligence',\n",
       "     'ai',\n",
       "     'prompt-engineering',\n",
       "     'openai'],\n",
       "    'topics': ['programming'],\n",
       "    'claps': 2425,\n",
       "    'voters': 436,\n",
       "    'word_count': 1432,\n",
       "    'responses_count': 28,\n",
       "    'reading_time': 6.10377358490566,\n",
       "    'url': 'https://medium.com/@jordan_gibbs/forget-prompt-engineering-chatgpt-can-write-perfect-prompts-for-you-6ad21c4cfa99',\n",
       "    'unique_slug': 'forget-prompt-engineering-chatgpt-can-write-perfect-prompts-for-you-6ad21c4cfa99',\n",
       "    'image_url': 'https://miro.medium.com/1*heKVq8v-TzkRBbrNuYsAMw.png',\n",
       "    'lang': 'en',\n",
       "    'is_series': False,\n",
       "    'is_locked': True,\n",
       "    'is_shortform': False,\n",
       "    'top_highlight': '1. Always use the COSTAR prompt framework:\\nContext (C): Provide essential background information or setting for the task. This helps the LLM understand the specific scenario or domain it is dealing with, leading to more relevant responses.\\nObjective (O): Clearly articulate the goal or purpose of the prompt. Specify what you want the LLM to accomplish, ensuring that its focus remains on achieving this particular aim.\\nStyle (S): Define the desired style of the response. This could range from imitating the writing style of a specific profession, like a scientist or journalist, to emulating the narrative tone of certain genres, such as formal reports or creative fiction.\\nTone (T): Determine the emotional or attitudinal coloring of the response. Whether it\\'s formal, casual, enthusiastic, or empathetic, setting the tone ensures the LLM\\'s response aligns with the intended sentiment.\\nAudience (A): Identify the target audience for whom the response is intended. Tailoring the content and complexity of the LLM\\'s response to suit the audience, such as experts, beginners, or a general readership, ensures better comprehension and engagement.\\nResponse Format (R): Specify the format in which you want the response. This could be a list, a structured report, a JSON object, a narrative, etc. Defining the format helps in generating responses that are suitable for your subsequent use, whether it be for analysis, presentation, or further processing.\\n2. Break down complex tasks into a sequence of simpler prompts in an interactive conversation. \\n3. Employ affirmative directives such as `do,\\' while steering clear of negative language like \\'don\\'t\\'. \\n4. Implement example-driven prompting (Use few-shot prompting). \\n5. Use following phrases: \"Your task is\" and \"You MUST\". \\n6. Always use leading words like writing \"think step by step\". \\n7. Assign a role to the model i.e. \"you are an expert ___\"\\n8. Repeat specific words or phrases multiple times within a prompt. \\n9. Try to induce Chain-of-thought (CoT) when possible, guiding the LLM to do dive in deeper to each step\\n10. Use output primers, which involve concluding your prompt with the beginning of the desired output. Utilize output primers by ending your prompt with the start of the anticipated response. \\n11. To write an essay /text /paragraph /article or any type of text that should be detailed: \"Write an ultra-detailed [essay/text /paragraph] for me on [topic] in detail by adding all the information necessary\".'},\n",
       "   {'id': '8088ec559681',\n",
       "    'title': 'How to *Not* Use ChatGPT',\n",
       "    'subtitle': 'Every single thing you absolutely shouldn’t use ChatGPT for (there’s a lot)',\n",
       "    'author': '4beacba7dc8a',\n",
       "    'publication_id': '*Self-Published*',\n",
       "    'published_at': '2024-01-20 22:58:19',\n",
       "    'last_modified_at': '2024-01-20 22:58:19',\n",
       "    'tags': ['chatgpt',\n",
       "     'artificial-intelligence',\n",
       "     'ai',\n",
       "     'technology',\n",
       "     'writing'],\n",
       "    'topics': ['design', 'programming'],\n",
       "    'claps': 663,\n",
       "    'voters': 94,\n",
       "    'word_count': 2760,\n",
       "    'responses_count': 11,\n",
       "    'reading_time': 12.01509433962264,\n",
       "    'url': 'https://medium.com/@jordan_gibbs/how-to-not-use-chatgpt-8088ec559681',\n",
       "    'unique_slug': 'how-to-not-use-chatgpt-8088ec559681',\n",
       "    'image_url': 'https://miro.medium.com/1*h5-lcbnZhj8qhodrkFjGkw.png',\n",
       "    'lang': 'en',\n",
       "    'is_series': False,\n",
       "    'is_locked': True,\n",
       "    'is_shortform': False,\n",
       "    'top_highlight': ''},\n",
       "   {'id': '0991c54be605',\n",
       "    'title': 'How to Prompt ChatGPT to Teach You Anything',\n",
       "    'subtitle': 'I created a prompt chain that enables you to learn any complex concept from ChatGPT.',\n",
       "    'author': '4beacba7dc8a',\n",
       "    'publication_id': '*Self-Published*',\n",
       "    'published_at': '2023-11-25 04:09:32',\n",
       "    'last_modified_at': '2023-11-25 04:09:32',\n",
       "    'tags': ['artificial-intelligence',\n",
       "     'chatgpt',\n",
       "     'learning',\n",
       "     'reading',\n",
       "     'science'],\n",
       "    'topics': ['artificial-intelligence', 'programming'],\n",
       "    'claps': 1332,\n",
       "    'voters': 294,\n",
       "    'word_count': 913,\n",
       "    'responses_count': 21,\n",
       "    'reading_time': 4.645283018867924,\n",
       "    'url': 'https://medium.com/@jordan_gibbs/how-to-prompt-chatgpt-to-teach-you-anything-0991c54be605',\n",
       "    'unique_slug': 'how-to-prompt-chatgpt-to-teach-you-anything-0991c54be605',\n",
       "    'image_url': 'https://miro.medium.com/1*D5I02-bjuJur5wMWk2Z6ig.png',\n",
       "    'lang': 'en',\n",
       "    'is_series': False,\n",
       "    'is_locked': True,\n",
       "    'is_shortform': False,\n",
       "    'top_highlight': 'Provide an executive summary of this link [or attatched document]. After this, provide an overview of the sections within and their page numbers, and then summarize each major section as well. Always cite your sources.'},\n",
       "   {'id': '55ef2bdc4d4a',\n",
       "    'title': 'The Most Important ChatGPT Prompt',\n",
       "    'subtitle': 'I‘ve read dozens of articles about “the best ChatGPT prompts,” but I’ve never seen the most effective one…',\n",
       "    'author': '4beacba7dc8a',\n",
       "    'publication_id': '*Self-Published*',\n",
       "    'published_at': '2023-12-18 17:26:16',\n",
       "    'last_modified_at': '2023-12-18 17:26:16',\n",
       "    'tags': ['chatgpt',\n",
       "     'openai',\n",
       "     'ai',\n",
       "     'artificial-intelligence',\n",
       "     'prompt-engineering'],\n",
       "    'topics': ['programming'],\n",
       "    'claps': 3344,\n",
       "    'voters': 736,\n",
       "    'word_count': 763,\n",
       "    'responses_count': 48,\n",
       "    'reading_time': 3.829245283018868,\n",
       "    'url': 'https://medium.com/@jordan_gibbs/the-most-important-chatgpt-prompt-55ef2bdc4d4a',\n",
       "    'unique_slug': 'the-most-important-chatgpt-prompt-55ef2bdc4d4a',\n",
       "    'image_url': 'https://miro.medium.com/1*12v9CX7ENSplhj3upW9TkQ.png',\n",
       "    'lang': 'en',\n",
       "    'is_series': False,\n",
       "    'is_locked': True,\n",
       "    'is_shortform': False,\n",
       "    'top_highlight': '\"Before you start, please ask me any questions you have about this so I can give you more context. Be extremely comprehensive.\"'},\n",
       "   {'id': 'fbdcf256f6bc',\n",
       "    'title': 'Upskilling Yourself with AI will Change Your Life',\n",
       "    'subtitle': 'I’ll show you how to harness AI’s best use case with this simple framework.',\n",
       "    'author': '4beacba7dc8a',\n",
       "    'publication_id': '*Self-Published*',\n",
       "    'published_at': '2023-11-21 02:33:00',\n",
       "    'last_modified_at': '2023-11-21 02:33:00',\n",
       "    'tags': ['learning',\n",
       "     'personal-development',\n",
       "     'personal-growth',\n",
       "     'artificial-intelligence',\n",
       "     'chatgpt'],\n",
       "    'topics': ['artificial-intelligence', 'work', 'programming'],\n",
       "    'claps': 503,\n",
       "    'voters': 40,\n",
       "    'word_count': 1338,\n",
       "    'responses_count': 6,\n",
       "    'reading_time': 5.882389937106918,\n",
       "    'url': 'https://medium.com/@jordan_gibbs/upskilling-yourself-with-ai-will-change-your-life-fbdcf256f6bc',\n",
       "    'unique_slug': 'upskilling-yourself-with-ai-will-change-your-life-fbdcf256f6bc',\n",
       "    'image_url': 'https://miro.medium.com/1*Ep3iJro_D5eFYGgPBBH8Cw.png',\n",
       "    'lang': 'en',\n",
       "    'is_series': False,\n",
       "    'is_locked': True,\n",
       "    'is_shortform': False,\n",
       "    'top_highlight': \"I've developed a general framework that generalizes AI upskilling to any field. I have used this framework now for the past six months, and I can say with absolute certainty that it has changed my life for the better.\"},\n",
       "   {'id': 'd952c5716930',\n",
       "    'title': 'The Top 100 Self-Help Books in One: ChatGPT’s Master Lessons',\n",
       "    'subtitle': 'All self-help books share the same DNA, so I extracted the most common core principles with ChatGPT.',\n",
       "    'author': '4beacba7dc8a',\n",
       "    'publication_id': '*Self-Published*',\n",
       "    'published_at': '2024-02-04 20:10:06',\n",
       "    'last_modified_at': '2024-02-04 20:10:06',\n",
       "    'tags': ['chatgpt',\n",
       "     'ai',\n",
       "     'reading',\n",
       "     'self-improvement',\n",
       "     'artificial-intelligence'],\n",
       "    'topics': ['books', 'self'],\n",
       "    'claps': 629,\n",
       "    'voters': 51,\n",
       "    'word_count': 1112,\n",
       "    'responses_count': 5,\n",
       "    'reading_time': 4.746226415094339,\n",
       "    'url': 'https://medium.com/@jordan_gibbs/the-top-100-self-help-books-in-one-chatgpts-master-lessons-d952c5716930',\n",
       "    'unique_slug': 'the-top-100-self-help-books-in-one-chatgpts-master-lessons-d952c5716930',\n",
       "    'image_url': 'https://miro.medium.com/1*nSeg0aeWBOHDYFb4UteGTA.png',\n",
       "    'lang': 'en',\n",
       "    'is_series': False,\n",
       "    'is_locked': True,\n",
       "    'is_shortform': False,\n",
       "    'top_highlight': ''},\n",
       "   {'id': '0765f71dee3e',\n",
       "    'title': 'The Art of Asking the Right Question',\n",
       "    'subtitle': 'All of our problems are solvable\\u200a—\\u200aif we could only ask the right questions.',\n",
       "    'author': '4beacba7dc8a',\n",
       "    'publication_id': '*Self-Published*',\n",
       "    'published_at': '2024-02-01 18:19:13',\n",
       "    'last_modified_at': '2024-02-01 18:19:13',\n",
       "    'tags': ['problem-solving',\n",
       "     'questions',\n",
       "     'productivity',\n",
       "     'inspiration',\n",
       "     'self-improvement'],\n",
       "    'topics': ['psychology', 'self'],\n",
       "    'claps': 134,\n",
       "    'voters': 14,\n",
       "    'word_count': 1698,\n",
       "    'responses_count': 2,\n",
       "    'reading_time': 6.9575471698113205,\n",
       "    'url': 'https://medium.com/@jordan_gibbs/the-art-of-asking-the-right-question-0765f71dee3e',\n",
       "    'unique_slug': 'the-art-of-asking-the-right-question-0765f71dee3e',\n",
       "    'image_url': 'https://miro.medium.com/1*VTM9PjtwBhMT7xvytE_Lew.png',\n",
       "    'lang': 'en',\n",
       "    'is_series': False,\n",
       "    'is_locked': True,\n",
       "    'is_shortform': False,\n",
       "    'top_highlight': '\"If I had an hour to solve a problem and my life depended on the solution, I would spend the first 55 minutes determining the proper question to ask... for once I know the proper question, I could solve the problem in less than five minutes.\"'},\n",
       "   {'id': 'fb3f7e0d9deb',\n",
       "    'title': 'Read 1000 Books per Year with ChatGPT',\n",
       "    'subtitle': 'Supercharge your reading volume, comprehension, and retention with ChatGPT-assisted reading',\n",
       "    'author': '4beacba7dc8a',\n",
       "    'publication_id': '*Self-Published*',\n",
       "    'published_at': '2024-01-03 03:39:02',\n",
       "    'last_modified_at': '2024-01-03 03:39:02',\n",
       "    'tags': ['chatgpt',\n",
       "     'ai',\n",
       "     'artificial-intelligence',\n",
       "     'reading',\n",
       "     'learning'],\n",
       "    'topics': ['productivity'],\n",
       "    'claps': 1757,\n",
       "    'voters': 293,\n",
       "    'word_count': 1126,\n",
       "    'responses_count': 33,\n",
       "    'reading_time': 5.1990566037735855,\n",
       "    'url': 'https://medium.com/@jordan_gibbs/read-1000-books-per-year-with-chatgpt-fb3f7e0d9deb',\n",
       "    'unique_slug': 'read-1000-books-per-year-with-chatgpt-fb3f7e0d9deb',\n",
       "    'image_url': 'https://miro.medium.com/1*IsLL1ZnRVJ0fkoysWFx5Uw.png',\n",
       "    'lang': 'en',\n",
       "    'is_series': False,\n",
       "    'is_locked': True,\n",
       "    'is_shortform': False,\n",
       "    'top_highlight': 'Write an ultra-detailed summary about [Insert Book Title].'},\n",
       "   {'id': '948fce739c61',\n",
       "    'title': 'Do Gimmicky ChatGPT Prompts Actually Work?',\n",
       "    'subtitle': 'I analyzed if viral gimmick prompts actually trick ChatGPT into working harder.',\n",
       "    'author': '4beacba7dc8a',\n",
       "    'publication_id': '*Self-Published*',\n",
       "    'published_at': '2023-12-27 03:02:16',\n",
       "    'last_modified_at': '2023-12-27 03:02:16',\n",
       "    'tags': ['chatgpt',\n",
       "     'openai',\n",
       "     'ai',\n",
       "     'artificial-intelligence',\n",
       "     'prompt-engineering'],\n",
       "    'topics': ['data-science', 'programming'],\n",
       "    'claps': 125,\n",
       "    'voters': 21,\n",
       "    'word_count': 513,\n",
       "    'responses_count': 2,\n",
       "    'reading_time': 2.319182389937107,\n",
       "    'url': 'https://medium.com/@jordan_gibbs/do-gimmicky-chatgpt-prompts-actually-work-948fce739c61',\n",
       "    'unique_slug': 'do-gimmicky-chatgpt-prompts-actually-work-948fce739c61',\n",
       "    'image_url': 'https://miro.medium.com/1*Uz4_8rQuiXIQXCNDSjN0wQ.png',\n",
       "    'lang': 'en',\n",
       "    'is_series': False,\n",
       "    'is_locked': True,\n",
       "    'is_shortform': False,\n",
       "    'top_highlight': ''},\n",
       "   {'id': 'b0911e3faf6b',\n",
       "    'title': 'Which Phrases are the Most “ChatGPT” of All?',\n",
       "    'subtitle': 'I analyzed 1.2 million GPT words to find the most common phrases output by ChatGPT\\u200a—\\u200aI found some crazy results.',\n",
       "    'author': '4beacba7dc8a',\n",
       "    'publication_id': '*Self-Published*',\n",
       "    'published_at': '2023-12-14 17:36:37',\n",
       "    'last_modified_at': '2023-12-14 17:36:37',\n",
       "    'tags': ['chatgpt',\n",
       "     'ai',\n",
       "     'artificial-intelligence',\n",
       "     'openai',\n",
       "     'linguistics'],\n",
       "    'topics': ['data-science'],\n",
       "    'claps': 1106,\n",
       "    'voters': 158,\n",
       "    'word_count': 816,\n",
       "    'responses_count': 22,\n",
       "    'reading_time': 3.9125786163522016,\n",
       "    'url': 'https://medium.com/@jordan_gibbs/which-phrases-are-the-most-chatgpt-of-all-b0911e3faf6b',\n",
       "    'unique_slug': 'which-phrases-are-the-most-chatgpt-of-all-b0911e3faf6b',\n",
       "    'image_url': 'https://miro.medium.com/1*5ARxvUDOs_76GIHYtDCYKQ.png',\n",
       "    'lang': 'en',\n",
       "    'is_series': False,\n",
       "    'is_locked': True,\n",
       "    'is_shortform': False,\n",
       "    'top_highlight': ''}]},\n",
       " '630ab5ffdf27': {'id': '630ab5ffdf27',\n",
       "  'username': 'jacobistyping',\n",
       "  'fullname': 'Jacob Bennett',\n",
       "  'bio': 'Eng @ Medium • https://jacob.bio • I write about software engineering, product design and development, and leadership in tech.',\n",
       "  'followers_count': 25716,\n",
       "  'following_count': 76,\n",
       "  'publication_following_count': 35,\n",
       "  'image_url': 'https://miro.medium.com/1*pii4hAS8roHyiOd0ONnHoA@2x.jpeg',\n",
       "  'twitter_username': '',\n",
       "  'is_writer_program_enrolled': True,\n",
       "  'allow_notes': True,\n",
       "  'medium_member_at': '1970-01-31 00:00:00',\n",
       "  'is_suspended': False,\n",
       "  'top_writer_in': [],\n",
       "  'has_list': True,\n",
       "  'is_book_author': False,\n",
       "  'tipping_link': 'https://ko-fi.com/jacobistyping',\n",
       "  'bg_image_url': '',\n",
       "  'logo_image_url': '',\n",
       "  'followers': ['0008a90f7d7f',\n",
       "   '00149b7421b2',\n",
       "   '0016c6d6a984',\n",
       "   '00183ef79cce',\n",
       "   '001ce0063391',\n",
       "   '00261d9dd4f9',\n",
       "   '003a91d0f9a1',\n",
       "   '00418aadfc4b',\n",
       "   '0046ce282326',\n",
       "   '004b48ab4b32',\n",
       "   '005956b07565',\n",
       "   '0076c2a4fccc',\n",
       "   '009733c9ec1e',\n",
       "   '00a78a6007f4',\n",
       "   '00adf31ab408',\n",
       "   '00b8eada8b79',\n",
       "   '00f24bcd7bd7',\n",
       "   '0108b7898242',\n",
       "   '0109e784bcf3',\n",
       "   '010aff80b0a3',\n",
       "   '011a74d45a8b',\n",
       "   '01237873b7d5',\n",
       "   '012fdb5da8ec',\n",
       "   '0143c3cfd773',\n",
       "   '01504d6c22ed',\n",
       "   '01a6eed31abb',\n",
       "   '01a9c1259fcc',\n",
       "   '01c016e994f9',\n",
       "   '01c3d6b01450',\n",
       "   '01cf0debc091',\n",
       "   '01e22e257aad',\n",
       "   '01e76051e5c1',\n",
       "   '01eb5edb6a57',\n",
       "   '01ec1a0c6bf3',\n",
       "   '01ed3aed44cd',\n",
       "   '01faad01498c',\n",
       "   '0200e0eab7bd',\n",
       "   '02147b72ccdc',\n",
       "   '0222ca211b33',\n",
       "   '022a74088f12',\n",
       "   '0249960b42f0',\n",
       "   '02592ce69e20',\n",
       "   '025ad739634f',\n",
       "   '02628641dd9b',\n",
       "   '028b27877c10',\n",
       "   '02e955325ee9',\n",
       "   '02ec4289a70b',\n",
       "   '02f9009f19a9',\n",
       "   '03133540481d',\n",
       "   '0327d9e6545f',\n",
       "   '032a08f6c8d8',\n",
       "   '03311fd5f4e7',\n",
       "   '0344c819f9fc',\n",
       "   '0345651c406a',\n",
       "   '03524b370ed6',\n",
       "   '036ecf5a78de',\n",
       "   '0375cf039b1f',\n",
       "   '037cf47840d3',\n",
       "   '037e56d957e3',\n",
       "   '03892fe24790',\n",
       "   '03bc9df9f99b',\n",
       "   '03bff1292d9c',\n",
       "   '03d778a58360',\n",
       "   '03db7b4295c8',\n",
       "   '03f6ee79f36c',\n",
       "   '041f2e0c25bf',\n",
       "   '042085141fef',\n",
       "   '0424cd3b13bb',\n",
       "   '04432e9db852',\n",
       "   '04500c057f2b',\n",
       "   '045559435124',\n",
       "   '04588df35309',\n",
       "   '0458ac9ef3fd',\n",
       "   '047461f352a9',\n",
       "   '0485b6f6e008',\n",
       "   '048721225600',\n",
       "   '04a8b4facdbf',\n",
       "   '04b7ceab9f78',\n",
       "   '04bbf25c8178',\n",
       "   '04ca33ca0707',\n",
       "   '04d07e673737',\n",
       "   '051276cc78f1',\n",
       "   '0524df2841da',\n",
       "   '053ddfdb3053',\n",
       "   '0540142a916e',\n",
       "   '0556c608c8b7',\n",
       "   '0566fd552a56',\n",
       "   '057ae7cd2ddd',\n",
       "   '058a6d5a31c2',\n",
       "   '05906bfbe5cd',\n",
       "   '0591cd50fcdb',\n",
       "   '05a7512b66cd',\n",
       "   '05af046c95a4',\n",
       "   '05ba059adbb6',\n",
       "   '05bba34de306',\n",
       "   '05ce4bbf9fff',\n",
       "   '05cf15363a93',\n",
       "   '05e507811d9f',\n",
       "   '05eaf182d754',\n",
       "   '05ec127105b9',\n",
       "   '060a20697ec0',\n",
       "   '0612100996f6',\n",
       "   '0614f6c1d39e',\n",
       "   '0646d2f4d2df',\n",
       "   '064f9190c730',\n",
       "   '065dde52b681',\n",
       "   '06959f0077ec',\n",
       "   '06982b3aaf3d',\n",
       "   '07062e00b174',\n",
       "   '071d629f8ede',\n",
       "   '071da920fdde',\n",
       "   '073133dbe904',\n",
       "   '0732d8943782',\n",
       "   '0737076c49cf',\n",
       "   '075bec19ed6b',\n",
       "   '07630528f351',\n",
       "   '0785fb89fab4',\n",
       "   '07a32ae77163',\n",
       "   '07a7fe9b6483',\n",
       "   '07c53b240b01',\n",
       "   '07ca6823fa60',\n",
       "   '08097d4c62a1',\n",
       "   '083da1d105d8',\n",
       "   '085db9bd8bee',\n",
       "   '086801ed3994',\n",
       "   '08971108c998',\n",
       "   '08bdfa8e1c15',\n",
       "   '08c51b99c7bd',\n",
       "   '08c60103d108',\n",
       "   '08e525e13b8c',\n",
       "   '08f0d4fd16d2',\n",
       "   '0905b230a33a',\n",
       "   '092686d9364a',\n",
       "   '09335f825c05',\n",
       "   '093b94338898',\n",
       "   '0942daae186e',\n",
       "   '09a3d2219474',\n",
       "   '09abeab74b1b',\n",
       "   '09ae3edc9722',\n",
       "   '09b6ac590e29',\n",
       "   '09b7fba39f2e',\n",
       "   '09ba36b87a06',\n",
       "   '09bb3b52a462',\n",
       "   '09c7cc1c97f2',\n",
       "   '09ced9f9f27f',\n",
       "   '09edfe95038a',\n",
       "   '09ee02318ee5',\n",
       "   '09f10af24958',\n",
       "   '09ff47974055',\n",
       "   '0a09771ab0c6',\n",
       "   '0a1019150c3e',\n",
       "   '0a11b6d6fbc9',\n",
       "   '0a18575bfefc',\n",
       "   '0a5023a0b43b',\n",
       "   '0a5b4b6bf759',\n",
       "   '0a905269dfe4',\n",
       "   '0a90a192a60b',\n",
       "   '0a9f4e679fe2',\n",
       "   '0aa919e64d91',\n",
       "   '0aaf7a1f8af3',\n",
       "   '0aaf8e99c8c7',\n",
       "   '0abc3ebf7b31',\n",
       "   '0abce5a499cf',\n",
       "   '0ae7fff06995',\n",
       "   '0b08fe198ecf',\n",
       "   '0b11eea1a0c1',\n",
       "   '0b176a2545af',\n",
       "   '0b2021d26409',\n",
       "   '0b234e69a7f9',\n",
       "   '0b2b7e14bbb4',\n",
       "   '0b30a72301a1',\n",
       "   '0b36e4263392',\n",
       "   '0b37349d902a',\n",
       "   '0b46aee0d1fa',\n",
       "   '0b55a755b4ae',\n",
       "   '0b5bf4e33e99',\n",
       "   '0b643af76977',\n",
       "   '0b915a500f12',\n",
       "   '0b91e99eb2bf',\n",
       "   '0b91ffcad622',\n",
       "   '0b94187ee8f5',\n",
       "   '0b96f6886a09',\n",
       "   '0ba16e169f1b',\n",
       "   '0bb15c4c190c',\n",
       "   '0bc872ce959b',\n",
       "   '0c1e0b204b77',\n",
       "   '0c36b68c3f11',\n",
       "   '0c498e7f5e6e',\n",
       "   '0c4f4c08d9cb',\n",
       "   '0c5502b3eacb',\n",
       "   '0c58ccfbd34f',\n",
       "   '0c602f4e893a',\n",
       "   '0c7067d7bf7d',\n",
       "   '0c88344e2cb0',\n",
       "   '0c8d56eda234',\n",
       "   '0c95c287b9fb',\n",
       "   '0c96a8cd6d1f',\n",
       "   '0ca299a030e3',\n",
       "   '0cac7d0160fc',\n",
       "   '0cae5c94bb40',\n",
       "   '0cbb8de08159',\n",
       "   '0cc42e98f068',\n",
       "   '0cc4d4dd1f14',\n",
       "   '0ccd347285af',\n",
       "   '0cd224d82ed7',\n",
       "   '0ce15d267ef1',\n",
       "   '0ce543c936f4',\n",
       "   '0cec65fa12b8',\n",
       "   '0ced55597187',\n",
       "   '0cf3cf1c1015',\n",
       "   '0cf8dc7a5bc1',\n",
       "   '0cfb5f2c1b64',\n",
       "   '0d02a526311b',\n",
       "   '0d11d07c746e',\n",
       "   '0d1aa9ca5728',\n",
       "   '0d320c220d70',\n",
       "   '0d3ae394438c',\n",
       "   '0d689a970b60',\n",
       "   '0d6a560df67d',\n",
       "   '0d898122bb61',\n",
       "   '0d9c480487a9',\n",
       "   '0db782600277',\n",
       "   '0dc1cec049d3',\n",
       "   '0dc95dae0b63',\n",
       "   '0dcd34ff62d3',\n",
       "   '0dd63eaaa48f',\n",
       "   '0dfe280b276f',\n",
       "   '0e05ef961ac1',\n",
       "   '0e13a8173277',\n",
       "   '0e2272c8a3e3',\n",
       "   '0e2f34049763',\n",
       "   '0e365ad5e60a',\n",
       "   '0e44dcf60b26',\n",
       "   '0e5faf098978',\n",
       "   '0e7588d35f8d',\n",
       "   '0e7923c448c0',\n",
       "   '0e8fc6b09e89',\n",
       "   '0eacbe3178a1',\n",
       "   '0ec324fbcb05',\n",
       "   '0ec548320a3f',\n",
       "   '0eca275c588c',\n",
       "   '0ed0e5a8ca2f',\n",
       "   '0f045d779d2f',\n",
       "   '0f14b25034eb',\n",
       "   '0f3096c32875',\n",
       "   '0f445a7ef51b',\n",
       "   '0f46955e6ac5',\n",
       "   '0f568c99db6e',\n",
       "   '0f68be24fe5d',\n",
       "   '0f6f08d3268f',\n",
       "   '0f7a796b4e93',\n",
       "   '0f9de8e7ec40',\n",
       "   '0fa63034cad7',\n",
       "   '0fbc79ec017d',\n",
       "   '0fca98e3802a',\n",
       "   '0fdacfb5e0a2',\n",
       "   '0fdd58b66321',\n",
       "   '0fe8275352ea',\n",
       "   '0ff29dbed73d',\n",
       "   '0ff632cf8f64',\n",
       "   '0ff882a63404',\n",
       "   '0ffc36f368ef',\n",
       "   '1000993cc6d8',\n",
       "   '100130cb5f3a',\n",
       "   '1002247489c9',\n",
       "   '1003f78bff66',\n",
       "   '10042c5219ed',\n",
       "   '10048a1c6fe7',\n",
       "   '100662371207',\n",
       "   '1008f2849939',\n",
       "   '100bf12bbf78',\n",
       "   '100c11327c05',\n",
       "   '100e2e6f538a',\n",
       "   '101686506f03',\n",
       "   '101ab1ce96a2',\n",
       "   '101c6f949724',\n",
       "   '101d3b5f0f95',\n",
       "   '10214af0ba15',\n",
       "   '1021590cd84a',\n",
       "   '10252a48d64a',\n",
       "   '1027a45a61c4',\n",
       "   '102bb0cd3637',\n",
       "   '1031b39330b0',\n",
       "   '103581ee7c9d',\n",
       "   '1038b1ace022',\n",
       "   '10396b89532c',\n",
       "   '103f20e816eb',\n",
       "   '103ff6fc7530',\n",
       "   '1040bda7ef15',\n",
       "   '10414f9b0f50',\n",
       "   '1048f0f87cfb',\n",
       "   '10497a096abc',\n",
       "   '1049effcb522',\n",
       "   '104a155c2a82',\n",
       "   '104bf933f735',\n",
       "   '104c178215ad',\n",
       "   '105223d2c9a0',\n",
       "   '1052fa490159',\n",
       "   '105624e522db',\n",
       "   '1056af42639e',\n",
       "   '1057ffee7964',\n",
       "   '1059cd5aee6e',\n",
       "   '105a3c72085a',\n",
       "   '1065c866fa3b',\n",
       "   '10665f5465b5',\n",
       "   '106745496231',\n",
       "   '10680c0d365c',\n",
       "   '10689b6ad7dd',\n",
       "   '1069084617cc',\n",
       "   '1069ef0d9d8a',\n",
       "   '106ddfc57bd4',\n",
       "   '106e0782fa22',\n",
       "   '106e27102c9b',\n",
       "   '106fe47cf4ec',\n",
       "   '1070d28095b3',\n",
       "   '10767895d1ba',\n",
       "   '10768b1e0a87',\n",
       "   '1077fa310fc5',\n",
       "   '10798221737d',\n",
       "   '107b8d4ceb7c',\n",
       "   '107fb5d0ef44',\n",
       "   '108bb256eaa2',\n",
       "   '108e08d9c994',\n",
       "   '108e684bb29',\n",
       "   '108e8c5446c5',\n",
       "   '1093360c9fcb',\n",
       "   '1094b42ebfb0',\n",
       "   '1097143a6852',\n",
       "   '1099eb971d5a',\n",
       "   '109bde043dcf',\n",
       "   '109c74cbb000',\n",
       "   '109c991899f8',\n",
       "   '109db930abda',\n",
       "   '10a05352ff10',\n",
       "   '10a300b1108b',\n",
       "   '10a305a6c9d5',\n",
       "   '10a7a3a6279c',\n",
       "   '10a8801553ac',\n",
       "   '10ab27bf4bab',\n",
       "   '10ada71eab9e',\n",
       "   '10ae4014d860',\n",
       "   '10afee97b0a5',\n",
       "   '10b34745d318',\n",
       "   '10bcc75fae04',\n",
       "   '10be6ed52ca8',\n",
       "   '10bebdcc70b6',\n",
       "   '10c432608c7a',\n",
       "   '10c47a1a6220',\n",
       "   '10c50a19c270',\n",
       "   '10c5646f8c28',\n",
       "   '10c6c33d67d6',\n",
       "   '10cce5633d2d',\n",
       "   '10cceacb79a5',\n",
       "   '10cd10383056',\n",
       "   '10cf78ee0cba',\n",
       "   '10d1933157db',\n",
       "   '10d4f30b0891',\n",
       "   '10d64fbe4bc5',\n",
       "   '10dac8194ea9',\n",
       "   '10dc9184d24c',\n",
       "   '10ddf9cf6d53',\n",
       "   '10de7cb84f80',\n",
       "   '10e31e56f94e',\n",
       "   '10e5ff17d4f4',\n",
       "   '10e7d422e9c7',\n",
       "   '10eb2e3fed0f',\n",
       "   '10eddde94d16',\n",
       "   '10ef1750bcc5',\n",
       "   '10f0ea246988',\n",
       "   '10f29fdf2d',\n",
       "   '10f2e75565dd',\n",
       "   '10f43dcd438e',\n",
       "   '10f581b06f04',\n",
       "   '10fadbeef640',\n",
       "   '10fbbdca581',\n",
       "   '10fc4ba0ee05',\n",
       "   '10fd0f205f33',\n",
       "   '10ff9a2e65bf',\n",
       "   '1103621af7f4',\n",
       "   '110682a48dbb',\n",
       "   '1106f1adab9d',\n",
       "   '11071ab804ab',\n",
       "   '110c613d8115',\n",
       "   '110e08bba8fa',\n",
       "   '11123ae4691a',\n",
       "   '11126a212f9d',\n",
       "   '1116dba591b6',\n",
       "   '1117491376df',\n",
       "   '111c7240239f',\n",
       "   '111d65dfa793',\n",
       "   '1120111d59f0',\n",
       "   '1124350ef8bb',\n",
       "   '1124b326f672',\n",
       "   '11254daea18c',\n",
       "   '1125918679ba',\n",
       "   '112901b42c06',\n",
       "   '11296153d65',\n",
       "   '112db6206bca',\n",
       "   '1131a766a8d',\n",
       "   '11347b6cc6a0',\n",
       "   '11355deac56a',\n",
       "   '1135b8228e59',\n",
       "   '1138b0dc9dc4',\n",
       "   '1138df2f4d80',\n",
       "   '113a21effaff',\n",
       "   '113bc11a1239',\n",
       "   '113e63516dc3',\n",
       "   '11438af8c776',\n",
       "   '1145834bd631',\n",
       "   '1149c536e9a',\n",
       "   '114a4741dc95',\n",
       "   '114cd04814c',\n",
       "   '115082a6c6f5',\n",
       "   '11528d1decf5',\n",
       "   '1155f320294b',\n",
       "   '115656f04fea',\n",
       "   '1156594a9b17',\n",
       "   '1159f2bb69e0',\n",
       "   '1167b684bec5',\n",
       "   '116b26eca26d',\n",
       "   '116cef0675c5',\n",
       "   '116f7c26473f',\n",
       "   '117182cf3e54',\n",
       "   '117300ed2788',\n",
       "   '11735842faa',\n",
       "   '1174113b42e4',\n",
       "   '1178df281529',\n",
       "   '1184b97e5db3',\n",
       "   '1184fe02b3af',\n",
       "   '118c7748586f',\n",
       "   '118cec4f60b5',\n",
       "   '11919c94d596',\n",
       "   '11939f12eb7e',\n",
       "   '11949743c97f',\n",
       "   '11957770892a',\n",
       "   '119668a80479',\n",
       "   '119bb908ee9b',\n",
       "   '11a271cdf577',\n",
       "   '11a5f5263674',\n",
       "   '11acb378a7f9',\n",
       "   '11aeed44b05e',\n",
       "   '11b8283c51b',\n",
       "   '11bb12b54192',\n",
       "   '11bf9637fa33',\n",
       "   '11c464d3d2df',\n",
       "   '11c595f05a3',\n",
       "   '11ca8c2fde7',\n",
       "   '11cb9ce642b3',\n",
       "   '11cd9b6ed0ce',\n",
       "   '11cdf6161b69',\n",
       "   '11cef9b3aabe',\n",
       "   '11d19db0ef99',\n",
       "   '11d3af3bf9da',\n",
       "   '11d3c09cb167',\n",
       "   '11d457c3391c',\n",
       "   '11d785b0b001',\n",
       "   '11d78a795f00',\n",
       "   '11db305563e4',\n",
       "   '11decacbdcf2',\n",
       "   '11e252593ffe',\n",
       "   '11e47caff04',\n",
       "   '11e65fe4fa0a',\n",
       "   '11ebdbfd3d01',\n",
       "   '11ed09c6bef8',\n",
       "   '11ef127d2789',\n",
       "   '11ef5f9df73a',\n",
       "   '11efb5189d72',\n",
       "   '11f10e61d67b',\n",
       "   '11f209b4768e',\n",
       "   '11f3a7faedb1',\n",
       "   '11f3b9ffceed',\n",
       "   '11f48dc32e31',\n",
       "   '11fbe83ddebb',\n",
       "   '11fdbf4a3cca',\n",
       "   '11ffbcedde9'],\n",
       "  'top_articles': [{'id': '0826b977bb5a',\n",
       "    'title': 'My magical first job as a self-taught software engineer',\n",
       "    'subtitle': 'I’m a self-taught software engineer. No formal courses. No internship. Being self-taught means I have some noticeable gaps in my technical…',\n",
       "    'author': '630ab5ffdf27',\n",
       "    'publication_id': '7fa1ab2ec345',\n",
       "    'published_at': '2024-02-16 10:31:47',\n",
       "    'last_modified_at': '2024-02-16 10:31:47',\n",
       "    'tags': ['programming',\n",
       "     'software-engineering',\n",
       "     'software-development',\n",
       "     'careers'],\n",
       "    'topics': ['work', 'programming'],\n",
       "    'claps': 211,\n",
       "    'voters': 21,\n",
       "    'word_count': 350,\n",
       "    'responses_count': 5,\n",
       "    'reading_time': 1.520754716981132,\n",
       "    'url': 'https://atomic.engineering/my-magical-first-job-as-a-self-taught-software-engineer-0826b977bb5a',\n",
       "    'unique_slug': 'my-magical-first-job-as-a-self-taught-software-engineer-0826b977bb5a',\n",
       "    'image_url': 'https://miro.medium.com/0*dpx9eSSU8dllS32h.png',\n",
       "    'lang': 'en',\n",
       "    'is_series': False,\n",
       "    'is_locked': False,\n",
       "    'is_shortform': False,\n",
       "    'top_highlight': 'Comparison is the thief of joy.'},\n",
       "   {'id': '3be015341e5e',\n",
       "    'title': 'An algorithm for high-performance engineering teams',\n",
       "    'subtitle': 'How does a team go from “good” to “great”?',\n",
       "    'author': '630ab5ffdf27',\n",
       "    'publication_id': '7fa1ab2ec345',\n",
       "    'published_at': '2024-02-14 16:37:02',\n",
       "    'last_modified_at': '2024-02-15 04:02:03',\n",
       "    'tags': ['leadership', 'programming', 'software-engineering'],\n",
       "    'topics': ['work', 'programming'],\n",
       "    'claps': 459,\n",
       "    'voters': 58,\n",
       "    'word_count': 1588,\n",
       "    'responses_count': 8,\n",
       "    'reading_time': 6.542452830188679,\n",
       "    'url': 'https://atomic.engineering/an-algorithm-for-high-performance-engineering-teams-3be015341e5e',\n",
       "    'unique_slug': 'an-algorithm-for-high-performance-engineering-teams-3be015341e5e',\n",
       "    'image_url': 'https://miro.medium.com/1*YBldg8qIX_Y7oxfu_UaS8w.png',\n",
       "    'lang': 'en',\n",
       "    'is_series': False,\n",
       "    'is_locked': True,\n",
       "    'is_shortform': False,\n",
       "    'top_highlight': 'All models are wrong, but some are useful.'},\n",
       "   {'id': 'a8f2b9faad1d',\n",
       "    'title': 'I almost got fired once',\n",
       "    'subtitle': '👋 Hi, this is Jacob with this week’s newsletter, “I almost got fired once.”',\n",
       "    'author': '630ab5ffdf27',\n",
       "    'publication_id': '7fa1ab2ec345',\n",
       "    'published_at': '2024-02-09 11:31:46',\n",
       "    'last_modified_at': '2024-02-09 11:31:46',\n",
       "    'tags': ['programming',\n",
       "     'software-development',\n",
       "     'software-engineering',\n",
       "     'problem-solving',\n",
       "     'leadership'],\n",
       "    'topics': ['work', 'programming'],\n",
       "    'claps': 378,\n",
       "    'voters': 34,\n",
       "    'word_count': 746,\n",
       "    'responses_count': 5,\n",
       "    'reading_time': 3.1984276729559746,\n",
       "    'url': 'https://atomic.engineering/i-almost-got-fired-once-a8f2b9faad1d',\n",
       "    'unique_slug': 'i-almost-got-fired-once-a8f2b9faad1d',\n",
       "    'image_url': 'https://miro.medium.com/1*LB-gvS9Z52OtQKljoJy6bw.png',\n",
       "    'lang': 'en',\n",
       "    'is_series': False,\n",
       "    'is_locked': False,\n",
       "    'is_shortform': False,\n",
       "    'top_highlight': 'Luke Millar (VP of Eng at Medium) explained to me what made one of our team members so valuable. \"They\\'re not necessarily fast, but I know if I give them a hard problem that no one else understands, they\\'ll eventually find an answer, and it will be a good one.\"'},\n",
       "   {'id': '547e3edc7a36',\n",
       "    'title': 'A tale of two engineering teams',\n",
       "    'subtitle': '👋 Hi, this is Jacob with this week’s newsletter, “A tale of two engineering teams.”',\n",
       "    'author': '630ab5ffdf27',\n",
       "    'publication_id': '7fa1ab2ec345',\n",
       "    'published_at': '2024-02-02 11:31:43',\n",
       "    'last_modified_at': '2024-02-02 11:31:43',\n",
       "    'tags': ['programming',\n",
       "     'software-development',\n",
       "     'software-engineering',\n",
       "     'technology'],\n",
       "    'topics': ['programming'],\n",
       "    'claps': 595,\n",
       "    'voters': 70,\n",
       "    'word_count': 616,\n",
       "    'responses_count': 6,\n",
       "    'reading_time': 2.5245283018867926,\n",
       "    'url': 'https://atomic.engineering/a-tale-of-two-engineering-teams-547e3edc7a36',\n",
       "    'unique_slug': 'a-tale-of-two-engineering-teams-547e3edc7a36',\n",
       "    'image_url': 'https://miro.medium.com/0*dpMZyiz7Wm5sI2B6.png',\n",
       "    'lang': 'en',\n",
       "    'is_series': False,\n",
       "    'is_locked': False,\n",
       "    'is_shortform': False,\n",
       "    'top_highlight': '\"First, make it work.\" You are out of business if it doesn\\'t work.'},\n",
       "   {'id': '597a768f6509',\n",
       "    'title': 'Welcome to The Standup',\n",
       "    'subtitle': 'A single idea. 5 minutes or less. Every week.',\n",
       "    'author': '630ab5ffdf27',\n",
       "    'publication_id': '7fa1ab2ec345',\n",
       "    'published_at': '2024-01-26 13:32:22',\n",
       "    'last_modified_at': '2024-01-26 16:52:09',\n",
       "    'tags': ['programming',\n",
       "     'software-development',\n",
       "     'software-engineering',\n",
       "     'software-architecture',\n",
       "     'data-science'],\n",
       "    'topics': ['programming'],\n",
       "    'claps': 79,\n",
       "    'voters': 11,\n",
       "    'word_count': 120,\n",
       "    'responses_count': 1,\n",
       "    'reading_time': 0.4528301886792453,\n",
       "    'url': 'https://atomic.engineering/welcome-to-atomic-engineering-daily-597a768f6509',\n",
       "    'unique_slug': 'welcome-to-atomic-engineering-daily-597a768f6509',\n",
       "    'image_url': '',\n",
       "    'lang': 'en',\n",
       "    'is_series': False,\n",
       "    'is_locked': False,\n",
       "    'is_shortform': True,\n",
       "    'top_highlight': ''},\n",
       "   {'id': 'edd9949df58b',\n",
       "    'title': 'The 5 paid subscriptions I actually use in 2024 as a software engineer',\n",
       "    'subtitle': 'Tools I use that are cheaper than Netflix',\n",
       "    'author': '630ab5ffdf27',\n",
       "    'publication_id': '5517fd7b58a6',\n",
       "    'published_at': '2024-01-04 15:44:45',\n",
       "    'last_modified_at': '2024-01-04 15:44:45',\n",
       "    'tags': ['software-engineering',\n",
       "     'software-development',\n",
       "     'programming',\n",
       "     'technology',\n",
       "     'data-science'],\n",
       "    'topics': ['programming'],\n",
       "    'claps': 9093,\n",
       "    'voters': 2385,\n",
       "    'word_count': 896,\n",
       "    'responses_count': 122,\n",
       "    'reading_time': 4.331132075471698,\n",
       "    'url': 'https://levelup.gitconnected.com/the-5-paid-subscriptions-i-actually-use-in-2024-as-a-software-engineer-edd9949df58b',\n",
       "    'unique_slug': 'the-5-paid-subscriptions-i-actually-use-in-2024-as-a-software-engineer-edd9949df58b',\n",
       "    'image_url': 'https://miro.medium.com/1*jDgxfrxa6FoWb5e0VAFt-w.gif',\n",
       "    'lang': 'en',\n",
       "    'is_series': False,\n",
       "    'is_locked': True,\n",
       "    'is_shortform': False,\n",
       "    'top_highlight': 'Kagi: a better search engine than Google'},\n",
       "   {'id': '815da93996a',\n",
       "    'title': 'Yes, You Can Write ‘switch’ Statements in Python',\n",
       "    'subtitle': 'And it comes with a secret superpower!',\n",
       "    'author': '630ab5ffdf27',\n",
       "    'publication_id': '78073def27b8',\n",
       "    'published_at': '2023-04-05 04:17:00',\n",
       "    'last_modified_at': '2023-04-14 20:55:11',\n",
       "    'tags': ['python',\n",
       "     'programming',\n",
       "     'software-development',\n",
       "     'data-science',\n",
       "     'technology'],\n",
       "    'topics': ['programming'],\n",
       "    'claps': 560,\n",
       "    'voters': 82,\n",
       "    'word_count': 1110,\n",
       "    'responses_count': 8,\n",
       "    'reading_time': 4.3886792452830194,\n",
       "    'url': 'https://python.plainenglish.io/yes-you-can-write-switch-statements-in-python-815da93996a',\n",
       "    'unique_slug': 'yes-you-can-write-switch-statements-in-python-815da93996a',\n",
       "    'image_url': 'https://miro.medium.com/0*ZK-x4MQeq7ElOOW1.png',\n",
       "    'lang': 'en',\n",
       "    'is_series': False,\n",
       "    'is_locked': True,\n",
       "    'is_shortform': False,\n",
       "    'top_highlight': ''},\n",
       "   {'id': 'c1fe776c108f',\n",
       "    'title': 'The comprehensive guide to Python project setup',\n",
       "    'subtitle': 'Start your project right and reap the rewards for years',\n",
       "    'author': '630ab5ffdf27',\n",
       "    'publication_id': '5517fd7b58a6',\n",
       "    'published_at': '2023-04-04 17:24:29',\n",
       "    'last_modified_at': '2023-04-04 17:24:29',\n",
       "    'tags': ['python',\n",
       "     'programming',\n",
       "     'software-development',\n",
       "     'data-science',\n",
       "     'technology'],\n",
       "    'topics': ['programming'],\n",
       "    'claps': 1331,\n",
       "    'voters': 399,\n",
       "    'word_count': 2632,\n",
       "    'responses_count': 9,\n",
       "    'reading_time': 10.315408805031446,\n",
       "    'url': 'https://levelup.gitconnected.com/the-comprehensive-guide-to-python-project-setup-c1fe776c108f',\n",
       "    'unique_slug': 'the-comprehensive-guide-to-python-project-setup-c1fe776c108f',\n",
       "    'image_url': 'https://miro.medium.com/0*LxrVQie98hgHzUAQ.png',\n",
       "    'lang': 'en',\n",
       "    'is_series': False,\n",
       "    'is_locked': True,\n",
       "    'is_shortform': False,\n",
       "    'top_highlight': 'Indeed, the ratio of time spent reading versus writing is well over 10 to 1. We are constantly reading old code as part of the effort to write new code. ...[Therefore,] making it easy to read makes it easier to write.'},\n",
       "   {'id': '9418515a315a',\n",
       "    'title': 'The 5 paid subscriptions I actually use in 2023 as a software engineer',\n",
       "    'subtitle': 'Tools I use that are cheaper than Netflix',\n",
       "    'author': '630ab5ffdf27',\n",
       "    'publication_id': '9758482ba857',\n",
       "    'published_at': '2023-03-25 17:01:41',\n",
       "    'last_modified_at': '2023-03-25 17:01:41',\n",
       "    'tags': ['programming',\n",
       "     'technology',\n",
       "     'education',\n",
       "     'data-science',\n",
       "     'software-development'],\n",
       "    'topics': ['programming'],\n",
       "    'claps': 4606,\n",
       "    'voters': 1554,\n",
       "    'word_count': 665,\n",
       "    'responses_count': 47,\n",
       "    'reading_time': 3.3427672955974845,\n",
       "    'url': 'https://medium.com/geekculture/the-5-paid-subscriptions-i-actually-use-in-2023-as-a-software-engineer-9418515a315a',\n",
       "    'unique_slug': 'the-5-paid-subscriptions-i-actually-use-in-2023-as-a-software-engineer-9418515a315a',\n",
       "    'image_url': 'https://miro.medium.com/1*pB-JOp4O5Q1jUj3YX4ca8w.png',\n",
       "    'lang': 'en',\n",
       "    'is_series': False,\n",
       "    'is_locked': True,\n",
       "    'is_shortform': False,\n",
       "    'top_highlight': 'Bonus: Excalidraw'},\n",
       "   {'id': 'ae06c6f24827',\n",
       "    'title': 'Solution to LeetCode #1: Two Sum (Python)',\n",
       "    'subtitle': 'Top 0.2% of solutions',\n",
       "    'author': '630ab5ffdf27',\n",
       "    'publication_id': '*Self-Published*',\n",
       "    'published_at': '2023-03-18 06:23:34',\n",
       "    'last_modified_at': '2023-03-30 03:07:10',\n",
       "    'tags': ['python',\n",
       "     'programming',\n",
       "     'software-development',\n",
       "     'leetcode',\n",
       "     'leetcode-easy'],\n",
       "    'topics': ['programming'],\n",
       "    'claps': 10,\n",
       "    'voters': 6,\n",
       "    'word_count': 976,\n",
       "    'responses_count': 0,\n",
       "    'reading_time': 4.233018867924528,\n",
       "    'url': 'https://jacobistyping.medium.com/solution-to-leetcode-1-two-sum-python-ae06c6f24827',\n",
       "    'unique_slug': 'solution-to-leetcode-1-two-sum-python-ae06c6f24827',\n",
       "    'image_url': 'https://miro.medium.com/1*TBZxhGJLzO1V4BjJuz_u-w.png',\n",
       "    'lang': 'en',\n",
       "    'is_series': False,\n",
       "    'is_locked': True,\n",
       "    'is_shortform': False,\n",
       "    'top_highlight': ''}]},\n",
       " 'b856005e5ecd': {'id': 'b856005e5ecd',\n",
       "  'username': 'fareedkhandev',\n",
       "  'fullname': 'Fareed Khan',\n",
       "  'bio': 'MSc Data Science, I write on AI https://www.linkedin.com/in/fareed-khan-dev/',\n",
       "  'followers_count': 20638,\n",
       "  'following_count': 0,\n",
       "  'publication_following_count': 0,\n",
       "  'image_url': 'https://miro.medium.com/1*UQfm5_v_d3Qfr-bhpjxttA.jpeg',\n",
       "  'twitter_username': '',\n",
       "  'is_writer_program_enrolled': True,\n",
       "  'allow_notes': True,\n",
       "  'medium_member_at': '',\n",
       "  'is_suspended': False,\n",
       "  'top_writer_in': ['artificial-intelligence'],\n",
       "  'has_list': True,\n",
       "  'is_book_author': False,\n",
       "  'tipping_link': None,\n",
       "  'bg_image_url': 'https://miro.medium.com/1*s6NvJCwSEfrImbVhHRcXww.png',\n",
       "  'logo_image_url': '',\n",
       "  'followers': ['000d5dcca96e',\n",
       "   '001479440872',\n",
       "   '001564222f42',\n",
       "   '001aa2fef563',\n",
       "   '001cda02fcc8',\n",
       "   '002125e32c14',\n",
       "   '002324d8d54e',\n",
       "   '00245ad345da',\n",
       "   '002ad9a41d6c',\n",
       "   '002b4293149f',\n",
       "   '0037f86827fc',\n",
       "   '00514a15a497',\n",
       "   '00555da4d13e',\n",
       "   '005b0e23b5d5',\n",
       "   '00660fd05fa7',\n",
       "   '006e2dc93e15',\n",
       "   '00777a15e411',\n",
       "   '0078a8c1aefd',\n",
       "   '007bea05ce8b',\n",
       "   '007f75dc5b13',\n",
       "   '00852dc4a8f8',\n",
       "   '0086caac613e',\n",
       "   '00881c47ec2f',\n",
       "   '008ad3b517ed',\n",
       "   '008ddd676829',\n",
       "   '008f38c8da01',\n",
       "   '0099604306b3',\n",
       "   '00abad96696a',\n",
       "   '00b0e8341965',\n",
       "   '00b9a33bb81f',\n",
       "   '00be927f89ab',\n",
       "   '00c64e4cd031',\n",
       "   '00cd031344d6',\n",
       "   '00d0c88bf952',\n",
       "   '00dc604a327d',\n",
       "   '00e97ebedb8a',\n",
       "   '00ebb2df916a',\n",
       "   '00ee2b300b93',\n",
       "   '00f30a0a1851',\n",
       "   '01010508c78c',\n",
       "   '0103bac3e4c5',\n",
       "   '01054c60a74b',\n",
       "   '0108b7898242',\n",
       "   '0126db676b5c',\n",
       "   '0132e668bef5',\n",
       "   '013a93929819',\n",
       "   '013ac02ee753',\n",
       "   '014c7dcc1805',\n",
       "   '015a70caff10',\n",
       "   '015af1ffb9e9',\n",
       "   '016f7c983e1a',\n",
       "   '017b2b5950b7',\n",
       "   '017beb27a328',\n",
       "   '018bb99f378e',\n",
       "   '019f96270dad',\n",
       "   '01a6eed31abb',\n",
       "   '01a9d29e11d0',\n",
       "   '01aa82adde90',\n",
       "   '01bace87a8ca',\n",
       "   '01c090982695',\n",
       "   '01cd4571a9c5',\n",
       "   '01d758d3b9ef',\n",
       "   '01dc6815573d',\n",
       "   '01dd92560877',\n",
       "   '01dfdc67abb4',\n",
       "   '01e57daf3792',\n",
       "   '01e786ad41f4',\n",
       "   '01f2ff720ca1',\n",
       "   '01f54c70d46b',\n",
       "   '01f8b0ded080',\n",
       "   '0200be746bf6',\n",
       "   '020b7fa0b326',\n",
       "   '020c63ec4b35',\n",
       "   '0213b0ab0980',\n",
       "   '0232d63472f7',\n",
       "   '02331c9dd59d',\n",
       "   '0248662e2c78',\n",
       "   '024bd81e538c',\n",
       "   '02593edd9dcf',\n",
       "   '025df2df9a37',\n",
       "   '026c20ce6dc4',\n",
       "   '027028d9bde3',\n",
       "   '027afa6fc5a2',\n",
       "   '0286c1223c5a',\n",
       "   '02895332c321',\n",
       "   '028b27877c10',\n",
       "   '029482385112',\n",
       "   '029b35f74526',\n",
       "   '029b77d8edc5',\n",
       "   '02a46ec65eda',\n",
       "   '02a4afe1c62f',\n",
       "   '02a543005871',\n",
       "   '02af2813611b',\n",
       "   '02b5114c779a',\n",
       "   '02b8ed232856',\n",
       "   '02bbd17887c1',\n",
       "   '02d322287866',\n",
       "   '02e055ad3d54',\n",
       "   '02e2899979ff',\n",
       "   '02eaf3040291',\n",
       "   '02f3945ec474',\n",
       "   '02f9493e4478',\n",
       "   '03005888c3ee',\n",
       "   '03011804df2a',\n",
       "   '03065cdbf766',\n",
       "   '03073f490cd5',\n",
       "   '030da18f9dbe',\n",
       "   '0311876815d1',\n",
       "   '0316d7e5df44',\n",
       "   '032580f1cb46',\n",
       "   '033281fc4608',\n",
       "   '0334334523f2',\n",
       "   '03356e90b08c',\n",
       "   '0344c819f9fc',\n",
       "   '034f59d2a2b6',\n",
       "   '035acb0a534c',\n",
       "   '03609e9ab716',\n",
       "   '0362f4faf050',\n",
       "   '0378275e395d',\n",
       "   '037e56d957e3',\n",
       "   '03839b49b297',\n",
       "   '038468c411bb',\n",
       "   '038616bedd81',\n",
       "   '03864b87e5d5',\n",
       "   '0394cbc345e8',\n",
       "   '03aafc794c37',\n",
       "   '03ace9b06076',\n",
       "   '03af4c0aa53f',\n",
       "   '03b3549b5abf',\n",
       "   '03b52ef93f2c',\n",
       "   '03b989b142df',\n",
       "   '03bff1292d9c',\n",
       "   '03c20bb966cb',\n",
       "   '03c38d86764e',\n",
       "   '03c4eaf9b98d',\n",
       "   '03c5ef696031',\n",
       "   '03d71dd7fca1',\n",
       "   '03d7ea27763f',\n",
       "   '03d812148b66',\n",
       "   '03d9b3adfc5c',\n",
       "   '03e454892701',\n",
       "   '03e94dc60823',\n",
       "   '03efb158d13c',\n",
       "   '03efea4c9a1b',\n",
       "   '03f4ccc0289c',\n",
       "   '03fa533aee11',\n",
       "   '040180bca2cc',\n",
       "   '040c7932dfde',\n",
       "   '04194339257e',\n",
       "   '0424cd3b13bb',\n",
       "   '042595bf2506',\n",
       "   '043317c43dd5',\n",
       "   '0434b6c60a39',\n",
       "   '043ff8992ec6',\n",
       "   '044383f60972',\n",
       "   '044473c7fcc2',\n",
       "   '04500c057f2b',\n",
       "   '046054fee6d5',\n",
       "   '0460ef2f61ce',\n",
       "   '04647ebeaa2c',\n",
       "   '047f817e27eb',\n",
       "   '04840369bb54',\n",
       "   '0485b6f6e008',\n",
       "   '048a85367977',\n",
       "   '049d89885fc2',\n",
       "   '04a629d5f671',\n",
       "   '04b1ae4257eb',\n",
       "   '04b35f2e10cb',\n",
       "   '04b79939a0ea',\n",
       "   '04ca33ca0707',\n",
       "   '04ca692983f8',\n",
       "   '04e3a26296f6',\n",
       "   '04e94eb13d69',\n",
       "   '04f020827223',\n",
       "   '04f35d12678d',\n",
       "   '04f3cbce8589',\n",
       "   '04f6f444672f',\n",
       "   '04fcaf4d395d',\n",
       "   '04fdceda33bc',\n",
       "   '051b52bfd42b',\n",
       "   '051b7c6a2cfb',\n",
       "   '0521ee1b4665',\n",
       "   '0540f47dec86',\n",
       "   '054cfd9a67ce',\n",
       "   '054fe8607270',\n",
       "   '05507ea0dbf7',\n",
       "   '05527a3163a8',\n",
       "   '05587e7e825b',\n",
       "   '05601ccf0efd',\n",
       "   '0566fd552a56',\n",
       "   '058078a46768',\n",
       "   '0589ca8d247d',\n",
       "   '058a6d5a31c2',\n",
       "   '0590fe56fced',\n",
       "   '05a7254d12d4',\n",
       "   '05b524828f43',\n",
       "   '05bc4c99c7fe',\n",
       "   '05bd7651c504',\n",
       "   '05c8ff7cd95d',\n",
       "   '05cbda4eee92',\n",
       "   '05d6d0c339d7',\n",
       "   '05f04bbf6efd',\n",
       "   '05f8ccaafbb5',\n",
       "   '05f95e3e7f07',\n",
       "   '05f9be6f76f4',\n",
       "   '0603bcfe9147',\n",
       "   '060a20697ec0',\n",
       "   '061310e7625b',\n",
       "   '061f697e5109',\n",
       "   '06376237b3a2',\n",
       "   '063991ed8967',\n",
       "   '063e7f2a714d',\n",
       "   '06402132e7a6',\n",
       "   '06494b4a9dca',\n",
       "   '064f4dbfc89d',\n",
       "   '065ddc08fbf4',\n",
       "   '066982244fb5',\n",
       "   '067264ce16ff',\n",
       "   '0678e99488bc',\n",
       "   '0684a980a2af',\n",
       "   '06959f0077ec',\n",
       "   '0695ce306bf1',\n",
       "   '069a9346ae53',\n",
       "   '069b5e629f36',\n",
       "   '069e9e80de88',\n",
       "   '06b37e86523a',\n",
       "   '06c260f44d72',\n",
       "   '06cc083e0d36',\n",
       "   '06d375f1f359',\n",
       "   '06d50a8f4e3a',\n",
       "   '06e14752c974',\n",
       "   '06e1b05169c5',\n",
       "   '06e3ffa6d3be',\n",
       "   '06fda0eebc7e',\n",
       "   '0712db3d73c6',\n",
       "   '0722bfb7d8b7',\n",
       "   '0728c366269d',\n",
       "   '072e8a5bae3f',\n",
       "   '073133dbe904',\n",
       "   '07418a59c9ec',\n",
       "   '074264ba0bf2',\n",
       "   '0755e72a8170',\n",
       "   '07627f64c7a8',\n",
       "   '07636284f4e6',\n",
       "   '0766bbc464da',\n",
       "   '076870fb4f6e',\n",
       "   '0769035b4f64',\n",
       "   '0771da6b2e1a',\n",
       "   '07738f7780df',\n",
       "   '0779702f21ca',\n",
       "   '07815b9165b5',\n",
       "   '07c53b240b01',\n",
       "   '07d44247ce39',\n",
       "   '07d60741970e',\n",
       "   '07e0d3b6de6d',\n",
       "   '07f377e4b159',\n",
       "   '07fe5bb99114',\n",
       "   '080400bd192b',\n",
       "   '08047e8a72ce',\n",
       "   '08058ca7cb45',\n",
       "   '081211515b71',\n",
       "   '081e2e24163d',\n",
       "   '081e7c5a55c6',\n",
       "   '0825edb4c985',\n",
       "   '083143c92cd1',\n",
       "   '083144fb1453',\n",
       "   '0851bb62d061',\n",
       "   '0852a2b3b127',\n",
       "   '0859720c1d98',\n",
       "   '085bec289fdd',\n",
       "   '08650834cee0',\n",
       "   '0866c1a979c3',\n",
       "   '0871368b476a',\n",
       "   '087d205cfb92',\n",
       "   '0880c44e0fa4',\n",
       "   '088294c59a00',\n",
       "   '0885e95b332c',\n",
       "   '08936f14b4f8',\n",
       "   '089e1d05b958',\n",
       "   '08b38a341a20',\n",
       "   '08baa4cd5db4',\n",
       "   '08bc6dd9d533',\n",
       "   '08be81d214d3',\n",
       "   '08c62e60b692',\n",
       "   '08c79d0822bf',\n",
       "   '08ce20f34bf2',\n",
       "   '08ce8c617a6b',\n",
       "   '08d5bde87212',\n",
       "   '08d84e21966f',\n",
       "   '08dfb1d3d332',\n",
       "   '08ef551f09fe',\n",
       "   '08fbecb50868',\n",
       "   '0903bac2144c',\n",
       "   '090cf9dd50ba',\n",
       "   '091618c022cd',\n",
       "   '091e8983f0c8',\n",
       "   '092ad3cd4c7f',\n",
       "   '092d1c8b6b55',\n",
       "   '093546249c7d',\n",
       "   '09412376a417',\n",
       "   '0942daae186e',\n",
       "   '094346ed26fd',\n",
       "   '0945339dedc8',\n",
       "   '095899d8debd',\n",
       "   '0959e162bd12',\n",
       "   '095acf723068',\n",
       "   '0968784ad222',\n",
       "   '09758690eda2',\n",
       "   '0998cb6a6681',\n",
       "   '099e6dc72d34',\n",
       "   '099e70ce2bc5',\n",
       "   '09a4e315994c',\n",
       "   '09b3b54fa342',\n",
       "   '09b6ac590e29',\n",
       "   '09b7fba39f2e',\n",
       "   '09d0ad5c9557',\n",
       "   '09df49047cf5',\n",
       "   '09e24d94fc99',\n",
       "   '09e2b2930fff',\n",
       "   '09f1c934596f',\n",
       "   '09f7b15139d0',\n",
       "   '09f92b4c6751',\n",
       "   '09f9da79e5ea',\n",
       "   '09fb4e4bbc45',\n",
       "   '09fcdb026a45',\n",
       "   '09fd4ecd6ef1',\n",
       "   '09fdb311fa82',\n",
       "   '0a069ab8cbab',\n",
       "   '0a18575bfefc',\n",
       "   '0a19f6f7ee15',\n",
       "   '0a2f66d10ad1',\n",
       "   '0a36d207ccca',\n",
       "   '0a3b8a6cb352',\n",
       "   '0a492ed4f5e5',\n",
       "   '0a5023a0b43b',\n",
       "   '0a511cd9492e',\n",
       "   '0a6a9868ad64',\n",
       "   '0a6ef4e42d38',\n",
       "   '0a725ea7ec56',\n",
       "   '0a7374549346',\n",
       "   '0a7c7f0fb687',\n",
       "   '0a7cf7a5bd09',\n",
       "   '0a854916b268',\n",
       "   '0a8a9303268d',\n",
       "   '0a8cc69ddb75',\n",
       "   '0a90a192a60b',\n",
       "   '0a9803025a3b',\n",
       "   '0a993390b99e',\n",
       "   '0a9f4e679fe2',\n",
       "   '0aa0535061cc',\n",
       "   '0aa3c84294dc',\n",
       "   '0ab51ae3a996',\n",
       "   '0ac13385b33f',\n",
       "   '0ac49c1ee456',\n",
       "   '0ac966a8bd62',\n",
       "   '0ad70b185bbe',\n",
       "   '0ad8210dbae1',\n",
       "   '0ad880961c5c',\n",
       "   '0ae118657c98',\n",
       "   '0ae139fd80f8',\n",
       "   '0ae37b032f53',\n",
       "   '0aec875213e7',\n",
       "   '0af0a1b91b37',\n",
       "   '0af5f373313c',\n",
       "   '0af919cf690e',\n",
       "   '0af9475d8527',\n",
       "   '0afede805da8',\n",
       "   '0b002a16f7e9',\n",
       "   '0b0325b320ee',\n",
       "   '0b176a2545af',\n",
       "   '0b1799ea38fd',\n",
       "   '0b1f054d198f',\n",
       "   '0b2021d26409',\n",
       "   '0b2557c251f7',\n",
       "   '0b2c41bc18cd',\n",
       "   '0b36e4263392',\n",
       "   '0b37349d902a',\n",
       "   '0b3dee90fdf3',\n",
       "   '0b4174323f76',\n",
       "   '0b4330a7c25a',\n",
       "   '0b46aee0d1fa',\n",
       "   '0b4f09a465e8',\n",
       "   '0b507195d88a',\n",
       "   '0b52eb2b4650',\n",
       "   '0b561f262df9',\n",
       "   '0b5e04ebd895',\n",
       "   '0b654cc04e8d',\n",
       "   '0b65756dd50f',\n",
       "   '0b72546edb87',\n",
       "   '0b8192ed96ed',\n",
       "   '0b8df69c12a1',\n",
       "   '0b907f3143c6',\n",
       "   '0b916e6f0690',\n",
       "   '0ba3f35f7fcf',\n",
       "   '0bac90cc45c1',\n",
       "   '0bb85f2a0b3b',\n",
       "   '0bba877ead8d',\n",
       "   '0bbd1d8ab904',\n",
       "   '0bda1b9f7b67',\n",
       "   '0be14ab7d63a',\n",
       "   '0be7589e82af',\n",
       "   '0be797753069',\n",
       "   '0c06d8c818a1',\n",
       "   '0c12ddd398a9',\n",
       "   '0c1378a29064',\n",
       "   '0c1e0b204b77',\n",
       "   '0c24fdd6348c',\n",
       "   '0c2766f0f9eb',\n",
       "   '0c280646479c',\n",
       "   '0c336a372b85',\n",
       "   '0c36423c1121',\n",
       "   '0c378e262c08',\n",
       "   '0c451e675ee4',\n",
       "   '0c4933ee4a84',\n",
       "   '0c4c15373bbd',\n",
       "   '0c5502b3eacb',\n",
       "   '0c602f4e893a',\n",
       "   '0c64c95e3b5b',\n",
       "   '0c8067ff2343',\n",
       "   '0c85e1ee279d',\n",
       "   '0c90990745da',\n",
       "   '0c95c287b9fb',\n",
       "   '0c9a285d8aa0',\n",
       "   '0ca0e30eb989',\n",
       "   '0cac357c2820',\n",
       "   '0cacbce72e83',\n",
       "   '0cad9fecf547',\n",
       "   '0cb1b0a018a6',\n",
       "   '0cb4861f2a22',\n",
       "   '0cc32a561870',\n",
       "   '0cc564def774',\n",
       "   '0cc781fc9c71',\n",
       "   '0ccd347285af',\n",
       "   '0cd3044bc3e6',\n",
       "   '0ce482945847',\n",
       "   '0ce90a8685ea',\n",
       "   '0cf4a3893e1e',\n",
       "   '0cff73b4743f',\n",
       "   '0d025226c2be',\n",
       "   '0d02a526311b',\n",
       "   '0d0ba6f7a1d3',\n",
       "   '0d11d07c746e',\n",
       "   '0d1ca3c5d9ea',\n",
       "   '0d1fc34808cb',\n",
       "   '0d2a72f1f842',\n",
       "   '0d2a7ab24aa9',\n",
       "   '0d2ba3d82223',\n",
       "   '0d31f07daf95',\n",
       "   '0d320c220d70',\n",
       "   '0d374cde199a',\n",
       "   '0d3befbbdca6',\n",
       "   '0d58ac7ba0d4',\n",
       "   '0d64ff3e44b0',\n",
       "   '0d70bccaec58',\n",
       "   '0d70c3ed6b4f',\n",
       "   '0d775bc73e23',\n",
       "   '0d8759d7f0e4',\n",
       "   '0d898122bb61',\n",
       "   '0d89ecd05943',\n",
       "   '0d99fcffdf8b',\n",
       "   '0d9eab495b3c',\n",
       "   '0da520a74e5e'],\n",
       "  'top_articles': [{'id': 'ded34fccd16a',\n",
       "    'title': '100x Faster\\u200a—\\u200aScaling Your RAG App for Billions of Embeddings',\n",
       "    'subtitle': 'Computing Cosine Similarity in parallel',\n",
       "    'author': 'b856005e5ecd',\n",
       "    'publication_id': '5517fd7b58a6',\n",
       "    'published_at': '2024-02-15 12:16:47',\n",
       "    'last_modified_at': '2024-02-15 12:16:47',\n",
       "    'tags': ['data-science',\n",
       "     'python',\n",
       "     'chatgpt',\n",
       "     'large-language-models',\n",
       "     'coding'],\n",
       "    'topics': ['machine-learning', 'data-science', 'programming'],\n",
       "    'claps': 276,\n",
       "    'voters': 38,\n",
       "    'word_count': 2310,\n",
       "    'responses_count': 0,\n",
       "    'reading_time': 9.966981132075471,\n",
       "    'url': 'https://levelup.gitconnected.com/100x-faster-scaling-your-rag-app-for-billions-of-embeddings-ded34fccd16a',\n",
       "    'unique_slug': '100x-faster-scaling-your-rag-app-for-billions-of-embeddings-ded34fccd16a',\n",
       "    'image_url': 'https://miro.medium.com/1*4Ry1nUyUXjrDE9L2GDRwEg.png',\n",
       "    'lang': 'en',\n",
       "    'is_series': False,\n",
       "    'is_locked': False,\n",
       "    'is_shortform': False,\n",
       "    'top_highlight': ''},\n",
       "   {'id': 'f612398f06c2',\n",
       "    'title': 'Building a Million-Parameter LLM from Scratch Using Python',\n",
       "    'subtitle': 'A Step-by-Step Guide to Replicating LLaMA Architecture',\n",
       "    'author': 'b856005e5ecd',\n",
       "    'publication_id': '5517fd7b58a6',\n",
       "    'published_at': '2023-12-07 14:55:24',\n",
       "    'last_modified_at': '2023-12-19 04:25:11',\n",
       "    'tags': ['artificial-intelligence',\n",
       "     'python',\n",
       "     'data-science',\n",
       "     'chatgpt',\n",
       "     'deep-learning'],\n",
       "    'topics': [],\n",
       "    'claps': 2426,\n",
       "    'voters': 645,\n",
       "    'word_count': 6094,\n",
       "    'responses_count': 31,\n",
       "    'reading_time': 24.796226415094342,\n",
       "    'url': 'https://levelup.gitconnected.com/building-a-million-parameter-llm-from-scratch-using-python-f612398f06c2',\n",
       "    'unique_slug': 'building-a-million-parameter-llm-from-scratch-using-python-f612398f06c2',\n",
       "    'image_url': 'https://miro.medium.com/1*ox3hToPFUWxAwURxYEXiGg.jpeg',\n",
       "    'lang': 'en',\n",
       "    'is_series': False,\n",
       "    'is_locked': False,\n",
       "    'is_shortform': False,\n",
       "    'top_highlight': '# Definition of a basic neural network class\\nclass SimpleBrokenModel(nn.Module):\\n    def __init__(self, config=MASTER_CONFIG):\\n\\n        # Rest of the code        \\n        ... \\n\\n        # Forward pass function for the base model\\n        def forward(self, idx, targets=None):\\n            # Embedding layer converts character indices to vectors\\n            x = self.embedding(idx)\\n            \\n            # Linear layers for modeling relationships between features\\n            a = self.linear(x)\\n            \\n            # Apply softmax activation to obtain probability distribution\\n            logits = F.softmax(a, dim=-1)\\n\\n            # If targets are provided, calculate and return the cross-entropy loss\\n            if targets is not None:\\n                # Reshape logits and targets for cross-entropy calculation\\n                loss = F.cross_entropy(logits.view(-1, self.config[\\'vocab_size\\']), targets.view(-1))\\n                return logits, loss\\n\\n            # If targets are not provided, return the logits\\n            else:\\n                return logits\\n\\n        # Print the total number of model parameters\\n        print(\"Model parameters:\", sum([m.numel() for m in self.parameters()]))'},\n",
       "   {'id': '969af38516b2',\n",
       "    'title': 'Chat with Graphs Intelligently',\n",
       "    'subtitle': 'Talking Graphs, Your Data Speaks Up',\n",
       "    'author': 'b856005e5ecd',\n",
       "    'publication_id': '5517fd7b58a6',\n",
       "    'published_at': '2024-01-23 04:01:22',\n",
       "    'last_modified_at': '2024-01-23 04:01:22',\n",
       "    'tags': ['data-science',\n",
       "     'data-visualization',\n",
       "     'python',\n",
       "     'artificial-intelligence',\n",
       "     'chatgpt'],\n",
       "    'topics': ['data-science', 'programming'],\n",
       "    'claps': 442,\n",
       "    'voters': 46,\n",
       "    'word_count': 1179,\n",
       "    'responses_count': 1,\n",
       "    'reading_time': 5.949056603773585,\n",
       "    'url': 'https://levelup.gitconnected.com/chat-with-graphs-intelligently-969af38516b2',\n",
       "    'unique_slug': 'chat-with-graphs-intelligently-969af38516b2',\n",
       "    'image_url': 'https://miro.medium.com/1*VrxMVWJjDT42bSvySMwYxw.png',\n",
       "    'lang': 'en',\n",
       "    'is_series': False,\n",
       "    'is_locked': False,\n",
       "    'is_shortform': False,\n",
       "    'top_highlight': ''},\n",
       "   {'id': 'e9390e2b9ed8',\n",
       "    'title': 'Create a Copilot inside your notebooks that can chat with graphs, write code and more',\n",
       "    'subtitle': 'An Intelligent Help for Efficient Programming',\n",
       "    'author': 'b856005e5ecd',\n",
       "    'publication_id': '5517fd7b58a6',\n",
       "    'published_at': '2024-01-11 15:39:01',\n",
       "    'last_modified_at': '2024-01-12 15:22:35',\n",
       "    'tags': ['python',\n",
       "     'github',\n",
       "     'machine-learning',\n",
       "     'programming',\n",
       "     'data-science'],\n",
       "    'topics': ['programming'],\n",
       "    'claps': 749,\n",
       "    'voters': 136,\n",
       "    'word_count': 3276,\n",
       "    'responses_count': 9,\n",
       "    'reading_time': 13.495597484276729,\n",
       "    'url': 'https://levelup.gitconnected.com/create-copilot-inside-your-notebooks-that-can-chat-with-graphs-write-code-and-more-e9390e2b9ed8',\n",
       "    'unique_slug': 'create-copilot-inside-your-notebooks-that-can-chat-with-graphs-write-code-and-more-e9390e2b9ed8',\n",
       "    'image_url': 'https://miro.medium.com/1*DETUd5sgj8GAQAVvLMrkEQ.png',\n",
       "    'lang': 'en',\n",
       "    'is_series': False,\n",
       "    'is_locked': False,\n",
       "    'is_shortform': False,\n",
       "    'top_highlight': ''},\n",
       "   {'id': '16d4e64e6eb1',\n",
       "    'title': 'Solving Transformer by Hand: A Step-by-Step Math Example',\n",
       "    'subtitle': 'Performing numerous matrix multiplications to solve the encoder and decoder parts of the transformer',\n",
       "    'author': 'b856005e5ecd',\n",
       "    'publication_id': '5517fd7b58a6',\n",
       "    'published_at': '2023-12-18 12:41:09',\n",
       "    'last_modified_at': '2023-12-21 04:19:24',\n",
       "    'tags': ['data-science',\n",
       "     'artificial-intelligence',\n",
       "     'machine-learning',\n",
       "     'python',\n",
       "     'deep-learning'],\n",
       "    'topics': ['machine-learning', 'data-science', 'programming'],\n",
       "    'claps': 1717,\n",
       "    'voters': 346,\n",
       "    'word_count': 2607,\n",
       "    'responses_count': 26,\n",
       "    'reading_time': 12.787735849056602,\n",
       "    'url': 'https://levelup.gitconnected.com/understanding-transformers-from-start-to-end-a-step-by-step-math-example-16d4e64e6eb1',\n",
       "    'unique_slug': 'understanding-transformers-from-start-to-end-a-step-by-step-math-example-16d4e64e6eb1',\n",
       "    'image_url': 'https://miro.medium.com/1*99eK1ktrNGPyt4IPowcAgg.png',\n",
       "    'lang': 'en',\n",
       "    'is_series': False,\n",
       "    'is_locked': False,\n",
       "    'is_shortform': False,\n",
       "    'top_highlight': 'When training, there are two inputs to the decoder. One is from the encoder, where the output matrix of the last add and norm layer serves as the query and key for the second multi-head attention layer in the decoder part. Below is the visualization of it (from batool haider):'},\n",
       "   {'id': '3e71f406338b',\n",
       "    'title': 'Free GenAI APIs You Can Use in 2024',\n",
       "    'subtitle': 'Exploring the Latest Free GenAI APIs',\n",
       "    'author': 'b856005e5ecd',\n",
       "    'publication_id': '5517fd7b58a6',\n",
       "    'published_at': '2024-02-04 18:47:29',\n",
       "    'last_modified_at': '2024-02-04 18:47:29',\n",
       "    'tags': ['api',\n",
       "     'artificial-intelligence',\n",
       "     'data-science',\n",
       "     'machine-learning',\n",
       "     'ai'],\n",
       "    'topics': ['programming'],\n",
       "    'claps': 240,\n",
       "    'voters': 22,\n",
       "    'word_count': 1304,\n",
       "    'responses_count': 4,\n",
       "    'reading_time': 5.304088050314466,\n",
       "    'url': 'https://levelup.gitconnected.com/free-genai-apis-you-can-use-in-2024-3e71f406338b',\n",
       "    'unique_slug': 'free-genai-apis-you-can-use-in-2024-3e71f406338b',\n",
       "    'image_url': 'https://miro.medium.com/1*jRaq7jiSFE1HivnUiIJxzQ.png',\n",
       "    'lang': 'en',\n",
       "    'is_series': False,\n",
       "    'is_locked': False,\n",
       "    'is_shortform': False,\n",
       "    'top_highlight': ''},\n",
       "   {'id': '2675c73080ff',\n",
       "    'title': 'Make your LLM aware of today’s Knowledge using Python',\n",
       "    'subtitle': 'A Classification Approach, Making LLM Knowledge-Aware',\n",
       "    'author': 'b856005e5ecd',\n",
       "    'publication_id': '5517fd7b58a6',\n",
       "    'published_at': '2024-01-30 18:32:09',\n",
       "    'last_modified_at': '2024-02-02 14:42:33',\n",
       "    'tags': ['data-science',\n",
       "     'python',\n",
       "     'machine-learning',\n",
       "     'deep-learning',\n",
       "     'programming'],\n",
       "    'topics': ['programming'],\n",
       "    'claps': 202,\n",
       "    'voters': 23,\n",
       "    'word_count': 3321,\n",
       "    'responses_count': 1,\n",
       "    'reading_time': 13.832075471698113,\n",
       "    'url': 'https://levelup.gitconnected.com/solve-llm-knowledge-cutoff-problem-with-python-2675c73080ff',\n",
       "    'unique_slug': 'solve-llm-knowledge-cutoff-problem-with-python-2675c73080ff',\n",
       "    'image_url': 'https://miro.medium.com/1*_bXvfeEEfLCQ7ekmUZh94w.png',\n",
       "    'lang': 'en',\n",
       "    'is_series': False,\n",
       "    'is_locked': False,\n",
       "    'is_shortform': False,\n",
       "    'top_highlight': ''},\n",
       "   {'id': '9a083d3811df',\n",
       "    'title': 'Convert Weak LLM to Strong LLM Using SPIN Technique',\n",
       "    'subtitle': 'Can we help a weak LLM get better without getting more data?',\n",
       "    'author': 'b856005e5ecd',\n",
       "    'publication_id': '5517fd7b58a6',\n",
       "    'published_at': '2024-01-16 23:24:01',\n",
       "    'last_modified_at': '2024-01-16 23:24:01',\n",
       "    'tags': ['machine-learning',\n",
       "     'deep-learning',\n",
       "     'large-language-models',\n",
       "     'ai',\n",
       "     'data-science'],\n",
       "    'topics': ['machine-learning'],\n",
       "    'claps': 75,\n",
       "    'voters': 12,\n",
       "    'word_count': 3289,\n",
       "    'responses_count': 3,\n",
       "    'reading_time': 13.711320754716981,\n",
       "    'url': 'https://levelup.gitconnected.com/convert-weak-llm-to-strong-llm-using-spin-technique-9a083d3811df',\n",
       "    'unique_slug': 'convert-weak-llm-to-strong-llm-using-spin-technique-9a083d3811df',\n",
       "    'image_url': 'https://miro.medium.com/1*thxroSFEju_2OFHme6mPVA.png',\n",
       "    'lang': 'en',\n",
       "    'is_series': False,\n",
       "    'is_locked': False,\n",
       "    'is_shortform': False,\n",
       "    'top_highlight': ''},\n",
       "   {'id': 'f3ebc8c42da3',\n",
       "    'title': 'Coding Stable Diffusion from Scratch',\n",
       "    'subtitle': 'A step by step guide of implementing diffusion model architecture.',\n",
       "    'author': 'b856005e5ecd',\n",
       "    'publication_id': '5517fd7b58a6',\n",
       "    'published_at': '2024-01-04 15:46:31',\n",
       "    'last_modified_at': '2024-01-10 12:03:43',\n",
       "    'tags': ['artificial-intelligence',\n",
       "     'data-science',\n",
       "     'stable-diffusion',\n",
       "     'python',\n",
       "     'machine-learning'],\n",
       "    'topics': [],\n",
       "    'claps': 438,\n",
       "    'voters': 69,\n",
       "    'word_count': 8669,\n",
       "    'responses_count': 6,\n",
       "    'reading_time': 34.46320754716981,\n",
       "    'url': 'https://levelup.gitconnected.com/building-stable-diffusion-from-scratch-using-python-f3ebc8c42da3',\n",
       "    'unique_slug': 'building-stable-diffusion-from-scratch-using-python-f3ebc8c42da3',\n",
       "    'image_url': 'https://miro.medium.com/1*pFNOzxb0_7WkcAyK5NhMxA.png',\n",
       "    'lang': 'en',\n",
       "    'is_series': False,\n",
       "    'is_locked': False,\n",
       "    'is_shortform': False,\n",
       "    'top_highlight': 'This choice is driven by the fact that a color image with 512x512 resolution has a huge number of potential values. In comparison, Stable Diffusion uses a compressed image that is 48 times smaller, containing fewer values. This significant reduction in processing requirements allows the use of Stable Diffusion on a desktop computer with an NVIDIA GPU featuring 8 GB of RAM. The effectiveness of the smaller latent space is based on the idea that natural images follow patterns rather than randomness. Stable Diffusion uses variational autoencoder (VAE) files in the decoder to capture intricate details such as eyes.'},\n",
       "   {'id': 'c26d08a55809',\n",
       "    'title': 'Building Powerful NLP Library in Python for 2024',\n",
       "    'subtitle': 'How Gemini by Google has transformed NLP tasks',\n",
       "    'author': 'b856005e5ecd',\n",
       "    'publication_id': '5517fd7b58a6',\n",
       "    'published_at': '2023-12-28 22:13:24',\n",
       "    'last_modified_at': '2024-01-01 09:32:00',\n",
       "    'tags': ['nlp',\n",
       "     'python',\n",
       "     'data-science',\n",
       "     'machine-learning',\n",
       "     'deep-learning'],\n",
       "    'topics': ['machine-learning', 'programming'],\n",
       "    'claps': 585,\n",
       "    'voters': 98,\n",
       "    'word_count': 3475,\n",
       "    'responses_count': 4,\n",
       "    'reading_time': 13.81320754716981,\n",
       "    'url': 'https://levelup.gitconnected.com/how-i-created-the-most-powerful-nlp-library-in-python-c26d08a55809',\n",
       "    'unique_slug': 'how-i-created-the-most-powerful-nlp-library-in-python-c26d08a55809',\n",
       "    'image_url': 'https://miro.medium.com/1*iW0G158ttjCvYxJd1aFWwg.png',\n",
       "    'lang': 'en',\n",
       "    'is_series': False,\n",
       "    'is_locked': False,\n",
       "    'is_shortform': False,\n",
       "    'top_highlight': ''}]},\n",
       " 'b0fbe613be9d': {'id': 'b0fbe613be9d',\n",
       "  'username': 'cobusgreyling',\n",
       "  'fullname': 'Cobus Greyling',\n",
       "  'bio': 'I explore and write about all things at the intersection of AI & language; LLMs/NLP/NLU, Chat/Voicebots, CCAI. www.cobusgreyling.com',\n",
       "  'followers_count': 16025,\n",
       "  'following_count': 0,\n",
       "  'publication_following_count': 0,\n",
       "  'image_url': 'https://miro.medium.com/1*nzfAEuujMN0s-aK6R7RcNg.jpeg',\n",
       "  'twitter_username': 'CobusGreylingZA',\n",
       "  'is_writer_program_enrolled': True,\n",
       "  'allow_notes': True,\n",
       "  'medium_member_at': '2019-08-02 11:35:19',\n",
       "  'is_suspended': False,\n",
       "  'top_writer_in': ['artificial-intelligence'],\n",
       "  'has_list': False,\n",
       "  'is_book_author': False,\n",
       "  'tipping_link': 'https://www.paypal.com/paypalme/cobusgreyling',\n",
       "  'bg_image_url': 'https://miro.medium.com/1*KiwJUvgoPmg22_obeK4SbA.jpeg',\n",
       "  'logo_image_url': '',\n",
       "  'followers': ['00245ad345da',\n",
       "   '00388d34235e',\n",
       "   '004bab759a12',\n",
       "   '0051a417ab48',\n",
       "   '005b0e23b5d5',\n",
       "   '005bd74ecb32',\n",
       "   '006a2946b9b9',\n",
       "   '006f9474ee69',\n",
       "   '00777a15e411',\n",
       "   '0099e6750330',\n",
       "   '009c5114926b',\n",
       "   '00a6814e9fb8',\n",
       "   '00ab25f608fa',\n",
       "   '00abad96696a',\n",
       "   '00ad050899b5',\n",
       "   '00b8eada8b79',\n",
       "   '00c864ade3db',\n",
       "   '00dd5ca6857d',\n",
       "   '00de22ec4707',\n",
       "   '00e650761df5',\n",
       "   '00f1dddb885d',\n",
       "   '01054c60a74b',\n",
       "   '0120fe55e44b',\n",
       "   '0126db676b5c',\n",
       "   '0141de4c4f7b',\n",
       "   '0158b5dca221',\n",
       "   '01600fd2aff6',\n",
       "   '017dd141af02',\n",
       "   '019f96270dad',\n",
       "   '01a9d29e11d0',\n",
       "   '01b0fa936fca',\n",
       "   '01b6b3976822',\n",
       "   '01cd4571a9c5',\n",
       "   '01ce5e8a5d48',\n",
       "   '01d758d3b9ef',\n",
       "   '01d92b58569d',\n",
       "   '01da1d589b4e',\n",
       "   '01daee96cb28',\n",
       "   '01dfdc67abb4',\n",
       "   '01f0841afdf5',\n",
       "   '01f8b0ded080',\n",
       "   '020b33c0820c',\n",
       "   '02196c29640d',\n",
       "   '021ec30c749e',\n",
       "   '0232d63472f7',\n",
       "   '02331c9dd59d',\n",
       "   '0248662e2c78',\n",
       "   '024bd81e538c',\n",
       "   '02593edd9dcf',\n",
       "   '025df2df9a37',\n",
       "   '0264b2e02184',\n",
       "   '027028d9bde3',\n",
       "   '0271142d456b',\n",
       "   '027591fe81d7',\n",
       "   '027b9b59cb41',\n",
       "   '028b27877c10',\n",
       "   '029482385112',\n",
       "   '02970a301007',\n",
       "   '029b77d8edc5',\n",
       "   '02a46ec65eda',\n",
       "   '02af31637544',\n",
       "   '02af5b038892',\n",
       "   '02b8ed232856',\n",
       "   '02c51431ff4c',\n",
       "   '02d7581eb08b',\n",
       "   '02d853f90ec1',\n",
       "   '02eaf3040291',\n",
       "   '02fcf4bdfdf6',\n",
       "   '030207032d8b',\n",
       "   '03138f5ff046',\n",
       "   '031ca58f8742',\n",
       "   '031e45ac1bd6',\n",
       "   '0332239585f9',\n",
       "   '0334334523f2',\n",
       "   '033eb7b3cdfd',\n",
       "   '033f73e79d6e',\n",
       "   '034f59d2a2b6',\n",
       "   '036fbff49afc',\n",
       "   '037cf47840d3',\n",
       "   '037eb302f1b6',\n",
       "   '03c3e57423f1',\n",
       "   '03d71dd7fca1',\n",
       "   '03d778a58360',\n",
       "   '03d7d3416226',\n",
       "   '03ea1b6e9b97',\n",
       "   '03f381560951',\n",
       "   '03fa533aee11',\n",
       "   '041f8af397cd',\n",
       "   '0423accc6932',\n",
       "   '0434b6c60a39',\n",
       "   '044550146f67',\n",
       "   '044b25e6c0eb',\n",
       "   '0462852c58a4',\n",
       "   '046a109f9648',\n",
       "   '046dee9c1a33',\n",
       "   '0481d9673dcc',\n",
       "   '04840369bb54',\n",
       "   '04890d43acab',\n",
       "   '049d89885fc2',\n",
       "   '049dbabe955a',\n",
       "   '04b64744fada',\n",
       "   '04b79939a0ea',\n",
       "   '04ca33ca0707',\n",
       "   '04d0adca0dc2',\n",
       "   '04e94eb13d69',\n",
       "   '04f020827223',\n",
       "   '04f35d12678d',\n",
       "   '051bf35d4e0a',\n",
       "   '0525226e118e',\n",
       "   '05372b6f54ff',\n",
       "   '054cfd9a67ce',\n",
       "   '05527a3163a8',\n",
       "   '0559b1b9bfc4',\n",
       "   '0559b94922c5',\n",
       "   '055df98e2677',\n",
       "   '05601ccf0efd',\n",
       "   '0562b33e89a3',\n",
       "   '056b75de06d7',\n",
       "   '056d17f08df8',\n",
       "   '05709ca39bb3',\n",
       "   '0587ee1a40da',\n",
       "   '0589ca8d247d',\n",
       "   '0591cd50fcdb',\n",
       "   '05a00331113c',\n",
       "   '05a10764b263',\n",
       "   '05e4d4eb693b',\n",
       "   '05eab01a40a6',\n",
       "   '05f3a138d526',\n",
       "   '05f804d1a69c',\n",
       "   '05f95e3e7f07',\n",
       "   '05f9be6f76f4',\n",
       "   '05fcc1d96571',\n",
       "   '063991ed8967',\n",
       "   '0672a591a4a1',\n",
       "   '06a8f81625eb',\n",
       "   '06a9a2bd4c5e',\n",
       "   '06be8ea40327',\n",
       "   '06cc423f3760',\n",
       "   '06e3d209c881',\n",
       "   '06f8412877e2',\n",
       "   '0706457043d4',\n",
       "   '070de554a633',\n",
       "   '0712db3d73c6',\n",
       "   '071be2e34da6',\n",
       "   '071da180c727',\n",
       "   '071ed49225de',\n",
       "   '072e3183dcf2',\n",
       "   '0731981a7119',\n",
       "   '0744a64a8eff',\n",
       "   '074762642b82',\n",
       "   '07517811cfb3',\n",
       "   '075d8e06a67c',\n",
       "   '07636284f4e6',\n",
       "   '0766bbc464da',\n",
       "   '076870fb4f6e',\n",
       "   '078604ebbecc',\n",
       "   '0788cbdf325a',\n",
       "   '078bed9d9616',\n",
       "   '078dd4777d70',\n",
       "   '079451d3c524',\n",
       "   '079b0ef0117b',\n",
       "   '07a551684cb2',\n",
       "   '07aa4860d532',\n",
       "   '07beec0f2f9d',\n",
       "   '07c3cddc4d66',\n",
       "   '07c53b240b01',\n",
       "   '07de4a549083',\n",
       "   '08097d4c62a1',\n",
       "   '081e1aca4f11',\n",
       "   '0827a93fb49b',\n",
       "   '082b1d58e0b4',\n",
       "   '084b1cee3202',\n",
       "   '0858cc0b2f80',\n",
       "   '0859720c1d98',\n",
       "   '086b4277d00d',\n",
       "   '087cbf9e23f1',\n",
       "   '0880c44e0fa4',\n",
       "   '0881e966615f',\n",
       "   '0882ed121944',\n",
       "   '0886e13a6860',\n",
       "   '08a1489a937a',\n",
       "   '08ab2e6fdb16',\n",
       "   '08b04d69f5d3',\n",
       "   '08b38a341a20',\n",
       "   '08b6783cd5ef',\n",
       "   '08ba2a0c4db5',\n",
       "   '08bcd3cc3efd',\n",
       "   '08c62e60b692',\n",
       "   '08ea0613c014',\n",
       "   '09084aba3069',\n",
       "   '0915a5517f4e',\n",
       "   '09368c4aac79',\n",
       "   '0938708a834b',\n",
       "   '093efab77c0b',\n",
       "   '09412376a417',\n",
       "   '09496b255385',\n",
       "   '095b039c6a5e',\n",
       "   '0960c8b08350',\n",
       "   '096cf59672b7',\n",
       "   '0986e03d8a26',\n",
       "   '098d6abcdc82',\n",
       "   '098e55095631',\n",
       "   '099e6dc72d34',\n",
       "   '099e70ce2bc5',\n",
       "   '09a0c86076d7',\n",
       "   '09ab165a53a1',\n",
       "   '09c3ad7a272d',\n",
       "   '09c4b362c0b1',\n",
       "   '09c5fa4cdb81',\n",
       "   '09ddcc706425',\n",
       "   '09f9da79e5ea',\n",
       "   '09fcab1a64ee',\n",
       "   '09fec82451d0',\n",
       "   '0a066f33751d',\n",
       "   '0a070cff554c',\n",
       "   '0a0861664640',\n",
       "   '0a13f9ab1a11',\n",
       "   '0a37c3725ff8',\n",
       "   '0a4b5de4d7da',\n",
       "   '0a56f844fb29',\n",
       "   '0a595e69a341',\n",
       "   '0a6a9868ad64',\n",
       "   '0a90a192a60b',\n",
       "   '0a993390b99e',\n",
       "   '0a9a98242d51',\n",
       "   '0aaecaf1814b',\n",
       "   '0ab51ae3a996',\n",
       "   '0ab88081d0d2',\n",
       "   '0abca50227a6',\n",
       "   '0ac13385b33f',\n",
       "   '0ac49c1ee456',\n",
       "   '0ac966a8bd62',\n",
       "   '0ac981d0a6a1',\n",
       "   '0ad63b3e1667',\n",
       "   '0adec660bc39',\n",
       "   '0ae37b032f53',\n",
       "   '0af0a1b91b37',\n",
       "   '0af5f373313c',\n",
       "   '0af9c51b5a85',\n",
       "   '0b02e13f26f5',\n",
       "   '0b1799ea38fd',\n",
       "   '0b1f054d198f',\n",
       "   '0b2c41bc18cd',\n",
       "   '0b3187c3d05f',\n",
       "   '0b44856d88c9',\n",
       "   '0b507195d88a',\n",
       "   '0b73331b18dc',\n",
       "   '0b73fc294bd6',\n",
       "   '0b7400307701',\n",
       "   '0b8df69c12a1',\n",
       "   '0b916e6f0690',\n",
       "   '0b94187ee8f5',\n",
       "   '0b96f6886a09',\n",
       "   '0b9d32aa10ca',\n",
       "   '0bae915b8dd8',\n",
       "   '0bb85f2a0b3b',\n",
       "   '0bbd1d8ab904',\n",
       "   '0bff4eb20707',\n",
       "   '0c0a64b7ec00',\n",
       "   '0c1c652993c2',\n",
       "   '0c31601f0d49',\n",
       "   '0c336a372b85',\n",
       "   '0c36423c1121',\n",
       "   '0c36b68c3f11',\n",
       "   '0c3b83b34c18',\n",
       "   '0c3f001991da',\n",
       "   '0c5632def34e',\n",
       "   '0c602f4e893a',\n",
       "   '0c6a8c669d5e',\n",
       "   '0c7c50e368b5',\n",
       "   '0c87a6f69a56',\n",
       "   '0c8f27bed63f',\n",
       "   '0c99e2df02ba',\n",
       "   '0c9a285d8aa0',\n",
       "   '0c9fd081753b',\n",
       "   '0cb1b0a018a6',\n",
       "   '0cd3044bc3e6',\n",
       "   '0ce2e7398143',\n",
       "   '0ce8acd83f29',\n",
       "   '0cf32b4f2b5a',\n",
       "   '0cf4a3893e1e',\n",
       "   '0cf61dc814cd',\n",
       "   '0cff73b4743f',\n",
       "   '0d025226c2be',\n",
       "   '0d08be4ad3f5',\n",
       "   '0d2949696dc1',\n",
       "   '0d41009efe5c',\n",
       "   '0d4195d44e4b',\n",
       "   '0d5e802362e6',\n",
       "   '0d5f2322ad0f',\n",
       "   '0d6a560df67d',\n",
       "   '0d7e3b2ccf93',\n",
       "   '0d8e7e958dc1',\n",
       "   '0d8f1fe315cb',\n",
       "   '0d90996c3229',\n",
       "   '0da0acafd64e',\n",
       "   '0da4abc1e3ef',\n",
       "   '0da7d7ee6581',\n",
       "   '0da9d5a107d6',\n",
       "   '0dc1178bb4ae',\n",
       "   '0dc7b0989b7a',\n",
       "   '0df97c23a854',\n",
       "   '0dff5db4c528',\n",
       "   '0e1177fd919f',\n",
       "   '0e12f8cc4094',\n",
       "   '0e1bf0c70ac7',\n",
       "   '0e1ed6728180',\n",
       "   '0e365ad5e60a',\n",
       "   '0e40f77ac6a3',\n",
       "   '0e4f2698d2b5',\n",
       "   '0e57fdddf48a',\n",
       "   '0e5faf098978',\n",
       "   '0e61305155f2',\n",
       "   '0e61f3697d54',\n",
       "   '0e62adbf8cbf',\n",
       "   '0e67cf807688',\n",
       "   '0e78f10c2cce',\n",
       "   '0e809eb771c1',\n",
       "   '0e80c3b2eecf',\n",
       "   '0e92d7f0ecf3',\n",
       "   '0ec9b1440c55',\n",
       "   '0ed3ab6a73d2',\n",
       "   '0ed5b971913f',\n",
       "   '0edc0a7f6f5c',\n",
       "   '0ee9c5d7c66c',\n",
       "   '0eeb4ac901e1',\n",
       "   '0efa91bc2ac7',\n",
       "   '0f0f0fb9d0c3',\n",
       "   '0f1be1d24f0b',\n",
       "   '0f23c2db73eb',\n",
       "   '0f27b22b653f',\n",
       "   '0f2a9dcf99b7',\n",
       "   '0f2d491c775b',\n",
       "   '0f35596f4b39',\n",
       "   '0f358c3768fe',\n",
       "   '0f3e3cee1388',\n",
       "   '0f426356c0d8',\n",
       "   '0f480e4548b5',\n",
       "   '0f4af9e138b2',\n",
       "   '0f62e8cc5c0b',\n",
       "   '0f67fb9705d2',\n",
       "   '0f6b9206626e',\n",
       "   '0f6d6cbe137e',\n",
       "   '0f8f92ad9e64',\n",
       "   '0f988a7a0e65',\n",
       "   '0fd3168dcaeb',\n",
       "   '0fd3da51cdac',\n",
       "   '0fec2acc9023',\n",
       "   '0ff632cf8f64',\n",
       "   '10008f996bda',\n",
       "   '100130cb5f3a',\n",
       "   '1004744b3d9d',\n",
       "   '1004be02ba7d',\n",
       "   '10086105f0e',\n",
       "   '100b43fd2650',\n",
       "   '100b53ebc8b8',\n",
       "   '101de089057b',\n",
       "   '101f95b892b2',\n",
       "   '101fc89f46ad',\n",
       "   '1025557181ec',\n",
       "   '102aa3aac04d',\n",
       "   '102e92a0608b',\n",
       "   '10325487d561',\n",
       "   '10333ed1635b',\n",
       "   '1034809bd5f1',\n",
       "   '10357a7524b1',\n",
       "   '1039eaf9905a',\n",
       "   '103aa2ff6182',\n",
       "   '103bba4b85cf',\n",
       "   '1044743b26ac',\n",
       "   '10497a096abc',\n",
       "   '104c7f23bfc6',\n",
       "   '104fb1e9c863',\n",
       "   '105d3157afbb',\n",
       "   '105fca20fc96',\n",
       "   '106454488e08',\n",
       "   '1064d0584a39',\n",
       "   '1071150c3802',\n",
       "   '107b99ca1de0',\n",
       "   '107cb4dd2f1e',\n",
       "   '107d44836680',\n",
       "   '107f0369703c',\n",
       "   '1080bb486c99',\n",
       "   '1083a1076980',\n",
       "   '10893048ab3f',\n",
       "   '108d4530c27c',\n",
       "   '10902c053179',\n",
       "   '109153aff456',\n",
       "   '1093cc9740c1',\n",
       "   '109d74952367',\n",
       "   '109db457e43f',\n",
       "   '109df8306904',\n",
       "   '109e0a11229d',\n",
       "   '10a209951983',\n",
       "   '10a213ff07af',\n",
       "   '10a8c2a3433d',\n",
       "   '10ae5a4cc69c',\n",
       "   '10aec8086600',\n",
       "   '10b34745d318',\n",
       "   '10b46356afd0',\n",
       "   '10bdada62df1',\n",
       "   '10c48fb7cf6d',\n",
       "   '10c6330f3732',\n",
       "   '10c9866a9c56',\n",
       "   '10ced7cc0adb',\n",
       "   '10cf78ee0cba',\n",
       "   '10d4097a3b78',\n",
       "   '10d6f62df7b6',\n",
       "   '10dbed0c83dc',\n",
       "   '10dc00bfb7c4',\n",
       "   '10de7cb84f80',\n",
       "   '10dee34829b',\n",
       "   '10e135f00548',\n",
       "   '10e4e51e349f',\n",
       "   '10e6c66c709a',\n",
       "   '10e7525cc9d4',\n",
       "   '10e76aaec395',\n",
       "   '10ed1a443915',\n",
       "   '10ed7cb7442e',\n",
       "   '10ef2b0e30d7',\n",
       "   '10f00002abe9',\n",
       "   '10f1e264cdfc',\n",
       "   '10f2f9e08f41',\n",
       "   '10fb881b36b',\n",
       "   '10fb972a5b01',\n",
       "   '1101b374a64',\n",
       "   '1103621af7f4',\n",
       "   '11073aa57e7',\n",
       "   '110caafc39e7',\n",
       "   '110f5f63a9b0',\n",
       "   '111041ec9681',\n",
       "   '1110f4d515a4',\n",
       "   '111148ed63d5',\n",
       "   '1114e0175910',\n",
       "   '11165e2ce11f',\n",
       "   '111bff8a7188',\n",
       "   '111cc0be3d32',\n",
       "   '112921ffe52a',\n",
       "   '112b67245303',\n",
       "   '112dc412e8ba',\n",
       "   '1130543621aa',\n",
       "   '1132935e33ab',\n",
       "   '1135a6d93d71',\n",
       "   '113bf76ff1a',\n",
       "   '1141afc2443f',\n",
       "   '1146b6c35b1',\n",
       "   '114916af26d8',\n",
       "   '114bb975ae25',\n",
       "   '114c978c1f10',\n",
       "   '114f9f2b1b5',\n",
       "   '1153056725a1',\n",
       "   '1161be8b3027',\n",
       "   '11636c743ee9',\n",
       "   '11668ac4b924',\n",
       "   '116dba0464c2',\n",
       "   '1170a5f15cf9',\n",
       "   '117187099f80',\n",
       "   '11723a0b4b18',\n",
       "   '117614d7351b',\n",
       "   '1186e860021b',\n",
       "   '11876ef067a9',\n",
       "   '118a628f8f88',\n",
       "   '118b9166dc9c',\n",
       "   '118ca9d38b10',\n",
       "   '118f6be90b94',\n",
       "   '119461a67189',\n",
       "   '119889921d00',\n",
       "   '11999502f8b',\n",
       "   '119a5cb08eb4',\n",
       "   '119a942fde97',\n",
       "   '119f35173888',\n",
       "   '11a03310f879',\n",
       "   '11a33aec74b4',\n",
       "   '11a959a13441',\n",
       "   '11abf527d1ce'],\n",
       "  'top_articles': [{'id': 'c06edaa78534',\n",
       "    'title': 'Demonstrate, Search, Predict (DSP) for LLMs',\n",
       "    'subtitle': 'This study which is just over a year old from Stanford, makes for interesting reading and illustrates how far we have come over as short…',\n",
       "    'author': 'b0fbe613be9d',\n",
       "    'publication_id': '*Self-Published*',\n",
       "    'published_at': '2024-02-16 08:18:20',\n",
       "    'last_modified_at': '2024-02-16 08:18:20',\n",
       "    'tags': ['ai',\n",
       "     'artificial-intelligence',\n",
       "     'machine-learning',\n",
       "     'large-language-models',\n",
       "     'conversational-ai'],\n",
       "    'topics': ['machine-learning'],\n",
       "    'claps': 65,\n",
       "    'voters': 9,\n",
       "    'word_count': 873,\n",
       "    'responses_count': 1,\n",
       "    'reading_time': 4.494339622641509,\n",
       "    'url': 'https://cobusgreyling.medium.com/demonstrate-search-predict-dsp-for-llms-c06edaa78534',\n",
       "    'unique_slug': 'demonstrate-search-predict-dsp-for-llms-c06edaa78534',\n",
       "    'image_url': 'https://miro.medium.com/1*54LE60qrXqdvlPMJWLPYNg.png',\n",
       "    'lang': 'en',\n",
       "    'is_series': False,\n",
       "    'is_locked': False,\n",
       "    'is_shortform': False,\n",
       "    'top_highlight': ''},\n",
       "   {'id': '9a5aaa01e437',\n",
       "    'title': 'T-RAG = RAG + Fine-Tuning + Entity Detection',\n",
       "    'subtitle': 'The T-RAG approach is premised on combining RAG architecture with an open-source fine-tuned LLM and an entities tree vector database. The…',\n",
       "    'author': 'b0fbe613be9d',\n",
       "    'publication_id': '*Self-Published*',\n",
       "    'published_at': '2024-02-15 09:08:22',\n",
       "    'last_modified_at': '2024-02-15 09:08:22',\n",
       "    'tags': ['ai',\n",
       "     'artificial-intelligence',\n",
       "     'large-language-models',\n",
       "     'machine-learning',\n",
       "     'conversational-ai'],\n",
       "    'topics': ['machine-learning', 'programming'],\n",
       "    'claps': 283,\n",
       "    'voters': 50,\n",
       "    'word_count': 874,\n",
       "    'responses_count': 2,\n",
       "    'reading_time': 4.34811320754717,\n",
       "    'url': 'https://cobusgreyling.medium.com/t-rag-rag-fine-tuning-entity-detection-9a5aaa01e437',\n",
       "    'unique_slug': 't-rag-rag-fine-tuning-entity-detection-9a5aaa01e437',\n",
       "    'image_url': 'https://miro.medium.com/1*1q3swfPylyxyN-BGOjwTrQ.png',\n",
       "    'lang': 'en',\n",
       "    'is_series': False,\n",
       "    'is_locked': False,\n",
       "    'is_shortform': False,\n",
       "    'top_highlight': 'Subsequently, this information is amalgamated with the document chunks retrieved from the vector database to construct the context.'},\n",
       "   {'id': '1f62a6cbdaef',\n",
       "    'title': 'Run A Small Language Model (SLM) Local & Offline',\n",
       "    'subtitle': 'One notable advantage of SLMs are their flexibility in deployment\\u200a—\\u200athey can be run locally or offline, providing users with greater…',\n",
       "    'author': 'b0fbe613be9d',\n",
       "    'publication_id': '*Self-Published*',\n",
       "    'published_at': '2024-02-14 08:46:14',\n",
       "    'last_modified_at': '2024-02-14 08:46:14',\n",
       "    'tags': ['ai',\n",
       "     'artificial-intelligence',\n",
       "     'machine-learning',\n",
       "     'technology',\n",
       "     'conversational-ai'],\n",
       "    'topics': ['machine-learning'],\n",
       "    'claps': 345,\n",
       "    'voters': 45,\n",
       "    'word_count': 1156,\n",
       "    'responses_count': 1,\n",
       "    'reading_time': 5.612264150943396,\n",
       "    'url': 'https://cobusgreyling.medium.com/run-a-small-language-model-slm-local-offline-1f62a6cbdaef',\n",
       "    'unique_slug': 'run-a-small-language-model-slm-local-offline-1f62a6cbdaef',\n",
       "    'image_url': 'https://miro.medium.com/1*9EaS5q1U-uYJ25wQ5FBxMQ.png',\n",
       "    'lang': 'en',\n",
       "    'is_series': False,\n",
       "    'is_locked': False,\n",
       "    'is_shortform': False,\n",
       "    'top_highlight': 'It demonstrates nearly state-of-the-art performance in common sense, language understanding, and logical reasoning, despite having fewer parameters.'},\n",
       "   {'id': 'd088c69be2fb',\n",
       "    'title': 'The Case For Small Language Models',\n",
       "    'subtitle': 'Microsoft Phi-2 is a small language model capable of common-sense reasoning, language understanding, generation and more…',\n",
       "    'author': 'b0fbe613be9d',\n",
       "    'publication_id': '*Self-Published*',\n",
       "    'published_at': '2024-02-13 10:02:42',\n",
       "    'last_modified_at': '2024-02-13 10:02:42',\n",
       "    'tags': ['ai',\n",
       "     'artificial-intelligence',\n",
       "     'machine-learning',\n",
       "     'conversational-ai',\n",
       "     'chatbots'],\n",
       "    'topics': ['artificial-intelligence', 'machine-learning'],\n",
       "    'claps': 383,\n",
       "    'voters': 22,\n",
       "    'word_count': 1689,\n",
       "    'responses_count': 1,\n",
       "    'reading_time': 7.506918238993711,\n",
       "    'url': 'https://cobusgreyling.medium.com/the-case-for-small-language-models-d088c69be2fb',\n",
       "    'unique_slug': 'the-case-for-small-language-models-d088c69be2fb',\n",
       "    'image_url': 'https://miro.medium.com/1*BIBopB2C6AicmwqpzhLfOA.png',\n",
       "    'lang': 'en',\n",
       "    'is_series': False,\n",
       "    'is_locked': False,\n",
       "    'is_shortform': False,\n",
       "    'top_highlight': ''},\n",
       "   {'id': '3594ee338467',\n",
       "    'title': 'Beyond Chain-of-Thought LLM Reasoning',\n",
       "    'subtitle': 'This approach can be implemented on a prompt level and does not require any dedicated frameworks or pre-processing.',\n",
       "    'author': 'b0fbe613be9d',\n",
       "    'publication_id': '*Self-Published*',\n",
       "    'published_at': '2024-02-12 18:42:55',\n",
       "    'last_modified_at': '2024-02-12 18:43:17',\n",
       "    'tags': ['ai',\n",
       "     'artificial-intelligence',\n",
       "     'machine-learning',\n",
       "     'prompt-engineering',\n",
       "     'conversational-ai'],\n",
       "    'topics': ['artificial-intelligence', 'machine-learning'],\n",
       "    'claps': 90,\n",
       "    'voters': 8,\n",
       "    'word_count': 689,\n",
       "    'responses_count': 0,\n",
       "    'reading_time': 3.7333333333333334,\n",
       "    'url': 'https://cobusgreyling.medium.com/beyond-chain-of-thought-llm-reasoning-3594ee338467',\n",
       "    'unique_slug': 'beyond-chain-of-thought-llm-reasoning-3594ee338467',\n",
       "    'image_url': 'https://miro.medium.com/1*i2s2TWgy5bqxdimGEnbvxA.png',\n",
       "    'lang': 'en',\n",
       "    'is_series': False,\n",
       "    'is_locked': False,\n",
       "    'is_shortform': False,\n",
       "    'top_highlight': ''},\n",
       "   {'id': '44c6d6f7c2f6',\n",
       "    'title': 'Comparing Human, LLM & LLM-RAG Responses',\n",
       "    'subtitle': 'A recent study, focusing on the healthcare & preoperative medicine compared expert human feedback with LLM generation and RAG enhanced…',\n",
       "    'author': 'b0fbe613be9d',\n",
       "    'publication_id': '*Self-Published*',\n",
       "    'published_at': '2024-02-09 12:08:15',\n",
       "    'last_modified_at': '2024-02-09 12:08:15',\n",
       "    'tags': ['ai',\n",
       "     'artificial-intelligence',\n",
       "     'machine-learning',\n",
       "     'large-language-models',\n",
       "     'prompt-engineering'],\n",
       "    'topics': ['artificial-intelligence', 'data-science'],\n",
       "    'claps': 187,\n",
       "    'voters': 24,\n",
       "    'word_count': 546,\n",
       "    'responses_count': 0,\n",
       "    'reading_time': 3.110377358490566,\n",
       "    'url': 'https://cobusgreyling.medium.com/comparing-human-llm-llm-rag-responses-44c6d6f7c2f6',\n",
       "    'unique_slug': 'comparing-human-llm-llm-rag-responses-44c6d6f7c2f6',\n",
       "    'image_url': 'https://miro.medium.com/1*ltyLqlHdBxOqKlrnWLlCUw.png',\n",
       "    'lang': 'en',\n",
       "    'is_series': False,\n",
       "    'is_locked': False,\n",
       "    'is_shortform': False,\n",
       "    'top_highlight': ''},\n",
       "   {'id': 'f574bb9a405e',\n",
       "    'title': 'Craft Successful Conversational User Interfaces: Align User Intent With Developed Intent',\n",
       "    'subtitle': 'In this article I illustrate how to achieve intent alignment by making use of the Kore.ai XO Platform Intent Discovery Tool.',\n",
       "    'author': 'b0fbe613be9d',\n",
       "    'publication_id': '*Self-Published*',\n",
       "    'published_at': '2024-02-08 12:11:10',\n",
       "    'last_modified_at': '2024-02-08 15:20:53',\n",
       "    'tags': ['ai',\n",
       "     'artificial-intelligence',\n",
       "     'conversational-ai',\n",
       "     'conversational-ui',\n",
       "     'chatbots'],\n",
       "    'topics': ['artificial-intelligence'],\n",
       "    'claps': 43,\n",
       "    'voters': 4,\n",
       "    'word_count': 1446,\n",
       "    'responses_count': 1,\n",
       "    'reading_time': 6.656603773584906,\n",
       "    'url': 'https://cobusgreyling.medium.com/craft-successful-conversational-user-interfaces-align-user-intent-with-developed-intent-f574bb9a405e',\n",
       "    'unique_slug': 'craft-successful-conversational-user-interfaces-align-user-intent-with-developed-intent-f574bb9a405e',\n",
       "    'image_url': 'https://miro.medium.com/1*282CBGj0AItCB_EiEMmMIA.png',\n",
       "    'lang': 'en',\n",
       "    'is_series': False,\n",
       "    'is_locked': False,\n",
       "    'is_shortform': False,\n",
       "    'top_highlight': ''},\n",
       "   {'id': '904db5ebeefa',\n",
       "    'title': 'A Benchmark for Verifying Chain-Of-Thought',\n",
       "    'subtitle': 'A Chain-of-Thought is only as strong as its weakest link; a recent study from Google Research created a benchmark for Verifiers of…',\n",
       "    'author': 'b0fbe613be9d',\n",
       "    'publication_id': '*Self-Published*',\n",
       "    'published_at': '2024-02-07 20:56:54',\n",
       "    'last_modified_at': '2024-02-07 20:56:54',\n",
       "    'tags': ['ai',\n",
       "     'artificial-intelligence',\n",
       "     'large-language-models',\n",
       "     'machine-learning',\n",
       "     'conversational-ai'],\n",
       "    'topics': ['machine-learning', 'data-science'],\n",
       "    'claps': 148,\n",
       "    'voters': 5,\n",
       "    'word_count': 816,\n",
       "    'responses_count': 0,\n",
       "    'reading_time': 4.379245283018868,\n",
       "    'url': 'https://cobusgreyling.medium.com/a-benchmark-for-verifying-chain-of-thought-904db5ebeefa',\n",
       "    'unique_slug': 'a-benchmark-for-verifying-chain-of-thought-904db5ebeefa',\n",
       "    'image_url': 'https://miro.medium.com/1*9gQtv8MpXKXt7qKdmh7NRw.png',\n",
       "    'lang': 'en',\n",
       "    'is_series': False,\n",
       "    'is_locked': False,\n",
       "    'is_shortform': False,\n",
       "    'top_highlight': ''},\n",
       "   {'id': '02ead9cc2532',\n",
       "    'title': 'Seven RAG Engineering Failure Points',\n",
       "    'subtitle': 'Retrieval-Augmented Generation (RAG) systems remains a compelling solution to the challenge of relevant up-to-date reference data at…',\n",
       "    'author': 'b0fbe613be9d',\n",
       "    'publication_id': '*Self-Published*',\n",
       "    'published_at': '2024-02-06 14:44:18',\n",
       "    'last_modified_at': '2024-02-06 14:44:18',\n",
       "    'tags': ['ai',\n",
       "     'artificial-intelligence',\n",
       "     'machine-learning',\n",
       "     'large-language-models',\n",
       "     'conversational-ai'],\n",
       "    'topics': ['machine-learning', 'programming'],\n",
       "    'claps': 211,\n",
       "    'voters': 18,\n",
       "    'word_count': 1429,\n",
       "    'responses_count': 0,\n",
       "    'reading_time': 6.092452830188679,\n",
       "    'url': 'https://cobusgreyling.medium.com/seven-rag-engineering-failure-points-02ead9cc2532',\n",
       "    'unique_slug': 'seven-rag-engineering-failure-points-02ead9cc2532',\n",
       "    'image_url': 'https://miro.medium.com/1*ZBt1IUgsv4fKMhWbQJkVqQ.png',\n",
       "    'lang': 'en',\n",
       "    'is_series': False,\n",
       "    'is_locked': False,\n",
       "    'is_shortform': False,\n",
       "    'top_highlight': ''},\n",
       "   {'id': 'f6f3c38656b9',\n",
       "    'title': 'OpenAI Agent Query Planning Using LlamaIndex',\n",
       "    'subtitle': 'Agentic RAG can be described as an agent based approach to perform question answering over multiple documents in an orchestrated fashion…',\n",
       "    'author': 'b0fbe613be9d',\n",
       "    'publication_id': '*Self-Published*',\n",
       "    'published_at': '2024-02-05 15:36:21',\n",
       "    'last_modified_at': '2024-02-05 15:36:21',\n",
       "    'tags': ['ai',\n",
       "     'artificial-intelligence',\n",
       "     'large-language-models',\n",
       "     'machine-learning',\n",
       "     'conversational-ai'],\n",
       "    'topics': ['programming'],\n",
       "    'claps': 46,\n",
       "    'voters': 9,\n",
       "    'word_count': 667,\n",
       "    'responses_count': 0,\n",
       "    'reading_time': 3.466981132075472,\n",
       "    'url': 'https://cobusgreyling.medium.com/openai-agent-query-planning-using-llamaindex-f6f3c38656b9',\n",
       "    'unique_slug': 'openai-agent-query-planning-using-llamaindex-f6f3c38656b9',\n",
       "    'image_url': 'https://miro.medium.com/1*JcQ5Nt-Rz1xBJjVYTTv4rw.png',\n",
       "    'lang': 'en',\n",
       "    'is_series': False,\n",
       "    'is_locked': False,\n",
       "    'is_shortform': False,\n",
       "    'top_highlight': ''}]},\n",
       " '14176fcb5743': {'id': '14176fcb5743',\n",
       "  'username': 'inchristiely',\n",
       "  'fullname': 'Christie C.',\n",
       "  'bio': '🎨 AI Art Educator & Creator | 5 x Top Writer | Master Midjourney❤️Turn AI Art into Cash 💰👉🏻 https://bit.ly/MidjourneyPrompt',\n",
       "  'followers_count': 56048,\n",
       "  'following_count': 121,\n",
       "  'publication_following_count': 19,\n",
       "  'image_url': 'https://miro.medium.com/1*yuFGmpFZLaaqPADFQ7pOTw.jpeg',\n",
       "  'twitter_username': '',\n",
       "  'is_writer_program_enrolled': True,\n",
       "  'allow_notes': True,\n",
       "  'medium_member_at': '2023-01-04 07:53:34',\n",
       "  'is_suspended': False,\n",
       "  'top_writer_in': ['art',\n",
       "   'design',\n",
       "   'creativity',\n",
       "   'artificial-intelligence',\n",
       "   'future'],\n",
       "  'has_list': True,\n",
       "  'is_book_author': False,\n",
       "  'tipping_link': 'https://www.buymeacoffee.com/inchristie',\n",
       "  'bg_image_url': 'https://miro.medium.com/1*zSvLnsT4bqSA_CqA5ms2sA.png',\n",
       "  'logo_image_url': '',\n",
       "  'followers': ['00008456a9f0',\n",
       "   '0000a6571897',\n",
       "   '00032ca4b88c',\n",
       "   '00045a935c88',\n",
       "   '0004b0e05369',\n",
       "   '0006c15d8338',\n",
       "   '000c187af99b',\n",
       "   '000eb90e70d8',\n",
       "   '00116aa9884a',\n",
       "   '00149b7421b2',\n",
       "   '001564222f42',\n",
       "   '00160071cea3',\n",
       "   '00180712c53d',\n",
       "   '001aa2fef563',\n",
       "   '001d3500f024',\n",
       "   '002324d8d54e',\n",
       "   '0023a4a5cccf',\n",
       "   '00245ad345da',\n",
       "   '0024d33e6c7d',\n",
       "   '0026b2c6e32d',\n",
       "   '002b3b17db23',\n",
       "   '002e56e573db',\n",
       "   '002f357f1a1c',\n",
       "   '00301e37f53a',\n",
       "   '0031244c509e',\n",
       "   '0034535aa881',\n",
       "   '00348dfc8976',\n",
       "   '0036dfd4faf4',\n",
       "   '0037f86827fc',\n",
       "   '00388d34235e',\n",
       "   '003a91d0f9a1',\n",
       "   '003e441c0874',\n",
       "   '003f7ff5f599',\n",
       "   '003fe511835f',\n",
       "   '0041541f90e4',\n",
       "   '004279a3a73e',\n",
       "   '0045f7ba4422',\n",
       "   '0046ffb589fe',\n",
       "   '004a8030a14f',\n",
       "   '004aff8458fb',\n",
       "   '004daca42132',\n",
       "   '004e20cb72b3',\n",
       "   '005144e861bb',\n",
       "   '0055540ed1c8',\n",
       "   '0056cb1a6eaf',\n",
       "   '0058b5cae97b',\n",
       "   '005956b07565',\n",
       "   '005a95dd3e00',\n",
       "   '005b0e23b5d5',\n",
       "   '005e8316fae9',\n",
       "   '0064a097f654',\n",
       "   '00651cee34db',\n",
       "   '00660fd05fa7',\n",
       "   '00688c9cb4b6',\n",
       "   '006a2946b9b9',\n",
       "   '006be6184a29',\n",
       "   '006d5db8f610',\n",
       "   '007091a67938',\n",
       "   '007248b58676',\n",
       "   '0076c2a4fccc',\n",
       "   '00777a15e411',\n",
       "   '007ea42d4cc5',\n",
       "   '007f75dc5b13',\n",
       "   '007fe78a3458',\n",
       "   '0081b869b24d',\n",
       "   '00828a580394',\n",
       "   '008336b15cb2',\n",
       "   '0086caac613e',\n",
       "   '0086ebd600be',\n",
       "   '008ad0baf6ff',\n",
       "   '008b7bf66892',\n",
       "   '008bd264da31',\n",
       "   '008cb99a7973',\n",
       "   '008e42d846db',\n",
       "   '009390c0458d',\n",
       "   '0097be63ad9b',\n",
       "   '009a07908d63',\n",
       "   '009a793747ae',\n",
       "   '009daf38588f',\n",
       "   '009ee6c6d2d7',\n",
       "   '00a07f50ac66',\n",
       "   '00a338135b96',\n",
       "   '00a6814e9fb8',\n",
       "   '00a7f4726d5b',\n",
       "   '00abad96696a',\n",
       "   '00ad050899b5',\n",
       "   '00af43322bed',\n",
       "   '00b86c239ae9',\n",
       "   '00b8eada8b79',\n",
       "   '00b9a33bb81f',\n",
       "   '00bedca4ccd6',\n",
       "   '00bf37dfa958',\n",
       "   '00bf54d77b79',\n",
       "   '00c10cc7fc78',\n",
       "   '00c3d47c9bdc',\n",
       "   '00c70b8be752',\n",
       "   '00c864ade3db',\n",
       "   '00ca80653208',\n",
       "   '00cd031344d6',\n",
       "   '00cd0905c7a9',\n",
       "   '00d0c88bf952',\n",
       "   '00d626d8279f',\n",
       "   '00da4ebaf9e6',\n",
       "   '00dd762aef3b',\n",
       "   '00de22ec4707',\n",
       "   '00dfb9d3a6ba',\n",
       "   '00e279792601',\n",
       "   '00e64025302f',\n",
       "   '00e8f72cbac1',\n",
       "   '00e974fe1be5',\n",
       "   '00e97ebedb8a',\n",
       "   '00ebb2df916a',\n",
       "   '00ee2b300b93',\n",
       "   '00f1dddb885d',\n",
       "   '00f24bcd7bd7',\n",
       "   '00f29e780193',\n",
       "   '00f2d8152332',\n",
       "   '00f3825d8b3a',\n",
       "   '00f91a736e7a',\n",
       "   '00f9656b27a7',\n",
       "   '00fc6797fe4b',\n",
       "   '00fcb9e6c880',\n",
       "   '0100bfad1385',\n",
       "   '0102838e5346',\n",
       "   '010285d248a0',\n",
       "   '01054c60a74b',\n",
       "   '010740fb5f37',\n",
       "   '0109e784bcf3',\n",
       "   '010c2c4a5e25',\n",
       "   '0115c36ef483',\n",
       "   '0115c4d222bc',\n",
       "   '0119c2b70e94',\n",
       "   '011ac46681d4',\n",
       "   '011c896e89a2',\n",
       "   '0122867c5794',\n",
       "   '01247722f2d2',\n",
       "   '012b181e1fba',\n",
       "   '012cbb376227',\n",
       "   '012fdb5da8ec',\n",
       "   '0130f859c87c',\n",
       "   '013141d04d67',\n",
       "   '0132641e0bd2',\n",
       "   '0139c54af843',\n",
       "   '013a93929819',\n",
       "   '0140b0fcc755',\n",
       "   '0142dce745d6',\n",
       "   '0143b7013542',\n",
       "   '01446399ce9a',\n",
       "   '014670628993',\n",
       "   '014791450ac1',\n",
       "   '0147ce94e2c1',\n",
       "   '01480dc32f54',\n",
       "   '0148ce17a280',\n",
       "   '014ab4e7800a',\n",
       "   '014b50f2b8a9',\n",
       "   '014c7dcc1805',\n",
       "   '014d1f452bc8',\n",
       "   '014d530d567c',\n",
       "   '014efbc1c2ff',\n",
       "   '015426ced173',\n",
       "   '0158b5dca221',\n",
       "   '015d2558fb2e',\n",
       "   '015dbcb25f80',\n",
       "   '015fb2f70943',\n",
       "   '0160350ca03d',\n",
       "   '01611624d56b',\n",
       "   '016248200680',\n",
       "   '01663a4bdf0c',\n",
       "   '016bc359f30c',\n",
       "   '016e2f04b248',\n",
       "   '017686580bb5',\n",
       "   '01782b701a24',\n",
       "   '017974e6b3bb',\n",
       "   '0179a5ea3099',\n",
       "   '017b2b5950b7',\n",
       "   '017beb27a328',\n",
       "   '017dd141af02',\n",
       "   '017fdc964e67',\n",
       "   '0180d9a03889',\n",
       "   '01821004b009',\n",
       "   '01881ecb24b2',\n",
       "   '018b35c4d3dc',\n",
       "   '018bb99f378e',\n",
       "   '018c1b2876b5',\n",
       "   '018e38713fca',\n",
       "   '0197500bd26c',\n",
       "   '01987da15355',\n",
       "   '019bfb4cf3ff',\n",
       "   '019c80d76690',\n",
       "   '01a1ba538f61',\n",
       "   '01a6eed31abb',\n",
       "   '01a81a9a1134',\n",
       "   '01a9c1259fcc',\n",
       "   '01a9d29e11d0',\n",
       "   '01ad1d61b5e2',\n",
       "   '01ae5a74d887',\n",
       "   '01aff610f2c5',\n",
       "   '01b0fa936fca',\n",
       "   '01b12abe8016',\n",
       "   '01b20a505427',\n",
       "   '01b59d1c170a',\n",
       "   '01bace87a8ca',\n",
       "   '01bbf69759fd',\n",
       "   '01c016e994f9',\n",
       "   '01c090982695',\n",
       "   '01c2c1fff3a7',\n",
       "   '01d173ab023a',\n",
       "   '01d592a3b772',\n",
       "   '01d64214e662',\n",
       "   '01d6ca04e85f',\n",
       "   '01d9c405c912',\n",
       "   '01d9cc1c64d3',\n",
       "   '01dab43fcca6',\n",
       "   '01dc6815573d',\n",
       "   '01debae60774',\n",
       "   '01e22e257aad',\n",
       "   '01e5530ef612',\n",
       "   '01e76051e5c1',\n",
       "   '01ea7518f437',\n",
       "   '01eb5edb6a57',\n",
       "   '01ec1a0c6bf3',\n",
       "   '01ec83891f8e',\n",
       "   '01f0841afdf5',\n",
       "   '01f21095700f',\n",
       "   '01f41843a8eb',\n",
       "   '01f918c8ca17',\n",
       "   '01faad01498c',\n",
       "   '01ff5e54d902',\n",
       "   '0200be746bf6',\n",
       "   '0202f7d65d9e',\n",
       "   '0203ae1ce789',\n",
       "   '0205d9c2fbf4',\n",
       "   '0209e4300043',\n",
       "   '020b33c0820c',\n",
       "   '020b8507aeb0',\n",
       "   '020c3a9002e5',\n",
       "   '020ed720c5ee',\n",
       "   '020f9dcc253c',\n",
       "   '0212a3c23533',\n",
       "   '021355eb0717',\n",
       "   '0213b0ab0980',\n",
       "   '0213d25f83a0',\n",
       "   '0215ad7ba320',\n",
       "   '0216cd8af098',\n",
       "   '021750e3b2b9',\n",
       "   '02176f2d6293',\n",
       "   '02197edcb979',\n",
       "   '021a5907125c',\n",
       "   '021d519b5bc3',\n",
       "   '021ec30c749e',\n",
       "   '0221ae9122c4',\n",
       "   '0222ca211b33',\n",
       "   '022a3f515cba',\n",
       "   '022e978e0155',\n",
       "   '0231ff0dbc3a',\n",
       "   '023559818fbc',\n",
       "   '02357e0b8347',\n",
       "   '0239d6bfe7fd',\n",
       "   '023f4705461f',\n",
       "   '02453bf6fb4f',\n",
       "   '024976a0ff7c',\n",
       "   '0249960b42f0',\n",
       "   '024d46d48ec8',\n",
       "   '0254c3fc1245',\n",
       "   '0255a6b87784',\n",
       "   '0257c7496d5f',\n",
       "   '0258cd7dd371',\n",
       "   '02597f14885e',\n",
       "   '025c47d6e1fb',\n",
       "   '025dd53e105c',\n",
       "   '025df2df9a37',\n",
       "   '025e3eb1f404',\n",
       "   '026498e585a6',\n",
       "   '02654ae74f51',\n",
       "   '026cd15d4c81',\n",
       "   '026d06779866',\n",
       "   '026f0b914ddd',\n",
       "   '026f620d992f',\n",
       "   '027028d9bde3',\n",
       "   '0273d8927bef',\n",
       "   '0274127db0fa',\n",
       "   '02755bb63273',\n",
       "   '0276082a3a87',\n",
       "   '027657869777',\n",
       "   '027b9b59cb41',\n",
       "   '027c98ccc223',\n",
       "   '02816671a5e7',\n",
       "   '028770318e79',\n",
       "   '0287accaaf1d',\n",
       "   '028b27877c10',\n",
       "   '028cbd441505',\n",
       "   '02942f450ffe',\n",
       "   '029482385112',\n",
       "   '02975fb9e397',\n",
       "   '029b35f74526',\n",
       "   '029b77d8edc5',\n",
       "   '02a00a2d45c3',\n",
       "   '02a46ec65eda',\n",
       "   '02a4afe1c62f',\n",
       "   '02a53fac2eb5',\n",
       "   '02af5b038892',\n",
       "   '02b0cba4f85e',\n",
       "   '02b22a27378a',\n",
       "   '02b471d26b4b',\n",
       "   '02b5114c779a',\n",
       "   '02b5c8f6c7bf',\n",
       "   '02b5d0a9dea7',\n",
       "   '02b847074ab7',\n",
       "   '02b8509caa67',\n",
       "   '02b99eb02d96',\n",
       "   '02bbd17887c1',\n",
       "   '02bed666ac14',\n",
       "   '02c49d343b8e',\n",
       "   '02c6e523d977',\n",
       "   '02c963384c80',\n",
       "   '02c9c79d1812',\n",
       "   '02ca76513457',\n",
       "   '02ce0f83f004',\n",
       "   '02d6b32e6591',\n",
       "   '02d7581eb08b',\n",
       "   '02e055ad3d54',\n",
       "   '02e057389c47',\n",
       "   '02e46356161d',\n",
       "   '02e6cab3305f',\n",
       "   '02e793cf0306',\n",
       "   '02eabc5afc9b',\n",
       "   '02eaf3040291',\n",
       "   '02eef590a42c',\n",
       "   '02f9493e4478',\n",
       "   '02f982b6308e',\n",
       "   '02fe3a80da7b',\n",
       "   '03005888c3ee',\n",
       "   '03009c312966',\n",
       "   '03011804df2a',\n",
       "   '0301f0276167',\n",
       "   '030207032d8b',\n",
       "   '0304608d6585',\n",
       "   '030b3b29d1d4',\n",
       "   '0312c2e01765',\n",
       "   '03133540481d',\n",
       "   '03138f5ff046',\n",
       "   '0315db4cbe86',\n",
       "   '031c9b856d55',\n",
       "   '031ca58f8742',\n",
       "   '031ce2fc805a',\n",
       "   '031e45ac1bd6',\n",
       "   '031febdd6afe',\n",
       "   '032447a310fa',\n",
       "   '032580f1cb46',\n",
       "   '032c92283903',\n",
       "   '032d8a21f407',\n",
       "   '0332239585f9',\n",
       "   '0334334523f2',\n",
       "   '033dddc0e361',\n",
       "   '03401f344e2a',\n",
       "   '0343c6cde955',\n",
       "   '0344c819f9fc',\n",
       "   '03470591377f',\n",
       "   '0348267ad688',\n",
       "   '03487d9e6ab6',\n",
       "   '034b64e5bbf2',\n",
       "   '034da96e10dc',\n",
       "   '034f2c13e874',\n",
       "   '03561c8d445b',\n",
       "   '0356a6d54d75',\n",
       "   '03587a17e4f1',\n",
       "   '0358fb7e422b',\n",
       "   '035e5ae9177b',\n",
       "   '0362aca28985',\n",
       "   '0362f4faf050',\n",
       "   '0368e0999892',\n",
       "   '036ada4f9da0',\n",
       "   '036c957356d8',\n",
       "   '036ecf5a78de',\n",
       "   '037352fe2d13',\n",
       "   '0375742afb7f',\n",
       "   '03778713d516',\n",
       "   '037a8786167e',\n",
       "   '037c22fae1ce',\n",
       "   '037cf47840d3',\n",
       "   '037dfc0eaffb',\n",
       "   '037e56d957e3',\n",
       "   '03809bbd4626',\n",
       "   '03815a1f922d',\n",
       "   '03839b49b297',\n",
       "   '038616bedd81',\n",
       "   '03880d7392d7',\n",
       "   '038881c812d8',\n",
       "   '038a09a9c2c1',\n",
       "   '038ac12ed38b',\n",
       "   '038c023a62bf',\n",
       "   '038e46d6da63',\n",
       "   '038edce6cec6',\n",
       "   '0394aaa1403a',\n",
       "   '03954ee233b7',\n",
       "   '039568695bb5',\n",
       "   '0396e51ec32d',\n",
       "   '039e1349ed1d',\n",
       "   '03a3c9504dff',\n",
       "   '03ac41fac508',\n",
       "   '03ac9a983caa',\n",
       "   '03af4c0aa53f',\n",
       "   '03b0e8ccce84',\n",
       "   '03b31424b5a4',\n",
       "   '03b3549b5abf',\n",
       "   '03b4a1b945c1',\n",
       "   '03b52ef93f2c',\n",
       "   '03b54aaa3027',\n",
       "   '03b9cff66a17',\n",
       "   '03ba95901a24',\n",
       "   '03bc0f18c610',\n",
       "   '03bcb370b730',\n",
       "   '03bff1292d9c',\n",
       "   '03c167203c08',\n",
       "   '03c1c3820c90',\n",
       "   '03c2df878679',\n",
       "   '03c5ef696031',\n",
       "   '03c77847c9a6',\n",
       "   '03ca893966eb',\n",
       "   '03cc3c502760',\n",
       "   '03d06374eaac',\n",
       "   '03d6b850b7b5',\n",
       "   '03d71dd7fca1',\n",
       "   '03d778a58360',\n",
       "   '03d7b2786a8c',\n",
       "   '03d7d3416226',\n",
       "   '03d8ea1ba078',\n",
       "   '03d93b246494',\n",
       "   '03da2b9ffebc',\n",
       "   '03dfd549f1aa',\n",
       "   '03e454892701',\n",
       "   '03e527c257f9',\n",
       "   '03e667074fb8',\n",
       "   '03e714ce1e2a',\n",
       "   '03efbae57fbc',\n",
       "   '03f2be916786',\n",
       "   '03f381560951',\n",
       "   '03f3abdfa2aa',\n",
       "   '03f4ccc0289c',\n",
       "   '03f811a2765f',\n",
       "   '03f9d334c243',\n",
       "   '03fa389c69ac',\n",
       "   '03fc2e37c371',\n",
       "   '040180bca2cc',\n",
       "   '0404526e704b',\n",
       "   '04059ff14c46',\n",
       "   '040692a0066c',\n",
       "   '0407e146f755',\n",
       "   '0408a97d7661',\n",
       "   '0408febca528',\n",
       "   '0409b232ec6e',\n",
       "   '040b368f8924',\n",
       "   '040b73d4cbfb',\n",
       "   '0410469b15fa',\n",
       "   '0416970847cc',\n",
       "   '04192f6ae7b7',\n",
       "   '04194339257e',\n",
       "   '041a215c25fb',\n",
       "   '041d24ea93ee',\n",
       "   '041d615444f5',\n",
       "   '0421dfe57484',\n",
       "   '0424cd3b13bb',\n",
       "   '0428ee002a03',\n",
       "   '042e1dbf2616',\n",
       "   '04300428355f',\n",
       "   '04320f7be488',\n",
       "   '0434b6c60a39',\n",
       "   '04384c3f6ee2',\n",
       "   '043fcaeb2430',\n",
       "   '043fe8379c89',\n",
       "   '043ff8992ec6',\n",
       "   '04417a0f362d',\n",
       "   '044473c7fcc2',\n",
       "   '04452136d200',\n",
       "   '044550146f67',\n",
       "   '044e80535091'],\n",
       "  'top_articles': [{'id': '6921c4f43c2a',\n",
       "    'title': 'Midjourney V6 New Prompting Technique\\u200a—\\u200aIntroduction to “The 4W1H” 🎨',\n",
       "    'subtitle': 'Elevate Your Prompt Writing Structure & Skills',\n",
       "    'author': '14176fcb5743',\n",
       "    'publication_id': '48e972f5c24e',\n",
       "    'published_at': '2023-12-27 13:01:24',\n",
       "    'last_modified_at': '2024-01-24 02:48:22',\n",
       "    'tags': ['midjourney',\n",
       "     'artificial-intelligence',\n",
       "     'creativity',\n",
       "     'design',\n",
       "     'art'],\n",
       "    'topics': ['design'],\n",
       "    'claps': 2487,\n",
       "    'voters': 382,\n",
       "    'word_count': 1369,\n",
       "    'responses_count': 25,\n",
       "    'reading_time': 6.666037735849057,\n",
       "    'url': 'https://bootcamp.uxdesign.cc/midjourney-v6-new-prompting-technique-introduction-to-the-4w1h-6921c4f43c2a',\n",
       "    'unique_slug': 'midjourney-v6-new-prompting-technique-introduction-to-the-4w1h-6921c4f43c2a',\n",
       "    'image_url': 'https://miro.medium.com/1*2QvnFaQZQzbV04MAZcfUJQ.png',\n",
       "    'lang': 'en',\n",
       "    'is_series': False,\n",
       "    'is_locked': True,\n",
       "    'is_shortform': False,\n",
       "    'top_highlight': 'By breaking down the elements of your artwork into What, Who, When, Where, and How, you will assist Midjourney in gaining a deeper understanding of your creative thoughts.'},\n",
       "   {'id': 'b467aa07365e',\n",
       "    'title': '9 Midjourney V6. Prompting Technique You Need to Know 🎨',\n",
       "    'subtitle': 'Relearn Prompt Writing to Take Your AI Art to the Next Level!',\n",
       "    'author': '14176fcb5743',\n",
       "    'publication_id': '48e972f5c24e',\n",
       "    'published_at': '2024-01-19 13:01:48',\n",
       "    'last_modified_at': '2024-02-12 10:11:21',\n",
       "    'tags': ['midjourney',\n",
       "     'artificial-intelligence',\n",
       "     'creativity',\n",
       "     'design',\n",
       "     'art'],\n",
       "    'topics': ['artificial-intelligence', 'design', 'programming'],\n",
       "    'claps': 1143,\n",
       "    'voters': 132,\n",
       "    'word_count': 1887,\n",
       "    'responses_count': 10,\n",
       "    'reading_time': 9.070754716981131,\n",
       "    'url': 'https://bootcamp.uxdesign.cc/9-midjourney-v6-prompting-technique-you-need-to-know-b467aa07365e',\n",
       "    'unique_slug': '9-midjourney-v6-prompting-technique-you-need-to-know-b467aa07365e',\n",
       "    'image_url': 'https://miro.medium.com/1*EgyE5HYnjwDhLjJR04NPcw.png',\n",
       "    'lang': 'en',\n",
       "    'is_series': False,\n",
       "    'is_locked': True,\n",
       "    'is_shortform': False,\n",
       "    'top_highlight': ''},\n",
       "   {'id': '5afc5b228cb3',\n",
       "    'title': 'One Magical Midjourney Prompt to Elevate Your Creativity!',\n",
       "    'subtitle': 'Level Up Your AI Image with this One Word',\n",
       "    'author': '14176fcb5743',\n",
       "    'publication_id': '48e972f5c24e',\n",
       "    'published_at': '2023-11-13 13:02:01',\n",
       "    'last_modified_at': '2023-12-19 09:34:03',\n",
       "    'tags': ['midjourney',\n",
       "     'artificial-intelligence',\n",
       "     'creativity',\n",
       "     'design',\n",
       "     'art'],\n",
       "    'topics': ['design'],\n",
       "    'claps': 830,\n",
       "    'voters': 85,\n",
       "    'word_count': 1186,\n",
       "    'responses_count': 14,\n",
       "    'reading_time': 6.225471698113208,\n",
       "    'url': 'https://bootcamp.uxdesign.cc/one-magical-midjourney-prompt-to-elevate-your-creativity-5afc5b228cb3',\n",
       "    'unique_slug': 'one-magical-midjourney-prompt-to-elevate-your-creativity-5afc5b228cb3',\n",
       "    'image_url': 'https://miro.medium.com/1*9LYsteVtPZ629V14eYA17A.png',\n",
       "    'lang': 'en',\n",
       "    'is_series': False,\n",
       "    'is_locked': True,\n",
       "    'is_shortform': False,\n",
       "    'top_highlight': 'Prompt: [ People ], picking a [ Food ], bright studio light, [ Color ] background, minimalist, miniature food photography, soft color blending --ar 3:4'},\n",
       "   {'id': '71196de661cb',\n",
       "    'title': '20+ Incredible Midjourney Prompts You Must Try!',\n",
       "    'subtitle': 'Elevate Your AI Arts with These Creative Prompts',\n",
       "    'author': '14176fcb5743',\n",
       "    'publication_id': '48e972f5c24e',\n",
       "    'published_at': '2023-11-06 13:01:59',\n",
       "    'last_modified_at': '2024-01-18 01:36:25',\n",
       "    'tags': ['midjourney',\n",
       "     'artificial-intelligence',\n",
       "     'creativity',\n",
       "     'art',\n",
       "     'design'],\n",
       "    'topics': ['artificial-intelligence', 'design'],\n",
       "    'claps': 1112,\n",
       "    'voters': 160,\n",
       "    'word_count': 1278,\n",
       "    'responses_count': 20,\n",
       "    'reading_time': 6.722641509433963,\n",
       "    'url': 'https://bootcamp.uxdesign.cc/x20-incredible-midjourney-prompts-you-must-try-71196de661cb',\n",
       "    'unique_slug': 'x20-incredible-midjourney-prompts-you-must-try-71196de661cb',\n",
       "    'image_url': 'https://miro.medium.com/1*aYQLn2P3QdFqB-d8UdfZNA.png',\n",
       "    'lang': 'en',\n",
       "    'is_series': False,\n",
       "    'is_locked': True,\n",
       "    'is_shortform': False,\n",
       "    'top_highlight': 'Prompt: Blacklight planet in the galaxy, fancy dreamy'},\n",
       "   {'id': '27e9975cce9c',\n",
       "    'title': 'Midjourney Comprehensive Guide: Commands, Features and Tricks here!',\n",
       "    'subtitle': 'How to Use Midjourney to Elevate Your Images and Creativity',\n",
       "    'author': '14176fcb5743',\n",
       "    'publication_id': '48e972f5c24e',\n",
       "    'published_at': '2023-07-30 13:02:32',\n",
       "    'last_modified_at': '2024-01-04 03:03:59',\n",
       "    'tags': ['midjourney',\n",
       "     'artificial-intelligence',\n",
       "     'creativity',\n",
       "     'design',\n",
       "     'future'],\n",
       "    'topics': ['design'],\n",
       "    'claps': 1085,\n",
       "    'voters': 193,\n",
       "    'word_count': 1998,\n",
       "    'responses_count': 18,\n",
       "    'reading_time': 9.489622641509433,\n",
       "    'url': 'https://bootcamp.uxdesign.cc/a-comprehensive-midjourney-guide-commands-features-and-tricks-here-27e9975cce9c',\n",
       "    'unique_slug': 'a-comprehensive-midjourney-guide-commands-features-and-tricks-here-27e9975cce9c',\n",
       "    'image_url': 'https://miro.medium.com/1*jARZCchLet3ZIpvMvN01Qg.png',\n",
       "    'lang': 'en',\n",
       "    'is_series': False,\n",
       "    'is_locked': True,\n",
       "    'is_shortform': False,\n",
       "    'top_highlight': 'Using the same seed number will produce a similar style.'},\n",
       "   {'id': 'da3e4b1ac900',\n",
       "    'title': 'Top 12 Visual Design Trends for 2024 That Boost Engagement (Part 2)',\n",
       "    'subtitle': 'The Hottest Creative Styles to Captivate Audiences This Year',\n",
       "    'author': '14176fcb5743',\n",
       "    'publication_id': '*Self-Published*',\n",
       "    'published_at': '2024-02-18 13:01:39',\n",
       "    'last_modified_at': '2024-02-18 13:01:39',\n",
       "    'tags': ['midjourney',\n",
       "     'artificial-intelligence',\n",
       "     'creativity',\n",
       "     'design',\n",
       "     'make-money'],\n",
       "    'topics': ['design'],\n",
       "    'claps': 336,\n",
       "    'voters': 18,\n",
       "    'word_count': 1327,\n",
       "    'responses_count': 5,\n",
       "    'reading_time': 7.007547169811321,\n",
       "    'url': 'https://medium.com/@inchristiely/top-12-visual-design-trends-for-2024-that-boost-engagement-part-2-da3e4b1ac900',\n",
       "    'unique_slug': 'top-12-visual-design-trends-for-2024-that-boost-engagement-part-2-da3e4b1ac900',\n",
       "    'image_url': 'https://miro.medium.com/1*AUCseY5Vt4MMvTlUwf6zpA.png',\n",
       "    'lang': 'en',\n",
       "    'is_series': False,\n",
       "    'is_locked': True,\n",
       "    'is_shortform': False,\n",
       "    'top_highlight': ''},\n",
       "   {'id': '572cd5758aa6',\n",
       "    'title': 'Top 12 Visual Design Trends for 2024 That Boost Engagement',\n",
       "    'subtitle': 'The Hottest Creative Styles to Captivate Audiences This Year',\n",
       "    'author': '14176fcb5743',\n",
       "    'publication_id': '48e972f5c24e',\n",
       "    'published_at': '2024-02-17 13:01:57',\n",
       "    'last_modified_at': '2024-02-17 21:52:30',\n",
       "    'tags': ['design', 'creativity', 'art', 'midjourney', 'make-money-online'],\n",
       "    'topics': ['design'],\n",
       "    'claps': 410,\n",
       "    'voters': 26,\n",
       "    'word_count': 1313,\n",
       "    'responses_count': 2,\n",
       "    'reading_time': 6.904716981132076,\n",
       "    'url': 'https://bootcamp.uxdesign.cc/top-12-visual-design-trends-for-2024-that-boost-engagement-572cd5758aa6',\n",
       "    'unique_slug': 'top-12-visual-design-trends-for-2024-that-boost-engagement-572cd5758aa6',\n",
       "    'image_url': 'https://miro.medium.com/1*D0D5XzAIxQ7ywOYPVNbyag.png',\n",
       "    'lang': 'en',\n",
       "    'is_series': False,\n",
       "    'is_locked': True,\n",
       "    'is_shortform': False,\n",
       "    'top_highlight': ''},\n",
       "   {'id': '865c0b54d1cb',\n",
       "    'title': 'Midjourney V6 Alpha is Now the Default with Improvements to Details, Contrast and Coherence🔥',\n",
       "    'subtitle': 'Prepared for NEW “describe” and “Character Consistency” Coming Soon!',\n",
       "    'author': '14176fcb5743',\n",
       "    'publication_id': '48e972f5c24e',\n",
       "    'published_at': '2024-02-15 13:02:01',\n",
       "    'last_modified_at': '2024-02-15 23:48:39',\n",
       "    'tags': ['midjourney',\n",
       "     'artificial-intelligence',\n",
       "     'creativity',\n",
       "     'design',\n",
       "     'art'],\n",
       "    'topics': ['design', 'programming'],\n",
       "    'claps': 163,\n",
       "    'voters': 11,\n",
       "    'word_count': 1155,\n",
       "    'responses_count': 2,\n",
       "    'reading_time': 5.758490566037736,\n",
       "    'url': 'https://bootcamp.uxdesign.cc/midjourney-v6-alpha-is-now-the-default-with-improvements-to-details-contrast-and-coherence-865c0b54d1cb',\n",
       "    'unique_slug': 'midjourney-v6-alpha-is-now-the-default-with-improvements-to-details-contrast-and-coherence-865c0b54d1cb',\n",
       "    'image_url': 'https://miro.medium.com/1*wybK0zuHORyKn8YH0AAELQ.png',\n",
       "    'lang': 'en',\n",
       "    'is_series': False,\n",
       "    'is_locked': True,\n",
       "    'is_shortform': False,\n",
       "    'top_highlight': ''},\n",
       "   {'id': '6e8d6357da20',\n",
       "    'title': 'Midjourney V6 Essential- Transform Style with “Remix” 🎨',\n",
       "    'subtitle': 'A Structure to follow with Visual Examples and Usage',\n",
       "    'author': '14176fcb5743',\n",
       "    'publication_id': '48e972f5c24e',\n",
       "    'published_at': '2024-02-12 13:01:48',\n",
       "    'last_modified_at': '2024-02-12 22:20:55',\n",
       "    'tags': ['midjourney',\n",
       "     'artificial-intelligence',\n",
       "     'creativity',\n",
       "     'design',\n",
       "     'art'],\n",
       "    'topics': ['design'],\n",
       "    'claps': 416,\n",
       "    'voters': 25,\n",
       "    'word_count': 1279,\n",
       "    'responses_count': 5,\n",
       "    'reading_time': 6.576415094339622,\n",
       "    'url': 'https://bootcamp.uxdesign.cc/midjourney-v6-essential-transform-style-with-remix-6e8d6357da20',\n",
       "    'unique_slug': 'midjourney-v6-essential-transform-style-with-remix-6e8d6357da20',\n",
       "    'image_url': 'https://miro.medium.com/1*SrQ7YHs4cumUYkm1j5Kxfw.png',\n",
       "    'lang': 'en',\n",
       "    'is_series': False,\n",
       "    'is_locked': True,\n",
       "    'is_shortform': False,\n",
       "    'top_highlight': ''},\n",
       "   {'id': '92741d8fb067',\n",
       "    'title': 'Ultimate Guide to Using Midjourney Website Alpha! 💻',\n",
       "    'subtitle': 'Image Generation, Batch download and Smart Organisation with Ease!',\n",
       "    'author': '14176fcb5743',\n",
       "    'publication_id': '48e972f5c24e',\n",
       "    'published_at': '2024-02-09 13:01:32',\n",
       "    'last_modified_at': '2024-02-09 21:42:14',\n",
       "    'tags': ['midjourney',\n",
       "     'artificial-intelligence',\n",
       "     'creativity',\n",
       "     'design',\n",
       "     'art'],\n",
       "    'topics': ['design'],\n",
       "    'claps': 584,\n",
       "    'voters': 55,\n",
       "    'word_count': 1139,\n",
       "    'responses_count': 7,\n",
       "    'reading_time': 6.44811320754717,\n",
       "    'url': 'https://bootcamp.uxdesign.cc/ultimate-guide-to-using-midjourney-website-alpha-92741d8fb067',\n",
       "    'unique_slug': 'ultimate-guide-to-using-midjourney-website-alpha-92741d8fb067',\n",
       "    'image_url': 'https://miro.medium.com/1*wkYFlLubAFBU-8aWHkqtfQ.png',\n",
       "    'lang': 'en',\n",
       "    'is_series': False,\n",
       "    'is_locked': True,\n",
       "    'is_shortform': False,\n",
       "    'top_highlight': ''}]},\n",
       " '9b351e8113e9': {'id': '9b351e8113e9',\n",
       "  'username': 'ignacio.de.gregorio.noblejas',\n",
       "  'fullname': 'Ignacio de Gregorio',\n",
       "  'bio': 'I break down the most advanced AI systems in the world for you. Sign up for my newsletter at https://thetechoasis.beehiiv.com/subscribe',\n",
       "  'followers_count': 71934,\n",
       "  'following_count': 25,\n",
       "  'publication_following_count': 0,\n",
       "  'image_url': 'https://miro.medium.com/1*p6kCCpNZARkVEYv4OCH7GQ@2x.jpeg',\n",
       "  'twitter_username': 'TheTechOasis1',\n",
       "  'is_writer_program_enrolled': True,\n",
       "  'allow_notes': True,\n",
       "  'medium_member_at': '2022-06-12 09:31:55',\n",
       "  'is_suspended': False,\n",
       "  'top_writer_in': ['future',\n",
       "   'technology',\n",
       "   'business',\n",
       "   'artificial-intelligence'],\n",
       "  'has_list': False,\n",
       "  'is_book_author': False,\n",
       "  'tipping_link': 'https://ko-fi.com/ignaciodegregorio',\n",
       "  'bg_image_url': '',\n",
       "  'logo_image_url': '',\n",
       "  'followers': ['00017297cca0',\n",
       "   '0002df3940d5',\n",
       "   '00032ca4b88c',\n",
       "   '0006c15d8338',\n",
       "   '0008a90f7d7f',\n",
       "   '000bf9dc5e4c',\n",
       "   '000df73e666e',\n",
       "   '00116aa9884a',\n",
       "   '00117ef3e7b2',\n",
       "   '001479440872',\n",
       "   '00149b7421b2',\n",
       "   '00153b23a790',\n",
       "   '001564222f42',\n",
       "   '00160071cea3',\n",
       "   '00171b7cf6ea',\n",
       "   '00183ef79cce',\n",
       "   '001982a8e04f',\n",
       "   '001aa2fef563',\n",
       "   '001cda02fcc8',\n",
       "   '001d3500f024',\n",
       "   '001df7788a05',\n",
       "   '001fd5bb3ac9',\n",
       "   '0023a4a5cccf',\n",
       "   '00245ad345da',\n",
       "   '0024e4c6beba',\n",
       "   '00281ba99460',\n",
       "   '002ea8cbcfe6',\n",
       "   '0030bf7bb342',\n",
       "   '0031a66e1c0a',\n",
       "   '00348dfc8976',\n",
       "   '003a91d0f9a1',\n",
       "   '003f7ff5f599',\n",
       "   '00456e4a5913',\n",
       "   '00461627c883',\n",
       "   '0048c34d88d1',\n",
       "   '004bab759a12',\n",
       "   '004c5bf99ca3',\n",
       "   '005144e861bb',\n",
       "   '00514a15a497',\n",
       "   '005383618362',\n",
       "   '0053fc2a4355',\n",
       "   '005850479c9b',\n",
       "   '005a95dd3e00',\n",
       "   '005b0e23b5d5',\n",
       "   '005bd74ecb32',\n",
       "   '00615f94806a',\n",
       "   '0063e952c937',\n",
       "   '0067079f283d',\n",
       "   '00688c9cb4b6',\n",
       "   '006a2946b9b9',\n",
       "   '006f9474ee69',\n",
       "   '007091a67938',\n",
       "   '007248b58676',\n",
       "   '007650b0d0bc',\n",
       "   '0076bbf71f48',\n",
       "   '0076c2a4fccc',\n",
       "   '0078a8c1aefd',\n",
       "   '007ea42d4cc5',\n",
       "   '007f82ad8d14',\n",
       "   '00828a580394',\n",
       "   '0082c1c6d5d0',\n",
       "   '008336b15cb2',\n",
       "   '0086caac613e',\n",
       "   '00887a2a0019',\n",
       "   '008b26bd7f55',\n",
       "   '008b6a717429',\n",
       "   '008bd264da31',\n",
       "   '008c77a77273',\n",
       "   '008ddd676829',\n",
       "   '009390c0458d',\n",
       "   '00964ac5f2a3',\n",
       "   '009733c9ec1e',\n",
       "   '009a07908d63',\n",
       "   '009a735ac8fc',\n",
       "   '009d52bf1f14',\n",
       "   '009d8bd2c571',\n",
       "   '00a07f50ac66',\n",
       "   '00a338135b96',\n",
       "   '00a6814e9fb8',\n",
       "   '00a78a6007f4',\n",
       "   '00a7f4726d5b',\n",
       "   '00ab25f608fa',\n",
       "   '00abad96696a',\n",
       "   '00ad050899b5',\n",
       "   '00b2c392e7d2',\n",
       "   '00b2d5b80654',\n",
       "   '00b55f06c078',\n",
       "   '00b971c4bb7e',\n",
       "   '00b9a33bb81f',\n",
       "   '00bedca4ccd6',\n",
       "   '00bf37dfa958',\n",
       "   '00bf73ef7072',\n",
       "   '00bf76172539',\n",
       "   '00c0c5ad7d20',\n",
       "   '00c10cc7fc78',\n",
       "   '00c29e7b8855',\n",
       "   '00c3d47c9bdc',\n",
       "   '00c92de144a8',\n",
       "   '00d0c88bf952',\n",
       "   '00d13eeadeea',\n",
       "   '00d4a304c174',\n",
       "   '00d8401e2269',\n",
       "   '00da4ebaf9e6',\n",
       "   '00dabd5cc1c8',\n",
       "   '00dd5ca6857d',\n",
       "   '00dd762aef3b',\n",
       "   '00de22ec4707',\n",
       "   '00e0c1d7564f',\n",
       "   '00e0d82cfc65',\n",
       "   '00e24093bedc',\n",
       "   '00e28e58fcba',\n",
       "   '00e307da3db2',\n",
       "   '00e64025302f',\n",
       "   '00e650761df5',\n",
       "   '00e8ccaf36ec',\n",
       "   '00e974fe1be5',\n",
       "   '00eac73f7362',\n",
       "   '00ed2c9c84c6',\n",
       "   '00ee2b300b93',\n",
       "   '00efb7dca942',\n",
       "   '00f1dddb885d',\n",
       "   '00f29e780193',\n",
       "   '00f2ac2ee90c',\n",
       "   '00f2b39df175',\n",
       "   '00f2d8152332',\n",
       "   '0102838e5346',\n",
       "   '0103bac3e4c5',\n",
       "   '01059d64855a',\n",
       "   '010740fb5f37',\n",
       "   '010aff80b0a3',\n",
       "   '0110c5453e04',\n",
       "   '0111fe792d8c',\n",
       "   '0115c4d222bc',\n",
       "   '01187ddb099e',\n",
       "   '012072537565',\n",
       "   '0120fe55e44b',\n",
       "   '0122867c5794',\n",
       "   '012384a08196',\n",
       "   '01247722f2d2',\n",
       "   '012942a5844d',\n",
       "   '012fbed07467',\n",
       "   '012fdb5da8ec',\n",
       "   '013141d04d67',\n",
       "   '0132e668bef5',\n",
       "   '0133e9eca8d0',\n",
       "   '013a93929819',\n",
       "   '0143c3cfd773',\n",
       "   '0145a67a6204',\n",
       "   '014670628993',\n",
       "   '014ab4e7800a',\n",
       "   '014c206a567d',\n",
       "   '014c3755e989',\n",
       "   '014c4ec248ef',\n",
       "   '014c7dcc1805',\n",
       "   '0150b85c82d0',\n",
       "   '015426ced173',\n",
       "   '01546d6defe3',\n",
       "   '015af1ffb9e9',\n",
       "   '015d51a58568',\n",
       "   '015fb2f70943',\n",
       "   '016315d32ffd',\n",
       "   '01663a4bdf0c',\n",
       "   '0167ffe02d3e',\n",
       "   '016a4c58266b',\n",
       "   '01735f40ffd3',\n",
       "   '0179a5ea3099',\n",
       "   '017c3a81fbe5',\n",
       "   '017d414827cb',\n",
       "   '017eb98156b0',\n",
       "   '01802193e4dc',\n",
       "   '0180435fba92',\n",
       "   '01821004b009',\n",
       "   '01881ecb24b2',\n",
       "   '0188630903f9',\n",
       "   '018b35c4d3dc',\n",
       "   '018bf5c2865c',\n",
       "   '018edd67bcbd',\n",
       "   '018f1876ee04',\n",
       "   '01945c2e4158',\n",
       "   '019fde482bf2',\n",
       "   '01a6eed31abb',\n",
       "   '01a707c451b0',\n",
       "   '01a89797c005',\n",
       "   '01a9c1259fcc',\n",
       "   '01a9d29e11d0',\n",
       "   '01abcc58edd1',\n",
       "   '01ad1d61b5e2',\n",
       "   '01b0cbaa548a',\n",
       "   '01b0fa936fca',\n",
       "   '01b12abe8016',\n",
       "   '01b32e60bb31',\n",
       "   '01b393da4d36',\n",
       "   '01b86781e65d',\n",
       "   '01bace87a8ca',\n",
       "   '01bbf69759fd',\n",
       "   '01bcce2c8c54',\n",
       "   '01c016e994f9',\n",
       "   '01c090982695',\n",
       "   '01c2063597aa',\n",
       "   '01c2630a5a9b',\n",
       "   '01c27ec40175',\n",
       "   '01c7bf6b5fee',\n",
       "   '01c8af679d67',\n",
       "   '01c9ec4b7ad7',\n",
       "   '01cbebf15b2c',\n",
       "   '01ce5e8a5d48',\n",
       "   '01cf0debc091',\n",
       "   '01d0f8759724',\n",
       "   '01d173ab023a',\n",
       "   '01d823822d50',\n",
       "   '01d8e578b7b2',\n",
       "   '01d9c405c912',\n",
       "   '01d9cc1c64d3',\n",
       "   '01da1d589b4e',\n",
       "   '01dac4257384',\n",
       "   '01dc6815573d',\n",
       "   '01dcf66e6129',\n",
       "   '01deaca63d3a',\n",
       "   '01df5693fbe3',\n",
       "   '01dfdc67abb4',\n",
       "   '01e22e257aad',\n",
       "   '01e5530ef612',\n",
       "   '01e57daf3792',\n",
       "   '01e76051e5c1',\n",
       "   '01eb5edb6a57',\n",
       "   '01ec1a0c6bf3',\n",
       "   '01ecbaf7a5c6',\n",
       "   '01ede4d1f8a8',\n",
       "   '01f153b7d6ce',\n",
       "   '01f41843a8eb',\n",
       "   '01f8b0ded080',\n",
       "   '01faad01498c',\n",
       "   '01fced2bc1fb',\n",
       "   '0204ef6947ed',\n",
       "   '020c63ec4b35',\n",
       "   '02110309b737',\n",
       "   '0213b0ab0980',\n",
       "   '0215b70f6683',\n",
       "   '02164018b2c7',\n",
       "   '0216cd8af098',\n",
       "   '021750e3b2b9',\n",
       "   '021845e465c3',\n",
       "   '02196c29640d',\n",
       "   '021ec30c749e',\n",
       "   '0221ae9122c4',\n",
       "   '0222ca211b33',\n",
       "   '0224fb58572d',\n",
       "   '022ba2c619c9',\n",
       "   '022c06cbaf58',\n",
       "   '022ca441960a',\n",
       "   '02322685de86',\n",
       "   '02331c9dd59d',\n",
       "   '0234440f063d',\n",
       "   '0235f0d8d1f7',\n",
       "   '023a4c4f29de',\n",
       "   '023e6cf1ccc7',\n",
       "   '023f7bdcacb5',\n",
       "   '02410e3dba57',\n",
       "   '0244c85c0130',\n",
       "   '02453bf6fb4f',\n",
       "   '0248662e2c78',\n",
       "   '024976a0ff7c',\n",
       "   '024bd81e538c',\n",
       "   '02533e82cf32',\n",
       "   '0254c3fc1245',\n",
       "   '0255d48bb5d1',\n",
       "   '02567e5e84c6',\n",
       "   '02593edd9dcf',\n",
       "   '025c47d6e1fb',\n",
       "   '02628641dd9b',\n",
       "   '0262a760168a',\n",
       "   '0264b2e02184',\n",
       "   '026660425fde',\n",
       "   '02673bdad0ff',\n",
       "   '0268ed5fa186',\n",
       "   '0268f2f725c1',\n",
       "   '026c20ce6dc4',\n",
       "   '026e7cf51d96',\n",
       "   '027028d9bde3',\n",
       "   '0271142d456b',\n",
       "   '02746ee744b1',\n",
       "   '02755bb63273',\n",
       "   '027657869777',\n",
       "   '0277d33cf0d8',\n",
       "   '027c98ccc223',\n",
       "   '027d795e32ea',\n",
       "   '0284e5b85bb5',\n",
       "   '0286c1223c5a',\n",
       "   '028b27877c10',\n",
       "   '028cbd441505',\n",
       "   '02942f450ffe',\n",
       "   '029482385112',\n",
       "   '02970a301007',\n",
       "   '029d2d09a30e',\n",
       "   '029d685664b8',\n",
       "   '02a00a2d45c3',\n",
       "   '02a46ec65eda',\n",
       "   '02a4cdc650a7',\n",
       "   '02a94771b11f',\n",
       "   '02aa07c8f84f',\n",
       "   '02af2813611b',\n",
       "   '02af31637544',\n",
       "   '02af5b038892',\n",
       "   '02b1f2f39bdb',\n",
       "   '02b5114c779a',\n",
       "   '02b5c0807d21',\n",
       "   '02bbd17887c1',\n",
       "   '02c13b34624f',\n",
       "   '02c25cbf385b',\n",
       "   '02c605a55873',\n",
       "   '02d0530432da',\n",
       "   '02d3e361de32',\n",
       "   '02d41a047dbb',\n",
       "   '02d4446ce1d0',\n",
       "   '02d63c21760c',\n",
       "   '02d65605dc46',\n",
       "   '02d90d9c12a4',\n",
       "   '02dcb5291c2b',\n",
       "   '02dfd12343df',\n",
       "   '02e055ad3d54',\n",
       "   '02e22d13798f',\n",
       "   '02e46356161d',\n",
       "   '02e793cf0306',\n",
       "   '02eaf3040291',\n",
       "   '02ebc437bb65',\n",
       "   '02ed07da7b7f',\n",
       "   '02eef590a42c',\n",
       "   '02f1c22d1018',\n",
       "   '02f9009f19a9',\n",
       "   '02f9493e4478',\n",
       "   '02fc92bd91c2',\n",
       "   '02fcf4bdfdf6',\n",
       "   '03011804df2a',\n",
       "   '0301f0276167',\n",
       "   '030207032d8b',\n",
       "   '0303a1ff94de',\n",
       "   '030f88006732',\n",
       "   '0311876815d1',\n",
       "   '0311d6bbc2b3',\n",
       "   '031310aab142',\n",
       "   '03133540481d',\n",
       "   '0315db4cbe86',\n",
       "   '031c8883784a',\n",
       "   '031c9b856d55',\n",
       "   '031ca58f8742',\n",
       "   '0322154dedac',\n",
       "   '03264e120660',\n",
       "   '032a08f6c8d8',\n",
       "   '032d5abb77b8',\n",
       "   '032e23fb0d6c',\n",
       "   '03300c1dfa01',\n",
       "   '0330240f9bcd',\n",
       "   '03306b172d54',\n",
       "   '0330b68b78bc',\n",
       "   '0333e8bd3079',\n",
       "   '0334334523f2',\n",
       "   '033543f7ae60',\n",
       "   '0335e094d442',\n",
       "   '03364292d6cd',\n",
       "   '0337d98e45c1',\n",
       "   '033dddc0e361',\n",
       "   '03416dedaeef',\n",
       "   '0343d08c6b9f',\n",
       "   '0344c819f9fc',\n",
       "   '0345651c406a',\n",
       "   '03470591377f',\n",
       "   '03487d9e6ab6',\n",
       "   '034d31bc0cce',\n",
       "   '034f59d2a2b6',\n",
       "   '03543f06a03c',\n",
       "   '0357c9c8b95e',\n",
       "   '03587a17e4f1',\n",
       "   '03609e9ab716',\n",
       "   '03613c0abe9a',\n",
       "   '0368e0999892',\n",
       "   '0369f9952c90',\n",
       "   '036a3143ba7c',\n",
       "   '036decbb2387',\n",
       "   '036ecf5a78de',\n",
       "   '0375cf039b1f',\n",
       "   '03778713d516',\n",
       "   '037870e978d2',\n",
       "   '0378b35ec56f',\n",
       "   '0379e52c638c',\n",
       "   '037ad0d4cf52',\n",
       "   '037b2b4698bd',\n",
       "   '037c8712293a',\n",
       "   '037cf47840d3',\n",
       "   '037dfc0eaffb',\n",
       "   '037e56d957e3',\n",
       "   '037f41f997a2',\n",
       "   '03815a1f922d',\n",
       "   '038385d05991',\n",
       "   '03839b49b297',\n",
       "   '038468c411bb',\n",
       "   '03892fe24790',\n",
       "   '0390bb0a0c6c',\n",
       "   '0394cbc345e8',\n",
       "   '03954ee233b7',\n",
       "   '039568695bb5',\n",
       "   '0396e51ec32d',\n",
       "   '0399f52401f6',\n",
       "   '039e1349ed1d',\n",
       "   '039f95537ebe',\n",
       "   '03a3c9504dff',\n",
       "   '03aac8a59532',\n",
       "   '03abcd2b84ea',\n",
       "   '03af4c0aa53f',\n",
       "   '03b3549b5abf',\n",
       "   '03b4a1b945c1',\n",
       "   '03b52ef93f2c',\n",
       "   '03b9cff66a17',\n",
       "   '03b9dc13ef75',\n",
       "   '03bc0f18c610',\n",
       "   '03bc9df9f99b',\n",
       "   '03bfe8127859',\n",
       "   '03bff1292d9c',\n",
       "   '03c167203c08',\n",
       "   '03c20bb966cb',\n",
       "   '03c2df878679',\n",
       "   '03c3e57423f1',\n",
       "   '03c43c6aec18',\n",
       "   '03c4eaf9b98d',\n",
       "   '03c5ef696031',\n",
       "   '03c83d686bad',\n",
       "   '03cb850da693',\n",
       "   '03cbd563c72a',\n",
       "   '03cc3c502760',\n",
       "   '03d06374eaac',\n",
       "   '03d4aa74a513',\n",
       "   '03d5dc080d7a',\n",
       "   '03d778a58360',\n",
       "   '03d812148b66',\n",
       "   '03da2b9ffebc',\n",
       "   '03e21728b8a8',\n",
       "   '03e34216c276',\n",
       "   '03e3ce676ea6',\n",
       "   '03e527c257f9',\n",
       "   '03e94dc60823',\n",
       "   '03f3abdfa2aa',\n",
       "   '03f6b4337b59',\n",
       "   '03f6ee79f36c',\n",
       "   '03f8e7fb65a6',\n",
       "   '03f9d334c243',\n",
       "   '03fa533aee11',\n",
       "   '03fe1f8f15f5',\n",
       "   '040011a8e244',\n",
       "   '04004cfc62c7',\n",
       "   '0404a73ce7d6',\n",
       "   '040692a0066c',\n",
       "   '0408febca528',\n",
       "   '0409b232ec6e',\n",
       "   '040b73d4cbfb',\n",
       "   '040b97a5e632',\n",
       "   '04180e243248',\n",
       "   '04194339257e',\n",
       "   '041b31277374',\n",
       "   '041f934e6edc',\n",
       "   '042085141fef',\n",
       "   '0424195a162e',\n",
       "   '0424cd3b13bb',\n",
       "   '042595bf2506',\n",
       "   '04300428355f',\n",
       "   '04309e2cef08'],\n",
       "  'top_articles': [{'id': 'a2ce57de0b02',\n",
       "    'title': 'Is Mamba the End of ChatGPT As We Know It?',\n",
       "    'subtitle': 'The Great New Question',\n",
       "    'author': '9b351e8113e9',\n",
       "    'publication_id': '98111c9905da',\n",
       "    'published_at': '2024-01-11 18:02:22',\n",
       "    'last_modified_at': '2024-01-11 18:02:22',\n",
       "    'tags': ['technology',\n",
       "     'artificial-intelligence',\n",
       "     'chatgpt',\n",
       "     'future',\n",
       "     'data-science'],\n",
       "    'topics': ['artificial-intelligence', 'machine-learning'],\n",
       "    'claps': 6308,\n",
       "    'voters': 1229,\n",
       "    'word_count': 1711,\n",
       "    'responses_count': 76,\n",
       "    'reading_time': 7.406603773584906,\n",
       "    'url': 'https://pub.towardsai.net/is-mamba-the-end-of-chatgpt-as-we-know-it-a2ce57de0b02',\n",
       "    'unique_slug': 'is-mamba-the-end-of-chatgpt-as-we-know-it-a2ce57de0b02',\n",
       "    'image_url': 'https://miro.medium.com/0*Igf3DFdae9Kd14Iy',\n",
       "    'lang': 'en',\n",
       "    'is_series': False,\n",
       "    'is_locked': True,\n",
       "    'is_shortform': False,\n",
       "    'top_highlight': 'Just like the attention module sits at the core of the Transformer, the Selective State Space Model (Selective SSM) sits at the core of Mamba.'},\n",
       "   {'id': '818b2a8ad33e',\n",
       "    'title': 'OpenAI Just Killed an Entire Market in 45 Minutes',\n",
       "    'subtitle': 'The Story Everyone Should Have Seen Coming',\n",
       "    'author': '9b351e8113e9',\n",
       "    'publication_id': '*Self-Published*',\n",
       "    'published_at': '2023-11-09 17:24:58',\n",
       "    'last_modified_at': '2023-11-09 17:24:58',\n",
       "    'tags': ['artificial-intelligence',\n",
       "     'programming',\n",
       "     'business',\n",
       "     'technology',\n",
       "     'future'],\n",
       "    'topics': ['artificial-intelligence'],\n",
       "    'claps': 14479,\n",
       "    'voters': 2876,\n",
       "    'word_count': 1262,\n",
       "    'responses_count': 233,\n",
       "    'reading_time': 5.312264150943396,\n",
       "    'url': 'https://medium.com/@ignacio.de.gregorio.noblejas/openai-just-killed-an-entire-market-in-45-minutes-818b2a8ad33e',\n",
       "    'unique_slug': 'openai-just-killed-an-entire-market-in-45-minutes-818b2a8ad33e',\n",
       "    'image_url': 'https://miro.medium.com/1*OL0MU1g3AT0dZSfswimi3Q.png',\n",
       "    'lang': 'en',\n",
       "    'is_series': False,\n",
       "    'is_locked': True,\n",
       "    'is_shortform': False,\n",
       "    'top_highlight': 'A product or solution that makes the lives of people who use it easier.'},\n",
       "   {'id': '680450c472c',\n",
       "    'title': 'Google goes beyond ChatGPT and shocks the world',\n",
       "    'subtitle': 'The new age of robots is upon us',\n",
       "    'author': '9b351e8113e9',\n",
       "    'publication_id': '*Self-Published*',\n",
       "    'published_at': '2023-03-02 19:03:12',\n",
       "    'last_modified_at': '2023-03-26 11:34:05',\n",
       "    'tags': ['artificial-intelligence',\n",
       "     'technology',\n",
       "     'ai',\n",
       "     'automation',\n",
       "     'google'],\n",
       "    'topics': ['artificial-intelligence'],\n",
       "    'claps': 2485,\n",
       "    'voters': 581,\n",
       "    'word_count': 1723,\n",
       "    'responses_count': 41,\n",
       "    'reading_time': 7.05188679245283,\n",
       "    'url': 'https://medium.com/@ignacio.de.gregorio.noblejas/offline-rl-680450c472c',\n",
       "    'unique_slug': 'offline-rl-680450c472c',\n",
       "    'image_url': 'https://miro.medium.com/0*-g_1d5r1GpXXuoT4',\n",
       "    'lang': 'en',\n",
       "    'is_series': False,\n",
       "    'is_locked': True,\n",
       "    'is_shortform': False,\n",
       "    'top_highlight': 'You measure an error and you find ways to minimize it by giving the model a lot of data.'},\n",
       "   {'id': '4cc9cf343185',\n",
       "    'title': 'An AI more impressive than ChatGPT is here',\n",
       "    'subtitle': 'Action Transformers are the next leap for AI',\n",
       "    'author': '9b351e8113e9',\n",
       "    'publication_id': '*Self-Published*',\n",
       "    'published_at': '2023-01-28 14:22:28',\n",
       "    'last_modified_at': '2023-02-03 09:29:32',\n",
       "    'tags': ['artificial-intelligence',\n",
       "     'technology',\n",
       "     'investing',\n",
       "     'productivity',\n",
       "     'automation'],\n",
       "    'topics': ['artificial-intelligence'],\n",
       "    'claps': 2571,\n",
       "    'voters': 462,\n",
       "    'word_count': 1794,\n",
       "    'responses_count': 49,\n",
       "    'reading_time': 6.969811320754717,\n",
       "    'url': 'https://medium.com/@ignacio.de.gregorio.noblejas/ai-more-impressive-than-chatgpt-4cc9cf343185',\n",
       "    'unique_slug': 'ai-more-impressive-than-chatgpt-4cc9cf343185',\n",
       "    'image_url': 'https://miro.medium.com/0*xHXIND6zAmCSovN_',\n",
       "    'lang': 'en',\n",
       "    'is_series': False,\n",
       "    'is_locked': True,\n",
       "    'is_shortform': False,\n",
       "    'top_highlight': 'Adept.ai is no ordinary startup.'},\n",
       "   {'id': '6d59742ee635',\n",
       "    'title': 'Can ChatGPT kill Google?',\n",
       "    'subtitle': 'AI is disrupting everything, even trillion-dollar businesses',\n",
       "    'author': '9b351e8113e9',\n",
       "    'publication_id': '*Self-Published*',\n",
       "    'published_at': '2022-12-28 18:27:04',\n",
       "    'last_modified_at': '2022-12-30 20:35:00',\n",
       "    'tags': ['artificial-intelligence',\n",
       "     'ai',\n",
       "     'technology',\n",
       "     'google',\n",
       "     'investing'],\n",
       "    'topics': ['artificial-intelligence', 'business', 'technology'],\n",
       "    'claps': 6341,\n",
       "    'voters': 1445,\n",
       "    'word_count': 1418,\n",
       "    'responses_count': 227,\n",
       "    'reading_time': 5.734276729559749,\n",
       "    'url': 'https://medium.com/@ignacio.de.gregorio.noblejas/can-chatgpt-kill-google-6d59742ee635',\n",
       "    'unique_slug': 'can-chatgpt-kill-google-6d59742ee635',\n",
       "    'image_url': 'https://miro.medium.com/0*3bPbSq7pXs8P5Mdq',\n",
       "    'lang': 'en',\n",
       "    'is_series': False,\n",
       "    'is_locked': True,\n",
       "    'is_shortform': False,\n",
       "    'top_highlight': 'Can ChatGPT kill Google?'},\n",
       "   {'id': '158587d68dfe',\n",
       "    'title': 'Lumiere, Google’s Amazing Video Breakthrough',\n",
       "    'subtitle': 'Text-to-Video on a new level',\n",
       "    'author': '9b351e8113e9',\n",
       "    'publication_id': '98111c9905da',\n",
       "    'published_at': '2024-02-13 20:01:50',\n",
       "    'last_modified_at': '2024-02-13 20:01:50',\n",
       "    'tags': ['artificial-intelligence',\n",
       "     'technology',\n",
       "     'google',\n",
       "     'data-science',\n",
       "     'future'],\n",
       "    'topics': ['artificial-intelligence', 'machine-learning'],\n",
       "    'claps': 1196,\n",
       "    'voters': 119,\n",
       "    'word_count': 1492,\n",
       "    'responses_count': 9,\n",
       "    'reading_time': 6.880188679245283,\n",
       "    'url': 'https://pub.towardsai.net/lumiere-googles-amazing-video-breakthrough-158587d68dfe',\n",
       "    'unique_slug': 'lumiere-googles-amazing-video-breakthrough-158587d68dfe',\n",
       "    'image_url': 'https://miro.medium.com/0*XOdZjJp7-DELdwB9',\n",
       "    'lang': 'en',\n",
       "    'is_series': False,\n",
       "    'is_locked': True,\n",
       "    'is_shortform': False,\n",
       "    'top_highlight': ''},\n",
       "   {'id': 'd49b7a88ec2e',\n",
       "    'title': 'Demystifying 1X’s Incredible AI Androids',\n",
       "    'subtitle': 'Understanding The Incredible Demonstration',\n",
       "    'author': '9b351e8113e9',\n",
       "    'publication_id': '*Self-Published*',\n",
       "    'published_at': '2024-02-10 18:26:02',\n",
       "    'last_modified_at': '2024-02-10 18:26:02',\n",
       "    'tags': ['artificial-intelligence',\n",
       "     'technology',\n",
       "     'robotics',\n",
       "     'future',\n",
       "     'business'],\n",
       "    'topics': ['artificial-intelligence'],\n",
       "    'claps': 204,\n",
       "    'voters': 28,\n",
       "    'word_count': 1270,\n",
       "    'responses_count': 1,\n",
       "    'reading_time': 5.49245283018868,\n",
       "    'url': 'https://medium.com/@ignacio.de.gregorio.noblejas/demystifying-1xs-incredible-ai-androids-d49b7a88ec2e',\n",
       "    'unique_slug': 'demystifying-1xs-incredible-ai-androids-d49b7a88ec2e',\n",
       "    'image_url': 'https://miro.medium.com/0*uXMEP240i5mTflit.jpg',\n",
       "    'lang': 'en',\n",
       "    'is_series': False,\n",
       "    'is_locked': True,\n",
       "    'is_shortform': False,\n",
       "    'top_highlight': ''},\n",
       "   {'id': '81af3d4be61c',\n",
       "    'title': 'Google Finally Challenges ChatGPT',\n",
       "    'subtitle': 'A turning point for AI?',\n",
       "    'author': '9b351e8113e9',\n",
       "    'publication_id': '98111c9905da',\n",
       "    'published_at': '2024-02-06 00:01:59',\n",
       "    'last_modified_at': '2024-02-06 00:01:59',\n",
       "    'tags': ['artificial-intelligence',\n",
       "     'technology',\n",
       "     'google',\n",
       "     'data-science',\n",
       "     'chatgpt'],\n",
       "    'topics': ['artificial-intelligence', 'machine-learning'],\n",
       "    'claps': 737,\n",
       "    'voters': 57,\n",
       "    'word_count': 1454,\n",
       "    'responses_count': 8,\n",
       "    'reading_time': 6.186792452830189,\n",
       "    'url': 'https://pub.towardsai.net/google-finally-challenges-chatgpt-81af3d4be61c',\n",
       "    'unique_slug': 'google-finally-challenges-chatgpt-81af3d4be61c',\n",
       "    'image_url': 'https://miro.medium.com/0*Kc3HwZcMF5-0LLev',\n",
       "    'lang': 'en',\n",
       "    'is_series': False,\n",
       "    'is_locked': True,\n",
       "    'is_shortform': False,\n",
       "    'top_highlight': ''},\n",
       "   {'id': 'e7f55b0514a1',\n",
       "    'title': 'Meta’s Self-Rewarding Models, the Key to SuperHuman LLMs?',\n",
       "    'subtitle': 'Meta, the company behind Facebook, Whatsapp, and Rayban’s Meta glasses, has announced a recent, highly promising AI breakthrough…',\n",
       "    'author': '9b351e8113e9',\n",
       "    'publication_id': '98111c9905da',\n",
       "    'published_at': '2024-01-30 22:01:37',\n",
       "    'last_modified_at': '2024-01-30 22:01:37',\n",
       "    'tags': ['artificial-intelligence',\n",
       "     'technology',\n",
       "     'future',\n",
       "     'business',\n",
       "     'data-science'],\n",
       "    'topics': ['artificial-intelligence', 'machine-learning'],\n",
       "    'claps': 644,\n",
       "    'voters': 75,\n",
       "    'word_count': 1206,\n",
       "    'responses_count': 11,\n",
       "    'reading_time': 5.3842767295597485,\n",
       "    'url': 'https://pub.towardsai.net/metas-self-rewarding-models-the-key-to-superhuman-llms-e7f55b0514a1',\n",
       "    'unique_slug': 'metas-self-rewarding-models-the-key-to-superhuman-llms-e7f55b0514a1',\n",
       "    'image_url': 'https://miro.medium.com/0*nekYT7IptIXWKufq',\n",
       "    'lang': 'en',\n",
       "    'is_series': False,\n",
       "    'is_locked': True,\n",
       "    'is_shortform': False,\n",
       "    'top_highlight': \"Meta, the company behind Facebook, Whatsapp, and Rayban's Meta glasses, has announced a recent, highly promising AI breakthrough, Self-Rewarding Language Models.\"},\n",
       "   {'id': '01deab746b42',\n",
       "    'title': 'I Found The Recipe for Cocaine on Instagram',\n",
       "    'subtitle': 'The Cost of AI Progress, or Facing Reality?',\n",
       "    'author': '9b351e8113e9',\n",
       "    'publication_id': '*Self-Published*',\n",
       "    'published_at': '2024-01-27 18:22:08',\n",
       "    'last_modified_at': '2024-01-27 18:22:08',\n",
       "    'tags': ['artificial-intelligence',\n",
       "     'technology',\n",
       "     'instagram',\n",
       "     'chatgpt',\n",
       "     'future'],\n",
       "    'topics': ['artificial-intelligence', 'machine-learning'],\n",
       "    'claps': 270,\n",
       "    'voters': 27,\n",
       "    'word_count': 1442,\n",
       "    'responses_count': 4,\n",
       "    'reading_time': 5.6415094339622645,\n",
       "    'url': 'https://medium.com/@ignacio.de.gregorio.noblejas/i-found-the-recipe-for-cocaine-on-instagram-01deab746b42',\n",
       "    'unique_slug': 'i-found-the-recipe-for-cocaine-on-instagram-01deab746b42',\n",
       "    'image_url': 'https://miro.medium.com/0*hyw9dpRX-jB1x5ul',\n",
       "    'lang': 'en',\n",
       "    'is_series': False,\n",
       "    'is_locked': True,\n",
       "    'is_shortform': False,\n",
       "    'top_highlight': 'I Found The Recipe for Cocaine on Instagram'}]},\n",
       " '5d33decdf4c4': {'id': '5d33decdf4c4',\n",
       "  'username': 'avi_chawla',\n",
       "  'fullname': 'Avi Chawla',\n",
       "  'bio': '👉 Get a Free Data Science PDF (550+ pages) with 320+ tips by subscribing to my daily newsletter today: https://bit.ly/DailyDS.',\n",
       "  'followers_count': 19823,\n",
       "  'following_count': 14,\n",
       "  'publication_following_count': 7,\n",
       "  'image_url': 'https://miro.medium.com/1*xr3tPZhdFVW2tywEudvAgw.jpeg',\n",
       "  'twitter_username': '_avichawla',\n",
       "  'is_writer_program_enrolled': True,\n",
       "  'allow_notes': True,\n",
       "  'medium_member_at': '2024-01-29 16:15:59',\n",
       "  'is_suspended': False,\n",
       "  'top_writer_in': ['artificial-intelligence'],\n",
       "  'has_list': False,\n",
       "  'is_book_author': False,\n",
       "  'tipping_link': 'https://ko-fi.com/avichawla',\n",
       "  'bg_image_url': 'https://miro.medium.com/1*l9M1JyqhVKynPXjEDU7ShA.png',\n",
       "  'logo_image_url': '',\n",
       "  'followers': ['001479440872',\n",
       "   '002125e32c14',\n",
       "   '002b3b17db23',\n",
       "   '0049d4282be9',\n",
       "   '005c18b43c6c',\n",
       "   '00777a15e411',\n",
       "   '009454aff841',\n",
       "   '00abad96696a',\n",
       "   '00b0ad7585f2',\n",
       "   '00b8eada8b79',\n",
       "   '0113484d6400',\n",
       "   '0143c3cfd773',\n",
       "   '016af649be8c',\n",
       "   '017686580bb5',\n",
       "   '01b0fa936fca',\n",
       "   '01faad01498c',\n",
       "   '02196c29640d',\n",
       "   '0223fdfce593',\n",
       "   '02593edd9dcf',\n",
       "   '025df2df9a37',\n",
       "   '027028d9bde3',\n",
       "   '027d795e32ea',\n",
       "   '028b27877c10',\n",
       "   '029482385112',\n",
       "   '02cf374e2ba8',\n",
       "   '03133540481d',\n",
       "   '0344c819f9fc',\n",
       "   '03492a1d5eb4',\n",
       "   '035acb0a534c',\n",
       "   '03609e9ab716',\n",
       "   '036b6bbbf3dd',\n",
       "   '036ecf5a78de',\n",
       "   '037cf47840d3',\n",
       "   '038616bedd81',\n",
       "   '038ebf7c20c8',\n",
       "   '03ace9b06076',\n",
       "   '03bff1292d9c',\n",
       "   '03d71dd7fca1',\n",
       "   '03d778a58360',\n",
       "   '03d7d3416226',\n",
       "   '03e94dc60823',\n",
       "   '03fa389c69ac',\n",
       "   '03fbacb5dc2d',\n",
       "   '0424cd3b13bb',\n",
       "   '042595bf2506',\n",
       "   '04500c057f2b',\n",
       "   '04840369bb54',\n",
       "   '049d89885fc2',\n",
       "   '049dbabe955a',\n",
       "   '04ca33ca0707',\n",
       "   '054cfd9a67ce',\n",
       "   '05527a3163a8',\n",
       "   '0562b33e89a3',\n",
       "   '05638bfece78',\n",
       "   '05858f351466',\n",
       "   '058a6d5a31c2',\n",
       "   '059b0d5e8f7e',\n",
       "   '05adcd2d9f9c',\n",
       "   '05d6d0c339d7',\n",
       "   '05f95e3e7f07',\n",
       "   '05f9be6f76f4',\n",
       "   '060a20697ec0',\n",
       "   '063991ed8967',\n",
       "   '0651b49a9912',\n",
       "   '066982244fb5',\n",
       "   '0695ce306bf1',\n",
       "   '06b7bdc80d7d',\n",
       "   '06ca8f55dd11',\n",
       "   '06cc083e0d36',\n",
       "   '06d375f1f359',\n",
       "   '06e14752c974',\n",
       "   '07111536eaca',\n",
       "   '0712db3d73c6',\n",
       "   '071da920fdde',\n",
       "   '071f8b7c3185',\n",
       "   '072be4d3738f',\n",
       "   '073133dbe904',\n",
       "   '07576ffa035f',\n",
       "   '075d8e06a67c',\n",
       "   '07c46abd2124',\n",
       "   '07d44247ce39',\n",
       "   '080cc07cd260',\n",
       "   '083ddd31f199',\n",
       "   '0859720c1d98',\n",
       "   '087b3c7d7bb8',\n",
       "   '08c62e60b692',\n",
       "   '08c79d0822bf',\n",
       "   '09084aba3069',\n",
       "   '0915a5517f4e',\n",
       "   '092578aef198',\n",
       "   '092eabcdc76d',\n",
       "   '095b039c6a5e',\n",
       "   '0960c8b08350',\n",
       "   '09abeab74b1b',\n",
       "   '09b6ac590e29',\n",
       "   '09b7fba39f2e',\n",
       "   '09b8affbed3b',\n",
       "   '09b91e9a51d8',\n",
       "   '09c4b362c0b1',\n",
       "   '09e24d94fc99',\n",
       "   '09f9da79e5ea',\n",
       "   '0a0c931f79ce',\n",
       "   '0a135250fa2a',\n",
       "   '0a7c7f0fb687',\n",
       "   '0a993390b99e',\n",
       "   '0a9f4e679fe2',\n",
       "   '0aaf7a1f8af3',\n",
       "   '0ac966a8bd62',\n",
       "   '0aef21fff913',\n",
       "   '0b002a16f7e9',\n",
       "   '0b08fe198ecf',\n",
       "   '0b36e4263392',\n",
       "   '0b37349d902a',\n",
       "   '0b3e45548064',\n",
       "   '0b94187ee8f5',\n",
       "   '0b96f6886a09',\n",
       "   '0bb85f2a0b3b',\n",
       "   '0bc872ce959b',\n",
       "   '0be27622ce75',\n",
       "   '0be7589e82af',\n",
       "   '0c2574f5ecbb',\n",
       "   '0c36b68c3f11',\n",
       "   '0c7bd7f53804',\n",
       "   '0c9a285d8aa0',\n",
       "   '0cc8c6c95ff7',\n",
       "   '0cf4a3893e1e',\n",
       "   '0d025226c2be',\n",
       "   '0d0b59432c4c',\n",
       "   '0d11d07c746e',\n",
       "   '0d58ac7ba0d4',\n",
       "   '0d99fcffdf8b',\n",
       "   '0da06b70dafa',\n",
       "   '0dabd06d5be7',\n",
       "   '0dbb707642fa',\n",
       "   '0e12f8cc4094',\n",
       "   '0e327a4e60f6',\n",
       "   '0e365ad5e60a',\n",
       "   '0e4aa70f7594',\n",
       "   '0e5faf098978',\n",
       "   '0e61f3697d54',\n",
       "   '0e62adbf8cbf',\n",
       "   '0e8f1f09db68',\n",
       "   '0e8fc6b09e89',\n",
       "   '0e92d7f0ecf3',\n",
       "   '0ecb94100b7c',\n",
       "   '0ed0e5a8ca2f',\n",
       "   '0ed5b971913f',\n",
       "   '0edc6763e4b8',\n",
       "   '0eebb404158d',\n",
       "   '0efa91bc2ac7',\n",
       "   '0f09ab593f5d',\n",
       "   '0f11c2541a42',\n",
       "   '0f27b22b653f',\n",
       "   '0f4af9e138b2',\n",
       "   '0f6d6cbe137e',\n",
       "   '0fd3168dcaeb',\n",
       "   '0ff632cf8f64',\n",
       "   '10052e59bb8',\n",
       "   '10086105f0e',\n",
       "   '1017ec31ff47',\n",
       "   '1019e27bdd51',\n",
       "   '102520668a5c',\n",
       "   '10289fba5362',\n",
       "   '1029ee1607b0',\n",
       "   '102c3badd86b',\n",
       "   '10325487d561',\n",
       "   '10396b89532c',\n",
       "   '103a2959be1c',\n",
       "   '103a6ba0ed98',\n",
       "   '1048f0f87cfb',\n",
       "   '10497a096abc',\n",
       "   '104e87813ff0',\n",
       "   '1054a8d9c61',\n",
       "   '10586288dd8a',\n",
       "   '105a3c72085a',\n",
       "   '105a9f3d24c0',\n",
       "   '105d3157afbb',\n",
       "   '105e46f960eb',\n",
       "   '1061a371ca87',\n",
       "   '106358b72f7d',\n",
       "   '1065c866fa3b',\n",
       "   '10667b589e6a',\n",
       "   '106f7166931e',\n",
       "   '106fe47cf4ec',\n",
       "   '1070aa1d0388',\n",
       "   '107d8bace682',\n",
       "   '107f6d9b619',\n",
       "   '108123fbe94c',\n",
       "   '1084e750528f',\n",
       "   '108e08d9c994',\n",
       "   '108e4ce59c54',\n",
       "   '108ed5bbb4db',\n",
       "   '10929a91fba4',\n",
       "   '109422fcf756',\n",
       "   '109696ac95e1',\n",
       "   '1096af2326ea',\n",
       "   '10a0845ff59a',\n",
       "   '10a209951983',\n",
       "   '10a213ff07af',\n",
       "   '10a36409ff1c',\n",
       "   '10acf539597a',\n",
       "   '10b81a106444',\n",
       "   '10b964fd3f2f',\n",
       "   '10bcc75fae04',\n",
       "   '10bdc4918953',\n",
       "   '10bebdcc70b6',\n",
       "   '10c6330f3732',\n",
       "   '10c93355c3a1',\n",
       "   '10cab7319cf7',\n",
       "   '10cc23f94edb',\n",
       "   '10cd10383056',\n",
       "   '10d4097a3b78',\n",
       "   '10d687232338',\n",
       "   '10dc15d24660',\n",
       "   '10dce128a5b5',\n",
       "   '10de7cb84f80',\n",
       "   '10dff2d7b6d6',\n",
       "   '10dff7210369',\n",
       "   '10eac13c8a9f',\n",
       "   '10f00002abe9',\n",
       "   '10f0979f4bab',\n",
       "   '10f2e75565dd',\n",
       "   '10f581b06f04',\n",
       "   '10f810bdab31',\n",
       "   '10fb23b3bee3',\n",
       "   '10fb972a5b01',\n",
       "   '10fbbdca581',\n",
       "   '10fdc06703b7',\n",
       "   '11073aa57e7',\n",
       "   '110c20571c0',\n",
       "   '110d8bd6ba16',\n",
       "   '110eb35f3108',\n",
       "   '1110f4d515a4',\n",
       "   '111148ed63d5',\n",
       "   '1114e0175910',\n",
       "   '11159c320ed2',\n",
       "   '1119858761ac',\n",
       "   '111e12ac4e8c',\n",
       "   '112755db28da',\n",
       "   '112a95bac7d2',\n",
       "   '112d4264e53d',\n",
       "   '11326ad3e239',\n",
       "   '113a659a0eba',\n",
       "   '113bf76ff1a',\n",
       "   '11415a95f64d',\n",
       "   '11424c740f68',\n",
       "   '1145834bd631',\n",
       "   '11470cb8fd27',\n",
       "   '1148d4911947',\n",
       "   '114916af26d8',\n",
       "   '114931f619db',\n",
       "   '1149c536e9a',\n",
       "   '114ae057ed56',\n",
       "   '1154d945b1e1',\n",
       "   '115b849287db',\n",
       "   '115f14824f10',\n",
       "   '115f36ada0dc',\n",
       "   '1160f3f6a3b7',\n",
       "   '1163cdca60a4',\n",
       "   '116c68e0fa8e',\n",
       "   '116dba0464c2',\n",
       "   '117187099f80',\n",
       "   '11777614c8cc',\n",
       "   '1178eb3a0b3a',\n",
       "   '117a239b0b29',\n",
       "   '11827944ca43',\n",
       "   '118780296cd8',\n",
       "   '118983d0e22e',\n",
       "   '118e309a51cd',\n",
       "   '11906eeaea3d',\n",
       "   '11999502f8b',\n",
       "   '119a942fde97',\n",
       "   '119f685dc82',\n",
       "   '11a28e5adb70',\n",
       "   '11a527b10562',\n",
       "   '11a5cd42222f',\n",
       "   '11a5f5263674',\n",
       "   '11a880facf4f',\n",
       "   '11a8e9b707c1',\n",
       "   '11b02e0f006b',\n",
       "   '11ba0d53ceb8',\n",
       "   '11bde9d63427',\n",
       "   '11be413ecabf',\n",
       "   '11bf271b935',\n",
       "   '11bfb0114049',\n",
       "   '11cb9ce642b3',\n",
       "   '11cbbe600de3',\n",
       "   '11cc65a63ce2',\n",
       "   '11d457c3391c',\n",
       "   '11d73e19e83',\n",
       "   '11d8058eb9ea',\n",
       "   '11dc50c134f2',\n",
       "   '11dc8bfa738',\n",
       "   '11df8902d05c',\n",
       "   '11e3c3005d9a',\n",
       "   '11ebdbfd3d01',\n",
       "   '11f666a2cad5',\n",
       "   '11ffbcedde9',\n",
       "   '12011bb19ac',\n",
       "   '12016cef5565',\n",
       "   '1208d55c4db3',\n",
       "   '120ba2a15cbf',\n",
       "   '120d05b2c739',\n",
       "   '120e86e05604',\n",
       "   '120f52df0c9',\n",
       "   '120f6f28b64d',\n",
       "   '120fb2364d57',\n",
       "   '121075f29909',\n",
       "   '1210a8c57251',\n",
       "   '1211f76437ca',\n",
       "   '121252b44bf0',\n",
       "   '12132df95414',\n",
       "   '1213dfed1781',\n",
       "   '12147d2ab84f',\n",
       "   '12180e5253b8',\n",
       "   '121b8273e82b',\n",
       "   '121d327d7b4b',\n",
       "   '121f13972b73',\n",
       "   '1222f21b0765',\n",
       "   '12255a79be1d',\n",
       "   '12267150bb11',\n",
       "   '12287983bbb8',\n",
       "   '122bc8f6489a',\n",
       "   '122d30176f0c',\n",
       "   '122d8a5b4f82',\n",
       "   '122e5d23cf10',\n",
       "   '12350974a546',\n",
       "   '12358015a65d',\n",
       "   '1236c76381ee',\n",
       "   '123db12e2ac8',\n",
       "   '123fde4829a4',\n",
       "   '12428b861f98',\n",
       "   '12473cb27397',\n",
       "   '1249376c22c',\n",
       "   '124a6f536e55',\n",
       "   '124c8f48b29e',\n",
       "   '1250cc8ad30d',\n",
       "   '12524c2bcf45',\n",
       "   '1256da67d66',\n",
       "   '125739d4bb1e',\n",
       "   '125ca5a54318',\n",
       "   '1264e3103b7a',\n",
       "   '12665ee42fe5',\n",
       "   '12686bfaf94e',\n",
       "   '1271e9d40ead',\n",
       "   '1274825ba247',\n",
       "   '1276a2ab058c',\n",
       "   '12778e94e2ae',\n",
       "   '1278ffcbde31',\n",
       "   '12795f53407',\n",
       "   '127b5cd9af2e',\n",
       "   '127cf59ceed8',\n",
       "   '127eb2a08feb',\n",
       "   '127fdd997104',\n",
       "   '127ff50be0dc',\n",
       "   '1281bc0111d2',\n",
       "   '1282209f804e',\n",
       "   '12892a109be6',\n",
       "   '128a5eeebdbb',\n",
       "   '1295e5f7c10e',\n",
       "   '129a68b12a3b',\n",
       "   '129b9efb4709',\n",
       "   '129c84491f8',\n",
       "   '12a204627804',\n",
       "   '12a2761509dd',\n",
       "   '12a47e20cb76',\n",
       "   '12a5e12ccaec',\n",
       "   '12ad09df6c88',\n",
       "   '12ad7129ed6',\n",
       "   '12ae44bb',\n",
       "   '12aef9d4fe3d',\n",
       "   '12aff0ba9d3a',\n",
       "   '12b0b68c733d',\n",
       "   '12b37ecff2f9',\n",
       "   '12b432d38854',\n",
       "   '12b59ceaf220',\n",
       "   '12b6bb036be0',\n",
       "   '12b6cabb4f29',\n",
       "   '12b6df61d612',\n",
       "   '12b718c74e72',\n",
       "   '12b74d19ca7b',\n",
       "   '12b79801a574',\n",
       "   '12b9efc2c3bd',\n",
       "   '12bbc81528d0',\n",
       "   '12bca38baee5',\n",
       "   '12c331fa060d',\n",
       "   '12c52f932f1c',\n",
       "   '12c62c101def',\n",
       "   '12c8185c451c',\n",
       "   '12c81865555',\n",
       "   '12c93a8cb22c',\n",
       "   '12ca87df488',\n",
       "   '12ca95aaf757',\n",
       "   '12cdcd13f0ef',\n",
       "   '12cfc88cfc34',\n",
       "   '12d1359528ac',\n",
       "   '12d1f74cd25f',\n",
       "   '12d8aafd0ab9',\n",
       "   '12d8ae9859a8',\n",
       "   '12d9a2a773bd',\n",
       "   '12dc2b3c44da',\n",
       "   '12e03c57f14b',\n",
       "   '12e119a2bc25',\n",
       "   '12e3a8f4e63a',\n",
       "   '12eb560dd4cd',\n",
       "   '12efc5f80b58',\n",
       "   '12f22d9cc9f1',\n",
       "   '12fafb6213e0',\n",
       "   '12fb10a3f483',\n",
       "   '13059381c38c',\n",
       "   '130800821d36',\n",
       "   '13108208ab61',\n",
       "   '13116a83354d',\n",
       "   '131667fa818f',\n",
       "   '1317ffccf622',\n",
       "   '131ce024ca99',\n",
       "   '13238b3d08b8',\n",
       "   '132bf3ac90a5',\n",
       "   '132c56a9c859',\n",
       "   '1333d5a1100',\n",
       "   '1337ea3c6778',\n",
       "   '133e606f8130',\n",
       "   '13484d9e0a12',\n",
       "   '134991995804',\n",
       "   '1359aa093b12',\n",
       "   '135bafcf9079',\n",
       "   '135bb107b9ff',\n",
       "   '135c5dd3bb18',\n",
       "   '135e27bc0ec2',\n",
       "   '13631d7ad369',\n",
       "   '136663019227',\n",
       "   '13671df1d6fe',\n",
       "   '1374910bb273',\n",
       "   '1378c84c3b67',\n",
       "   '1378d5e02ee1',\n",
       "   '138262efa2c',\n",
       "   '1382b4b830c8',\n",
       "   '1386523ea123',\n",
       "   '1386fb39ee05',\n",
       "   '138a032ab346',\n",
       "   '138c8c9ac64a',\n",
       "   '139384340624',\n",
       "   '139e7b07d7ff',\n",
       "   '139e7c4d7bdc',\n",
       "   '13a0bd7e6e1',\n",
       "   '13a64b26206d',\n",
       "   '13ae289ed418',\n",
       "   '13b0da6f5b10',\n",
       "   '13b47e22b97d',\n",
       "   '13b79633ab03',\n",
       "   '13bca66e9a0b',\n",
       "   '13bed9618c1a',\n",
       "   '13c017dea18d',\n",
       "   '13c06a6e1fea',\n",
       "   '13c0cf9925bb',\n",
       "   '13c15661794',\n",
       "   '13c72316822',\n",
       "   '13c78567313b',\n",
       "   '13c9629a819',\n",
       "   '13d00f9a8488',\n",
       "   '13d2bdfaf40c',\n",
       "   '13d5941b8906',\n",
       "   '13d5e3ca4a59',\n",
       "   '13d69911948c',\n",
       "   '13d8bd81f4ef',\n",
       "   '13ddeb43c96d',\n",
       "   '13de18f8ec09',\n",
       "   '13e1ca928072',\n",
       "   '13e4b03f47e9',\n",
       "   '13e61131dfd0',\n",
       "   '13ed089af9d1',\n",
       "   '13f517e8c017',\n",
       "   '13f7bd70a487',\n",
       "   '13f8c7076d97'],\n",
       "  'top_articles': [{'id': '83e870b5f0e4',\n",
       "    'title': '320+ Python and Data Science Tips\\u200a—\\u200aCovering Pandas, NumPy, ML Basics, Sklearn, Jupyter, and More.',\n",
       "    'subtitle': 'A self-curated collection of Python and Data Science tips to level up your data game.',\n",
       "    'author': '5d33decdf4c4',\n",
       "    'publication_id': 'a648dc4ecb66',\n",
       "    'published_at': '2023-10-06 11:49:29',\n",
       "    'last_modified_at': '2023-10-06 11:49:29',\n",
       "    'tags': ['data-science',\n",
       "     'artificial-intelligence',\n",
       "     'machine-learning',\n",
       "     'python',\n",
       "     'technology'],\n",
       "    'topics': ['data-science'],\n",
       "    'claps': 853,\n",
       "    'voters': 220,\n",
       "    'word_count': 1017,\n",
       "    'responses_count': 10,\n",
       "    'reading_time': 5.2377358490566035,\n",
       "    'url': 'https://towardsdev.com/320-python-and-data-science-tips-covering-pandas-numpy-ml-basics-sklearn-jupyter-and-more-83e870b5f0e4',\n",
       "    'unique_slug': '320-python-and-data-science-tips-covering-pandas-numpy-ml-basics-sklearn-jupyter-and-more-83e870b5f0e4',\n",
       "    'image_url': 'https://miro.medium.com/1*E_pmPQYZ7eMxd_eKxgpKqg.png',\n",
       "    'lang': 'en',\n",
       "    'is_series': False,\n",
       "    'is_locked': False,\n",
       "    'is_shortform': False,\n",
       "    'top_highlight': ''},\n",
       "   {'id': 'a4ff1b694707',\n",
       "    'title': '20% of Pandas Functions that Data Scientists Use 80% of the Time',\n",
       "    'subtitle': 'Putting Pareto’s Principle to work on the Pandas library',\n",
       "    'author': '5d33decdf4c4',\n",
       "    'publication_id': '7f60cf5620c9',\n",
       "    'published_at': '2022-05-16 12:05:21',\n",
       "    'last_modified_at': '2022-05-16 20:12:26',\n",
       "    'tags': ['pandas', 'data-science', 'python', 'dataframes'],\n",
       "    'topics': ['data-science', 'programming'],\n",
       "    'claps': 1581,\n",
       "    'voters': 530,\n",
       "    'word_count': 803,\n",
       "    'responses_count': 12,\n",
       "    'reading_time': 4.780188679245283,\n",
       "    'url': 'https://towardsdatascience.com/20-of-pandas-functions-that-data-scientists-use-80-of-the-time-a4ff1b694707',\n",
       "    'unique_slug': '20-of-pandas-functions-that-data-scientists-use-80-of-the-time-a4ff1b694707',\n",
       "    'image_url': 'https://miro.medium.com/0*qjsBnhHUXY5XV-wX',\n",
       "    'lang': 'en',\n",
       "    'is_series': False,\n",
       "    'is_locked': True,\n",
       "    'is_shortform': False,\n",
       "    'top_highlight': \"Mastering an entire Python library like Pandas can be challenging for anyone. However, if we take a step back and think, do we really need to be aware of every minute detail of a specific library, especially when we live in a world governed by Pareto's Principle? For those who don't know, Pareto's Principle (also known as the 80–20 rule) says that 20% of your inputs will always contribute towards generating 80% of your outputs.\"},\n",
       "   {'id': 'c0954c410f8f',\n",
       "    'title': 'Why I Stopped Dumping DataFrames to a CSV and Why You Should Too',\n",
       "    'subtitle': 'It’s time to say goodbye to pd.to_csv() and pd.read_csv()',\n",
       "    'author': '5d33decdf4c4',\n",
       "    'publication_id': '7f60cf5620c9',\n",
       "    'published_at': '2022-05-10 18:23:41',\n",
       "    'last_modified_at': '2022-05-12 13:02:50',\n",
       "    'tags': ['pandas', 'programming', 'csv', 'dataframes'],\n",
       "    'topics': ['data-science', 'programming'],\n",
       "    'claps': 1359,\n",
       "    'voters': 478,\n",
       "    'word_count': 761,\n",
       "    'responses_count': 27,\n",
       "    'reading_time': 3.571698113207547,\n",
       "    'url': 'https://towardsdatascience.com/why-i-stopped-dumping-dataframes-to-a-csv-and-why-you-should-too-c0954c410f8f',\n",
       "    'unique_slug': 'why-i-stopped-dumping-dataframes-to-a-csv-and-why-you-should-too-c0954c410f8f',\n",
       "    'image_url': 'https://miro.medium.com/0*UnRRF7CCQ91Uwk7t',\n",
       "    'lang': 'en',\n",
       "    'is_series': False,\n",
       "    'is_locked': True,\n",
       "    'is_shortform': False,\n",
       "    'top_highlight': 'In my opinion, both Parquet and Feather are the best available file formats out there to choose from the six we have explored in this post.'},\n",
       "   {'id': 'fb0c1f1f2972',\n",
       "    'title': 'Introducing IceCream: Never Use Print() To Debug Your Python Code Again',\n",
       "    'subtitle': 'Why I stopped using print() statements for debugging and why you should too',\n",
       "    'author': '5d33decdf4c4',\n",
       "    'publication_id': '32881626c9c9',\n",
       "    'published_at': '2024-01-29 07:24:23',\n",
       "    'last_modified_at': '2024-01-29 10:21:50',\n",
       "    'tags': ['data-science',\n",
       "     'machine-learning',\n",
       "     'artificial-intelligence',\n",
       "     'python',\n",
       "     'programming'],\n",
       "    'topics': ['programming'],\n",
       "    'claps': 556,\n",
       "    'voters': 84,\n",
       "    'word_count': 893,\n",
       "    'responses_count': 6,\n",
       "    'reading_time': 4.069811320754717,\n",
       "    'url': 'https://medium.datadriveninvestor.com/introducing-icecream-never-use-print-to-debug-your-python-code-again-fb0c1f1f2972',\n",
       "    'unique_slug': 'introducing-icecream-never-use-print-to-debug-your-python-code-again-fb0c1f1f2972',\n",
       "    'image_url': 'https://miro.medium.com/0*2n51QKEzXu0iKtBK',\n",
       "    'lang': 'en',\n",
       "    'is_series': False,\n",
       "    'is_locked': True,\n",
       "    'is_shortform': False,\n",
       "    'top_highlight': ''},\n",
       "   {'id': '5edf898909e7',\n",
       "    'title': 'Introducing Pandarallel: Never Use The Apply Method In Pandas Again',\n",
       "    'subtitle': 'Why I stopped using Apply() in Pandas and why you should too.',\n",
       "    'author': '5d33decdf4c4',\n",
       "    'publication_id': '32881626c9c9',\n",
       "    'published_at': '2024-01-24 10:59:56',\n",
       "    'last_modified_at': '2024-02-01 10:26:40',\n",
       "    'tags': ['data-science',\n",
       "     'machine-learning',\n",
       "     'pandas',\n",
       "     'python',\n",
       "     'artificial-intelligence'],\n",
       "    'topics': ['data-science', 'programming'],\n",
       "    'claps': 352,\n",
       "    'voters': 67,\n",
       "    'word_count': 809,\n",
       "    'responses_count': 3,\n",
       "    'reading_time': 4.1028301886792455,\n",
       "    'url': 'https://medium.datadriveninvestor.com/introducing-pandarallel-never-use-the-apply-method-in-pandas-again-5edf898909e7',\n",
       "    'unique_slug': 'introducing-pandarallel-never-use-the-apply-method-in-pandas-again-5edf898909e7',\n",
       "    'image_url': 'https://miro.medium.com/0*bR4akeZyYmtpC98C',\n",
       "    'lang': 'en',\n",
       "    'is_series': False,\n",
       "    'is_locked': True,\n",
       "    'is_shortform': False,\n",
       "    'top_highlight': ''},\n",
       "   {'id': 'ddbf9b5039a1',\n",
       "    'title': '5 Things I Wish the Pandas Library Could Do',\n",
       "    'subtitle': 'Discussing five subtle limitations of Pandas',\n",
       "    'author': '5d33decdf4c4',\n",
       "    'publication_id': '32881626c9c9',\n",
       "    'published_at': '2024-01-24 10:59:47',\n",
       "    'last_modified_at': '2024-02-13 05:38:21',\n",
       "    'tags': ['data-science',\n",
       "     'machine-learning',\n",
       "     'sql',\n",
       "     'python',\n",
       "     'artificial-intelligence'],\n",
       "    'topics': ['data-science', 'programming'],\n",
       "    'claps': 313,\n",
       "    'voters': 25,\n",
       "    'word_count': 1804,\n",
       "    'responses_count': 3,\n",
       "    'reading_time': 7.857547169811321,\n",
       "    'url': 'https://medium.datadriveninvestor.com/5-things-i-wish-the-pandas-library-could-do-ddbf9b5039a1',\n",
       "    'unique_slug': '5-things-i-wish-the-pandas-library-could-do-ddbf9b5039a1',\n",
       "    'image_url': 'https://miro.medium.com/0*V4eRjCCJ3g1OaYU3',\n",
       "    'lang': 'en',\n",
       "    'is_series': False,\n",
       "    'is_locked': True,\n",
       "    'is_shortform': False,\n",
       "    'top_highlight': ''},\n",
       "   {'id': '620a84c14408',\n",
       "    'title': 'Powerful One-liners in Pandas Every Data Scientist Should Know',\n",
       "    'subtitle': 'Things you can do in one line using Pandas',\n",
       "    'author': '5d33decdf4c4',\n",
       "    'publication_id': '32881626c9c9',\n",
       "    'published_at': '2024-01-17 03:02:19',\n",
       "    'last_modified_at': '2024-01-17 03:09:18',\n",
       "    'tags': ['data-science',\n",
       "     'machine-learning',\n",
       "     'python',\n",
       "     'pandas',\n",
       "     'artificial-intelligence'],\n",
       "    'topics': ['data-science', 'programming'],\n",
       "    'claps': 448,\n",
       "    'voters': 86,\n",
       "    'word_count': 1542,\n",
       "    'responses_count': 5,\n",
       "    'reading_time': 7.418867924528302,\n",
       "    'url': 'https://medium.datadriveninvestor.com/powerful-one-liners-in-pandas-every-data-scientist-should-know-620a84c14408',\n",
       "    'unique_slug': 'powerful-one-liners-in-pandas-every-data-scientist-should-know-620a84c14408',\n",
       "    'image_url': 'https://miro.medium.com/0*npy63uZkFgDYzici',\n",
       "    'lang': 'en',\n",
       "    'is_series': False,\n",
       "    'is_locked': True,\n",
       "    'is_shortform': False,\n",
       "    'top_highlight': ''},\n",
       "   {'id': 'f67bb6e5317a',\n",
       "    'title': '20 Newbie Mistakes that Even Skilled Python Programmers Make',\n",
       "    'subtitle': 'A collection of common mistakes that you should avoid while coding in Python',\n",
       "    'author': '5d33decdf4c4',\n",
       "    'publication_id': '32881626c9c9',\n",
       "    'published_at': '2024-01-17 03:01:26',\n",
       "    'last_modified_at': '2024-02-13 05:37:08',\n",
       "    'tags': ['data-science',\n",
       "     'python',\n",
       "     'machine-learning',\n",
       "     'python-programming',\n",
       "     'artificial-intelligence'],\n",
       "    'topics': ['programming'],\n",
       "    'claps': 207,\n",
       "    'voters': 39,\n",
       "    'word_count': 1765,\n",
       "    'responses_count': 7,\n",
       "    'reading_time': 7.7937106918238985,\n",
       "    'url': 'https://medium.datadriveninvestor.com/20-newbie-mistakes-that-even-skilled-python-programmers-make-f67bb6e5317a',\n",
       "    'unique_slug': '20-newbie-mistakes-that-even-skilled-python-programmers-make-f67bb6e5317a',\n",
       "    'image_url': 'https://miro.medium.com/0*jN9CVaNSvGEE2ksQ',\n",
       "    'lang': 'en',\n",
       "    'is_series': False,\n",
       "    'is_locked': True,\n",
       "    'is_shortform': False,\n",
       "    'top_highlight': ''},\n",
       "   {'id': 'b2316bcc4c0f',\n",
       "    'title': '5 Jupyter Hacks That You Never Knew Even Existed',\n",
       "    'subtitle': 'With a bonus tip',\n",
       "    'author': '5d33decdf4c4',\n",
       "    'publication_id': '32881626c9c9',\n",
       "    'published_at': '2024-01-09 16:35:49',\n",
       "    'last_modified_at': '2024-01-23 15:19:34',\n",
       "    'tags': ['data-science',\n",
       "     'machine-learning',\n",
       "     'artificial-intelligence',\n",
       "     'python',\n",
       "     'programming'],\n",
       "    'topics': ['data-science', 'programming'],\n",
       "    'claps': 524,\n",
       "    'voters': 129,\n",
       "    'word_count': 1145,\n",
       "    'responses_count': 9,\n",
       "    'reading_time': 5.454088050314466,\n",
       "    'url': 'https://medium.datadriveninvestor.com/5-jupyter-hacks-that-you-never-knew-even-existed-b2316bcc4c0f',\n",
       "    'unique_slug': '5-jupyter-hacks-that-you-never-knew-even-existed-b2316bcc4c0f',\n",
       "    'image_url': 'https://miro.medium.com/0*HsAklpaUqoziyZmf',\n",
       "    'lang': 'en',\n",
       "    'is_series': False,\n",
       "    'is_locked': True,\n",
       "    'is_shortform': False,\n",
       "    'top_highlight': ''},\n",
       "   {'id': 'f1e31af2257a',\n",
       "    'title': 'Five Killer Optimization Techniques That Most Pandas Users Aren’t Aware Of',\n",
       "    'subtitle': 'A step towards data analysis run-time optimization',\n",
       "    'author': '5d33decdf4c4',\n",
       "    'publication_id': 'a648dc4ecb66',\n",
       "    'published_at': '2024-01-06 19:27:29',\n",
       "    'last_modified_at': '2024-01-12 06:16:39',\n",
       "    'tags': ['data-science',\n",
       "     'machine-learning',\n",
       "     'artificial-intelligence',\n",
       "     'python',\n",
       "     'pandas'],\n",
       "    'topics': ['data-science', 'programming'],\n",
       "    'claps': 559,\n",
       "    'voters': 153,\n",
       "    'word_count': 2030,\n",
       "    'responses_count': 6,\n",
       "    'reading_time': 8.910377358490566,\n",
       "    'url': 'https://towardsdev.com/five-killer-optimization-techniques-that-most-pandas-arent-aware-of-f1e31af2257a',\n",
       "    'unique_slug': 'five-killer-optimization-techniques-that-most-pandas-arent-aware-of-f1e31af2257a',\n",
       "    'image_url': 'https://miro.medium.com/0*aGty_aThlP_5zNyr',\n",
       "    'lang': 'en',\n",
       "    'is_series': False,\n",
       "    'is_locked': True,\n",
       "    'is_shortform': False,\n",
       "    'top_highlight': ''}]},\n",
       " '8c8e5b7182ef': {'id': '8c8e5b7182ef',\n",
       "  'username': 'iampaulrose',\n",
       "  'fullname': 'Paul Rose',\n",
       "  'bio': 'I am Paul Rose. A Faith-Led 5-Figure writer with viable online business ideas to share: Book My Services here: hello@iampaulrose.online',\n",
       "  'followers_count': 40019,\n",
       "  'following_count': 22,\n",
       "  'publication_following_count': 2,\n",
       "  'image_url': 'https://miro.medium.com/1*ciVcV4Ec9cARHdgwnGN4Eg.png',\n",
       "  'twitter_username': '',\n",
       "  'is_writer_program_enrolled': True,\n",
       "  'allow_notes': True,\n",
       "  'medium_member_at': '',\n",
       "  'is_suspended': False,\n",
       "  'top_writer_in': ['artificial-intelligence'],\n",
       "  'has_list': True,\n",
       "  'is_book_author': False,\n",
       "  'tipping_link': None,\n",
       "  'bg_image_url': '',\n",
       "  'logo_image_url': '',\n",
       "  'followers': ['0000a6571897',\n",
       "   '0008a90f7d7f',\n",
       "   '0009dee2120f',\n",
       "   '00121111de35',\n",
       "   '001479440872',\n",
       "   '001cda02fcc8',\n",
       "   '0023a4a5cccf',\n",
       "   '00246f9a3bb9',\n",
       "   '002a176869dc',\n",
       "   '002ea8cbcfe6',\n",
       "   '0031244c509e',\n",
       "   '0031a66e1c0a',\n",
       "   '00348dfc8976',\n",
       "   '00388d34235e',\n",
       "   '0041541f90e4',\n",
       "   '00461627c883',\n",
       "   '0046f2567302',\n",
       "   '004a8030a14f',\n",
       "   '004c0c1190e0',\n",
       "   '004c5bf99ca3',\n",
       "   '004c98a92f1e',\n",
       "   '004e20cb72b3',\n",
       "   '004eabca064a',\n",
       "   '005144e861bb',\n",
       "   '00514a15a497',\n",
       "   '0051a417ab48',\n",
       "   '0058b5cae97b',\n",
       "   '005a95dd3e00',\n",
       "   '005b0e23b5d5',\n",
       "   '005eac737ec5',\n",
       "   '0067079f283d',\n",
       "   '00688c9cb4b6',\n",
       "   '006ce3710ec2',\n",
       "   '007044b1abc2',\n",
       "   '0078a8c1aefd',\n",
       "   '007bea05ce8b',\n",
       "   '007f75dc5b13',\n",
       "   '007f82ad8d14',\n",
       "   '00828a580394',\n",
       "   '008336b15cb2',\n",
       "   '0085243f0078',\n",
       "   '00852dc4a8f8',\n",
       "   '00876614f6f2',\n",
       "   '00887a2a0019',\n",
       "   '008b26bd7f55',\n",
       "   '008bd264da31',\n",
       "   '008ddd676829',\n",
       "   '0099e6750330',\n",
       "   '009d52bf1f14',\n",
       "   '009e138ad99d',\n",
       "   '00a338135b96',\n",
       "   '00a6814e9fb8',\n",
       "   '00a998f54217',\n",
       "   '00abad96696a',\n",
       "   '00ad46289376',\n",
       "   '00b0ad7585f2',\n",
       "   '00b226d2cdfd',\n",
       "   '00b2d5b80654',\n",
       "   '00b8eada8b79',\n",
       "   '00b9a33bb81f',\n",
       "   '00bd45a429a2',\n",
       "   '00be927f89ab',\n",
       "   '00bf37dfa958',\n",
       "   '00bf76172539',\n",
       "   '00c0c5ad7d20',\n",
       "   '00c29e7b8855',\n",
       "   '00c3d47c9bdc',\n",
       "   '00c864ade3db',\n",
       "   '00c92de144a8',\n",
       "   '00cd031344d6',\n",
       "   '00cd0905c7a9',\n",
       "   '00d7db40ae51',\n",
       "   '00da4ebaf9e6',\n",
       "   '00dabd5cc1c8',\n",
       "   '00dd762aef3b',\n",
       "   '00de22ec4707',\n",
       "   '00df1a732cde',\n",
       "   '00e279792601',\n",
       "   '00e307da3db2',\n",
       "   '00e97ebedb8a',\n",
       "   '00ebb2df916a',\n",
       "   '00efb7dca942',\n",
       "   '00f1dddb885d',\n",
       "   '00f29e780193',\n",
       "   '00f2ac2ee90c',\n",
       "   '00f2b39df175',\n",
       "   '00fcb9e6c880',\n",
       "   '0102838e5346',\n",
       "   '010285d248a0',\n",
       "   '01054c60a74b',\n",
       "   '0108b7898242',\n",
       "   '010d900f4f08',\n",
       "   '010dfba1fa83',\n",
       "   '010f43fe49da',\n",
       "   '0110c5453e04',\n",
       "   '0111fe792d8c',\n",
       "   '011448276703',\n",
       "   '0115c36ef483',\n",
       "   '0118db6944de',\n",
       "   '012072537565',\n",
       "   '0120fe55e44b',\n",
       "   '01247722f2d2',\n",
       "   '01252b645741',\n",
       "   '0125fe812e98',\n",
       "   '0126db676b5c',\n",
       "   '012b181e1fba',\n",
       "   '012fbed07467',\n",
       "   '012fdb5da8ec',\n",
       "   '013141d04d67',\n",
       "   '01324c4cb04f',\n",
       "   '013472d18757',\n",
       "   '0140b0fcc755',\n",
       "   '01446399ce9a',\n",
       "   '0145e38f5621',\n",
       "   '014670628993',\n",
       "   '0146b43458a7',\n",
       "   '014c206a567d',\n",
       "   '014e7f3319d2',\n",
       "   '0158b5dca221',\n",
       "   '0159248ebd9d',\n",
       "   '0161834c87ce',\n",
       "   '0162e49590d5',\n",
       "   '01663a4bdf0c',\n",
       "   '016af649be8c',\n",
       "   '0174392b5871',\n",
       "   '017502aab5dd',\n",
       "   '0176a24fa729',\n",
       "   '01782b701a24',\n",
       "   '017974e6b3bb',\n",
       "   '017beb27a328',\n",
       "   '017eb98156b0',\n",
       "   '0180435fba92',\n",
       "   '0181d61ce69a',\n",
       "   '018356794628',\n",
       "   '01881ecb24b2',\n",
       "   '018bb99f378e',\n",
       "   '01990c65fee3',\n",
       "   '019f13a609df',\n",
       "   '01a6eed31abb',\n",
       "   '01abcc58edd1',\n",
       "   '01aece4b6234',\n",
       "   '01b144d2c7aa',\n",
       "   '01b59d1c170a',\n",
       "   '01b6b3976822',\n",
       "   '01b6b8539a0f',\n",
       "   '01b7d6e14e06',\n",
       "   '01bace87a8ca',\n",
       "   '01c27ec40175',\n",
       "   '01c2c1fff3a7',\n",
       "   '01c42fc5d27c',\n",
       "   '01c5cde1a0f3',\n",
       "   '01c7bf6b5fee',\n",
       "   '01c9ec4b7ad7',\n",
       "   '01cd59d6712d',\n",
       "   '01cf0debc091',\n",
       "   '01d61addd690',\n",
       "   '01d6ca04e85f',\n",
       "   '01d92b58569d',\n",
       "   '01d9cc1c64d3',\n",
       "   '01da1d589b4e',\n",
       "   '01dc6815573d',\n",
       "   '01dcf66e6129',\n",
       "   '01df5693fbe3',\n",
       "   '01dfdc67abb4',\n",
       "   '01e09d0d2c0d',\n",
       "   '01e20e91a531',\n",
       "   '01e51829d427',\n",
       "   '01e57daf3792',\n",
       "   '01e92bda419a',\n",
       "   '01f0841afdf5',\n",
       "   '01f41843a8eb',\n",
       "   '01f47833341b',\n",
       "   '01f6bd20de5f',\n",
       "   '01f8b0ded080',\n",
       "   '01faad01498c',\n",
       "   '01fced2bc1fb',\n",
       "   '0204e90c8fc5',\n",
       "   '0204ef6947ed',\n",
       "   '020a816b0330',\n",
       "   '0212a3c23533',\n",
       "   '0213d25f83a0',\n",
       "   '02147b72ccdc',\n",
       "   '0216cd8af098',\n",
       "   '02174e76d3c2',\n",
       "   '021845e465c3',\n",
       "   '02196c29640d',\n",
       "   '021ec30c749e',\n",
       "   '0222ca211b33',\n",
       "   '0224fb58572d',\n",
       "   '0232d63472f7',\n",
       "   '023bfd20611a',\n",
       "   '0241fbdcc2de',\n",
       "   '02453bf6fb4f',\n",
       "   '024732db4896',\n",
       "   '0249960b42f0',\n",
       "   '02535fd5d9e2',\n",
       "   '025441c4cf72',\n",
       "   '0254c3fc1245',\n",
       "   '0255a6b87784',\n",
       "   '0258cd7dd371',\n",
       "   '025c47d6e1fb',\n",
       "   '025f7eb40f94',\n",
       "   '02673bdad0ff',\n",
       "   '026a05a7039e',\n",
       "   '026b6e49bd1a',\n",
       "   '0273d8927bef',\n",
       "   '02746ee744b1',\n",
       "   '02755bb63273',\n",
       "   '027591fe81d7',\n",
       "   '02816671a5e7',\n",
       "   '02816a568fdb',\n",
       "   '0281c9edcf53',\n",
       "   '028495e9580a',\n",
       "   '0284e5b85bb5',\n",
       "   '0287accaaf1d',\n",
       "   '02889a8fdb61',\n",
       "   '02895332c321',\n",
       "   '028df5c3ab56',\n",
       "   '0291cc704a0f',\n",
       "   '0292cfd39c8b',\n",
       "   '0293663044a9',\n",
       "   '02942f450ffe',\n",
       "   '029482385112',\n",
       "   '02975fb9e397',\n",
       "   '029b77d8edc5',\n",
       "   '029e00a83ad8',\n",
       "   '02a00a2d45c3',\n",
       "   '02a46ec65eda',\n",
       "   '02a4afe1c62f',\n",
       "   '02a543005871',\n",
       "   '02a8bf44be84',\n",
       "   '02ae849c6e4d',\n",
       "   '02af5b038892',\n",
       "   '02b0c4df08db',\n",
       "   '02b0cba4f85e',\n",
       "   '02b5114c779a',\n",
       "   '02b79380469f',\n",
       "   '02b847074ab7',\n",
       "   '02bbd17887c1',\n",
       "   '02bd72b57e7d',\n",
       "   '02be761bfb2d',\n",
       "   '02c06716feea',\n",
       "   '02c56e86fe5e',\n",
       "   '02c605a55873',\n",
       "   '02cd02987793',\n",
       "   '02cf374e2ba8',\n",
       "   '02d0530432da',\n",
       "   '02d41a047dbb',\n",
       "   '02d63c21760c',\n",
       "   '02d7581eb08b',\n",
       "   '02d853f90ec1',\n",
       "   '02d90d9c12a4',\n",
       "   '02db121b8208',\n",
       "   '02df76ec54b6',\n",
       "   '02e055ad3d54',\n",
       "   '02e46356161d',\n",
       "   '02e7f1aafe0a',\n",
       "   '02e8916de07c',\n",
       "   '02eabc5afc9b',\n",
       "   '02eaf3040291',\n",
       "   '02ec3c3965d7',\n",
       "   '02ed07da7b7f',\n",
       "   '02f38b77d466',\n",
       "   '02f9009f19a9',\n",
       "   '02f9493e4478',\n",
       "   '02f9665647fe',\n",
       "   '02fc92bd91c2',\n",
       "   '03011804df2a',\n",
       "   '0301f0276167',\n",
       "   '030207032d8b',\n",
       "   '03065cdbf766',\n",
       "   '030c1c2d30cc',\n",
       "   '030f88006732',\n",
       "   '0311d6bbc2b3',\n",
       "   '031310aab142',\n",
       "   '03138f5ff046',\n",
       "   '0316d7e5df44',\n",
       "   '031c39ccb611',\n",
       "   '031c8883784a',\n",
       "   '031f2761b09d',\n",
       "   '031febdd6afe',\n",
       "   '03222f72e0ac',\n",
       "   '032580f1cb46',\n",
       "   '03264e120660',\n",
       "   '032d5abb77b8',\n",
       "   '032feba1632d',\n",
       "   '03306b172d54',\n",
       "   '0331edf90e25',\n",
       "   '0332239585f9',\n",
       "   '033277b1bb4d',\n",
       "   '033543f7ae60',\n",
       "   '03364292d6cd',\n",
       "   '0338fbd35117',\n",
       "   '033b94e5332a',\n",
       "   '033dddc0e361',\n",
       "   '033f73e79d6e',\n",
       "   '03416dedaeef',\n",
       "   '0344d3bc4e4e',\n",
       "   '03487d9e6ab6',\n",
       "   '034d31bc0cce',\n",
       "   '034f59d2a2b6',\n",
       "   '0356a6d54d75',\n",
       "   '0357c9c8b95e',\n",
       "   '03587a17e4f1',\n",
       "   '0358d2c322bb',\n",
       "   '03609e9ab716',\n",
       "   '0369f9952c90',\n",
       "   '036ecf5a78de',\n",
       "   '036f96145c35',\n",
       "   '0373b59500f0',\n",
       "   '0375742afb7f',\n",
       "   '0375cf039b1f',\n",
       "   '03778713d516',\n",
       "   '037923a36dfe',\n",
       "   '037cf47840d3',\n",
       "   '037e56d957e3',\n",
       "   '037eb302f1b6',\n",
       "   '037f3a15d265',\n",
       "   '03809bbd4626',\n",
       "   '038ac12ed38b',\n",
       "   '038ebf7c20c8',\n",
       "   '0394cbc345e8',\n",
       "   '03954ee233b7',\n",
       "   '039563a6c0f4',\n",
       "   '0396e51ec32d',\n",
       "   '039cc4c0bbcf',\n",
       "   '039e1349ed1d',\n",
       "   '03abcd2b84ea',\n",
       "   '03b3549b5abf',\n",
       "   '03b4a1b945c1',\n",
       "   '03b52ef93f2c',\n",
       "   '03bc0f18c610',\n",
       "   '03bfe8127859',\n",
       "   '03bff1292d9c',\n",
       "   '03c167203c08',\n",
       "   '03c1aad4bb27',\n",
       "   '03c318223ccd',\n",
       "   '03c3e57423f1',\n",
       "   '03c5ef696031',\n",
       "   '03cab8b23624',\n",
       "   '03cad22f2d67',\n",
       "   '03cc3c502760',\n",
       "   '03d778a58360',\n",
       "   '03da63b7de2a',\n",
       "   '03db173a95a5',\n",
       "   '03e21728b8a8',\n",
       "   '03e34216c276',\n",
       "   '03e3ce676ea6',\n",
       "   '03e5adae14e8',\n",
       "   '03e5bbf1c58b',\n",
       "   '03e805a06b94',\n",
       "   '03e94dc60823',\n",
       "   '03ea8addd8c5',\n",
       "   '03f381560951',\n",
       "   '03f6b4337b59',\n",
       "   '03f6ee79f36c',\n",
       "   '03f7a9298630',\n",
       "   '03f811a2765f',\n",
       "   '03f81fb26117',\n",
       "   '03f92b467616',\n",
       "   '03f9f760efe8',\n",
       "   '03fa533aee11',\n",
       "   '03faf8478b3c',\n",
       "   '040011a8e244',\n",
       "   '040180bca2cc',\n",
       "   '040514b5961e',\n",
       "   '0408a97d7661',\n",
       "   '04093c78da7f',\n",
       "   '040b368f8924',\n",
       "   '041038a06af0',\n",
       "   '0416cd768aa7',\n",
       "   '041b31277374',\n",
       "   '041f934e6edc',\n",
       "   '0421dfe57484',\n",
       "   '0424cd3b13bb',\n",
       "   '042830f5c385',\n",
       "   '042d5c18f7df',\n",
       "   '04309e2cef08',\n",
       "   '043221bf8ccc',\n",
       "   '0434b6c60a39',\n",
       "   '04384c3f6ee2',\n",
       "   '04393e013407',\n",
       "   '043bcc47b08b',\n",
       "   '043fe8379c89',\n",
       "   '043ff8992ec6',\n",
       "   '044473c7fcc2',\n",
       "   '04480c952a8b',\n",
       "   '044dad8f3a33',\n",
       "   '04507796390c',\n",
       "   '04548e168f72',\n",
       "   '0455212572af',\n",
       "   '045522282a31',\n",
       "   '0458a9932086',\n",
       "   '046054fee6d5',\n",
       "   '0462c5cb781e',\n",
       "   '04676cca0eba',\n",
       "   '046befb47a5c',\n",
       "   '046dee9c1a33',\n",
       "   '046f821cca84',\n",
       "   '047dbce543a9',\n",
       "   '047f817e27eb',\n",
       "   '0480c1a4b86f',\n",
       "   '04820b0e1d7f',\n",
       "   '04840369bb54',\n",
       "   '0485b6f6e008',\n",
       "   '0486e2bab99f',\n",
       "   '0487921a2cd9',\n",
       "   '0487a70bd406',\n",
       "   '0488cb6529c7',\n",
       "   '04890d43acab',\n",
       "   '048979b866f1',\n",
       "   '048c4dbe2902',\n",
       "   '04910b161709',\n",
       "   '0493aea76b52',\n",
       "   '049708098c50',\n",
       "   '049aaa2a9211',\n",
       "   '049be2ba8a3b',\n",
       "   '049d24cede8e',\n",
       "   '049dbabe955a',\n",
       "   '049eee9fef11',\n",
       "   '04a709db6561',\n",
       "   '04a9353fcc2e',\n",
       "   '04a9a4f16791',\n",
       "   '04ac936cc7c4',\n",
       "   '04add81c5fad',\n",
       "   '04aeafb19e7d',\n",
       "   '04b05ca640a6',\n",
       "   '04b35f2e10cb',\n",
       "   '04b6ceaf0f25',\n",
       "   '04b8b0227b8b',\n",
       "   '04be9e365e20',\n",
       "   '04c41cedf4c4',\n",
       "   '04c629da31af',\n",
       "   '04ca63f69a55',\n",
       "   '04cd9c28ab37',\n",
       "   '04ce0ada381f',\n",
       "   '04d5ed47b8c3',\n",
       "   '04d6cd12f849',\n",
       "   '04d7b08c81c8',\n",
       "   '04da2d2ca678',\n",
       "   '04df76d56fc1',\n",
       "   '04dfdc4ef56b',\n",
       "   '04e70c9a0ce9',\n",
       "   '04e8f0536eb2',\n",
       "   '04e93b810724',\n",
       "   '04e94eb13d69',\n",
       "   '04ecdfce0104',\n",
       "   '04f020827223',\n",
       "   '04f02a2276f3',\n",
       "   '04f063d9956b',\n",
       "   '04f4564e0a8b',\n",
       "   '04fcaf4d395d',\n",
       "   '04fd48136f67',\n",
       "   '0505a3c915e9',\n",
       "   '0506d49d2b82',\n",
       "   '0506dd348542',\n",
       "   '05075ad06a6c',\n",
       "   '0510ef507dfa',\n",
       "   '051276cc78f1',\n",
       "   '0512ca74b513',\n",
       "   '051bf35d4e0a',\n",
       "   '05206ee25cf4',\n",
       "   '0522b8bdc6c2',\n",
       "   '0523b8decd5f',\n",
       "   '0525226e118e',\n",
       "   '052c8a5a77a9'],\n",
       "  'top_articles': [{'id': '2eb0d15d6d77',\n",
       "    'title': 'I Built The 5 Income Streams Every Writer Should Have',\n",
       "    'subtitle': 'How To Make Money as a Writer',\n",
       "    'author': '8c8e5b7182ef',\n",
       "    'publication_id': '*Self-Published*',\n",
       "    'published_at': '2024-02-16 19:39:53',\n",
       "    'last_modified_at': '2024-02-16 19:44:12',\n",
       "    'tags': ['passive-income',\n",
       "     'side-hustle',\n",
       "     'make-money-online',\n",
       "     'affiliate-marketing',\n",
       "     'writer'],\n",
       "    'topics': ['freelancing', 'writing'],\n",
       "    'claps': 558,\n",
       "    'voters': 55,\n",
       "    'word_count': 2022,\n",
       "    'responses_count': 10,\n",
       "    'reading_time': 9.330188679245282,\n",
       "    'url': 'https://medium.com/@iampaulrose/i-built-the-5-income-streams-every-writer-should-have-2eb0d15d6d77',\n",
       "    'unique_slug': 'i-built-the-5-income-streams-every-writer-should-have-2eb0d15d6d77',\n",
       "    'image_url': 'https://miro.medium.com/0*qHvZkZbMS3hS2S7b',\n",
       "    'lang': 'en',\n",
       "    'is_series': False,\n",
       "    'is_locked': False,\n",
       "    'is_shortform': False,\n",
       "    'top_highlight': \"By posting high-quality content pieces on traffic platforms, you'll be passively building a portfolio of content for potential clients to see.\"},\n",
       "   {'id': '40f61887f107',\n",
       "    'title': 'I Found 5 Ways To Make Money With AI Art',\n",
       "    'subtitle': 'How To Make Passive Income With AI Art',\n",
       "    'author': '8c8e5b7182ef',\n",
       "    'publication_id': '*Self-Published*',\n",
       "    'published_at': '2024-02-15 02:43:52',\n",
       "    'last_modified_at': '2024-02-16 02:19:12',\n",
       "    'tags': ['ai',\n",
       "     'artificial-intelligence',\n",
       "     'ai-art',\n",
       "     'passive-income',\n",
       "     'side-hustle'],\n",
       "    'topics': ['artificial-intelligence'],\n",
       "    'claps': 530,\n",
       "    'voters': 51,\n",
       "    'word_count': 1942,\n",
       "    'responses_count': 7,\n",
       "    'reading_time': 9.678301886792452,\n",
       "    'url': 'https://medium.com/@iampaulrose/i-found-5-ways-to-make-money-with-ai-art-40f61887f107',\n",
       "    'unique_slug': 'i-found-5-ways-to-make-money-with-ai-art-40f61887f107',\n",
       "    'image_url': 'https://miro.medium.com/0*MOAhI1B6TFGBfkOl',\n",
       "    'lang': 'en',\n",
       "    'is_series': False,\n",
       "    'is_locked': False,\n",
       "    'is_shortform': False,\n",
       "    'top_highlight': ''},\n",
       "   {'id': 'abb6f463e3cb',\n",
       "    'title': 'I Sold on Gumroad For 6 Months',\n",
       "    'subtitle': 'How Much Did I Make and How Can A Beginner Start Something Similar?',\n",
       "    'author': '8c8e5b7182ef',\n",
       "    'publication_id': '*Self-Published*',\n",
       "    'published_at': '2024-02-12 22:51:09',\n",
       "    'last_modified_at': '2024-02-12 23:10:08',\n",
       "    'tags': ['passive-income',\n",
       "     'make-money-online',\n",
       "     'gumroad',\n",
       "     'notion',\n",
       "     'side-hustle'],\n",
       "    'topics': ['marketing', 'startups'],\n",
       "    'claps': 434,\n",
       "    'voters': 71,\n",
       "    'word_count': 2075,\n",
       "    'responses_count': 24,\n",
       "    'reading_time': 9.430188679245283,\n",
       "    'url': 'https://medium.com/@iampaulrose/i-sold-on-gumroad-for-6-months-abb6f463e3cb',\n",
       "    'unique_slug': 'i-sold-on-gumroad-for-6-months-abb6f463e3cb',\n",
       "    'image_url': 'https://miro.medium.com/1*_nf5axcmGlNl5uk7Bj4Xuw.jpeg',\n",
       "    'lang': 'en',\n",
       "    'is_series': False,\n",
       "    'is_locked': False,\n",
       "    'is_shortform': False,\n",
       "    'top_highlight': 'Because zero traffic = zero sales.'},\n",
       "   {'id': '1c0e84854e4e',\n",
       "    'title': 'How To Write An eBook and Actually Make Passive Income',\n",
       "    'subtitle': 'Without Spending Month Writing Your First Draft',\n",
       "    'author': '8c8e5b7182ef',\n",
       "    'publication_id': '*Self-Published*',\n",
       "    'published_at': '2024-02-10 21:44:02',\n",
       "    'last_modified_at': '2024-02-10 21:52:01',\n",
       "    'tags': ['passive-income',\n",
       "     'side-hustle',\n",
       "     'make-money-online',\n",
       "     'gumroad',\n",
       "     'online-business'],\n",
       "    'topics': ['writing'],\n",
       "    'claps': 1514,\n",
       "    'voters': 137,\n",
       "    'word_count': 1679,\n",
       "    'responses_count': 32,\n",
       "    'reading_time': 7.835849056603774,\n",
       "    'url': 'https://medium.com/@iampaulrose/how-to-write-an-ebook-and-actually-make-passive-income-1c0e84854e4e',\n",
       "    'unique_slug': 'how-to-write-an-ebook-and-actually-make-passive-income-1c0e84854e4e',\n",
       "    'image_url': 'https://miro.medium.com/0*ZwHe-qqWjx5s5fup',\n",
       "    'lang': 'en',\n",
       "    'is_series': False,\n",
       "    'is_locked': False,\n",
       "    'is_shortform': False,\n",
       "    'top_highlight': 'Medium + quality eBooks = thousands of dollars in passive.'},\n",
       "   {'id': 'fc25899ff745',\n",
       "    'title': 'I Started a Cute & Profitable Side Hustle',\n",
       "    'subtitle': 'And I’m Loving It So Far',\n",
       "    'author': '8c8e5b7182ef',\n",
       "    'publication_id': '*Self-Published*',\n",
       "    'published_at': '2024-02-08 22:38:04',\n",
       "    'last_modified_at': '2024-02-08 22:46:38',\n",
       "    'tags': ['passive-income',\n",
       "     'side-hustle',\n",
       "     'make-money-online',\n",
       "     'ai',\n",
       "     'ai-art'],\n",
       "    'topics': ['marketing'],\n",
       "    'claps': 1770,\n",
       "    'voters': 191,\n",
       "    'word_count': 2102,\n",
       "    'responses_count': 47,\n",
       "    'reading_time': 10.232075471698113,\n",
       "    'url': 'https://medium.com/@iampaulrose/i-started-a-cute-profitable-side-hustle-fc25899ff745',\n",
       "    'unique_slug': 'i-started-a-cute-profitable-side-hustle-fc25899ff745',\n",
       "    'image_url': 'https://miro.medium.com/0*0SGdByWaPIXUmbaD',\n",
       "    'lang': 'en',\n",
       "    'is_series': False,\n",
       "    'is_locked': False,\n",
       "    'is_shortform': False,\n",
       "    'top_highlight': ''},\n",
       "   {'id': '9fe3b230f547',\n",
       "    'title': 'An Easy Canva Side Hustle To Try For Passive Income',\n",
       "    'subtitle': 'How To Make Your First Dollar Online ',\n",
       "    'author': '8c8e5b7182ef',\n",
       "    'publication_id': '*Self-Published*',\n",
       "    'published_at': '2024-02-06 22:21:42',\n",
       "    'last_modified_at': '2024-02-07 05:49:35',\n",
       "    'tags': ['amazon',\n",
       "     'chatgpt',\n",
       "     'passive-income',\n",
       "     'side-hustle',\n",
       "     'make-money-online'],\n",
       "    'topics': ['marketing'],\n",
       "    'claps': 775,\n",
       "    'voters': 112,\n",
       "    'word_count': 1945,\n",
       "    'responses_count': 21,\n",
       "    'reading_time': 9.139622641509435,\n",
       "    'url': 'https://medium.com/@iampaulrose/an-easy-canva-side-hustle-to-try-for-passive-income-9fe3b230f547',\n",
       "    'unique_slug': 'an-easy-canva-side-hustle-to-try-for-passive-income-9fe3b230f547',\n",
       "    'image_url': 'https://miro.medium.com/0*px8ihcYxmIlESEnH',\n",
       "    'lang': 'en',\n",
       "    'is_series': False,\n",
       "    'is_locked': False,\n",
       "    'is_shortform': False,\n",
       "    'top_highlight': ''},\n",
       "   {'id': '1899e0b4b098',\n",
       "    'title': 'A Side Hustle Better Than Selling Canva Templates',\n",
       "    'subtitle': 'I Love Canva Templates But This Is Better ',\n",
       "    'author': '8c8e5b7182ef',\n",
       "    'publication_id': '*Self-Published*',\n",
       "    'published_at': '2024-02-04 19:20:02',\n",
       "    'last_modified_at': '2024-02-04 19:23:46',\n",
       "    'tags': ['passive-income',\n",
       "     'make-money-online-fast',\n",
       "     'chatgpt',\n",
       "     'notion',\n",
       "     'gumroad'],\n",
       "    'topics': ['marketing'],\n",
       "    'claps': 1692,\n",
       "    'voters': 251,\n",
       "    'word_count': 1850,\n",
       "    'responses_count': 32,\n",
       "    'reading_time': 8.731132075471699,\n",
       "    'url': 'https://medium.com/@iampaulrose/a-side-hustle-better-than-selling-canva-templates-1899e0b4b098',\n",
       "    'unique_slug': 'a-side-hustle-better-than-selling-canva-templates-1899e0b4b098',\n",
       "    'image_url': 'https://miro.medium.com/0*ouK5AEYap1hXkmTQ',\n",
       "    'lang': 'en',\n",
       "    'is_series': False,\n",
       "    'is_locked': False,\n",
       "    'is_shortform': False,\n",
       "    'top_highlight': ''},\n",
       "   {'id': '0bbfd98ac496',\n",
       "    'title': 'I Tried Making Money With a Free AI Art Generator',\n",
       "    'subtitle': 'How To Make Money with AI Art',\n",
       "    'author': '8c8e5b7182ef',\n",
       "    'publication_id': '*Self-Published*',\n",
       "    'published_at': '2024-02-02 21:43:31',\n",
       "    'last_modified_at': '2024-02-03 06:13:24',\n",
       "    'tags': ['ai-art',\n",
       "     'ai',\n",
       "     'artificial-intelligence',\n",
       "     'passive-income',\n",
       "     'make-money-online'],\n",
       "    'topics': ['artificial-intelligence', 'marketing'],\n",
       "    'claps': 4188,\n",
       "    'voters': 511,\n",
       "    'word_count': 1565,\n",
       "    'responses_count': 88,\n",
       "    'reading_time': 8.05566037735849,\n",
       "    'url': 'https://medium.com/@iampaulrose/i-tried-making-money-with-a-free-ai-art-generator-0bbfd98ac496',\n",
       "    'unique_slug': 'i-tried-making-money-with-a-free-ai-art-generator-0bbfd98ac496',\n",
       "    'image_url': 'https://miro.medium.com/1*ZOMR_5njto2MATAKRtD3yw.jpeg',\n",
       "    'lang': 'en',\n",
       "    'is_series': False,\n",
       "    'is_locked': False,\n",
       "    'is_shortform': False,\n",
       "    'top_highlight': \"It's super easy to get acquainted with this art generator and I highly recommend it for beginners.\"},\n",
       "   {'id': 'a506114d7a46',\n",
       "    'title': 'How To Write On Medium For Passive Income In 2024',\n",
       "    'subtitle': 'The Seamless Story Strategy ',\n",
       "    'author': '8c8e5b7182ef',\n",
       "    'publication_id': '*Self-Published*',\n",
       "    'published_at': '2024-01-31 21:22:12',\n",
       "    'last_modified_at': '2024-01-31 21:22:12',\n",
       "    'tags': ['passive-income',\n",
       "     'side-hustle',\n",
       "     'make-money-online',\n",
       "     'online-business',\n",
       "     'medium'],\n",
       "    'topics': ['writing', 'marketing'],\n",
       "    'claps': 565,\n",
       "    'voters': 56,\n",
       "    'word_count': 1849,\n",
       "    'responses_count': 17,\n",
       "    'reading_time': 8.427358490566037,\n",
       "    'url': 'https://medium.com/@iampaulrose/how-to-write-on-medium-for-passive-income-in-2024-a506114d7a46',\n",
       "    'unique_slug': 'how-to-write-on-medium-for-passive-income-in-2024-a506114d7a46',\n",
       "    'image_url': 'https://miro.medium.com/0*jofiNnNPWCgs4DaL',\n",
       "    'lang': 'en',\n",
       "    'is_series': False,\n",
       "    'is_locked': False,\n",
       "    'is_shortform': False,\n",
       "    'top_highlight': 'Give first, ask after.'},\n",
       "   {'id': 'bf026cd7e80f',\n",
       "    'title': 'How I Make $100 Per Day In Passive Income As a Writer',\n",
       "    'subtitle': 'A Writer’s Guide To Passive Income ',\n",
       "    'author': '8c8e5b7182ef',\n",
       "    'publication_id': '*Self-Published*',\n",
       "    'published_at': '2024-01-29 19:59:22',\n",
       "    'last_modified_at': '2024-01-29 19:59:22',\n",
       "    'tags': ['passive-income',\n",
       "     'side-hustle',\n",
       "     'make-money-online',\n",
       "     'writers-on-medium',\n",
       "     'online-business'],\n",
       "    'topics': ['freelancing', 'writing'],\n",
       "    'claps': 643,\n",
       "    'voters': 51,\n",
       "    'word_count': 1757,\n",
       "    'responses_count': 20,\n",
       "    'reading_time': 8.280188679245283,\n",
       "    'url': 'https://medium.com/@iampaulrose/how-i-make-100-per-day-in-passive-income-as-a-writer-bf026cd7e80f',\n",
       "    'unique_slug': 'how-i-make-100-per-day-in-passive-income-as-a-writer-bf026cd7e80f',\n",
       "    'image_url': 'https://miro.medium.com/0*t6pwyW9OiBg1Y4gO',\n",
       "    'lang': 'en',\n",
       "    'is_series': False,\n",
       "    'is_locked': False,\n",
       "    'is_shortform': False,\n",
       "    'top_highlight': 'You need to be able to churn out new stories at least 3 times a week, without compromising on the quality.'}]},\n",
       " '37a2cbe8bd15': {'id': '37a2cbe8bd15',\n",
       "  'username': 'pareto_investor',\n",
       "  'fullname': 'The Pareto Investor',\n",
       "  'bio': '',\n",
       "  'followers_count': 38872,\n",
       "  'following_count': 0,\n",
       "  'publication_following_count': 0,\n",
       "  'image_url': 'https://miro.medium.com/1*b_HcCX1sv_BC8k-CdPk8dQ.png',\n",
       "  'twitter_username': 'pareto_investor',\n",
       "  'is_writer_program_enrolled': True,\n",
       "  'allow_notes': False,\n",
       "  'medium_member_at': '2022-12-01 10:48:27',\n",
       "  'is_suspended': False,\n",
       "  'top_writer_in': ['business',\n",
       "   'artificial-intelligence',\n",
       "   'science',\n",
       "   'technology',\n",
       "   'entrepreneurship',\n",
       "   'investing',\n",
       "   'innovation',\n",
       "   'finance',\n",
       "   'future',\n",
       "   'education',\n",
       "   'startup'],\n",
       "  'has_list': True,\n",
       "  'is_book_author': True,\n",
       "  'tipping_link': 'https://buy.stripe.com/5kA4h51K307mapq7ss',\n",
       "  'bg_image_url': '',\n",
       "  'logo_image_url': '',\n",
       "  'followers': ['0000a6571897',\n",
       "   '0000d489eba9',\n",
       "   '0002df3940d5',\n",
       "   '00059c07a524',\n",
       "   '0008a90f7d7f',\n",
       "   '0009a6a21190',\n",
       "   '0009dee2120f',\n",
       "   '00116aa9884a',\n",
       "   '00121111de35',\n",
       "   '00149b7421b2',\n",
       "   '0016c6d6a984',\n",
       "   '00183ef79cce',\n",
       "   '001aa2fef563',\n",
       "   '001cda02fcc8',\n",
       "   '001d3500f024',\n",
       "   '001fa7916bd6',\n",
       "   '002324d8d54e',\n",
       "   '0023a4a5cccf',\n",
       "   '0023ab307b0a',\n",
       "   '00245ad345da',\n",
       "   '0024d33e6c7d',\n",
       "   '00269ae4ca4c',\n",
       "   '0026f580dd1c',\n",
       "   '00281ba99460',\n",
       "   '002ad9a41d6c',\n",
       "   '0030e2bb3393',\n",
       "   '00348dfc8976',\n",
       "   '0037f86827fc',\n",
       "   '003a91d0f9a1',\n",
       "   '0041541f90e4',\n",
       "   '00418aadfc4b',\n",
       "   '004249638f40',\n",
       "   '00456e4a5913',\n",
       "   '0049d4282be9',\n",
       "   '004bab759a12',\n",
       "   '004c089e7e84',\n",
       "   '004c5bf99ca3',\n",
       "   '004c7dcf0101',\n",
       "   '004eabca064a',\n",
       "   '005144e861bb',\n",
       "   '00514a15a497',\n",
       "   '0055540ed1c8',\n",
       "   '00555da4d13e',\n",
       "   '00570f3efb38',\n",
       "   '005956b07565',\n",
       "   '0059a794608a',\n",
       "   '005a95dd3e00',\n",
       "   '005b0e23b5d5',\n",
       "   '005bd74ecb32',\n",
       "   '005fa32445d4',\n",
       "   '00615f94806a',\n",
       "   '006219942518',\n",
       "   '00660fd05fa7',\n",
       "   '0067079f283d',\n",
       "   '00688c9cb4b6',\n",
       "   '007091a67938',\n",
       "   '0076bbf71f48',\n",
       "   '0076c2a4fccc',\n",
       "   '0078a8c1aefd',\n",
       "   '007a99cfdd88',\n",
       "   '007e9440626b',\n",
       "   '007f75dc5b13',\n",
       "   '007f82ad8d14',\n",
       "   '00850ccafbce',\n",
       "   '0086caac613e',\n",
       "   '00887a2a0019',\n",
       "   '008b26bd7f55',\n",
       "   '008b6a717429',\n",
       "   '008bd264da31',\n",
       "   '008ddd676829',\n",
       "   '008e42d846db',\n",
       "   '0097313f5838',\n",
       "   '009867af188a',\n",
       "   '0099e6750330',\n",
       "   '009d52bf1f14',\n",
       "   '009d6ed390ee',\n",
       "   '009daf38588f',\n",
       "   '00a07f50ac66',\n",
       "   '00a2033e3de5',\n",
       "   '00a325e40797',\n",
       "   '00a6814e9fb8',\n",
       "   '00a78a6007f4',\n",
       "   '00a7f4726d5b',\n",
       "   '00abad96696a',\n",
       "   '00adf31ab408',\n",
       "   '00b2c392e7d2',\n",
       "   '00b2d5b80654',\n",
       "   '00b4f2f9e451',\n",
       "   '00bf76172539',\n",
       "   '00c0b174f5eb',\n",
       "   '00c0c5ad7d20',\n",
       "   '00c3d47c9bdc',\n",
       "   '00c864ade3db',\n",
       "   '00c92de144a8',\n",
       "   '00cc00410196',\n",
       "   '00cf6cd10199',\n",
       "   '00d098d3c48e',\n",
       "   '00d4226226d8',\n",
       "   '00d9fed5f4f3',\n",
       "   '00da4ebaf9e6',\n",
       "   '00dabd5cc1c8',\n",
       "   '00dd5ca6857d',\n",
       "   '00dd762aef3b',\n",
       "   '00de22ec4707',\n",
       "   '00e192972eac',\n",
       "   '00e64025302f',\n",
       "   '00e8ccaf36ec',\n",
       "   '00e974fe1be5',\n",
       "   '00e97ebedb8a',\n",
       "   '00ebb2df916a',\n",
       "   '00ed2c9c84c6',\n",
       "   '00ee2b300b93',\n",
       "   '00efb7dca942',\n",
       "   '00f1dddb885d',\n",
       "   '00f24bcd7bd7',\n",
       "   '00f29e780193',\n",
       "   '00f2ac2ee90c',\n",
       "   '00f2b39df175',\n",
       "   '00f2d8152332',\n",
       "   '00f43a7695e4',\n",
       "   '0100778b4d3c',\n",
       "   '01010508c78c',\n",
       "   '0102838e5346',\n",
       "   '010450c4eee1',\n",
       "   '01054c60a74b',\n",
       "   '010740fb5f37',\n",
       "   '0109e784bcf3',\n",
       "   '010aff80b0a3',\n",
       "   '0111fe792d8c',\n",
       "   '011448276703',\n",
       "   '01187ddb099e',\n",
       "   '012072537565',\n",
       "   '01247722f2d2',\n",
       "   '0126db676b5c',\n",
       "   '012b23a80707',\n",
       "   '012fbed07467',\n",
       "   '012fdb5da8ec',\n",
       "   '01320255ccb5',\n",
       "   '0132641e0bd2',\n",
       "   '013472d18757',\n",
       "   '0143c3cfd773',\n",
       "   '0145e38f5621',\n",
       "   '014c206a567d',\n",
       "   '014c3755e989',\n",
       "   '0150b85c82d0',\n",
       "   '015426ced173',\n",
       "   '015a70caff10',\n",
       "   '015d51a58568',\n",
       "   '015d7d639f44',\n",
       "   '015f4f7ef794',\n",
       "   '015fb2f70943',\n",
       "   '0162aa8a4f41',\n",
       "   '01663a4bdf0c',\n",
       "   '016a4c58266b',\n",
       "   '016de1c51b0c',\n",
       "   '0170ec115344',\n",
       "   '01735f40ffd3',\n",
       "   '01771ab0270a',\n",
       "   '01788a3741a2',\n",
       "   '0179a5ea3099',\n",
       "   '017beb27a328',\n",
       "   '0180435fba92',\n",
       "   '01821004b009',\n",
       "   '01881ecb24b2',\n",
       "   '018a1e42e660',\n",
       "   '018b35c4d3dc',\n",
       "   '018bb99f378e',\n",
       "   '018bf5c2865c',\n",
       "   '018edd67bcbd',\n",
       "   '0197500bd26c',\n",
       "   '019961f8f81c',\n",
       "   '019f96270dad',\n",
       "   '01a6eed31abb',\n",
       "   '01a707c451b0',\n",
       "   '01a9c1259fcc',\n",
       "   '01a9d29e11d0',\n",
       "   '01aa82adde90',\n",
       "   '01abcc58edd1',\n",
       "   '01acedaef69f',\n",
       "   '01ad314750b4',\n",
       "   '01b0cbaa548a',\n",
       "   '01b12abe8016',\n",
       "   '01b144d2c7aa',\n",
       "   '01b30514dec6',\n",
       "   '01b32e60bb31',\n",
       "   '01b393da4d36',\n",
       "   '01b6b8539a0f',\n",
       "   '01b7d6e14e06',\n",
       "   '01b86781e65d',\n",
       "   '01bace87a8ca',\n",
       "   '01bbf69759fd',\n",
       "   '01c016e994f9',\n",
       "   '01c090982695',\n",
       "   '01c4067edbca',\n",
       "   '01c7bf6b5fee',\n",
       "   '01c88532e192',\n",
       "   '01c8af679d67',\n",
       "   '01cd4571a9c5',\n",
       "   '01cf0debc091',\n",
       "   '01d64214e662',\n",
       "   '01d823822d50',\n",
       "   '01d92b58569d',\n",
       "   '01d9cc1c64d3',\n",
       "   '01da1d589b4e',\n",
       "   '01dc6815573d',\n",
       "   '01dcf66e6129',\n",
       "   '01df5693fbe3',\n",
       "   '01dfdc67abb4',\n",
       "   '01e22e257aad',\n",
       "   '01e23b1c1d65',\n",
       "   '01e57daf3792',\n",
       "   '01e76051e5c1',\n",
       "   '01e786ad41f4',\n",
       "   '01ea7518f437',\n",
       "   '01eaeb918c05',\n",
       "   '01eb5edb6a57',\n",
       "   '01ec1a0c6bf3',\n",
       "   '01ede4d1f8a8',\n",
       "   '01f153b7d6ce',\n",
       "   '01f54c70d46b',\n",
       "   '01f8b0ded080',\n",
       "   '01faad01498c',\n",
       "   '02003ebe3684',\n",
       "   '0200be746bf6',\n",
       "   '0204e90c8fc5',\n",
       "   '0204ef6947ed',\n",
       "   '0205d9c2fbf4',\n",
       "   '0207b71f7295',\n",
       "   '020b33c0820c',\n",
       "   '020b7fa0b326',\n",
       "   '020c63ec4b35',\n",
       "   '020eaa9fe01f',\n",
       "   '020fb92275f1',\n",
       "   '021109984c5e',\n",
       "   '0213d25f83a0',\n",
       "   '02147b72ccdc',\n",
       "   '0215bf12b71b',\n",
       "   '02164018b2c7',\n",
       "   '0216cd8af098',\n",
       "   '021750e3b2b9',\n",
       "   '02196c29640d',\n",
       "   '021ec30c749e',\n",
       "   '0221ae9122c4',\n",
       "   '0222ca211b33',\n",
       "   '0224fb58572d',\n",
       "   '02265e78d281',\n",
       "   '0229a376a099',\n",
       "   '022a3f515cba',\n",
       "   '022f2332cad5',\n",
       "   '0232d63472f7',\n",
       "   '02331c9dd59d',\n",
       "   '02366bbb011f',\n",
       "   '023a4c4f29de',\n",
       "   '023f4705461f',\n",
       "   '023f7bdcacb5',\n",
       "   '0242189cdefc',\n",
       "   '02453bf6fb4f',\n",
       "   '0248662e2c78',\n",
       "   '024a028fbd6b',\n",
       "   '024bd81e538c',\n",
       "   '024cab8f2524',\n",
       "   '02527b05dcc3',\n",
       "   '025332284feb',\n",
       "   '02533e82cf32',\n",
       "   '0254c3fc1245',\n",
       "   '02567e5e84c6',\n",
       "   '0258cd7dd371',\n",
       "   '025ab811646f',\n",
       "   '025ad739634f',\n",
       "   '025c47d6e1fb',\n",
       "   '0262a760168a',\n",
       "   '026660425fde',\n",
       "   '0268f2f725c1',\n",
       "   '026a05a7039e',\n",
       "   '026c20ce6dc4',\n",
       "   '027028d9bde3',\n",
       "   '02703b990c10',\n",
       "   '0271142d456b',\n",
       "   '0273d8927bef',\n",
       "   '02746ee744b1',\n",
       "   '02755bb63273',\n",
       "   '027c98ccc223',\n",
       "   '027d795e32ea',\n",
       "   '027dae4d7eae',\n",
       "   '02858aa57411',\n",
       "   '0286c1223c5a',\n",
       "   '028770318e79',\n",
       "   '0287accaaf1d',\n",
       "   '028b27877c10',\n",
       "   '028c22ff6181',\n",
       "   '02900cb9e486',\n",
       "   '0292cfd39c8b',\n",
       "   '02931e66d01b',\n",
       "   '0294262e42c0',\n",
       "   '029482385112',\n",
       "   '02970a301007',\n",
       "   '029901b442f9',\n",
       "   '029b77d8edc5',\n",
       "   '029d685664b8',\n",
       "   '02a1fdd201bb',\n",
       "   '02a46ec65eda',\n",
       "   '02a4afe1c62f',\n",
       "   '02a543005871',\n",
       "   '02a7e138596f',\n",
       "   '02af2813611b',\n",
       "   '02af31637544',\n",
       "   '02af5b038892',\n",
       "   '02b0c4df08db',\n",
       "   '02b0cba4f85e',\n",
       "   '02b3463eff9c',\n",
       "   '02b5114c779a',\n",
       "   '02b7152ed6ef',\n",
       "   '02b79380469f',\n",
       "   '02b8ed232856',\n",
       "   '02b9fd478f1a',\n",
       "   '02bbd17887c1',\n",
       "   '02bc15e9be98',\n",
       "   '02c25cbf385b',\n",
       "   '02caa55d7a33',\n",
       "   '02d0171e31be',\n",
       "   '02d0530432da',\n",
       "   '02d2d88551a8',\n",
       "   '02d322287866',\n",
       "   '02d3f73f2844',\n",
       "   '02d41a047dbb',\n",
       "   '02d4446ce1d0',\n",
       "   '02d65605dc46',\n",
       "   '02d853f90ec1',\n",
       "   '02db58d8db59',\n",
       "   '02dc4b9bf2bc',\n",
       "   '02dce5f9d067',\n",
       "   '02ddb8d39e78',\n",
       "   '02df76ec54b6',\n",
       "   '02e055ad3d54',\n",
       "   '02e46356161d',\n",
       "   '02e4acfda89d',\n",
       "   '02e793cf0306',\n",
       "   '02eaf3040291',\n",
       "   '02ed07da7b7f',\n",
       "   '02f0da92be77',\n",
       "   '02f9009f19a9',\n",
       "   '02f9493e4478',\n",
       "   '030207032d8b',\n",
       "   '0309a4505896',\n",
       "   '030f88006732',\n",
       "   '0311876815d1',\n",
       "   '0311d46ba2d2',\n",
       "   '0311d533601f',\n",
       "   '0311d6bbc2b3',\n",
       "   '0312c2e01765',\n",
       "   '031310aab142',\n",
       "   '03133540481d',\n",
       "   '0314e9c82ad4',\n",
       "   '031c39ccb611',\n",
       "   '031ca58f8742',\n",
       "   '031f2761b09d',\n",
       "   '031febdd6afe',\n",
       "   '03247f663cbd',\n",
       "   '03264e120660',\n",
       "   '032a08f6c8d8',\n",
       "   '032c92283903',\n",
       "   '032d5abb77b8',\n",
       "   '032debbdbad6',\n",
       "   '032e23fb0d6c',\n",
       "   '032e54e23b1b',\n",
       "   '032eb742a778',\n",
       "   '0330240f9bcd',\n",
       "   '03306b172d54',\n",
       "   '03311fd5f4e7',\n",
       "   '0332239585f9',\n",
       "   '0334334523f2',\n",
       "   '033543f7ae60',\n",
       "   '0339b427bb79',\n",
       "   '033dddc0e361',\n",
       "   '03401f344e2a',\n",
       "   '0340967d812d',\n",
       "   '03416dedaeef',\n",
       "   '0344c819f9fc',\n",
       "   '0344d3bc4e4e',\n",
       "   '0345651c406a',\n",
       "   '034815965a09',\n",
       "   '03487d9e6ab6',\n",
       "   '034d31bc0cce',\n",
       "   '034f2c13e874',\n",
       "   '034f59d2a2b6',\n",
       "   '0357c9c8b95e',\n",
       "   '0358d2c322bb',\n",
       "   '03609e9ab716',\n",
       "   '0367a4b51257',\n",
       "   '0368e0999892',\n",
       "   '036ecf5a78de',\n",
       "   '0373b59500f0',\n",
       "   '0375cf039b1f',\n",
       "   '037ad0d4cf52',\n",
       "   '037c5ba54034',\n",
       "   '037cf47840d3',\n",
       "   '037e56d957e3',\n",
       "   '03892fe24790',\n",
       "   '038ac12ed38b',\n",
       "   '038ebf7c20c8',\n",
       "   '0394cbc345e8',\n",
       "   '0395ad4694fe',\n",
       "   '0399f52401f6',\n",
       "   '039e1349ed1d',\n",
       "   '039f63939601',\n",
       "   '039f95537ebe',\n",
       "   '03a21f1c9d5f',\n",
       "   '03aac8a59532',\n",
       "   '03aafc794c37',\n",
       "   '03abcd2b84ea',\n",
       "   '03ad94e8f868',\n",
       "   '03b06970ee08',\n",
       "   '03b3549b5abf',\n",
       "   '03b4a1b945c1',\n",
       "   '03b52ef93f2c',\n",
       "   '03bc0f18c610',\n",
       "   '03bc9df9f99b',\n",
       "   '03bcb370b730',\n",
       "   '03bfe8127859',\n",
       "   '03bff1292d9c',\n",
       "   '03c167203c08',\n",
       "   '03c20bb966cb',\n",
       "   '03c2df878679',\n",
       "   '03c43c6aec18',\n",
       "   '03c5ef696031',\n",
       "   '03cc3c502760',\n",
       "   '03d5dc080d7a',\n",
       "   '03d778a58360',\n",
       "   '03d8ea1ba078',\n",
       "   '03da2b9ffebc',\n",
       "   '03da63b7de2a',\n",
       "   '03df3f866bc4',\n",
       "   '03e1dc9fc331',\n",
       "   '03e21728b8a8',\n",
       "   '03e454892701',\n",
       "   '03e5bbf1c58b',\n",
       "   '03e94dc60823',\n",
       "   '03f68ae59d7c',\n",
       "   '03f6b4337b59',\n",
       "   '03f6ee79f36c',\n",
       "   '03f8e7fb65a6',\n",
       "   '03f9d334c243',\n",
       "   '03fa533aee11',\n",
       "   '040180bca2cc',\n",
       "   '040244f13662',\n",
       "   '0404526e704b',\n",
       "   '0404a73ce7d6',\n",
       "   '0407e146f755',\n",
       "   '04087b0dcb5b',\n",
       "   '04093c78da7f',\n",
       "   '040b368f8924',\n",
       "   '040c7932dfde',\n",
       "   '04142228a545',\n",
       "   '04180e243248',\n",
       "   '041f2e0c25bf',\n",
       "   '0423accc6932',\n",
       "   '0424cd3b13bb',\n",
       "   '042595bf2506',\n",
       "   '042fc9dda41e',\n",
       "   '043221bf8ccc',\n",
       "   '043317c43dd5'],\n",
       "  'top_articles': [{'id': 'be50cc308056',\n",
       "    'title': 'Why You Should Pay Attention to Perplexity AI',\n",
       "    'subtitle': 'I have Replaced Google with This New A.I.-Powered Search Engine!',\n",
       "    'author': '37a2cbe8bd15',\n",
       "    'publication_id': '*Self-Published*',\n",
       "    'published_at': '2024-02-02 11:09:46',\n",
       "    'last_modified_at': '2024-02-18 11:33:57',\n",
       "    'tags': ['technology',\n",
       "     'internet',\n",
       "     'artificial-intelligence',\n",
       "     'business',\n",
       "     'entrepreneurship'],\n",
       "    'topics': ['artificial-intelligence'],\n",
       "    'claps': 997,\n",
       "    'voters': 148,\n",
       "    'word_count': 506,\n",
       "    'responses_count': 17,\n",
       "    'reading_time': 2.459433962264151,\n",
       "    'url': 'https://medium.com/@pareto_investor/why-you-should-pay-attention-to-perplexity-ai-be50cc308056',\n",
       "    'unique_slug': 'why-you-should-pay-attention-to-perplexity-ai-be50cc308056',\n",
       "    'image_url': 'https://miro.medium.com/1*3ydXkh_Hth6MwLVoAduj_A.png',\n",
       "    'lang': 'en',\n",
       "    'is_series': False,\n",
       "    'is_locked': True,\n",
       "    'is_shortform': False,\n",
       "    'top_highlight': 'As it bypasses the traditional ad-driven model of the internet, it challenges the status quo of online information access.'},\n",
       "   {'id': '82653b2b36e2',\n",
       "    'title': 'Mistral CEO Confirms ‘Leak’ of New Open-Source AI Model Nearing GPT-4 Performance',\n",
       "    'subtitle': 'The new open-source large language model (LLM), rumored to approach the performance of GPT-4, a benchmark in the field.',\n",
       "    'author': '37a2cbe8bd15',\n",
       "    'publication_id': '*Self-Published*',\n",
       "    'published_at': '2024-02-01 12:25:45',\n",
       "    'last_modified_at': '2024-02-18 11:34:27',\n",
       "    'tags': ['artificial-intelligence',\n",
       "     'technology',\n",
       "     'business',\n",
       "     'machine-learning',\n",
       "     'programming'],\n",
       "    'topics': ['artificial-intelligence'],\n",
       "    'claps': 610,\n",
       "    'voters': 71,\n",
       "    'word_count': 555,\n",
       "    'responses_count': 7,\n",
       "    'reading_time': 2.6443396226415095,\n",
       "    'url': 'https://medium.com/@pareto_investor/mistral-ceo-confirms-leak-of-new-open-source-ai-model-nearing-gpt-4-performance-82653b2b36e2',\n",
       "    'unique_slug': 'mistral-ceo-confirms-leak-of-new-open-source-ai-model-nearing-gpt-4-performance-82653b2b36e2',\n",
       "    'image_url': 'https://miro.medium.com/0*k4FEslXGg4pEwzjx.jpg',\n",
       "    'lang': 'en',\n",
       "    'is_series': False,\n",
       "    'is_locked': True,\n",
       "    'is_shortform': False,\n",
       "    'top_highlight': 'Quantization, the process mentioned in this context, is a technique in machine learning (ML) that simplifies AI model architectures for use on less powerful hardware.'},\n",
       "   {'id': 'bcee41843775',\n",
       "    'title': 'ChatGPT has Just Been Dethroned by French Geniuses!',\n",
       "    'subtitle': 'These Three Individuals, a Former Researcher at DeepMind and Two Others from Meta,  Completely Transformed the AI Game!',\n",
       "    'author': '37a2cbe8bd15',\n",
       "    'publication_id': '*Self-Published*',\n",
       "    'published_at': '2024-01-20 18:06:31',\n",
       "    'last_modified_at': '2024-02-18 11:38:23',\n",
       "    'tags': ['artificial-intelligence',\n",
       "     'programming',\n",
       "     'machine-learning',\n",
       "     'technology',\n",
       "     'business'],\n",
       "    'topics': ['artificial-intelligence'],\n",
       "    'claps': 4495,\n",
       "    'voters': 902,\n",
       "    'word_count': 1075,\n",
       "    'responses_count': 70,\n",
       "    'reading_time': 4.8899371069182385,\n",
       "    'url': 'https://medium.com/@pareto_investor/chatgpt-has-just-been-dethroned-by-french-geniuses-bcee41843775',\n",
       "    'unique_slug': 'chatgpt-has-just-been-dethroned-by-french-geniuses-bcee41843775',\n",
       "    'image_url': 'https://miro.medium.com/1*6IIgPUJ-0UPUL4xe3Y5IKg.png',\n",
       "    'lang': 'en',\n",
       "    'is_series': False,\n",
       "    'is_locked': True,\n",
       "    'is_shortform': False,\n",
       "    'top_highlight': 'However, its size also allows it to run locally on devices like Macs and even some iPhones, making it highly accessible.'},\n",
       "   {'id': '5272ff33c5cd',\n",
       "    'title': 'ChatGPT Has Gone Bad!',\n",
       "    'subtitle': 'It seems that ChatGPT, particularly GPT-4, is becoming foolish, or more precisely, it’s becoming lazy.',\n",
       "    'author': '37a2cbe8bd15',\n",
       "    'publication_id': '*Self-Published*',\n",
       "    'published_at': '2024-01-28 15:02:49',\n",
       "    'last_modified_at': '2024-02-18 16:16:17',\n",
       "    'tags': ['artificial-intelligence',\n",
       "     'technology',\n",
       "     'programming',\n",
       "     'machine-learning',\n",
       "     'entrepreneurship'],\n",
       "    'topics': ['artificial-intelligence', 'programming'],\n",
       "    'claps': 2106,\n",
       "    'voters': 295,\n",
       "    'word_count': 2283,\n",
       "    'responses_count': 65,\n",
       "    'reading_time': 8.998427672955975,\n",
       "    'url': 'https://medium.com/@pareto_investor/chatgpt-has-gone-bad-5272ff33c5cd',\n",
       "    'unique_slug': 'chatgpt-has-gone-bad-5272ff33c5cd',\n",
       "    'image_url': 'https://miro.medium.com/0*nFHZy_dv1ACH7EOM',\n",
       "    'lang': 'en',\n",
       "    'is_series': False,\n",
       "    'is_locked': True,\n",
       "    'is_shortform': False,\n",
       "    'top_highlight': 'There are several versions of GPT-4. Yes, they correspond to different versions at a given time. For example, GPT4 03–14 is the version from March 2023, 06 is from June 2023, and so we can already see the first thing is that they are not ordered chronologically.'},\n",
       "   {'id': '211b2207b566',\n",
       "    'title': '7 Best Books for Beginners in Stock Market & Personal Investing!',\n",
       "    'subtitle': 'My Honest Review on What I believe are the Best Finance Books for Investing & Money',\n",
       "    'author': '37a2cbe8bd15',\n",
       "    'publication_id': '*Self-Published*',\n",
       "    'published_at': '2024-02-18 15:35:18',\n",
       "    'last_modified_at': '2024-02-18 17:51:51',\n",
       "    'tags': ['books', 'investing', 'education', 'money', 'self-improvement'],\n",
       "    'topics': ['money'],\n",
       "    'claps': 15,\n",
       "    'voters': 6,\n",
       "    'word_count': 788,\n",
       "    'responses_count': 0,\n",
       "    'reading_time': 3.1735849056603773,\n",
       "    'url': 'https://medium.com/@pareto_investor/my-best-7-books-for-beginners-in-stock-market-personal-investing-211b2207b566',\n",
       "    'unique_slug': 'my-best-7-books-for-beginners-in-stock-market-personal-investing-211b2207b566',\n",
       "    'image_url': 'https://miro.medium.com/0*yLNWOqSKbyfgVbO7',\n",
       "    'lang': 'en',\n",
       "    'is_series': False,\n",
       "    'is_locked': False,\n",
       "    'is_shortform': False,\n",
       "    'top_highlight': ''},\n",
       "   {'id': '2b8eb1e86f25',\n",
       "    'title': 'I Was Right about Palantir!',\n",
       "    'subtitle': 'The Company Has a Big Plan to Dominate AI World!',\n",
       "    'author': '37a2cbe8bd15',\n",
       "    'publication_id': '*Self-Published*',\n",
       "    'published_at': '2024-02-18 02:01:56',\n",
       "    'last_modified_at': '2024-02-18 11:23:28',\n",
       "    'tags': ['technology', 'ai', 'investing', 'stock-market', 'trading'],\n",
       "    'topics': ['artificial-intelligence'],\n",
       "    'claps': 213,\n",
       "    'voters': 13,\n",
       "    'word_count': 563,\n",
       "    'responses_count': 1,\n",
       "    'reading_time': 3.074528301886793,\n",
       "    'url': 'https://medium.com/@pareto_investor/i-was-right-about-palantir-2b8eb1e86f25',\n",
       "    'unique_slug': 'i-was-right-about-palantir-2b8eb1e86f25',\n",
       "    'image_url': 'https://miro.medium.com/0*kxmzisq-zZCYs05y.jpg',\n",
       "    'lang': 'en',\n",
       "    'is_series': False,\n",
       "    'is_locked': True,\n",
       "    'is_shortform': False,\n",
       "    'top_highlight': ''},\n",
       "   {'id': '681c04c2a74f',\n",
       "    'title': 'Why Bitcoin?',\n",
       "    'subtitle': 'How to Get Rich with Investing (without Getting Lucky)',\n",
       "    'author': '37a2cbe8bd15',\n",
       "    'publication_id': '*Self-Published*',\n",
       "    'published_at': '2024-02-17 20:50:32',\n",
       "    'last_modified_at': '2024-02-18 11:23:33',\n",
       "    'tags': ['bitcoin', 'life', 'finance', 'money', 'self-improvement'],\n",
       "    'topics': ['cryptocurrency'],\n",
       "    'claps': 202,\n",
       "    'voters': 14,\n",
       "    'word_count': 689,\n",
       "    'responses_count': 1,\n",
       "    'reading_time': 3.3,\n",
       "    'url': 'https://medium.com/@pareto_investor/why-bitcoin-681c04c2a74f',\n",
       "    'unique_slug': 'why-bitcoin-681c04c2a74f',\n",
       "    'image_url': 'https://miro.medium.com/0*d-rDBS60N966vxZ3.jpeg',\n",
       "    'lang': 'en',\n",
       "    'is_series': False,\n",
       "    'is_locked': True,\n",
       "    'is_shortform': False,\n",
       "    'top_highlight': ''},\n",
       "   {'id': '329ca6732470',\n",
       "    'title': 'Apple GPT\\u200a—\\u200aWhat Do We Know So Far!',\n",
       "    'subtitle': 'Apple is the sleeping giant in the realm of artificial intelligence.',\n",
       "    'author': '37a2cbe8bd15',\n",
       "    'publication_id': '*Self-Published*',\n",
       "    'published_at': '2024-02-17 11:16:52',\n",
       "    'last_modified_at': '2024-02-18 11:23:51',\n",
       "    'tags': ['apple',\n",
       "     'artificial-intelligence',\n",
       "     'technology',\n",
       "     'business',\n",
       "     'programming'],\n",
       "    'topics': ['artificial-intelligence'],\n",
       "    'claps': 107,\n",
       "    'voters': 8,\n",
       "    'word_count': 889,\n",
       "    'responses_count': 0,\n",
       "    'reading_time': 3.5547169811320756,\n",
       "    'url': 'https://medium.com/@pareto_investor/apple-gpt-what-do-we-know-so-far-329ca6732470',\n",
       "    'unique_slug': 'apple-gpt-what-do-we-know-so-far-329ca6732470',\n",
       "    'image_url': 'https://miro.medium.com/0*jBHC93WZ4Ah65cR-',\n",
       "    'lang': 'en',\n",
       "    'is_series': False,\n",
       "    'is_locked': True,\n",
       "    'is_shortform': False,\n",
       "    'top_highlight': ''},\n",
       "   {'id': '1add43659444',\n",
       "    'title': 'Cricket Might Be the Next Big Sport in America',\n",
       "    'subtitle': 'How to Get Rich with Investing (without Getting Lucky)',\n",
       "    'author': '37a2cbe8bd15',\n",
       "    'publication_id': '*Self-Published*',\n",
       "    'published_at': '2024-02-17 02:01:45',\n",
       "    'last_modified_at': '2024-02-18 11:24:01',\n",
       "    'tags': ['cricket', 'india', 'usa', 'sports', 'news'],\n",
       "    'topics': ['sports'],\n",
       "    'claps': 89,\n",
       "    'voters': 5,\n",
       "    'word_count': 536,\n",
       "    'responses_count': 2,\n",
       "    'reading_time': 2.722641509433962,\n",
       "    'url': 'https://medium.com/@pareto_investor/cricket-might-be-the-next-big-sport-in-america-1add43659444',\n",
       "    'unique_slug': 'cricket-might-be-the-next-big-sport-in-america-1add43659444',\n",
       "    'image_url': 'https://miro.medium.com/0*9n_TcVZIsnIouOj7',\n",
       "    'lang': 'en',\n",
       "    'is_series': False,\n",
       "    'is_locked': True,\n",
       "    'is_shortform': False,\n",
       "    'top_highlight': ''},\n",
       "   {'id': 'c33063302058',\n",
       "    'title': 'Yield Curve’s 40-Year Low Is Now Signaling Recession',\n",
       "    'subtitle': 'After being deeply negative, the US Treasury yield curve is in the process of de-inverting, signaling a potential recession!',\n",
       "    'author': '37a2cbe8bd15',\n",
       "    'publication_id': '*Self-Published*',\n",
       "    'published_at': '2024-02-16 12:05:58',\n",
       "    'last_modified_at': '2024-02-18 11:24:55',\n",
       "    'tags': ['economics', 'investing', 'trading', 'finance', 'stock-market'],\n",
       "    'topics': ['money', 'economy'],\n",
       "    'claps': 69,\n",
       "    'voters': 12,\n",
       "    'word_count': 410,\n",
       "    'responses_count': 1,\n",
       "    'reading_time': 1.9305031446540881,\n",
       "    'url': 'https://medium.com/@pareto_investor/yield-curves-40-year-low-is-now-signaling-recession-c33063302058',\n",
       "    'unique_slug': 'yield-curves-40-year-low-is-now-signaling-recession-c33063302058',\n",
       "    'image_url': 'https://miro.medium.com/0*BekymDxtFY_iYx7R.png',\n",
       "    'lang': 'en',\n",
       "    'is_series': False,\n",
       "    'is_locked': True,\n",
       "    'is_shortform': False,\n",
       "    'top_highlight': ''}]},\n",
       " '15a29a4fc6ad': {'id': '15a29a4fc6ad',\n",
       "  'username': 'miptgirl',\n",
       "  'fullname': 'Mariya Mansurova',\n",
       "  'bio': 'Data & Product Analytics Lead at Wise | ClickHouse Evangelist',\n",
       "  'followers_count': 7465,\n",
       "  'following_count': 109,\n",
       "  'publication_following_count': 10,\n",
       "  'image_url': 'https://miro.medium.com/1*7fFHr8XBAuR_SgJknIyODA.png',\n",
       "  'twitter_username': '',\n",
       "  'is_writer_program_enrolled': True,\n",
       "  'allow_notes': True,\n",
       "  'medium_member_at': '2022-12-27 20:34:01',\n",
       "  'is_suspended': False,\n",
       "  'top_writer_in': [],\n",
       "  'has_list': False,\n",
       "  'is_book_author': False,\n",
       "  'tipping_link': None,\n",
       "  'bg_image_url': '',\n",
       "  'logo_image_url': '',\n",
       "  'followers': ['00245ad345da',\n",
       "   '002a25275643',\n",
       "   '0041541f90e4',\n",
       "   '004bab759a12',\n",
       "   '005b0e23b5d5',\n",
       "   '0078a8c1aefd',\n",
       "   '00852dc4a8f8',\n",
       "   '0099e6750330',\n",
       "   '00a325e40797',\n",
       "   '00b4c203ce70',\n",
       "   '00d0c88bf952',\n",
       "   '00d13eeadeea',\n",
       "   '00e97ebedb8a',\n",
       "   '00f1dddb885d',\n",
       "   '00f24bcd7bd7',\n",
       "   '01010508c78c',\n",
       "   '0103bac3e4c5',\n",
       "   '0108b7898242',\n",
       "   '01252b645741',\n",
       "   '0126db676b5c',\n",
       "   '0143c3cfd773',\n",
       "   '0150b85c82d0',\n",
       "   '018bb99f378e',\n",
       "   '019f96270dad',\n",
       "   '01a9c1259fcc',\n",
       "   '01a9d29e11d0',\n",
       "   '01aa82adde90',\n",
       "   '01bace87a8ca',\n",
       "   '01cf0debc091',\n",
       "   '01dc6815573d',\n",
       "   '01eb5edb6a57',\n",
       "   '01ec1a0c6bf3',\n",
       "   '020b7fa0b326',\n",
       "   '020c63ec4b35',\n",
       "   '021ec30c749e',\n",
       "   '0232d63472f7',\n",
       "   '025c47d6e1fb',\n",
       "   '027028d9bde3',\n",
       "   '027d795e32ea',\n",
       "   '0286c1223c5a',\n",
       "   '028b27877c10',\n",
       "   '028f587d96ec',\n",
       "   '0293663044a9',\n",
       "   '029cfb8f7394',\n",
       "   '02b0cba4f85e',\n",
       "   '02b8ed232856',\n",
       "   '02b9fd478f1a',\n",
       "   '02bbd17887c1',\n",
       "   '02c13b34624f',\n",
       "   '02d322287866',\n",
       "   '02d3f73f2844',\n",
       "   '02e055ad3d54',\n",
       "   '02ed07da7b7f',\n",
       "   '03011804df2a',\n",
       "   '030da18f9dbe',\n",
       "   '031febdd6afe',\n",
       "   '0334795b30df',\n",
       "   '03609e9ab716',\n",
       "   '036d500f5511',\n",
       "   '037cf47840d3',\n",
       "   '038ac12ed38b',\n",
       "   '039e1349ed1d',\n",
       "   '03aac8a59532',\n",
       "   '03b31424b5a4',\n",
       "   '03b52ef93f2c',\n",
       "   '03b9dc13ef75',\n",
       "   '03c5ef696031',\n",
       "   '03d71dd7fca1',\n",
       "   '03e059f5c7be',\n",
       "   '040180bca2cc',\n",
       "   '0407e146f755',\n",
       "   '0409b232ec6e',\n",
       "   '042741548a1c',\n",
       "   '0434b6c60a39',\n",
       "   '04500c057f2b',\n",
       "   '046054fee6d5',\n",
       "   '047784d29104',\n",
       "   '047f817e27eb',\n",
       "   '0485b6f6e008',\n",
       "   '0493aea76b52',\n",
       "   '049708098c50',\n",
       "   '049a24575f76',\n",
       "   '04ca33ca0707',\n",
       "   '04d0aa545f5c',\n",
       "   '04e94eb13d69',\n",
       "   '04ecdfce0104',\n",
       "   '04f020827223',\n",
       "   '052bcedc9384',\n",
       "   '054cfd9a67ce',\n",
       "   '0589ca8d247d',\n",
       "   '058a6d5a31c2',\n",
       "   '059c1d7ce970',\n",
       "   '05c86952af36',\n",
       "   '05d8ccd269ff',\n",
       "   '060a20697ec0',\n",
       "   '061310e7625b',\n",
       "   '0626d34a4ce3',\n",
       "   '062efdacb637',\n",
       "   '06376237b3a2',\n",
       "   '06378d7a507b',\n",
       "   '063ad40278ae',\n",
       "   '069622bc84ac',\n",
       "   '06b0361ed717',\n",
       "   '06b37e86523a',\n",
       "   '06c352ed33e5',\n",
       "   '06fda0eebc7e',\n",
       "   '071da920fdde',\n",
       "   '071e6f1cbf50',\n",
       "   '072e8a5bae3f',\n",
       "   '075bec19ed6b',\n",
       "   '076870fb4f6e',\n",
       "   '077147cc7a6a',\n",
       "   '0785ad8d80e3',\n",
       "   '0788cbdf325a',\n",
       "   '0794ebaca189',\n",
       "   '079a0707aa7f',\n",
       "   '07de4a549083',\n",
       "   '07e81997ce29',\n",
       "   '07f5564612f9',\n",
       "   '080400bd192b',\n",
       "   '08047e8a72ce',\n",
       "   '083144fb1453',\n",
       "   '083da6d823ab',\n",
       "   '084e4112f19a',\n",
       "   '0859720c1d98',\n",
       "   '0871368b476a',\n",
       "   '0880c44e0fa4',\n",
       "   '0881e966615f',\n",
       "   '089e1d05b958',\n",
       "   '08baa4cd5db4',\n",
       "   '08be81d214d3',\n",
       "   '08c51b99c7bd',\n",
       "   '08fc4260381d',\n",
       "   '090b22adc953',\n",
       "   '092eabcdc76d',\n",
       "   '09813e8652ac',\n",
       "   '09a4e315994c',\n",
       "   '09b6ac590e29',\n",
       "   '09b7fba39f2e',\n",
       "   '09e29988218e',\n",
       "   '09ec142dd122',\n",
       "   '09f10af24958',\n",
       "   '09f1c934596f',\n",
       "   '09fec82451d0',\n",
       "   '0a11b6d6fbc9',\n",
       "   '0a17c3b235cd',\n",
       "   '0a2a81cabf1d',\n",
       "   '0a330a2ab2d6',\n",
       "   '0a3b8a6cb352',\n",
       "   '0a5e729e1212',\n",
       "   '0a66b788f5af',\n",
       "   '0a6e7ab351d7',\n",
       "   '0a752c5d555c',\n",
       "   '0a7f33d2154c',\n",
       "   '0a8cc69ddb75',\n",
       "   '0a8dce58cf70',\n",
       "   '0a90a192a60b',\n",
       "   '0a9f4e679fe2',\n",
       "   '0aa919e64d91',\n",
       "   '0aaf7a1f8af3',\n",
       "   '0ab88081d0d2',\n",
       "   '0ac13385b33f',\n",
       "   '0ac49c1ee456',\n",
       "   '0ac966a8bd62',\n",
       "   '0ad70b185bbe',\n",
       "   '0ae37b032f53',\n",
       "   '0af0a1b91b37',\n",
       "   '0af5f373313c',\n",
       "   '0afede805da8',\n",
       "   '0b047ea2a2e2',\n",
       "   '0b1f054d198f',\n",
       "   '0b2021d26409',\n",
       "   '0b234e69a7f9',\n",
       "   '0b507195d88a',\n",
       "   '0b561f262df9',\n",
       "   '0b72a9fcaf46',\n",
       "   '0b8df69c12a1',\n",
       "   '0b916e6f0690',\n",
       "   '0ba8bf581f8b',\n",
       "   '0bbd1d8ab904',\n",
       "   '0be7589e82af',\n",
       "   '0bf9396ba14b',\n",
       "   '0c0931e7e38b',\n",
       "   '0c12ddd398a9',\n",
       "   '0c1b7840aa69',\n",
       "   '0c2766f0f9eb',\n",
       "   '0c602f4e893a',\n",
       "   '0c6c7453e01f',\n",
       "   '0c7067d7bf7d',\n",
       "   '0c866821e5f2',\n",
       "   '0c8d56eda234',\n",
       "   '0c9a285d8aa0',\n",
       "   '0cb1b0a018a6',\n",
       "   '0cc42e98f068',\n",
       "   '0cc4d4dd1f14',\n",
       "   '0cc92b608b1c',\n",
       "   '0ccaf32189fd',\n",
       "   '0ccd347285af',\n",
       "   '0cd3044bc3e6',\n",
       "   '0ce2e7398143',\n",
       "   '0cf2e2cda367',\n",
       "   '0cf4a3893e1e',\n",
       "   '0cff73b4743f',\n",
       "   '0d038600a7ba',\n",
       "   '0d2a7ab24aa9',\n",
       "   '0d4f4a7c73c3',\n",
       "   '0d9eab495b3c',\n",
       "   '0da7b81d3bff',\n",
       "   '0da7d7ee6581',\n",
       "   '0dba8d609c7a',\n",
       "   '0dd63eaaa48f',\n",
       "   '0de8dcf65882',\n",
       "   '0df5515e2249',\n",
       "   '0e13a8173277',\n",
       "   '0e2982a014b8',\n",
       "   '0e3068f64280',\n",
       "   '0e394e9c888a',\n",
       "   '0e40f77ac6a3',\n",
       "   '0e4acb68928f',\n",
       "   '0e5faf098978',\n",
       "   '0e7588d35f8d',\n",
       "   '0e7aad736294',\n",
       "   '0e874f5a665f',\n",
       "   '0eacbe3178a1',\n",
       "   '0eb8d34d917e',\n",
       "   '0ec324fbcb05',\n",
       "   '0ec548320a3f',\n",
       "   '0edc0a7f6f5c',\n",
       "   '0ee9c5d7c66c',\n",
       "   '0efa91bc2ac7',\n",
       "   '0f05103506ea',\n",
       "   '0f09ab593f5d',\n",
       "   '0f11c2541a42',\n",
       "   '0f27b22b653f',\n",
       "   '0f2ab9efc69c',\n",
       "   '0f34cac151b7',\n",
       "   '0f423255412e',\n",
       "   '0f4f91d5e9ec',\n",
       "   '0f648d0e5c6d',\n",
       "   '0f68be24fe5d',\n",
       "   '0f6f08d3268f',\n",
       "   '0f743f1ef744',\n",
       "   '0f8f3db1304a',\n",
       "   '0fbc79ec017d',\n",
       "   '0fc09dd1003d',\n",
       "   '0fca98e3802a',\n",
       "   '0fdc5cfcc38f',\n",
       "   '0fdf387c3e80',\n",
       "   '0ff632cf8f64',\n",
       "   '1025557181ec',\n",
       "   '1025d650f3de',\n",
       "   '102aa3aac04d',\n",
       "   '102b0522d2f3',\n",
       "   '10403e9a11e6',\n",
       "   '1056c2e38502',\n",
       "   '105a3c72085a',\n",
       "   '105f04329cdf',\n",
       "   '105f29efb579',\n",
       "   '105fca20fc96',\n",
       "   '1065d24018d3',\n",
       "   '1065f99a1eea',\n",
       "   '107dfae317',\n",
       "   '1087988dcd14',\n",
       "   '10893048ab3f',\n",
       "   '1089cef6b721',\n",
       "   '108d3ae40e53',\n",
       "   '1093cc9740c1',\n",
       "   '1099d4bcd32f',\n",
       "   '10a305a6c9d5',\n",
       "   '10a349c85c5f',\n",
       "   '10c3f4839891',\n",
       "   '10c5b2579104',\n",
       "   '10c6921582c6',\n",
       "   '10ca64581648',\n",
       "   '10d00fa29742',\n",
       "   '10d64fbe4bc5',\n",
       "   '10dd083faa41',\n",
       "   '10f581b06f04',\n",
       "   '110e24f51140',\n",
       "   '1125918679ba',\n",
       "   '112fa4feba3a',\n",
       "   '11373d393a94',\n",
       "   '114058fb8ef9',\n",
       "   '114b31d17d80',\n",
       "   '114bb975ae25',\n",
       "   '1156db930142',\n",
       "   '115a636d63d8',\n",
       "   '115c8dc08064',\n",
       "   '115d4f4c51b5',\n",
       "   '11668ac4b924',\n",
       "   '11692171d5f9',\n",
       "   '116a88107736',\n",
       "   '117404aa37a1',\n",
       "   '1174113b42e4',\n",
       "   '117692bcec31',\n",
       "   '118b4633d18',\n",
       "   '118c7827e179',\n",
       "   '118e16f08ad4',\n",
       "   '118f38e258ce',\n",
       "   '118f527f6a42',\n",
       "   '119461a67189',\n",
       "   '119875805e2a',\n",
       "   '1199efd054cc',\n",
       "   '119c4a805c3d',\n",
       "   '119ded79b0c1',\n",
       "   '11a33aec74b4',\n",
       "   '11b19430c928',\n",
       "   '11c3a7afae2e',\n",
       "   '11c3c511360a',\n",
       "   '11c5524f33fd',\n",
       "   '11c6177013d3',\n",
       "   '11cb650c70',\n",
       "   '11d8017573a2',\n",
       "   '11e016b2a9a6',\n",
       "   '11ebdbfd3d01',\n",
       "   '11f58156e40f',\n",
       "   '11f666a2cad5',\n",
       "   '11f66a4295d3',\n",
       "   '11fecc75b53e',\n",
       "   '11ffbcedde9',\n",
       "   '1203d6ecc8eb',\n",
       "   '121252b44bf0',\n",
       "   '12267150bb11',\n",
       "   '1231be630a53',\n",
       "   '123fcdb66f89',\n",
       "   '1248ff600851',\n",
       "   '1256da67d66',\n",
       "   '1257d7c3096f',\n",
       "   '12601e98b9a3',\n",
       "   '12665ee42fe5',\n",
       "   '1276a2ab058c',\n",
       "   '1278ebdf3e3c',\n",
       "   '127a668fb66f',\n",
       "   '127b2c19eee5',\n",
       "   '127dfcc7d9b9',\n",
       "   '12892a109be6',\n",
       "   '1294b367df14',\n",
       "   '129d238e441e',\n",
       "   '12a204627804',\n",
       "   '12b2c0e8f5d',\n",
       "   '12b6bb036be0',\n",
       "   '12b81f0e0084',\n",
       "   '12b899e0abc2',\n",
       "   '12c3723a3f32',\n",
       "   '12c5d90d1b2c',\n",
       "   '12cb4d81ed69',\n",
       "   '12d40d4857f7',\n",
       "   '12d6a2ec97b',\n",
       "   '12d9fec8277f',\n",
       "   '12dfdf998c63',\n",
       "   '12fddf492974',\n",
       "   '130bf5a44e9a',\n",
       "   '13102aec0c9c',\n",
       "   '13118f1ac69a',\n",
       "   '1331886ae02c',\n",
       "   '1332ed212be8',\n",
       "   '13405f79f337',\n",
       "   '13435b1208e8',\n",
       "   '13540ae6680e',\n",
       "   '135ab283559e',\n",
       "   '13695e1fff8a',\n",
       "   '136c9cffa503',\n",
       "   '1378987eaa53',\n",
       "   '137c131485da',\n",
       "   '1398a177c442',\n",
       "   '139d1032ac0f',\n",
       "   '13a40599fb71',\n",
       "   '13a787cf5176',\n",
       "   '13c431ce2039',\n",
       "   '13c43f1eb00c',\n",
       "   '13cbc18d6975',\n",
       "   '13dafa14dc1c',\n",
       "   '13e60ac4e995',\n",
       "   '13f189b8cbc0',\n",
       "   '1409cf91e928',\n",
       "   '1415027fe5bd',\n",
       "   '14155f21714',\n",
       "   '141fa70b60b6',\n",
       "   '14291a05946f',\n",
       "   '142a5b944941',\n",
       "   '1430456ad365',\n",
       "   '143184ecac7b',\n",
       "   '143329ba8c8d',\n",
       "   '143d65f9e120',\n",
       "   '14446d982b66',\n",
       "   '1451e2780411',\n",
       "   '1453bc74cad6',\n",
       "   '1456e2f4af2d',\n",
       "   '1456fd5c74f3',\n",
       "   '1472fefa2726',\n",
       "   '14783340ad09',\n",
       "   '147a092435f4',\n",
       "   '14800603b822',\n",
       "   '148808dd8b19',\n",
       "   '148ae689f366',\n",
       "   '14901eb589cd',\n",
       "   '14950b04f4d9',\n",
       "   '14998d6066d',\n",
       "   '14a3144d269c',\n",
       "   '14ae73fc7ed2',\n",
       "   '14ae83138b4c',\n",
       "   '14b13505eda7',\n",
       "   '14b21e52011e',\n",
       "   '14ba6947691c',\n",
       "   '14bbc8ef606f',\n",
       "   '14c1270158eb',\n",
       "   '14c3467c677f',\n",
       "   '14c389c13cbd',\n",
       "   '14cc2cff1e8f',\n",
       "   '14d0c4cfeb19',\n",
       "   '14d767c71e5b',\n",
       "   '14d8d59ae35c',\n",
       "   '14f4c065e283',\n",
       "   '14f5457d36a8',\n",
       "   '1503d896d5c1',\n",
       "   '150e82c09614',\n",
       "   '1520a91cc7bb',\n",
       "   '1528ab18200e',\n",
       "   '153126a6a2eb',\n",
       "   '15427dad4ba8',\n",
       "   '1552ebbd91d2',\n",
       "   '156388a0ed17',\n",
       "   '156add97b19e',\n",
       "   '156d7df54349',\n",
       "   '1575f21bd8e7',\n",
       "   '158052850fa0',\n",
       "   '1593def7ad40',\n",
       "   '159ddd307511',\n",
       "   '159f438b0755',\n",
       "   '15a059b5ab64',\n",
       "   '15ab750b1e76',\n",
       "   '15bcb5d7f95f',\n",
       "   '15dfd69cb65b',\n",
       "   '15e353cb75ed',\n",
       "   '15e3c0fdbff5',\n",
       "   '15eacbff3122',\n",
       "   '15ec16f548d7',\n",
       "   '15efc0a67bc',\n",
       "   '15f678545f54',\n",
       "   '15f6797f06d1',\n",
       "   '160c3e933453',\n",
       "   '161240e1fbe5',\n",
       "   '161a46f216b',\n",
       "   '161a950363d8',\n",
       "   '1623611679c5',\n",
       "   '1624130f217',\n",
       "   '162a34c46be0',\n",
       "   '162ae4264606',\n",
       "   '162bc9680ec6',\n",
       "   '162c5e4d3153',\n",
       "   '162fc7604691',\n",
       "   '1634a1b73a96',\n",
       "   '163632d5573b',\n",
       "   '1636cdd02cd8',\n",
       "   '1639b5005e38',\n",
       "   '163e7f05eb7b',\n",
       "   '163f0a2ca647',\n",
       "   '1646ee03bd72',\n",
       "   '166051d364b5',\n",
       "   '1663be6269a9',\n",
       "   '166848cfc62b',\n",
       "   '167837bfd5f4',\n",
       "   '1688fea86cbf',\n",
       "   '168f8fc4a832',\n",
       "   '169238d736f7',\n",
       "   '169b5527fee1',\n",
       "   '169dc6374534',\n",
       "   '16a1cd57af32',\n",
       "   '16a5493931b6'],\n",
       "  'top_articles': [{'id': 'afd97fce8fb5',\n",
       "    'title': 'Text Embeddings: Comprehensive Guide',\n",
       "    'subtitle': 'Evolution, visualisation, and applications of text embeddings',\n",
       "    'author': '15a29a4fc6ad',\n",
       "    'publication_id': '7f60cf5620c9',\n",
       "    'published_at': '2024-02-13 08:03:13',\n",
       "    'last_modified_at': '2024-02-13 08:03:13',\n",
       "    'tags': ['data-science',\n",
       "     'nlp',\n",
       "     'machine-learning',\n",
       "     'deep-dives',\n",
       "     'embedding'],\n",
       "    'topics': ['machine-learning', 'data-science', 'programming'],\n",
       "    'claps': 815,\n",
       "    'voters': 175,\n",
       "    'word_count': 4616,\n",
       "    'responses_count': 17,\n",
       "    'reading_time': 19.368867924528303,\n",
       "    'url': 'https://towardsdatascience.com/text-embeddings-comprehensive-guide-afd97fce8fb5',\n",
       "    'unique_slug': 'text-embeddings-comprehensive-guide-afd97fce8fb5',\n",
       "    'image_url': 'https://miro.medium.com/1*0OVy_qF0NLJOyUnfz8lRzg.jpeg',\n",
       "    'lang': 'en',\n",
       "    'is_series': False,\n",
       "    'is_locked': False,\n",
       "    'is_shortform': False,\n",
       "    'top_highlight': ''},\n",
       "   {'id': 'c5b9faa7a950',\n",
       "    'title': 'Data Visualisation 101: Playbook for Attention-Grabbing Visuals',\n",
       "    'subtitle': 'Practical Techniques for Captivating Visual Communication with Plotly',\n",
       "    'author': '15a29a4fc6ad',\n",
       "    'publication_id': '7f60cf5620c9',\n",
       "    'published_at': '2024-02-05 16:55:55',\n",
       "    'last_modified_at': '2024-02-05 16:55:55',\n",
       "    'tags': ['data-visualization',\n",
       "     'data-science',\n",
       "     'python',\n",
       "     'deep-dives',\n",
       "     'getting-started'],\n",
       "    'topics': ['data-science', 'programming'],\n",
       "    'claps': 950,\n",
       "    'voters': 164,\n",
       "    'word_count': 3269,\n",
       "    'responses_count': 10,\n",
       "    'reading_time': 14.085849056603774,\n",
       "    'url': 'https://towardsdatascience.com/data-visualisation-101-playbook-for-attention-grabbing-visuals-c5b9faa7a950',\n",
       "    'unique_slug': 'data-visualisation-101-playbook-for-attention-grabbing-visuals-c5b9faa7a950',\n",
       "    'image_url': 'https://miro.medium.com/1*JZNAv55DOK4L47LTl5KfTg.png',\n",
       "    'lang': 'en',\n",
       "    'is_series': False,\n",
       "    'is_locked': False,\n",
       "    'is_shortform': False,\n",
       "    'top_highlight': ''},\n",
       "   {'id': '3a10838b150d',\n",
       "    'title': 'Visualisation 101: Choosing the Best Visualisation Type',\n",
       "    'subtitle': 'Comprehensive guide for different visualisation use cases',\n",
       "    'author': '15a29a4fc6ad',\n",
       "    'publication_id': '7f60cf5620c9',\n",
       "    'published_at': '2024-01-12 20:44:18',\n",
       "    'last_modified_at': '2024-01-12 20:44:18',\n",
       "    'tags': ['visualization',\n",
       "     'data-science',\n",
       "     'python',\n",
       "     'editors-pick',\n",
       "     'data-visualization'],\n",
       "    'topics': ['visual-design', 'design', 'data-science', 'programming'],\n",
       "    'claps': 1133,\n",
       "    'voters': 243,\n",
       "    'word_count': 3701,\n",
       "    'responses_count': 19,\n",
       "    'reading_time': 15.866037735849057,\n",
       "    'url': 'https://towardsdatascience.com/visualisation-101-choosing-the-best-visualisation-type-3a10838b150d',\n",
       "    'unique_slug': 'visualisation-101-choosing-the-best-visualisation-type-3a10838b150d',\n",
       "    'image_url': 'https://miro.medium.com/1*ZnlImfsQ4VkFgLH-c5tsow.jpeg',\n",
       "    'lang': 'en',\n",
       "    'is_series': False,\n",
       "    'is_locked': False,\n",
       "    'is_shortform': False,\n",
       "    'top_highlight': \"One of the most famous examples is Anscombe's quartet. It was created by statistician Francis Anscombe, and it consists of 4 data sets with almost equal descriptive statistics: means, variances and correlations. But when we look at the data, we can see how different the datasets are.\"},\n",
       "   {'id': '9d42488dc327',\n",
       "    'title': 'Can LLMs Replace Data Analysts? Learning to Collaborate',\n",
       "    'subtitle': 'Part 3: Teaching the LLM agent to pose and address clarifying questions',\n",
       "    'author': '15a29a4fc6ad',\n",
       "    'publication_id': '7f60cf5620c9',\n",
       "    'published_at': '2024-01-09 13:19:56',\n",
       "    'last_modified_at': '2024-01-09 13:19:56',\n",
       "    'tags': ['llm',\n",
       "     'data-science',\n",
       "     'artificial-intelligence',\n",
       "     'deep-dives',\n",
       "     'editors-pick'],\n",
       "    'topics': ['artificial-intelligence',\n",
       "     'machine-learning',\n",
       "     'data-science',\n",
       "     'programming'],\n",
       "    'claps': 669,\n",
       "    'voters': 79,\n",
       "    'word_count': 5002,\n",
       "    'responses_count': 8,\n",
       "    'reading_time': 19.57547169811321,\n",
       "    'url': 'https://towardsdatascience.com/can-llms-replace-data-analysts-learning-to-collaborate-9d42488dc327',\n",
       "    'unique_slug': 'can-llms-replace-data-analysts-learning-to-collaborate-9d42488dc327',\n",
       "    'image_url': 'https://miro.medium.com/1*wUDorQvoHBbMLqPFvvVorw.jpeg',\n",
       "    'lang': 'en',\n",
       "    'is_series': False,\n",
       "    'is_locked': False,\n",
       "    'is_shortform': False,\n",
       "    'top_highlight': \"So, for an LLM-powered analyst, mastering the art of posing and addressing follow-up questions is essential since I can't imagine an analyst working in isolation.\"},\n",
       "   {'id': '8cf7da132259',\n",
       "    'title': 'Can LLMs Replace Data Analysts? Getting Answers Using SQL',\n",
       "    'subtitle': 'Part 2: Diving deeper into LLM agents',\n",
       "    'author': '15a29a4fc6ad',\n",
       "    'publication_id': '7f60cf5620c9',\n",
       "    'published_at': '2023-12-22 16:01:00',\n",
       "    'last_modified_at': '2023-12-22 16:01:00',\n",
       "    'tags': ['llm',\n",
       "     'data-science',\n",
       "     'artificial-intelligence',\n",
       "     'agents',\n",
       "     'editors-pick'],\n",
       "    'topics': ['artificial-intelligence', 'machine-learning', 'data-science'],\n",
       "    'claps': 823,\n",
       "    'voters': 239,\n",
       "    'word_count': 7816,\n",
       "    'responses_count': 11,\n",
       "    'reading_time': 30.444339622641508,\n",
       "    'url': 'https://towardsdatascience.com/can-llms-replace-data-analysts-getting-answers-using-sql-8cf7da132259',\n",
       "    'unique_slug': 'can-llms-replace-data-analysts-getting-answers-using-sql-8cf7da132259',\n",
       "    'image_url': 'https://miro.medium.com/1*o5J_rJVXP2J4NhBheT0IlQ.png',\n",
       "    'lang': 'en',\n",
       "    'is_series': False,\n",
       "    'is_locked': False,\n",
       "    'is_shortform': False,\n",
       "    'top_highlight': 'The core idea of the LLM agents is to use LLM as a reasoning engine to define the set of actions to take. In the classic approach, we hardcode a sequence of actions, but with agents, we give the model tools and tasks and let her decide how to achieve them.'},\n",
       "   {'id': '851578fa10ce',\n",
       "    'title': 'Can LLMs Replace Data Analysts? Building An LLM-Powered Analyst',\n",
       "    'subtitle': 'Part 1: empowering ChatGPT with tools',\n",
       "    'author': '15a29a4fc6ad',\n",
       "    'publication_id': '7f60cf5620c9',\n",
       "    'published_at': '2023-12-11 17:08:56',\n",
       "    'last_modified_at': '2023-12-11 17:08:56',\n",
       "    'tags': ['llm',\n",
       "     'data-science',\n",
       "     'agents',\n",
       "     'editors-pick',\n",
       "     'artificial-intelligence'],\n",
       "    'topics': ['data-science'],\n",
       "    'claps': 1492,\n",
       "    'voters': 326,\n",
       "    'word_count': 4613,\n",
       "    'responses_count': 19,\n",
       "    'reading_time': 18.240880503144652,\n",
       "    'url': 'https://towardsdatascience.com/can-llms-replace-data-analysts-building-an-llm-powered-analyst-851578fa10ce',\n",
       "    'unique_slug': 'can-llms-replace-data-analysts-building-an-llm-powered-analyst-851578fa10ce',\n",
       "    'image_url': 'https://miro.medium.com/1*cUH3JCAISUwvit33qk6D7g.jpeg',\n",
       "    'lang': 'en',\n",
       "    'is_series': False,\n",
       "    'is_locked': False,\n",
       "    'is_shortform': False,\n",
       "    'top_highlight': \"The essential concept related to agents (that I've already mentioned above) is tools. Tools are functions that LLM could invoke to get missing information (for example, execute SQL, use a calculator or call a search engine). Tools are crucial because they allow you to bring LLMs to the next level and interact with the world. In this article, we will primarily focus on OpenAI functions as tools.\"},\n",
       "   {'id': 'd7486d88c541',\n",
       "    'title': 'LMQL\\u200a—\\u200aSQL for Language Models',\n",
       "    'subtitle': 'Yet another tool that could help you with LLM applications',\n",
       "    'author': '15a29a4fc6ad',\n",
       "    'publication_id': '7f60cf5620c9',\n",
       "    'published_at': '2023-11-27 16:31:51',\n",
       "    'last_modified_at': '2023-11-27 16:31:51',\n",
       "    'tags': ['llm',\n",
       "     'sentiment-analysis',\n",
       "     'nlp',\n",
       "     'data-science',\n",
       "     'editors-pick'],\n",
       "    'topics': ['artificial-intelligence', 'data-science', 'programming'],\n",
       "    'claps': 883,\n",
       "    'voters': 251,\n",
       "    'word_count': 3898,\n",
       "    'responses_count': 12,\n",
       "    'reading_time': 16.30943396226415,\n",
       "    'url': 'https://towardsdatascience.com/lmql-sql-for-language-models-d7486d88c541',\n",
       "    'unique_slug': 'lmql-sql-for-language-models-d7486d88c541',\n",
       "    'image_url': 'https://miro.medium.com/1*yv1s9-5rzlm5NTrWJUdRIA.jpeg',\n",
       "    'lang': 'en',\n",
       "    'is_series': False,\n",
       "    'is_locked': False,\n",
       "    'is_shortform': False,\n",
       "    'top_highlight': 'I believe the most crucial benefit of LMQL is the complete control of your output. However, with such an approach, you will also have another layer of abstraction over LLM (similar to LangChain, which we discussed earlier). It will allow you to switch from one backend to another easily if you need to. LMQL can work with different backends: OpenAI, HuggingFace Transformers or llama.cpp.'},\n",
       "   {'id': 'eaf5469b83b0',\n",
       "    'title': 'RAG: How to Talk to Your Data',\n",
       "    'subtitle': 'Comprehensive guide on how to analyse customer feedback using ChatGPT',\n",
       "    'author': '15a29a4fc6ad',\n",
       "    'publication_id': '7f60cf5620c9',\n",
       "    'published_at': '2023-11-11 05:54:51',\n",
       "    'last_modified_at': '2023-11-11 08:46:29',\n",
       "    'tags': ['chatgpt',\n",
       "     'llm',\n",
       "     'langchain',\n",
       "     'hands-on-tutorials',\n",
       "     'naturallanguageprocessing'],\n",
       "    'topics': ['machine-learning', 'programming'],\n",
       "    'claps': 429,\n",
       "    'voters': 93,\n",
       "    'word_count': 4751,\n",
       "    'responses_count': 5,\n",
       "    'reading_time': 20.378301886792453,\n",
       "    'url': 'https://towardsdatascience.com/rag-how-to-talk-to-your-data-eaf5469b83b0',\n",
       "    'unique_slug': 'rag-how-to-talk-to-your-data-eaf5469b83b0',\n",
       "    'image_url': 'https://miro.medium.com/1*XFIVfZf4FYSm4lY01Auimw.png',\n",
       "    'lang': 'en',\n",
       "    'is_series': False,\n",
       "    'is_locked': False,\n",
       "    'is_shortform': False,\n",
       "    'top_highlight': ''},\n",
       "   {'id': 'e3b3e99e4fca',\n",
       "    'title': 'Topic Modelling in production',\n",
       "    'subtitle': 'Leveraging LangChain to move from ad-hoc Jupyter Notebooks to production modular service',\n",
       "    'author': '15a29a4fc6ad',\n",
       "    'publication_id': '7f60cf5620c9',\n",
       "    'published_at': '2023-10-30 14:07:06',\n",
       "    'last_modified_at': '2023-10-30 14:07:06',\n",
       "    'tags': ['chatgpt',\n",
       "     'llm',\n",
       "     'machine-learning',\n",
       "     'evaluation',\n",
       "     'editors-pick'],\n",
       "    'topics': ['artificial-intelligence', 'machine-learning', 'data-science'],\n",
       "    'claps': 392,\n",
       "    'voters': 79,\n",
       "    'word_count': 5271,\n",
       "    'responses_count': 6,\n",
       "    'reading_time': 21.390566037735848,\n",
       "    'url': 'https://towardsdatascience.com/topic-modelling-in-production-e3b3e99e4fca',\n",
       "    'unique_slug': 'topic-modelling-in-production-e3b3e99e4fca',\n",
       "    'image_url': 'https://miro.medium.com/1*zrrzdFgAnm7YAyIYtINhoA.jpeg',\n",
       "    'lang': 'en',\n",
       "    'is_series': False,\n",
       "    'is_locked': False,\n",
       "    'is_shortform': False,\n",
       "    'top_highlight': ''},\n",
       "   {'id': 'c288b48918af',\n",
       "    'title': 'Understanding Retention with Gradio',\n",
       "    'subtitle': 'How to leverage web applications for analytics',\n",
       "    'author': '15a29a4fc6ad',\n",
       "    'publication_id': '7f60cf5620c9',\n",
       "    'published_at': '2023-10-21 00:01:49',\n",
       "    'last_modified_at': '2023-10-21 08:46:52',\n",
       "    'tags': ['programming',\n",
       "     'python',\n",
       "     'web-development',\n",
       "     'data-science',\n",
       "     'hands-on-tutorials'],\n",
       "    'topics': ['machine-learning',\n",
       "     'software-engineering',\n",
       "     'data-science',\n",
       "     'programming'],\n",
       "    'claps': 200,\n",
       "    'voters': 32,\n",
       "    'word_count': 3426,\n",
       "    'responses_count': 1,\n",
       "    'reading_time': 14.228301886792453,\n",
       "    'url': 'https://towardsdatascience.com/understanding-retention-with-gradio-c288b48918af',\n",
       "    'unique_slug': 'understanding-retention-with-gradio-c288b48918af',\n",
       "    'image_url': 'https://miro.medium.com/1*5g9rJ4iCzdBTMPAKVuEljg.png',\n",
       "    'lang': 'en',\n",
       "    'is_series': False,\n",
       "    'is_locked': False,\n",
       "    'is_shortform': False,\n",
       "    'top_highlight': ''}]},\n",
       " 'fb44e21903f3': {'id': 'fb44e21903f3',\n",
       "  'username': 'frank-andrade',\n",
       "  'fullname': 'The PyCoach',\n",
       "  'bio': 'My ChatGPT Course - ChatGPT Unleashed: Master GPT-4 & Prompt Engineering: bit.ly/chatgpt-pycoach',\n",
       "  'followers_count': 135695,\n",
       "  'following_count': 13,\n",
       "  'publication_following_count': 3,\n",
       "  'image_url': 'https://miro.medium.com/1*veEX4-CiLz5jqUjwWfQo_Q.jpeg',\n",
       "  'twitter_username': 'ThePyCoach',\n",
       "  'is_writer_program_enrolled': True,\n",
       "  'allow_notes': True,\n",
       "  'medium_member_at': '2024-01-03 12:08:25',\n",
       "  'is_suspended': False,\n",
       "  'top_writer_in': ['science', 'artificial-intelligence', 'technology'],\n",
       "  'has_list': True,\n",
       "  'is_book_author': False,\n",
       "  'tipping_link': 'https://www.paypal.com/donate/?hosted_button_id=FV6C563QKSYGS',\n",
       "  'bg_image_url': '',\n",
       "  'logo_image_url': '',\n",
       "  'followers': ['0008d1d32e50',\n",
       "   '00117ef3e7b2',\n",
       "   '001479440872',\n",
       "   '00153b23a790',\n",
       "   '00183ef79cce',\n",
       "   '0023a4a5cccf',\n",
       "   '00245ad345da',\n",
       "   '00388d34235e',\n",
       "   '003c898ec4a7',\n",
       "   '003fe511835f',\n",
       "   '0041541f90e4',\n",
       "   '00456e4a5913',\n",
       "   '00477577ef07',\n",
       "   '004c7dcf0101',\n",
       "   '004d3a6a5f5c',\n",
       "   '004e20cb72b3',\n",
       "   '005144e861bb',\n",
       "   '0051a417ab48',\n",
       "   '00555da4d13e',\n",
       "   '00595bfcb7de',\n",
       "   '005c18b43c6c',\n",
       "   '0067079f283d',\n",
       "   '00688c9cb4b6',\n",
       "   '006a2946b9b9',\n",
       "   '007248b58676',\n",
       "   '00777a15e411',\n",
       "   '0078a8c1aefd',\n",
       "   '00828a580394',\n",
       "   '0087eac60399',\n",
       "   '00887a2a0019',\n",
       "   '00898d68a8d8',\n",
       "   '008bd264da31',\n",
       "   '008e42d846db',\n",
       "   '008e9df23730',\n",
       "   '00984f1b6f67',\n",
       "   '009861293cfb',\n",
       "   '00a2033e3de5',\n",
       "   '00a6814e9fb8',\n",
       "   '00a78a6007f4',\n",
       "   '00a7f4726d5b',\n",
       "   '00abad96696a',\n",
       "   '00add8d180a5',\n",
       "   '00af43322bed',\n",
       "   '00b0ad7585f2',\n",
       "   '00b2c392e7d2',\n",
       "   '00b2d5b80654',\n",
       "   '00b8eada8b79',\n",
       "   '00c0c5ad7d20',\n",
       "   '00c54aa1ed8f',\n",
       "   '00d8401e2269',\n",
       "   '00d9fed5f4f3',\n",
       "   '00da4ebaf9e6',\n",
       "   '00dabd5cc1c8',\n",
       "   '00dbe31561b3',\n",
       "   '00dc8f86d367',\n",
       "   '00dd5ca6857d',\n",
       "   '00dd762aef3b',\n",
       "   '00de22ec4707',\n",
       "   '00e8ccaf36ec',\n",
       "   '00efb7dca942',\n",
       "   '00f1dddb885d',\n",
       "   '00f3825d8b3a',\n",
       "   '0100bfad1385',\n",
       "   '0100f7710191',\n",
       "   '0102838e5346',\n",
       "   '01054c60a74b',\n",
       "   '010aff80b0a3',\n",
       "   '010d0f45e2cd',\n",
       "   '0111fe792d8c',\n",
       "   '0120fe55e44b',\n",
       "   '01247722f2d2',\n",
       "   '0126db676b5c',\n",
       "   '012fbed07467',\n",
       "   '0136ab45dad9',\n",
       "   '0137eaabb94e',\n",
       "   '014670628993',\n",
       "   '0147f605c5db',\n",
       "   '0148cadc7e45',\n",
       "   '014c206a567d',\n",
       "   '014c3755e989',\n",
       "   '014efbc1c2ff',\n",
       "   '0151e1c50a4d',\n",
       "   '0158b5dca221',\n",
       "   '016a4c58266b',\n",
       "   '017686580bb5',\n",
       "   '01782b701a24',\n",
       "   '017dd141af02',\n",
       "   '017f6844d2e2',\n",
       "   '01821004b009',\n",
       "   '018817b73fd3',\n",
       "   '01881ecb24b2',\n",
       "   '018b35c4d3dc',\n",
       "   '018f1876ee04',\n",
       "   '01990c65fee3',\n",
       "   '01a707c451b0',\n",
       "   '01b12abe8016',\n",
       "   '01b393da4d36',\n",
       "   '01b4efeff9a1',\n",
       "   '01b571f13d0c',\n",
       "   '01bace87a8ca',\n",
       "   '01c01b947c2d',\n",
       "   '01c2063597aa',\n",
       "   '01c399f36ba1',\n",
       "   '01c88532e192',\n",
       "   '01c9ec4b7ad7',\n",
       "   '01cf0debc091',\n",
       "   '01d173ab023a',\n",
       "   '01d437bc8064',\n",
       "   '01d758d3b9ef',\n",
       "   '01d8e578b7b2',\n",
       "   '01d9c405c912',\n",
       "   '01d9cc1c64d3',\n",
       "   '01da1d589b4e',\n",
       "   '01dac4afff8a',\n",
       "   '01daee96cb28',\n",
       "   '01db58af4bc4',\n",
       "   '01dfdc67abb4',\n",
       "   '01e23b1c1d65',\n",
       "   '01e57daf3792',\n",
       "   '01f41843a8eb',\n",
       "   '01f8b0ded080',\n",
       "   '01faad01498c',\n",
       "   '01fced2bc1fb',\n",
       "   '01ff65a0ad34',\n",
       "   '02003ebe3684',\n",
       "   '0204ef6947ed',\n",
       "   '02070e84b81f',\n",
       "   '020b7fa0b326',\n",
       "   '02110309b737',\n",
       "   '0212a3c23533',\n",
       "   '02196c29640d',\n",
       "   '021d519b5bc3',\n",
       "   '02280d93570d',\n",
       "   '022ba2c619c9',\n",
       "   '023045d36029',\n",
       "   '02322685de86',\n",
       "   '0232d63472f7',\n",
       "   '02331c9dd59d',\n",
       "   '0234440f063d',\n",
       "   '0248662e2c78',\n",
       "   '024bd81e538c',\n",
       "   '02593edd9dcf',\n",
       "   '025df2df9a37',\n",
       "   '0262a760168a',\n",
       "   '0263d85a8fb5',\n",
       "   '0264b2e02184',\n",
       "   '0268f2f725c1',\n",
       "   '0271142d456b',\n",
       "   '027afa6fc5a2',\n",
       "   '027b9b59cb41',\n",
       "   '027d795e32ea',\n",
       "   '027dae4d7eae',\n",
       "   '0282f6923d6b',\n",
       "   '028495e9580a',\n",
       "   '028b27877c10',\n",
       "   '02931e66d01b',\n",
       "   '02942f450ffe',\n",
       "   '029482385112',\n",
       "   '02970a301007',\n",
       "   '029b5c04a6c6',\n",
       "   '029d10c2f6f3',\n",
       "   '029d685664b8',\n",
       "   '02a46ec65eda',\n",
       "   '02a4cdc650a7',\n",
       "   '02af5b038892',\n",
       "   '02b0cba4f85e',\n",
       "   '02b5114c779a',\n",
       "   '02b55d3a1e00',\n",
       "   '02b8ed232856',\n",
       "   '02bfbef36f37',\n",
       "   '02c0a68048ec',\n",
       "   '02c13b34624f',\n",
       "   '02c255a90dfc',\n",
       "   '02c7f5df2d54',\n",
       "   '02cf374e2ba8',\n",
       "   '02d0530432da',\n",
       "   '02d41a047dbb',\n",
       "   '02d425d4bee9',\n",
       "   '02d5c22ee957',\n",
       "   '02d63c21760c',\n",
       "   '02d65605dc46',\n",
       "   '02d7581eb08b',\n",
       "   '02db58d8db59',\n",
       "   '02dd4389cb56',\n",
       "   '02e08aa7923f',\n",
       "   '02e475cb1119',\n",
       "   '02e793cf0306',\n",
       "   '02eaf3040291',\n",
       "   '02ed07da7b7f',\n",
       "   '02eef590a42c',\n",
       "   '02f02d77edd2',\n",
       "   '02f6ac7faaac',\n",
       "   '03003f596e54',\n",
       "   '0301f0276167',\n",
       "   '030207032d8b',\n",
       "   '0307981d6591',\n",
       "   '03081b20fb4b',\n",
       "   '030f88006732',\n",
       "   '031182edd03b',\n",
       "   '031310aab142',\n",
       "   '03133540481d',\n",
       "   '03159f6d6201',\n",
       "   '0316d7e5df44',\n",
       "   '031f2761b09d',\n",
       "   '032d5abb77b8',\n",
       "   '032e54e23b1b',\n",
       "   '03300c1dfa01',\n",
       "   '0330240f9bcd',\n",
       "   '033047e9ac9b',\n",
       "   '03306b172d54',\n",
       "   '03342d576b07',\n",
       "   '033703f31d01',\n",
       "   '0337d98e45c1',\n",
       "   '033965e0bb31',\n",
       "   '033dddc0e361',\n",
       "   '033eb7b3cdfd',\n",
       "   '033f73e79d6e',\n",
       "   '03416dedaeef',\n",
       "   '0344c819f9fc',\n",
       "   '0345651c406a',\n",
       "   '034815965a09',\n",
       "   '03487d9e6ab6',\n",
       "   '034f59d2a2b6',\n",
       "   '034ff0c468c0',\n",
       "   '03587a17e4f1',\n",
       "   '0358fb7e422b',\n",
       "   '035d8d2a6e3e',\n",
       "   '03609e9ab716',\n",
       "   '03659d6f7167',\n",
       "   '036aba21e350',\n",
       "   '036b32594457',\n",
       "   '036b6bbbf3dd',\n",
       "   '036ecf5a78de',\n",
       "   '036fbff49afc',\n",
       "   '037594dba978',\n",
       "   '037cf47840d3',\n",
       "   '037eb302f1b6',\n",
       "   '038385d05991',\n",
       "   '03864b87e5d5',\n",
       "   '038a71bb5643',\n",
       "   '0391dc79c050',\n",
       "   '0393d11e19bc',\n",
       "   '039563a6c0f4',\n",
       "   '0396e51ec32d',\n",
       "   '039e1349ed1d',\n",
       "   '03aac8a59532',\n",
       "   '03abcd2b84ea',\n",
       "   '03ace9b06076',\n",
       "   '03b4a1b945c1',\n",
       "   '03b52ef93f2c',\n",
       "   '03ba778853a9',\n",
       "   '03cc3c502760',\n",
       "   '03d71dd7fca1',\n",
       "   '03d778a58360',\n",
       "   '03d7d3416226',\n",
       "   '03e21728b8a8',\n",
       "   '03e527c257f9',\n",
       "   '03e94dc60823',\n",
       "   '03efbae57fbc',\n",
       "   '03fa533aee11',\n",
       "   '03fe71c35f9b',\n",
       "   '0409b4c901e0',\n",
       "   '041b31277374',\n",
       "   '0424195a162e',\n",
       "   '042595bf2506',\n",
       "   '0428ee002a03',\n",
       "   '042adf22d8c6',\n",
       "   '042b949fa1df',\n",
       "   '04300428355f',\n",
       "   '043221bf8ccc',\n",
       "   '04384c3f6ee2',\n",
       "   '04396030e4fd',\n",
       "   '043cd53a2148',\n",
       "   '04507796390c',\n",
       "   '04548e168f72',\n",
       "   '045c720b9946',\n",
       "   '046227c4bd26',\n",
       "   '04642341d47b',\n",
       "   '046a109f9648',\n",
       "   '046bc945bad1',\n",
       "   '046dee9c1a33',\n",
       "   '046f821cca84',\n",
       "   '0476e67d4326',\n",
       "   '047e0bb9bf46',\n",
       "   '047f817e27eb',\n",
       "   '04840369bb54',\n",
       "   '04887b109028',\n",
       "   '0488cb6529c7',\n",
       "   '048979b866f1',\n",
       "   '048e7e7b457a',\n",
       "   '0497fdbd3053',\n",
       "   '049d24cede8e',\n",
       "   '049d89885fc2',\n",
       "   '04a34f2f76c6',\n",
       "   '04a3babd67f1',\n",
       "   '04abe36775c2',\n",
       "   '04aeafb19e7d',\n",
       "   '04b05ca640a6',\n",
       "   '04b64744fada',\n",
       "   '04b8b0227b8b',\n",
       "   '04bbdf5d44ce',\n",
       "   '04c1208ef3c1',\n",
       "   '04c64858eb44',\n",
       "   '04c65cef2361',\n",
       "   '04ca33ca0707',\n",
       "   '04d0adca0dc2',\n",
       "   '04d2dd591718',\n",
       "   '04d3e1bc360f',\n",
       "   '04d685f34568',\n",
       "   '04d6cd12f849',\n",
       "   '04e2faff920f',\n",
       "   '04e93b810724',\n",
       "   '04e94eb13d69',\n",
       "   '04ecdfce0104',\n",
       "   '04ef4a39f7fb',\n",
       "   '04f020827223',\n",
       "   '04f063d9956b',\n",
       "   '04fbc71cc0d6',\n",
       "   '0501a9c4329e',\n",
       "   '0506d49d2b82',\n",
       "   '0510d11d9324',\n",
       "   '051bf35d4e0a',\n",
       "   '05210203743a',\n",
       "   '05284d6fc362',\n",
       "   '052877c01841',\n",
       "   '052cd880ea2d',\n",
       "   '052ec7da0a2c',\n",
       "   '0547d4779c29',\n",
       "   '054b8841783d',\n",
       "   '054c57c29903',\n",
       "   '054c6f85e73a',\n",
       "   '05527a3163a8',\n",
       "   '05587e7e825b',\n",
       "   '0559b94922c5',\n",
       "   '055df98e2677',\n",
       "   '055fffabdbd9',\n",
       "   '056055927b0a',\n",
       "   '05606c29320c',\n",
       "   '0562b33e89a3',\n",
       "   '056d17f08df8',\n",
       "   '056e29398026',\n",
       "   '0572d0664f88',\n",
       "   '0577d07da4eb',\n",
       "   '057ae7cd2ddd',\n",
       "   '057fba91271b',\n",
       "   '058078a46768',\n",
       "   '0584981f45f3',\n",
       "   '058a6d5a31c2',\n",
       "   '0590fe56fced',\n",
       "   '0591cd50fcdb',\n",
       "   '0597394845f8',\n",
       "   '05981b9ce618',\n",
       "   '059b0d5e8f7e',\n",
       "   '059f912c9ba1',\n",
       "   '05a00331113c',\n",
       "   '05a0b0fcbaf1',\n",
       "   '05a0e6fe58e3',\n",
       "   '05a0ebf7a06e',\n",
       "   '05aa8f050397',\n",
       "   '05b1c42379be',\n",
       "   '05b3db008294',\n",
       "   '05b5eebb6e15',\n",
       "   '05b67ee84186',\n",
       "   '05b7fa07a335',\n",
       "   '05bb21089d21',\n",
       "   '05bce450cb31',\n",
       "   '05c4ce56386f',\n",
       "   '05c86952af36',\n",
       "   '05cc8277c7d4',\n",
       "   '05ce1223cae0',\n",
       "   '05ce1616cfad',\n",
       "   '05cf0e0ac763',\n",
       "   '05cf15363a93',\n",
       "   '05d6d0c339d7',\n",
       "   '05eab01a40a6',\n",
       "   '05eb7b046c5a',\n",
       "   '05ec6bc5cba4',\n",
       "   '05ed96c09efe',\n",
       "   '05ef87641d45',\n",
       "   '05f1bab0e90a',\n",
       "   '05f3a138d526',\n",
       "   '05f519385063',\n",
       "   '05f804d1a69c',\n",
       "   '05f95e3e7f07',\n",
       "   '05f9be6f76f4',\n",
       "   '0607a542f6b5',\n",
       "   '0612100996f6',\n",
       "   '06140d198bd6',\n",
       "   '0615354111cc',\n",
       "   '061cbe4f2445',\n",
       "   '06223b42e354',\n",
       "   '06261e0c30bc',\n",
       "   '062853dfffb3',\n",
       "   '0633c1ce68f4',\n",
       "   '063991ed8967',\n",
       "   '063ce1a30995',\n",
       "   '063d96265981',\n",
       "   '063fc61af6d7',\n",
       "   '065032306a6a',\n",
       "   '0651b49a9912',\n",
       "   '06561a8e76aa',\n",
       "   '06565d2080ba',\n",
       "   '065e4bfafe52',\n",
       "   '0662113530e4',\n",
       "   '0662472674ea',\n",
       "   '066982244fb5',\n",
       "   '067007c48ba3',\n",
       "   '06711d3536d6',\n",
       "   '06774ca72fe7',\n",
       "   '0678e50a916c',\n",
       "   '067b0aa816c9',\n",
       "   '067e58b7ca9a',\n",
       "   '0681d777e1aa',\n",
       "   '0682d485a667',\n",
       "   '068e87933189',\n",
       "   '0694d06ecc83',\n",
       "   '06953231c9c0',\n",
       "   '069a9346ae53',\n",
       "   '06a8bb9538b3',\n",
       "   '06a8f81625eb',\n",
       "   '06a990b50d24',\n",
       "   '06aff53c963d',\n",
       "   '06b7bdc80d7d',\n",
       "   '06ba4e161535',\n",
       "   '06c0c1dfd342',\n",
       "   '06c585175df7',\n",
       "   '06c9e2d23eb3',\n",
       "   '06cc423f3760',\n",
       "   '06d375f1f359',\n",
       "   '06ddb1515844',\n",
       "   '06e11507e592',\n",
       "   '06e14752c974',\n",
       "   '06e36d967945',\n",
       "   '06e71a7dd415',\n",
       "   '06f1311e6f6f',\n",
       "   '06f216368875',\n",
       "   '06f75bfbe563',\n",
       "   '06f8412877e2',\n",
       "   '06f8a7b750cd',\n",
       "   '0700d8dea276',\n",
       "   '0704d62f2041',\n",
       "   '070504b37fd7',\n",
       "   '0706457043d4',\n",
       "   '070de554a633',\n",
       "   '07111536eaca',\n",
       "   '0712db3d73c6',\n",
       "   '07193aa53bf6',\n",
       "   '0719efd42839',\n",
       "   '071be2e34da6',\n",
       "   '071da920fdde',\n",
       "   '071e4e0536ef',\n",
       "   '072097543e86',\n",
       "   '07228a3998a1',\n",
       "   '0728c366269d',\n",
       "   '072be4d3738f',\n",
       "   '072d77c6b2a0',\n",
       "   '072e8a5bae3f',\n",
       "   '073133dbe904',\n",
       "   '073524fea43c',\n",
       "   '0744a64a8eff',\n",
       "   '074755f68248',\n",
       "   '075164f7be57',\n",
       "   '07517811cfb3',\n",
       "   '075530da7b04',\n",
       "   '075b1029419f',\n",
       "   '075d8e06a67c',\n",
       "   '076045452315',\n",
       "   '0766bbc464da',\n",
       "   '0769a30d3e05'],\n",
       "  'top_articles': [{'id': '5137fdafb355',\n",
       "    'title': 'You’re Not The Only One Feeling AI Fatigue (Or: Why That New AI Tool Isn’t for You)',\n",
       "    'subtitle': 'More AI tools, more AI fatigue.',\n",
       "    'author': 'fb44e21903f3',\n",
       "    'publication_id': '76436a11a2b0',\n",
       "    'published_at': '2024-02-13 16:56:05',\n",
       "    'last_modified_at': '2024-02-13 16:56:05',\n",
       "    'tags': ['artificial-intelligence', 'technology', 'chatgpt', 'science'],\n",
       "    'topics': ['artificial-intelligence'],\n",
       "    'claps': 624,\n",
       "    'voters': 85,\n",
       "    'word_count': 1355,\n",
       "    'responses_count': 14,\n",
       "    'reading_time': 5.313207547169812,\n",
       "    'url': 'https://medium.com/artificial-corner/youre-not-the-only-one-feeling-ai-fatigue-or-why-that-new-ai-tool-isn-t-for-you-5137fdafb355',\n",
       "    'unique_slug': 'youre-not-the-only-one-feeling-ai-fatigue-or-why-that-new-ai-tool-isn-t-for-you-5137fdafb355',\n",
       "    'image_url': 'https://miro.medium.com/1*U-x0yxnQOUB7DvRS0YTaSw.png',\n",
       "    'lang': 'en',\n",
       "    'is_series': False,\n",
       "    'is_locked': True,\n",
       "    'is_shortform': False,\n",
       "    'top_highlight': 'I turned a deaf ear to the influencers persuading me to jump on every new AI tool'},\n",
       "   {'id': 'b3e8446773b9',\n",
       "    'title': 'Gemini Ultra vs GPT-4: Did Google Beat GPT-4 This Time?',\n",
       "    'subtitle': 'The good, bad, and unexpected of Gemini Ultra.',\n",
       "    'author': 'fb44e21903f3',\n",
       "    'publication_id': '76436a11a2b0',\n",
       "    'published_at': '2024-02-09 18:26:53',\n",
       "    'last_modified_at': '2024-02-09 18:26:53',\n",
       "    'tags': ['artificial-intelligence',\n",
       "     'technology',\n",
       "     'chatgpt',\n",
       "     'midjourney',\n",
       "     'science'],\n",
       "    'topics': ['artificial-intelligence', 'design'],\n",
       "    'claps': 504,\n",
       "    'voters': 96,\n",
       "    'word_count': 1162,\n",
       "    'responses_count': 9,\n",
       "    'reading_time': 5.834905660377359,\n",
       "    'url': 'https://medium.com/artificial-corner/gemini-ultra-vs-gpt-4-did-google-beat-gpt-4-this-time-b3e8446773b9',\n",
       "    'unique_slug': 'gemini-ultra-vs-gpt-4-did-google-beat-gpt-4-this-time-b3e8446773b9',\n",
       "    'image_url': 'https://miro.medium.com/1*zdt7zAOcfYY6K66kea0mUQ.jpeg',\n",
       "    'lang': 'en',\n",
       "    'is_series': False,\n",
       "    'is_locked': True,\n",
       "    'is_shortform': False,\n",
       "    'top_highlight': \"However, unlike DALL-E 3, Gemini doesn't improve your prompt. If I use the same prompt on ChatGPT, DALL-E 3 will generate a prompt that gives a more eye-catching look to the image.\"},\n",
       "   {'id': 'bb4d6a735fc1',\n",
       "    'title': 'I Tried Multiple AI Coding Assistants. These Are The Best',\n",
       "    'subtitle': 'Best AI coding assistants for beginners and experienced programmers.',\n",
       "    'author': 'fb44e21903f3',\n",
       "    'publication_id': '76436a11a2b0',\n",
       "    'published_at': '2024-01-25 18:39:41',\n",
       "    'last_modified_at': '2024-01-25 18:39:41',\n",
       "    'tags': ['chatgpt',\n",
       "     'technology',\n",
       "     'artificial-intelligence',\n",
       "     'programming',\n",
       "     'python'],\n",
       "    'topics': ['artificial-intelligence', 'programming'],\n",
       "    'claps': 1371,\n",
       "    'voters': 324,\n",
       "    'word_count': 1255,\n",
       "    'responses_count': 22,\n",
       "    'reading_time': 6.635849056603773,\n",
       "    'url': 'https://medium.com/artificial-corner/i-tried-multiple-ai-coding-assistants-these-are-the-best-bb4d6a735fc1',\n",
       "    'unique_slug': 'i-tried-multiple-ai-coding-assistants-these-are-the-best-bb4d6a735fc1',\n",
       "    'image_url': 'https://miro.medium.com/1*4Xv28m71C-27267n8fP-WQ.png',\n",
       "    'lang': 'en',\n",
       "    'is_series': False,\n",
       "    'is_locked': True,\n",
       "    'is_shortform': False,\n",
       "    'top_highlight': 'I Tried Multiple AI Coding Assistants. These Are The Best'},\n",
       "   {'id': 'e6dd223d6ae0',\n",
       "    'title': 'The Best GPTs for Programmers',\n",
       "    'subtitle': 'These GPTs will automate part of your coding projects.',\n",
       "    'author': 'fb44e21903f3',\n",
       "    'publication_id': '76436a11a2b0',\n",
       "    'published_at': '2024-01-19 17:59:27',\n",
       "    'last_modified_at': '2024-01-19 17:59:27',\n",
       "    'tags': ['chatgpt',\n",
       "     'artificial-intelligence',\n",
       "     'technology',\n",
       "     'python',\n",
       "     'programming'],\n",
       "    'topics': ['programming'],\n",
       "    'claps': 613,\n",
       "    'voters': 179,\n",
       "    'word_count': 924,\n",
       "    'responses_count': 6,\n",
       "    'reading_time': 4.836792452830188,\n",
       "    'url': 'https://medium.com/artificial-corner/the-best-gpts-for-programmers-e6dd223d6ae0',\n",
       "    'unique_slug': 'the-best-gpts-for-programmers-e6dd223d6ae0',\n",
       "    'image_url': 'https://miro.medium.com/1*g0gnC_K7D0CbCakIYaxVdQ.png',\n",
       "    'lang': 'en',\n",
       "    'is_series': False,\n",
       "    'is_locked': True,\n",
       "    'is_shortform': False,\n",
       "    'top_highlight': ''},\n",
       "   {'id': '84e568626e89',\n",
       "    'title': 'OpenAI Just Released The GPT Store. Here’s How To Use It And Make Money With Your GPT',\n",
       "    'subtitle': 'Learn how to publish your GPT to the store and monetize it.',\n",
       "    'author': 'fb44e21903f3',\n",
       "    'publication_id': '76436a11a2b0',\n",
       "    'published_at': '2024-01-11 14:04:50',\n",
       "    'last_modified_at': '2024-01-11 14:04:50',\n",
       "    'tags': ['artificial-intelligence',\n",
       "     'technology',\n",
       "     'chatgpt',\n",
       "     'science',\n",
       "     'python'],\n",
       "    'topics': ['programming'],\n",
       "    'claps': 2314,\n",
       "    'voters': 392,\n",
       "    'word_count': 826,\n",
       "    'responses_count': 29,\n",
       "    'reading_time': 4.166981132075472,\n",
       "    'url': 'https://medium.com/artificial-corner/openai-just-released-the-gpt-store-heres-how-to-use-it-and-make-money-with-your-gpt-84e568626e89',\n",
       "    'unique_slug': 'openai-just-released-the-gpt-store-heres-how-to-use-it-and-make-money-with-your-gpt-84e568626e89',\n",
       "    'image_url': 'https://miro.medium.com/1*d41v0LCPk7uIG0okVZ_kCQ.png',\n",
       "    'lang': 'en',\n",
       "    'is_series': False,\n",
       "    'is_locked': True,\n",
       "    'is_shortform': False,\n",
       "    'top_highlight': 'As you can see there are three, but the one I created for a previous tutorial is the first (I think the comment bubble on the right means how many conversations have been started with a GPT).'},\n",
       "   {'id': '4eaff6178983',\n",
       "    'title': 'Artificial Corner Will No Longer Publish Stories On This Site',\n",
       "    'subtitle': 'Here’s why and some important details.',\n",
       "    'author': 'fb44e21903f3',\n",
       "    'publication_id': '76436a11a2b0',\n",
       "    'published_at': '2023-12-26 17:18:38',\n",
       "    'last_modified_at': '2023-12-26 17:18:38',\n",
       "    'tags': ['chatgpt', 'technology', 'artificial-intelligence', 'science'],\n",
       "    'topics': ['artificial-intelligence'],\n",
       "    'claps': 294,\n",
       "    'voters': 40,\n",
       "    'word_count': 300,\n",
       "    'responses_count': 4,\n",
       "    'reading_time': 1.3320754716981131,\n",
       "    'url': 'https://medium.com/artificial-corner/artificial-corner-will-no-longer-publish-stories-on-this-site-4eaff6178983',\n",
       "    'unique_slug': 'artificial-corner-will-no-longer-publish-stories-on-this-site-4eaff6178983',\n",
       "    'image_url': 'https://miro.medium.com/0*NoKpYRcRcsXEes3B',\n",
       "    'lang': 'en',\n",
       "    'is_series': False,\n",
       "    'is_locked': False,\n",
       "    'is_shortform': False,\n",
       "    'top_highlight': ''},\n",
       "   {'id': '4ff7e5973b05',\n",
       "    'title': '“Google Will Kill ChatGPT” and Other Overhyped AI Predictions We Heard In 2023',\n",
       "    'subtitle': 'Here are some predictions that I doubt will happen in 2024 or the near future (and why I think so).',\n",
       "    'author': 'fb44e21903f3',\n",
       "    'publication_id': '76436a11a2b0',\n",
       "    'published_at': '2023-12-20 18:41:12',\n",
       "    'last_modified_at': '2023-12-20 18:41:12',\n",
       "    'tags': ['artificial-intelligence', 'chatgpt', 'technology', 'science'],\n",
       "    'topics': ['artificial-intelligence'],\n",
       "    'claps': 491,\n",
       "    'voters': 46,\n",
       "    'word_count': 1166,\n",
       "    'responses_count': 8,\n",
       "    'reading_time': 4.95,\n",
       "    'url': 'https://medium.com/artificial-corner/google-will-kill-chatgpt-and-other-overhyped-ai-predictions-we-heard-in-2023-4ff7e5973b05',\n",
       "    'unique_slug': 'google-will-kill-chatgpt-and-other-overhyped-ai-predictions-we-heard-in-2023-4ff7e5973b05',\n",
       "    'image_url': 'https://miro.medium.com/1*R_NH8O9YvZ4zVACxdQwJow.png',\n",
       "    'lang': 'en',\n",
       "    'is_series': False,\n",
       "    'is_locked': True,\n",
       "    'is_shortform': False,\n",
       "    'top_highlight': ''},\n",
       "   {'id': 'e23bfa19bf16',\n",
       "    'title': 'A Hands-On Comparison: Gemini Pro vs GPT-3.5',\n",
       "    'subtitle': 'And the winner is\\xa0…',\n",
       "    'author': 'fb44e21903f3',\n",
       "    'publication_id': '76436a11a2b0',\n",
       "    'published_at': '2023-12-12 12:01:54',\n",
       "    'last_modified_at': '2023-12-12 12:01:54',\n",
       "    'tags': ['chatgpt',\n",
       "     'artificial-intelligence',\n",
       "     'technology',\n",
       "     'science',\n",
       "     'python'],\n",
       "    'topics': ['programming'],\n",
       "    'claps': 567,\n",
       "    'voters': 74,\n",
       "    'word_count': 989,\n",
       "    'responses_count': 10,\n",
       "    'reading_time': 5.382075471698113,\n",
       "    'url': 'https://medium.com/artificial-corner/a-hands-on-comparison-gemini-pro-vs-gpt-3-5-e23bfa19bf16',\n",
       "    'unique_slug': 'a-hands-on-comparison-gemini-pro-vs-gpt-3-5-e23bfa19bf16',\n",
       "    'image_url': 'https://miro.medium.com/1*0KOYEV-7j3NXe7zHP6URyA.png',\n",
       "    'lang': 'en',\n",
       "    'is_series': False,\n",
       "    'is_locked': True,\n",
       "    'is_shortform': False,\n",
       "    'top_highlight': ''},\n",
       "   {'id': '16ed78293975',\n",
       "    'title': 'Here’s Why I Still Don’t Buy the Hype of Google Gemini',\n",
       "    'subtitle': 'Gemini might not be as good as it seems to be.',\n",
       "    'author': 'fb44e21903f3',\n",
       "    'publication_id': '76436a11a2b0',\n",
       "    'published_at': '2023-12-08 17:49:53',\n",
       "    'last_modified_at': '2023-12-08 17:49:53',\n",
       "    'tags': ['chatgpt',\n",
       "     'artificial-intelligence',\n",
       "     'technology',\n",
       "     'science',\n",
       "     'python'],\n",
       "    'topics': ['artificial-intelligence'],\n",
       "    'claps': 615,\n",
       "    'voters': 97,\n",
       "    'word_count': 1078,\n",
       "    'responses_count': 9,\n",
       "    'reading_time': 5.317924528301887,\n",
       "    'url': 'https://medium.com/artificial-corner/heres-why-i-still-don-t-buy-the-hype-of-google-gemini-16ed78293975',\n",
       "    'unique_slug': 'heres-why-i-still-don-t-buy-the-hype-of-google-gemini-16ed78293975',\n",
       "    'image_url': 'https://miro.medium.com/0*QQ7EbFFz_gxnv5xv.png',\n",
       "    'lang': 'en',\n",
       "    'is_series': False,\n",
       "    'is_locked': True,\n",
       "    'is_shortform': False,\n",
       "    'top_highlight': \"Google's Gemini was just unveiled, and I haven't seen so much hype since ChatGPT was released by OpenAI.\"},\n",
       "   {'id': 'c6b672104721',\n",
       "    'title': 'GPT Actions: How to Create Advanced Automation in Your GPTs',\n",
       "    'subtitle': 'Customize your GPT further by connecting it to thousands of apps.',\n",
       "    'author': 'fb44e21903f3',\n",
       "    'publication_id': '76436a11a2b0',\n",
       "    'published_at': '2023-12-06 15:43:28',\n",
       "    'last_modified_at': '2023-12-06 15:43:28',\n",
       "    'tags': ['chatgpt',\n",
       "     'artificial-intelligence',\n",
       "     'technology',\n",
       "     'science',\n",
       "     'python'],\n",
       "    'topics': ['programming'],\n",
       "    'claps': 863,\n",
       "    'voters': 159,\n",
       "    'word_count': 1018,\n",
       "    'responses_count': 6,\n",
       "    'reading_time': 5.341509433962264,\n",
       "    'url': 'https://medium.com/artificial-corner/gpt-actions-how-to-create-advanced-automation-in-your-gpts-c6b672104721',\n",
       "    'unique_slug': 'gpt-actions-how-to-create-advanced-automation-in-your-gpts-c6b672104721',\n",
       "    'image_url': 'https://miro.medium.com/1*L-BjgiP_1w-PlnsfCmV1HA.png',\n",
       "    'lang': 'en',\n",
       "    'is_series': False,\n",
       "    'is_locked': True,\n",
       "    'is_shortform': False,\n",
       "    'top_highlight': ''}]}}"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_writers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the amount of distinct followers across all writers\n",
    "common_followers = set()\n",
    "for writer in test_writers.keys():\n",
    "\tfollows = test_writers[writer]['followers']\n",
    "\tcommon_followers.update(follows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4991"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(common_followers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dictionary of followers with values being the writers that\n",
    "# the user follows\n",
    "followers_dict = dict()\n",
    "for writer in test_writers.keys():\n",
    "\tfor follower in test_writers[writer]['followers']:\n",
    "\t\tif follower in followers_dict.keys():\n",
    "\t\t\tfollowers_dict[follower].append(writer)\n",
    "\t\telse:\n",
    "\t\t\tfollowers_dict[follower] = [writer]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'0037690620ed': ['fca9db1c7da0'],\n",
       " '01545acdd5dc': ['fca9db1c7da0'],\n",
       " '02533e82cf32': ['fca9db1c7da0', '9b351e8113e9', '37a2cbe8bd15'],\n",
       " '037cf47840d3': ['fca9db1c7da0',\n",
       "  '8a910484fe84',\n",
       "  '630ab5ffdf27',\n",
       "  'b0fbe613be9d',\n",
       "  '14176fcb5743',\n",
       "  '9b351e8113e9',\n",
       "  '5d33decdf4c4',\n",
       "  '8c8e5b7182ef',\n",
       "  '37a2cbe8bd15',\n",
       "  '15a29a4fc6ad',\n",
       "  'fb44e21903f3'],\n",
       " '049a24575f76': ['fca9db1c7da0', '15a29a4fc6ad'],\n",
       " '0563ca85f1ce': ['fca9db1c7da0'],\n",
       " '05c249a233a3': ['fca9db1c7da0'],\n",
       " '068120eb5c86': ['fca9db1c7da0', '4beacba7dc8a'],\n",
       " '06f27e3e4b56': ['fca9db1c7da0', '4beacba7dc8a'],\n",
       " '072e8a5bae3f': ['fca9db1c7da0',\n",
       "  '76398be9016',\n",
       "  'd80580992695',\n",
       "  '8a910484fe84',\n",
       "  'b856005e5ecd',\n",
       "  '15a29a4fc6ad',\n",
       "  'fb44e21903f3'],\n",
       " '07776a6be87b': ['fca9db1c7da0'],\n",
       " '07e34a659436': ['fca9db1c7da0', '4beacba7dc8a'],\n",
       " '07e34f7c7d05': ['fca9db1c7da0'],\n",
       " '0898d770aaec': ['fca9db1c7da0'],\n",
       " '0ba16e169f1b': ['fca9db1c7da0', '630ab5ffdf27'],\n",
       " '0be7589e82af': ['fca9db1c7da0',\n",
       "  'd80580992695',\n",
       "  'b856005e5ecd',\n",
       "  '5d33decdf4c4',\n",
       "  '15a29a4fc6ad'],\n",
       " '0dc84e997489': ['fca9db1c7da0'],\n",
       " '0e4e43c296c3': ['fca9db1c7da0'],\n",
       " '0e6b445bc2e9': ['fca9db1c7da0'],\n",
       " '0fc25c6ddce0': ['fca9db1c7da0'],\n",
       " '100130cb5f3a': ['fca9db1c7da0',\n",
       "  '8a910484fe84',\n",
       "  '630ab5ffdf27',\n",
       "  'b0fbe613be9d'],\n",
       " '1003f78bff66': ['fca9db1c7da0', '630ab5ffdf27'],\n",
       " '103571b2301': ['fca9db1c7da0'],\n",
       " '104e6f2dee35': ['fca9db1c7da0'],\n",
       " '107eab148cd8': ['fca9db1c7da0'],\n",
       " '10809e49a0f7': ['fca9db1c7da0'],\n",
       " '1087988dcd14': ['fca9db1c7da0', '15a29a4fc6ad'],\n",
       " '109ddee8ed19': ['fca9db1c7da0', 'e10ad955760c'],\n",
       " '10ae5a4cc69c': ['fca9db1c7da0', 'b0fbe613be9d'],\n",
       " '10c1fb4676a1': ['fca9db1c7da0'],\n",
       " '10eb1b294a6': ['fca9db1c7da0'],\n",
       " '1111526cc8d9': ['fca9db1c7da0'],\n",
       " '114ee25a8885': ['fca9db1c7da0'],\n",
       " '1150d1a23b0b': ['fca9db1c7da0'],\n",
       " '117b87d0509': ['fca9db1c7da0'],\n",
       " '118f611b37fc': ['fca9db1c7da0'],\n",
       " '11a205eeb0d3': ['fca9db1c7da0', '76398be9016'],\n",
       " '11b11f39b8fb': ['fca9db1c7da0', '4beacba7dc8a'],\n",
       " '11b1cbb9ab3d': ['fca9db1c7da0'],\n",
       " '11dfa21b9e31': ['fca9db1c7da0'],\n",
       " '11f50604c552': ['fca9db1c7da0'],\n",
       " '120b07b1f1f0': ['fca9db1c7da0'],\n",
       " '124060e7a368': ['fca9db1c7da0'],\n",
       " '1256da67d66': ['fca9db1c7da0',\n",
       "  'e10ad955760c',\n",
       "  '76398be9016',\n",
       "  '5d33decdf4c4',\n",
       "  '15a29a4fc6ad'],\n",
       " '125b209df9f5': ['fca9db1c7da0'],\n",
       " '127fb4d5f1ab': ['fca9db1c7da0'],\n",
       " '12930cbf4f5a': ['fca9db1c7da0', '4beacba7dc8a'],\n",
       " '12935397bcf1': ['fca9db1c7da0', '8a910484fe84', '4beacba7dc8a'],\n",
       " '129d238e441e': ['fca9db1c7da0', '15a29a4fc6ad'],\n",
       " '12c56d867282': ['fca9db1c7da0'],\n",
       " '12d49d6fc8ee': ['fca9db1c7da0'],\n",
       " '12d6a2ec97b': ['fca9db1c7da0', '15a29a4fc6ad'],\n",
       " '12d864e71039': ['fca9db1c7da0'],\n",
       " '131667fa818f': ['fca9db1c7da0', '5d33decdf4c4'],\n",
       " '133715b59c87': ['fca9db1c7da0'],\n",
       " '1342b6fa9bb0': ['fca9db1c7da0'],\n",
       " '136f00a1f051': ['fca9db1c7da0'],\n",
       " '13892a868dbe': ['fca9db1c7da0'],\n",
       " '139fbc5cfbf7': ['fca9db1c7da0'],\n",
       " '13a4b7fe75a2': ['fca9db1c7da0'],\n",
       " '13a6702a9106': ['fca9db1c7da0'],\n",
       " '13d29f45618b': ['fca9db1c7da0'],\n",
       " '13e1ae0324de': ['fca9db1c7da0'],\n",
       " '146800b81a98': ['fca9db1c7da0'],\n",
       " '1472fefa2726': ['fca9db1c7da0', '15a29a4fc6ad'],\n",
       " '14838626365d': ['fca9db1c7da0'],\n",
       " '148858854d0': ['fca9db1c7da0'],\n",
       " '148ae689f366': ['fca9db1c7da0',\n",
       "  'e10ad955760c',\n",
       "  '76398be9016',\n",
       "  '4beacba7dc8a',\n",
       "  '15a29a4fc6ad'],\n",
       " '14a98065ff0c': ['fca9db1c7da0'],\n",
       " '14d86166ad6f': ['fca9db1c7da0'],\n",
       " '14f32acf3397': ['fca9db1c7da0', '4beacba7dc8a'],\n",
       " '14f8f5fdd30a': ['fca9db1c7da0', '4beacba7dc8a'],\n",
       " '1503d896d5c1': ['fca9db1c7da0', '15a29a4fc6ad'],\n",
       " '152e2571f73a': ['fca9db1c7da0'],\n",
       " '1568d8ee7a9c': ['fca9db1c7da0', '76398be9016'],\n",
       " '158d53902311': ['fca9db1c7da0'],\n",
       " '158f61e51274': ['fca9db1c7da0'],\n",
       " '15b09c0562f5': ['fca9db1c7da0'],\n",
       " '15b154ae2cb5': ['fca9db1c7da0'],\n",
       " '15fa374f76be': ['fca9db1c7da0'],\n",
       " '160206a233f3': ['fca9db1c7da0'],\n",
       " '160a3611ba78': ['fca9db1c7da0'],\n",
       " '16262d07c8aa': ['fca9db1c7da0'],\n",
       " '167fdfa41b1b': ['fca9db1c7da0'],\n",
       " '1691bc75f4fc': ['fca9db1c7da0'],\n",
       " '169f538dfde3': ['fca9db1c7da0', '4beacba7dc8a'],\n",
       " '16a020cbbac3': ['fca9db1c7da0'],\n",
       " '16ed9209e469': ['fca9db1c7da0'],\n",
       " '1702b0484189': ['fca9db1c7da0'],\n",
       " '17135ea3595b': ['fca9db1c7da0'],\n",
       " '171a8da6d4d2': ['fca9db1c7da0'],\n",
       " '171cf339abc2': ['fca9db1c7da0'],\n",
       " '17787488936a': ['fca9db1c7da0'],\n",
       " '178c2dfb46d6': ['fca9db1c7da0'],\n",
       " '17a2958eebfd': ['fca9db1c7da0'],\n",
       " '17a5424ab02': ['fca9db1c7da0'],\n",
       " '17ad088d7611': ['fca9db1c7da0', '4beacba7dc8a'],\n",
       " '17c9b888001c': ['fca9db1c7da0', 'e10ad955760c', '8a910484fe84'],\n",
       " '17cf7e8c9fa3': ['fca9db1c7da0'],\n",
       " '17de20885fbe': ['fca9db1c7da0', '4beacba7dc8a'],\n",
       " '18b5fd193c7d': ['fca9db1c7da0', '8a910484fe84', '4beacba7dc8a'],\n",
       " '18cd1cb8c387': ['fca9db1c7da0'],\n",
       " '18cf1c56822f': ['fca9db1c7da0'],\n",
       " '18f2a4792ef9': ['fca9db1c7da0'],\n",
       " '190879219c69': ['fca9db1c7da0'],\n",
       " '19255e7b9fca': ['fca9db1c7da0'],\n",
       " '192b451c44f': ['fca9db1c7da0'],\n",
       " '1946dacfd581': ['fca9db1c7da0'],\n",
       " '196cc1a76416': ['fca9db1c7da0'],\n",
       " '197e8422e0fc': ['fca9db1c7da0', '4beacba7dc8a'],\n",
       " '198a0ec09f66': ['fca9db1c7da0'],\n",
       " '19b91c977f65': ['fca9db1c7da0'],\n",
       " '19cad4233712': ['fca9db1c7da0', 'e10ad955760c', '4beacba7dc8a'],\n",
       " '19dd0c8d4ef2': ['fca9db1c7da0', '4beacba7dc8a'],\n",
       " '19e594cea92b': ['fca9db1c7da0'],\n",
       " '1a0960a5e5d8': ['fca9db1c7da0', '4beacba7dc8a'],\n",
       " '1a2b4a164606': ['fca9db1c7da0'],\n",
       " '1a37e73e13fa': ['fca9db1c7da0'],\n",
       " '1a45027479b1': ['fca9db1c7da0',\n",
       "  'e10ad955760c',\n",
       "  '8a910484fe84',\n",
       "  '4beacba7dc8a'],\n",
       " '1a52a163e688': ['fca9db1c7da0'],\n",
       " '1a795dd733ff': ['fca9db1c7da0'],\n",
       " '1a8d9a7a1154': ['fca9db1c7da0'],\n",
       " '1aac0378d08': ['fca9db1c7da0'],\n",
       " '1ad971c986a3': ['fca9db1c7da0'],\n",
       " '1b025a36076d': ['fca9db1c7da0'],\n",
       " '1b143d93cae3': ['fca9db1c7da0'],\n",
       " '1b17cba977ce': ['fca9db1c7da0'],\n",
       " '1b33a6992e38': ['fca9db1c7da0'],\n",
       " '1b3581d77e59': ['fca9db1c7da0'],\n",
       " '1b5776dcec20': ['fca9db1c7da0'],\n",
       " '1b62bbd4b8fa': ['fca9db1c7da0'],\n",
       " '1b66a948a46b': ['fca9db1c7da0'],\n",
       " '1b7726fe6e23': ['fca9db1c7da0'],\n",
       " '1b8c1ccb940': ['fca9db1c7da0'],\n",
       " '1b95f0abfc7': ['fca9db1c7da0'],\n",
       " '1baa04e6c10f': ['fca9db1c7da0'],\n",
       " '1bab0eebf8ad': ['fca9db1c7da0'],\n",
       " '1bf3eeb4c176': ['fca9db1c7da0'],\n",
       " '1c21c9489490': ['fca9db1c7da0'],\n",
       " '1c2de135b506': ['fca9db1c7da0'],\n",
       " '1c31311b814a': ['fca9db1c7da0'],\n",
       " '1c38d2ae2cab': ['fca9db1c7da0'],\n",
       " '1c4c52460647': ['fca9db1c7da0'],\n",
       " '1c7f1b2ec141': ['fca9db1c7da0'],\n",
       " '1c80cc183550': ['fca9db1c7da0', '4beacba7dc8a'],\n",
       " '1c8c2c95b65c': ['fca9db1c7da0'],\n",
       " '1d45745cf04d': ['fca9db1c7da0', '8a910484fe84'],\n",
       " '1d61a22bf84d': ['fca9db1c7da0'],\n",
       " '1d61b6484f68': ['fca9db1c7da0'],\n",
       " '1d86cc7c988f': ['fca9db1c7da0'],\n",
       " '1d8c997e56f': ['fca9db1c7da0'],\n",
       " '1df725bf1e10': ['fca9db1c7da0'],\n",
       " '1e21b01857b7': ['fca9db1c7da0'],\n",
       " '1e5d59c39633': ['fca9db1c7da0'],\n",
       " '1e5e1d6f9246': ['fca9db1c7da0'],\n",
       " '1e9c63609dd8': ['fca9db1c7da0'],\n",
       " '1ea5b0068b9e': ['fca9db1c7da0'],\n",
       " '1eb044daad32': ['fca9db1c7da0'],\n",
       " '1ec0ef32ba5e': ['fca9db1c7da0'],\n",
       " '1f0bdba77b61': ['fca9db1c7da0'],\n",
       " '1f12cc676340': ['fca9db1c7da0', '8a910484fe84'],\n",
       " '1f1f2fe2d8e': ['fca9db1c7da0'],\n",
       " '1f2002b4afd5': ['fca9db1c7da0'],\n",
       " '1f30e2517d7d': ['fca9db1c7da0'],\n",
       " '1f38862a373a': ['fca9db1c7da0'],\n",
       " '1f49a76b5dbf': ['fca9db1c7da0'],\n",
       " '1f6a2872d3ba': ['fca9db1c7da0'],\n",
       " '1f806cbd06a3': ['fca9db1c7da0'],\n",
       " '1f80c20e1605': ['fca9db1c7da0'],\n",
       " '1f992c278206': ['fca9db1c7da0'],\n",
       " '1fbad54a1a4c': ['fca9db1c7da0'],\n",
       " '1fcbe0e72': ['fca9db1c7da0'],\n",
       " '1fdad61879a': ['fca9db1c7da0'],\n",
       " '1ff84ce5d71e': ['fca9db1c7da0'],\n",
       " '20056822c5e9': ['fca9db1c7da0'],\n",
       " '201f51730529': ['fca9db1c7da0'],\n",
       " '2038a4578a09': ['fca9db1c7da0'],\n",
       " '207988005f34': ['fca9db1c7da0'],\n",
       " '20c7c7250e7d': ['fca9db1c7da0'],\n",
       " '20d6e3bd4448': ['fca9db1c7da0', '8a910484fe84'],\n",
       " '20dee3a5f3f7': ['fca9db1c7da0', '4beacba7dc8a'],\n",
       " '20fde2e682fe': ['fca9db1c7da0', '4beacba7dc8a'],\n",
       " '21110cd779c1': ['fca9db1c7da0'],\n",
       " '211e57773b60': ['fca9db1c7da0'],\n",
       " '2147d2141871': ['fca9db1c7da0'],\n",
       " '215a921e117e': ['fca9db1c7da0'],\n",
       " '216f4a9f397d': ['fca9db1c7da0'],\n",
       " '21d7e3ed77b9': ['fca9db1c7da0'],\n",
       " '21db5ec686ec': ['fca9db1c7da0'],\n",
       " '21f9aef0706d': ['fca9db1c7da0'],\n",
       " '221953517d77': ['fca9db1c7da0'],\n",
       " '2223f1eeeb6b': ['fca9db1c7da0'],\n",
       " '2227b9abe4b3': ['fca9db1c7da0'],\n",
       " '222a54770ce4': ['fca9db1c7da0'],\n",
       " '22336e9a638d': ['fca9db1c7da0'],\n",
       " '22a1bd45b190': ['fca9db1c7da0'],\n",
       " '22a1eee94b17': ['fca9db1c7da0'],\n",
       " '22f809b0f6e': ['fca9db1c7da0'],\n",
       " '232cc30fcdd4': ['fca9db1c7da0'],\n",
       " '232dafee93a7': ['fca9db1c7da0'],\n",
       " '2345c09bd515': ['fca9db1c7da0'],\n",
       " '235a8e13f0aa': ['fca9db1c7da0'],\n",
       " '238ff338127f': ['fca9db1c7da0', '8a910484fe84', '4beacba7dc8a'],\n",
       " '23cb27b3d676': ['fca9db1c7da0'],\n",
       " '23d591f8c62b': ['fca9db1c7da0'],\n",
       " '23e230a7bb62': ['fca9db1c7da0'],\n",
       " '23ed4c1c194c': ['fca9db1c7da0'],\n",
       " '240e5ff0bdac': ['fca9db1c7da0'],\n",
       " '241431e40959': ['fca9db1c7da0'],\n",
       " '2421dae9756': ['fca9db1c7da0', '4beacba7dc8a'],\n",
       " '242546687286': ['fca9db1c7da0'],\n",
       " '245f97293f28': ['fca9db1c7da0', '8a910484fe84', '4beacba7dc8a'],\n",
       " '2462c40cc0fc': ['fca9db1c7da0'],\n",
       " '24739a967b10': ['fca9db1c7da0'],\n",
       " '24a30481245b': ['fca9db1c7da0'],\n",
       " '24bf3cb876e': ['fca9db1c7da0'],\n",
       " '250cd24cecf6': ['fca9db1c7da0'],\n",
       " '254e653181d2': ['fca9db1c7da0'],\n",
       " '2552d67b635a': ['fca9db1c7da0'],\n",
       " '2574477c96c5': ['fca9db1c7da0', '4beacba7dc8a'],\n",
       " '2595a8e1f019': ['fca9db1c7da0'],\n",
       " '25969546056': ['fca9db1c7da0'],\n",
       " '259e270544a1': ['fca9db1c7da0'],\n",
       " '25b72c578216': ['fca9db1c7da0'],\n",
       " '260d3636c103': ['fca9db1c7da0'],\n",
       " '2620a9fe68a6': ['fca9db1c7da0'],\n",
       " '263e67b31f76': ['fca9db1c7da0'],\n",
       " '26541584aaf3': ['fca9db1c7da0'],\n",
       " '26713aebf55c': ['fca9db1c7da0'],\n",
       " '26a6c3a2b11f': ['fca9db1c7da0'],\n",
       " '26b873a96c43': ['fca9db1c7da0'],\n",
       " '26d875208aed': ['fca9db1c7da0'],\n",
       " '274124d7b5ea': ['fca9db1c7da0'],\n",
       " '275d1c3753b1': ['fca9db1c7da0'],\n",
       " '27a640854747': ['fca9db1c7da0', '4beacba7dc8a'],\n",
       " '27a676387455': ['fca9db1c7da0'],\n",
       " '27ac89d76183': ['fca9db1c7da0'],\n",
       " '27aee7ba01e3': ['fca9db1c7da0'],\n",
       " '27b16783c35c': ['fca9db1c7da0'],\n",
       " '27e82070ebf5': ['fca9db1c7da0'],\n",
       " '27ed17c95fc5': ['fca9db1c7da0'],\n",
       " '27ffaffe620b': ['fca9db1c7da0'],\n",
       " '28195d56dc07': ['fca9db1c7da0'],\n",
       " '282b4abd098c': ['fca9db1c7da0'],\n",
       " '283b9d3bdb9d': ['fca9db1c7da0'],\n",
       " '28472f176d5': ['fca9db1c7da0'],\n",
       " '2851eb8b7dc0': ['fca9db1c7da0'],\n",
       " '2860529375ec': ['fca9db1c7da0'],\n",
       " '286f17319b8e': ['fca9db1c7da0'],\n",
       " '28addfa604a2': ['fca9db1c7da0'],\n",
       " '28ce6a616ea9': ['fca9db1c7da0'],\n",
       " '28d17c8eb2dc': ['fca9db1c7da0'],\n",
       " '28e67395edbd': ['fca9db1c7da0'],\n",
       " '2916cb3fd236': ['fca9db1c7da0', '4beacba7dc8a'],\n",
       " '294aebc97b51': ['fca9db1c7da0'],\n",
       " '296748b0175': ['fca9db1c7da0'],\n",
       " '297e51245852': ['fca9db1c7da0'],\n",
       " '29924788dea8': ['fca9db1c7da0', '8a910484fe84', '4beacba7dc8a'],\n",
       " '299a399693a7': ['fca9db1c7da0', '4beacba7dc8a'],\n",
       " '29bce29af83f': ['fca9db1c7da0'],\n",
       " '29caff485c5': ['fca9db1c7da0'],\n",
       " '29f459525caa': ['fca9db1c7da0'],\n",
       " '2a02e436f9b3': ['fca9db1c7da0'],\n",
       " '2a6a5aa51240': ['fca9db1c7da0', '4beacba7dc8a'],\n",
       " '2a8736afd5e6': ['fca9db1c7da0'],\n",
       " '2a94df6eb624': ['fca9db1c7da0'],\n",
       " '2ab4498735cb': ['fca9db1c7da0'],\n",
       " '2ab9f98db92d': ['fca9db1c7da0'],\n",
       " '2b25f8105a4a': ['fca9db1c7da0'],\n",
       " '2b2a855a4b9c': ['fca9db1c7da0'],\n",
       " '2b82e19db3be': ['fca9db1c7da0', '4beacba7dc8a'],\n",
       " '2b8a3d6203ce': ['fca9db1c7da0'],\n",
       " '2bd41a7eb4b9': ['fca9db1c7da0'],\n",
       " '2be3f6dbd3d3': ['fca9db1c7da0'],\n",
       " '2bee5569e17b': ['fca9db1c7da0'],\n",
       " '2bf6f536f700': ['fca9db1c7da0'],\n",
       " '2c0961f12de7': ['fca9db1c7da0', '4beacba7dc8a'],\n",
       " '2c193c2c51d1': ['fca9db1c7da0'],\n",
       " '2c3ed7d9a734': ['fca9db1c7da0', '4beacba7dc8a'],\n",
       " '2c5dcda349ee': ['fca9db1c7da0'],\n",
       " '2c5e5df36874': ['fca9db1c7da0'],\n",
       " '2c6c716b2ec3': ['fca9db1c7da0'],\n",
       " '2c6ff54608e5': ['fca9db1c7da0'],\n",
       " '2c78890cb2e9': ['fca9db1c7da0'],\n",
       " '2c8c7efbe7af': ['fca9db1c7da0'],\n",
       " '2ced48fdc5f1': ['fca9db1c7da0'],\n",
       " '2d23c4ccfadc': ['fca9db1c7da0'],\n",
       " '2d36a6f5a4dc': ['fca9db1c7da0'],\n",
       " '2d4ea74beed4': ['fca9db1c7da0'],\n",
       " '2d736468ba7a': ['fca9db1c7da0'],\n",
       " '2d7c383b0d6c': ['fca9db1c7da0'],\n",
       " '2d8396ccfa7f': ['fca9db1c7da0'],\n",
       " '2d93b58a0f8a': ['fca9db1c7da0'],\n",
       " '2dac3478a8f9': ['fca9db1c7da0'],\n",
       " '2db491df47db': ['fca9db1c7da0'],\n",
       " '2dd95a8da342': ['fca9db1c7da0'],\n",
       " '2deeb387b27c': ['fca9db1c7da0'],\n",
       " '2df2ad7c8ded': ['fca9db1c7da0'],\n",
       " '2e36d844f63e': ['fca9db1c7da0'],\n",
       " '2e487ebbd7c3': ['fca9db1c7da0'],\n",
       " '2e6c787baa97': ['fca9db1c7da0'],\n",
       " '2e909231046': ['fca9db1c7da0'],\n",
       " '2e98d2b47491': ['fca9db1c7da0'],\n",
       " '2eb6ed025385': ['fca9db1c7da0'],\n",
       " '2ef5137cfb52': ['fca9db1c7da0'],\n",
       " '2f45238d380a': ['fca9db1c7da0'],\n",
       " '2f53ccfa3e70': ['fca9db1c7da0'],\n",
       " '2f6e0afd9b17': ['fca9db1c7da0', '4beacba7dc8a'],\n",
       " '2f721b484b71': ['fca9db1c7da0'],\n",
       " '2f974295d555': ['fca9db1c7da0'],\n",
       " '2fb7d7a5d437': ['fca9db1c7da0'],\n",
       " '2fb9bbb8395e': ['fca9db1c7da0'],\n",
       " '2fc7128b61b9': ['fca9db1c7da0'],\n",
       " '2fd662cff65': ['fca9db1c7da0'],\n",
       " '2ff751b6b28': ['fca9db1c7da0'],\n",
       " '300932814274': ['fca9db1c7da0'],\n",
       " '300af2335ef0': ['fca9db1c7da0'],\n",
       " '300b3068b9cb': ['fca9db1c7da0'],\n",
       " '306033f095fc': ['fca9db1c7da0'],\n",
       " '30618acc174f': ['fca9db1c7da0'],\n",
       " '3065e94428b1': ['fca9db1c7da0'],\n",
       " '307cf3fed8f3': ['fca9db1c7da0'],\n",
       " '309411915414': ['fca9db1c7da0'],\n",
       " '30c6bb8d8b33': ['fca9db1c7da0'],\n",
       " '30d9ebb5d14e': ['fca9db1c7da0'],\n",
       " '30e8701d3b7': ['fca9db1c7da0'],\n",
       " '30fea69a5379': ['fca9db1c7da0'],\n",
       " '311ef44807a0': ['fca9db1c7da0', '4beacba7dc8a'],\n",
       " '312ddc2f5661': ['fca9db1c7da0'],\n",
       " '31392b352019': ['fca9db1c7da0'],\n",
       " '314bad222d98': ['fca9db1c7da0'],\n",
       " '317d2c36c3c2': ['fca9db1c7da0'],\n",
       " '3188c8c51a1f': ['fca9db1c7da0'],\n",
       " '31a22280e522': ['fca9db1c7da0'],\n",
       " '31c90dbaa414': ['fca9db1c7da0'],\n",
       " '31ccf6b63c65': ['fca9db1c7da0'],\n",
       " '31e6df7c31c4': ['fca9db1c7da0', '4beacba7dc8a'],\n",
       " '31ee22931ebc': ['fca9db1c7da0'],\n",
       " '31f0b60f589d': ['fca9db1c7da0'],\n",
       " '3210cdfd89bb': ['fca9db1c7da0'],\n",
       " '3230c8577683': ['fca9db1c7da0'],\n",
       " '327fba308cb4': ['fca9db1c7da0', '4beacba7dc8a'],\n",
       " '32bcdad9a02e': ['fca9db1c7da0'],\n",
       " '32c9a5daf94': ['fca9db1c7da0', '4beacba7dc8a'],\n",
       " '32d828f85104': ['fca9db1c7da0'],\n",
       " '3341760cfecc': ['fca9db1c7da0'],\n",
       " '336d298be9f9': ['fca9db1c7da0'],\n",
       " '339d7693bd23': ['fca9db1c7da0'],\n",
       " '33ae616e4a2e': ['fca9db1c7da0'],\n",
       " '340173c1cae3': ['fca9db1c7da0'],\n",
       " '340da48444ef': ['fca9db1c7da0'],\n",
       " '34110f02021a': ['fca9db1c7da0'],\n",
       " '342a310f3603': ['fca9db1c7da0'],\n",
       " '3446bd7a71a5': ['fca9db1c7da0', '4beacba7dc8a'],\n",
       " '34536064487c': ['fca9db1c7da0', '4beacba7dc8a'],\n",
       " '3454f558c8b2': ['fca9db1c7da0'],\n",
       " '34712f78e59': ['fca9db1c7da0'],\n",
       " '34bc0bc70527': ['fca9db1c7da0'],\n",
       " '34dbcc04c55': ['fca9db1c7da0'],\n",
       " '34ef93e174ca': ['fca9db1c7da0'],\n",
       " '352367b2bcd9': ['fca9db1c7da0'],\n",
       " '3526b8a1aba6': ['fca9db1c7da0'],\n",
       " '3531b65ca266': ['fca9db1c7da0'],\n",
       " '353ff8c26606': ['fca9db1c7da0'],\n",
       " '355ab04cdc6f': ['fca9db1c7da0'],\n",
       " '35667da67e95': ['fca9db1c7da0'],\n",
       " '3568102908d8': ['fca9db1c7da0'],\n",
       " '3584ae2be8ef': ['fca9db1c7da0'],\n",
       " '35ae5a8b0332': ['fca9db1c7da0'],\n",
       " '35cdff80635a': ['fca9db1c7da0'],\n",
       " '35dadf373281': ['fca9db1c7da0'],\n",
       " '35e5c85cdc03': ['fca9db1c7da0'],\n",
       " '35ffcc9a155c': ['fca9db1c7da0'],\n",
       " '36382e46bd27': ['fca9db1c7da0'],\n",
       " '364813830cb5': ['fca9db1c7da0'],\n",
       " '366799ba6166': ['fca9db1c7da0'],\n",
       " '3691db96637a': ['fca9db1c7da0'],\n",
       " '36986ee89fda': ['fca9db1c7da0'],\n",
       " '36b8d5ca089b': ['fca9db1c7da0'],\n",
       " '36d01147dfd6': ['fca9db1c7da0'],\n",
       " '371cc54053d5': ['fca9db1c7da0'],\n",
       " '375810cbf7d1': ['fca9db1c7da0'],\n",
       " '3758607015c5': ['fca9db1c7da0'],\n",
       " '37fb6215fe2c': ['fca9db1c7da0'],\n",
       " '384235bf4a78': ['fca9db1c7da0'],\n",
       " '3867bd959df2': ['fca9db1c7da0'],\n",
       " '3888ba015d84': ['fca9db1c7da0'],\n",
       " '3891c05f2401': ['fca9db1c7da0'],\n",
       " '389c460042dc': ['fca9db1c7da0'],\n",
       " '38a45bc85ba3': ['fca9db1c7da0'],\n",
       " '38a73e03a2bd': ['fca9db1c7da0'],\n",
       " '39012ebeb6da': ['fca9db1c7da0'],\n",
       " '3911a2da7f7e': ['fca9db1c7da0'],\n",
       " '39425e737d54': ['fca9db1c7da0'],\n",
       " '3958ce7b0a09': ['fca9db1c7da0'],\n",
       " '39877fc04ab5': ['fca9db1c7da0'],\n",
       " '39ba49470d23': ['fca9db1c7da0'],\n",
       " '39df77437b5b': ['fca9db1c7da0'],\n",
       " '3a068833f0fd': ['fca9db1c7da0'],\n",
       " '3a1cb0d15387': ['fca9db1c7da0'],\n",
       " '3a21b0b6405': ['fca9db1c7da0'],\n",
       " '3a924a04bfba': ['fca9db1c7da0'],\n",
       " '3a9b7cd8496': ['fca9db1c7da0'],\n",
       " '3abb5812d43': ['fca9db1c7da0'],\n",
       " '3acbcc8f28e1': ['fca9db1c7da0'],\n",
       " '3aeb7384083a': ['fca9db1c7da0'],\n",
       " '3af7ecdedae0': ['fca9db1c7da0'],\n",
       " '3b0dc9811625': ['fca9db1c7da0'],\n",
       " '3b28c383478e': ['fca9db1c7da0'],\n",
       " '3b4256bd37e6': ['fca9db1c7da0'],\n",
       " '3b487b2e2c93': ['fca9db1c7da0'],\n",
       " '3ba706b3ee54': ['fca9db1c7da0'],\n",
       " '3bab7d566179': ['fca9db1c7da0'],\n",
       " '3c0070fe8a54': ['fca9db1c7da0'],\n",
       " '3c92223562e1': ['fca9db1c7da0'],\n",
       " '3c97e67e041d': ['fca9db1c7da0'],\n",
       " '3cb440764fc4': ['fca9db1c7da0'],\n",
       " '3cdb183ec4dd': ['fca9db1c7da0'],\n",
       " '3ce4a2ed76cc': ['fca9db1c7da0'],\n",
       " '3ce611a70687': ['fca9db1c7da0'],\n",
       " '3ced08c4ede3': ['fca9db1c7da0'],\n",
       " '3cf698f9e01c': ['fca9db1c7da0'],\n",
       " '3cfa1c83a95f': ['fca9db1c7da0'],\n",
       " '3d1c8db21fb0': ['fca9db1c7da0'],\n",
       " '3d2d6f48d179': ['fca9db1c7da0'],\n",
       " '3d2db6a2946b': ['fca9db1c7da0'],\n",
       " '3d3ccfe5cc64': ['fca9db1c7da0'],\n",
       " '3d4c5d91eeec': ['fca9db1c7da0'],\n",
       " '3d57921f2742': ['fca9db1c7da0'],\n",
       " '3d8dbeb9314d': ['fca9db1c7da0'],\n",
       " '3d8debdc3363': ['fca9db1c7da0'],\n",
       " '3d977f4ac15d': ['fca9db1c7da0'],\n",
       " '3da8a61ca6cb': ['fca9db1c7da0'],\n",
       " '3e15660c4ff4': ['fca9db1c7da0'],\n",
       " '3e3a830c73c5': ['fca9db1c7da0'],\n",
       " '3e601e922108': ['fca9db1c7da0'],\n",
       " '3e6a4844f16d': ['fca9db1c7da0'],\n",
       " '3e78a66bf655': ['fca9db1c7da0'],\n",
       " '3eb3947a724e': ['fca9db1c7da0'],\n",
       " '3ee7a93a472b': ['fca9db1c7da0'],\n",
       " '3f026fd617e6': ['fca9db1c7da0'],\n",
       " '3f049b1bc69c': ['fca9db1c7da0'],\n",
       " '3f55d7d7a3e7': ['fca9db1c7da0'],\n",
       " '3f6a1df33fab': ['fca9db1c7da0'],\n",
       " '3f6e94323f54': ['fca9db1c7da0'],\n",
       " '3f75236f0633': ['fca9db1c7da0'],\n",
       " '3fd893534d6b': ['fca9db1c7da0'],\n",
       " '3fe660c24e52': ['fca9db1c7da0'],\n",
       " '3ffb2d20574b': ['fca9db1c7da0'],\n",
       " '40098a41cd9f': ['fca9db1c7da0'],\n",
       " '4011848f12e9': ['fca9db1c7da0'],\n",
       " '405196932e0f': ['fca9db1c7da0'],\n",
       " '40676f3c5d7c': ['fca9db1c7da0'],\n",
       " '406a12c95a7e': ['fca9db1c7da0'],\n",
       " '407124b7da5b': ['fca9db1c7da0'],\n",
       " '40b7b5b6d321': ['fca9db1c7da0'],\n",
       " '40c8a23b90d5': ['fca9db1c7da0'],\n",
       " '40db095ecc2c': ['fca9db1c7da0'],\n",
       " '40f92e632e65': ['fca9db1c7da0'],\n",
       " '41264972aeef': ['fca9db1c7da0'],\n",
       " '413f41a58494': ['fca9db1c7da0'],\n",
       " '4155e4e99a67': ['fca9db1c7da0'],\n",
       " '417779fee024': ['fca9db1c7da0'],\n",
       " '41aff52b2f70': ['fca9db1c7da0'],\n",
       " '41befeaee0c7': ['fca9db1c7da0'],\n",
       " '41ce34b894f4': ['fca9db1c7da0'],\n",
       " '41e8a9e4637d': ['fca9db1c7da0'],\n",
       " '42079a49c8ec': ['fca9db1c7da0'],\n",
       " '4232a5f9e599': ['fca9db1c7da0'],\n",
       " '424084974977': ['fca9db1c7da0'],\n",
       " '4262bbc4b8a8': ['fca9db1c7da0'],\n",
       " '42697edb950f': ['fca9db1c7da0'],\n",
       " '426e2cacc658': ['fca9db1c7da0'],\n",
       " '4271399e5ae6': ['fca9db1c7da0'],\n",
       " '4288a53c86e0': ['fca9db1c7da0'],\n",
       " '42908a5658b5': ['fca9db1c7da0'],\n",
       " '42aeca1e18e5': ['fca9db1c7da0'],\n",
       " '42c72ed7472c': ['fca9db1c7da0'],\n",
       " '42cfbfcb8473': ['fca9db1c7da0'],\n",
       " '434998b874db': ['fca9db1c7da0'],\n",
       " '438997c02baf': ['fca9db1c7da0'],\n",
       " '43bc52d139e5': ['fca9db1c7da0'],\n",
       " '43ca83f33c10': ['fca9db1c7da0'],\n",
       " '43e36df2cffa': ['fca9db1c7da0'],\n",
       " '43fe3cbae1ca': ['fca9db1c7da0'],\n",
       " '441585203bff': ['fca9db1c7da0'],\n",
       " '444530f6f78e': ['fca9db1c7da0'],\n",
       " '447ba43dbd76': ['fca9db1c7da0'],\n",
       " '447c330e1b84': ['fca9db1c7da0'],\n",
       " '4489283c8ab1': ['fca9db1c7da0'],\n",
       " '44bffcff5d54': ['fca9db1c7da0'],\n",
       " '44c5e5fbd36d': ['fca9db1c7da0'],\n",
       " '44dc4c6cf3db': ['fca9db1c7da0'],\n",
       " '44ee7bb7b54f': ['fca9db1c7da0'],\n",
       " '450d641f20f8': ['fca9db1c7da0'],\n",
       " '4514ad7050a': ['fca9db1c7da0'],\n",
       " '45256b119fe1': ['fca9db1c7da0'],\n",
       " '00149b7421b2': ['e10ad955760c',\n",
       "  'd80580992695',\n",
       "  '630ab5ffdf27',\n",
       "  '14176fcb5743',\n",
       "  '9b351e8113e9',\n",
       "  '37a2cbe8bd15'],\n",
       " '00183ef79cce': ['e10ad955760c',\n",
       "  '630ab5ffdf27',\n",
       "  '9b351e8113e9',\n",
       "  '37a2cbe8bd15',\n",
       "  'fb44e21903f3'],\n",
       " '00418aadfc4b': ['e10ad955760c',\n",
       "  'd80580992695',\n",
       "  '630ab5ffdf27',\n",
       "  '37a2cbe8bd15'],\n",
       " '00555da4d13e': ['e10ad955760c',\n",
       "  'b856005e5ecd',\n",
       "  '37a2cbe8bd15',\n",
       "  'fb44e21903f3'],\n",
       " '005c18b43c6c': ['e10ad955760c',\n",
       "  'd80580992695',\n",
       "  '5d33decdf4c4',\n",
       "  'fb44e21903f3'],\n",
       " '009733c9ec1e': ['e10ad955760c',\n",
       "  '76398be9016',\n",
       "  'd80580992695',\n",
       "  '630ab5ffdf27',\n",
       "  '9b351e8113e9'],\n",
       " '00a78a6007f4': ['e10ad955760c',\n",
       "  'd80580992695',\n",
       "  '630ab5ffdf27',\n",
       "  '9b351e8113e9',\n",
       "  '37a2cbe8bd15',\n",
       "  'fb44e21903f3'],\n",
       " '00adf31ab408': ['e10ad955760c',\n",
       "  'd80580992695',\n",
       "  '630ab5ffdf27',\n",
       "  '37a2cbe8bd15'],\n",
       " '00b8eada8b79': ['e10ad955760c',\n",
       "  '76398be9016',\n",
       "  'd80580992695',\n",
       "  '4beacba7dc8a',\n",
       "  '630ab5ffdf27',\n",
       "  'b0fbe613be9d',\n",
       "  '14176fcb5743',\n",
       "  '5d33decdf4c4',\n",
       "  '8c8e5b7182ef',\n",
       "  'fb44e21903f3'],\n",
       " '00c31001fec0': ['e10ad955760c'],\n",
       " '00cb490f7bee': ['e10ad955760c'],\n",
       " '00f2d8152332': ['e10ad955760c',\n",
       "  '14176fcb5743',\n",
       "  '9b351e8113e9',\n",
       "  '37a2cbe8bd15'],\n",
       " '0109e784bcf3': ['e10ad955760c',\n",
       "  'd80580992695',\n",
       "  '630ab5ffdf27',\n",
       "  '14176fcb5743',\n",
       "  '37a2cbe8bd15'],\n",
       " '0143c3cfd773': ['e10ad955760c',\n",
       "  '76398be9016',\n",
       "  'd80580992695',\n",
       "  '630ab5ffdf27',\n",
       "  '9b351e8113e9',\n",
       "  '5d33decdf4c4',\n",
       "  '37a2cbe8bd15',\n",
       "  '15a29a4fc6ad'],\n",
       " '01a9c1259fcc': ['e10ad955760c',\n",
       "  '630ab5ffdf27',\n",
       "  '14176fcb5743',\n",
       "  '9b351e8113e9',\n",
       "  '37a2cbe8bd15',\n",
       "  '15a29a4fc6ad'],\n",
       " '01cf0debc091': ['e10ad955760c',\n",
       "  '76398be9016',\n",
       "  'd80580992695',\n",
       "  '630ab5ffdf27',\n",
       "  '9b351e8113e9',\n",
       "  '8c8e5b7182ef',\n",
       "  '37a2cbe8bd15',\n",
       "  '15a29a4fc6ad',\n",
       "  'fb44e21903f3'],\n",
       " '01e22e257aad': ['e10ad955760c',\n",
       "  'd80580992695',\n",
       "  '630ab5ffdf27',\n",
       "  '14176fcb5743',\n",
       "  '9b351e8113e9',\n",
       "  '37a2cbe8bd15'],\n",
       " '01eb5edb6a57': ['e10ad955760c',\n",
       "  '630ab5ffdf27',\n",
       "  '14176fcb5743',\n",
       "  '9b351e8113e9',\n",
       "  '37a2cbe8bd15',\n",
       "  '15a29a4fc6ad'],\n",
       " '01ec1a0c6bf3': ['e10ad955760c',\n",
       "  '630ab5ffdf27',\n",
       "  '14176fcb5743',\n",
       "  '9b351e8113e9',\n",
       "  '37a2cbe8bd15',\n",
       "  '15a29a4fc6ad'],\n",
       " '01faad01498c': ['e10ad955760c',\n",
       "  '630ab5ffdf27',\n",
       "  '14176fcb5743',\n",
       "  '9b351e8113e9',\n",
       "  '5d33decdf4c4',\n",
       "  '8c8e5b7182ef',\n",
       "  '37a2cbe8bd15',\n",
       "  'fb44e21903f3'],\n",
       " '0215bf12b71b': ['e10ad955760c', '37a2cbe8bd15'],\n",
       " '022a74088f12': ['e10ad955760c', '630ab5ffdf27'],\n",
       " '028b27877c10': ['e10ad955760c',\n",
       "  '76398be9016',\n",
       "  'd80580992695',\n",
       "  '630ab5ffdf27',\n",
       "  'b856005e5ecd',\n",
       "  'b0fbe613be9d',\n",
       "  '14176fcb5743',\n",
       "  '9b351e8113e9',\n",
       "  '5d33decdf4c4',\n",
       "  '37a2cbe8bd15',\n",
       "  '15a29a4fc6ad',\n",
       "  'fb44e21903f3'],\n",
       " '029482385112': ['e10ad955760c',\n",
       "  'd80580992695',\n",
       "  '4beacba7dc8a',\n",
       "  'b856005e5ecd',\n",
       "  'b0fbe613be9d',\n",
       "  '14176fcb5743',\n",
       "  '9b351e8113e9',\n",
       "  '5d33decdf4c4',\n",
       "  '8c8e5b7182ef',\n",
       "  '37a2cbe8bd15',\n",
       "  'fb44e21903f3'],\n",
       " '03133540481d': ['e10ad955760c',\n",
       "  '76398be9016',\n",
       "  'd80580992695',\n",
       "  '630ab5ffdf27',\n",
       "  '14176fcb5743',\n",
       "  '9b351e8113e9',\n",
       "  '5d33decdf4c4',\n",
       "  '37a2cbe8bd15',\n",
       "  'fb44e21903f3'],\n",
       " '0315db4cbe86': ['e10ad955760c', '14176fcb5743', '9b351e8113e9'],\n",
       " '032e23fb0d6c': ['e10ad955760c', '9b351e8113e9', '37a2cbe8bd15'],\n",
       " '0344c819f9fc': ['e10ad955760c',\n",
       "  '76398be9016',\n",
       "  'd80580992695',\n",
       "  '630ab5ffdf27',\n",
       "  'b856005e5ecd',\n",
       "  '14176fcb5743',\n",
       "  '9b351e8113e9',\n",
       "  '5d33decdf4c4',\n",
       "  '37a2cbe8bd15',\n",
       "  'fb44e21903f3'],\n",
       " '0345651c406a': ['e10ad955760c',\n",
       "  'd80580992695',\n",
       "  '630ab5ffdf27',\n",
       "  '9b351e8113e9',\n",
       "  '37a2cbe8bd15',\n",
       "  'fb44e21903f3'],\n",
       " '03609e9ab716': ['e10ad955760c',\n",
       "  '76398be9016',\n",
       "  'd80580992695',\n",
       "  'b856005e5ecd',\n",
       "  '9b351e8113e9',\n",
       "  '5d33decdf4c4',\n",
       "  '8c8e5b7182ef',\n",
       "  '37a2cbe8bd15',\n",
       "  '15a29a4fc6ad',\n",
       "  'fb44e21903f3'],\n",
       " '036ecf5a78de': ['e10ad955760c',\n",
       "  '76398be9016',\n",
       "  'd80580992695',\n",
       "  '630ab5ffdf27',\n",
       "  '14176fcb5743',\n",
       "  '9b351e8113e9',\n",
       "  '5d33decdf4c4',\n",
       "  '8c8e5b7182ef',\n",
       "  '37a2cbe8bd15',\n",
       "  'fb44e21903f3'],\n",
       " '0375cf039b1f': ['e10ad955760c',\n",
       "  'd80580992695',\n",
       "  '630ab5ffdf27',\n",
       "  '9b351e8113e9',\n",
       "  '8c8e5b7182ef',\n",
       "  '37a2cbe8bd15'],\n",
       " '037e56d957e3': ['e10ad955760c',\n",
       "  'd80580992695',\n",
       "  '630ab5ffdf27',\n",
       "  'b856005e5ecd',\n",
       "  '14176fcb5743',\n",
       "  '9b351e8113e9',\n",
       "  '8c8e5b7182ef',\n",
       "  '37a2cbe8bd15'],\n",
       " '03bff1292d9c': ['e10ad955760c',\n",
       "  '4beacba7dc8a',\n",
       "  '630ab5ffdf27',\n",
       "  'b856005e5ecd',\n",
       "  '14176fcb5743',\n",
       "  '9b351e8113e9',\n",
       "  '5d33decdf4c4',\n",
       "  '8c8e5b7182ef',\n",
       "  '37a2cbe8bd15'],\n",
       " '03d778a58360': ['e10ad955760c',\n",
       "  '76398be9016',\n",
       "  'd80580992695',\n",
       "  '4beacba7dc8a',\n",
       "  '630ab5ffdf27',\n",
       "  'b0fbe613be9d',\n",
       "  '14176fcb5743',\n",
       "  '9b351e8113e9',\n",
       "  '5d33decdf4c4',\n",
       "  '8c8e5b7182ef',\n",
       "  '37a2cbe8bd15',\n",
       "  'fb44e21903f3'],\n",
       " '03f6ee79f36c': ['e10ad955760c',\n",
       "  'd80580992695',\n",
       "  '630ab5ffdf27',\n",
       "  '9b351e8113e9',\n",
       "  '8c8e5b7182ef',\n",
       "  '37a2cbe8bd15'],\n",
       " '045559435124': ['e10ad955760c',\n",
       "  '76398be9016',\n",
       "  'd80580992695',\n",
       "  '630ab5ffdf27'],\n",
       " '0458ac9ef3fd': ['e10ad955760c', 'd80580992695', '630ab5ffdf27'],\n",
       " '0476caa94dfc': ['e10ad955760c'],\n",
       " '0488cb6529c7': ['e10ad955760c',\n",
       "  '76398be9016',\n",
       "  '8c8e5b7182ef',\n",
       "  'fb44e21903f3'],\n",
       " '04b04fd923ef': ['e10ad955760c'],\n",
       " '04b1c11cd996': ['e10ad955760c'],\n",
       " '04b7ceab9f78': ['e10ad955760c', '630ab5ffdf27'],\n",
       " '04ca33ca0707': ['e10ad955760c',\n",
       "  '76398be9016',\n",
       "  'd80580992695',\n",
       "  '8a910484fe84',\n",
       "  '4beacba7dc8a',\n",
       "  '630ab5ffdf27',\n",
       "  'b856005e5ecd',\n",
       "  'b0fbe613be9d',\n",
       "  '5d33decdf4c4',\n",
       "  '15a29a4fc6ad',\n",
       "  'fb44e21903f3'],\n",
       " '04e94eb13d69': ['e10ad955760c',\n",
       "  '76398be9016',\n",
       "  'd80580992695',\n",
       "  'b856005e5ecd',\n",
       "  'b0fbe613be9d',\n",
       "  '8c8e5b7182ef',\n",
       "  '15a29a4fc6ad',\n",
       "  'fb44e21903f3'],\n",
       " '051276cc78f1': ['e10ad955760c',\n",
       "  'd80580992695',\n",
       "  '630ab5ffdf27',\n",
       "  '8c8e5b7182ef'],\n",
       " '053ddfdb3053': ['e10ad955760c', '630ab5ffdf27'],\n",
       " '0556c608c8b7': ['e10ad955760c', 'd80580992695', '630ab5ffdf27'],\n",
       " '056d17f08df8': ['e10ad955760c',\n",
       "  '76398be9016',\n",
       "  '4beacba7dc8a',\n",
       "  'b0fbe613be9d',\n",
       "  'fb44e21903f3'],\n",
       " '057ae7cd2ddd': ['e10ad955760c', '630ab5ffdf27', 'fb44e21903f3'],\n",
       " '057c43d907f2': ['e10ad955760c'],\n",
       " '058a6d5a31c2': ['e10ad955760c',\n",
       "  '76398be9016',\n",
       "  'd80580992695',\n",
       "  '630ab5ffdf27',\n",
       "  'b856005e5ecd',\n",
       "  '5d33decdf4c4',\n",
       "  '15a29a4fc6ad',\n",
       "  'fb44e21903f3'],\n",
       " '0591cd50fcdb': ['e10ad955760c',\n",
       "  'd80580992695',\n",
       "  '630ab5ffdf27',\n",
       "  'b0fbe613be9d',\n",
       "  'fb44e21903f3'],\n",
       " '05a7512b66cd': ['e10ad955760c', '630ab5ffdf27'],\n",
       " '05cf15363a93': ['e10ad955760c',\n",
       "  'd80580992695',\n",
       "  '630ab5ffdf27',\n",
       "  'fb44e21903f3'],\n",
       " '05e507811d9f': ['e10ad955760c', 'd80580992695', '630ab5ffdf27'],\n",
       " '060a20697ec0': ['e10ad955760c',\n",
       "  '76398be9016',\n",
       "  'd80580992695',\n",
       "  '630ab5ffdf27',\n",
       "  'b856005e5ecd',\n",
       "  '5d33decdf4c4',\n",
       "  '15a29a4fc6ad'],\n",
       " '0612100996f6': ['e10ad955760c',\n",
       "  'd80580992695',\n",
       "  '630ab5ffdf27',\n",
       "  'fb44e21903f3'],\n",
       " '0649acc497b0': ['e10ad955760c'],\n",
       " '064ece55104e': ['e10ad955760c', 'd80580992695'],\n",
       " '064f9190c730': ['e10ad955760c', '630ab5ffdf27'],\n",
       " '069e39a538ec': ['e10ad955760c'],\n",
       " '06ffa3d84351': ['e10ad955760c', 'd80580992695'],\n",
       " '071c8132ccd0': ['e10ad955760c'],\n",
       " '071da920fdde': ['e10ad955760c',\n",
       "  '76398be9016',\n",
       "  'd80580992695',\n",
       "  '630ab5ffdf27',\n",
       "  '5d33decdf4c4',\n",
       "  '15a29a4fc6ad',\n",
       "  'fb44e21903f3'],\n",
       " '0726c6a08a55': ['e10ad955760c'],\n",
       " '073133dbe904': ['e10ad955760c',\n",
       "  '76398be9016',\n",
       "  'd80580992695',\n",
       "  '630ab5ffdf27',\n",
       "  'b856005e5ecd',\n",
       "  '5d33decdf4c4',\n",
       "  'fb44e21903f3'],\n",
       " '07630528f351': ['e10ad955760c', '630ab5ffdf27'],\n",
       " '07a32ae77163': ['e10ad955760c', '630ab5ffdf27'],\n",
       " '07c53b240b01': ['e10ad955760c',\n",
       "  'd80580992695',\n",
       "  '630ab5ffdf27',\n",
       "  'b856005e5ecd',\n",
       "  'b0fbe613be9d'],\n",
       " '08097d4c62a1': ['e10ad955760c',\n",
       "  '76398be9016',\n",
       "  '630ab5ffdf27',\n",
       "  'b0fbe613be9d'],\n",
       " '081e7c5a55c6': ['e10ad955760c', 'd80580992695', 'b856005e5ecd'],\n",
       " '0863583a2017': ['e10ad955760c'],\n",
       " '0866c1a979c3': ['e10ad955760c', 'b856005e5ecd'],\n",
       " '086801ed3994': ['e10ad955760c', '630ab5ffdf27'],\n",
       " '08c62e60b692': ['e10ad955760c',\n",
       "  'd80580992695',\n",
       "  'b856005e5ecd',\n",
       "  'b0fbe613be9d',\n",
       "  '5d33decdf4c4'],\n",
       " '092d376d06b1': ['e10ad955760c'],\n",
       " '09335f825c05': ['e10ad955760c',\n",
       "  '76398be9016',\n",
       "  'd80580992695',\n",
       "  '630ab5ffdf27'],\n",
       " '093b94338898': ['e10ad955760c', 'd80580992695', '630ab5ffdf27'],\n",
       " '096d447a462e': ['e10ad955760c'],\n",
       " '09abeab74b1b': ['e10ad955760c',\n",
       "  'd80580992695',\n",
       "  '630ab5ffdf27',\n",
       "  '5d33decdf4c4'],\n",
       " '09b6ac590e29': ['e10ad955760c',\n",
       "  '76398be9016',\n",
       "  'd80580992695',\n",
       "  '630ab5ffdf27',\n",
       "  'b856005e5ecd',\n",
       "  '5d33decdf4c4',\n",
       "  '15a29a4fc6ad'],\n",
       " '09b7fba39f2e': ['e10ad955760c',\n",
       "  '76398be9016',\n",
       "  'd80580992695',\n",
       "  '630ab5ffdf27',\n",
       "  'b856005e5ecd',\n",
       "  '5d33decdf4c4',\n",
       "  '15a29a4fc6ad'],\n",
       " '09edfe95038a': ['e10ad955760c',\n",
       "  '76398be9016',\n",
       "  'd80580992695',\n",
       "  '630ab5ffdf27'],\n",
       " '0a5b4b6bf759': ['e10ad955760c', '630ab5ffdf27'],\n",
       " '0a8cc69ddb75': ['e10ad955760c',\n",
       "  '76398be9016',\n",
       "  'd80580992695',\n",
       "  'b856005e5ecd',\n",
       "  '15a29a4fc6ad'],\n",
       " '0a9f4e679fe2': ['e10ad955760c',\n",
       "  'd80580992695',\n",
       "  '630ab5ffdf27',\n",
       "  'b856005e5ecd',\n",
       "  '5d33decdf4c4',\n",
       "  '15a29a4fc6ad'],\n",
       " '0aa919e64d91': ['e10ad955760c', '630ab5ffdf27', '15a29a4fc6ad'],\n",
       " '0abce5a499cf': ['e10ad955760c', 'd80580992695', '630ab5ffdf27'],\n",
       " '0ac981d0a6a1': ['e10ad955760c', '76398be9016', 'b0fbe613be9d'],\n",
       " '0af0a1b91b37': ['e10ad955760c',\n",
       "  'd80580992695',\n",
       "  '8a910484fe84',\n",
       "  'b856005e5ecd',\n",
       "  'b0fbe613be9d',\n",
       "  '15a29a4fc6ad'],\n",
       " '0b1f7a361970': ['e10ad955760c'],\n",
       " '0b2021d26409': ['e10ad955760c',\n",
       "  'd80580992695',\n",
       "  '630ab5ffdf27',\n",
       "  'b856005e5ecd',\n",
       "  '15a29a4fc6ad'],\n",
       " '0b234e69a7f9': ['e10ad955760c', '630ab5ffdf27', '15a29a4fc6ad'],\n",
       " '0b36e4263392': ['e10ad955760c',\n",
       "  '76398be9016',\n",
       "  'd80580992695',\n",
       "  '630ab5ffdf27',\n",
       "  'b856005e5ecd',\n",
       "  '5d33decdf4c4'],\n",
       " '0b37349d902a': ['e10ad955760c',\n",
       "  'd80580992695',\n",
       "  '630ab5ffdf27',\n",
       "  'b856005e5ecd',\n",
       "  '5d33decdf4c4'],\n",
       " '0b8ff2210469': ['e10ad955760c'],\n",
       " '0b94187ee8f5': ['e10ad955760c',\n",
       "  '76398be9016',\n",
       "  'd80580992695',\n",
       "  '630ab5ffdf27',\n",
       "  'b0fbe613be9d',\n",
       "  '5d33decdf4c4'],\n",
       " '0b96f6886a09': ['e10ad955760c',\n",
       "  'd80580992695',\n",
       "  '4beacba7dc8a',\n",
       "  '630ab5ffdf27',\n",
       "  'b0fbe613be9d',\n",
       "  '5d33decdf4c4'],\n",
       " '0bbd1d8ab904': ['e10ad955760c',\n",
       "  '76398be9016',\n",
       "  'd80580992695',\n",
       "  'b856005e5ecd',\n",
       "  'b0fbe613be9d',\n",
       "  '15a29a4fc6ad'],\n",
       " '0bc872ce959b': ['e10ad955760c',\n",
       "  '76398be9016',\n",
       "  'd80580992695',\n",
       "  '630ab5ffdf27',\n",
       "  '5d33decdf4c4'],\n",
       " '0bf1aaa7789b': ['e10ad955760c'],\n",
       " '0c12ddd398a9': ['e10ad955760c',\n",
       "  '8a910484fe84',\n",
       "  'b856005e5ecd',\n",
       "  '15a29a4fc6ad'],\n",
       " '0c36b68c3f11': ['e10ad955760c',\n",
       "  '76398be9016',\n",
       "  'd80580992695',\n",
       "  '630ab5ffdf27',\n",
       "  'b0fbe613be9d',\n",
       "  '5d33decdf4c4'],\n",
       " '0c4a6fad5f96': ['e10ad955760c', 'd80580992695'],\n",
       " '0c602f4e893a': ['e10ad955760c',\n",
       "  '4beacba7dc8a',\n",
       "  '630ab5ffdf27',\n",
       "  'b856005e5ecd',\n",
       "  'b0fbe613be9d',\n",
       "  '15a29a4fc6ad'],\n",
       " '0c834d1c219f': ['e10ad955760c'],\n",
       " '0c8d56eda234': ['e10ad955760c',\n",
       "  'd80580992695',\n",
       "  '630ab5ffdf27',\n",
       "  '15a29a4fc6ad'],\n",
       " '0ccd347285af': ['e10ad955760c',\n",
       "  '76398be9016',\n",
       "  'd80580992695',\n",
       "  '630ab5ffdf27',\n",
       "  'b856005e5ecd',\n",
       "  '15a29a4fc6ad'],\n",
       " '0cec65fa12b8': ['e10ad955760c', '630ab5ffdf27'],\n",
       " '0ced55597187': ['e10ad955760c', '630ab5ffdf27'],\n",
       " '0cf3cf1c1015': ['e10ad955760c',\n",
       "  '76398be9016',\n",
       "  'd80580992695',\n",
       "  '630ab5ffdf27'],\n",
       " '0d1aa9ca5728': ['e10ad955760c', '630ab5ffdf27'],\n",
       " '0d2949696dc1': ['e10ad955760c', '76398be9016', 'b0fbe613be9d'],\n",
       " '0d6a560df67d': ['e10ad955760c',\n",
       "  '76398be9016',\n",
       "  'd80580992695',\n",
       "  '630ab5ffdf27',\n",
       "  'b0fbe613be9d'],\n",
       " '0d7815861d2c': ['e10ad955760c'],\n",
       " '0d89ecd05943': ['e10ad955760c', 'b856005e5ecd'],\n",
       " '0d9c480487a9': ['e10ad955760c', '630ab5ffdf27'],\n",
       " '0dc20688cac0': ['e10ad955760c', 'd80580992695'],\n",
       " '0dd63eaaa48f': ['e10ad955760c',\n",
       "  'd80580992695',\n",
       "  '630ab5ffdf27',\n",
       "  '15a29a4fc6ad'],\n",
       " '0e365ad5e60a': ['e10ad955760c',\n",
       "  '76398be9016',\n",
       "  'd80580992695',\n",
       "  '630ab5ffdf27',\n",
       "  'b0fbe613be9d',\n",
       "  '5d33decdf4c4'],\n",
       " '0e4aa70f7594': ['e10ad955760c',\n",
       "  '76398be9016',\n",
       "  'd80580992695',\n",
       "  '5d33decdf4c4'],\n",
       " '0e5faf098978': ['e10ad955760c',\n",
       "  '76398be9016',\n",
       "  'd80580992695',\n",
       "  '4beacba7dc8a',\n",
       "  '630ab5ffdf27',\n",
       "  'b0fbe613be9d',\n",
       "  '5d33decdf4c4',\n",
       "  '15a29a4fc6ad'],\n",
       " '0e61305155f2': ['e10ad955760c',\n",
       "  '76398be9016',\n",
       "  '4beacba7dc8a',\n",
       "  'b0fbe613be9d'],\n",
       " '0e7588d35f8d': ['e10ad955760c', '630ab5ffdf27', '15a29a4fc6ad'],\n",
       " '0e7dc74f4b5f': ['e10ad955760c', 'd80580992695'],\n",
       " '0e809eb771c1': ['e10ad955760c', '4beacba7dc8a', 'b0fbe613be9d'],\n",
       " '0eacbe3178a1': ['e10ad955760c',\n",
       "  'd80580992695',\n",
       "  '630ab5ffdf27',\n",
       "  '15a29a4fc6ad'],\n",
       " '0ec324fbcb05': ['e10ad955760c', '630ab5ffdf27', '15a29a4fc6ad'],\n",
       " '0ed0e5a8ca2f': ['e10ad955760c',\n",
       "  '76398be9016',\n",
       "  'd80580992695',\n",
       "  '630ab5ffdf27',\n",
       "  '5d33decdf4c4'],\n",
       " '0efa91bc2ac7': ['e10ad955760c',\n",
       "  '76398be9016',\n",
       "  'd80580992695',\n",
       "  'b0fbe613be9d',\n",
       "  '5d33decdf4c4',\n",
       "  '15a29a4fc6ad'],\n",
       " '0f14b25034eb': ['e10ad955760c', '630ab5ffdf27'],\n",
       " '0f68be24fe5d': ['e10ad955760c', '630ab5ffdf27', '15a29a4fc6ad'],\n",
       " '0f6f08d3268f': ['e10ad955760c', '630ab5ffdf27', '15a29a4fc6ad'],\n",
       " '0fdacfb5e0a2': ['e10ad955760c', '630ab5ffdf27'],\n",
       " '0fdd58b66321': ['e10ad955760c', '630ab5ffdf27'],\n",
       " '1002708bb2dd': ['e10ad955760c'],\n",
       " '1017ec31ff47': ['e10ad955760c', '5d33decdf4c4'],\n",
       " '1041042eecf4': ['e10ad955760c'],\n",
       " '104405037911': ['e10ad955760c'],\n",
       " '1047a13dcf84': ['e10ad955760c'],\n",
       " '10497a096abc': ['e10ad955760c',\n",
       "  '76398be9016',\n",
       "  '4beacba7dc8a',\n",
       "  '630ab5ffdf27',\n",
       "  'b0fbe613be9d',\n",
       "  '5d33decdf4c4'],\n",
       " '105a25458d59': ['e10ad955760c'],\n",
       " '105a3c72085a': ['e10ad955760c',\n",
       "  '630ab5ffdf27',\n",
       "  '5d33decdf4c4',\n",
       "  '15a29a4fc6ad'],\n",
       " '10626c7bdc67': ['e10ad955760c'],\n",
       " '106745496231': ['e10ad955760c', '630ab5ffdf27'],\n",
       " '106ae4eb88b0': ['e10ad955760c'],\n",
       " '107492e4f8c5': ['e10ad955760c'],\n",
       " '107e751f0199': ['e10ad955760c'],\n",
       " '1087a3cf4a0f': ['e10ad955760c'],\n",
       " '108e08d9c994': ['e10ad955760c',\n",
       "  '76398be9016',\n",
       "  '630ab5ffdf27',\n",
       "  '5d33decdf4c4'],\n",
       " '1096b7e06ce2': ['e10ad955760c'],\n",
       " '109ff6d51065': ['e10ad955760c'],\n",
       " '10a06830076d': ['e10ad955760c'],\n",
       " '10a305a6c9d5': ['e10ad955760c', '630ab5ffdf27', '15a29a4fc6ad'],\n",
       " '10aacc6f7e3d': ['e10ad955760c'],\n",
       " '10b81a106444': ['e10ad955760c', '5d33decdf4c4'],\n",
       " '10be897e1662': ['e10ad955760c'],\n",
       " '10cceacb79a5': ['e10ad955760c', '630ab5ffdf27'],\n",
       " '10cf78ee0cba': ['e10ad955760c',\n",
       "  '76398be9016',\n",
       "  '630ab5ffdf27',\n",
       "  'b0fbe613be9d'],\n",
       " '10cfc8f4b0ce': ['e10ad955760c'],\n",
       " '10d0fed7e76f': ['e10ad955760c'],\n",
       " '10d64fbe4bc5': ['e10ad955760c', '630ab5ffdf27', '15a29a4fc6ad'],\n",
       " '10d971fe0375': ['e10ad955760c'],\n",
       " '10dd161d7772': ['e10ad955760c'],\n",
       " '10de7cb84f80': ['e10ad955760c',\n",
       "  '630ab5ffdf27',\n",
       "  'b0fbe613be9d',\n",
       "  '5d33decdf4c4'],\n",
       " '10dff6eeed00': ['e10ad955760c'],\n",
       " '10e8b71566e': ['e10ad955760c'],\n",
       " '10eb8bf345c1': ['e10ad955760c'],\n",
       " '10ed7cb7442e': ['e10ad955760c',\n",
       "  '76398be9016',\n",
       "  '4beacba7dc8a',\n",
       "  'b0fbe613be9d'],\n",
       " '10f581b06f04': ['e10ad955760c',\n",
       "  '76398be9016',\n",
       "  '630ab5ffdf27',\n",
       "  '5d33decdf4c4',\n",
       "  '15a29a4fc6ad'],\n",
       " '10fecb0972ba': ['e10ad955760c'],\n",
       " '110b2339d711': ['e10ad955760c'],\n",
       " '110da4763449': ['e10ad955760c'],\n",
       " '1125918679ba': ['e10ad955760c', '630ab5ffdf27', '15a29a4fc6ad'],\n",
       " '113ee8fc4182': ['e10ad955760c', '4beacba7dc8a'],\n",
       " '114bb975ae25': ['e10ad955760c',\n",
       "  '76398be9016',\n",
       "  'b0fbe613be9d',\n",
       "  '15a29a4fc6ad'],\n",
       " '116d7b59a07d': ['e10ad955760c'],\n",
       " '1172fd6dc56': ['e10ad955760c'],\n",
       " '1191aae9fbe7': ['e10ad955760c'],\n",
       " '11939f12eb7e': ['e10ad955760c', '630ab5ffdf27'],\n",
       " '119461a67189': ['e10ad955760c',\n",
       "  '76398be9016',\n",
       "  'b0fbe613be9d',\n",
       "  '15a29a4fc6ad'],\n",
       " '119668a80479': ['e10ad955760c', '630ab5ffdf27'],\n",
       " '11ac10147fb0': ['e10ad955760c'],\n",
       " '11ac44078875': ['e10ad955760c'],\n",
       " '11af8c1ee005': ['e10ad955760c'],\n",
       " '11ba4de99946': ['e10ad955760c'],\n",
       " '11c63cf0ce56': ['e10ad955760c', '76398be9016'],\n",
       " '11c675ef5930': ['e10ad955760c'],\n",
       " '11ea806b0a0a': ['e10ad955760c'],\n",
       " '11ebdbfd3d01': ['e10ad955760c',\n",
       "  '630ab5ffdf27',\n",
       "  '5d33decdf4c4',\n",
       "  '15a29a4fc6ad'],\n",
       " '11f57056ef35': ['e10ad955760c'],\n",
       " '11f622ac4fc5': ['e10ad955760c'],\n",
       " '11ff1013b4d6': ['e10ad955760c'],\n",
       " '1200b2182238': ['e10ad955760c'],\n",
       " '120395cb5552': ['e10ad955760c'],\n",
       " '1203ff17e2d6': ['e10ad955760c'],\n",
       " '120718656361': ['e10ad955760c'],\n",
       " '120ba2a15cbf': ['e10ad955760c', '5d33decdf4c4'],\n",
       " '120e9fd3086': ['e10ad955760c'],\n",
       " '1215a1073da7': ['e10ad955760c'],\n",
       " '122e0b588f5f': ['e10ad955760c'],\n",
       " '123aeb8f2a65': ['e10ad955760c'],\n",
       " '124da67fdbab': ['e10ad955760c'],\n",
       " '12524c2bcf45': ['e10ad955760c', '76398be9016', '5d33decdf4c4'],\n",
       " '125eb60c78ff': ['e10ad955760c'],\n",
       " '12665ee42fe5': ['e10ad955760c',\n",
       "  '76398be9016',\n",
       "  '5d33decdf4c4',\n",
       "  '15a29a4fc6ad'],\n",
       " '126dcdd739e9': ['e10ad955760c'],\n",
       " '1276a2ab058c': ['e10ad955760c',\n",
       "  '76398be9016',\n",
       "  '5d33decdf4c4',\n",
       "  '15a29a4fc6ad'],\n",
       " '1279b2ff18e1': ['e10ad955760c'],\n",
       " '12892a109be6': ['e10ad955760c',\n",
       "  '76398be9016',\n",
       "  '4beacba7dc8a',\n",
       "  '5d33decdf4c4',\n",
       "  '15a29a4fc6ad'],\n",
       " '128da2b4ec36': ['e10ad955760c', '76398be9016'],\n",
       " '129a68b12a3b': ['e10ad955760c', '76398be9016', '5d33decdf4c4'],\n",
       " '129fb2cd056f': ['e10ad955760c'],\n",
       " '12a204627804': ['e10ad955760c',\n",
       "  '76398be9016',\n",
       "  '5d33decdf4c4',\n",
       "  '15a29a4fc6ad'],\n",
       " '12a3be4b5805': ['e10ad955760c'],\n",
       " '12a4a68006b7': ['e10ad955760c'],\n",
       " '12a9f08aed7b': ['e10ad955760c'],\n",
       " '12ad037c4c7e': ['e10ad955760c'],\n",
       " '12b889180aa8': ['e10ad955760c'],\n",
       " '12e327e575dc': ['e10ad955760c'],\n",
       " '12e73c0f1931': ['e10ad955760c'],\n",
       " '12ea0ea3cf20': ['e10ad955760c'],\n",
       " '12ef6616161c': ['e10ad955760c', '76398be9016'],\n",
       " '12f50c61038f': ['e10ad955760c'],\n",
       " '12fa3dfc9fcf': ['e10ad955760c'],\n",
       " '12ffa859e07d': ['e10ad955760c'],\n",
       " '1301ed5b36e6': ['e10ad955760c'],\n",
       " '13072b8d22f3': ['e10ad955760c', '76398be9016'],\n",
       " '130800821d36': ['e10ad955760c', '5d33decdf4c4'],\n",
       " '130c9927dfaf': ['e10ad955760c'],\n",
       " '130d0f4fb9c9': ['e10ad955760c'],\n",
       " '13244b92ff7a': ['e10ad955760c'],\n",
       " '133229767165': ['e10ad955760c'],\n",
       " '1334d2e5afe': ['e10ad955760c'],\n",
       " '1340f0cb9bfe': ['e10ad955760c'],\n",
       " '135253871a3b': ['e10ad955760c'],\n",
       " '135607d83f67': ['e10ad955760c'],\n",
       " '1365178c7535': ['e10ad955760c'],\n",
       " '136902642b64': ['e10ad955760c'],\n",
       " '136b8d469bf9': ['e10ad955760c'],\n",
       " '136cf1142fed': ['e10ad955760c'],\n",
       " '137b395910dc': ['e10ad955760c'],\n",
       " '137c131485da': ['e10ad955760c', '15a29a4fc6ad'],\n",
       " '13a40599fb71': ['e10ad955760c', '15a29a4fc6ad'],\n",
       " '13a64b26206d': ['e10ad955760c', '5d33decdf4c4'],\n",
       " '13bca66e9a0b': ['e10ad955760c', '5d33decdf4c4'],\n",
       " '13ce2c4c46a7': ['e10ad955760c'],\n",
       " '13d279556fc2': ['e10ad955760c'],\n",
       " '13e90ef9aef': ['e10ad955760c'],\n",
       " '13ecc6bcd7ee': ['e10ad955760c'],\n",
       " '13ee5c5ac2b1': ['e10ad955760c'],\n",
       " '13fdeefac3ba': ['e10ad955760c'],\n",
       " '141161644192': ['e10ad955760c'],\n",
       " '142a5b944941': ['e10ad955760c', '15a29a4fc6ad'],\n",
       " '142cd54f2047': ['e10ad955760c'],\n",
       " '1430456ad365': ['e10ad955760c', '76398be9016', '15a29a4fc6ad'],\n",
       " '143184ecac7b': ['e10ad955760c', '15a29a4fc6ad'],\n",
       " '14446d982b66': ['e10ad955760c', '76398be9016', '15a29a4fc6ad'],\n",
       " '1447748d95d3': ['e10ad955760c'],\n",
       " '1448d7661cec': ['e10ad955760c'],\n",
       " '1448e970c28': ['e10ad955760c'],\n",
       " '145c5b968234': ['e10ad955760c'],\n",
       " '14657854cafa': ['e10ad955760c'],\n",
       " '14671773ef5': ['e10ad955760c'],\n",
       " '146b1ef463a9': ['e10ad955760c', '76398be9016'],\n",
       " '14762f2b17f2': ['e10ad955760c'],\n",
       " '148b4f785641': ['e10ad955760c'],\n",
       " '148c1be58442': ['e10ad955760c'],\n",
       " '148e65c6a81a': ['e10ad955760c'],\n",
       " '14950b04f4d9': ['e10ad955760c', '76398be9016', '15a29a4fc6ad'],\n",
       " '14aadbfe102a': ['e10ad955760c'],\n",
       " '14ca2b0807e8': ['e10ad955760c'],\n",
       " '14cd2b5df6f5': ['e10ad955760c', '76398be9016'],\n",
       " '14d767c71e5b': ['e10ad955760c', '4beacba7dc8a', '15a29a4fc6ad'],\n",
       " '14d7cdda8afa': ['e10ad955760c'],\n",
       " '14d8d59ae35c': ['e10ad955760c',\n",
       "  '76398be9016',\n",
       "  '4beacba7dc8a',\n",
       "  '15a29a4fc6ad'],\n",
       " '14d9991e7944': ['e10ad955760c'],\n",
       " '14e31690cede': ['e10ad955760c'],\n",
       " '14f13d7da131': ['e10ad955760c'],\n",
       " '15117a3e232c': ['e10ad955760c'],\n",
       " '15127b43c5cd': ['e10ad955760c'],\n",
       " '152ed5acea22': ['e10ad955760c'],\n",
       " '1530d465dbcc': ['e10ad955760c'],\n",
       " '1537c3b25c80': ['e10ad955760c'],\n",
       " '154e49eaa3ce': ['e10ad955760c'],\n",
       " '1565865a39bc': ['e10ad955760c'],\n",
       " '156675d1f1f0': ['e10ad955760c'],\n",
       " '156763787e80': ['e10ad955760c'],\n",
       " '156d7df54349': ['e10ad955760c', '15a29a4fc6ad'],\n",
       " '157174a5390c': ['e10ad955760c'],\n",
       " '15745a47dc7': ['e10ad955760c'],\n",
       " '1578151e227b': ['e10ad955760c'],\n",
       " '15898626fa82': ['e10ad955760c'],\n",
       " '158a8cec6718': ['e10ad955760c'],\n",
       " '15966a0e203a': ['e10ad955760c'],\n",
       " '1596aa39d815': ['e10ad955760c'],\n",
       " '1597a5e848ab': ['e10ad955760c'],\n",
       " '159a50f05cb3': ['e10ad955760c'],\n",
       " '159a81fabf0c': ['e10ad955760c'],\n",
       " '15a6ca4c955e': ['e10ad955760c', '4beacba7dc8a'],\n",
       " '15cbb5ae0eeb': ['e10ad955760c'],\n",
       " '15d1985b3bbd': ['e10ad955760c'],\n",
       " '15d1c06b368d': ['e10ad955760c'],\n",
       " '15d24f1029cd': ['e10ad955760c'],\n",
       " '15e3b066f9b8': ['e10ad955760c'],\n",
       " '160c0bac9012': ['e10ad955760c'],\n",
       " '160c3e933453': ['e10ad955760c', '8a910484fe84', '15a29a4fc6ad'],\n",
       " '162493f72268': ['e10ad955760c'],\n",
       " '164497287266': ['e10ad955760c'],\n",
       " '1651eb9a4ba0': ['e10ad955760c'],\n",
       " '165c408ed9b': ['e10ad955760c', '4beacba7dc8a'],\n",
       " '1675f455ff19': ['e10ad955760c'],\n",
       " '167cfb793ee3': ['e10ad955760c'],\n",
       " '1684cc3963b5': ['e10ad955760c'],\n",
       " '168ade45dce2': ['e10ad955760c'],\n",
       " '168b985e91b0': ['e10ad955760c'],\n",
       " '168e9003ef74': ['e10ad955760c'],\n",
       " '168f8fc4a832': ['e10ad955760c', '4beacba7dc8a', '15a29a4fc6ad'],\n",
       " '169b5527fee1': ['e10ad955760c', '8a910484fe84', '15a29a4fc6ad'],\n",
       " '169c5dc9497d': ['e10ad955760c'],\n",
       " '169fe19d8df8': ['e10ad955760c'],\n",
       " '16aadebc2fce': ['e10ad955760c'],\n",
       " '16afe74ef984': ['e10ad955760c'],\n",
       " '16c33b9713c8': ['e10ad955760c'],\n",
       " '16c3b3f94a5f': ['e10ad955760c'],\n",
       " '16c57ca9ba40': ['e10ad955760c'],\n",
       " '16c5dd564002': ['e10ad955760c'],\n",
       " '16c9194b3c3f': ['e10ad955760c'],\n",
       " '16cf86c4bbb5': ['e10ad955760c', '8a910484fe84'],\n",
       " '16d00810ad30': ['e10ad955760c'],\n",
       " '16e17a3a28cc': ['e10ad955760c'],\n",
       " '16e7e8d8f18e': ['e10ad955760c'],\n",
       " '1704096afcd4': ['e10ad955760c'],\n",
       " '17082f91e32b': ['e10ad955760c'],\n",
       " '170cee3dbfa6': ['e10ad955760c'],\n",
       " '1715f386c47c': ['e10ad955760c'],\n",
       " '17177ddb9346': ['e10ad955760c'],\n",
       " '171e4625019d': ['e10ad955760c'],\n",
       " '172e53866d46': ['e10ad955760c'],\n",
       " '172f2b2a4ee7': ['e10ad955760c'],\n",
       " '174458d9b787': ['e10ad955760c'],\n",
       " '1744f4151595': ['e10ad955760c'],\n",
       " '1752ebf3bdc7': ['e10ad955760c'],\n",
       " '175387949708': ['e10ad955760c'],\n",
       " '17642c8a9218': ['e10ad955760c'],\n",
       " '17645ab95c5a': ['e10ad955760c'],\n",
       " '176530335ccb': ['e10ad955760c'],\n",
       " '176670e9c6c6': ['e10ad955760c'],\n",
       " '176917181194': ['e10ad955760c'],\n",
       " '17761ba6e006': ['e10ad955760c'],\n",
       " '17819ac3102a': ['e10ad955760c'],\n",
       " '178e1694ea41': ['e10ad955760c'],\n",
       " '17994169720': ['e10ad955760c'],\n",
       " '179cd0885a2': ['e10ad955760c'],\n",
       " '179f8d32ccd2': ['e10ad955760c'],\n",
       " '17a0fb103d7f': ['e10ad955760c'],\n",
       " '17a99636e7': ['e10ad955760c'],\n",
       " '17b8c87426a7': ['e10ad955760c'],\n",
       " '17bb2a364fb7': ['e10ad955760c'],\n",
       " '17be8e0d12cf': ['e10ad955760c'],\n",
       " '17befc1a93a6': ['e10ad955760c'],\n",
       " '17cbfaad6866': ['e10ad955760c'],\n",
       " '17cc489b125d': ['e10ad955760c'],\n",
       " '17ccdcaeabd7': ['e10ad955760c'],\n",
       " '17cd9a55c071': ['e10ad955760c'],\n",
       " '17ce2d37c16a': ['e10ad955760c'],\n",
       " '17da3bb741d5': ['e10ad955760c'],\n",
       " '17f94d50271b': ['e10ad955760c'],\n",
       " '17fbaeb73b20': ['e10ad955760c'],\n",
       " '17fdd7a7ba0d': ['e10ad955760c'],\n",
       " '18043d4355ed': ['e10ad955760c'],\n",
       " '18094fd27d29': ['e10ad955760c'],\n",
       " '1817385bb13f': ['e10ad955760c'],\n",
       " '181aec70f893': ['e10ad955760c'],\n",
       " '18298843b89': ['e10ad955760c'],\n",
       " '182cf34c2fae': ['e10ad955760c'],\n",
       " '182dda462ef2': ['e10ad955760c', '4beacba7dc8a'],\n",
       " '1833532cf8d1': ['e10ad955760c'],\n",
       " '1834a87307ce': ['e10ad955760c'],\n",
       " '18363c9fee64': ['e10ad955760c'],\n",
       " '184bc2662bb8': ['e10ad955760c'],\n",
       " '185e09e3fc6d': ['e10ad955760c'],\n",
       " '18661e81f319': ['e10ad955760c'],\n",
       " '186766706a9e': ['e10ad955760c'],\n",
       " '18687e7631d7': ['e10ad955760c'],\n",
       " '187277a001df': ['e10ad955760c'],\n",
       " '188549d9b8e3': ['e10ad955760c'],\n",
       " '18885432cdf0': ['e10ad955760c'],\n",
       " '1895c8dbf967': ['e10ad955760c'],\n",
       " '189823b30cbd': ['e10ad955760c'],\n",
       " '18a35891105a': ['e10ad955760c'],\n",
       " '18a42b5dd85': ['e10ad955760c'],\n",
       " '18a5ebc26249': ['e10ad955760c'],\n",
       " '18a6db16996d': ['e10ad955760c'],\n",
       " '18b055c50d64': ['e10ad955760c'],\n",
       " '18b0daa4388e': ['e10ad955760c'],\n",
       " '18c34ef669f': ['e10ad955760c'],\n",
       " '18ccd143350e': ['e10ad955760c'],\n",
       " '18d3d3c27b7a': ['e10ad955760c'],\n",
       " '18dae231b60e': ['e10ad955760c'],\n",
       " '18e4c0f348aa': ['e10ad955760c'],\n",
       " '18f732948dd1': ['e10ad955760c'],\n",
       " '190a292777d4': ['e10ad955760c'],\n",
       " '1915afa5a5a5': ['e10ad955760c'],\n",
       " '19249b2351ae': ['e10ad955760c'],\n",
       " '192f273107b': ['e10ad955760c', '8a910484fe84'],\n",
       " '19330404384e': ['e10ad955760c'],\n",
       " '1936048e08d6': ['e10ad955760c'],\n",
       " '194e1c158333': ['e10ad955760c'],\n",
       " '195e6a161649': ['e10ad955760c'],\n",
       " '1975ecf7d15a': ['e10ad955760c'],\n",
       " '19762c6c7b10': ['e10ad955760c'],\n",
       " '19880a76e030': ['e10ad955760c'],\n",
       " '19a6d67c6a9b': ['e10ad955760c'],\n",
       " '19b94f6f208a': ['e10ad955760c'],\n",
       " '19c249cb2aed': ['e10ad955760c'],\n",
       " '19d03c669023': ['e10ad955760c'],\n",
       " '19dd0b03b71d': ['e10ad955760c'],\n",
       " '19efbf6cb6f6': ['e10ad955760c'],\n",
       " '19fff93cd315': ['e10ad955760c'],\n",
       " '1a05438d6247': ['e10ad955760c'],\n",
       " '1a08496ec3b0': ['e10ad955760c'],\n",
       " '1a0874fdea94': ['e10ad955760c'],\n",
       " '1a0b9d57826f': ['e10ad955760c', '4beacba7dc8a'],\n",
       " '1a26226717de': ['e10ad955760c'],\n",
       " '1a2dbd8414a4': ['e10ad955760c'],\n",
       " '1a3b96579e7c': ['e10ad955760c', '8a910484fe84', '4beacba7dc8a'],\n",
       " '1a4fda812580': ['e10ad955760c'],\n",
       " '1a54ec526cbc': ['e10ad955760c'],\n",
       " '1a5629a9ff57': ['e10ad955760c'],\n",
       " '1a56f4f58b2b': ['e10ad955760c'],\n",
       " '1a6406209265': ['e10ad955760c'],\n",
       " '1a7661f07732': ['e10ad955760c'],\n",
       " '1a7942f3d9c6': ['e10ad955760c'],\n",
       " '1a7b4287ab33': ['e10ad955760c'],\n",
       " '1a7c5a422267': ['e10ad955760c'],\n",
       " '1a7df6a63fda': ['e10ad955760c'],\n",
       " '1a820d25020c': ['e10ad955760c'],\n",
       " '1a88e27a1ddd': ['e10ad955760c'],\n",
       " '1a8b67b2893': ['e10ad955760c'],\n",
       " '1a8c08538833': ['e10ad955760c'],\n",
       " '1a8d81e694d6': ['e10ad955760c'],\n",
       " '1a9139423b61': ['e10ad955760c'],\n",
       " '1a9306eba2ef': ['e10ad955760c'],\n",
       " '1a938bc96fb2': ['e10ad955760c'],\n",
       " '1a9fc03d760': ['e10ad955760c'],\n",
       " '1aa619e0550a': ['e10ad955760c'],\n",
       " '1ac0a52421bc': ['e10ad955760c'],\n",
       " '1ac1934bbae4': ['e10ad955760c'],\n",
       " '1ad89d63ee8e': ['e10ad955760c'],\n",
       " '1ae72e97012c': ['e10ad955760c'],\n",
       " '1ae7d378b06f': ['e10ad955760c'],\n",
       " '1aebe0c0a8a6': ['e10ad955760c'],\n",
       " '1b117e0b92f6': ['e10ad955760c'],\n",
       " '1b294bd607be': ['e10ad955760c'],\n",
       " '1b2a3414cad7': ['e10ad955760c'],\n",
       " '1b383ca79080': ['e10ad955760c'],\n",
       " '1b45b966c576': ['e10ad955760c'],\n",
       " '1b4b58394e85': ['e10ad955760c'],\n",
       " '1b4c85e51842': ['e10ad955760c'],\n",
       " '1b4efcfaa2af': ['e10ad955760c'],\n",
       " '1b50da98b884': ['e10ad955760c', '4beacba7dc8a'],\n",
       " '1b6443bd8f4c': ['e10ad955760c'],\n",
       " '1b6d45ecfbfd': ['e10ad955760c'],\n",
       " '1b6de1e895ac': ['e10ad955760c'],\n",
       " '1b7422879ee0': ['e10ad955760c'],\n",
       " '1b9cb41e4b74': ['e10ad955760c'],\n",
       " '1bb06c75646e': ['e10ad955760c'],\n",
       " '1bb609adeb79': ['e10ad955760c'],\n",
       " '1bba907b9ad2': ['e10ad955760c'],\n",
       " '1bd5603396d1': ['e10ad955760c'],\n",
       " '1bdc477b8179': ['e10ad955760c'],\n",
       " '1bf13f7b4824': ['e10ad955760c'],\n",
       " '1bf37f7800f9': ['e10ad955760c'],\n",
       " '1bf4dad54f64': ['e10ad955760c'],\n",
       " '1bf9683fd634': ['e10ad955760c'],\n",
       " '1bfe56776905': ['e10ad955760c'],\n",
       " '1c150c2e8bb9': ['e10ad955760c'],\n",
       " '1c20f09ad277': ['e10ad955760c'],\n",
       " '1c299fd98275': ['e10ad955760c'],\n",
       " '00245ad345da': ['76398be9016',\n",
       "  '4beacba7dc8a',\n",
       "  'b856005e5ecd',\n",
       "  'b0fbe613be9d',\n",
       "  '14176fcb5743',\n",
       "  '9b351e8113e9',\n",
       "  '37a2cbe8bd15',\n",
       "  '15a29a4fc6ad',\n",
       "  'fb44e21903f3'],\n",
       " '0048135eab64': ['76398be9016'],\n",
       " '0078a8c1aefd': ['76398be9016',\n",
       "  'b856005e5ecd',\n",
       "  '9b351e8113e9',\n",
       "  '8c8e5b7182ef',\n",
       "  '37a2cbe8bd15',\n",
       "  '15a29a4fc6ad',\n",
       "  'fb44e21903f3'],\n",
       " '00850ccafbce': ['76398be9016', '37a2cbe8bd15'],\n",
       " '00abad96696a': ['76398be9016',\n",
       "  'd80580992695',\n",
       "  'b856005e5ecd',\n",
       "  'b0fbe613be9d',\n",
       "  '14176fcb5743',\n",
       "  '9b351e8113e9',\n",
       "  '5d33decdf4c4',\n",
       "  '8c8e5b7182ef',\n",
       "  '37a2cbe8bd15',\n",
       "  'fb44e21903f3'],\n",
       " '00b0ad7585f2': ['76398be9016',\n",
       "  '5d33decdf4c4',\n",
       "  '8c8e5b7182ef',\n",
       "  'fb44e21903f3'],\n",
       " '010f43fe49da': ['76398be9016', '8c8e5b7182ef'],\n",
       " '012072537565': ['76398be9016',\n",
       "  '9b351e8113e9',\n",
       "  '8c8e5b7182ef',\n",
       "  '37a2cbe8bd15'],\n",
       " '012fdb5da8ec': ['76398be9016',\n",
       "  '630ab5ffdf27',\n",
       "  '14176fcb5743',\n",
       "  '9b351e8113e9',\n",
       "  '8c8e5b7182ef',\n",
       "  '37a2cbe8bd15'],\n",
       " '01504d6c22ed': ['76398be9016', '630ab5ffdf27'],\n",
       " '01a9bec2ec7a': ['76398be9016'],\n",
       " '01ae33f2ac2d': ['76398be9016'],\n",
       " '01b0fa936fca': ['76398be9016',\n",
       "  'b0fbe613be9d',\n",
       "  '14176fcb5743',\n",
       "  '9b351e8113e9',\n",
       "  '5d33decdf4c4'],\n",
       " '01bace87a8ca': ['76398be9016',\n",
       "  'b856005e5ecd',\n",
       "  '14176fcb5743',\n",
       "  '9b351e8113e9',\n",
       "  '8c8e5b7182ef',\n",
       "  '37a2cbe8bd15',\n",
       "  '15a29a4fc6ad',\n",
       "  'fb44e21903f3'],\n",
       " '02196c29640d': ['76398be9016',\n",
       "  'b0fbe613be9d',\n",
       "  '9b351e8113e9',\n",
       "  '5d33decdf4c4',\n",
       "  '8c8e5b7182ef',\n",
       "  '37a2cbe8bd15',\n",
       "  'fb44e21903f3'],\n",
       " '02331c9dd59d': ['76398be9016',\n",
       "  'b856005e5ecd',\n",
       "  'b0fbe613be9d',\n",
       "  '9b351e8113e9',\n",
       "  '37a2cbe8bd15',\n",
       "  'fb44e21903f3'],\n",
       " '0239c84a897c': ['76398be9016'],\n",
       " '024bf4648d4b': ['76398be9016'],\n",
       " '02593edd9dcf': ['76398be9016',\n",
       "  'd80580992695',\n",
       "  'b856005e5ecd',\n",
       "  'b0fbe613be9d',\n",
       "  '9b351e8113e9',\n",
       "  '5d33decdf4c4',\n",
       "  'fb44e21903f3'],\n",
       " '02af2813611b': ['76398be9016',\n",
       "  'b856005e5ecd',\n",
       "  '9b351e8113e9',\n",
       "  '37a2cbe8bd15'],\n",
       " '02b5114c779a': ['76398be9016',\n",
       "  'b856005e5ecd',\n",
       "  '14176fcb5743',\n",
       "  '9b351e8113e9',\n",
       "  '8c8e5b7182ef',\n",
       "  '37a2cbe8bd15',\n",
       "  'fb44e21903f3'],\n",
       " '02d65605dc46': ['76398be9016',\n",
       "  '9b351e8113e9',\n",
       "  '37a2cbe8bd15',\n",
       "  'fb44e21903f3'],\n",
       " ...}"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "followers_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert follower dictionary to json\n",
    "follower_json = json.dumps(followers_dict)\n",
    "\n",
    "with open('follower_info.json', 'w') as json_file:\n",
    "\tjson_file.write(follower_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'type': 'service_account',\n",
       " 'project_id': 'dds-project-group8',\n",
       " 'private_key_id': 'eb665cf6f28905cc6711ccf67dc00d2aaa7fe552',\n",
       " 'private_key': '-----BEGIN PRIVATE KEY-----\\nMIIEvgIBADANBgkqhkiG9w0BAQEFAASCBKgwggSkAgEAAoIBAQDt99V4tV728tZ/\\nvCVdxtEQOBjBxb/xB9WT1q9+T8PyPswQUCuA6inXuNRPLy3T1b3b2whFskomYieX\\nJFXV5iLLWkVJytjhgRIwXdkKR+wa3yod3zkBwReFOrTPpWK1c7aTZ0mTkWhU2b/U\\n/l3Mj0doQBiCFH+YADpnhlg2oHjWhN2etk+YKANNkVFe1gUD/vVuMWu0Rbd4NEJR\\nBexxcUAu/oQ8YdCjUhId/NE1YDwZXpzSwyDJlCki/N9re32ccPKqLtdQyEpHpnZ6\\no8sRj/br3U4y9IaVvwobVmshNOU9aNrU0StiujnSUeoVdyj/jMtgt9mqLN3x7F5k\\nirPdk3JXAgMBAAECggEALlX4mhVu1VT5kUu4Vuc0pBzYLTrtIeitnKjL6SNs+wlh\\nQLfrkKGH3jpeFMESAlJ3Mo0WskOCDrFEFjj8AbdbBQ+huDmoO1ifiw1rCoZwodbc\\nY46okf/gLY/9zwTcEIrkfRU6jWJd10/C+50/9GndtJ3uZ73IDnfU532QRaq/fL1o\\nLRjZz/Ql6q3sdiSCM9H2noTbxujnB089DIOi4D4KPVJqsT5bY8n2Ul/KXC7oTCAo\\ntwjc1owmSm6qpQ1FfGzzBwMyfuvN74+0rzkrhb0bX+SpJclRno5hJKG5L1VyVOtG\\nqzyMT065QqenXB8JkjACyU5ytEE5vNYEj919IuHpYQKBgQD5+r9qLkphioTRb8Bz\\nOIfMtoibECkjh3razdtT4KiOdfR/fzwh/zpz2NZURLfKS9lfLmjyEqQ+2JTgI31n\\nDJhH9CurmVdQjCHMrHY1wmJTKthNB8yqQk89iV/STqGugU6AE7o2bntnb6vIzbPM\\nwnIuQNhDuqtNsaMiUwyeoXFHEQKBgQDzswehAk+fLW+ot4P6oKv4nwjsAlM5wuY2\\ntWff9y14vfDhsuo/mYh1uEdkxFZszpMWDrmOPMkFGcdoBqe21hd4GPgqxXVAXEFQ\\nLHff6x7uvhHiC3hHDblt8Q5AsWGb/vl7iz3DoG3p+Dn1ytWkZN+dUZmnA3fk6Gc3\\n0VYFVssy5wKBgA9o7bPV9q/coiNnCC4SJgzwk6s7a83M5D3owsSA7OMbUl8psMNH\\nwIqzq0K2mb3Wvyem7ME/dPCK2WKXzXs0w45r9uU1JrTIbqz3VLIrsXP/CCZ3fJ5i\\nSBA7D7UfM8hWIEi07p28Yc8Wizhttc/BjNhdFvfV4gmAEdZj2DtPKHSBAoGBAOTJ\\nxDTFraicCIMV3wLxyuG7tK2VtTq6HlVoU5/xN7BuafIKfV6+Ll2OZwBUT2sROQdx\\nRYUizfpK7GleLiA5uIjYsEu/W0fUFMFHLjd7TmwG51UXPZE/ckGkGKRlo2THqMLy\\nw0agm/AXSZrXFWGkDkdsr1sbp3ixMw41KpQSmuwrAoGBAOvnfByCTjStVNwcyOYh\\nlWv8/SRJo6/CZ1L4pLHOtkdX7WQbXKh6W1N+GLbN47EFCtaAOUxO4i2ccdv5dii2\\nrKBc71h92Nk/8eZ4iTZ2gyUVaH1dkPPEJMaUb7Hths34iy+wkqVG2Gw+xbk9cnAr\\nzAuO7WVwq84rHM1Ji9WtKMwi\\n-----END PRIVATE KEY-----\\n',\n",
       " 'client_email': 'dds-project-grp8@dds-project-group8.iam.gserviceaccount.com',\n",
       " 'client_id': '106109559051410839528',\n",
       " 'auth_uri': 'https://accounts.google.com/o/oauth2/auth',\n",
       " 'token_uri': 'https://oauth2.googleapis.com/token',\n",
       " 'auth_provider_x509_cert_url': 'https://www.googleapis.com/oauth2/v1/certs',\n",
       " 'client_x509_cert_url': 'https://www.googleapis.com/robot/v1/metadata/x509/dds-project-grp8%40dds-project-group8.iam.gserviceaccount.com',\n",
       " 'universe_domain': 'googleapis.com'}"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('../dds-project-group8-eb665cf6f289.json', 'rb') as js_file:\n",
    "\ttest_js = json.load(js_file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Article Content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save writer-article dictionary to pickle file\n",
    "with open('./pkl_files/writer_article_info.pkl', 'rb') as wa_file:\n",
    "\tupdated_articles = pickle.load(wa_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fca9db1c7da0': [{'id': '34c195a93d41',\n",
       "   'title': 'How I Won Singapore’s GPT-4 Prompt Engineering Competition',\n",
       "   'subtitle': 'A deep dive into the strategies I learned for harnessing the power of Large Language Models (LLMs)',\n",
       "   'author': 'fca9db1c7da0',\n",
       "   'publication_id': '7f60cf5620c9',\n",
       "   'published_at': '2023-12-29 00:29:22',\n",
       "   'last_modified_at': '2024-01-29 06:15:01',\n",
       "   'tags': ['data-science',\n",
       "    'artificial-intelligence',\n",
       "    'prompt-engineering',\n",
       "    'editors-pick',\n",
       "    'technology'],\n",
       "   'topics': ['artificial-intelligence', 'data-science'],\n",
       "   'claps': 11406,\n",
       "   'voters': 2300,\n",
       "   'word_count': 5571,\n",
       "   'responses_count': 157,\n",
       "   'reading_time': 22.722641509433963,\n",
       "   'url': 'https://towardsdatascience.com/how-i-won-singapores-gpt-4-prompt-engineering-competition-34c195a93d41',\n",
       "   'unique_slug': 'how-i-won-singapores-gpt-4-prompt-engineering-competition-34c195a93d41',\n",
       "   'image_url': 'https://miro.medium.com/1*RAI4cBXe1_zaxVykHz79oA.jpeg',\n",
       "   'lang': 'en',\n",
       "   'is_series': False,\n",
       "   'is_locked': True,\n",
       "   'is_shortform': False,\n",
       "   'top_highlight': 'Use System Prompts to provide instructions that you want the LLM to remember when responding throughout the entire chat.'},\n",
       "  {'id': '8c339f8fb602',\n",
       "   'title': 'Stacked Ensembles for Advanced Predictive Modeling With H2O.ai and Optuna',\n",
       "   'subtitle': 'And how I placed top 10% in Europe’s largest machine learning competition with them!',\n",
       "   'author': 'fca9db1c7da0',\n",
       "   'publication_id': '7f60cf5620c9',\n",
       "   'published_at': '2023-12-18 16:05:44',\n",
       "   'last_modified_at': '2023-12-29 16:32:23',\n",
       "   'tags': ['machine-learning',\n",
       "    'data-science',\n",
       "    'deep-learning',\n",
       "    'ensemble-learning',\n",
       "    'python'],\n",
       "   'topics': ['machine-learning', 'data-science'],\n",
       "   'claps': 462,\n",
       "   'voters': 104,\n",
       "   'word_count': 3134,\n",
       "   'responses_count': 11,\n",
       "   'reading_time': 12.376415094339624,\n",
       "   'url': 'https://towardsdatascience.com/stacked-ensembles-for-advanced-predictive-modeling-with-h2o-ai-and-optuna-8c339f8fb602',\n",
       "   'unique_slug': 'stacked-ensembles-for-advanced-predictive-modeling-with-h2o-ai-and-optuna-8c339f8fb602',\n",
       "   'image_url': 'https://miro.medium.com/1*5FM14YZopRvGK9baJR0OtQ.png',\n",
       "   'lang': 'en',\n",
       "   'is_series': False,\n",
       "   'is_locked': True,\n",
       "   'is_shortform': False,\n",
       "   'top_highlight': ''}],\n",
       " 'e10ad955760c': [{'id': '0d11918ee0b3',\n",
       "   'title': 'Create a Stock Chatbot with your own CSV Data',\n",
       "   'subtitle': 'An Explorative Study with Python',\n",
       "   'author': 'e10ad955760c',\n",
       "   'publication_id': '32881626c9c9',\n",
       "   'published_at': '2024-02-15 05:08:49',\n",
       "   'last_modified_at': '2024-02-15 10:22:46',\n",
       "   'tags': ['programming',\n",
       "    'artificial-intelligence',\n",
       "    'data-science',\n",
       "    'technology',\n",
       "    'python'],\n",
       "   'topics': ['machine-learning', 'data-science'],\n",
       "   'claps': 67,\n",
       "   'voters': 10,\n",
       "   'word_count': 2140,\n",
       "   'responses_count': 0,\n",
       "   'reading_time': 9.275471698113208,\n",
       "   'url': 'https://medium.datadriveninvestor.com/create-a-stock-chatbot-with-your-own-csv-data-0d11918ee0b3',\n",
       "   'unique_slug': 'create-a-stock-chatbot-with-your-own-csv-data-0d11918ee0b3',\n",
       "   'image_url': 'https://miro.medium.com/0*DCZrugG03DH7dlty',\n",
       "   'lang': 'en',\n",
       "   'is_series': False,\n",
       "   'is_locked': False,\n",
       "   'is_shortform': False,\n",
       "   'top_highlight': ''},\n",
       "  {'id': 'ea2e2261fcbf',\n",
       "   'title': 'Stock Market Sentiment Prediction with OpenAI and Python',\n",
       "   'subtitle': 'An interesting exploration of the power of LLMs in stock analysis',\n",
       "   'author': 'e10ad955760c',\n",
       "   'publication_id': '5517fd7b58a6',\n",
       "   'published_at': '2024-02-04 18:46:05',\n",
       "   'last_modified_at': '2024-02-06 03:51:20',\n",
       "   'tags': ['programming',\n",
       "    'artificial-intelligence',\n",
       "    'technology',\n",
       "    'python',\n",
       "    'data-science'],\n",
       "   'topics': ['programming'],\n",
       "   'claps': 691,\n",
       "   'voters': 147,\n",
       "   'word_count': 2496,\n",
       "   'responses_count': 4,\n",
       "   'reading_time': 10.3688679245283,\n",
       "   'url': 'https://levelup.gitconnected.com/stock-market-sentiment-prediction-with-openai-and-python-ea2e2261fcbf',\n",
       "   'unique_slug': 'stock-market-sentiment-prediction-with-openai-and-python-ea2e2261fcbf',\n",
       "   'image_url': 'https://miro.medium.com/0*PDMtUUdUatJPSaZ_',\n",
       "   'lang': 'en',\n",
       "   'is_series': False,\n",
       "   'is_locked': False,\n",
       "   'is_shortform': False,\n",
       "   'top_highlight': ''},\n",
       "  {'id': '54948a3da389',\n",
       "   'title': 'Stock Price Prediction with Quantum Machine Learning in Python',\n",
       "   'subtitle': 'An overview of the challenges and opportunities',\n",
       "   'author': 'e10ad955760c',\n",
       "   'publication_id': '32881626c9c9',\n",
       "   'published_at': '2024-01-23 05:41:09',\n",
       "   'last_modified_at': '2024-02-13 13:27:06',\n",
       "   'tags': ['machine-learning',\n",
       "    'data-science',\n",
       "    'programming',\n",
       "    'artificial-intelligence',\n",
       "    'python'],\n",
       "   'topics': ['machine-learning', 'programming'],\n",
       "   'claps': 1581,\n",
       "   'voters': 332,\n",
       "   'word_count': 3687,\n",
       "   'responses_count': 21,\n",
       "   'reading_time': 16.013207547169813,\n",
       "   'url': 'https://medium.datadriveninvestor.com/stock-price-prediction-with-quantum-machine-learning-in-python-54948a3da389',\n",
       "   'unique_slug': 'stock-price-prediction-with-quantum-machine-learning-in-python-54948a3da389',\n",
       "   'image_url': 'https://miro.medium.com/0*xGjBwo2cGCdAky8J',\n",
       "   'lang': 'en',\n",
       "   'is_series': False,\n",
       "   'is_locked': False,\n",
       "   'is_shortform': False,\n",
       "   'top_highlight': \"These quantum systems (particles or circuits) do some interesting things. They can be in different states at the same time (superposition), connect in a special way (entanglement), and even go through barriers they shouldn't (tunneling).\"},\n",
       "  {'id': '750d5520b20b',\n",
       "   'title': 'Use ChatGPT to get All-Time views on your Medium Stories',\n",
       "   'subtitle': \"An untold secret to get what Medium doesn't provide to its authors\",\n",
       "   'author': 'e10ad955760c',\n",
       "   'publication_id': '5517fd7b58a6',\n",
       "   'published_at': '2024-01-23 04:00:48',\n",
       "   'last_modified_at': '2024-01-23 04:00:48',\n",
       "   'tags': ['data-science',\n",
       "    'artificial-intelligence',\n",
       "    'chatgpt',\n",
       "    'medium',\n",
       "    'blogging'],\n",
       "   'topics': ['programming'],\n",
       "   'claps': 210,\n",
       "   'voters': 12,\n",
       "   'word_count': 957,\n",
       "   'responses_count': 1,\n",
       "   'reading_time': 4.311320754716981,\n",
       "   'url': 'https://levelup.gitconnected.com/use-chatgpt-to-get-all-time-views-on-your-medium-stories-750d5520b20b',\n",
       "   'unique_slug': 'use-chatgpt-to-get-all-time-views-on-your-medium-stories-750d5520b20b',\n",
       "   'image_url': 'https://miro.medium.com/0*-LgsPM4boW7h0zGE',\n",
       "   'lang': 'en',\n",
       "   'is_series': False,\n",
       "   'is_locked': False,\n",
       "   'is_shortform': False,\n",
       "   'top_highlight': ''},\n",
       "  {'id': 'e50392d5e7f3',\n",
       "   'title': 'Implementing a Forex Hedging Strategy with Python',\n",
       "   'subtitle': 'A step-by-step guide to creating a risk-averse portfolio',\n",
       "   'author': 'e10ad955760c',\n",
       "   'publication_id': '32881626c9c9',\n",
       "   'published_at': '2024-01-14 06:06:59',\n",
       "   'last_modified_at': '2024-02-05 16:31:54',\n",
       "   'tags': ['finance', 'data-science', 'python', 'programming', 'technology'],\n",
       "   'topics': ['data-science', 'programming'],\n",
       "   'claps': 157,\n",
       "   'voters': 31,\n",
       "   'word_count': 2943,\n",
       "   'responses_count': 6,\n",
       "   'reading_time': 12.905660377358492,\n",
       "   'url': 'https://medium.datadriveninvestor.com/implementing-a-forex-hedging-strategy-with-python-e50392d5e7f3',\n",
       "   'unique_slug': 'implementing-a-forex-hedging-strategy-with-python-e50392d5e7f3',\n",
       "   'image_url': 'https://miro.medium.com/0*kPeEbruJtv9UxubJ',\n",
       "   'lang': 'en',\n",
       "   'is_series': False,\n",
       "   'is_locked': False,\n",
       "   'is_shortform': False,\n",
       "   'top_highlight': ''},\n",
       "  {'id': '4a80d94a7851',\n",
       "   'title': 'How to use Deep Learning for Real-Time Trading Decisions',\n",
       "   'subtitle': 'A hands-on guide to building a deep learning model with Python and APIs',\n",
       "   'author': 'e10ad955760c',\n",
       "   'publication_id': '5517fd7b58a6',\n",
       "   'published_at': '2024-01-09 16:01:00',\n",
       "   'last_modified_at': '2024-02-05 05:21:53',\n",
       "   'tags': ['technology',\n",
       "    'artificial-intelligence',\n",
       "    'data-science',\n",
       "    'python',\n",
       "    'programming'],\n",
       "   'topics': ['machine-learning', 'data-science'],\n",
       "   'claps': 514,\n",
       "   'voters': 111,\n",
       "   'word_count': 2891,\n",
       "   'responses_count': 5,\n",
       "   'reading_time': 11.959433962264152,\n",
       "   'url': 'https://levelup.gitconnected.com/how-to-use-deep-learning-for-real-time-trading-decisions-4a80d94a7851',\n",
       "   'unique_slug': 'how-to-use-deep-learning-for-real-time-trading-decisions-4a80d94a7851',\n",
       "   'image_url': 'https://miro.medium.com/0*1j53jWdN1Yh1UPwj',\n",
       "   'lang': 'en',\n",
       "   'is_series': False,\n",
       "   'is_locked': False,\n",
       "   'is_shortform': False,\n",
       "   'top_highlight': ''},\n",
       "  {'id': 'f566e3fdcbc5',\n",
       "   'title': 'Using AI + Dividends to Manage Risk',\n",
       "   'subtitle': 'A practical case-study using Python and APIs',\n",
       "   'author': 'e10ad955760c',\n",
       "   'publication_id': '5517fd7b58a6',\n",
       "   'published_at': '2023-12-19 13:47:41',\n",
       "   'last_modified_at': '2024-01-08 04:18:07',\n",
       "   'tags': ['data-science',\n",
       "    'artificial-intelligence',\n",
       "    'python',\n",
       "    'programming',\n",
       "    'finance'],\n",
       "   'topics': ['data-science', 'programming'],\n",
       "   'claps': 129,\n",
       "   'voters': 11,\n",
       "   'word_count': 1303,\n",
       "   'responses_count': 0,\n",
       "   'reading_time': 6.1169811320754715,\n",
       "   'url': 'https://levelup.gitconnected.com/using-ai-dividends-to-manage-risk-f566e3fdcbc5',\n",
       "   'unique_slug': 'using-ai-dividends-to-manage-risk-f566e3fdcbc5',\n",
       "   'image_url': 'https://miro.medium.com/0*yYSJhO5S8bBWDF1A',\n",
       "   'lang': 'en',\n",
       "   'is_series': False,\n",
       "   'is_locked': False,\n",
       "   'is_shortform': False,\n",
       "   'top_highlight': ''},\n",
       "  {'id': '05da6551637c',\n",
       "   'title': 'Real-Time Options Analysis with Python',\n",
       "   'subtitle': 'A Python case study to dive deep into the options realm using APIs',\n",
       "   'author': 'e10ad955760c',\n",
       "   'publication_id': '32881626c9c9',\n",
       "   'published_at': '2023-12-19 10:19:54',\n",
       "   'last_modified_at': '2023-12-19 10:23:43',\n",
       "   'tags': ['finance', 'technology', 'programming', 'data-science', 'python'],\n",
       "   'topics': ['data-science', 'programming'],\n",
       "   'claps': 366,\n",
       "   'voters': 72,\n",
       "   'word_count': 2247,\n",
       "   'responses_count': 6,\n",
       "   'reading_time': 9.312578616352202,\n",
       "   'url': 'https://medium.datadriveninvestor.com/real-time-options-analysis-with-python-05da6551637c',\n",
       "   'unique_slug': 'real-time-options-analysis-with-python-05da6551637c',\n",
       "   'image_url': 'https://miro.medium.com/0*zBAobsC5ItBX5f28',\n",
       "   'lang': 'en',\n",
       "   'is_series': False,\n",
       "   'is_locked': False,\n",
       "   'is_shortform': False,\n",
       "   'top_highlight': ''},\n",
       "  {'id': '58ed12a492dc',\n",
       "   'title': 'An Algo Trading Strategy which made +8,371%: A Python Case Study',\n",
       "   'subtitle': 'Backtesting of a simple breakout trading strategy with APIs and Python',\n",
       "   'author': 'e10ad955760c',\n",
       "   'publication_id': '5517fd7b58a6',\n",
       "   'published_at': '2023-11-28 20:54:51',\n",
       "   'last_modified_at': '2023-11-30 03:21:05',\n",
       "   'tags': ['finance', 'programming', 'python', 'data-science', 'technology'],\n",
       "   'topics': ['programming'],\n",
       "   'claps': 2814,\n",
       "   'voters': 844,\n",
       "   'word_count': 1564,\n",
       "   'responses_count': 53,\n",
       "   'reading_time': 6.85188679245283,\n",
       "   'url': 'https://levelup.gitconnected.com/an-algo-trading-strategy-which-made-8-371-a-python-case-study-58ed12a492dc',\n",
       "   'unique_slug': 'an-algo-trading-strategy-which-made-8-371-a-python-case-study-58ed12a492dc',\n",
       "   'image_url': 'https://miro.medium.com/0*NVcgICnCBFvG0gM7',\n",
       "   'lang': 'en',\n",
       "   'is_series': False,\n",
       "   'is_locked': False,\n",
       "   'is_shortform': False,\n",
       "   'top_highlight': \"Before moving to the coding part, it's essential to have a good background on the strategy we're going to build in this article. Our trading strategy follows the principle of simplicity yet a very effective breakout strategy.\"},\n",
       "  {'id': '936934fea7d0',\n",
       "   'title': 'Finding the Best Sector to Invest in using Python',\n",
       "   'subtitle': 'Navigating the task of picking the right sector using APIs',\n",
       "   'author': 'e10ad955760c',\n",
       "   'publication_id': '5517fd7b58a6',\n",
       "   'published_at': '2023-11-13 00:17:43',\n",
       "   'last_modified_at': '2023-11-13 00:17:43',\n",
       "   'tags': ['finance', 'python', 'data-science', 'programming', 'technology'],\n",
       "   'topics': ['programming'],\n",
       "   'claps': 276,\n",
       "   'voters': 49,\n",
       "   'word_count': 1043,\n",
       "   'responses_count': 4,\n",
       "   'reading_time': 4.6358490566037736,\n",
       "   'url': 'https://levelup.gitconnected.com/finding-the-best-sector-to-invest-in-using-python-936934fea7d0',\n",
       "   'unique_slug': 'finding-the-best-sector-to-invest-in-using-python-936934fea7d0',\n",
       "   'image_url': 'https://miro.medium.com/0*ldsDKhn0hLacv7S8',\n",
       "   'lang': 'en',\n",
       "   'is_series': False,\n",
       "   'is_locked': False,\n",
       "   'is_shortform': False,\n",
       "   'top_highlight': ''}],\n",
       " '76398be9016': [{'id': '5d39cff63d52',\n",
       "   'title': 'Understanding Google’s GPT Killer- The Pathways Architecture',\n",
       "   'subtitle': 'The reason why their model Bard will be much more than a language model',\n",
       "   'author': '76398be9016',\n",
       "   'publication_id': '9758482ba857',\n",
       "   'published_at': '2023-02-18 11:44:10',\n",
       "   'last_modified_at': '2023-04-27 03:18:12',\n",
       "   'tags': ['machine-learning',\n",
       "    'artificial-intelligence',\n",
       "    'technology',\n",
       "    'programming',\n",
       "    'data-science'],\n",
       "   'topics': ['artificial-intelligence', 'machine-learning'],\n",
       "   'claps': 315,\n",
       "   'voters': 70,\n",
       "   'word_count': 2156,\n",
       "   'responses_count': 4,\n",
       "   'reading_time': 9.335849056603774,\n",
       "   'url': 'https://medium.com/geekculture/understanding-googles-gpt-killer-the-pathways-architecture-5d39cff63d52',\n",
       "   'unique_slug': 'understanding-googles-gpt-killer-the-pathways-architecture-5d39cff63d52',\n",
       "   'image_url': 'https://miro.medium.com/0*TPGsdVpfJ5-bmA9Z.jpeg',\n",
       "   'lang': 'en',\n",
       "   'is_series': False,\n",
       "   'is_locked': False,\n",
       "   'is_shortform': False,\n",
       "   'top_highlight': ''},\n",
       "  {'id': '5e142b8931e6',\n",
       "   'title': 'Improve Neural Networks by using Complex Numbers',\n",
       "   'subtitle': 'Can Complex Functions be the next breakthrough in Computer Vision?',\n",
       "   'author': '76398be9016',\n",
       "   'publication_id': '9758482ba857',\n",
       "   'published_at': '2022-11-17 00:59:57',\n",
       "   'last_modified_at': '2023-04-26 21:31:16',\n",
       "   'tags': ['machine-learning',\n",
       "    'artificial-intelligence',\n",
       "    'technology',\n",
       "    'data-science',\n",
       "    'self-improvement'],\n",
       "   'topics': ['machine-learning'],\n",
       "   'claps': 577,\n",
       "   'voters': 116,\n",
       "   'word_count': 1846,\n",
       "   'responses_count': 6,\n",
       "   'reading_time': 8.466037735849056,\n",
       "   'url': 'https://medium.com/geekculture/improve-neural-networks-by-using-complex-numbers-5e142b8931e6',\n",
       "   'unique_slug': 'improve-neural-networks-by-using-complex-numbers-5e142b8931e6',\n",
       "   'image_url': 'https://miro.medium.com/1*huvbsdKFNJp45SoOcgwmHw.png',\n",
       "   'lang': 'en',\n",
       "   'is_series': False,\n",
       "   'is_locked': False,\n",
       "   'is_shortform': False,\n",
       "   'top_highlight': 'Recently, someone in my LinkedIn network shared this very interesting paper with me. Titled, \"CoShNet: A Hybrid Complex Valued Neural Network using Shearlets\", this paper proposes the use of complex functions in a hybrid neural network. If you are very confused by those words, don\\'t worry I was too. In this article, I will explain the idea of hybrid neural networks and how they can be used to improve traditional Convolutional Neural Networks. Then we will cover how using Complex Functions can be used to boost the performance of these models even further. This is going to be a very fun one.'},\n",
       "  {'id': '92296297a541',\n",
       "   'title': 'How Amazon makes Machine Learning Trustworthy',\n",
       "   'subtitle': 'With all the discussion around Bias in ChatGPT and Machine Learning, these techniques might be very helpful',\n",
       "   'author': '76398be9016',\n",
       "   'publication_id': '9758482ba857',\n",
       "   'published_at': '2022-12-12 11:48:18',\n",
       "   'last_modified_at': '2023-05-06 19:42:01',\n",
       "   'tags': ['machine-learning',\n",
       "    'artificial-intelligence',\n",
       "    'technology',\n",
       "    'data-science',\n",
       "    'programming'],\n",
       "   'topics': ['artificial-intelligence', 'machine-learning'],\n",
       "   'claps': 41,\n",
       "   'voters': 13,\n",
       "   'word_count': 1776,\n",
       "   'responses_count': 1,\n",
       "   'reading_time': 8.05188679245283,\n",
       "   'url': 'https://medium.com/geekculture/how-amazon-makes-machine-learning-trustworthy-92296297a541',\n",
       "   'unique_slug': 'how-amazon-makes-machine-learning-trustworthy-92296297a541',\n",
       "   'image_url': 'https://miro.medium.com/0*_ej-xHk4ROErgvkz',\n",
       "   'lang': 'en',\n",
       "   'is_series': False,\n",
       "   'is_locked': False,\n",
       "   'is_shortform': False,\n",
       "   'top_highlight': 'Machine Learning has swept the world recently. Thanks to all the amazing results companies have been rushing to adopt Data-Driven decision-making into their processes. Given all the amazing demos by DALLE, StableDiffusion, and now ChatGPT, more and more people are waking up to the potential of AI. However, some people have been raising concerns about the potential for harm that these models have. Recently, ChatGPT has gained some attention, because users have discovered that it can generate some spicy outputs. Take a look at how ChatGPT can identify good scientists based on their race and gender.'},\n",
       "  {'id': 'fcad692b1456',\n",
       "   'title': 'Why Tree-Based Models Beat Deep Learning on Tabular Data',\n",
       "   'subtitle': 'A much-needed reality check for AI Researchers and Engineers caught up in the hype around Deep Learning',\n",
       "   'author': '76398be9016',\n",
       "   'publication_id': '9758482ba857',\n",
       "   'published_at': '2022-08-27 00:08:15',\n",
       "   'last_modified_at': '2023-05-01 22:04:24',\n",
       "   'tags': ['data-science',\n",
       "    'artificial-intelligence',\n",
       "    'machine-learning',\n",
       "    'technology',\n",
       "    'programming'],\n",
       "   'topics': ['artificial-intelligence', 'machine-learning', 'data-science'],\n",
       "   'claps': 609,\n",
       "   'voters': 179,\n",
       "   'word_count': 1691,\n",
       "   'responses_count': 5,\n",
       "   'reading_time': 7.581132075471698,\n",
       "   'url': 'https://medium.com/geekculture/why-tree-based-models-beat-deep-learning-on-tabular-data-fcad692b1456',\n",
       "   'unique_slug': 'why-tree-based-models-beat-deep-learning-on-tabular-data-fcad692b1456',\n",
       "   'image_url': 'https://miro.medium.com/1*TXcH3Sgw-prj4DrM0GUmWQ.png',\n",
       "   'lang': 'en',\n",
       "   'is_series': False,\n",
       "   'is_locked': False,\n",
       "   'is_shortform': False,\n",
       "   'top_highlight': \"This was the first reason that the authors shared that Deep Learning Neural Networks couldn't compete with Random Forests. Simply put, when it comes to non-smooth functions/decision boundaries, Neural Networks struggle to create the best-fit functions. Random Forests do much better with weird/jagged/irregular patterns.\"},\n",
       "  {'id': '9ef2ea904986',\n",
       "   'title': 'How to learn Machine Learning in 2022',\n",
       "   'subtitle': 'A step by step guide to getting into machine learning',\n",
       "   'author': '76398be9016',\n",
       "   'publication_id': '9758482ba857',\n",
       "   'published_at': '2022-01-20 21:23:05',\n",
       "   'last_modified_at': '2022-12-11 22:13:47',\n",
       "   'tags': ['machine-learning',\n",
       "    'artificial-intelligence',\n",
       "    'data-science',\n",
       "    'programming',\n",
       "    'technology'],\n",
       "   'topics': ['machine-learning'],\n",
       "   'claps': 236,\n",
       "   'voters': 69,\n",
       "   'word_count': 1426,\n",
       "   'responses_count': 3,\n",
       "   'reading_time': 6.431132075471698,\n",
       "   'url': 'https://medium.com/geekculture/how-to-learn-machine-learning-in-2022-9ef2ea904986',\n",
       "   'unique_slug': 'how-to-learn-machine-learning-in-2022-9ef2ea904986',\n",
       "   'image_url': 'https://miro.medium.com/1*18fasTe1sOKBcDoyYY5Nbw.png',\n",
       "   'lang': 'en',\n",
       "   'is_series': False,\n",
       "   'is_locked': False,\n",
       "   'is_shortform': False,\n",
       "   'top_highlight': ''},\n",
       "  {'id': 'bf4cb36751ea',\n",
       "   'title': 'Why some CEOs hate Remote Work',\n",
       "   'subtitle': 'Is it truly a lack of productivity or is it something more?',\n",
       "   'author': '76398be9016',\n",
       "   'publication_id': '32881626c9c9',\n",
       "   'published_at': '2024-02-17 06:42:03',\n",
       "   'last_modified_at': '2024-02-18 09:45:38',\n",
       "   'tags': ['business',\n",
       "    'technology',\n",
       "    'programming',\n",
       "    'software-development',\n",
       "    'culture'],\n",
       "   'topics': ['work'],\n",
       "   'claps': 242,\n",
       "   'voters': 9,\n",
       "   'word_count': 1072,\n",
       "   'responses_count': 0,\n",
       "   'reading_time': 4.595283018867924,\n",
       "   'url': 'https://medium.datadriveninvestor.com/why-some-ceos-hate-remote-work-bf4cb36751ea',\n",
       "   'unique_slug': 'why-some-ceos-hate-remote-work-bf4cb36751ea',\n",
       "   'image_url': 'https://miro.medium.com/0*00ERjm7K0uAn-blF.jpeg',\n",
       "   'lang': 'en',\n",
       "   'is_series': False,\n",
       "   'is_locked': False,\n",
       "   'is_shortform': False,\n",
       "   'top_highlight': 'The remote work vs in-person debate seems to be more divisive than ever.'},\n",
       "  {'id': '7b104513834e',\n",
       "   'title': 'Google’s High-Performance Computing Expert shares his thoughts on how to use AI',\n",
       "   'subtitle': 'Partnering with AI to reimagine problem-solving: the ‘intelligence’ that is artificial may be our own',\n",
       "   'author': '76398be9016',\n",
       "   'publication_id': '*Self-Published*',\n",
       "   'published_at': '2024-02-15 17:11:21',\n",
       "   'last_modified_at': '2024-02-15 17:11:21',\n",
       "   'tags': ['machine-learning',\n",
       "    'technology',\n",
       "    'artificial-intelligence',\n",
       "    'data-science',\n",
       "    'philosophy'],\n",
       "   'topics': ['artificial-intelligence'],\n",
       "   'claps': 2,\n",
       "   'voters': 2,\n",
       "   'word_count': 3079,\n",
       "   'responses_count': 0,\n",
       "   'reading_time': 12.002201257861635,\n",
       "   'url': 'https://machine-learning-made-simple.medium.com/googles-high-performance-computing-expert-shares-his-thoughts-on-how-to-use-ai-7b104513834e',\n",
       "   'unique_slug': 'googles-high-performance-computing-expert-shares-his-thoughts-on-how-to-use-ai-7b104513834e',\n",
       "   'image_url': 'https://miro.medium.com/1*b9LTaujSPgYWZL-qD3Zf1Q.jpeg',\n",
       "   'lang': 'en',\n",
       "   'is_series': False,\n",
       "   'is_locked': False,\n",
       "   'is_shortform': False,\n",
       "   'top_highlight': ''},\n",
       "  {'id': 'cd3a824ba81f',\n",
       "   'title': 'Interesting Content in AI, Software, Business, and Tech- 02/14/2024',\n",
       "   'subtitle': 'Content to help you keep up with Machine Learning, Deep Learning, Data Science, Software Engineering, Finance, Business, and more',\n",
       "   'author': '76398be9016',\n",
       "   'publication_id': '*Self-Published*',\n",
       "   'published_at': '2024-02-14 19:33:45',\n",
       "   'last_modified_at': '2024-02-14 19:33:45',\n",
       "   'tags': ['machine-learning',\n",
       "    'artificial-intelligence',\n",
       "    'software-development',\n",
       "    'technology',\n",
       "    'business'],\n",
       "   'topics': ['artificial-intelligence', 'programming'],\n",
       "   'claps': 62,\n",
       "   'voters': 7,\n",
       "   'word_count': 2592,\n",
       "   'responses_count': 0,\n",
       "   'reading_time': 10.331132075471698,\n",
       "   'url': 'https://machine-learning-made-simple.medium.com/interesting-content-in-ai-software-business-and-tech-02-14-2024-cd3a824ba81f',\n",
       "   'unique_slug': 'interesting-content-in-ai-software-business-and-tech-02-14-2024-cd3a824ba81f',\n",
       "   'image_url': 'https://miro.medium.com/1*b9LTaujSPgYWZL-qD3Zf1Q.jpeg',\n",
       "   'lang': 'en',\n",
       "   'is_series': False,\n",
       "   'is_locked': False,\n",
       "   'is_shortform': False,\n",
       "   'top_highlight': ''},\n",
       "  {'id': '68896a42b991',\n",
       "   'title': 'Understanding Space-Based Architecture for efficient Data Processing',\n",
       "   'subtitle': 'A possible game-changer for edge AI, real-time supply chain analysis, and more',\n",
       "   'author': '76398be9016',\n",
       "   'publication_id': '*Self-Published*',\n",
       "   'published_at': '2024-02-12 06:10:32',\n",
       "   'last_modified_at': '2024-02-12 06:10:32',\n",
       "   'tags': ['machine-learning',\n",
       "    'artificial-intelligence',\n",
       "    'data-science',\n",
       "    'technology',\n",
       "    'programming'],\n",
       "   'topics': ['machine-learning', 'data-science', 'programming'],\n",
       "   'claps': 143,\n",
       "   'voters': 5,\n",
       "   'word_count': 1519,\n",
       "   'responses_count': 0,\n",
       "   'reading_time': 6.5654088050314465,\n",
       "   'url': 'https://machine-learning-made-simple.medium.com/understanding-space-based-architecture-for-efficient-data-processing-68896a42b991',\n",
       "   'unique_slug': 'understanding-space-based-architecture-for-efficient-data-processing-68896a42b991',\n",
       "   'image_url': 'https://miro.medium.com/0*DNzgMaNXu8TWw4zj.png',\n",
       "   'lang': 'en',\n",
       "   'is_series': False,\n",
       "   'is_locked': False,\n",
       "   'is_shortform': False,\n",
       "   'top_highlight': ''},\n",
       "  {'id': '5204dd12bc73',\n",
       "   'title': 'Why Data is an Incomplete Representation of Reality',\n",
       "   'subtitle': 'A look at some major limitations of Data',\n",
       "   'author': '76398be9016',\n",
       "   'publication_id': '*Self-Published*',\n",
       "   'published_at': '2024-02-10 01:37:21',\n",
       "   'last_modified_at': '2024-02-10 01:37:21',\n",
       "   'tags': ['machine-learning',\n",
       "    'artificial-intelligence',\n",
       "    'technology',\n",
       "    'data-science',\n",
       "    'mathematics'],\n",
       "   'topics': ['artificial-intelligence'],\n",
       "   'claps': 336,\n",
       "   'voters': 18,\n",
       "   'word_count': 4016,\n",
       "   'responses_count': 2,\n",
       "   'reading_time': 16.28805031446541,\n",
       "   'url': 'https://machine-learning-made-simple.medium.com/why-data-is-an-incomplete-representation-of-reality-5204dd12bc73',\n",
       "   'unique_slug': 'why-data-is-an-incomplete-representation-of-reality-5204dd12bc73',\n",
       "   'image_url': 'https://miro.medium.com/0*WQ0fY_kNLiVHfH0E.png',\n",
       "   'lang': 'en',\n",
       "   'is_series': False,\n",
       "   'is_locked': False,\n",
       "   'is_shortform': False,\n",
       "   'top_highlight': ''}],\n",
       " 'd80580992695': [{'id': '6a7ab0b04d35',\n",
       "   'title': 'Don’t use loc/iloc with Loops In Python, Instead, Use This!',\n",
       "   'subtitle': 'Run your loops at a 60X faster speed',\n",
       "   'author': 'd80580992695',\n",
       "   'publication_id': '29038077e4c6',\n",
       "   'published_at': '2024-01-24 01:46:17',\n",
       "   'last_modified_at': '2024-01-30 10:42:58',\n",
       "   'tags': ['python',\n",
       "    'data-science',\n",
       "    'data-analysis',\n",
       "    'programming',\n",
       "    'loops-in-python'],\n",
       "   'topics': ['data-science', 'programming'],\n",
       "   'claps': 1311,\n",
       "   'voters': 331,\n",
       "   'word_count': 679,\n",
       "   'responses_count': 10,\n",
       "   'reading_time': 2.9455974842767296,\n",
       "   'url': 'https://medium.com/codex/dont-use-loc-iloc-with-loops-in-python-instead-use-this-6a7ab0b04d35',\n",
       "   'unique_slug': 'dont-use-loc-iloc-with-loops-in-python-instead-use-this-6a7ab0b04d35',\n",
       "   'image_url': 'https://miro.medium.com/1*SyvWzmE0YT19onb4ODlYrw.jpeg',\n",
       "   'lang': 'en',\n",
       "   'is_series': False,\n",
       "   'is_locked': True,\n",
       "   'is_shortform': False,\n",
       "   'top_highlight': 'loc and iloc are meant to access multiple elements(series/dataframe) at the same time, potentially to perform vectorized operations.'},\n",
       "  {'id': 'e8b0172b9581',\n",
       "   'title': 'Say Goodbye to Loops in Python, and Welcome Vectorization!',\n",
       "   'subtitle': 'Use Vectorization\\u200a—\\u200aa super-fast alternative to loops in Python',\n",
       "   'author': 'd80580992695',\n",
       "   'publication_id': '29038077e4c6',\n",
       "   'published_at': '2023-12-28 02:01:32',\n",
       "   'last_modified_at': '2023-12-29 08:28:02',\n",
       "   'tags': ['data-science',\n",
       "    'programming',\n",
       "    'python',\n",
       "    'data-analysis',\n",
       "    'python-programming'],\n",
       "   'topics': ['data-science', 'programming'],\n",
       "   'claps': 4313,\n",
       "   'voters': 1310,\n",
       "   'word_count': 966,\n",
       "   'responses_count': 55,\n",
       "   'reading_time': 4.595283018867924,\n",
       "   'url': 'https://medium.com/codex/say-goodbye-to-loops-in-python-and-welcome-vectorization-e8b0172b9581',\n",
       "   'unique_slug': 'say-goodbye-to-loops-in-python-and-welcome-vectorization-e8b0172b9581',\n",
       "   'image_url': 'https://miro.medium.com/0*OMVt9wKbfIPJIB_5.jpeg',\n",
       "   'lang': 'en',\n",
       "   'is_series': False,\n",
       "   'is_locked': True,\n",
       "   'is_shortform': False,\n",
       "   'top_highlight': \"Vectorization is the technique of implementing (NumPy) array operations on a dataset. In the background, it applies the operations to all the elements of an array or series in one go (unlike a 'for' loop that manipulates one row at a time).\"},\n",
       "  {'id': '792181d2464a',\n",
       "   'title': 'Top 10 Data Visualizations of 2023 Worth Looking at!',\n",
       "   'subtitle': 'Level Up Your Visualization Game!',\n",
       "   'author': 'd80580992695',\n",
       "   'publication_id': '29038077e4c6',\n",
       "   'published_at': '2023-12-27 01:01:42',\n",
       "   'last_modified_at': '2023-12-29 08:28:09',\n",
       "   'tags': ['data-science',\n",
       "    'data-visualization',\n",
       "    'data',\n",
       "    'visualization',\n",
       "    'data-analysis'],\n",
       "   'topics': ['data-science'],\n",
       "   'claps': 993,\n",
       "   'voters': 297,\n",
       "   'word_count': 794,\n",
       "   'responses_count': 13,\n",
       "   'reading_time': 3.1962264150943396,\n",
       "   'url': 'https://medium.com/codex/top-10-data-visualizations-of-2023-worth-looking-at-792181d2464a',\n",
       "   'unique_slug': 'top-10-data-visualizations-of-2023-worth-looking-at-792181d2464a',\n",
       "   'image_url': 'https://miro.medium.com/1*qcQcxcTncHwVMBExIY5oZg.png',\n",
       "   'lang': 'en',\n",
       "   'is_series': False,\n",
       "   'is_locked': True,\n",
       "   'is_shortform': False,\n",
       "   'top_highlight': ''},\n",
       "  {'id': 'cb7975befa53',\n",
       "   'title': 'Follow this 10-Step Template for an Awesome Data Analysis!',\n",
       "   'subtitle': 'Pic Credit: Unsplash',\n",
       "   'author': 'd80580992695',\n",
       "   'publication_id': '78073def27b8',\n",
       "   'published_at': '2023-09-21 01:02:53',\n",
       "   'last_modified_at': '2024-01-27 19:11:28',\n",
       "   'tags': ['data-analysis',\n",
       "    'data-science',\n",
       "    'data-visualization',\n",
       "    'python',\n",
       "    'programming'],\n",
       "   'topics': ['data-science'],\n",
       "   'claps': 553,\n",
       "   'voters': 100,\n",
       "   'word_count': 1106,\n",
       "   'responses_count': 4,\n",
       "   'reading_time': 5.473584905660378,\n",
       "   'url': 'https://python.plainenglish.io/follow-this-10-step-template-for-an-awesome-data-analysis-cb7975befa53',\n",
       "   'unique_slug': 'follow-this-10-step-template-for-an-awesome-data-analysis-cb7975befa53',\n",
       "   'image_url': 'https://miro.medium.com/1*jwsGPNhgEMmjIaKH4u2HcA.jpeg',\n",
       "   'lang': 'en',\n",
       "   'is_series': False,\n",
       "   'is_locked': False,\n",
       "   'is_shortform': False,\n",
       "   'top_highlight': ''},\n",
       "  {'id': 'd30fa1b701f6',\n",
       "   'title': 'Don’t Start Your SQL Queries with the ‘Select’ Statement',\n",
       "   'subtitle': 'Follow this right approach to write your SQL queries',\n",
       "   'author': 'd80580992695',\n",
       "   'publication_id': '7f60cf5620c9',\n",
       "   'published_at': '2022-12-05 23:31:35',\n",
       "   'last_modified_at': '2022-12-08 20:35:19',\n",
       "   'tags': ['sql',\n",
       "    'programming',\n",
       "    'data-science',\n",
       "    'data-analysis',\n",
       "    'relational-databases'],\n",
       "   'topics': ['data-science', 'programming'],\n",
       "   'claps': 1921,\n",
       "   'voters': 569,\n",
       "   'word_count': 876,\n",
       "   'responses_count': 41,\n",
       "   'reading_time': 4.3556603773584905,\n",
       "   'url': 'https://towardsdatascience.com/dont-start-your-sql-queries-with-select-clause-d30fa1b701f6',\n",
       "   'unique_slug': 'dont-start-your-sql-queries-with-select-clause-d30fa1b701f6',\n",
       "   'image_url': 'https://miro.medium.com/1*ok4j2wjoNtVrYKhpENbgGw.jpeg',\n",
       "   'lang': 'en',\n",
       "   'is_series': False,\n",
       "   'is_locked': True,\n",
       "   'is_shortform': False,\n",
       "   'top_highlight': \"Don't Start Your SQL Queries with the 'Select' Statement\"},\n",
       "  {'id': 'a97c4639c183',\n",
       "   'title': 'Don’t Write Another Line Of Code In Python Until You’ve Seen These Mistakes!',\n",
       "   'subtitle': 'Let’s start writing cleaner codes in Python',\n",
       "   'author': 'd80580992695',\n",
       "   'publication_id': '*Self-Published*',\n",
       "   'published_at': '2024-02-13 01:47:25',\n",
       "   'last_modified_at': '2024-02-13 01:47:25',\n",
       "   'tags': ['python', 'programming', 'data-science', 'analytics', 'coding'],\n",
       "   'topics': ['programming'],\n",
       "   'claps': 151,\n",
       "   'voters': 16,\n",
       "   'word_count': 757,\n",
       "   'responses_count': 2,\n",
       "   'reading_time': 3.056603773584906,\n",
       "   'url': 'https://anmol3015.medium.com/dont-write-another-line-of-code-in-python-until-you-ve-seen-these-mistakes-a97c4639c183',\n",
       "   'unique_slug': 'dont-write-another-line-of-code-in-python-until-you-ve-seen-these-mistakes-a97c4639c183',\n",
       "   'image_url': 'https://miro.medium.com/1*VBK3top74w5boIFOeOOtNw.jpeg',\n",
       "   'lang': 'en',\n",
       "   'is_series': False,\n",
       "   'is_locked': True,\n",
       "   'is_shortform': False,\n",
       "   'top_highlight': ''},\n",
       "  {'id': 'b0935bf96ee2',\n",
       "   'title': 'Pandas Crash Course: Top 30 Functions for ANY Data Analysis',\n",
       "   'subtitle': 'Become a Pro in using Pandas for Data Science',\n",
       "   'author': 'd80580992695',\n",
       "   'publication_id': '*Self-Published*',\n",
       "   'published_at': '2024-02-06 01:47:21',\n",
       "   'last_modified_at': '2024-02-06 01:47:21',\n",
       "   'tags': ['python',\n",
       "    'pandas',\n",
       "    'data-science',\n",
       "    'data-analysis',\n",
       "    'programming'],\n",
       "   'topics': ['data-science', 'programming'],\n",
       "   'claps': 421,\n",
       "   'voters': 63,\n",
       "   'word_count': 1271,\n",
       "   'responses_count': 3,\n",
       "   'reading_time': 7.046226415094339,\n",
       "   'url': 'https://anmol3015.medium.com/pandas-crash-course-top-30-functions-for-any-data-analysis-b0935bf96ee2',\n",
       "   'unique_slug': 'pandas-crash-course-top-30-functions-for-any-data-analysis-b0935bf96ee2',\n",
       "   'image_url': 'https://miro.medium.com/1*VBK3top74w5boIFOeOOtNw.jpeg',\n",
       "   'lang': 'en',\n",
       "   'is_series': False,\n",
       "   'is_locked': True,\n",
       "   'is_shortform': False,\n",
       "   'top_highlight': ''},\n",
       "  {'id': '68ffa12f8885',\n",
       "   'title': 'Data Visualization Tips to have a long-lasting Impact on Your Audience',\n",
       "   'subtitle': 'Let’s start with the Bar Chart',\n",
       "   'author': 'd80580992695',\n",
       "   'publication_id': '*Self-Published*',\n",
       "   'published_at': '2024-01-30 01:52:20',\n",
       "   'last_modified_at': '2024-01-30 14:39:16',\n",
       "   'tags': ['data-visualization',\n",
       "    'data-science',\n",
       "    'data',\n",
       "    'visualization',\n",
       "    'data-analysis'],\n",
       "   'topics': ['data-science'],\n",
       "   'claps': 126,\n",
       "   'voters': 28,\n",
       "   'word_count': 736,\n",
       "   'responses_count': 1,\n",
       "   'reading_time': 3.827358490566038,\n",
       "   'url': 'https://anmol3015.medium.com/data-visualization-tips-to-have-a-long-lasting-impact-on-your-audience-68ffa12f8885',\n",
       "   'unique_slug': 'data-visualization-tips-to-have-a-long-lasting-impact-on-your-audience-68ffa12f8885',\n",
       "   'image_url': 'https://miro.medium.com/1*NhCWYLw5Qd0o8vYZA6lyKA.png',\n",
       "   'lang': 'en',\n",
       "   'is_series': False,\n",
       "   'is_locked': True,\n",
       "   'is_shortform': False,\n",
       "   'top_highlight': ''},\n",
       "  {'id': '81909c97e7d2',\n",
       "   'title': 'Don’t Underestimate the Power of Matplotlib, It can create Animations Too!',\n",
       "   'subtitle': 'The untapped potential of matplotlib',\n",
       "   'author': 'd80580992695',\n",
       "   'publication_id': '29038077e4c6',\n",
       "   'published_at': '2024-01-17 01:32:14',\n",
       "   'last_modified_at': '2024-01-24 12:29:53',\n",
       "   'tags': ['python-programming',\n",
       "    'python',\n",
       "    'visualization',\n",
       "    'data-science',\n",
       "    'data-visualization'],\n",
       "   'topics': ['data-science', 'programming'],\n",
       "   'claps': 147,\n",
       "   'voters': 37,\n",
       "   'word_count': 836,\n",
       "   'responses_count': 2,\n",
       "   'reading_time': 3.988050314465409,\n",
       "   'url': 'https://medium.com/codex/dont-underestimate-the-power-of-matplotlib-it-can-create-animations-too-81909c97e7d2',\n",
       "   'unique_slug': 'dont-underestimate-the-power-of-matplotlib-it-can-create-animations-too-81909c97e7d2',\n",
       "   'image_url': 'https://miro.medium.com/1*Zg5A9B0Mr8cTE5a8u7N7_A.jpeg',\n",
       "   'lang': 'en',\n",
       "   'is_series': False,\n",
       "   'is_locked': True,\n",
       "   'is_shortform': False,\n",
       "   'top_highlight': ''},\n",
       "  {'id': 'f4104ce25e0b',\n",
       "   'title': 'Top 10 coding mistakes committed by Data Scientists\\u200a—\\u200aA Dramatic Version',\n",
       "   'subtitle': 'Hey there, fellow Data Scientists! Let’s spill the tea on some common mistakes we data scientists tend to do while dancing with the code…',\n",
       "   'author': 'd80580992695',\n",
       "   'publication_id': '29038077e4c6',\n",
       "   'published_at': '2023-12-25 01:01:37',\n",
       "   'last_modified_at': '2024-01-01 08:33:33',\n",
       "   'tags': ['data-science', 'data', 'python', 'data-analysis'],\n",
       "   'topics': ['data-science'],\n",
       "   'claps': 50,\n",
       "   'voters': 18,\n",
       "   'word_count': 898,\n",
       "   'responses_count': 2,\n",
       "   'reading_time': 3.588679245283019,\n",
       "   'url': 'https://medium.com/codex/top-10-coding-mistakes-committed-by-data-scientists-a-dramatic-version-f4104ce25e0b',\n",
       "   'unique_slug': 'top-10-coding-mistakes-committed-by-data-scientists-a-dramatic-version-f4104ce25e0b',\n",
       "   'image_url': 'https://miro.medium.com/1*BeHAZ9ATRAfXS5RLRJD1ZQ.jpeg',\n",
       "   'lang': 'en',\n",
       "   'is_series': False,\n",
       "   'is_locked': True,\n",
       "   'is_shortform': False,\n",
       "   'top_highlight': ''}],\n",
       " '8a910484fe84': [{'id': '0f27c5684804',\n",
       "   'title': 'Want to be Rich? DON’T Start a Side Hustle.',\n",
       "   'subtitle': 'Why Side Hustles Won’t Transform Your Life, But This Five-Step Formula Will',\n",
       "   'author': '8a910484fe84',\n",
       "   'publication_id': '*Self-Published*',\n",
       "   'published_at': '2023-12-03 22:29:33',\n",
       "   'last_modified_at': '2024-01-06 16:38:33',\n",
       "   'tags': ['side-hustle',\n",
       "    'business',\n",
       "    'entrepreneurship',\n",
       "    'make-money-online',\n",
       "    'marketing'],\n",
       "   'topics': ['startups'],\n",
       "   'claps': 244,\n",
       "   'voters': 30,\n",
       "   'word_count': 791,\n",
       "   'responses_count': 8,\n",
       "   'reading_time': 3.368238993710692,\n",
       "   'url': 'https://medium.com/@moneytent/want-to-be-rich-dont-start-a-side-hustle-0f27c5684804',\n",
       "   'unique_slug': 'want-to-be-rich-dont-start-a-side-hustle-0f27c5684804',\n",
       "   'image_url': 'https://miro.medium.com/1*th_mKOVG4094x6gq7xlF8w.png',\n",
       "   'lang': 'en',\n",
       "   'is_series': False,\n",
       "   'is_locked': False,\n",
       "   'is_shortform': False,\n",
       "   'top_highlight': \"You can't, not yet. Create the Minimum Viable Product (MVP), the simplest version of your solution.\"},\n",
       "  {'id': 'fe0a5a72bed5',\n",
       "   'title': 'The New AI Side Hustle That’s Making $1,579+/Day',\n",
       "   'subtitle': 'Unlocking a Goldmine: The Underrated AI Side Hustle',\n",
       "   'author': '8a910484fe84',\n",
       "   'publication_id': '*Self-Published*',\n",
       "   'published_at': '2024-02-02 22:01:42',\n",
       "   'last_modified_at': '2024-02-02 22:01:42',\n",
       "   'tags': ['ai',\n",
       "    'side-hustle',\n",
       "    'artificial-intelligence',\n",
       "    'make-money-online',\n",
       "    'machine-learning'],\n",
       "   'topics': ['artificial-intelligence', 'marketing'],\n",
       "   'claps': 13,\n",
       "   'voters': 5,\n",
       "   'word_count': 646,\n",
       "   'responses_count': 0,\n",
       "   'reading_time': 2.821069182389937,\n",
       "   'url': 'https://medium.com/@moneytent/the-new-ai-side-hustle-thats-making-1-579-day-fe0a5a72bed5',\n",
       "   'unique_slug': 'the-new-ai-side-hustle-thats-making-1-579-day-fe0a5a72bed5',\n",
       "   'image_url': 'https://miro.medium.com/1*CY891-DC6oRRgoZ0tA_Glw.png',\n",
       "   'lang': 'en',\n",
       "   'is_series': False,\n",
       "   'is_locked': False,\n",
       "   'is_shortform': False,\n",
       "   'top_highlight': ''},\n",
       "  {'id': '16e93bc3cb05',\n",
       "   'title': 'Top AI tools for UI Designers',\n",
       "   'subtitle': 'Leveraging AI in UI/UX Design: A Creative Revolution',\n",
       "   'author': '8a910484fe84',\n",
       "   'publication_id': '*Self-Published*',\n",
       "   'published_at': '2024-02-02 21:01:42',\n",
       "   'last_modified_at': '2024-02-02 21:01:42',\n",
       "   'tags': ['ui', 'ui-design', 'ai', 'artificial-intelligence', 'ai-tools'],\n",
       "   'topics': ['design'],\n",
       "   'claps': 6,\n",
       "   'voters': 1,\n",
       "   'word_count': 881,\n",
       "   'responses_count': 0,\n",
       "   'reading_time': 3.7078616352201257,\n",
       "   'url': 'https://medium.com/@moneytent/top-ai-tools-for-ui-designers-16e93bc3cb05',\n",
       "   'unique_slug': 'top-ai-tools-for-ui-designers-16e93bc3cb05',\n",
       "   'image_url': 'https://miro.medium.com/1*npLf3N72udSPw7mlAfi6Aw.png',\n",
       "   'lang': 'en',\n",
       "   'is_series': False,\n",
       "   'is_locked': False,\n",
       "   'is_shortform': False,\n",
       "   'top_highlight': ''},\n",
       "  {'id': '63eba8ec76a1',\n",
       "   'title': 'BEST AI Tools for Content Creators in 2024!',\n",
       "   'subtitle': 'Harnessing the Power of AI for Unparalleled Content Creation',\n",
       "   'author': '8a910484fe84',\n",
       "   'publication_id': '*Self-Published*',\n",
       "   'published_at': '2024-02-02 20:01:01',\n",
       "   'last_modified_at': '2024-02-02 20:01:01',\n",
       "   'tags': ['ai',\n",
       "    'content-creation',\n",
       "    'artificial-intelligence',\n",
       "    'youtube',\n",
       "    'machine-learning'],\n",
       "   'topics': ['artificial-intelligence'],\n",
       "   'claps': 26,\n",
       "   'voters': 4,\n",
       "   'word_count': 685,\n",
       "   'responses_count': 0,\n",
       "   'reading_time': 2.968238993710692,\n",
       "   'url': 'https://medium.com/@moneytent/best-ai-tools-for-content-creators-in-2024-63eba8ec76a1',\n",
       "   'unique_slug': 'best-ai-tools-for-content-creators-in-2024-63eba8ec76a1',\n",
       "   'image_url': 'https://miro.medium.com/1*t7NwUxee8giAMPWqdIFqJA.png',\n",
       "   'lang': 'en',\n",
       "   'is_series': False,\n",
       "   'is_locked': False,\n",
       "   'is_shortform': False,\n",
       "   'top_highlight': ''},\n",
       "  {'id': 'e1e04de813a0',\n",
       "   'title': 'How To Build a Website FAST Using AI',\n",
       "   'subtitle': 'Dive into the Future of Web Design\\u200a—\\u200aEffortless, Quick, and Tailored to Your Brand with AI',\n",
       "   'author': '8a910484fe84',\n",
       "   'publication_id': '*Self-Published*',\n",
       "   'published_at': '2024-02-02 19:01:40',\n",
       "   'last_modified_at': '2024-02-02 19:01:40',\n",
       "   'tags': ['website',\n",
       "    'ai',\n",
       "    'artificial-intelligence',\n",
       "    'machine-learning',\n",
       "    'no-code'],\n",
       "   'topics': ['marketing', 'design'],\n",
       "   'claps': 7,\n",
       "   'voters': 1,\n",
       "   'word_count': 794,\n",
       "   'responses_count': 0,\n",
       "   'reading_time': 3.3795597484276727,\n",
       "   'url': 'https://medium.com/@moneytent/how-to-build-a-website-fast-using-ai-e1e04de813a0',\n",
       "   'unique_slug': 'how-to-build-a-website-fast-using-ai-e1e04de813a0',\n",
       "   'image_url': 'https://miro.medium.com/1*6k1FnAPWYG52bRsZOGIhYA.png',\n",
       "   'lang': 'en',\n",
       "   'is_series': False,\n",
       "   'is_locked': False,\n",
       "   'is_shortform': False,\n",
       "   'top_highlight': ''},\n",
       "  {'id': 'c6a008a4fb67',\n",
       "   'title': 'Making AI Mobile App Using One Tool For FREE!',\n",
       "   'subtitle': 'Embracing the No-Code Revolution: Crafting Digital Dreams Without Coding',\n",
       "   'author': '8a910484fe84',\n",
       "   'publication_id': '*Self-Published*',\n",
       "   'published_at': '2024-02-02 18:01:53',\n",
       "   'last_modified_at': '2024-02-02 18:01:53',\n",
       "   'tags': ['ai',\n",
       "    'apps',\n",
       "    'artificial-intelligence',\n",
       "    'ai-tools',\n",
       "    'mobile-app-development'],\n",
       "   'topics': ['artificial-intelligence'],\n",
       "   'claps': 9,\n",
       "   'voters': 2,\n",
       "   'word_count': 807,\n",
       "   'responses_count': 0,\n",
       "   'reading_time': 3.428616352201258,\n",
       "   'url': 'https://medium.com/@moneytent/making-ai-mobile-app-using-one-tool-for-free-c6a008a4fb67',\n",
       "   'unique_slug': 'making-ai-mobile-app-using-one-tool-for-free-c6a008a4fb67',\n",
       "   'image_url': 'https://miro.medium.com/1*VvGvvUL8RVPPMV-DextZ_w.png',\n",
       "   'lang': 'en',\n",
       "   'is_series': False,\n",
       "   'is_locked': False,\n",
       "   'is_shortform': False,\n",
       "   'top_highlight': ''},\n",
       "  {'id': '914c14819bcf',\n",
       "   'title': 'This Free ChatGPT SEO Script Is Worth Millions',\n",
       "   'subtitle': 'Transforming a YouTube Script into a Captivating Medium Article',\n",
       "   'author': '8a910484fe84',\n",
       "   'publication_id': '*Self-Published*',\n",
       "   'published_at': '2024-02-02 17:02:00',\n",
       "   'last_modified_at': '2024-02-02 17:02:00',\n",
       "   'tags': ['chatgpt', 'seo', 'ai', 'artificial-intelligence', 'script'],\n",
       "   'topics': ['programming'],\n",
       "   'claps': 2,\n",
       "   'voters': 2,\n",
       "   'word_count': 744,\n",
       "   'responses_count': 0,\n",
       "   'reading_time': 3.190880503144654,\n",
       "   'url': 'https://medium.com/@moneytent/this-free-chatgpt-seo-script-is-worth-millions-914c14819bcf',\n",
       "   'unique_slug': 'this-free-chatgpt-seo-script-is-worth-millions-914c14819bcf',\n",
       "   'image_url': 'https://miro.medium.com/1*S9B7W4HAhxAdazIrjnY0Kg.png',\n",
       "   'lang': 'en',\n",
       "   'is_series': False,\n",
       "   'is_locked': False,\n",
       "   'is_shortform': False,\n",
       "   'top_highlight': ''},\n",
       "  {'id': 'f004bd43e60b',\n",
       "   'title': 'Copy My $400/Day Affiliate Marketing Strategy',\n",
       "   'subtitle': 'Unveiling the Secrets to Successful Affiliate Marketing\\u200a—\\u200aA Journey from Trials to Triumph',\n",
       "   'author': '8a910484fe84',\n",
       "   'publication_id': '*Self-Published*',\n",
       "   'published_at': '2024-02-02 16:01:42',\n",
       "   'last_modified_at': '2024-02-02 16:01:42',\n",
       "   'tags': ['affiliate-marketing',\n",
       "    'make-money-online',\n",
       "    'marketing',\n",
       "    'passive-income',\n",
       "    'side-hustle'],\n",
       "   'topics': ['marketing'],\n",
       "   'claps': 71,\n",
       "   'voters': 5,\n",
       "   'word_count': 630,\n",
       "   'responses_count': 1,\n",
       "   'reading_time': 2.760691823899371,\n",
       "   'url': 'https://medium.com/@moneytent/copy-my-400-day-affiliate-marketing-strategy-f004bd43e60b',\n",
       "   'unique_slug': 'copy-my-400-day-affiliate-marketing-strategy-f004bd43e60b',\n",
       "   'image_url': 'https://miro.medium.com/1*uyYHVDRN_ShVQLttoJQrmQ.png',\n",
       "   'lang': 'en',\n",
       "   'is_series': False,\n",
       "   'is_locked': False,\n",
       "   'is_shortform': False,\n",
       "   'top_highlight': ''},\n",
       "  {'id': '262c355fdff1',\n",
       "   'title': '15 AI Tools That Will Make You Rich in 2024\\u200a—\\u200aGame Changer AI Tools in 2024!',\n",
       "   'subtitle': '15 Game-Changing AI Tools to Watch in 2024',\n",
       "   'author': '8a910484fe84',\n",
       "   'publication_id': '*Self-Published*',\n",
       "   'published_at': '2024-02-02 15:01:50',\n",
       "   'last_modified_at': '2024-02-02 15:01:50',\n",
       "   'tags': ['ai',\n",
       "    'ai-tools',\n",
       "    'artificial-intelligence',\n",
       "    'make-money-online',\n",
       "    'rich'],\n",
       "   'topics': ['artificial-intelligence'],\n",
       "   'claps': 56,\n",
       "   'voters': 7,\n",
       "   'word_count': 1184,\n",
       "   'responses_count': 0,\n",
       "   'reading_time': 4.85125786163522,\n",
       "   'url': 'https://medium.com/@moneytent/15-ai-tools-that-will-make-you-rich-in-2024-game-changer-ai-tools-in-2024-262c355fdff1',\n",
       "   'unique_slug': '15-ai-tools-that-will-make-you-rich-in-2024-game-changer-ai-tools-in-2024-262c355fdff1',\n",
       "   'image_url': 'https://miro.medium.com/1*7pH8oVdb0fyfQF7kOxU7Ew.png',\n",
       "   'lang': 'en',\n",
       "   'is_series': False,\n",
       "   'is_locked': False,\n",
       "   'is_shortform': False,\n",
       "   'top_highlight': ''},\n",
       "  {'id': 'c27c2166efec',\n",
       "   'title': 'Building a Video Content Agency with AI (in 2024)',\n",
       "   'subtitle': 'How AI Can Revolutionize Content Creation for Your Business',\n",
       "   'author': '8a910484fe84',\n",
       "   'publication_id': '*Self-Published*',\n",
       "   'published_at': '2024-02-02 14:01:43',\n",
       "   'last_modified_at': '2024-02-02 14:01:43',\n",
       "   'tags': ['content-creation',\n",
       "    'ai',\n",
       "    'artificial-intelligence',\n",
       "    'video-marketing',\n",
       "    'ai-tools'],\n",
       "   'topics': ['artificial-intelligence', 'marketing'],\n",
       "   'claps': 2,\n",
       "   'voters': 2,\n",
       "   'word_count': 716,\n",
       "   'responses_count': 0,\n",
       "   'reading_time': 3.0852201257861633,\n",
       "   'url': 'https://medium.com/@moneytent/building-a-video-content-agency-with-ai-in-2024-c27c2166efec',\n",
       "   'unique_slug': 'building-a-video-content-agency-with-ai-in-2024-c27c2166efec',\n",
       "   'image_url': 'https://miro.medium.com/1*3DFy3Mv7EVTxdikDGXLgcQ.png',\n",
       "   'lang': 'en',\n",
       "   'is_series': False,\n",
       "   'is_locked': False,\n",
       "   'is_shortform': False,\n",
       "   'top_highlight': ''}],\n",
       " '4beacba7dc8a': [{'id': '6ad21c4cfa99',\n",
       "   'title': 'Forget Prompt Engineering, ChatGPT Can Write Perfect Prompts for You',\n",
       "   'subtitle': 'I enabled ChatGPT to write optimal, research-based prompts so anyone can be an expert prompt engineer.',\n",
       "   'author': '4beacba7dc8a',\n",
       "   'publication_id': '*Self-Published*',\n",
       "   'published_at': '2024-01-13 20:28:42',\n",
       "   'last_modified_at': '2024-01-13 20:28:42',\n",
       "   'tags': ['chatgpt',\n",
       "    'artificial-intelligence',\n",
       "    'ai',\n",
       "    'prompt-engineering',\n",
       "    'openai'],\n",
       "   'topics': ['programming'],\n",
       "   'claps': 2425,\n",
       "   'voters': 436,\n",
       "   'word_count': 1432,\n",
       "   'responses_count': 28,\n",
       "   'reading_time': 6.10377358490566,\n",
       "   'url': 'https://medium.com/@jordan_gibbs/forget-prompt-engineering-chatgpt-can-write-perfect-prompts-for-you-6ad21c4cfa99',\n",
       "   'unique_slug': 'forget-prompt-engineering-chatgpt-can-write-perfect-prompts-for-you-6ad21c4cfa99',\n",
       "   'image_url': 'https://miro.medium.com/1*heKVq8v-TzkRBbrNuYsAMw.png',\n",
       "   'lang': 'en',\n",
       "   'is_series': False,\n",
       "   'is_locked': True,\n",
       "   'is_shortform': False,\n",
       "   'top_highlight': '1. Always use the COSTAR prompt framework:\\nContext (C): Provide essential background information or setting for the task. This helps the LLM understand the specific scenario or domain it is dealing with, leading to more relevant responses.\\nObjective (O): Clearly articulate the goal or purpose of the prompt. Specify what you want the LLM to accomplish, ensuring that its focus remains on achieving this particular aim.\\nStyle (S): Define the desired style of the response. This could range from imitating the writing style of a specific profession, like a scientist or journalist, to emulating the narrative tone of certain genres, such as formal reports or creative fiction.\\nTone (T): Determine the emotional or attitudinal coloring of the response. Whether it\\'s formal, casual, enthusiastic, or empathetic, setting the tone ensures the LLM\\'s response aligns with the intended sentiment.\\nAudience (A): Identify the target audience for whom the response is intended. Tailoring the content and complexity of the LLM\\'s response to suit the audience, such as experts, beginners, or a general readership, ensures better comprehension and engagement.\\nResponse Format (R): Specify the format in which you want the response. This could be a list, a structured report, a JSON object, a narrative, etc. Defining the format helps in generating responses that are suitable for your subsequent use, whether it be for analysis, presentation, or further processing.\\n2. Break down complex tasks into a sequence of simpler prompts in an interactive conversation. \\n3. Employ affirmative directives such as `do,\\' while steering clear of negative language like \\'don\\'t\\'. \\n4. Implement example-driven prompting (Use few-shot prompting). \\n5. Use following phrases: \"Your task is\" and \"You MUST\". \\n6. Always use leading words like writing \"think step by step\". \\n7. Assign a role to the model i.e. \"you are an expert ___\"\\n8. Repeat specific words or phrases multiple times within a prompt. \\n9. Try to induce Chain-of-thought (CoT) when possible, guiding the LLM to do dive in deeper to each step\\n10. Use output primers, which involve concluding your prompt with the beginning of the desired output. Utilize output primers by ending your prompt with the start of the anticipated response. \\n11. To write an essay /text /paragraph /article or any type of text that should be detailed: \"Write an ultra-detailed [essay/text /paragraph] for me on [topic] in detail by adding all the information necessary\".'},\n",
       "  {'id': '8088ec559681',\n",
       "   'title': 'How to *Not* Use ChatGPT',\n",
       "   'subtitle': 'Every single thing you absolutely shouldn’t use ChatGPT for (there’s a lot)',\n",
       "   'author': '4beacba7dc8a',\n",
       "   'publication_id': '*Self-Published*',\n",
       "   'published_at': '2024-01-20 22:58:19',\n",
       "   'last_modified_at': '2024-01-20 22:58:19',\n",
       "   'tags': ['chatgpt',\n",
       "    'artificial-intelligence',\n",
       "    'ai',\n",
       "    'technology',\n",
       "    'writing'],\n",
       "   'topics': ['design', 'programming'],\n",
       "   'claps': 663,\n",
       "   'voters': 94,\n",
       "   'word_count': 2760,\n",
       "   'responses_count': 11,\n",
       "   'reading_time': 12.01509433962264,\n",
       "   'url': 'https://medium.com/@jordan_gibbs/how-to-not-use-chatgpt-8088ec559681',\n",
       "   'unique_slug': 'how-to-not-use-chatgpt-8088ec559681',\n",
       "   'image_url': 'https://miro.medium.com/1*h5-lcbnZhj8qhodrkFjGkw.png',\n",
       "   'lang': 'en',\n",
       "   'is_series': False,\n",
       "   'is_locked': True,\n",
       "   'is_shortform': False,\n",
       "   'top_highlight': ''},\n",
       "  {'id': '0991c54be605',\n",
       "   'title': 'How to Prompt ChatGPT to Teach You Anything',\n",
       "   'subtitle': 'I created a prompt chain that enables you to learn any complex concept from ChatGPT.',\n",
       "   'author': '4beacba7dc8a',\n",
       "   'publication_id': '*Self-Published*',\n",
       "   'published_at': '2023-11-25 04:09:32',\n",
       "   'last_modified_at': '2023-11-25 04:09:32',\n",
       "   'tags': ['artificial-intelligence',\n",
       "    'chatgpt',\n",
       "    'learning',\n",
       "    'reading',\n",
       "    'science'],\n",
       "   'topics': ['artificial-intelligence', 'programming'],\n",
       "   'claps': 1332,\n",
       "   'voters': 294,\n",
       "   'word_count': 913,\n",
       "   'responses_count': 21,\n",
       "   'reading_time': 4.645283018867924,\n",
       "   'url': 'https://medium.com/@jordan_gibbs/how-to-prompt-chatgpt-to-teach-you-anything-0991c54be605',\n",
       "   'unique_slug': 'how-to-prompt-chatgpt-to-teach-you-anything-0991c54be605',\n",
       "   'image_url': 'https://miro.medium.com/1*D5I02-bjuJur5wMWk2Z6ig.png',\n",
       "   'lang': 'en',\n",
       "   'is_series': False,\n",
       "   'is_locked': True,\n",
       "   'is_shortform': False,\n",
       "   'top_highlight': 'Provide an executive summary of this link [or attatched document]. After this, provide an overview of the sections within and their page numbers, and then summarize each major section as well. Always cite your sources.'},\n",
       "  {'id': '55ef2bdc4d4a',\n",
       "   'title': 'The Most Important ChatGPT Prompt',\n",
       "   'subtitle': 'I‘ve read dozens of articles about “the best ChatGPT prompts,” but I’ve never seen the most effective one…',\n",
       "   'author': '4beacba7dc8a',\n",
       "   'publication_id': '*Self-Published*',\n",
       "   'published_at': '2023-12-18 17:26:16',\n",
       "   'last_modified_at': '2023-12-18 17:26:16',\n",
       "   'tags': ['chatgpt',\n",
       "    'openai',\n",
       "    'ai',\n",
       "    'artificial-intelligence',\n",
       "    'prompt-engineering'],\n",
       "   'topics': ['programming'],\n",
       "   'claps': 3344,\n",
       "   'voters': 736,\n",
       "   'word_count': 763,\n",
       "   'responses_count': 48,\n",
       "   'reading_time': 3.829245283018868,\n",
       "   'url': 'https://medium.com/@jordan_gibbs/the-most-important-chatgpt-prompt-55ef2bdc4d4a',\n",
       "   'unique_slug': 'the-most-important-chatgpt-prompt-55ef2bdc4d4a',\n",
       "   'image_url': 'https://miro.medium.com/1*12v9CX7ENSplhj3upW9TkQ.png',\n",
       "   'lang': 'en',\n",
       "   'is_series': False,\n",
       "   'is_locked': True,\n",
       "   'is_shortform': False,\n",
       "   'top_highlight': '\"Before you start, please ask me any questions you have about this so I can give you more context. Be extremely comprehensive.\"'},\n",
       "  {'id': 'fbdcf256f6bc',\n",
       "   'title': 'Upskilling Yourself with AI will Change Your Life',\n",
       "   'subtitle': 'I’ll show you how to harness AI’s best use case with this simple framework.',\n",
       "   'author': '4beacba7dc8a',\n",
       "   'publication_id': '*Self-Published*',\n",
       "   'published_at': '2023-11-21 02:33:00',\n",
       "   'last_modified_at': '2023-11-21 02:33:00',\n",
       "   'tags': ['learning',\n",
       "    'personal-development',\n",
       "    'personal-growth',\n",
       "    'artificial-intelligence',\n",
       "    'chatgpt'],\n",
       "   'topics': ['artificial-intelligence', 'work', 'programming'],\n",
       "   'claps': 503,\n",
       "   'voters': 40,\n",
       "   'word_count': 1338,\n",
       "   'responses_count': 6,\n",
       "   'reading_time': 5.882389937106918,\n",
       "   'url': 'https://medium.com/@jordan_gibbs/upskilling-yourself-with-ai-will-change-your-life-fbdcf256f6bc',\n",
       "   'unique_slug': 'upskilling-yourself-with-ai-will-change-your-life-fbdcf256f6bc',\n",
       "   'image_url': 'https://miro.medium.com/1*Ep3iJro_D5eFYGgPBBH8Cw.png',\n",
       "   'lang': 'en',\n",
       "   'is_series': False,\n",
       "   'is_locked': True,\n",
       "   'is_shortform': False,\n",
       "   'top_highlight': \"I've developed a general framework that generalizes AI upskilling to any field. I have used this framework now for the past six months, and I can say with absolute certainty that it has changed my life for the better.\"},\n",
       "  {'id': 'd952c5716930',\n",
       "   'title': 'The Top 100 Self-Help Books in One: ChatGPT’s Master Lessons',\n",
       "   'subtitle': 'All self-help books share the same DNA, so I extracted the most common core principles with ChatGPT.',\n",
       "   'author': '4beacba7dc8a',\n",
       "   'publication_id': '*Self-Published*',\n",
       "   'published_at': '2024-02-04 20:10:06',\n",
       "   'last_modified_at': '2024-02-04 20:10:06',\n",
       "   'tags': ['chatgpt',\n",
       "    'ai',\n",
       "    'reading',\n",
       "    'self-improvement',\n",
       "    'artificial-intelligence'],\n",
       "   'topics': ['books', 'self'],\n",
       "   'claps': 629,\n",
       "   'voters': 51,\n",
       "   'word_count': 1112,\n",
       "   'responses_count': 5,\n",
       "   'reading_time': 4.746226415094339,\n",
       "   'url': 'https://medium.com/@jordan_gibbs/the-top-100-self-help-books-in-one-chatgpts-master-lessons-d952c5716930',\n",
       "   'unique_slug': 'the-top-100-self-help-books-in-one-chatgpts-master-lessons-d952c5716930',\n",
       "   'image_url': 'https://miro.medium.com/1*nSeg0aeWBOHDYFb4UteGTA.png',\n",
       "   'lang': 'en',\n",
       "   'is_series': False,\n",
       "   'is_locked': True,\n",
       "   'is_shortform': False,\n",
       "   'top_highlight': ''},\n",
       "  {'id': '0765f71dee3e',\n",
       "   'title': 'The Art of Asking the Right Question',\n",
       "   'subtitle': 'All of our problems are solvable\\u200a—\\u200aif we could only ask the right questions.',\n",
       "   'author': '4beacba7dc8a',\n",
       "   'publication_id': '*Self-Published*',\n",
       "   'published_at': '2024-02-01 18:19:13',\n",
       "   'last_modified_at': '2024-02-01 18:19:13',\n",
       "   'tags': ['problem-solving',\n",
       "    'questions',\n",
       "    'productivity',\n",
       "    'inspiration',\n",
       "    'self-improvement'],\n",
       "   'topics': ['psychology', 'self'],\n",
       "   'claps': 134,\n",
       "   'voters': 14,\n",
       "   'word_count': 1698,\n",
       "   'responses_count': 2,\n",
       "   'reading_time': 6.9575471698113205,\n",
       "   'url': 'https://medium.com/@jordan_gibbs/the-art-of-asking-the-right-question-0765f71dee3e',\n",
       "   'unique_slug': 'the-art-of-asking-the-right-question-0765f71dee3e',\n",
       "   'image_url': 'https://miro.medium.com/1*VTM9PjtwBhMT7xvytE_Lew.png',\n",
       "   'lang': 'en',\n",
       "   'is_series': False,\n",
       "   'is_locked': True,\n",
       "   'is_shortform': False,\n",
       "   'top_highlight': '\"If I had an hour to solve a problem and my life depended on the solution, I would spend the first 55 minutes determining the proper question to ask... for once I know the proper question, I could solve the problem in less than five minutes.\"'},\n",
       "  {'id': 'fb3f7e0d9deb',\n",
       "   'title': 'Read 1000 Books per Year with ChatGPT',\n",
       "   'subtitle': 'Supercharge your reading volume, comprehension, and retention with ChatGPT-assisted reading',\n",
       "   'author': '4beacba7dc8a',\n",
       "   'publication_id': '*Self-Published*',\n",
       "   'published_at': '2024-01-03 03:39:02',\n",
       "   'last_modified_at': '2024-01-03 03:39:02',\n",
       "   'tags': ['chatgpt', 'ai', 'artificial-intelligence', 'reading', 'learning'],\n",
       "   'topics': ['productivity'],\n",
       "   'claps': 1757,\n",
       "   'voters': 293,\n",
       "   'word_count': 1126,\n",
       "   'responses_count': 33,\n",
       "   'reading_time': 5.1990566037735855,\n",
       "   'url': 'https://medium.com/@jordan_gibbs/read-1000-books-per-year-with-chatgpt-fb3f7e0d9deb',\n",
       "   'unique_slug': 'read-1000-books-per-year-with-chatgpt-fb3f7e0d9deb',\n",
       "   'image_url': 'https://miro.medium.com/1*IsLL1ZnRVJ0fkoysWFx5Uw.png',\n",
       "   'lang': 'en',\n",
       "   'is_series': False,\n",
       "   'is_locked': True,\n",
       "   'is_shortform': False,\n",
       "   'top_highlight': 'Write an ultra-detailed summary about [Insert Book Title].'},\n",
       "  {'id': '948fce739c61',\n",
       "   'title': 'Do Gimmicky ChatGPT Prompts Actually Work?',\n",
       "   'subtitle': 'I analyzed if viral gimmick prompts actually trick ChatGPT into working harder.',\n",
       "   'author': '4beacba7dc8a',\n",
       "   'publication_id': '*Self-Published*',\n",
       "   'published_at': '2023-12-27 03:02:16',\n",
       "   'last_modified_at': '2023-12-27 03:02:16',\n",
       "   'tags': ['chatgpt',\n",
       "    'openai',\n",
       "    'ai',\n",
       "    'artificial-intelligence',\n",
       "    'prompt-engineering'],\n",
       "   'topics': ['data-science', 'programming'],\n",
       "   'claps': 125,\n",
       "   'voters': 21,\n",
       "   'word_count': 513,\n",
       "   'responses_count': 2,\n",
       "   'reading_time': 2.319182389937107,\n",
       "   'url': 'https://medium.com/@jordan_gibbs/do-gimmicky-chatgpt-prompts-actually-work-948fce739c61',\n",
       "   'unique_slug': 'do-gimmicky-chatgpt-prompts-actually-work-948fce739c61',\n",
       "   'image_url': 'https://miro.medium.com/1*Uz4_8rQuiXIQXCNDSjN0wQ.png',\n",
       "   'lang': 'en',\n",
       "   'is_series': False,\n",
       "   'is_locked': True,\n",
       "   'is_shortform': False,\n",
       "   'top_highlight': ''},\n",
       "  {'id': 'b0911e3faf6b',\n",
       "   'title': 'Which Phrases are the Most “ChatGPT” of All?',\n",
       "   'subtitle': 'I analyzed 1.2 million GPT words to find the most common phrases output by ChatGPT\\u200a—\\u200aI found some crazy results.',\n",
       "   'author': '4beacba7dc8a',\n",
       "   'publication_id': '*Self-Published*',\n",
       "   'published_at': '2023-12-14 17:36:37',\n",
       "   'last_modified_at': '2023-12-14 17:36:37',\n",
       "   'tags': ['chatgpt',\n",
       "    'ai',\n",
       "    'artificial-intelligence',\n",
       "    'openai',\n",
       "    'linguistics'],\n",
       "   'topics': ['data-science'],\n",
       "   'claps': 1106,\n",
       "   'voters': 158,\n",
       "   'word_count': 816,\n",
       "   'responses_count': 22,\n",
       "   'reading_time': 3.9125786163522016,\n",
       "   'url': 'https://medium.com/@jordan_gibbs/which-phrases-are-the-most-chatgpt-of-all-b0911e3faf6b',\n",
       "   'unique_slug': 'which-phrases-are-the-most-chatgpt-of-all-b0911e3faf6b',\n",
       "   'image_url': 'https://miro.medium.com/1*5ARxvUDOs_76GIHYtDCYKQ.png',\n",
       "   'lang': 'en',\n",
       "   'is_series': False,\n",
       "   'is_locked': True,\n",
       "   'is_shortform': False,\n",
       "   'top_highlight': ''}],\n",
       " '630ab5ffdf27': [{'id': '0826b977bb5a',\n",
       "   'title': 'My magical first job as a self-taught software engineer',\n",
       "   'subtitle': 'I’m a self-taught software engineer. No formal courses. No internship. Being self-taught means I have some noticeable gaps in my technical…',\n",
       "   'author': '630ab5ffdf27',\n",
       "   'publication_id': '7fa1ab2ec345',\n",
       "   'published_at': '2024-02-16 10:31:47',\n",
       "   'last_modified_at': '2024-02-16 10:31:47',\n",
       "   'tags': ['programming',\n",
       "    'software-engineering',\n",
       "    'software-development',\n",
       "    'careers'],\n",
       "   'topics': ['work', 'programming'],\n",
       "   'claps': 211,\n",
       "   'voters': 21,\n",
       "   'word_count': 350,\n",
       "   'responses_count': 5,\n",
       "   'reading_time': 1.520754716981132,\n",
       "   'url': 'https://atomic.engineering/my-magical-first-job-as-a-self-taught-software-engineer-0826b977bb5a',\n",
       "   'unique_slug': 'my-magical-first-job-as-a-self-taught-software-engineer-0826b977bb5a',\n",
       "   'image_url': 'https://miro.medium.com/0*dpx9eSSU8dllS32h.png',\n",
       "   'lang': 'en',\n",
       "   'is_series': False,\n",
       "   'is_locked': False,\n",
       "   'is_shortform': False,\n",
       "   'top_highlight': 'Comparison is the thief of joy.'},\n",
       "  {'id': '3be015341e5e',\n",
       "   'title': 'An algorithm for high-performance engineering teams',\n",
       "   'subtitle': 'How does a team go from “good” to “great”?',\n",
       "   'author': '630ab5ffdf27',\n",
       "   'publication_id': '7fa1ab2ec345',\n",
       "   'published_at': '2024-02-14 16:37:02',\n",
       "   'last_modified_at': '2024-02-15 04:02:03',\n",
       "   'tags': ['leadership', 'programming', 'software-engineering'],\n",
       "   'topics': ['work', 'programming'],\n",
       "   'claps': 459,\n",
       "   'voters': 58,\n",
       "   'word_count': 1588,\n",
       "   'responses_count': 8,\n",
       "   'reading_time': 6.542452830188679,\n",
       "   'url': 'https://atomic.engineering/an-algorithm-for-high-performance-engineering-teams-3be015341e5e',\n",
       "   'unique_slug': 'an-algorithm-for-high-performance-engineering-teams-3be015341e5e',\n",
       "   'image_url': 'https://miro.medium.com/1*YBldg8qIX_Y7oxfu_UaS8w.png',\n",
       "   'lang': 'en',\n",
       "   'is_series': False,\n",
       "   'is_locked': True,\n",
       "   'is_shortform': False,\n",
       "   'top_highlight': 'All models are wrong, but some are useful.'},\n",
       "  {'id': 'a8f2b9faad1d',\n",
       "   'title': 'I almost got fired once',\n",
       "   'subtitle': '👋 Hi, this is Jacob with this week’s newsletter, “I almost got fired once.”',\n",
       "   'author': '630ab5ffdf27',\n",
       "   'publication_id': '7fa1ab2ec345',\n",
       "   'published_at': '2024-02-09 11:31:46',\n",
       "   'last_modified_at': '2024-02-09 11:31:46',\n",
       "   'tags': ['programming',\n",
       "    'software-development',\n",
       "    'software-engineering',\n",
       "    'problem-solving',\n",
       "    'leadership'],\n",
       "   'topics': ['work', 'programming'],\n",
       "   'claps': 378,\n",
       "   'voters': 34,\n",
       "   'word_count': 746,\n",
       "   'responses_count': 5,\n",
       "   'reading_time': 3.1984276729559746,\n",
       "   'url': 'https://atomic.engineering/i-almost-got-fired-once-a8f2b9faad1d',\n",
       "   'unique_slug': 'i-almost-got-fired-once-a8f2b9faad1d',\n",
       "   'image_url': 'https://miro.medium.com/1*LB-gvS9Z52OtQKljoJy6bw.png',\n",
       "   'lang': 'en',\n",
       "   'is_series': False,\n",
       "   'is_locked': False,\n",
       "   'is_shortform': False,\n",
       "   'top_highlight': 'Luke Millar (VP of Eng at Medium) explained to me what made one of our team members so valuable. \"They\\'re not necessarily fast, but I know if I give them a hard problem that no one else understands, they\\'ll eventually find an answer, and it will be a good one.\"'},\n",
       "  {'id': '547e3edc7a36',\n",
       "   'title': 'A tale of two engineering teams',\n",
       "   'subtitle': '👋 Hi, this is Jacob with this week’s newsletter, “A tale of two engineering teams.”',\n",
       "   'author': '630ab5ffdf27',\n",
       "   'publication_id': '7fa1ab2ec345',\n",
       "   'published_at': '2024-02-02 11:31:43',\n",
       "   'last_modified_at': '2024-02-02 11:31:43',\n",
       "   'tags': ['programming',\n",
       "    'software-development',\n",
       "    'software-engineering',\n",
       "    'technology'],\n",
       "   'topics': ['programming'],\n",
       "   'claps': 595,\n",
       "   'voters': 70,\n",
       "   'word_count': 616,\n",
       "   'responses_count': 6,\n",
       "   'reading_time': 2.5245283018867926,\n",
       "   'url': 'https://atomic.engineering/a-tale-of-two-engineering-teams-547e3edc7a36',\n",
       "   'unique_slug': 'a-tale-of-two-engineering-teams-547e3edc7a36',\n",
       "   'image_url': 'https://miro.medium.com/0*dpMZyiz7Wm5sI2B6.png',\n",
       "   'lang': 'en',\n",
       "   'is_series': False,\n",
       "   'is_locked': False,\n",
       "   'is_shortform': False,\n",
       "   'top_highlight': '\"First, make it work.\" You are out of business if it doesn\\'t work.'},\n",
       "  {'id': '597a768f6509',\n",
       "   'title': 'Welcome to The Standup',\n",
       "   'subtitle': 'A single idea. 5 minutes or less. Every week.',\n",
       "   'author': '630ab5ffdf27',\n",
       "   'publication_id': '7fa1ab2ec345',\n",
       "   'published_at': '2024-01-26 13:32:22',\n",
       "   'last_modified_at': '2024-01-26 16:52:09',\n",
       "   'tags': ['programming',\n",
       "    'software-development',\n",
       "    'software-engineering',\n",
       "    'software-architecture',\n",
       "    'data-science'],\n",
       "   'topics': ['programming'],\n",
       "   'claps': 79,\n",
       "   'voters': 11,\n",
       "   'word_count': 120,\n",
       "   'responses_count': 1,\n",
       "   'reading_time': 0.4528301886792453,\n",
       "   'url': 'https://atomic.engineering/welcome-to-atomic-engineering-daily-597a768f6509',\n",
       "   'unique_slug': 'welcome-to-atomic-engineering-daily-597a768f6509',\n",
       "   'image_url': '',\n",
       "   'lang': 'en',\n",
       "   'is_series': False,\n",
       "   'is_locked': False,\n",
       "   'is_shortform': True,\n",
       "   'top_highlight': ''},\n",
       "  {'id': 'edd9949df58b',\n",
       "   'title': 'The 5 paid subscriptions I actually use in 2024 as a software engineer',\n",
       "   'subtitle': 'Tools I use that are cheaper than Netflix',\n",
       "   'author': '630ab5ffdf27',\n",
       "   'publication_id': '5517fd7b58a6',\n",
       "   'published_at': '2024-01-04 15:44:45',\n",
       "   'last_modified_at': '2024-01-04 15:44:45',\n",
       "   'tags': ['software-engineering',\n",
       "    'software-development',\n",
       "    'programming',\n",
       "    'technology',\n",
       "    'data-science'],\n",
       "   'topics': ['programming'],\n",
       "   'claps': 9093,\n",
       "   'voters': 2385,\n",
       "   'word_count': 896,\n",
       "   'responses_count': 122,\n",
       "   'reading_time': 4.331132075471698,\n",
       "   'url': 'https://levelup.gitconnected.com/the-5-paid-subscriptions-i-actually-use-in-2024-as-a-software-engineer-edd9949df58b',\n",
       "   'unique_slug': 'the-5-paid-subscriptions-i-actually-use-in-2024-as-a-software-engineer-edd9949df58b',\n",
       "   'image_url': 'https://miro.medium.com/1*jDgxfrxa6FoWb5e0VAFt-w.gif',\n",
       "   'lang': 'en',\n",
       "   'is_series': False,\n",
       "   'is_locked': True,\n",
       "   'is_shortform': False,\n",
       "   'top_highlight': 'Kagi: a better search engine than Google'},\n",
       "  {'id': '815da93996a',\n",
       "   'title': 'Yes, You Can Write ‘switch’ Statements in Python',\n",
       "   'subtitle': 'And it comes with a secret superpower!',\n",
       "   'author': '630ab5ffdf27',\n",
       "   'publication_id': '78073def27b8',\n",
       "   'published_at': '2023-04-05 04:17:00',\n",
       "   'last_modified_at': '2023-04-14 20:55:11',\n",
       "   'tags': ['python',\n",
       "    'programming',\n",
       "    'software-development',\n",
       "    'data-science',\n",
       "    'technology'],\n",
       "   'topics': ['programming'],\n",
       "   'claps': 560,\n",
       "   'voters': 82,\n",
       "   'word_count': 1110,\n",
       "   'responses_count': 8,\n",
       "   'reading_time': 4.3886792452830194,\n",
       "   'url': 'https://python.plainenglish.io/yes-you-can-write-switch-statements-in-python-815da93996a',\n",
       "   'unique_slug': 'yes-you-can-write-switch-statements-in-python-815da93996a',\n",
       "   'image_url': 'https://miro.medium.com/0*ZK-x4MQeq7ElOOW1.png',\n",
       "   'lang': 'en',\n",
       "   'is_series': False,\n",
       "   'is_locked': True,\n",
       "   'is_shortform': False,\n",
       "   'top_highlight': ''},\n",
       "  {'id': 'c1fe776c108f',\n",
       "   'title': 'The comprehensive guide to Python project setup',\n",
       "   'subtitle': 'Start your project right and reap the rewards for years',\n",
       "   'author': '630ab5ffdf27',\n",
       "   'publication_id': '5517fd7b58a6',\n",
       "   'published_at': '2023-04-04 17:24:29',\n",
       "   'last_modified_at': '2023-04-04 17:24:29',\n",
       "   'tags': ['python',\n",
       "    'programming',\n",
       "    'software-development',\n",
       "    'data-science',\n",
       "    'technology'],\n",
       "   'topics': ['programming'],\n",
       "   'claps': 1331,\n",
       "   'voters': 399,\n",
       "   'word_count': 2632,\n",
       "   'responses_count': 9,\n",
       "   'reading_time': 10.315408805031446,\n",
       "   'url': 'https://levelup.gitconnected.com/the-comprehensive-guide-to-python-project-setup-c1fe776c108f',\n",
       "   'unique_slug': 'the-comprehensive-guide-to-python-project-setup-c1fe776c108f',\n",
       "   'image_url': 'https://miro.medium.com/0*LxrVQie98hgHzUAQ.png',\n",
       "   'lang': 'en',\n",
       "   'is_series': False,\n",
       "   'is_locked': True,\n",
       "   'is_shortform': False,\n",
       "   'top_highlight': 'Indeed, the ratio of time spent reading versus writing is well over 10 to 1. We are constantly reading old code as part of the effort to write new code. ...[Therefore,] making it easy to read makes it easier to write.'},\n",
       "  {'id': '9418515a315a',\n",
       "   'title': 'The 5 paid subscriptions I actually use in 2023 as a software engineer',\n",
       "   'subtitle': 'Tools I use that are cheaper than Netflix',\n",
       "   'author': '630ab5ffdf27',\n",
       "   'publication_id': '9758482ba857',\n",
       "   'published_at': '2023-03-25 17:01:41',\n",
       "   'last_modified_at': '2023-03-25 17:01:41',\n",
       "   'tags': ['programming',\n",
       "    'technology',\n",
       "    'education',\n",
       "    'data-science',\n",
       "    'software-development'],\n",
       "   'topics': ['programming'],\n",
       "   'claps': 4606,\n",
       "   'voters': 1554,\n",
       "   'word_count': 665,\n",
       "   'responses_count': 47,\n",
       "   'reading_time': 3.3427672955974845,\n",
       "   'url': 'https://medium.com/geekculture/the-5-paid-subscriptions-i-actually-use-in-2023-as-a-software-engineer-9418515a315a',\n",
       "   'unique_slug': 'the-5-paid-subscriptions-i-actually-use-in-2023-as-a-software-engineer-9418515a315a',\n",
       "   'image_url': 'https://miro.medium.com/1*pB-JOp4O5Q1jUj3YX4ca8w.png',\n",
       "   'lang': 'en',\n",
       "   'is_series': False,\n",
       "   'is_locked': True,\n",
       "   'is_shortform': False,\n",
       "   'top_highlight': 'Bonus: Excalidraw'},\n",
       "  {'id': 'ae06c6f24827',\n",
       "   'title': 'Solution to LeetCode #1: Two Sum (Python)',\n",
       "   'subtitle': 'Top 0.2% of solutions',\n",
       "   'author': '630ab5ffdf27',\n",
       "   'publication_id': '*Self-Published*',\n",
       "   'published_at': '2023-03-18 06:23:34',\n",
       "   'last_modified_at': '2023-03-30 03:07:10',\n",
       "   'tags': ['python',\n",
       "    'programming',\n",
       "    'software-development',\n",
       "    'leetcode',\n",
       "    'leetcode-easy'],\n",
       "   'topics': ['programming'],\n",
       "   'claps': 10,\n",
       "   'voters': 6,\n",
       "   'word_count': 976,\n",
       "   'responses_count': 0,\n",
       "   'reading_time': 4.233018867924528,\n",
       "   'url': 'https://jacobistyping.medium.com/solution-to-leetcode-1-two-sum-python-ae06c6f24827',\n",
       "   'unique_slug': 'solution-to-leetcode-1-two-sum-python-ae06c6f24827',\n",
       "   'image_url': 'https://miro.medium.com/1*TBZxhGJLzO1V4BjJuz_u-w.png',\n",
       "   'lang': 'en',\n",
       "   'is_series': False,\n",
       "   'is_locked': True,\n",
       "   'is_shortform': False,\n",
       "   'top_highlight': ''}],\n",
       " 'b856005e5ecd': [{'id': 'ded34fccd16a',\n",
       "   'title': '100x Faster\\u200a—\\u200aScaling Your RAG App for Billions of Embeddings',\n",
       "   'subtitle': 'Computing Cosine Similarity in parallel',\n",
       "   'author': 'b856005e5ecd',\n",
       "   'publication_id': '5517fd7b58a6',\n",
       "   'published_at': '2024-02-15 12:16:47',\n",
       "   'last_modified_at': '2024-02-15 12:16:47',\n",
       "   'tags': ['data-science',\n",
       "    'python',\n",
       "    'chatgpt',\n",
       "    'large-language-models',\n",
       "    'coding'],\n",
       "   'topics': ['machine-learning', 'data-science', 'programming'],\n",
       "   'claps': 276,\n",
       "   'voters': 38,\n",
       "   'word_count': 2310,\n",
       "   'responses_count': 0,\n",
       "   'reading_time': 9.966981132075471,\n",
       "   'url': 'https://levelup.gitconnected.com/100x-faster-scaling-your-rag-app-for-billions-of-embeddings-ded34fccd16a',\n",
       "   'unique_slug': '100x-faster-scaling-your-rag-app-for-billions-of-embeddings-ded34fccd16a',\n",
       "   'image_url': 'https://miro.medium.com/1*4Ry1nUyUXjrDE9L2GDRwEg.png',\n",
       "   'lang': 'en',\n",
       "   'is_series': False,\n",
       "   'is_locked': False,\n",
       "   'is_shortform': False,\n",
       "   'top_highlight': ''},\n",
       "  {'id': 'f612398f06c2',\n",
       "   'title': 'Building a Million-Parameter LLM from Scratch Using Python',\n",
       "   'subtitle': 'A Step-by-Step Guide to Replicating LLaMA Architecture',\n",
       "   'author': 'b856005e5ecd',\n",
       "   'publication_id': '5517fd7b58a6',\n",
       "   'published_at': '2023-12-07 14:55:24',\n",
       "   'last_modified_at': '2023-12-19 04:25:11',\n",
       "   'tags': ['artificial-intelligence',\n",
       "    'python',\n",
       "    'data-science',\n",
       "    'chatgpt',\n",
       "    'deep-learning'],\n",
       "   'topics': [],\n",
       "   'claps': 2426,\n",
       "   'voters': 645,\n",
       "   'word_count': 6094,\n",
       "   'responses_count': 31,\n",
       "   'reading_time': 24.796226415094342,\n",
       "   'url': 'https://levelup.gitconnected.com/building-a-million-parameter-llm-from-scratch-using-python-f612398f06c2',\n",
       "   'unique_slug': 'building-a-million-parameter-llm-from-scratch-using-python-f612398f06c2',\n",
       "   'image_url': 'https://miro.medium.com/1*ox3hToPFUWxAwURxYEXiGg.jpeg',\n",
       "   'lang': 'en',\n",
       "   'is_series': False,\n",
       "   'is_locked': False,\n",
       "   'is_shortform': False,\n",
       "   'top_highlight': '# Definition of a basic neural network class\\nclass SimpleBrokenModel(nn.Module):\\n    def __init__(self, config=MASTER_CONFIG):\\n\\n        # Rest of the code        \\n        ... \\n\\n        # Forward pass function for the base model\\n        def forward(self, idx, targets=None):\\n            # Embedding layer converts character indices to vectors\\n            x = self.embedding(idx)\\n            \\n            # Linear layers for modeling relationships between features\\n            a = self.linear(x)\\n            \\n            # Apply softmax activation to obtain probability distribution\\n            logits = F.softmax(a, dim=-1)\\n\\n            # If targets are provided, calculate and return the cross-entropy loss\\n            if targets is not None:\\n                # Reshape logits and targets for cross-entropy calculation\\n                loss = F.cross_entropy(logits.view(-1, self.config[\\'vocab_size\\']), targets.view(-1))\\n                return logits, loss\\n\\n            # If targets are not provided, return the logits\\n            else:\\n                return logits\\n\\n        # Print the total number of model parameters\\n        print(\"Model parameters:\", sum([m.numel() for m in self.parameters()]))'},\n",
       "  {'id': '969af38516b2',\n",
       "   'title': 'Chat with Graphs Intelligently',\n",
       "   'subtitle': 'Talking Graphs, Your Data Speaks Up',\n",
       "   'author': 'b856005e5ecd',\n",
       "   'publication_id': '5517fd7b58a6',\n",
       "   'published_at': '2024-01-23 04:01:22',\n",
       "   'last_modified_at': '2024-01-23 04:01:22',\n",
       "   'tags': ['data-science',\n",
       "    'data-visualization',\n",
       "    'python',\n",
       "    'artificial-intelligence',\n",
       "    'chatgpt'],\n",
       "   'topics': ['data-science', 'programming'],\n",
       "   'claps': 442,\n",
       "   'voters': 46,\n",
       "   'word_count': 1179,\n",
       "   'responses_count': 1,\n",
       "   'reading_time': 5.949056603773585,\n",
       "   'url': 'https://levelup.gitconnected.com/chat-with-graphs-intelligently-969af38516b2',\n",
       "   'unique_slug': 'chat-with-graphs-intelligently-969af38516b2',\n",
       "   'image_url': 'https://miro.medium.com/1*VrxMVWJjDT42bSvySMwYxw.png',\n",
       "   'lang': 'en',\n",
       "   'is_series': False,\n",
       "   'is_locked': False,\n",
       "   'is_shortform': False,\n",
       "   'top_highlight': ''},\n",
       "  {'id': 'e9390e2b9ed8',\n",
       "   'title': 'Create a Copilot inside your notebooks that can chat with graphs, write code and more',\n",
       "   'subtitle': 'An Intelligent Help for Efficient Programming',\n",
       "   'author': 'b856005e5ecd',\n",
       "   'publication_id': '5517fd7b58a6',\n",
       "   'published_at': '2024-01-11 15:39:01',\n",
       "   'last_modified_at': '2024-01-12 15:22:35',\n",
       "   'tags': ['python',\n",
       "    'github',\n",
       "    'machine-learning',\n",
       "    'programming',\n",
       "    'data-science'],\n",
       "   'topics': ['programming'],\n",
       "   'claps': 749,\n",
       "   'voters': 136,\n",
       "   'word_count': 3276,\n",
       "   'responses_count': 9,\n",
       "   'reading_time': 13.495597484276729,\n",
       "   'url': 'https://levelup.gitconnected.com/create-copilot-inside-your-notebooks-that-can-chat-with-graphs-write-code-and-more-e9390e2b9ed8',\n",
       "   'unique_slug': 'create-copilot-inside-your-notebooks-that-can-chat-with-graphs-write-code-and-more-e9390e2b9ed8',\n",
       "   'image_url': 'https://miro.medium.com/1*DETUd5sgj8GAQAVvLMrkEQ.png',\n",
       "   'lang': 'en',\n",
       "   'is_series': False,\n",
       "   'is_locked': False,\n",
       "   'is_shortform': False,\n",
       "   'top_highlight': ''},\n",
       "  {'id': '16d4e64e6eb1',\n",
       "   'title': 'Solving Transformer by Hand: A Step-by-Step Math Example',\n",
       "   'subtitle': 'Performing numerous matrix multiplications to solve the encoder and decoder parts of the transformer',\n",
       "   'author': 'b856005e5ecd',\n",
       "   'publication_id': '5517fd7b58a6',\n",
       "   'published_at': '2023-12-18 12:41:09',\n",
       "   'last_modified_at': '2023-12-21 04:19:24',\n",
       "   'tags': ['data-science',\n",
       "    'artificial-intelligence',\n",
       "    'machine-learning',\n",
       "    'python',\n",
       "    'deep-learning'],\n",
       "   'topics': ['machine-learning', 'data-science', 'programming'],\n",
       "   'claps': 1717,\n",
       "   'voters': 346,\n",
       "   'word_count': 2607,\n",
       "   'responses_count': 26,\n",
       "   'reading_time': 12.787735849056602,\n",
       "   'url': 'https://levelup.gitconnected.com/understanding-transformers-from-start-to-end-a-step-by-step-math-example-16d4e64e6eb1',\n",
       "   'unique_slug': 'understanding-transformers-from-start-to-end-a-step-by-step-math-example-16d4e64e6eb1',\n",
       "   'image_url': 'https://miro.medium.com/1*99eK1ktrNGPyt4IPowcAgg.png',\n",
       "   'lang': 'en',\n",
       "   'is_series': False,\n",
       "   'is_locked': False,\n",
       "   'is_shortform': False,\n",
       "   'top_highlight': 'When training, there are two inputs to the decoder. One is from the encoder, where the output matrix of the last add and norm layer serves as the query and key for the second multi-head attention layer in the decoder part. Below is the visualization of it (from batool haider):'},\n",
       "  {'id': '3e71f406338b',\n",
       "   'title': 'Free GenAI APIs You Can Use in 2024',\n",
       "   'subtitle': 'Exploring the Latest Free GenAI APIs',\n",
       "   'author': 'b856005e5ecd',\n",
       "   'publication_id': '5517fd7b58a6',\n",
       "   'published_at': '2024-02-04 18:47:29',\n",
       "   'last_modified_at': '2024-02-04 18:47:29',\n",
       "   'tags': ['api',\n",
       "    'artificial-intelligence',\n",
       "    'data-science',\n",
       "    'machine-learning',\n",
       "    'ai'],\n",
       "   'topics': ['programming'],\n",
       "   'claps': 240,\n",
       "   'voters': 22,\n",
       "   'word_count': 1304,\n",
       "   'responses_count': 4,\n",
       "   'reading_time': 5.304088050314466,\n",
       "   'url': 'https://levelup.gitconnected.com/free-genai-apis-you-can-use-in-2024-3e71f406338b',\n",
       "   'unique_slug': 'free-genai-apis-you-can-use-in-2024-3e71f406338b',\n",
       "   'image_url': 'https://miro.medium.com/1*jRaq7jiSFE1HivnUiIJxzQ.png',\n",
       "   'lang': 'en',\n",
       "   'is_series': False,\n",
       "   'is_locked': False,\n",
       "   'is_shortform': False,\n",
       "   'top_highlight': ''},\n",
       "  {'id': '2675c73080ff',\n",
       "   'title': 'Make your LLM aware of today’s Knowledge using Python',\n",
       "   'subtitle': 'A Classification Approach, Making LLM Knowledge-Aware',\n",
       "   'author': 'b856005e5ecd',\n",
       "   'publication_id': '5517fd7b58a6',\n",
       "   'published_at': '2024-01-30 18:32:09',\n",
       "   'last_modified_at': '2024-02-02 14:42:33',\n",
       "   'tags': ['data-science',\n",
       "    'python',\n",
       "    'machine-learning',\n",
       "    'deep-learning',\n",
       "    'programming'],\n",
       "   'topics': ['programming'],\n",
       "   'claps': 202,\n",
       "   'voters': 23,\n",
       "   'word_count': 3321,\n",
       "   'responses_count': 1,\n",
       "   'reading_time': 13.832075471698113,\n",
       "   'url': 'https://levelup.gitconnected.com/solve-llm-knowledge-cutoff-problem-with-python-2675c73080ff',\n",
       "   'unique_slug': 'solve-llm-knowledge-cutoff-problem-with-python-2675c73080ff',\n",
       "   'image_url': 'https://miro.medium.com/1*_bXvfeEEfLCQ7ekmUZh94w.png',\n",
       "   'lang': 'en',\n",
       "   'is_series': False,\n",
       "   'is_locked': False,\n",
       "   'is_shortform': False,\n",
       "   'top_highlight': ''},\n",
       "  {'id': '9a083d3811df',\n",
       "   'title': 'Convert Weak LLM to Strong LLM Using SPIN Technique',\n",
       "   'subtitle': 'Can we help a weak LLM get better without getting more data?',\n",
       "   'author': 'b856005e5ecd',\n",
       "   'publication_id': '5517fd7b58a6',\n",
       "   'published_at': '2024-01-16 23:24:01',\n",
       "   'last_modified_at': '2024-01-16 23:24:01',\n",
       "   'tags': ['machine-learning',\n",
       "    'deep-learning',\n",
       "    'large-language-models',\n",
       "    'ai',\n",
       "    'data-science'],\n",
       "   'topics': ['machine-learning'],\n",
       "   'claps': 75,\n",
       "   'voters': 12,\n",
       "   'word_count': 3289,\n",
       "   'responses_count': 3,\n",
       "   'reading_time': 13.711320754716981,\n",
       "   'url': 'https://levelup.gitconnected.com/convert-weak-llm-to-strong-llm-using-spin-technique-9a083d3811df',\n",
       "   'unique_slug': 'convert-weak-llm-to-strong-llm-using-spin-technique-9a083d3811df',\n",
       "   'image_url': 'https://miro.medium.com/1*thxroSFEju_2OFHme6mPVA.png',\n",
       "   'lang': 'en',\n",
       "   'is_series': False,\n",
       "   'is_locked': False,\n",
       "   'is_shortform': False,\n",
       "   'top_highlight': ''},\n",
       "  {'id': 'f3ebc8c42da3',\n",
       "   'title': 'Coding Stable Diffusion from Scratch',\n",
       "   'subtitle': 'A step by step guide of implementing diffusion model architecture.',\n",
       "   'author': 'b856005e5ecd',\n",
       "   'publication_id': '5517fd7b58a6',\n",
       "   'published_at': '2024-01-04 15:46:31',\n",
       "   'last_modified_at': '2024-01-10 12:03:43',\n",
       "   'tags': ['artificial-intelligence',\n",
       "    'data-science',\n",
       "    'stable-diffusion',\n",
       "    'python',\n",
       "    'machine-learning'],\n",
       "   'topics': [],\n",
       "   'claps': 438,\n",
       "   'voters': 69,\n",
       "   'word_count': 8669,\n",
       "   'responses_count': 6,\n",
       "   'reading_time': 34.46320754716981,\n",
       "   'url': 'https://levelup.gitconnected.com/building-stable-diffusion-from-scratch-using-python-f3ebc8c42da3',\n",
       "   'unique_slug': 'building-stable-diffusion-from-scratch-using-python-f3ebc8c42da3',\n",
       "   'image_url': 'https://miro.medium.com/1*pFNOzxb0_7WkcAyK5NhMxA.png',\n",
       "   'lang': 'en',\n",
       "   'is_series': False,\n",
       "   'is_locked': False,\n",
       "   'is_shortform': False,\n",
       "   'top_highlight': 'This choice is driven by the fact that a color image with 512x512 resolution has a huge number of potential values. In comparison, Stable Diffusion uses a compressed image that is 48 times smaller, containing fewer values. This significant reduction in processing requirements allows the use of Stable Diffusion on a desktop computer with an NVIDIA GPU featuring 8 GB of RAM. The effectiveness of the smaller latent space is based on the idea that natural images follow patterns rather than randomness. Stable Diffusion uses variational autoencoder (VAE) files in the decoder to capture intricate details such as eyes.'},\n",
       "  {'id': 'c26d08a55809',\n",
       "   'title': 'Building Powerful NLP Library in Python for 2024',\n",
       "   'subtitle': 'How Gemini by Google has transformed NLP tasks',\n",
       "   'author': 'b856005e5ecd',\n",
       "   'publication_id': '5517fd7b58a6',\n",
       "   'published_at': '2023-12-28 22:13:24',\n",
       "   'last_modified_at': '2024-01-01 09:32:00',\n",
       "   'tags': ['nlp',\n",
       "    'python',\n",
       "    'data-science',\n",
       "    'machine-learning',\n",
       "    'deep-learning'],\n",
       "   'topics': ['machine-learning', 'programming'],\n",
       "   'claps': 585,\n",
       "   'voters': 98,\n",
       "   'word_count': 3475,\n",
       "   'responses_count': 4,\n",
       "   'reading_time': 13.81320754716981,\n",
       "   'url': 'https://levelup.gitconnected.com/how-i-created-the-most-powerful-nlp-library-in-python-c26d08a55809',\n",
       "   'unique_slug': 'how-i-created-the-most-powerful-nlp-library-in-python-c26d08a55809',\n",
       "   'image_url': 'https://miro.medium.com/1*iW0G158ttjCvYxJd1aFWwg.png',\n",
       "   'lang': 'en',\n",
       "   'is_series': False,\n",
       "   'is_locked': False,\n",
       "   'is_shortform': False,\n",
       "   'top_highlight': ''}],\n",
       " 'b0fbe613be9d': [{'id': 'c06edaa78534',\n",
       "   'title': 'Demonstrate, Search, Predict (DSP) for LLMs',\n",
       "   'subtitle': 'This study which is just over a year old from Stanford, makes for interesting reading and illustrates how far we have come over as short…',\n",
       "   'author': 'b0fbe613be9d',\n",
       "   'publication_id': '*Self-Published*',\n",
       "   'published_at': '2024-02-16 08:18:20',\n",
       "   'last_modified_at': '2024-02-16 08:18:20',\n",
       "   'tags': ['ai',\n",
       "    'artificial-intelligence',\n",
       "    'machine-learning',\n",
       "    'large-language-models',\n",
       "    'conversational-ai'],\n",
       "   'topics': ['machine-learning'],\n",
       "   'claps': 65,\n",
       "   'voters': 9,\n",
       "   'word_count': 873,\n",
       "   'responses_count': 1,\n",
       "   'reading_time': 4.494339622641509,\n",
       "   'url': 'https://cobusgreyling.medium.com/demonstrate-search-predict-dsp-for-llms-c06edaa78534',\n",
       "   'unique_slug': 'demonstrate-search-predict-dsp-for-llms-c06edaa78534',\n",
       "   'image_url': 'https://miro.medium.com/1*54LE60qrXqdvlPMJWLPYNg.png',\n",
       "   'lang': 'en',\n",
       "   'is_series': False,\n",
       "   'is_locked': False,\n",
       "   'is_shortform': False,\n",
       "   'top_highlight': ''},\n",
       "  {'id': '9a5aaa01e437',\n",
       "   'title': 'T-RAG = RAG + Fine-Tuning + Entity Detection',\n",
       "   'subtitle': 'The T-RAG approach is premised on combining RAG architecture with an open-source fine-tuned LLM and an entities tree vector database. The…',\n",
       "   'author': 'b0fbe613be9d',\n",
       "   'publication_id': '*Self-Published*',\n",
       "   'published_at': '2024-02-15 09:08:22',\n",
       "   'last_modified_at': '2024-02-15 09:08:22',\n",
       "   'tags': ['ai',\n",
       "    'artificial-intelligence',\n",
       "    'large-language-models',\n",
       "    'machine-learning',\n",
       "    'conversational-ai'],\n",
       "   'topics': ['machine-learning', 'programming'],\n",
       "   'claps': 283,\n",
       "   'voters': 50,\n",
       "   'word_count': 874,\n",
       "   'responses_count': 2,\n",
       "   'reading_time': 4.34811320754717,\n",
       "   'url': 'https://cobusgreyling.medium.com/t-rag-rag-fine-tuning-entity-detection-9a5aaa01e437',\n",
       "   'unique_slug': 't-rag-rag-fine-tuning-entity-detection-9a5aaa01e437',\n",
       "   'image_url': 'https://miro.medium.com/1*1q3swfPylyxyN-BGOjwTrQ.png',\n",
       "   'lang': 'en',\n",
       "   'is_series': False,\n",
       "   'is_locked': False,\n",
       "   'is_shortform': False,\n",
       "   'top_highlight': 'Subsequently, this information is amalgamated with the document chunks retrieved from the vector database to construct the context.'},\n",
       "  {'id': '1f62a6cbdaef',\n",
       "   'title': 'Run A Small Language Model (SLM) Local & Offline',\n",
       "   'subtitle': 'One notable advantage of SLMs are their flexibility in deployment\\u200a—\\u200athey can be run locally or offline, providing users with greater…',\n",
       "   'author': 'b0fbe613be9d',\n",
       "   'publication_id': '*Self-Published*',\n",
       "   'published_at': '2024-02-14 08:46:14',\n",
       "   'last_modified_at': '2024-02-14 08:46:14',\n",
       "   'tags': ['ai',\n",
       "    'artificial-intelligence',\n",
       "    'machine-learning',\n",
       "    'technology',\n",
       "    'conversational-ai'],\n",
       "   'topics': ['machine-learning'],\n",
       "   'claps': 345,\n",
       "   'voters': 45,\n",
       "   'word_count': 1156,\n",
       "   'responses_count': 1,\n",
       "   'reading_time': 5.612264150943396,\n",
       "   'url': 'https://cobusgreyling.medium.com/run-a-small-language-model-slm-local-offline-1f62a6cbdaef',\n",
       "   'unique_slug': 'run-a-small-language-model-slm-local-offline-1f62a6cbdaef',\n",
       "   'image_url': 'https://miro.medium.com/1*9EaS5q1U-uYJ25wQ5FBxMQ.png',\n",
       "   'lang': 'en',\n",
       "   'is_series': False,\n",
       "   'is_locked': False,\n",
       "   'is_shortform': False,\n",
       "   'top_highlight': 'It demonstrates nearly state-of-the-art performance in common sense, language understanding, and logical reasoning, despite having fewer parameters.'},\n",
       "  {'id': 'd088c69be2fb',\n",
       "   'title': 'The Case For Small Language Models',\n",
       "   'subtitle': 'Microsoft Phi-2 is a small language model capable of common-sense reasoning, language understanding, generation and more…',\n",
       "   'author': 'b0fbe613be9d',\n",
       "   'publication_id': '*Self-Published*',\n",
       "   'published_at': '2024-02-13 10:02:42',\n",
       "   'last_modified_at': '2024-02-13 10:02:42',\n",
       "   'tags': ['ai',\n",
       "    'artificial-intelligence',\n",
       "    'machine-learning',\n",
       "    'conversational-ai',\n",
       "    'chatbots'],\n",
       "   'topics': ['artificial-intelligence', 'machine-learning'],\n",
       "   'claps': 383,\n",
       "   'voters': 22,\n",
       "   'word_count': 1689,\n",
       "   'responses_count': 1,\n",
       "   'reading_time': 7.506918238993711,\n",
       "   'url': 'https://cobusgreyling.medium.com/the-case-for-small-language-models-d088c69be2fb',\n",
       "   'unique_slug': 'the-case-for-small-language-models-d088c69be2fb',\n",
       "   'image_url': 'https://miro.medium.com/1*BIBopB2C6AicmwqpzhLfOA.png',\n",
       "   'lang': 'en',\n",
       "   'is_series': False,\n",
       "   'is_locked': False,\n",
       "   'is_shortform': False,\n",
       "   'top_highlight': ''},\n",
       "  {'id': '3594ee338467',\n",
       "   'title': 'Beyond Chain-of-Thought LLM Reasoning',\n",
       "   'subtitle': 'This approach can be implemented on a prompt level and does not require any dedicated frameworks or pre-processing.',\n",
       "   'author': 'b0fbe613be9d',\n",
       "   'publication_id': '*Self-Published*',\n",
       "   'published_at': '2024-02-12 18:42:55',\n",
       "   'last_modified_at': '2024-02-12 18:43:17',\n",
       "   'tags': ['ai',\n",
       "    'artificial-intelligence',\n",
       "    'machine-learning',\n",
       "    'prompt-engineering',\n",
       "    'conversational-ai'],\n",
       "   'topics': ['artificial-intelligence', 'machine-learning'],\n",
       "   'claps': 90,\n",
       "   'voters': 8,\n",
       "   'word_count': 689,\n",
       "   'responses_count': 0,\n",
       "   'reading_time': 3.7333333333333334,\n",
       "   'url': 'https://cobusgreyling.medium.com/beyond-chain-of-thought-llm-reasoning-3594ee338467',\n",
       "   'unique_slug': 'beyond-chain-of-thought-llm-reasoning-3594ee338467',\n",
       "   'image_url': 'https://miro.medium.com/1*i2s2TWgy5bqxdimGEnbvxA.png',\n",
       "   'lang': 'en',\n",
       "   'is_series': False,\n",
       "   'is_locked': False,\n",
       "   'is_shortform': False,\n",
       "   'top_highlight': ''},\n",
       "  {'id': '44c6d6f7c2f6',\n",
       "   'title': 'Comparing Human, LLM & LLM-RAG Responses',\n",
       "   'subtitle': 'A recent study, focusing on the healthcare & preoperative medicine compared expert human feedback with LLM generation and RAG enhanced…',\n",
       "   'author': 'b0fbe613be9d',\n",
       "   'publication_id': '*Self-Published*',\n",
       "   'published_at': '2024-02-09 12:08:15',\n",
       "   'last_modified_at': '2024-02-09 12:08:15',\n",
       "   'tags': ['ai',\n",
       "    'artificial-intelligence',\n",
       "    'machine-learning',\n",
       "    'large-language-models',\n",
       "    'prompt-engineering'],\n",
       "   'topics': ['artificial-intelligence', 'data-science'],\n",
       "   'claps': 187,\n",
       "   'voters': 24,\n",
       "   'word_count': 546,\n",
       "   'responses_count': 0,\n",
       "   'reading_time': 3.110377358490566,\n",
       "   'url': 'https://cobusgreyling.medium.com/comparing-human-llm-llm-rag-responses-44c6d6f7c2f6',\n",
       "   'unique_slug': 'comparing-human-llm-llm-rag-responses-44c6d6f7c2f6',\n",
       "   'image_url': 'https://miro.medium.com/1*ltyLqlHdBxOqKlrnWLlCUw.png',\n",
       "   'lang': 'en',\n",
       "   'is_series': False,\n",
       "   'is_locked': False,\n",
       "   'is_shortform': False,\n",
       "   'top_highlight': ''},\n",
       "  {'id': 'f574bb9a405e',\n",
       "   'title': 'Craft Successful Conversational User Interfaces: Align User Intent With Developed Intent',\n",
       "   'subtitle': 'In this article I illustrate how to achieve intent alignment by making use of the Kore.ai XO Platform Intent Discovery Tool.',\n",
       "   'author': 'b0fbe613be9d',\n",
       "   'publication_id': '*Self-Published*',\n",
       "   'published_at': '2024-02-08 12:11:10',\n",
       "   'last_modified_at': '2024-02-08 15:20:53',\n",
       "   'tags': ['ai',\n",
       "    'artificial-intelligence',\n",
       "    'conversational-ai',\n",
       "    'conversational-ui',\n",
       "    'chatbots'],\n",
       "   'topics': ['artificial-intelligence'],\n",
       "   'claps': 43,\n",
       "   'voters': 4,\n",
       "   'word_count': 1446,\n",
       "   'responses_count': 1,\n",
       "   'reading_time': 6.656603773584906,\n",
       "   'url': 'https://cobusgreyling.medium.com/craft-successful-conversational-user-interfaces-align-user-intent-with-developed-intent-f574bb9a405e',\n",
       "   'unique_slug': 'craft-successful-conversational-user-interfaces-align-user-intent-with-developed-intent-f574bb9a405e',\n",
       "   'image_url': 'https://miro.medium.com/1*282CBGj0AItCB_EiEMmMIA.png',\n",
       "   'lang': 'en',\n",
       "   'is_series': False,\n",
       "   'is_locked': False,\n",
       "   'is_shortform': False,\n",
       "   'top_highlight': ''},\n",
       "  {'id': '904db5ebeefa',\n",
       "   'title': 'A Benchmark for Verifying Chain-Of-Thought',\n",
       "   'subtitle': 'A Chain-of-Thought is only as strong as its weakest link; a recent study from Google Research created a benchmark for Verifiers of…',\n",
       "   'author': 'b0fbe613be9d',\n",
       "   'publication_id': '*Self-Published*',\n",
       "   'published_at': '2024-02-07 20:56:54',\n",
       "   'last_modified_at': '2024-02-07 20:56:54',\n",
       "   'tags': ['ai',\n",
       "    'artificial-intelligence',\n",
       "    'large-language-models',\n",
       "    'machine-learning',\n",
       "    'conversational-ai'],\n",
       "   'topics': ['machine-learning', 'data-science'],\n",
       "   'claps': 148,\n",
       "   'voters': 5,\n",
       "   'word_count': 816,\n",
       "   'responses_count': 0,\n",
       "   'reading_time': 4.379245283018868,\n",
       "   'url': 'https://cobusgreyling.medium.com/a-benchmark-for-verifying-chain-of-thought-904db5ebeefa',\n",
       "   'unique_slug': 'a-benchmark-for-verifying-chain-of-thought-904db5ebeefa',\n",
       "   'image_url': 'https://miro.medium.com/1*9gQtv8MpXKXt7qKdmh7NRw.png',\n",
       "   'lang': 'en',\n",
       "   'is_series': False,\n",
       "   'is_locked': False,\n",
       "   'is_shortform': False,\n",
       "   'top_highlight': ''},\n",
       "  {'id': '02ead9cc2532',\n",
       "   'title': 'Seven RAG Engineering Failure Points',\n",
       "   'subtitle': 'Retrieval-Augmented Generation (RAG) systems remains a compelling solution to the challenge of relevant up-to-date reference data at…',\n",
       "   'author': 'b0fbe613be9d',\n",
       "   'publication_id': '*Self-Published*',\n",
       "   'published_at': '2024-02-06 14:44:18',\n",
       "   'last_modified_at': '2024-02-06 14:44:18',\n",
       "   'tags': ['ai',\n",
       "    'artificial-intelligence',\n",
       "    'machine-learning',\n",
       "    'large-language-models',\n",
       "    'conversational-ai'],\n",
       "   'topics': ['machine-learning', 'programming'],\n",
       "   'claps': 211,\n",
       "   'voters': 18,\n",
       "   'word_count': 1429,\n",
       "   'responses_count': 0,\n",
       "   'reading_time': 6.092452830188679,\n",
       "   'url': 'https://cobusgreyling.medium.com/seven-rag-engineering-failure-points-02ead9cc2532',\n",
       "   'unique_slug': 'seven-rag-engineering-failure-points-02ead9cc2532',\n",
       "   'image_url': 'https://miro.medium.com/1*ZBt1IUgsv4fKMhWbQJkVqQ.png',\n",
       "   'lang': 'en',\n",
       "   'is_series': False,\n",
       "   'is_locked': False,\n",
       "   'is_shortform': False,\n",
       "   'top_highlight': ''},\n",
       "  {'id': 'f6f3c38656b9',\n",
       "   'title': 'OpenAI Agent Query Planning Using LlamaIndex',\n",
       "   'subtitle': 'Agentic RAG can be described as an agent based approach to perform question answering over multiple documents in an orchestrated fashion…',\n",
       "   'author': 'b0fbe613be9d',\n",
       "   'publication_id': '*Self-Published*',\n",
       "   'published_at': '2024-02-05 15:36:21',\n",
       "   'last_modified_at': '2024-02-05 15:36:21',\n",
       "   'tags': ['ai',\n",
       "    'artificial-intelligence',\n",
       "    'large-language-models',\n",
       "    'machine-learning',\n",
       "    'conversational-ai'],\n",
       "   'topics': ['programming'],\n",
       "   'claps': 46,\n",
       "   'voters': 9,\n",
       "   'word_count': 667,\n",
       "   'responses_count': 0,\n",
       "   'reading_time': 3.466981132075472,\n",
       "   'url': 'https://cobusgreyling.medium.com/openai-agent-query-planning-using-llamaindex-f6f3c38656b9',\n",
       "   'unique_slug': 'openai-agent-query-planning-using-llamaindex-f6f3c38656b9',\n",
       "   'image_url': 'https://miro.medium.com/1*JcQ5Nt-Rz1xBJjVYTTv4rw.png',\n",
       "   'lang': 'en',\n",
       "   'is_series': False,\n",
       "   'is_locked': False,\n",
       "   'is_shortform': False,\n",
       "   'top_highlight': ''}],\n",
       " '14176fcb5743': [{'id': '6921c4f43c2a',\n",
       "   'title': 'Midjourney V6 New Prompting Technique\\u200a—\\u200aIntroduction to “The 4W1H” 🎨',\n",
       "   'subtitle': 'Elevate Your Prompt Writing Structure & Skills',\n",
       "   'author': '14176fcb5743',\n",
       "   'publication_id': '48e972f5c24e',\n",
       "   'published_at': '2023-12-27 13:01:24',\n",
       "   'last_modified_at': '2024-01-24 02:48:22',\n",
       "   'tags': ['midjourney',\n",
       "    'artificial-intelligence',\n",
       "    'creativity',\n",
       "    'design',\n",
       "    'art'],\n",
       "   'topics': ['design'],\n",
       "   'claps': 2487,\n",
       "   'voters': 382,\n",
       "   'word_count': 1369,\n",
       "   'responses_count': 25,\n",
       "   'reading_time': 6.666037735849057,\n",
       "   'url': 'https://bootcamp.uxdesign.cc/midjourney-v6-new-prompting-technique-introduction-to-the-4w1h-6921c4f43c2a',\n",
       "   'unique_slug': 'midjourney-v6-new-prompting-technique-introduction-to-the-4w1h-6921c4f43c2a',\n",
       "   'image_url': 'https://miro.medium.com/1*2QvnFaQZQzbV04MAZcfUJQ.png',\n",
       "   'lang': 'en',\n",
       "   'is_series': False,\n",
       "   'is_locked': True,\n",
       "   'is_shortform': False,\n",
       "   'top_highlight': 'By breaking down the elements of your artwork into What, Who, When, Where, and How, you will assist Midjourney in gaining a deeper understanding of your creative thoughts.'},\n",
       "  {'id': 'b467aa07365e',\n",
       "   'title': '9 Midjourney V6. Prompting Technique You Need to Know 🎨',\n",
       "   'subtitle': 'Relearn Prompt Writing to Take Your AI Art to the Next Level!',\n",
       "   'author': '14176fcb5743',\n",
       "   'publication_id': '48e972f5c24e',\n",
       "   'published_at': '2024-01-19 13:01:48',\n",
       "   'last_modified_at': '2024-02-12 10:11:21',\n",
       "   'tags': ['midjourney',\n",
       "    'artificial-intelligence',\n",
       "    'creativity',\n",
       "    'design',\n",
       "    'art'],\n",
       "   'topics': ['artificial-intelligence', 'design', 'programming'],\n",
       "   'claps': 1143,\n",
       "   'voters': 132,\n",
       "   'word_count': 1887,\n",
       "   'responses_count': 10,\n",
       "   'reading_time': 9.070754716981131,\n",
       "   'url': 'https://bootcamp.uxdesign.cc/9-midjourney-v6-prompting-technique-you-need-to-know-b467aa07365e',\n",
       "   'unique_slug': '9-midjourney-v6-prompting-technique-you-need-to-know-b467aa07365e',\n",
       "   'image_url': 'https://miro.medium.com/1*EgyE5HYnjwDhLjJR04NPcw.png',\n",
       "   'lang': 'en',\n",
       "   'is_series': False,\n",
       "   'is_locked': True,\n",
       "   'is_shortform': False,\n",
       "   'top_highlight': ''},\n",
       "  {'id': '5afc5b228cb3',\n",
       "   'title': 'One Magical Midjourney Prompt to Elevate Your Creativity!',\n",
       "   'subtitle': 'Level Up Your AI Image with this One Word',\n",
       "   'author': '14176fcb5743',\n",
       "   'publication_id': '48e972f5c24e',\n",
       "   'published_at': '2023-11-13 13:02:01',\n",
       "   'last_modified_at': '2023-12-19 09:34:03',\n",
       "   'tags': ['midjourney',\n",
       "    'artificial-intelligence',\n",
       "    'creativity',\n",
       "    'design',\n",
       "    'art'],\n",
       "   'topics': ['design'],\n",
       "   'claps': 830,\n",
       "   'voters': 85,\n",
       "   'word_count': 1186,\n",
       "   'responses_count': 14,\n",
       "   'reading_time': 6.225471698113208,\n",
       "   'url': 'https://bootcamp.uxdesign.cc/one-magical-midjourney-prompt-to-elevate-your-creativity-5afc5b228cb3',\n",
       "   'unique_slug': 'one-magical-midjourney-prompt-to-elevate-your-creativity-5afc5b228cb3',\n",
       "   'image_url': 'https://miro.medium.com/1*9LYsteVtPZ629V14eYA17A.png',\n",
       "   'lang': 'en',\n",
       "   'is_series': False,\n",
       "   'is_locked': True,\n",
       "   'is_shortform': False,\n",
       "   'top_highlight': 'Prompt: [ People ], picking a [ Food ], bright studio light, [ Color ] background, minimalist, miniature food photography, soft color blending --ar 3:4'},\n",
       "  {'id': '71196de661cb',\n",
       "   'title': '20+ Incredible Midjourney Prompts You Must Try!',\n",
       "   'subtitle': 'Elevate Your AI Arts with These Creative Prompts',\n",
       "   'author': '14176fcb5743',\n",
       "   'publication_id': '48e972f5c24e',\n",
       "   'published_at': '2023-11-06 13:01:59',\n",
       "   'last_modified_at': '2024-01-18 01:36:25',\n",
       "   'tags': ['midjourney',\n",
       "    'artificial-intelligence',\n",
       "    'creativity',\n",
       "    'art',\n",
       "    'design'],\n",
       "   'topics': ['artificial-intelligence', 'design'],\n",
       "   'claps': 1112,\n",
       "   'voters': 160,\n",
       "   'word_count': 1278,\n",
       "   'responses_count': 20,\n",
       "   'reading_time': 6.722641509433963,\n",
       "   'url': 'https://bootcamp.uxdesign.cc/x20-incredible-midjourney-prompts-you-must-try-71196de661cb',\n",
       "   'unique_slug': 'x20-incredible-midjourney-prompts-you-must-try-71196de661cb',\n",
       "   'image_url': 'https://miro.medium.com/1*aYQLn2P3QdFqB-d8UdfZNA.png',\n",
       "   'lang': 'en',\n",
       "   'is_series': False,\n",
       "   'is_locked': True,\n",
       "   'is_shortform': False,\n",
       "   'top_highlight': 'Prompt: Blacklight planet in the galaxy, fancy dreamy'},\n",
       "  {'id': '27e9975cce9c',\n",
       "   'title': 'Midjourney Comprehensive Guide: Commands, Features and Tricks here!',\n",
       "   'subtitle': 'How to Use Midjourney to Elevate Your Images and Creativity',\n",
       "   'author': '14176fcb5743',\n",
       "   'publication_id': '48e972f5c24e',\n",
       "   'published_at': '2023-07-30 13:02:32',\n",
       "   'last_modified_at': '2024-01-04 03:03:59',\n",
       "   'tags': ['midjourney',\n",
       "    'artificial-intelligence',\n",
       "    'creativity',\n",
       "    'design',\n",
       "    'future'],\n",
       "   'topics': ['design'],\n",
       "   'claps': 1085,\n",
       "   'voters': 193,\n",
       "   'word_count': 1998,\n",
       "   'responses_count': 18,\n",
       "   'reading_time': 9.489622641509433,\n",
       "   'url': 'https://bootcamp.uxdesign.cc/a-comprehensive-midjourney-guide-commands-features-and-tricks-here-27e9975cce9c',\n",
       "   'unique_slug': 'a-comprehensive-midjourney-guide-commands-features-and-tricks-here-27e9975cce9c',\n",
       "   'image_url': 'https://miro.medium.com/1*jARZCchLet3ZIpvMvN01Qg.png',\n",
       "   'lang': 'en',\n",
       "   'is_series': False,\n",
       "   'is_locked': True,\n",
       "   'is_shortform': False,\n",
       "   'top_highlight': 'Using the same seed number will produce a similar style.'},\n",
       "  {'id': 'da3e4b1ac900',\n",
       "   'title': 'Top 12 Visual Design Trends for 2024 That Boost Engagement (Part 2)',\n",
       "   'subtitle': 'The Hottest Creative Styles to Captivate Audiences This Year',\n",
       "   'author': '14176fcb5743',\n",
       "   'publication_id': '*Self-Published*',\n",
       "   'published_at': '2024-02-18 13:01:39',\n",
       "   'last_modified_at': '2024-02-18 13:01:39',\n",
       "   'tags': ['midjourney',\n",
       "    'artificial-intelligence',\n",
       "    'creativity',\n",
       "    'design',\n",
       "    'make-money'],\n",
       "   'topics': ['design'],\n",
       "   'claps': 336,\n",
       "   'voters': 18,\n",
       "   'word_count': 1327,\n",
       "   'responses_count': 5,\n",
       "   'reading_time': 7.007547169811321,\n",
       "   'url': 'https://medium.com/@inchristiely/top-12-visual-design-trends-for-2024-that-boost-engagement-part-2-da3e4b1ac900',\n",
       "   'unique_slug': 'top-12-visual-design-trends-for-2024-that-boost-engagement-part-2-da3e4b1ac900',\n",
       "   'image_url': 'https://miro.medium.com/1*AUCseY5Vt4MMvTlUwf6zpA.png',\n",
       "   'lang': 'en',\n",
       "   'is_series': False,\n",
       "   'is_locked': True,\n",
       "   'is_shortform': False,\n",
       "   'top_highlight': ''},\n",
       "  {'id': '572cd5758aa6',\n",
       "   'title': 'Top 12 Visual Design Trends for 2024 That Boost Engagement',\n",
       "   'subtitle': 'The Hottest Creative Styles to Captivate Audiences This Year',\n",
       "   'author': '14176fcb5743',\n",
       "   'publication_id': '48e972f5c24e',\n",
       "   'published_at': '2024-02-17 13:01:57',\n",
       "   'last_modified_at': '2024-02-17 21:52:30',\n",
       "   'tags': ['design', 'creativity', 'art', 'midjourney', 'make-money-online'],\n",
       "   'topics': ['design'],\n",
       "   'claps': 410,\n",
       "   'voters': 26,\n",
       "   'word_count': 1313,\n",
       "   'responses_count': 2,\n",
       "   'reading_time': 6.904716981132076,\n",
       "   'url': 'https://bootcamp.uxdesign.cc/top-12-visual-design-trends-for-2024-that-boost-engagement-572cd5758aa6',\n",
       "   'unique_slug': 'top-12-visual-design-trends-for-2024-that-boost-engagement-572cd5758aa6',\n",
       "   'image_url': 'https://miro.medium.com/1*D0D5XzAIxQ7ywOYPVNbyag.png',\n",
       "   'lang': 'en',\n",
       "   'is_series': False,\n",
       "   'is_locked': True,\n",
       "   'is_shortform': False,\n",
       "   'top_highlight': ''},\n",
       "  {'id': '865c0b54d1cb',\n",
       "   'title': 'Midjourney V6 Alpha is Now the Default with Improvements to Details, Contrast and Coherence🔥',\n",
       "   'subtitle': 'Prepared for NEW “describe” and “Character Consistency” Coming Soon!',\n",
       "   'author': '14176fcb5743',\n",
       "   'publication_id': '48e972f5c24e',\n",
       "   'published_at': '2024-02-15 13:02:01',\n",
       "   'last_modified_at': '2024-02-15 23:48:39',\n",
       "   'tags': ['midjourney',\n",
       "    'artificial-intelligence',\n",
       "    'creativity',\n",
       "    'design',\n",
       "    'art'],\n",
       "   'topics': ['design', 'programming'],\n",
       "   'claps': 163,\n",
       "   'voters': 11,\n",
       "   'word_count': 1155,\n",
       "   'responses_count': 2,\n",
       "   'reading_time': 5.758490566037736,\n",
       "   'url': 'https://bootcamp.uxdesign.cc/midjourney-v6-alpha-is-now-the-default-with-improvements-to-details-contrast-and-coherence-865c0b54d1cb',\n",
       "   'unique_slug': 'midjourney-v6-alpha-is-now-the-default-with-improvements-to-details-contrast-and-coherence-865c0b54d1cb',\n",
       "   'image_url': 'https://miro.medium.com/1*wybK0zuHORyKn8YH0AAELQ.png',\n",
       "   'lang': 'en',\n",
       "   'is_series': False,\n",
       "   'is_locked': True,\n",
       "   'is_shortform': False,\n",
       "   'top_highlight': ''},\n",
       "  {'id': '6e8d6357da20',\n",
       "   'title': 'Midjourney V6 Essential- Transform Style with “Remix” 🎨',\n",
       "   'subtitle': 'A Structure to follow with Visual Examples and Usage',\n",
       "   'author': '14176fcb5743',\n",
       "   'publication_id': '48e972f5c24e',\n",
       "   'published_at': '2024-02-12 13:01:48',\n",
       "   'last_modified_at': '2024-02-12 22:20:55',\n",
       "   'tags': ['midjourney',\n",
       "    'artificial-intelligence',\n",
       "    'creativity',\n",
       "    'design',\n",
       "    'art'],\n",
       "   'topics': ['design'],\n",
       "   'claps': 416,\n",
       "   'voters': 25,\n",
       "   'word_count': 1279,\n",
       "   'responses_count': 5,\n",
       "   'reading_time': 6.576415094339622,\n",
       "   'url': 'https://bootcamp.uxdesign.cc/midjourney-v6-essential-transform-style-with-remix-6e8d6357da20',\n",
       "   'unique_slug': 'midjourney-v6-essential-transform-style-with-remix-6e8d6357da20',\n",
       "   'image_url': 'https://miro.medium.com/1*SrQ7YHs4cumUYkm1j5Kxfw.png',\n",
       "   'lang': 'en',\n",
       "   'is_series': False,\n",
       "   'is_locked': True,\n",
       "   'is_shortform': False,\n",
       "   'top_highlight': ''},\n",
       "  {'id': '92741d8fb067',\n",
       "   'title': 'Ultimate Guide to Using Midjourney Website Alpha! 💻',\n",
       "   'subtitle': 'Image Generation, Batch download and Smart Organisation with Ease!',\n",
       "   'author': '14176fcb5743',\n",
       "   'publication_id': '48e972f5c24e',\n",
       "   'published_at': '2024-02-09 13:01:32',\n",
       "   'last_modified_at': '2024-02-09 21:42:14',\n",
       "   'tags': ['midjourney',\n",
       "    'artificial-intelligence',\n",
       "    'creativity',\n",
       "    'design',\n",
       "    'art'],\n",
       "   'topics': ['design'],\n",
       "   'claps': 584,\n",
       "   'voters': 55,\n",
       "   'word_count': 1139,\n",
       "   'responses_count': 7,\n",
       "   'reading_time': 6.44811320754717,\n",
       "   'url': 'https://bootcamp.uxdesign.cc/ultimate-guide-to-using-midjourney-website-alpha-92741d8fb067',\n",
       "   'unique_slug': 'ultimate-guide-to-using-midjourney-website-alpha-92741d8fb067',\n",
       "   'image_url': 'https://miro.medium.com/1*wkYFlLubAFBU-8aWHkqtfQ.png',\n",
       "   'lang': 'en',\n",
       "   'is_series': False,\n",
       "   'is_locked': True,\n",
       "   'is_shortform': False,\n",
       "   'top_highlight': ''}],\n",
       " '9b351e8113e9': [{'id': 'a2ce57de0b02',\n",
       "   'title': 'Is Mamba the End of ChatGPT As We Know It?',\n",
       "   'subtitle': 'The Great New Question',\n",
       "   'author': '9b351e8113e9',\n",
       "   'publication_id': '98111c9905da',\n",
       "   'published_at': '2024-01-11 18:02:22',\n",
       "   'last_modified_at': '2024-01-11 18:02:22',\n",
       "   'tags': ['technology',\n",
       "    'artificial-intelligence',\n",
       "    'chatgpt',\n",
       "    'future',\n",
       "    'data-science'],\n",
       "   'topics': ['artificial-intelligence', 'machine-learning'],\n",
       "   'claps': 6308,\n",
       "   'voters': 1229,\n",
       "   'word_count': 1711,\n",
       "   'responses_count': 76,\n",
       "   'reading_time': 7.406603773584906,\n",
       "   'url': 'https://pub.towardsai.net/is-mamba-the-end-of-chatgpt-as-we-know-it-a2ce57de0b02',\n",
       "   'unique_slug': 'is-mamba-the-end-of-chatgpt-as-we-know-it-a2ce57de0b02',\n",
       "   'image_url': 'https://miro.medium.com/0*Igf3DFdae9Kd14Iy',\n",
       "   'lang': 'en',\n",
       "   'is_series': False,\n",
       "   'is_locked': True,\n",
       "   'is_shortform': False,\n",
       "   'top_highlight': 'Just like the attention module sits at the core of the Transformer, the Selective State Space Model (Selective SSM) sits at the core of Mamba.'},\n",
       "  {'id': '818b2a8ad33e',\n",
       "   'title': 'OpenAI Just Killed an Entire Market in 45 Minutes',\n",
       "   'subtitle': 'The Story Everyone Should Have Seen Coming',\n",
       "   'author': '9b351e8113e9',\n",
       "   'publication_id': '*Self-Published*',\n",
       "   'published_at': '2023-11-09 17:24:58',\n",
       "   'last_modified_at': '2023-11-09 17:24:58',\n",
       "   'tags': ['artificial-intelligence',\n",
       "    'programming',\n",
       "    'business',\n",
       "    'technology',\n",
       "    'future'],\n",
       "   'topics': ['artificial-intelligence'],\n",
       "   'claps': 14479,\n",
       "   'voters': 2876,\n",
       "   'word_count': 1262,\n",
       "   'responses_count': 233,\n",
       "   'reading_time': 5.312264150943396,\n",
       "   'url': 'https://medium.com/@ignacio.de.gregorio.noblejas/openai-just-killed-an-entire-market-in-45-minutes-818b2a8ad33e',\n",
       "   'unique_slug': 'openai-just-killed-an-entire-market-in-45-minutes-818b2a8ad33e',\n",
       "   'image_url': 'https://miro.medium.com/1*OL0MU1g3AT0dZSfswimi3Q.png',\n",
       "   'lang': 'en',\n",
       "   'is_series': False,\n",
       "   'is_locked': True,\n",
       "   'is_shortform': False,\n",
       "   'top_highlight': 'A product or solution that makes the lives of people who use it easier.'},\n",
       "  {'id': '680450c472c',\n",
       "   'title': 'Google goes beyond ChatGPT and shocks the world',\n",
       "   'subtitle': 'The new age of robots is upon us',\n",
       "   'author': '9b351e8113e9',\n",
       "   'publication_id': '*Self-Published*',\n",
       "   'published_at': '2023-03-02 19:03:12',\n",
       "   'last_modified_at': '2023-03-26 11:34:05',\n",
       "   'tags': ['artificial-intelligence',\n",
       "    'technology',\n",
       "    'ai',\n",
       "    'automation',\n",
       "    'google'],\n",
       "   'topics': ['artificial-intelligence'],\n",
       "   'claps': 2485,\n",
       "   'voters': 581,\n",
       "   'word_count': 1723,\n",
       "   'responses_count': 41,\n",
       "   'reading_time': 7.05188679245283,\n",
       "   'url': 'https://medium.com/@ignacio.de.gregorio.noblejas/offline-rl-680450c472c',\n",
       "   'unique_slug': 'offline-rl-680450c472c',\n",
       "   'image_url': 'https://miro.medium.com/0*-g_1d5r1GpXXuoT4',\n",
       "   'lang': 'en',\n",
       "   'is_series': False,\n",
       "   'is_locked': True,\n",
       "   'is_shortform': False,\n",
       "   'top_highlight': 'You measure an error and you find ways to minimize it by giving the model a lot of data.'},\n",
       "  {'id': '4cc9cf343185',\n",
       "   'title': 'An AI more impressive than ChatGPT is here',\n",
       "   'subtitle': 'Action Transformers are the next leap for AI',\n",
       "   'author': '9b351e8113e9',\n",
       "   'publication_id': '*Self-Published*',\n",
       "   'published_at': '2023-01-28 14:22:28',\n",
       "   'last_modified_at': '2023-02-03 09:29:32',\n",
       "   'tags': ['artificial-intelligence',\n",
       "    'technology',\n",
       "    'investing',\n",
       "    'productivity',\n",
       "    'automation'],\n",
       "   'topics': ['artificial-intelligence'],\n",
       "   'claps': 2571,\n",
       "   'voters': 462,\n",
       "   'word_count': 1794,\n",
       "   'responses_count': 49,\n",
       "   'reading_time': 6.969811320754717,\n",
       "   'url': 'https://medium.com/@ignacio.de.gregorio.noblejas/ai-more-impressive-than-chatgpt-4cc9cf343185',\n",
       "   'unique_slug': 'ai-more-impressive-than-chatgpt-4cc9cf343185',\n",
       "   'image_url': 'https://miro.medium.com/0*xHXIND6zAmCSovN_',\n",
       "   'lang': 'en',\n",
       "   'is_series': False,\n",
       "   'is_locked': True,\n",
       "   'is_shortform': False,\n",
       "   'top_highlight': 'Adept.ai is no ordinary startup.'},\n",
       "  {'id': '6d59742ee635',\n",
       "   'title': 'Can ChatGPT kill Google?',\n",
       "   'subtitle': 'AI is disrupting everything, even trillion-dollar businesses',\n",
       "   'author': '9b351e8113e9',\n",
       "   'publication_id': '*Self-Published*',\n",
       "   'published_at': '2022-12-28 18:27:04',\n",
       "   'last_modified_at': '2022-12-30 20:35:00',\n",
       "   'tags': ['artificial-intelligence',\n",
       "    'ai',\n",
       "    'technology',\n",
       "    'google',\n",
       "    'investing'],\n",
       "   'topics': ['artificial-intelligence', 'business', 'technology'],\n",
       "   'claps': 6341,\n",
       "   'voters': 1445,\n",
       "   'word_count': 1418,\n",
       "   'responses_count': 227,\n",
       "   'reading_time': 5.734276729559749,\n",
       "   'url': 'https://medium.com/@ignacio.de.gregorio.noblejas/can-chatgpt-kill-google-6d59742ee635',\n",
       "   'unique_slug': 'can-chatgpt-kill-google-6d59742ee635',\n",
       "   'image_url': 'https://miro.medium.com/0*3bPbSq7pXs8P5Mdq',\n",
       "   'lang': 'en',\n",
       "   'is_series': False,\n",
       "   'is_locked': True,\n",
       "   'is_shortform': False,\n",
       "   'top_highlight': 'Can ChatGPT kill Google?'},\n",
       "  {'id': '158587d68dfe',\n",
       "   'title': 'Lumiere, Google’s Amazing Video Breakthrough',\n",
       "   'subtitle': 'Text-to-Video on a new level',\n",
       "   'author': '9b351e8113e9',\n",
       "   'publication_id': '98111c9905da',\n",
       "   'published_at': '2024-02-13 20:01:50',\n",
       "   'last_modified_at': '2024-02-13 20:01:50',\n",
       "   'tags': ['artificial-intelligence',\n",
       "    'technology',\n",
       "    'google',\n",
       "    'data-science',\n",
       "    'future'],\n",
       "   'topics': ['artificial-intelligence', 'machine-learning'],\n",
       "   'claps': 1196,\n",
       "   'voters': 119,\n",
       "   'word_count': 1492,\n",
       "   'responses_count': 9,\n",
       "   'reading_time': 6.880188679245283,\n",
       "   'url': 'https://pub.towardsai.net/lumiere-googles-amazing-video-breakthrough-158587d68dfe',\n",
       "   'unique_slug': 'lumiere-googles-amazing-video-breakthrough-158587d68dfe',\n",
       "   'image_url': 'https://miro.medium.com/0*XOdZjJp7-DELdwB9',\n",
       "   'lang': 'en',\n",
       "   'is_series': False,\n",
       "   'is_locked': True,\n",
       "   'is_shortform': False,\n",
       "   'top_highlight': ''},\n",
       "  {'id': 'd49b7a88ec2e',\n",
       "   'title': 'Demystifying 1X’s Incredible AI Androids',\n",
       "   'subtitle': 'Understanding The Incredible Demonstration',\n",
       "   'author': '9b351e8113e9',\n",
       "   'publication_id': '*Self-Published*',\n",
       "   'published_at': '2024-02-10 18:26:02',\n",
       "   'last_modified_at': '2024-02-10 18:26:02',\n",
       "   'tags': ['artificial-intelligence',\n",
       "    'technology',\n",
       "    'robotics',\n",
       "    'future',\n",
       "    'business'],\n",
       "   'topics': ['artificial-intelligence'],\n",
       "   'claps': 204,\n",
       "   'voters': 28,\n",
       "   'word_count': 1270,\n",
       "   'responses_count': 1,\n",
       "   'reading_time': 5.49245283018868,\n",
       "   'url': 'https://medium.com/@ignacio.de.gregorio.noblejas/demystifying-1xs-incredible-ai-androids-d49b7a88ec2e',\n",
       "   'unique_slug': 'demystifying-1xs-incredible-ai-androids-d49b7a88ec2e',\n",
       "   'image_url': 'https://miro.medium.com/0*uXMEP240i5mTflit.jpg',\n",
       "   'lang': 'en',\n",
       "   'is_series': False,\n",
       "   'is_locked': True,\n",
       "   'is_shortform': False,\n",
       "   'top_highlight': ''},\n",
       "  {'id': '81af3d4be61c',\n",
       "   'title': 'Google Finally Challenges ChatGPT',\n",
       "   'subtitle': 'A turning point for AI?',\n",
       "   'author': '9b351e8113e9',\n",
       "   'publication_id': '98111c9905da',\n",
       "   'published_at': '2024-02-06 00:01:59',\n",
       "   'last_modified_at': '2024-02-06 00:01:59',\n",
       "   'tags': ['artificial-intelligence',\n",
       "    'technology',\n",
       "    'google',\n",
       "    'data-science',\n",
       "    'chatgpt'],\n",
       "   'topics': ['artificial-intelligence', 'machine-learning'],\n",
       "   'claps': 737,\n",
       "   'voters': 57,\n",
       "   'word_count': 1454,\n",
       "   'responses_count': 8,\n",
       "   'reading_time': 6.186792452830189,\n",
       "   'url': 'https://pub.towardsai.net/google-finally-challenges-chatgpt-81af3d4be61c',\n",
       "   'unique_slug': 'google-finally-challenges-chatgpt-81af3d4be61c',\n",
       "   'image_url': 'https://miro.medium.com/0*Kc3HwZcMF5-0LLev',\n",
       "   'lang': 'en',\n",
       "   'is_series': False,\n",
       "   'is_locked': True,\n",
       "   'is_shortform': False,\n",
       "   'top_highlight': ''},\n",
       "  {'id': 'e7f55b0514a1',\n",
       "   'title': 'Meta’s Self-Rewarding Models, the Key to SuperHuman LLMs?',\n",
       "   'subtitle': 'Meta, the company behind Facebook, Whatsapp, and Rayban’s Meta glasses, has announced a recent, highly promising AI breakthrough…',\n",
       "   'author': '9b351e8113e9',\n",
       "   'publication_id': '98111c9905da',\n",
       "   'published_at': '2024-01-30 22:01:37',\n",
       "   'last_modified_at': '2024-01-30 22:01:37',\n",
       "   'tags': ['artificial-intelligence',\n",
       "    'technology',\n",
       "    'future',\n",
       "    'business',\n",
       "    'data-science'],\n",
       "   'topics': ['artificial-intelligence', 'machine-learning'],\n",
       "   'claps': 644,\n",
       "   'voters': 75,\n",
       "   'word_count': 1206,\n",
       "   'responses_count': 11,\n",
       "   'reading_time': 5.3842767295597485,\n",
       "   'url': 'https://pub.towardsai.net/metas-self-rewarding-models-the-key-to-superhuman-llms-e7f55b0514a1',\n",
       "   'unique_slug': 'metas-self-rewarding-models-the-key-to-superhuman-llms-e7f55b0514a1',\n",
       "   'image_url': 'https://miro.medium.com/0*nekYT7IptIXWKufq',\n",
       "   'lang': 'en',\n",
       "   'is_series': False,\n",
       "   'is_locked': True,\n",
       "   'is_shortform': False,\n",
       "   'top_highlight': \"Meta, the company behind Facebook, Whatsapp, and Rayban's Meta glasses, has announced a recent, highly promising AI breakthrough, Self-Rewarding Language Models.\"},\n",
       "  {'id': '01deab746b42',\n",
       "   'title': 'I Found The Recipe for Cocaine on Instagram',\n",
       "   'subtitle': 'The Cost of AI Progress, or Facing Reality?',\n",
       "   'author': '9b351e8113e9',\n",
       "   'publication_id': '*Self-Published*',\n",
       "   'published_at': '2024-01-27 18:22:08',\n",
       "   'last_modified_at': '2024-01-27 18:22:08',\n",
       "   'tags': ['artificial-intelligence',\n",
       "    'technology',\n",
       "    'instagram',\n",
       "    'chatgpt',\n",
       "    'future'],\n",
       "   'topics': ['artificial-intelligence', 'machine-learning'],\n",
       "   'claps': 270,\n",
       "   'voters': 27,\n",
       "   'word_count': 1442,\n",
       "   'responses_count': 4,\n",
       "   'reading_time': 5.6415094339622645,\n",
       "   'url': 'https://medium.com/@ignacio.de.gregorio.noblejas/i-found-the-recipe-for-cocaine-on-instagram-01deab746b42',\n",
       "   'unique_slug': 'i-found-the-recipe-for-cocaine-on-instagram-01deab746b42',\n",
       "   'image_url': 'https://miro.medium.com/0*hyw9dpRX-jB1x5ul',\n",
       "   'lang': 'en',\n",
       "   'is_series': False,\n",
       "   'is_locked': True,\n",
       "   'is_shortform': False,\n",
       "   'top_highlight': 'I Found The Recipe for Cocaine on Instagram'}],\n",
       " '5d33decdf4c4': [{'id': '83e870b5f0e4',\n",
       "   'title': '320+ Python and Data Science Tips\\u200a—\\u200aCovering Pandas, NumPy, ML Basics, Sklearn, Jupyter, and More.',\n",
       "   'subtitle': 'A self-curated collection of Python and Data Science tips to level up your data game.',\n",
       "   'author': '5d33decdf4c4',\n",
       "   'publication_id': 'a648dc4ecb66',\n",
       "   'published_at': '2023-10-06 11:49:29',\n",
       "   'last_modified_at': '2023-10-06 11:49:29',\n",
       "   'tags': ['data-science',\n",
       "    'artificial-intelligence',\n",
       "    'machine-learning',\n",
       "    'python',\n",
       "    'technology'],\n",
       "   'topics': ['data-science'],\n",
       "   'claps': 853,\n",
       "   'voters': 220,\n",
       "   'word_count': 1017,\n",
       "   'responses_count': 10,\n",
       "   'reading_time': 5.2377358490566035,\n",
       "   'url': 'https://towardsdev.com/320-python-and-data-science-tips-covering-pandas-numpy-ml-basics-sklearn-jupyter-and-more-83e870b5f0e4',\n",
       "   'unique_slug': '320-python-and-data-science-tips-covering-pandas-numpy-ml-basics-sklearn-jupyter-and-more-83e870b5f0e4',\n",
       "   'image_url': 'https://miro.medium.com/1*E_pmPQYZ7eMxd_eKxgpKqg.png',\n",
       "   'lang': 'en',\n",
       "   'is_series': False,\n",
       "   'is_locked': False,\n",
       "   'is_shortform': False,\n",
       "   'top_highlight': ''},\n",
       "  {'id': 'a4ff1b694707',\n",
       "   'title': '20% of Pandas Functions that Data Scientists Use 80% of the Time',\n",
       "   'subtitle': 'Putting Pareto’s Principle to work on the Pandas library',\n",
       "   'author': '5d33decdf4c4',\n",
       "   'publication_id': '7f60cf5620c9',\n",
       "   'published_at': '2022-05-16 12:05:21',\n",
       "   'last_modified_at': '2022-05-16 20:12:26',\n",
       "   'tags': ['pandas', 'data-science', 'python', 'dataframes'],\n",
       "   'topics': ['data-science', 'programming'],\n",
       "   'claps': 1581,\n",
       "   'voters': 530,\n",
       "   'word_count': 803,\n",
       "   'responses_count': 12,\n",
       "   'reading_time': 4.780188679245283,\n",
       "   'url': 'https://towardsdatascience.com/20-of-pandas-functions-that-data-scientists-use-80-of-the-time-a4ff1b694707',\n",
       "   'unique_slug': '20-of-pandas-functions-that-data-scientists-use-80-of-the-time-a4ff1b694707',\n",
       "   'image_url': 'https://miro.medium.com/0*qjsBnhHUXY5XV-wX',\n",
       "   'lang': 'en',\n",
       "   'is_series': False,\n",
       "   'is_locked': True,\n",
       "   'is_shortform': False,\n",
       "   'top_highlight': \"Mastering an entire Python library like Pandas can be challenging for anyone. However, if we take a step back and think, do we really need to be aware of every minute detail of a specific library, especially when we live in a world governed by Pareto's Principle? For those who don't know, Pareto's Principle (also known as the 80–20 rule) says that 20% of your inputs will always contribute towards generating 80% of your outputs.\"},\n",
       "  {'id': 'c0954c410f8f',\n",
       "   'title': 'Why I Stopped Dumping DataFrames to a CSV and Why You Should Too',\n",
       "   'subtitle': 'It’s time to say goodbye to pd.to_csv() and pd.read_csv()',\n",
       "   'author': '5d33decdf4c4',\n",
       "   'publication_id': '7f60cf5620c9',\n",
       "   'published_at': '2022-05-10 18:23:41',\n",
       "   'last_modified_at': '2022-05-12 13:02:50',\n",
       "   'tags': ['pandas', 'programming', 'csv', 'dataframes'],\n",
       "   'topics': ['data-science', 'programming'],\n",
       "   'claps': 1359,\n",
       "   'voters': 478,\n",
       "   'word_count': 761,\n",
       "   'responses_count': 27,\n",
       "   'reading_time': 3.571698113207547,\n",
       "   'url': 'https://towardsdatascience.com/why-i-stopped-dumping-dataframes-to-a-csv-and-why-you-should-too-c0954c410f8f',\n",
       "   'unique_slug': 'why-i-stopped-dumping-dataframes-to-a-csv-and-why-you-should-too-c0954c410f8f',\n",
       "   'image_url': 'https://miro.medium.com/0*UnRRF7CCQ91Uwk7t',\n",
       "   'lang': 'en',\n",
       "   'is_series': False,\n",
       "   'is_locked': True,\n",
       "   'is_shortform': False,\n",
       "   'top_highlight': 'In my opinion, both Parquet and Feather are the best available file formats out there to choose from the six we have explored in this post.'},\n",
       "  {'id': 'fb0c1f1f2972',\n",
       "   'title': 'Introducing IceCream: Never Use Print() To Debug Your Python Code Again',\n",
       "   'subtitle': 'Why I stopped using print() statements for debugging and why you should too',\n",
       "   'author': '5d33decdf4c4',\n",
       "   'publication_id': '32881626c9c9',\n",
       "   'published_at': '2024-01-29 07:24:23',\n",
       "   'last_modified_at': '2024-01-29 10:21:50',\n",
       "   'tags': ['data-science',\n",
       "    'machine-learning',\n",
       "    'artificial-intelligence',\n",
       "    'python',\n",
       "    'programming'],\n",
       "   'topics': ['programming'],\n",
       "   'claps': 556,\n",
       "   'voters': 84,\n",
       "   'word_count': 893,\n",
       "   'responses_count': 6,\n",
       "   'reading_time': 4.069811320754717,\n",
       "   'url': 'https://medium.datadriveninvestor.com/introducing-icecream-never-use-print-to-debug-your-python-code-again-fb0c1f1f2972',\n",
       "   'unique_slug': 'introducing-icecream-never-use-print-to-debug-your-python-code-again-fb0c1f1f2972',\n",
       "   'image_url': 'https://miro.medium.com/0*2n51QKEzXu0iKtBK',\n",
       "   'lang': 'en',\n",
       "   'is_series': False,\n",
       "   'is_locked': True,\n",
       "   'is_shortform': False,\n",
       "   'top_highlight': ''},\n",
       "  {'id': '5edf898909e7',\n",
       "   'title': 'Introducing Pandarallel: Never Use The Apply Method In Pandas Again',\n",
       "   'subtitle': 'Why I stopped using Apply() in Pandas and why you should too.',\n",
       "   'author': '5d33decdf4c4',\n",
       "   'publication_id': '32881626c9c9',\n",
       "   'published_at': '2024-01-24 10:59:56',\n",
       "   'last_modified_at': '2024-02-01 10:26:40',\n",
       "   'tags': ['data-science',\n",
       "    'machine-learning',\n",
       "    'pandas',\n",
       "    'python',\n",
       "    'artificial-intelligence'],\n",
       "   'topics': ['data-science', 'programming'],\n",
       "   'claps': 352,\n",
       "   'voters': 67,\n",
       "   'word_count': 809,\n",
       "   'responses_count': 3,\n",
       "   'reading_time': 4.1028301886792455,\n",
       "   'url': 'https://medium.datadriveninvestor.com/introducing-pandarallel-never-use-the-apply-method-in-pandas-again-5edf898909e7',\n",
       "   'unique_slug': 'introducing-pandarallel-never-use-the-apply-method-in-pandas-again-5edf898909e7',\n",
       "   'image_url': 'https://miro.medium.com/0*bR4akeZyYmtpC98C',\n",
       "   'lang': 'en',\n",
       "   'is_series': False,\n",
       "   'is_locked': True,\n",
       "   'is_shortform': False,\n",
       "   'top_highlight': ''},\n",
       "  {'id': 'ddbf9b5039a1',\n",
       "   'title': '5 Things I Wish the Pandas Library Could Do',\n",
       "   'subtitle': 'Discussing five subtle limitations of Pandas',\n",
       "   'author': '5d33decdf4c4',\n",
       "   'publication_id': '32881626c9c9',\n",
       "   'published_at': '2024-01-24 10:59:47',\n",
       "   'last_modified_at': '2024-02-13 05:38:21',\n",
       "   'tags': ['data-science',\n",
       "    'machine-learning',\n",
       "    'sql',\n",
       "    'python',\n",
       "    'artificial-intelligence'],\n",
       "   'topics': ['data-science', 'programming'],\n",
       "   'claps': 313,\n",
       "   'voters': 25,\n",
       "   'word_count': 1804,\n",
       "   'responses_count': 3,\n",
       "   'reading_time': 7.857547169811321,\n",
       "   'url': 'https://medium.datadriveninvestor.com/5-things-i-wish-the-pandas-library-could-do-ddbf9b5039a1',\n",
       "   'unique_slug': '5-things-i-wish-the-pandas-library-could-do-ddbf9b5039a1',\n",
       "   'image_url': 'https://miro.medium.com/0*V4eRjCCJ3g1OaYU3',\n",
       "   'lang': 'en',\n",
       "   'is_series': False,\n",
       "   'is_locked': True,\n",
       "   'is_shortform': False,\n",
       "   'top_highlight': ''},\n",
       "  {'id': '620a84c14408',\n",
       "   'title': 'Powerful One-liners in Pandas Every Data Scientist Should Know',\n",
       "   'subtitle': 'Things you can do in one line using Pandas',\n",
       "   'author': '5d33decdf4c4',\n",
       "   'publication_id': '32881626c9c9',\n",
       "   'published_at': '2024-01-17 03:02:19',\n",
       "   'last_modified_at': '2024-01-17 03:09:18',\n",
       "   'tags': ['data-science',\n",
       "    'machine-learning',\n",
       "    'python',\n",
       "    'pandas',\n",
       "    'artificial-intelligence'],\n",
       "   'topics': ['data-science', 'programming'],\n",
       "   'claps': 448,\n",
       "   'voters': 86,\n",
       "   'word_count': 1542,\n",
       "   'responses_count': 5,\n",
       "   'reading_time': 7.418867924528302,\n",
       "   'url': 'https://medium.datadriveninvestor.com/powerful-one-liners-in-pandas-every-data-scientist-should-know-620a84c14408',\n",
       "   'unique_slug': 'powerful-one-liners-in-pandas-every-data-scientist-should-know-620a84c14408',\n",
       "   'image_url': 'https://miro.medium.com/0*npy63uZkFgDYzici',\n",
       "   'lang': 'en',\n",
       "   'is_series': False,\n",
       "   'is_locked': True,\n",
       "   'is_shortform': False,\n",
       "   'top_highlight': ''},\n",
       "  {'id': 'f67bb6e5317a',\n",
       "   'title': '20 Newbie Mistakes that Even Skilled Python Programmers Make',\n",
       "   'subtitle': 'A collection of common mistakes that you should avoid while coding in Python',\n",
       "   'author': '5d33decdf4c4',\n",
       "   'publication_id': '32881626c9c9',\n",
       "   'published_at': '2024-01-17 03:01:26',\n",
       "   'last_modified_at': '2024-02-13 05:37:08',\n",
       "   'tags': ['data-science',\n",
       "    'python',\n",
       "    'machine-learning',\n",
       "    'python-programming',\n",
       "    'artificial-intelligence'],\n",
       "   'topics': ['programming'],\n",
       "   'claps': 207,\n",
       "   'voters': 39,\n",
       "   'word_count': 1765,\n",
       "   'responses_count': 7,\n",
       "   'reading_time': 7.7937106918238985,\n",
       "   'url': 'https://medium.datadriveninvestor.com/20-newbie-mistakes-that-even-skilled-python-programmers-make-f67bb6e5317a',\n",
       "   'unique_slug': '20-newbie-mistakes-that-even-skilled-python-programmers-make-f67bb6e5317a',\n",
       "   'image_url': 'https://miro.medium.com/0*jN9CVaNSvGEE2ksQ',\n",
       "   'lang': 'en',\n",
       "   'is_series': False,\n",
       "   'is_locked': True,\n",
       "   'is_shortform': False,\n",
       "   'top_highlight': ''},\n",
       "  {'id': 'b2316bcc4c0f',\n",
       "   'title': '5 Jupyter Hacks That You Never Knew Even Existed',\n",
       "   'subtitle': 'With a bonus tip',\n",
       "   'author': '5d33decdf4c4',\n",
       "   'publication_id': '32881626c9c9',\n",
       "   'published_at': '2024-01-09 16:35:49',\n",
       "   'last_modified_at': '2024-01-23 15:19:34',\n",
       "   'tags': ['data-science',\n",
       "    'machine-learning',\n",
       "    'artificial-intelligence',\n",
       "    'python',\n",
       "    'programming'],\n",
       "   'topics': ['data-science', 'programming'],\n",
       "   'claps': 524,\n",
       "   'voters': 129,\n",
       "   'word_count': 1145,\n",
       "   'responses_count': 9,\n",
       "   'reading_time': 5.454088050314466,\n",
       "   'url': 'https://medium.datadriveninvestor.com/5-jupyter-hacks-that-you-never-knew-even-existed-b2316bcc4c0f',\n",
       "   'unique_slug': '5-jupyter-hacks-that-you-never-knew-even-existed-b2316bcc4c0f',\n",
       "   'image_url': 'https://miro.medium.com/0*HsAklpaUqoziyZmf',\n",
       "   'lang': 'en',\n",
       "   'is_series': False,\n",
       "   'is_locked': True,\n",
       "   'is_shortform': False,\n",
       "   'top_highlight': ''},\n",
       "  {'id': 'f1e31af2257a',\n",
       "   'title': 'Five Killer Optimization Techniques That Most Pandas Users Aren’t Aware Of',\n",
       "   'subtitle': 'A step towards data analysis run-time optimization',\n",
       "   'author': '5d33decdf4c4',\n",
       "   'publication_id': 'a648dc4ecb66',\n",
       "   'published_at': '2024-01-06 19:27:29',\n",
       "   'last_modified_at': '2024-01-12 06:16:39',\n",
       "   'tags': ['data-science',\n",
       "    'machine-learning',\n",
       "    'artificial-intelligence',\n",
       "    'python',\n",
       "    'pandas'],\n",
       "   'topics': ['data-science', 'programming'],\n",
       "   'claps': 559,\n",
       "   'voters': 153,\n",
       "   'word_count': 2030,\n",
       "   'responses_count': 6,\n",
       "   'reading_time': 8.910377358490566,\n",
       "   'url': 'https://towardsdev.com/five-killer-optimization-techniques-that-most-pandas-arent-aware-of-f1e31af2257a',\n",
       "   'unique_slug': 'five-killer-optimization-techniques-that-most-pandas-arent-aware-of-f1e31af2257a',\n",
       "   'image_url': 'https://miro.medium.com/0*aGty_aThlP_5zNyr',\n",
       "   'lang': 'en',\n",
       "   'is_series': False,\n",
       "   'is_locked': True,\n",
       "   'is_shortform': False,\n",
       "   'top_highlight': ''}],\n",
       " '8c8e5b7182ef': [{'id': '2eb0d15d6d77',\n",
       "   'title': 'I Built The 5 Income Streams Every Writer Should Have',\n",
       "   'subtitle': 'How To Make Money as a Writer',\n",
       "   'author': '8c8e5b7182ef',\n",
       "   'publication_id': '*Self-Published*',\n",
       "   'published_at': '2024-02-16 19:39:53',\n",
       "   'last_modified_at': '2024-02-16 19:44:12',\n",
       "   'tags': ['passive-income',\n",
       "    'side-hustle',\n",
       "    'make-money-online',\n",
       "    'affiliate-marketing',\n",
       "    'writer'],\n",
       "   'topics': ['freelancing', 'writing'],\n",
       "   'claps': 558,\n",
       "   'voters': 55,\n",
       "   'word_count': 2022,\n",
       "   'responses_count': 10,\n",
       "   'reading_time': 9.330188679245282,\n",
       "   'url': 'https://medium.com/@iampaulrose/i-built-the-5-income-streams-every-writer-should-have-2eb0d15d6d77',\n",
       "   'unique_slug': 'i-built-the-5-income-streams-every-writer-should-have-2eb0d15d6d77',\n",
       "   'image_url': 'https://miro.medium.com/0*qHvZkZbMS3hS2S7b',\n",
       "   'lang': 'en',\n",
       "   'is_series': False,\n",
       "   'is_locked': False,\n",
       "   'is_shortform': False,\n",
       "   'top_highlight': \"By posting high-quality content pieces on traffic platforms, you'll be passively building a portfolio of content for potential clients to see.\"},\n",
       "  {'id': '40f61887f107',\n",
       "   'title': 'I Found 5 Ways To Make Money With AI Art',\n",
       "   'subtitle': 'How To Make Passive Income With AI Art',\n",
       "   'author': '8c8e5b7182ef',\n",
       "   'publication_id': '*Self-Published*',\n",
       "   'published_at': '2024-02-15 02:43:52',\n",
       "   'last_modified_at': '2024-02-16 02:19:12',\n",
       "   'tags': ['ai',\n",
       "    'artificial-intelligence',\n",
       "    'ai-art',\n",
       "    'passive-income',\n",
       "    'side-hustle'],\n",
       "   'topics': ['artificial-intelligence'],\n",
       "   'claps': 530,\n",
       "   'voters': 51,\n",
       "   'word_count': 1942,\n",
       "   'responses_count': 7,\n",
       "   'reading_time': 9.678301886792452,\n",
       "   'url': 'https://medium.com/@iampaulrose/i-found-5-ways-to-make-money-with-ai-art-40f61887f107',\n",
       "   'unique_slug': 'i-found-5-ways-to-make-money-with-ai-art-40f61887f107',\n",
       "   'image_url': 'https://miro.medium.com/0*MOAhI1B6TFGBfkOl',\n",
       "   'lang': 'en',\n",
       "   'is_series': False,\n",
       "   'is_locked': False,\n",
       "   'is_shortform': False,\n",
       "   'top_highlight': ''},\n",
       "  {'id': 'abb6f463e3cb',\n",
       "   'title': 'I Sold on Gumroad For 6 Months',\n",
       "   'subtitle': 'How Much Did I Make and How Can A Beginner Start Something Similar?',\n",
       "   'author': '8c8e5b7182ef',\n",
       "   'publication_id': '*Self-Published*',\n",
       "   'published_at': '2024-02-12 22:51:09',\n",
       "   'last_modified_at': '2024-02-12 23:10:08',\n",
       "   'tags': ['passive-income',\n",
       "    'make-money-online',\n",
       "    'gumroad',\n",
       "    'notion',\n",
       "    'side-hustle'],\n",
       "   'topics': ['marketing', 'startups'],\n",
       "   'claps': 434,\n",
       "   'voters': 71,\n",
       "   'word_count': 2075,\n",
       "   'responses_count': 24,\n",
       "   'reading_time': 9.430188679245283,\n",
       "   'url': 'https://medium.com/@iampaulrose/i-sold-on-gumroad-for-6-months-abb6f463e3cb',\n",
       "   'unique_slug': 'i-sold-on-gumroad-for-6-months-abb6f463e3cb',\n",
       "   'image_url': 'https://miro.medium.com/1*_nf5axcmGlNl5uk7Bj4Xuw.jpeg',\n",
       "   'lang': 'en',\n",
       "   'is_series': False,\n",
       "   'is_locked': False,\n",
       "   'is_shortform': False,\n",
       "   'top_highlight': 'Because zero traffic = zero sales.'},\n",
       "  {'id': '1c0e84854e4e',\n",
       "   'title': 'How To Write An eBook and Actually Make Passive Income',\n",
       "   'subtitle': 'Without Spending Month Writing Your First Draft',\n",
       "   'author': '8c8e5b7182ef',\n",
       "   'publication_id': '*Self-Published*',\n",
       "   'published_at': '2024-02-10 21:44:02',\n",
       "   'last_modified_at': '2024-02-10 21:52:01',\n",
       "   'tags': ['passive-income',\n",
       "    'side-hustle',\n",
       "    'make-money-online',\n",
       "    'gumroad',\n",
       "    'online-business'],\n",
       "   'topics': ['writing'],\n",
       "   'claps': 1514,\n",
       "   'voters': 137,\n",
       "   'word_count': 1679,\n",
       "   'responses_count': 32,\n",
       "   'reading_time': 7.835849056603774,\n",
       "   'url': 'https://medium.com/@iampaulrose/how-to-write-an-ebook-and-actually-make-passive-income-1c0e84854e4e',\n",
       "   'unique_slug': 'how-to-write-an-ebook-and-actually-make-passive-income-1c0e84854e4e',\n",
       "   'image_url': 'https://miro.medium.com/0*ZwHe-qqWjx5s5fup',\n",
       "   'lang': 'en',\n",
       "   'is_series': False,\n",
       "   'is_locked': False,\n",
       "   'is_shortform': False,\n",
       "   'top_highlight': 'Medium + quality eBooks = thousands of dollars in passive.'},\n",
       "  {'id': 'fc25899ff745',\n",
       "   'title': 'I Started a Cute & Profitable Side Hustle',\n",
       "   'subtitle': 'And I’m Loving It So Far',\n",
       "   'author': '8c8e5b7182ef',\n",
       "   'publication_id': '*Self-Published*',\n",
       "   'published_at': '2024-02-08 22:38:04',\n",
       "   'last_modified_at': '2024-02-08 22:46:38',\n",
       "   'tags': ['passive-income',\n",
       "    'side-hustle',\n",
       "    'make-money-online',\n",
       "    'ai',\n",
       "    'ai-art'],\n",
       "   'topics': ['marketing'],\n",
       "   'claps': 1770,\n",
       "   'voters': 191,\n",
       "   'word_count': 2102,\n",
       "   'responses_count': 47,\n",
       "   'reading_time': 10.232075471698113,\n",
       "   'url': 'https://medium.com/@iampaulrose/i-started-a-cute-profitable-side-hustle-fc25899ff745',\n",
       "   'unique_slug': 'i-started-a-cute-profitable-side-hustle-fc25899ff745',\n",
       "   'image_url': 'https://miro.medium.com/0*0SGdByWaPIXUmbaD',\n",
       "   'lang': 'en',\n",
       "   'is_series': False,\n",
       "   'is_locked': False,\n",
       "   'is_shortform': False,\n",
       "   'top_highlight': ''},\n",
       "  {'id': '9fe3b230f547',\n",
       "   'title': 'An Easy Canva Side Hustle To Try For Passive Income',\n",
       "   'subtitle': 'How To Make Your First Dollar Online ',\n",
       "   'author': '8c8e5b7182ef',\n",
       "   'publication_id': '*Self-Published*',\n",
       "   'published_at': '2024-02-06 22:21:42',\n",
       "   'last_modified_at': '2024-02-07 05:49:35',\n",
       "   'tags': ['amazon',\n",
       "    'chatgpt',\n",
       "    'passive-income',\n",
       "    'side-hustle',\n",
       "    'make-money-online'],\n",
       "   'topics': ['marketing'],\n",
       "   'claps': 775,\n",
       "   'voters': 112,\n",
       "   'word_count': 1945,\n",
       "   'responses_count': 21,\n",
       "   'reading_time': 9.139622641509435,\n",
       "   'url': 'https://medium.com/@iampaulrose/an-easy-canva-side-hustle-to-try-for-passive-income-9fe3b230f547',\n",
       "   'unique_slug': 'an-easy-canva-side-hustle-to-try-for-passive-income-9fe3b230f547',\n",
       "   'image_url': 'https://miro.medium.com/0*px8ihcYxmIlESEnH',\n",
       "   'lang': 'en',\n",
       "   'is_series': False,\n",
       "   'is_locked': False,\n",
       "   'is_shortform': False,\n",
       "   'top_highlight': ''},\n",
       "  {'id': '1899e0b4b098',\n",
       "   'title': 'A Side Hustle Better Than Selling Canva Templates',\n",
       "   'subtitle': 'I Love Canva Templates But This Is Better ',\n",
       "   'author': '8c8e5b7182ef',\n",
       "   'publication_id': '*Self-Published*',\n",
       "   'published_at': '2024-02-04 19:20:02',\n",
       "   'last_modified_at': '2024-02-04 19:23:46',\n",
       "   'tags': ['passive-income',\n",
       "    'make-money-online-fast',\n",
       "    'chatgpt',\n",
       "    'notion',\n",
       "    'gumroad'],\n",
       "   'topics': ['marketing'],\n",
       "   'claps': 1692,\n",
       "   'voters': 251,\n",
       "   'word_count': 1850,\n",
       "   'responses_count': 32,\n",
       "   'reading_time': 8.731132075471699,\n",
       "   'url': 'https://medium.com/@iampaulrose/a-side-hustle-better-than-selling-canva-templates-1899e0b4b098',\n",
       "   'unique_slug': 'a-side-hustle-better-than-selling-canva-templates-1899e0b4b098',\n",
       "   'image_url': 'https://miro.medium.com/0*ouK5AEYap1hXkmTQ',\n",
       "   'lang': 'en',\n",
       "   'is_series': False,\n",
       "   'is_locked': False,\n",
       "   'is_shortform': False,\n",
       "   'top_highlight': ''},\n",
       "  {'id': '0bbfd98ac496',\n",
       "   'title': 'I Tried Making Money With a Free AI Art Generator',\n",
       "   'subtitle': 'How To Make Money with AI Art',\n",
       "   'author': '8c8e5b7182ef',\n",
       "   'publication_id': '*Self-Published*',\n",
       "   'published_at': '2024-02-02 21:43:31',\n",
       "   'last_modified_at': '2024-02-03 06:13:24',\n",
       "   'tags': ['ai-art',\n",
       "    'ai',\n",
       "    'artificial-intelligence',\n",
       "    'passive-income',\n",
       "    'make-money-online'],\n",
       "   'topics': ['artificial-intelligence', 'marketing'],\n",
       "   'claps': 4188,\n",
       "   'voters': 511,\n",
       "   'word_count': 1565,\n",
       "   'responses_count': 88,\n",
       "   'reading_time': 8.05566037735849,\n",
       "   'url': 'https://medium.com/@iampaulrose/i-tried-making-money-with-a-free-ai-art-generator-0bbfd98ac496',\n",
       "   'unique_slug': 'i-tried-making-money-with-a-free-ai-art-generator-0bbfd98ac496',\n",
       "   'image_url': 'https://miro.medium.com/1*ZOMR_5njto2MATAKRtD3yw.jpeg',\n",
       "   'lang': 'en',\n",
       "   'is_series': False,\n",
       "   'is_locked': False,\n",
       "   'is_shortform': False,\n",
       "   'top_highlight': \"It's super easy to get acquainted with this art generator and I highly recommend it for beginners.\"},\n",
       "  {'id': 'a506114d7a46',\n",
       "   'title': 'How To Write On Medium For Passive Income In 2024',\n",
       "   'subtitle': 'The Seamless Story Strategy ',\n",
       "   'author': '8c8e5b7182ef',\n",
       "   'publication_id': '*Self-Published*',\n",
       "   'published_at': '2024-01-31 21:22:12',\n",
       "   'last_modified_at': '2024-01-31 21:22:12',\n",
       "   'tags': ['passive-income',\n",
       "    'side-hustle',\n",
       "    'make-money-online',\n",
       "    'online-business',\n",
       "    'medium'],\n",
       "   'topics': ['writing', 'marketing'],\n",
       "   'claps': 565,\n",
       "   'voters': 56,\n",
       "   'word_count': 1849,\n",
       "   'responses_count': 17,\n",
       "   'reading_time': 8.427358490566037,\n",
       "   'url': 'https://medium.com/@iampaulrose/how-to-write-on-medium-for-passive-income-in-2024-a506114d7a46',\n",
       "   'unique_slug': 'how-to-write-on-medium-for-passive-income-in-2024-a506114d7a46',\n",
       "   'image_url': 'https://miro.medium.com/0*jofiNnNPWCgs4DaL',\n",
       "   'lang': 'en',\n",
       "   'is_series': False,\n",
       "   'is_locked': False,\n",
       "   'is_shortform': False,\n",
       "   'top_highlight': 'Give first, ask after.'},\n",
       "  {'id': 'bf026cd7e80f',\n",
       "   'title': 'How I Make $100 Per Day In Passive Income As a Writer',\n",
       "   'subtitle': 'A Writer’s Guide To Passive Income ',\n",
       "   'author': '8c8e5b7182ef',\n",
       "   'publication_id': '*Self-Published*',\n",
       "   'published_at': '2024-01-29 19:59:22',\n",
       "   'last_modified_at': '2024-01-29 19:59:22',\n",
       "   'tags': ['passive-income',\n",
       "    'side-hustle',\n",
       "    'make-money-online',\n",
       "    'writers-on-medium',\n",
       "    'online-business'],\n",
       "   'topics': ['freelancing', 'writing'],\n",
       "   'claps': 643,\n",
       "   'voters': 51,\n",
       "   'word_count': 1757,\n",
       "   'responses_count': 20,\n",
       "   'reading_time': 8.280188679245283,\n",
       "   'url': 'https://medium.com/@iampaulrose/how-i-make-100-per-day-in-passive-income-as-a-writer-bf026cd7e80f',\n",
       "   'unique_slug': 'how-i-make-100-per-day-in-passive-income-as-a-writer-bf026cd7e80f',\n",
       "   'image_url': 'https://miro.medium.com/0*t6pwyW9OiBg1Y4gO',\n",
       "   'lang': 'en',\n",
       "   'is_series': False,\n",
       "   'is_locked': False,\n",
       "   'is_shortform': False,\n",
       "   'top_highlight': 'You need to be able to churn out new stories at least 3 times a week, without compromising on the quality.'}],\n",
       " '37a2cbe8bd15': [{'id': 'be50cc308056',\n",
       "   'title': 'Why You Should Pay Attention to Perplexity AI',\n",
       "   'subtitle': 'I have Replaced Google with This New A.I.-Powered Search Engine!',\n",
       "   'author': '37a2cbe8bd15',\n",
       "   'publication_id': '*Self-Published*',\n",
       "   'published_at': '2024-02-02 11:09:46',\n",
       "   'last_modified_at': '2024-02-18 11:33:57',\n",
       "   'tags': ['technology',\n",
       "    'internet',\n",
       "    'artificial-intelligence',\n",
       "    'business',\n",
       "    'entrepreneurship'],\n",
       "   'topics': ['artificial-intelligence'],\n",
       "   'claps': 997,\n",
       "   'voters': 148,\n",
       "   'word_count': 506,\n",
       "   'responses_count': 17,\n",
       "   'reading_time': 2.459433962264151,\n",
       "   'url': 'https://medium.com/@pareto_investor/why-you-should-pay-attention-to-perplexity-ai-be50cc308056',\n",
       "   'unique_slug': 'why-you-should-pay-attention-to-perplexity-ai-be50cc308056',\n",
       "   'image_url': 'https://miro.medium.com/1*3ydXkh_Hth6MwLVoAduj_A.png',\n",
       "   'lang': 'en',\n",
       "   'is_series': False,\n",
       "   'is_locked': True,\n",
       "   'is_shortform': False,\n",
       "   'top_highlight': 'As it bypasses the traditional ad-driven model of the internet, it challenges the status quo of online information access.'},\n",
       "  {'id': '82653b2b36e2',\n",
       "   'title': 'Mistral CEO Confirms ‘Leak’ of New Open-Source AI Model Nearing GPT-4 Performance',\n",
       "   'subtitle': 'The new open-source large language model (LLM), rumored to approach the performance of GPT-4, a benchmark in the field.',\n",
       "   'author': '37a2cbe8bd15',\n",
       "   'publication_id': '*Self-Published*',\n",
       "   'published_at': '2024-02-01 12:25:45',\n",
       "   'last_modified_at': '2024-02-18 11:34:27',\n",
       "   'tags': ['artificial-intelligence',\n",
       "    'technology',\n",
       "    'business',\n",
       "    'machine-learning',\n",
       "    'programming'],\n",
       "   'topics': ['artificial-intelligence'],\n",
       "   'claps': 610,\n",
       "   'voters': 71,\n",
       "   'word_count': 555,\n",
       "   'responses_count': 7,\n",
       "   'reading_time': 2.6443396226415095,\n",
       "   'url': 'https://medium.com/@pareto_investor/mistral-ceo-confirms-leak-of-new-open-source-ai-model-nearing-gpt-4-performance-82653b2b36e2',\n",
       "   'unique_slug': 'mistral-ceo-confirms-leak-of-new-open-source-ai-model-nearing-gpt-4-performance-82653b2b36e2',\n",
       "   'image_url': 'https://miro.medium.com/0*k4FEslXGg4pEwzjx.jpg',\n",
       "   'lang': 'en',\n",
       "   'is_series': False,\n",
       "   'is_locked': True,\n",
       "   'is_shortform': False,\n",
       "   'top_highlight': 'Quantization, the process mentioned in this context, is a technique in machine learning (ML) that simplifies AI model architectures for use on less powerful hardware.'},\n",
       "  {'id': 'bcee41843775',\n",
       "   'title': 'ChatGPT has Just Been Dethroned by French Geniuses!',\n",
       "   'subtitle': 'These Three Individuals, a Former Researcher at DeepMind and Two Others from Meta,  Completely Transformed the AI Game!',\n",
       "   'author': '37a2cbe8bd15',\n",
       "   'publication_id': '*Self-Published*',\n",
       "   'published_at': '2024-01-20 18:06:31',\n",
       "   'last_modified_at': '2024-02-18 11:38:23',\n",
       "   'tags': ['artificial-intelligence',\n",
       "    'programming',\n",
       "    'machine-learning',\n",
       "    'technology',\n",
       "    'business'],\n",
       "   'topics': ['artificial-intelligence'],\n",
       "   'claps': 4495,\n",
       "   'voters': 902,\n",
       "   'word_count': 1075,\n",
       "   'responses_count': 70,\n",
       "   'reading_time': 4.8899371069182385,\n",
       "   'url': 'https://medium.com/@pareto_investor/chatgpt-has-just-been-dethroned-by-french-geniuses-bcee41843775',\n",
       "   'unique_slug': 'chatgpt-has-just-been-dethroned-by-french-geniuses-bcee41843775',\n",
       "   'image_url': 'https://miro.medium.com/1*6IIgPUJ-0UPUL4xe3Y5IKg.png',\n",
       "   'lang': 'en',\n",
       "   'is_series': False,\n",
       "   'is_locked': True,\n",
       "   'is_shortform': False,\n",
       "   'top_highlight': 'However, its size also allows it to run locally on devices like Macs and even some iPhones, making it highly accessible.'},\n",
       "  {'id': '5272ff33c5cd',\n",
       "   'title': 'ChatGPT Has Gone Bad!',\n",
       "   'subtitle': 'It seems that ChatGPT, particularly GPT-4, is becoming foolish, or more precisely, it’s becoming lazy.',\n",
       "   'author': '37a2cbe8bd15',\n",
       "   'publication_id': '*Self-Published*',\n",
       "   'published_at': '2024-01-28 15:02:49',\n",
       "   'last_modified_at': '2024-02-18 16:16:17',\n",
       "   'tags': ['artificial-intelligence',\n",
       "    'technology',\n",
       "    'programming',\n",
       "    'machine-learning',\n",
       "    'entrepreneurship'],\n",
       "   'topics': ['artificial-intelligence', 'programming'],\n",
       "   'claps': 2106,\n",
       "   'voters': 295,\n",
       "   'word_count': 2283,\n",
       "   'responses_count': 65,\n",
       "   'reading_time': 8.998427672955975,\n",
       "   'url': 'https://medium.com/@pareto_investor/chatgpt-has-gone-bad-5272ff33c5cd',\n",
       "   'unique_slug': 'chatgpt-has-gone-bad-5272ff33c5cd',\n",
       "   'image_url': 'https://miro.medium.com/0*nFHZy_dv1ACH7EOM',\n",
       "   'lang': 'en',\n",
       "   'is_series': False,\n",
       "   'is_locked': True,\n",
       "   'is_shortform': False,\n",
       "   'top_highlight': 'There are several versions of GPT-4. Yes, they correspond to different versions at a given time. For example, GPT4 03–14 is the version from March 2023, 06 is from June 2023, and so we can already see the first thing is that they are not ordered chronologically.'},\n",
       "  {'id': '211b2207b566',\n",
       "   'title': '7 Best Books for Beginners in Stock Market & Personal Investing!',\n",
       "   'subtitle': 'My Honest Review on What I believe are the Best Finance Books for Investing & Money',\n",
       "   'author': '37a2cbe8bd15',\n",
       "   'publication_id': '*Self-Published*',\n",
       "   'published_at': '2024-02-18 15:35:18',\n",
       "   'last_modified_at': '2024-02-18 17:51:51',\n",
       "   'tags': ['books', 'investing', 'education', 'money', 'self-improvement'],\n",
       "   'topics': ['money'],\n",
       "   'claps': 15,\n",
       "   'voters': 6,\n",
       "   'word_count': 788,\n",
       "   'responses_count': 0,\n",
       "   'reading_time': 3.1735849056603773,\n",
       "   'url': 'https://medium.com/@pareto_investor/my-best-7-books-for-beginners-in-stock-market-personal-investing-211b2207b566',\n",
       "   'unique_slug': 'my-best-7-books-for-beginners-in-stock-market-personal-investing-211b2207b566',\n",
       "   'image_url': 'https://miro.medium.com/0*yLNWOqSKbyfgVbO7',\n",
       "   'lang': 'en',\n",
       "   'is_series': False,\n",
       "   'is_locked': False,\n",
       "   'is_shortform': False,\n",
       "   'top_highlight': ''},\n",
       "  {'id': '2b8eb1e86f25',\n",
       "   'title': 'I Was Right about Palantir!',\n",
       "   'subtitle': 'The Company Has a Big Plan to Dominate AI World!',\n",
       "   'author': '37a2cbe8bd15',\n",
       "   'publication_id': '*Self-Published*',\n",
       "   'published_at': '2024-02-18 02:01:56',\n",
       "   'last_modified_at': '2024-02-18 11:23:28',\n",
       "   'tags': ['technology', 'ai', 'investing', 'stock-market', 'trading'],\n",
       "   'topics': ['artificial-intelligence'],\n",
       "   'claps': 213,\n",
       "   'voters': 13,\n",
       "   'word_count': 563,\n",
       "   'responses_count': 1,\n",
       "   'reading_time': 3.074528301886793,\n",
       "   'url': 'https://medium.com/@pareto_investor/i-was-right-about-palantir-2b8eb1e86f25',\n",
       "   'unique_slug': 'i-was-right-about-palantir-2b8eb1e86f25',\n",
       "   'image_url': 'https://miro.medium.com/0*kxmzisq-zZCYs05y.jpg',\n",
       "   'lang': 'en',\n",
       "   'is_series': False,\n",
       "   'is_locked': True,\n",
       "   'is_shortform': False,\n",
       "   'top_highlight': ''},\n",
       "  {'id': '681c04c2a74f',\n",
       "   'title': 'Why Bitcoin?',\n",
       "   'subtitle': 'How to Get Rich with Investing (without Getting Lucky)',\n",
       "   'author': '37a2cbe8bd15',\n",
       "   'publication_id': '*Self-Published*',\n",
       "   'published_at': '2024-02-17 20:50:32',\n",
       "   'last_modified_at': '2024-02-18 11:23:33',\n",
       "   'tags': ['bitcoin', 'life', 'finance', 'money', 'self-improvement'],\n",
       "   'topics': ['cryptocurrency'],\n",
       "   'claps': 202,\n",
       "   'voters': 14,\n",
       "   'word_count': 689,\n",
       "   'responses_count': 1,\n",
       "   'reading_time': 3.3,\n",
       "   'url': 'https://medium.com/@pareto_investor/why-bitcoin-681c04c2a74f',\n",
       "   'unique_slug': 'why-bitcoin-681c04c2a74f',\n",
       "   'image_url': 'https://miro.medium.com/0*d-rDBS60N966vxZ3.jpeg',\n",
       "   'lang': 'en',\n",
       "   'is_series': False,\n",
       "   'is_locked': True,\n",
       "   'is_shortform': False,\n",
       "   'top_highlight': ''},\n",
       "  {'id': '329ca6732470',\n",
       "   'title': 'Apple GPT\\u200a—\\u200aWhat Do We Know So Far!',\n",
       "   'subtitle': 'Apple is the sleeping giant in the realm of artificial intelligence.',\n",
       "   'author': '37a2cbe8bd15',\n",
       "   'publication_id': '*Self-Published*',\n",
       "   'published_at': '2024-02-17 11:16:52',\n",
       "   'last_modified_at': '2024-02-18 11:23:51',\n",
       "   'tags': ['apple',\n",
       "    'artificial-intelligence',\n",
       "    'technology',\n",
       "    'business',\n",
       "    'programming'],\n",
       "   'topics': ['artificial-intelligence'],\n",
       "   'claps': 107,\n",
       "   'voters': 8,\n",
       "   'word_count': 889,\n",
       "   'responses_count': 0,\n",
       "   'reading_time': 3.5547169811320756,\n",
       "   'url': 'https://medium.com/@pareto_investor/apple-gpt-what-do-we-know-so-far-329ca6732470',\n",
       "   'unique_slug': 'apple-gpt-what-do-we-know-so-far-329ca6732470',\n",
       "   'image_url': 'https://miro.medium.com/0*jBHC93WZ4Ah65cR-',\n",
       "   'lang': 'en',\n",
       "   'is_series': False,\n",
       "   'is_locked': True,\n",
       "   'is_shortform': False,\n",
       "   'top_highlight': ''},\n",
       "  {'id': '1add43659444',\n",
       "   'title': 'Cricket Might Be the Next Big Sport in America',\n",
       "   'subtitle': 'How to Get Rich with Investing (without Getting Lucky)',\n",
       "   'author': '37a2cbe8bd15',\n",
       "   'publication_id': '*Self-Published*',\n",
       "   'published_at': '2024-02-17 02:01:45',\n",
       "   'last_modified_at': '2024-02-18 11:24:01',\n",
       "   'tags': ['cricket', 'india', 'usa', 'sports', 'news'],\n",
       "   'topics': ['sports'],\n",
       "   'claps': 89,\n",
       "   'voters': 5,\n",
       "   'word_count': 536,\n",
       "   'responses_count': 2,\n",
       "   'reading_time': 2.722641509433962,\n",
       "   'url': 'https://medium.com/@pareto_investor/cricket-might-be-the-next-big-sport-in-america-1add43659444',\n",
       "   'unique_slug': 'cricket-might-be-the-next-big-sport-in-america-1add43659444',\n",
       "   'image_url': 'https://miro.medium.com/0*9n_TcVZIsnIouOj7',\n",
       "   'lang': 'en',\n",
       "   'is_series': False,\n",
       "   'is_locked': True,\n",
       "   'is_shortform': False,\n",
       "   'top_highlight': ''},\n",
       "  {'id': 'c33063302058',\n",
       "   'title': 'Yield Curve’s 40-Year Low Is Now Signaling Recession',\n",
       "   'subtitle': 'After being deeply negative, the US Treasury yield curve is in the process of de-inverting, signaling a potential recession!',\n",
       "   'author': '37a2cbe8bd15',\n",
       "   'publication_id': '*Self-Published*',\n",
       "   'published_at': '2024-02-16 12:05:58',\n",
       "   'last_modified_at': '2024-02-18 11:24:55',\n",
       "   'tags': ['economics', 'investing', 'trading', 'finance', 'stock-market'],\n",
       "   'topics': ['money', 'economy'],\n",
       "   'claps': 69,\n",
       "   'voters': 12,\n",
       "   'word_count': 410,\n",
       "   'responses_count': 1,\n",
       "   'reading_time': 1.9305031446540881,\n",
       "   'url': 'https://medium.com/@pareto_investor/yield-curves-40-year-low-is-now-signaling-recession-c33063302058',\n",
       "   'unique_slug': 'yield-curves-40-year-low-is-now-signaling-recession-c33063302058',\n",
       "   'image_url': 'https://miro.medium.com/0*BekymDxtFY_iYx7R.png',\n",
       "   'lang': 'en',\n",
       "   'is_series': False,\n",
       "   'is_locked': True,\n",
       "   'is_shortform': False,\n",
       "   'top_highlight': ''}],\n",
       " '15a29a4fc6ad': [{'id': 'afd97fce8fb5',\n",
       "   'title': 'Text Embeddings: Comprehensive Guide',\n",
       "   'subtitle': 'Evolution, visualisation, and applications of text embeddings',\n",
       "   'author': '15a29a4fc6ad',\n",
       "   'publication_id': '7f60cf5620c9',\n",
       "   'published_at': '2024-02-13 08:03:13',\n",
       "   'last_modified_at': '2024-02-13 08:03:13',\n",
       "   'tags': ['data-science',\n",
       "    'nlp',\n",
       "    'machine-learning',\n",
       "    'deep-dives',\n",
       "    'embedding'],\n",
       "   'topics': ['machine-learning', 'data-science', 'programming'],\n",
       "   'claps': 815,\n",
       "   'voters': 175,\n",
       "   'word_count': 4616,\n",
       "   'responses_count': 17,\n",
       "   'reading_time': 19.368867924528303,\n",
       "   'url': 'https://towardsdatascience.com/text-embeddings-comprehensive-guide-afd97fce8fb5',\n",
       "   'unique_slug': 'text-embeddings-comprehensive-guide-afd97fce8fb5',\n",
       "   'image_url': 'https://miro.medium.com/1*0OVy_qF0NLJOyUnfz8lRzg.jpeg',\n",
       "   'lang': 'en',\n",
       "   'is_series': False,\n",
       "   'is_locked': False,\n",
       "   'is_shortform': False,\n",
       "   'top_highlight': ''},\n",
       "  {'id': 'c5b9faa7a950',\n",
       "   'title': 'Data Visualisation 101: Playbook for Attention-Grabbing Visuals',\n",
       "   'subtitle': 'Practical Techniques for Captivating Visual Communication with Plotly',\n",
       "   'author': '15a29a4fc6ad',\n",
       "   'publication_id': '7f60cf5620c9',\n",
       "   'published_at': '2024-02-05 16:55:55',\n",
       "   'last_modified_at': '2024-02-05 16:55:55',\n",
       "   'tags': ['data-visualization',\n",
       "    'data-science',\n",
       "    'python',\n",
       "    'deep-dives',\n",
       "    'getting-started'],\n",
       "   'topics': ['data-science', 'programming'],\n",
       "   'claps': 950,\n",
       "   'voters': 164,\n",
       "   'word_count': 3269,\n",
       "   'responses_count': 10,\n",
       "   'reading_time': 14.085849056603774,\n",
       "   'url': 'https://towardsdatascience.com/data-visualisation-101-playbook-for-attention-grabbing-visuals-c5b9faa7a950',\n",
       "   'unique_slug': 'data-visualisation-101-playbook-for-attention-grabbing-visuals-c5b9faa7a950',\n",
       "   'image_url': 'https://miro.medium.com/1*JZNAv55DOK4L47LTl5KfTg.png',\n",
       "   'lang': 'en',\n",
       "   'is_series': False,\n",
       "   'is_locked': False,\n",
       "   'is_shortform': False,\n",
       "   'top_highlight': ''},\n",
       "  {'id': '3a10838b150d',\n",
       "   'title': 'Visualisation 101: Choosing the Best Visualisation Type',\n",
       "   'subtitle': 'Comprehensive guide for different visualisation use cases',\n",
       "   'author': '15a29a4fc6ad',\n",
       "   'publication_id': '7f60cf5620c9',\n",
       "   'published_at': '2024-01-12 20:44:18',\n",
       "   'last_modified_at': '2024-01-12 20:44:18',\n",
       "   'tags': ['visualization',\n",
       "    'data-science',\n",
       "    'python',\n",
       "    'editors-pick',\n",
       "    'data-visualization'],\n",
       "   'topics': ['visual-design', 'design', 'data-science', 'programming'],\n",
       "   'claps': 1133,\n",
       "   'voters': 243,\n",
       "   'word_count': 3701,\n",
       "   'responses_count': 19,\n",
       "   'reading_time': 15.866037735849057,\n",
       "   'url': 'https://towardsdatascience.com/visualisation-101-choosing-the-best-visualisation-type-3a10838b150d',\n",
       "   'unique_slug': 'visualisation-101-choosing-the-best-visualisation-type-3a10838b150d',\n",
       "   'image_url': 'https://miro.medium.com/1*ZnlImfsQ4VkFgLH-c5tsow.jpeg',\n",
       "   'lang': 'en',\n",
       "   'is_series': False,\n",
       "   'is_locked': False,\n",
       "   'is_shortform': False,\n",
       "   'top_highlight': \"One of the most famous examples is Anscombe's quartet. It was created by statistician Francis Anscombe, and it consists of 4 data sets with almost equal descriptive statistics: means, variances and correlations. But when we look at the data, we can see how different the datasets are.\"},\n",
       "  {'id': '9d42488dc327',\n",
       "   'title': 'Can LLMs Replace Data Analysts? Learning to Collaborate',\n",
       "   'subtitle': 'Part 3: Teaching the LLM agent to pose and address clarifying questions',\n",
       "   'author': '15a29a4fc6ad',\n",
       "   'publication_id': '7f60cf5620c9',\n",
       "   'published_at': '2024-01-09 13:19:56',\n",
       "   'last_modified_at': '2024-01-09 13:19:56',\n",
       "   'tags': ['llm',\n",
       "    'data-science',\n",
       "    'artificial-intelligence',\n",
       "    'deep-dives',\n",
       "    'editors-pick'],\n",
       "   'topics': ['artificial-intelligence',\n",
       "    'machine-learning',\n",
       "    'data-science',\n",
       "    'programming'],\n",
       "   'claps': 669,\n",
       "   'voters': 79,\n",
       "   'word_count': 5002,\n",
       "   'responses_count': 8,\n",
       "   'reading_time': 19.57547169811321,\n",
       "   'url': 'https://towardsdatascience.com/can-llms-replace-data-analysts-learning-to-collaborate-9d42488dc327',\n",
       "   'unique_slug': 'can-llms-replace-data-analysts-learning-to-collaborate-9d42488dc327',\n",
       "   'image_url': 'https://miro.medium.com/1*wUDorQvoHBbMLqPFvvVorw.jpeg',\n",
       "   'lang': 'en',\n",
       "   'is_series': False,\n",
       "   'is_locked': False,\n",
       "   'is_shortform': False,\n",
       "   'top_highlight': \"So, for an LLM-powered analyst, mastering the art of posing and addressing follow-up questions is essential since I can't imagine an analyst working in isolation.\"},\n",
       "  {'id': '8cf7da132259',\n",
       "   'title': 'Can LLMs Replace Data Analysts? Getting Answers Using SQL',\n",
       "   'subtitle': 'Part 2: Diving deeper into LLM agents',\n",
       "   'author': '15a29a4fc6ad',\n",
       "   'publication_id': '7f60cf5620c9',\n",
       "   'published_at': '2023-12-22 16:01:00',\n",
       "   'last_modified_at': '2023-12-22 16:01:00',\n",
       "   'tags': ['llm',\n",
       "    'data-science',\n",
       "    'artificial-intelligence',\n",
       "    'agents',\n",
       "    'editors-pick'],\n",
       "   'topics': ['artificial-intelligence', 'machine-learning', 'data-science'],\n",
       "   'claps': 823,\n",
       "   'voters': 239,\n",
       "   'word_count': 7816,\n",
       "   'responses_count': 11,\n",
       "   'reading_time': 30.444339622641508,\n",
       "   'url': 'https://towardsdatascience.com/can-llms-replace-data-analysts-getting-answers-using-sql-8cf7da132259',\n",
       "   'unique_slug': 'can-llms-replace-data-analysts-getting-answers-using-sql-8cf7da132259',\n",
       "   'image_url': 'https://miro.medium.com/1*o5J_rJVXP2J4NhBheT0IlQ.png',\n",
       "   'lang': 'en',\n",
       "   'is_series': False,\n",
       "   'is_locked': False,\n",
       "   'is_shortform': False,\n",
       "   'top_highlight': 'The core idea of the LLM agents is to use LLM as a reasoning engine to define the set of actions to take. In the classic approach, we hardcode a sequence of actions, but with agents, we give the model tools and tasks and let her decide how to achieve them.'},\n",
       "  {'id': '851578fa10ce',\n",
       "   'title': 'Can LLMs Replace Data Analysts? Building An LLM-Powered Analyst',\n",
       "   'subtitle': 'Part 1: empowering ChatGPT with tools',\n",
       "   'author': '15a29a4fc6ad',\n",
       "   'publication_id': '7f60cf5620c9',\n",
       "   'published_at': '2023-12-11 17:08:56',\n",
       "   'last_modified_at': '2023-12-11 17:08:56',\n",
       "   'tags': ['llm',\n",
       "    'data-science',\n",
       "    'agents',\n",
       "    'editors-pick',\n",
       "    'artificial-intelligence'],\n",
       "   'topics': ['data-science'],\n",
       "   'claps': 1492,\n",
       "   'voters': 326,\n",
       "   'word_count': 4613,\n",
       "   'responses_count': 19,\n",
       "   'reading_time': 18.240880503144652,\n",
       "   'url': 'https://towardsdatascience.com/can-llms-replace-data-analysts-building-an-llm-powered-analyst-851578fa10ce',\n",
       "   'unique_slug': 'can-llms-replace-data-analysts-building-an-llm-powered-analyst-851578fa10ce',\n",
       "   'image_url': 'https://miro.medium.com/1*cUH3JCAISUwvit33qk6D7g.jpeg',\n",
       "   'lang': 'en',\n",
       "   'is_series': False,\n",
       "   'is_locked': False,\n",
       "   'is_shortform': False,\n",
       "   'top_highlight': \"The essential concept related to agents (that I've already mentioned above) is tools. Tools are functions that LLM could invoke to get missing information (for example, execute SQL, use a calculator or call a search engine). Tools are crucial because they allow you to bring LLMs to the next level and interact with the world. In this article, we will primarily focus on OpenAI functions as tools.\"},\n",
       "  {'id': 'd7486d88c541',\n",
       "   'title': 'LMQL\\u200a—\\u200aSQL for Language Models',\n",
       "   'subtitle': 'Yet another tool that could help you with LLM applications',\n",
       "   'author': '15a29a4fc6ad',\n",
       "   'publication_id': '7f60cf5620c9',\n",
       "   'published_at': '2023-11-27 16:31:51',\n",
       "   'last_modified_at': '2023-11-27 16:31:51',\n",
       "   'tags': ['llm',\n",
       "    'sentiment-analysis',\n",
       "    'nlp',\n",
       "    'data-science',\n",
       "    'editors-pick'],\n",
       "   'topics': ['artificial-intelligence', 'data-science', 'programming'],\n",
       "   'claps': 883,\n",
       "   'voters': 251,\n",
       "   'word_count': 3898,\n",
       "   'responses_count': 12,\n",
       "   'reading_time': 16.30943396226415,\n",
       "   'url': 'https://towardsdatascience.com/lmql-sql-for-language-models-d7486d88c541',\n",
       "   'unique_slug': 'lmql-sql-for-language-models-d7486d88c541',\n",
       "   'image_url': 'https://miro.medium.com/1*yv1s9-5rzlm5NTrWJUdRIA.jpeg',\n",
       "   'lang': 'en',\n",
       "   'is_series': False,\n",
       "   'is_locked': False,\n",
       "   'is_shortform': False,\n",
       "   'top_highlight': 'I believe the most crucial benefit of LMQL is the complete control of your output. However, with such an approach, you will also have another layer of abstraction over LLM (similar to LangChain, which we discussed earlier). It will allow you to switch from one backend to another easily if you need to. LMQL can work with different backends: OpenAI, HuggingFace Transformers or llama.cpp.'},\n",
       "  {'id': 'eaf5469b83b0',\n",
       "   'title': 'RAG: How to Talk to Your Data',\n",
       "   'subtitle': 'Comprehensive guide on how to analyse customer feedback using ChatGPT',\n",
       "   'author': '15a29a4fc6ad',\n",
       "   'publication_id': '7f60cf5620c9',\n",
       "   'published_at': '2023-11-11 05:54:51',\n",
       "   'last_modified_at': '2023-11-11 08:46:29',\n",
       "   'tags': ['chatgpt',\n",
       "    'llm',\n",
       "    'langchain',\n",
       "    'hands-on-tutorials',\n",
       "    'naturallanguageprocessing'],\n",
       "   'topics': ['machine-learning', 'programming'],\n",
       "   'claps': 429,\n",
       "   'voters': 93,\n",
       "   'word_count': 4751,\n",
       "   'responses_count': 5,\n",
       "   'reading_time': 20.378301886792453,\n",
       "   'url': 'https://towardsdatascience.com/rag-how-to-talk-to-your-data-eaf5469b83b0',\n",
       "   'unique_slug': 'rag-how-to-talk-to-your-data-eaf5469b83b0',\n",
       "   'image_url': 'https://miro.medium.com/1*XFIVfZf4FYSm4lY01Auimw.png',\n",
       "   'lang': 'en',\n",
       "   'is_series': False,\n",
       "   'is_locked': False,\n",
       "   'is_shortform': False,\n",
       "   'top_highlight': ''},\n",
       "  {'id': 'e3b3e99e4fca',\n",
       "   'title': 'Topic Modelling in production',\n",
       "   'subtitle': 'Leveraging LangChain to move from ad-hoc Jupyter Notebooks to production modular service',\n",
       "   'author': '15a29a4fc6ad',\n",
       "   'publication_id': '7f60cf5620c9',\n",
       "   'published_at': '2023-10-30 14:07:06',\n",
       "   'last_modified_at': '2023-10-30 14:07:06',\n",
       "   'tags': ['chatgpt',\n",
       "    'llm',\n",
       "    'machine-learning',\n",
       "    'evaluation',\n",
       "    'editors-pick'],\n",
       "   'topics': ['artificial-intelligence', 'machine-learning', 'data-science'],\n",
       "   'claps': 392,\n",
       "   'voters': 79,\n",
       "   'word_count': 5271,\n",
       "   'responses_count': 6,\n",
       "   'reading_time': 21.390566037735848,\n",
       "   'url': 'https://towardsdatascience.com/topic-modelling-in-production-e3b3e99e4fca',\n",
       "   'unique_slug': 'topic-modelling-in-production-e3b3e99e4fca',\n",
       "   'image_url': 'https://miro.medium.com/1*zrrzdFgAnm7YAyIYtINhoA.jpeg',\n",
       "   'lang': 'en',\n",
       "   'is_series': False,\n",
       "   'is_locked': False,\n",
       "   'is_shortform': False,\n",
       "   'top_highlight': ''},\n",
       "  {'id': 'c288b48918af',\n",
       "   'title': 'Understanding Retention with Gradio',\n",
       "   'subtitle': 'How to leverage web applications for analytics',\n",
       "   'author': '15a29a4fc6ad',\n",
       "   'publication_id': '7f60cf5620c9',\n",
       "   'published_at': '2023-10-21 00:01:49',\n",
       "   'last_modified_at': '2023-10-21 08:46:52',\n",
       "   'tags': ['programming',\n",
       "    'python',\n",
       "    'web-development',\n",
       "    'data-science',\n",
       "    'hands-on-tutorials'],\n",
       "   'topics': ['machine-learning',\n",
       "    'software-engineering',\n",
       "    'data-science',\n",
       "    'programming'],\n",
       "   'claps': 200,\n",
       "   'voters': 32,\n",
       "   'word_count': 3426,\n",
       "   'responses_count': 1,\n",
       "   'reading_time': 14.228301886792453,\n",
       "   'url': 'https://towardsdatascience.com/understanding-retention-with-gradio-c288b48918af',\n",
       "   'unique_slug': 'understanding-retention-with-gradio-c288b48918af',\n",
       "   'image_url': 'https://miro.medium.com/1*5g9rJ4iCzdBTMPAKVuEljg.png',\n",
       "   'lang': 'en',\n",
       "   'is_series': False,\n",
       "   'is_locked': False,\n",
       "   'is_shortform': False,\n",
       "   'top_highlight': ''}],\n",
       " 'fb44e21903f3': [{'id': '5137fdafb355',\n",
       "   'title': 'You’re Not The Only One Feeling AI Fatigue (Or: Why That New AI Tool Isn’t for You)',\n",
       "   'subtitle': 'More AI tools, more AI fatigue.',\n",
       "   'author': 'fb44e21903f3',\n",
       "   'publication_id': '76436a11a2b0',\n",
       "   'published_at': '2024-02-13 16:56:05',\n",
       "   'last_modified_at': '2024-02-13 16:56:05',\n",
       "   'tags': ['artificial-intelligence', 'technology', 'chatgpt', 'science'],\n",
       "   'topics': ['artificial-intelligence'],\n",
       "   'claps': 624,\n",
       "   'voters': 85,\n",
       "   'word_count': 1355,\n",
       "   'responses_count': 14,\n",
       "   'reading_time': 5.313207547169812,\n",
       "   'url': 'https://medium.com/artificial-corner/youre-not-the-only-one-feeling-ai-fatigue-or-why-that-new-ai-tool-isn-t-for-you-5137fdafb355',\n",
       "   'unique_slug': 'youre-not-the-only-one-feeling-ai-fatigue-or-why-that-new-ai-tool-isn-t-for-you-5137fdafb355',\n",
       "   'image_url': 'https://miro.medium.com/1*U-x0yxnQOUB7DvRS0YTaSw.png',\n",
       "   'lang': 'en',\n",
       "   'is_series': False,\n",
       "   'is_locked': True,\n",
       "   'is_shortform': False,\n",
       "   'top_highlight': 'I turned a deaf ear to the influencers persuading me to jump on every new AI tool'},\n",
       "  {'id': 'b3e8446773b9',\n",
       "   'title': 'Gemini Ultra vs GPT-4: Did Google Beat GPT-4 This Time?',\n",
       "   'subtitle': 'The good, bad, and unexpected of Gemini Ultra.',\n",
       "   'author': 'fb44e21903f3',\n",
       "   'publication_id': '76436a11a2b0',\n",
       "   'published_at': '2024-02-09 18:26:53',\n",
       "   'last_modified_at': '2024-02-09 18:26:53',\n",
       "   'tags': ['artificial-intelligence',\n",
       "    'technology',\n",
       "    'chatgpt',\n",
       "    'midjourney',\n",
       "    'science'],\n",
       "   'topics': ['artificial-intelligence', 'design'],\n",
       "   'claps': 504,\n",
       "   'voters': 96,\n",
       "   'word_count': 1162,\n",
       "   'responses_count': 9,\n",
       "   'reading_time': 5.834905660377359,\n",
       "   'url': 'https://medium.com/artificial-corner/gemini-ultra-vs-gpt-4-did-google-beat-gpt-4-this-time-b3e8446773b9',\n",
       "   'unique_slug': 'gemini-ultra-vs-gpt-4-did-google-beat-gpt-4-this-time-b3e8446773b9',\n",
       "   'image_url': 'https://miro.medium.com/1*zdt7zAOcfYY6K66kea0mUQ.jpeg',\n",
       "   'lang': 'en',\n",
       "   'is_series': False,\n",
       "   'is_locked': True,\n",
       "   'is_shortform': False,\n",
       "   'top_highlight': \"However, unlike DALL-E 3, Gemini doesn't improve your prompt. If I use the same prompt on ChatGPT, DALL-E 3 will generate a prompt that gives a more eye-catching look to the image.\"},\n",
       "  {'id': 'bb4d6a735fc1',\n",
       "   'title': 'I Tried Multiple AI Coding Assistants. These Are The Best',\n",
       "   'subtitle': 'Best AI coding assistants for beginners and experienced programmers.',\n",
       "   'author': 'fb44e21903f3',\n",
       "   'publication_id': '76436a11a2b0',\n",
       "   'published_at': '2024-01-25 18:39:41',\n",
       "   'last_modified_at': '2024-01-25 18:39:41',\n",
       "   'tags': ['chatgpt',\n",
       "    'technology',\n",
       "    'artificial-intelligence',\n",
       "    'programming',\n",
       "    'python'],\n",
       "   'topics': ['artificial-intelligence', 'programming'],\n",
       "   'claps': 1371,\n",
       "   'voters': 324,\n",
       "   'word_count': 1255,\n",
       "   'responses_count': 22,\n",
       "   'reading_time': 6.635849056603773,\n",
       "   'url': 'https://medium.com/artificial-corner/i-tried-multiple-ai-coding-assistants-these-are-the-best-bb4d6a735fc1',\n",
       "   'unique_slug': 'i-tried-multiple-ai-coding-assistants-these-are-the-best-bb4d6a735fc1',\n",
       "   'image_url': 'https://miro.medium.com/1*4Xv28m71C-27267n8fP-WQ.png',\n",
       "   'lang': 'en',\n",
       "   'is_series': False,\n",
       "   'is_locked': True,\n",
       "   'is_shortform': False,\n",
       "   'top_highlight': 'I Tried Multiple AI Coding Assistants. These Are The Best'},\n",
       "  {'id': 'e6dd223d6ae0',\n",
       "   'title': 'The Best GPTs for Programmers',\n",
       "   'subtitle': 'These GPTs will automate part of your coding projects.',\n",
       "   'author': 'fb44e21903f3',\n",
       "   'publication_id': '76436a11a2b0',\n",
       "   'published_at': '2024-01-19 17:59:27',\n",
       "   'last_modified_at': '2024-01-19 17:59:27',\n",
       "   'tags': ['chatgpt',\n",
       "    'artificial-intelligence',\n",
       "    'technology',\n",
       "    'python',\n",
       "    'programming'],\n",
       "   'topics': ['programming'],\n",
       "   'claps': 613,\n",
       "   'voters': 179,\n",
       "   'word_count': 924,\n",
       "   'responses_count': 6,\n",
       "   'reading_time': 4.836792452830188,\n",
       "   'url': 'https://medium.com/artificial-corner/the-best-gpts-for-programmers-e6dd223d6ae0',\n",
       "   'unique_slug': 'the-best-gpts-for-programmers-e6dd223d6ae0',\n",
       "   'image_url': 'https://miro.medium.com/1*g0gnC_K7D0CbCakIYaxVdQ.png',\n",
       "   'lang': 'en',\n",
       "   'is_series': False,\n",
       "   'is_locked': True,\n",
       "   'is_shortform': False,\n",
       "   'top_highlight': ''},\n",
       "  {'id': '84e568626e89',\n",
       "   'title': 'OpenAI Just Released The GPT Store. Here’s How To Use It And Make Money With Your GPT',\n",
       "   'subtitle': 'Learn how to publish your GPT to the store and monetize it.',\n",
       "   'author': 'fb44e21903f3',\n",
       "   'publication_id': '76436a11a2b0',\n",
       "   'published_at': '2024-01-11 14:04:50',\n",
       "   'last_modified_at': '2024-01-11 14:04:50',\n",
       "   'tags': ['artificial-intelligence',\n",
       "    'technology',\n",
       "    'chatgpt',\n",
       "    'science',\n",
       "    'python'],\n",
       "   'topics': ['programming'],\n",
       "   'claps': 2314,\n",
       "   'voters': 392,\n",
       "   'word_count': 826,\n",
       "   'responses_count': 29,\n",
       "   'reading_time': 4.166981132075472,\n",
       "   'url': 'https://medium.com/artificial-corner/openai-just-released-the-gpt-store-heres-how-to-use-it-and-make-money-with-your-gpt-84e568626e89',\n",
       "   'unique_slug': 'openai-just-released-the-gpt-store-heres-how-to-use-it-and-make-money-with-your-gpt-84e568626e89',\n",
       "   'image_url': 'https://miro.medium.com/1*d41v0LCPk7uIG0okVZ_kCQ.png',\n",
       "   'lang': 'en',\n",
       "   'is_series': False,\n",
       "   'is_locked': True,\n",
       "   'is_shortform': False,\n",
       "   'top_highlight': 'As you can see there are three, but the one I created for a previous tutorial is the first (I think the comment bubble on the right means how many conversations have been started with a GPT).'},\n",
       "  {'id': '4eaff6178983',\n",
       "   'title': 'Artificial Corner Will No Longer Publish Stories On This Site',\n",
       "   'subtitle': 'Here’s why and some important details.',\n",
       "   'author': 'fb44e21903f3',\n",
       "   'publication_id': '76436a11a2b0',\n",
       "   'published_at': '2023-12-26 17:18:38',\n",
       "   'last_modified_at': '2023-12-26 17:18:38',\n",
       "   'tags': ['chatgpt', 'technology', 'artificial-intelligence', 'science'],\n",
       "   'topics': ['artificial-intelligence'],\n",
       "   'claps': 294,\n",
       "   'voters': 40,\n",
       "   'word_count': 300,\n",
       "   'responses_count': 4,\n",
       "   'reading_time': 1.3320754716981131,\n",
       "   'url': 'https://medium.com/artificial-corner/artificial-corner-will-no-longer-publish-stories-on-this-site-4eaff6178983',\n",
       "   'unique_slug': 'artificial-corner-will-no-longer-publish-stories-on-this-site-4eaff6178983',\n",
       "   'image_url': 'https://miro.medium.com/0*NoKpYRcRcsXEes3B',\n",
       "   'lang': 'en',\n",
       "   'is_series': False,\n",
       "   'is_locked': False,\n",
       "   'is_shortform': False,\n",
       "   'top_highlight': ''},\n",
       "  {'id': '4ff7e5973b05',\n",
       "   'title': '“Google Will Kill ChatGPT” and Other Overhyped AI Predictions We Heard In 2023',\n",
       "   'subtitle': 'Here are some predictions that I doubt will happen in 2024 or the near future (and why I think so).',\n",
       "   'author': 'fb44e21903f3',\n",
       "   'publication_id': '76436a11a2b0',\n",
       "   'published_at': '2023-12-20 18:41:12',\n",
       "   'last_modified_at': '2023-12-20 18:41:12',\n",
       "   'tags': ['artificial-intelligence', 'chatgpt', 'technology', 'science'],\n",
       "   'topics': ['artificial-intelligence'],\n",
       "   'claps': 491,\n",
       "   'voters': 46,\n",
       "   'word_count': 1166,\n",
       "   'responses_count': 8,\n",
       "   'reading_time': 4.95,\n",
       "   'url': 'https://medium.com/artificial-corner/google-will-kill-chatgpt-and-other-overhyped-ai-predictions-we-heard-in-2023-4ff7e5973b05',\n",
       "   'unique_slug': 'google-will-kill-chatgpt-and-other-overhyped-ai-predictions-we-heard-in-2023-4ff7e5973b05',\n",
       "   'image_url': 'https://miro.medium.com/1*R_NH8O9YvZ4zVACxdQwJow.png',\n",
       "   'lang': 'en',\n",
       "   'is_series': False,\n",
       "   'is_locked': True,\n",
       "   'is_shortform': False,\n",
       "   'top_highlight': ''},\n",
       "  {'id': 'e23bfa19bf16',\n",
       "   'title': 'A Hands-On Comparison: Gemini Pro vs GPT-3.5',\n",
       "   'subtitle': 'And the winner is\\xa0…',\n",
       "   'author': 'fb44e21903f3',\n",
       "   'publication_id': '76436a11a2b0',\n",
       "   'published_at': '2023-12-12 12:01:54',\n",
       "   'last_modified_at': '2023-12-12 12:01:54',\n",
       "   'tags': ['chatgpt',\n",
       "    'artificial-intelligence',\n",
       "    'technology',\n",
       "    'science',\n",
       "    'python'],\n",
       "   'topics': ['programming'],\n",
       "   'claps': 567,\n",
       "   'voters': 74,\n",
       "   'word_count': 989,\n",
       "   'responses_count': 10,\n",
       "   'reading_time': 5.382075471698113,\n",
       "   'url': 'https://medium.com/artificial-corner/a-hands-on-comparison-gemini-pro-vs-gpt-3-5-e23bfa19bf16',\n",
       "   'unique_slug': 'a-hands-on-comparison-gemini-pro-vs-gpt-3-5-e23bfa19bf16',\n",
       "   'image_url': 'https://miro.medium.com/1*0KOYEV-7j3NXe7zHP6URyA.png',\n",
       "   'lang': 'en',\n",
       "   'is_series': False,\n",
       "   'is_locked': True,\n",
       "   'is_shortform': False,\n",
       "   'top_highlight': ''},\n",
       "  {'id': '16ed78293975',\n",
       "   'title': 'Here’s Why I Still Don’t Buy the Hype of Google Gemini',\n",
       "   'subtitle': 'Gemini might not be as good as it seems to be.',\n",
       "   'author': 'fb44e21903f3',\n",
       "   'publication_id': '76436a11a2b0',\n",
       "   'published_at': '2023-12-08 17:49:53',\n",
       "   'last_modified_at': '2023-12-08 17:49:53',\n",
       "   'tags': ['chatgpt',\n",
       "    'artificial-intelligence',\n",
       "    'technology',\n",
       "    'science',\n",
       "    'python'],\n",
       "   'topics': ['artificial-intelligence'],\n",
       "   'claps': 615,\n",
       "   'voters': 97,\n",
       "   'word_count': 1078,\n",
       "   'responses_count': 9,\n",
       "   'reading_time': 5.317924528301887,\n",
       "   'url': 'https://medium.com/artificial-corner/heres-why-i-still-don-t-buy-the-hype-of-google-gemini-16ed78293975',\n",
       "   'unique_slug': 'heres-why-i-still-don-t-buy-the-hype-of-google-gemini-16ed78293975',\n",
       "   'image_url': 'https://miro.medium.com/0*QQ7EbFFz_gxnv5xv.png',\n",
       "   'lang': 'en',\n",
       "   'is_series': False,\n",
       "   'is_locked': True,\n",
       "   'is_shortform': False,\n",
       "   'top_highlight': \"Google's Gemini was just unveiled, and I haven't seen so much hype since ChatGPT was released by OpenAI.\"},\n",
       "  {'id': 'c6b672104721',\n",
       "   'title': 'GPT Actions: How to Create Advanced Automation in Your GPTs',\n",
       "   'subtitle': 'Customize your GPT further by connecting it to thousands of apps.',\n",
       "   'author': 'fb44e21903f3',\n",
       "   'publication_id': '76436a11a2b0',\n",
       "   'published_at': '2023-12-06 15:43:28',\n",
       "   'last_modified_at': '2023-12-06 15:43:28',\n",
       "   'tags': ['chatgpt',\n",
       "    'artificial-intelligence',\n",
       "    'technology',\n",
       "    'science',\n",
       "    'python'],\n",
       "   'topics': ['programming'],\n",
       "   'claps': 863,\n",
       "   'voters': 159,\n",
       "   'word_count': 1018,\n",
       "   'responses_count': 6,\n",
       "   'reading_time': 5.341509433962264,\n",
       "   'url': 'https://medium.com/artificial-corner/gpt-actions-how-to-create-advanced-automation-in-your-gpts-c6b672104721',\n",
       "   'unique_slug': 'gpt-actions-how-to-create-advanced-automation-in-your-gpts-c6b672104721',\n",
       "   'image_url': 'https://miro.medium.com/1*L-BjgiP_1w-PlnsfCmV1HA.png',\n",
       "   'lang': 'en',\n",
       "   'is_series': False,\n",
       "   'is_locked': True,\n",
       "   'is_shortform': False,\n",
       "   'top_highlight': ''}]}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "updated_articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_article_content(article_id: str, headers=headers):\n",
    "\t'''\n",
    "\tFunction to retrieve content of each article by writers\n",
    "\t'''\n",
    "\turl = f\"https://medium2.p.rapidapi.com/article/{article_id}/content\"\n",
    "\tresponse = requests.get(url, headers=headers)\n",
    "\tarticle_content = response.json()\n",
    "\treturn article_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "for author in updated_articles.keys():\n",
    "\tfor article in updated_articles[author]:\n",
    "\t\tart_id = article['id']\n",
    "\t\tcontent = get_article_content(art_id)\n",
    "\t\tarticle['content'] = content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fca9db1c7da0': [{'id': '34c195a93d41',\n",
       "   'title': 'How I Won Singapore’s GPT-4 Prompt Engineering Competition',\n",
       "   'subtitle': 'A deep dive into the strategies I learned for harnessing the power of Large Language Models (LLMs)',\n",
       "   'author': 'fca9db1c7da0',\n",
       "   'publication_id': '7f60cf5620c9',\n",
       "   'published_at': '2023-12-29 00:29:22',\n",
       "   'last_modified_at': '2024-01-29 06:15:01',\n",
       "   'tags': ['data-science',\n",
       "    'artificial-intelligence',\n",
       "    'prompt-engineering',\n",
       "    'editors-pick',\n",
       "    'technology'],\n",
       "   'topics': ['artificial-intelligence', 'data-science'],\n",
       "   'claps': 11406,\n",
       "   'voters': 2300,\n",
       "   'word_count': 5571,\n",
       "   'responses_count': 157,\n",
       "   'reading_time': 22.722641509433963,\n",
       "   'url': 'https://towardsdatascience.com/how-i-won-singapores-gpt-4-prompt-engineering-competition-34c195a93d41',\n",
       "   'unique_slug': 'how-i-won-singapores-gpt-4-prompt-engineering-competition-34c195a93d41',\n",
       "   'image_url': 'https://miro.medium.com/1*RAI4cBXe1_zaxVykHz79oA.jpeg',\n",
       "   'lang': 'en',\n",
       "   'is_series': False,\n",
       "   'is_locked': True,\n",
       "   'is_shortform': False,\n",
       "   'top_highlight': 'Use System Prompts to provide instructions that you want the LLM to remember when responding throughout the entire chat.',\n",
       "   'content': {'id': '34c195a93d41',\n",
       "    'content': 'How I Won Singapore’s GPT-4 Prompt Engineering Competition\\n\\nA deep dive into the strategies I learned for harnessing the power of Large Language Models (LLMs)\\n\\nCelebrating a milestone - The real win was the priceless learning experience!\\n\\nLast month, I had the incredible honor of winning Singapore’s first ever GPT-4 Prompt Engineering competition, which brought together over 400 prompt-ly brilliant participants, organised by the Government Technology Agency of Singapore (GovTech).\\n\\nPrompt engineering is a discipline that blends both art and science - it is as much technical understanding as it is of creativity and strategic thinking. This is a compilation of the prompt engineering strategies I learned along the way, that push any LLM to do exactly what you need and more!\\n\\nAuthor’s Note:\\nIn writing this, I sought to steer away from the traditional prompt engineering techniques that have already been extensively discussed and documented online. Instead, my aim is to bring fresh insights that I learned through experimentation, and a different, personal take in understanding and approaching certain techniques. I hope you’ll enjoy reading this piece!\\n\\nThis article covers the following, with 🔵 referring to beginner-friendly prompting techniques while 🔴 refers to advanced strategies:\\n\\n1. [🔵] Structuring prompts using the CO-STAR framework\\n\\n2. [🔵] Sectioning prompts using delimiters\\n\\n3. [🔴] Creating system prompts with LLM guardrails\\n\\n4. [🔴] Analyzing datasets using only LLMs, without plugins or code - \\nWith a hands-on example of analyzing a real-world Kaggle dataset using GPT-4\\n\\n1. [🔵] Structuring Prompts using the CO-STAR framework\\n\\nEffective prompt structuring is crucial for eliciting optimal responses from an LLM. The CO-STAR framework, a brainchild of GovTech Singapore’s Data Science & AI team, is a handy template for structuring prompts. It considers all the key aspects that influence the effectiveness and relevance of an LLM’s response, leading to more optimal responses.\\n\\nCO-STAR framework - Image by author\\n\\nHere’s how it works:\\n\\n(C) Context: Provide background information on the task\\n\\nThis helps the LLM understand the specific scenario being discussed, ensuring its response is relevant.\\n\\n(O) Objective: Define what the task is that you want the LLM to perform\\n\\nBeing clear about your objective helps the LLM to focus its response on meeting that specific goal.\\n\\n(S) Style: Specify the writing style you want the LLM to use\\n\\nThis could be a particular famous person’s style of writing, or a particular expert in a profession, like a business analyst expert or CEO. This guides the LLM to respond with the manner and choice of words aligned with your needs.\\n\\n(T) Tone: Set the attitude of the response\\n\\nThis ensures the LLM’s response resonates with the intended sentiment or emotional context required. Examples are formal, humorous, empathetic, among others.\\n\\n(A) Audience: Identify who the response is intended for\\n\\nTailoring the LLM’s response to an audience, such as experts in a field, beginners, children, and so on, ensures that it is appropriate and understandable in your required context.\\n\\n(R) Response: Provide the response format\\n\\nThis ensures that the LLM outputs in the exact format that you require for downstream tasks. Examples include a list, a JSON, a professional report, and so on. For most LLM applications which work on the LLM responses programmatically for downstream manipulations, a JSON output format would be ideal.\\n\\nA practical application of CO-STAR\\n\\nHere’s a real-world example of why the CO-STAR framework is useful. Let’s say you work as a social media manager, and you need help drafting a Facebook post to advertise your company’s new product.\\n\\nA quick prompt without CO-STAR might look something like this:\\n\\nWrite a facebook post to advertise my company’s new product. My company’s name is Alpha and the product is called Beta, a new ultra-fast hairdryer.\\n\\nHere’s the output from GPT-4:\\n\\nIntroducing the Revolutionary Beta Hairdryer by Alpha!\\n- Say goodbye to long, tedious hair drying sessions! Alpha is proud to unveil the Beta, our latest innovation in haircare technology.\\n- Ultra-Fast Drying: The Beta is designed to cut your drying time in half, thanks to its advanced, powerful motor. Get ready faster and enjoy more time doing what you love!\\nShop Now: [Link to product page]\\n\\nWhile adequate, this output is painfully generic, lacking the specific nuances and targeted appeal necessary to resonate with your company’s audience.\\n\\nHere’s an example of using the CO-STAR template instead, which reminds you to incorporate other aspects of your task into your prompt, specifically the STYLE, TONE, and AUDIENCE aspects that are missing from the previous quick prompt:\\n\\n# CONTEXT # \\nI want to advertise my company’s new product. My company’s name is Alpha and the product is called Beta, which is a new ultra-fast hairdryer.\\n\\n# OBJECTIVE #\\nCreate a Facebook post for me, which aims to get people to click on the product link to purchase it.\\n\\n# STYLE #\\nFollow the writing style of successful companies that advertise similar products, such as Dyson.\\n\\n# TONE #\\nPersuasive\\n\\n# AUDIENCE #\\nMy company’s audience profile on Facebook is typically the older generation. Tailor your post to target what this audience typically looks out for in hair products.\\n\\n# RESPONSE #\\nThe Facebook post, kept concise yet impactful.\\n\\nBy applying CO-STAR, GPT-4’s response becomes significantly more targeted and effective:\\n\\nEmbrace Effortless Elegance with Alpha Beta - The Ultra-Fast Hairdryer for the Wise Generation.\\n\\nRediscover the joy of simple, effective hair care with Alpha Beta. Our latest innovation is more than just a hairdryer; it’s a promise of swift, gentle, and \\nreliable hair styling for those who appreciate the finer things in life.\\n\\n- Easy and Intuitive Use: Say goodbye to complicated gadgets. Alpha Beta is \\ncrafted for comfort and simplicity, perfect for those who value straightforward,\\nhassle-free technology. \\n- Time-Saving Technology: We understand your time is precious. That’s why Alpha Beta cuts down drying time significantly, giving you more moments to enjoy life’s pleasures.\\n\\nMake every day a good hair day with Alpha Beta. Experience the blend of \\nsophistication and simplicity today.\\n\\n[Your Product Link Here]\\n\\nThe CO-STAR framework guides you to provide all of the crucial pieces of information about your task to the LLM in a structured manner, ensuring a tailored and optimized response to exactly what you need.\\n\\n2. [🔵] Sectioning Prompts Using Delimiters\\n\\nImage generated by DALL·E 3\\n\\nDelimiters are special tokens that help the LLM distinguish which parts of your prompt it should consider as a single unit of meaning. This is important because your entire prompt arrives to the LLM as a single long sequence of tokens. Delimiters provide structure to this sequence of tokens by fencing specific parts of your prompt to be treated differently.\\n\\nIt is noteworthy that delimiters may not make a difference to the quality of an LLM’s response for straightforward tasks. However, the more complex the task, the more impact the usage of delimiters for sectioning has on the LLM’s response.\\n\\nDelimiters as Special Characters\\n\\nA delimiter could be any sequence of special characters that usually wouldn’t appear together, for example:\\n\\n###\\n\\n===\\n\\n>>>\\n\\nThe number and type of special characters chosen is inconsequential, as long as they are unique enough for the LLM to understand them as content separators instead of normal punctuation.\\n\\nHere’s an example of how you might use such delimiters in a prompt:\\n\\nClassify the sentiment of each conversation in <<<CONVERSATIONS>>> as \\n‘Positive’ or ‘Negative’. Give the sentiment classifications without any other preamble text.\\n\\n###\\n\\nEXAMPLE CONVERSATIONS\\n\\n[Agent]: Good morning, how can I assist you today?\\n[Customer]: This product is terrible, nothing like what was advertised!\\n[Customer]: I’m extremely disappointed and expect a full refund.\\n\\n[Agent]: Good morning, how can I help you today?\\n[Customer]: Hi, I just wanted to say that I’m really impressed with your \\nproduct. It exceeded my expectations!\\n\\n###\\n\\nEXAMPLE OUTPUTS\\n\\nNegative\\n\\nPositive\\n\\n###\\n\\n<<<\\n[Agent]: Hello! Welcome to our support. How can I help you today?\\n[Customer]: Hi there! I just wanted to let you know I received my order, and \\nit’s fantastic!\\n[Agent]: That’s great to hear! We’re thrilled you’re happy with your purchase. \\nIs there anything else I can assist you with?\\n[Customer]: No, that’s it. Just wanted to give some positive feedback. Thanks \\nfor your excellent service!\\n\\n[Agent]: Hello, thank you for reaching out. How can I assist you today?\\n[Customer]: I’m very disappointed with my recent purchase. It’s not what I expected at all.\\n[Agent]: I’m sorry to hear that. Could you please provide more details so I can help?\\n[Customer]: The product is of poor quality and it arrived late. I’m really \\nunhappy with this experience.\\n>>>\\n\\nAbove, the examples are sectioned using the delimiter ###, with the section headings EXAMPLE CONVERSATIONS and EXAMPLE OUTPUTS in capital letters to differentiate them. The preamble states that the conversations to be classified are sectioned inside <<<CONVERSATIONS>>>, and these conversations are subsequently given to the LLM at the bottom of the prompt without any explanatory text, but the LLM understands that these are the conversations it should classify due to the presence of the delimiters <<< and >>>.\\n\\nHere is the output from GPT-4, with the sentiment classifications given without any other preamble text outputted, like what we asked for:\\n\\nPositive\\n\\nNegative\\n\\nDelimiters as XML Tags\\n\\nAnother approach to using delimiters is having them as XML tags. XML tags are tags enclosed in angle brackets, with opening and closing tags. An example is <tag> and </tag>. This is effective as LLMs have been trained on a lot of web content in XML, and have learned to understand its formatting.\\n\\nHere’s the same prompt above, but structured using XML tags as delimiters instead:\\n\\nClassify the sentiment of the following conversations into one of two classes, using the examples given. Give the sentiment classifications without any other\\npreamble text.\\n\\n<classes>\\nPositive\\nNegative\\n</classes>\\n\\n<example-conversations>\\n[Agent]: Good morning, how can I assist you today?\\n[Customer]: This product is terrible, nothing like what was advertised!\\n[Customer]: I’m extremely disappointed and expect a full refund.\\n\\n[Agent]: Good morning, how can I help you today?\\n[Customer]: Hi, I just wanted to say that I’m really impressed with your \\nproduct. It exceeded my expectations!\\n</example-conversations>\\n\\n<example-classes>\\nNegative\\n\\nPositive\\n</example-classes>\\n\\n<conversations>\\n[Agent]: Hello! Welcome to our support. How can I help you today?\\n[Customer]: Hi there! I just wanted to let you know I received my order, and \\nit’s fantastic!\\n[Agent]: That’s great to hear! We’re thrilled you’re happy with your purchase. \\nIs there anything else I can assist you with?\\n[Customer]: No, that’s it. Just wanted to give some positive feedback. Thanks \\nfor your excellent service!\\n\\n[Agent]: Hello, thank you for reaching out. How can I assist you today?\\n[Customer]: I’m very disappointed with my recent purchase. It’s not what I \\nexpected at all.\\n[Agent]: I’m sorry to hear that. Could you please provide more details so I \\ncan help?\\n[Customer]: The product is of poor quality and it arrived late. I’m really \\nunhappy with this experience.\\n</conversations>\\n\\nIt is beneficial to use the same noun for the XML tag as the words you have used to describe them in the instructions. The instructions we gave in the prompt above were:\\n\\nClassify the sentiment of the following conversations into one of two classes, using the examples given. Give the sentiment classifications without any other\\npreamble text.\\n\\nWhere we used the nouns conversations, classes, and examples. As such, the XML tags we use as delimiters are <conversations>, <classes>, <example-conversations>, and <example-classes>. This ensures that the LLM understands how your instructions relate to the XML tags used as delimiters.\\n\\nAgain, the sectioning of your instructions in a clear and structured manner through the use of delimiters ensures that GPT-4 responds exactly how you want it to:\\n\\nPositive\\n\\nNegative\\n\\n3. [🔴] Creating System Prompts With LLM Guardrails\\n\\nBefore diving in, it is important to note that this section is relevant only to LLMs that possess a System Prompt feature, unlike the other sections in this article which are relevant for any LLM. The most notable LLM with this feature is, of course, ChatGPT, and therefore we will use ChatGPT as the illustrating example for this section.\\n\\nImage generated by DALL·E 3\\n\\nTerminology surrounding System Prompts\\n\\nFirst, let’s iron out terminology: With regards to ChatGPT, there exists a plethora of resources using these 3 terms almost interchangeably: \"System Prompts\", \"System Messages\", and \"Custom Instructions\". This has proved confusing to many (including me!), so much so that OpenAI released an article explaining these terminologies. Here’s a quick summary of it:\\n\\n\"System Prompts\" and \"System Messages\" are terms used when interacting with ChatGPT programmatically over its Chat Completions API.\\n\\nOn the other hand, \"Custom Instructions\" is the term used when interacting with ChatGPT over its user interface at https://chat.openai.com/.\\n\\nImage from Enterprise DNA Blog\\n\\nOverall, though, the 3 terms refer to the same thing, so don’t let the terminology confuse you! Moving forward, this section will use the term \"System Prompts\". Now let’s dive in!\\n\\nWhat are System Prompts?\\n\\nSystem Prompts are an additional prompt where you provide instructions on how the LLM should behave. It is considered additional as it is outside of your \"normal\" prompts (better known as User Prompts) to the LLM.\\n\\nWithin a chat, every time you provide a new prompt, System Prompts act like a filter that the LLM automatically applies before giving its response to your new prompt. This means that the System Prompts are taken into account every time the LLM responds within the chat.\\n\\nWhen should System Prompts be used?\\n\\nThe first question on your mind might be: Why should I provide instructions inside the System Prompt when I can also provide them in my first prompt to a new chat, before further conversations with the LLM?\\n\\nThe answer is because LLMs have a limit to their conversational memory. In the latter case, as the conversation carries on, the LLM is likely to \"forget\" this first prompt you provided to the chat, making these instructions obsolete.\\n\\nOn the other hand, when instructions are provided in the System Prompt, these System Prompt instructions are automatically taken into account together with each new prompt provided to the chat. This ensures that the LLM continues to receive these instructions even as the conversation carries on, no matter how long the chat becomes.\\n\\nIn conclusion:\\n\\nUse System Prompts to provide instructions that you want the LLM to remember when responding throughout the entire chat.\\n\\nWhat should System Prompts include?\\n\\nInstructions in the System Prompt typically includes the following categories:\\n\\nTask definition, so the LLM will always remember what it has to do throughout the chat.\\n\\nOutput format, so the LLM will always remember how it should respond.\\n\\nGuardrails, so the LLM will always remember how it should *not* respond. Guardrails are emerging field in LLM governance, referring to configured boundaries that an LLM is allowed to operate in.\\n\\nFor example, a System Prompt might look like this:\\n\\nYou will answer questions using this text: [insert text]. \\nYou will respond with a JSON object in this format: {\"Question\": \"Answer\"}.\\nIf the text does not contain sufficient information to answer the question, do not make up information and give the answer as \"NA\". \\nYou are only allowed to answer questions related to [insert scope]. Never answer any questions related to demographic information such as age, gender, and religion.\\n\\nWhere each portion relates to the categories as follows:\\n\\nBreaking down a System Prompt - Image by author\\n\\nBut then what goes into the \"normal\" prompts to the chat?\\n\\nNow you might be thinking: That sounds like a lot of information already being given in the System Prompt. What do I put in my \"normal\" prompts (better known as User Prompts) to the chat then?\\n\\nThe System Prompt outlines the general task at hand. In the above System Prompt example, the task has been defined to only use a specific piece of text for question-answering, and the LLM is instructed to respond in the format {\"Question\": \"Answer\"}.\\n\\nYou will answer questions using this text: [insert text]. \\nYou will respond with a JSON object in this format: {\"Question\": \"Answer\"}.\\n\\nIn this case, each User Prompt to the chat would simply be the question that you want answered using the text. For example, a User Prompt might be \"What is the text about?\". And the LLM would respond with {\"What is the text about?\": \"The text is about...\"}.\\n\\nBut let’s generalize this task example further. In practice, it would be more likely that you have multiple pieces of text that you want to ask questions on, rather than just 1. In this case, we could edit the first line of the above System Prompt from\\n\\nYou will answer questions using this text: [insert text].\\n\\nto\\n\\nYou will answer questions using the provided text.\\n\\nNow, each User Prompt to the chat would include both the text to conduct question-answering over, and the question to be answered, such as:\\n\\n<text>\\n[insert text]\\n</text>\\n\\n<question>\\n[insert question]\\n</question>\\n\\nHere, we also use XML tags as delimiters in order to provide the 2 required pieces of information to the LLM in a structured manner. The nouns used in the XML tags, text and question, correspond to the nouns used in the System Prompt so that the LLM understands how the tags relate to the System Prompt instructions.\\n\\nIn conclusion, the System Prompt should give the overall task instructions, and each User Prompt should provide the exact specifics that you want the task to be executed using. In this case, for example, these exact specifics are the text and the question.\\n\\nExtra: Making LLM guardrails dynamic\\n\\nAbove, guardrails are added through a few sentences in the System Prompt. These guardrails are then set in stone and do not change for the entire chat. What if you wish to have different guardrails in place at different points of the conversation?\\n\\nUnfortunately for users of the ChatGPT user interface, there is no straightforward way to do this right now. However, if you’re interacting with ChatGPT programmatically, you’re in luck! The increasing focus on building effective LLM guardrails has seen the development of open-source packages that allow you to set up far more detailed and dynamic guardrails programmatically.\\n\\nA noteworthy one is NeMo Guardrails developed by the NVIDIA team, which allows you to configure the expected conversation flow between users and the LLM, and thus set up different guardrails at different points of the chat, allowing for dynamic guardrails that evolve as the chat progresses. I definitely recommend checking it out!\\n\\n4. [🔴] Analyzing datasets using only LLMs, without plugins or code\\n\\nImage generated by DALL·E 3\\n\\nYou might have heard of OpenAI’s Advanced Data Analysis plugin within ChatGPT’s GPT-4 that is available to premium (paid) accounts. It allows users to upload datasets to ChatGPT and run code directly on the dataset, allowing for accurate data analysis.\\n\\nBut did you know that you don’t always need such plugins to analyze datasets well with LLMs? Let’s first understand the strengths and limitations of purely using LLMs to analyze datasets.\\n\\nTypes of dataset analysis that LLMs are *not* great at\\n\\nAs you probably already know, LLMs are limited in their ability to perform accurate mathematical calculations, making them unsuitable for tasks requiring precise quantitative analysis on datasets, such as:\\n\\nDescriptive Statistics: Summarizing numerical columns quantitatively, through measures like the mean or variance.\\n\\nCorrelation Analysis: Obtaining the precise correlation coefficient between columns.\\n\\nStatistical Analysis: Such as hypothesis testing to determine if there are statistically significant differences between groups of data points.\\n\\nMachine Learning: Performing predictive modelling on a dataset such as using linear regressions, gradient boosted trees, or neural networks.\\n\\nPerforming such quantitative tasks on datasets is why OpenAI’s Advanced Data Analysis plugin exists, so that programming languages step in to run code for such tasks on a dataset.\\n\\nSo, why would anyone want to analyze datasets using only LLMs and without such plugins?\\n\\nTypes of dataset analysis that LLMs are great at\\n\\nLLMs are excellent at identifying patterns and trends. This capability stems from their extensive training on diverse and voluminous data, enabling them to discern intricate patterns that may not be immediately apparent.\\n\\nThis makes them well-suited for tasks based on pattern-finding within datasets, such as:\\n\\nAnomaly detection: Identifying unusual data points that deviate from the norm, based on one or more column values.\\n\\nClustering: Grouping data points with similar characteristics across columns.\\n\\nCross-Column Relationships: Identifying combined trends across columns.\\n\\nTextual Analysis (For text-based columns): Categorization based on topic or sentiment.\\n\\nTrend Analysis (For datasets with time aspects): Identifying patterns, seasonal variations, or trends within columns across time.\\n\\nFor such pattern-based tasks, using LLMs alone may in fact produce better results within a shorter timeframe than using code! Let’s illustrate this fully with an example.\\n\\nAnalyzing a Kaggle dataset using only LLMs\\n\\nWe’ll use a popular real-world Kaggle dataset curated for Customer Personality Analysis, wherein a company seeks to segment its customer base in order to understand its customers better.\\n\\nFor easier validation of the LLM’s analysis later, we’ll subset this dataset to 50 rows and retain only the most relevant columns. After which, the dataset for analysis looks like this, where each row represents a customer, and the columns depict customer information:\\n\\nFirst 3 rows of dataset - Image by author\\n\\nSay you work on the company’s marketing team. You are tasked to utilize this dataset of customer information to guide marketing efforts. This is a 2-step task: First, use the dataset to generate meaningful customer segments. Next, generate ideas on how to best market towards each segment. Now this is a practical business problem where the pattern-finding (for step 1) capability of LLMs can truly excel.\\n\\nLet’s craft a prompt for this task as follows, using 4 prompt engineering techniques (more on these later!):\\n1. Breaking down a complex task into simple steps\\n2. Referencing intermediate outputs from each step\\n3. Formatting the LLM’s response\\n4. Separating the instructions from the dataset\\n\\nSystem Prompt:\\nI want you to act as a data scientist to analyze datasets. Do not make up information that is not in the dataset. For each analysis I ask for, provide me with the exact and definitive answer and do not provide me with code or instructions to do the analysis on other platforms.\\n\\nPrompt:\\n# CONTEXT #\\nI sell wine. I have a dataset of information on my customers: [year of birth, marital status, income, number of children, days since last purchase, amount spent].\\n\\n#############\\n\\n# OBJECTIVE #\\nI want you use the dataset to cluster my customers into groups and then give me ideas on how to target my marketing efforts towards each group. Use this step-by-step process and do not use code:\\n\\n1. CLUSTERS: Use the columns of the dataset to cluster the rows of the dataset, such that customers within the same cluster have similar column values while customers in different clusters have distinctly different column values. Ensure that each row only belongs to 1 cluster.\\n \\nFor each cluster found,\\n2. CLUSTER_INFORMATION: Describe the cluster in terms of the dataset columns.\\n3. CLUSTER_NAME: Interpret [CLUSTER_INFORMATION] to obtain a short name for the customer group in this cluster.\\n4. MARKETING_IDEAS: Generate ideas to market my product to this customer group.\\n5. RATIONALE: Explain why [MARKETING_IDEAS] is relevant and effective for this customer group.\\n\\n#############\\n\\n# STYLE #\\nBusiness analytics report\\n\\n#############\\n\\n# TONE #\\nProfessional, technical\\n\\n#############\\n\\n# AUDIENCE #\\nMy business partners. Convince them that your marketing strategy is well thought-out and fully backed by data.\\n\\n#############\\n\\n# RESPONSE: MARKDOWN REPORT #\\n <For each cluster in [CLUSTERS]>\\n - Customer Group: [CLUSTER_NAME]\\n - Profile: [CLUSTER_INFORMATION]\\n - Marketing Ideas: [MARKETING_IDEAS]\\n - Rationale: [RATIONALE]\\n\\n<Annex>\\n Give a table of the list of row numbers belonging to each cluster, in order to back up your analysis. Use these table headers: [[CLUSTER_NAME], List of Rows].\\n\\n#############\\n\\n# START ANALYSIS #\\n If you understand, ask me for my dataset.\\n\\nBelow is GPT-4’s reply, and we proceed to pass the dataset to it in a CSV string.\\n\\nGPT-4\\'s response - Image by author\\n\\nFollowing which, GPT-4 replies with its analysis in the markdown report format we asked for:\\n\\nGPT-4\\'s response - Image by author\\n\\nGPT-4\\'s response - Image by author\\n\\nGPT-4\\'s response - Image by author\\n\\nValidating the LLM’s analysis\\n\\nFor the sake of brevity, we’ll pick 2 customer groups generated by the LLM for validation - say, Young Families and Discerning Enthusiasts.\\n\\nYoung Families\\n- Profile synthesized by LLM: Born after 1980, Married or Together, Moderate to low income, Have children, Frequent small purchases.\\n- Rows clustered into this group by LLM: 3, 4, 7, 10, 16, 20\\n- Digging into the dataset, the full data for these rows are:\\n\\nFull data for Young Families - Image by author\\n\\nWhich exactly correspond to the profile identified by the LLM. It was even able to cluster the row with a null value without us preprocessing it beforehand!\\n\\nDiscerning Enthusiasts\\n- Profile synthesized by LLM: Wide age range, Any marital status, High income, Varied children status, High spend on purchases.\\n- Rows clustered into this group by LLM: 2, 5, 18, 29, 34, 36\\n- Digging into the dataset, the full data for these rows are:\\n\\nFull data for Discerning Enthusiasts - Image by author\\n\\nWhich again align very well with the profile identified by the LLM!\\n\\nThis example showcases LLMs’ abilities in pattern-finding, interpreting and distilling multi-dimensional datasets into meaningful insights, while ensuring that its analysis is deeply rooted in the factual truth of the dataset.\\n\\nWhat if we used ChatGPT’s Advanced Data Analysis plugin?\\n\\nFor completeness, I attempted this same task with the same prompt, but asked ChatGPT to execute the analysis using code instead, which activated its Advanced Data Analysis plugin. The idea was for the plugin to run code using a clustering algorithm like K-Means directly on the dataset to obtain each customer group, before synthesizing the profile of each cluster to provide marketing strategies.\\n\\nHowever, multiple attempts resulted in the following error messages with no outputs, despite the dataset being only 50 rows:\\n\\nError and no output from Attempt 1 - Image by author\\n\\nError and no output from Attempt 2 - Image by author\\n\\nWith the Advanced Data Analysis plugin right now, it appears that executing simpler tasks on datasets such as calculating descriptive statistics or creating graphs can be easily achieved, but more advanced tasks that require computing of algorithms may sometimes result in errors and no outputs, due to computational limits or otherwise.\\n\\nSo…When to analyze datasets using LLMs?\\n\\nThe answer is it depends on the type of analysis.\\n\\nFor tasks requiring precise mathematical calculations or complex, rule-based processing, conventional programming methods remain superior.\\n\\nFor tasks based on pattern-recognition, it can be challenging or more time-consuming to execute using conventional programming and algorithmic approaches. LLMs, however, excel at such tasks, and can even provide additional outputs such as annexes to back up its analysis, and full analysis reports in markdown formatting.\\n\\nUltimately, the decision to utilize LLMs hinges on the nature of the task at hand, balancing the strengths of LLMs in pattern-recognition against the precision and specificity offered by traditional programming techniques.\\n\\nNow back to the prompt engineering!\\n\\nBefore this section ends, let’s go back to the prompt used to generate this dataset analysis and break down the key prompt engineering techniques used:\\n\\nPrompt:\\n# CONTEXT #\\nI sell wine. I have a dataset of information on my customers: [year of birth, marital status, income, number of children, days since last purchase, amount spent].\\n\\n#############\\n\\n# OBJECTIVE #\\nI want you use the dataset to cluster my customers into groups and then give me ideas on how to target my marketing efforts towards each group. Use this step-by-step process and do not use code:\\n\\n1. CLUSTERS: Use the columns of the dataset to cluster the rows of the dataset, such that customers within the same cluster have similar column values while customers in different clusters have distinctly different column values. Ensure that each row only belongs to 1 cluster.\\n \\nFor each cluster found,\\n2. CLUSTER_INFORMATION: Describe the cluster in terms of the dataset columns.\\n3. CLUSTER_NAME: Interpret [CLUSTER_INFORMATION] to obtain a short name for the customer group in this cluster.\\n4. MARKETING_IDEAS: Generate ideas to market my product to this customer group.\\n5. RATIONALE: Explain why [MARKETING_IDEAS] is relevant and effective for this customer group.\\n\\n#############\\n\\n# STYLE #\\nBusiness analytics report\\n\\n#############\\n\\n# TONE #\\nProfessional, technical\\n\\n#############\\n\\n# AUDIENCE #\\nMy business partners. Convince them that your marketing strategy is well thought-out and fully backed by data.\\n\\n#############\\n\\n# RESPONSE: MARKDOWN REPORT #\\n <For each cluster in [CLUSTERS]>\\n - Customer Group: [CLUSTER_NAME]\\n - Profile: [CLUSTER_INFORMATION]\\n - Marketing Ideas: [MARKETING_IDEAS]\\n - Rationale: [RATIONALE]\\n\\n<Annex>\\n Give a table of the list of row numbers belonging to each cluster, in order to back up your analysis. Use these table headers: [[CLUSTER_NAME], List of Rows].\\n\\n#############\\n\\n# START ANALYSIS #\\n If you understand, ask me for my dataset.\\n\\nTechnique 1: Breaking down a complex task into simple steps\\nLLMs are great at performing simple tasks, but not so great at complex ones. As such, with complex tasks like this one, it is important to break down the task into simple step-by-step instructions for the LLM to follow. The idea is to give the LLM the steps that you yourself would take to execute the task.\\n\\nIn this example, the steps are given as:\\n\\nUse this step-by-step process and do not use code:\\n\\n1. CLUSTERS: Use the columns of the dataset to cluster the rows of the dataset, such that customers within the same cluster have similar column values while customers in different clusters have distinctly different column values. Ensure that each row only belongs to 1 cluster.\\n \\nFor each cluster found,\\n2. CLUSTER_INFORMATION: Describe the cluster in terms of the dataset columns.\\n3. CLUSTER_NAME: Interpret [CLUSTER_INFORMATION] to obtain a short name for the customer group in this cluster.\\n4. MARKETING_IDEAS: Generate ideas to market my product to this customer group.\\n5. RATIONALE: Explain why [MARKETING_IDEAS] is relevant and effective for this customer group.\\n\\nAs opposed to simply giving the overall task to the LLM as \"Cluster the customers into groups and then give ideas on how to market to each group\".\\n\\nWith step-by-step instructions, LLMs are significantly more likely to deliver the correct results.\\n\\nTechnique 2: Referencing intermediate outputs from each step\\nWhen providing the step-by-step process to the LLM, we give the intermediate output from each step a capitalized VARIABLE_NAME, namely CLUSTERS, CLUSTER_INFORMATION, CLUSTER_NAME, MARKETING_IDEAS and RATIONALE.\\n\\nCapitalization is used to differentiate these variable names from the body of instructions given. These intermediate outputs can later be referenced using square brackets as [VARIABLE_NAME].\\n\\nTechnique 3: Formatting the LLM’s response\\nHere, we ask for a markdown report format, which beautifies the LLM’s response. Having variable names from intermediate outputs again comes in handy here to dictate the structure of the report.\\n\\n# RESPONSE: MARKDOWN REPORT #\\n <For each cluster in [CLUSTERS]>\\n - Customer Group: [CLUSTER_NAME]\\n - Profile: [CLUSTER_INFORMATION]\\n - Marketing Ideas: [MARKETING_IDEAS]\\n - Rationale: [RATIONALE]\\n\\n<Annex>\\n Give a table of the list of row numbers belonging to each cluster, in order to back up your analysis. Use these table headers: [[CLUSTER_NAME], List of Rows].\\n\\nIn fact, you could even subsequently ask ChatGPT to provide the report as a downloadable file, allowing you to work off of its response in writing your final report.\\n\\nSaving GPT-4\\'s response as a file - Image by author\\n\\nTechnique 4: Separating the task instructions from the dataset\\nYou’ll notice that we never gave the dataset to the LLM in our first prompt. Instead, the prompt gives only the task instructions for the dataset analysis, with this added to the bottom:\\n\\n# START ANALYSIS #\\nIf you understand, ask me for my dataset.\\n\\nChatGPT then responded that it understands, and we passed the dataset to it as a CSV string in our next prompt:\\n\\nGPT-4\\'s response - Image by author\\n\\nBut why separate the instructions from the dataset?\\n\\nThe straightforward answer is that LLMs have a limit to their context window, or the number of tokens they can take as input in 1 prompt. A long prompt combining both instructions and data might exceed this limit, leading to truncation and loss of information.\\n\\nThe more intricate answer is that separating the instructions and the dataset helps the LLM maintain clarity in understanding each, with lower likelihood of missing out information. You might have experienced scenarios where the LLM \"accidentally forgets\" a certain instruction you gave as part of a longer prompt - for example, if you asked for a 100-word response and the LLM gives you a longer paragraph back. By receiving the instructions first, before the dataset that the instructions are for, the LLM can first digest what it should do, before executing it on the dataset provided next.\\n\\nNote however that this separation of instructions and dataset can only be achieved with chat LLMs as they maintain a conversational memory, unlike completion LLMs which do not.\\n\\nClosing Thoughts\\n\\nBefore this article ends, I wanted to share some personal reflections on this incredible journey.\\n\\nFirst, a heartfelt thank you to GovTech Singapore for orchestrating such an amazing competition.\\n\\nA live on-stage battle in the final round!\\n\\nSecond, a big shout-out to my fellow phenomenal competitors, who each brought something special, making the competition as enriching as it was challenging! I’ll never forget the final round, with us battling it out on stage and a live audience cheering us on - an experience I’ll always remember fondly.\\n\\nFor me, this wasn’t just a competition; it was a celebration of talent, creativity, and the spirit of learning. And I’m beyond excited to see what comes next!\\n\\nI had a lot of fun writing this, and if you had fun reading, I would really appreciate if you took a second to leave some claps and a follow! You can also buy me a matcha latte 🍵 to fuel my next article :)\\n\\nSee you in the next one!\\nSheila'}},\n",
       "  {'id': '8c339f8fb602',\n",
       "   'title': 'Stacked Ensembles for Advanced Predictive Modeling With H2O.ai and Optuna',\n",
       "   'subtitle': 'And how I placed top 10% in Europe’s largest machine learning competition with them!',\n",
       "   'author': 'fca9db1c7da0',\n",
       "   'publication_id': '7f60cf5620c9',\n",
       "   'published_at': '2023-12-18 16:05:44',\n",
       "   'last_modified_at': '2023-12-29 16:32:23',\n",
       "   'tags': ['machine-learning',\n",
       "    'data-science',\n",
       "    'deep-learning',\n",
       "    'ensemble-learning',\n",
       "    'python'],\n",
       "   'topics': ['machine-learning', 'data-science'],\n",
       "   'claps': 462,\n",
       "   'voters': 104,\n",
       "   'word_count': 3134,\n",
       "   'responses_count': 11,\n",
       "   'reading_time': 12.376415094339624,\n",
       "   'url': 'https://towardsdatascience.com/stacked-ensembles-for-advanced-predictive-modeling-with-h2o-ai-and-optuna-8c339f8fb602',\n",
       "   'unique_slug': 'stacked-ensembles-for-advanced-predictive-modeling-with-h2o-ai-and-optuna-8c339f8fb602',\n",
       "   'image_url': 'https://miro.medium.com/1*5FM14YZopRvGK9baJR0OtQ.png',\n",
       "   'lang': 'en',\n",
       "   'is_series': False,\n",
       "   'is_locked': True,\n",
       "   'is_shortform': False,\n",
       "   'top_highlight': '',\n",
       "   'content': {'id': '8c339f8fb602',\n",
       "    'content': \"How I Achieved Top 10% in Europe’s Largest Machine Learning Competition with Stacked Ensembles\\n\\nA conceptual and hands-on coding guide to training Stacked Ensembles with H2O.ai and Optuna\\n\\nImage generated by DALL·E 3\\n\\nWe all know that ensemble models outperform any singular model at predictive modeling. You’ve probably heard all about Bagging and Boosting as common ensemble methods, with Random Forests and Gradient Boosting Machines as respective examples.\\n\\nBut what about ensembling different models together under a separate higher-level model? This is where stacked ensembles comes in. This article is step-by-step guide on how to train stacked ensembles using the popular machine learning library, H2O.\\n\\nTo demonstrate the power of stacked ensembles, I will provide a walk-through of my full code for training a stacked ensemble of 40 Deep Neural Network, XGBoost and LightGBM models for the prediction task posed in the 2023 Cloudflight Coding Competition (AI Category), one of the largest coding competitions in Europe, where I placed top 10% on the competition leaderboard within a training time of 1 hour!\\n\\nThis guide will cover:\\n\\nWhat are stacked ensembles and how do they work?\\n\\nHow to train stacked ensembles with H2O.ai - \\nWith a full code walk-through in Python\\n\\nComparing the performance of a stacked ensemble versus standalone models\\n\\n1. What are Stacked Ensembles and how do they work?\\n\\nA stacked ensemble combines predictions from multiple models through another, higher-level model, with the aim being to increase overall predictive performance by capitalizing on the unique strengths of each constituent model. It involves 2 stages:\\n\\nStage 1: Multiple Base Models\\n\\nFirst, multiple base models are independently trained on the same training dataset. These models should ideally be diverse, ranging from simple linear regressions to complex deep learning models. The key is that they should differ from each other in some way, either in terms of using a different algorithm or using the same algorithm but with different hyperparameter settings.\\n\\nThe more diverse the base models are, the more powerful the eventual stacked ensemble. This is because different models are able to capture different patterns in the data. For example, a tree-based model might be good at capturing non-linear relationships, while a linear model excels at understanding linear trends. When these diverse base models are combined, the stacked ensemble can then leverage the different strengths of each base model, increasing predictive performance.\\n\\nStage 2: One Meta-Model\\n\\nAfter all the base models are trained, each base model’s predictions for the target is used as a feature for training a higher-level model, termed a meta-model. This means that the meta-model is not trained on the original dataset’s features, but instead on the predictions of the base models. If there are n base models, there are n predictions generated, and these are the n features used for training the meta-model.\\n\\nWhile the training features differ between the base models and the meta-model, the target however stays the same, which is the original target from the dataset.\\n\\nThe meta-model learns how to best combine the predictions from the base models to make a final, more accurate prediction.\\n\\nDetailed Steps for Training a Stacked Ensemble\\n\\nFor each base model:\\n1. Pick an algorithm (eg. Random Forest).\\n2. Use cross-validation to obtain the best set of hyperparameters for the algorithm.\\n3. Obtain cross-validation predictions for the target in the training set. These will be used to train the meta-model subsequently.\\n\\nTo illustrate this, say a Random Forest algorithm was chosen in Step 1, and its optimal hyperparameters were determined as h in Step 2.\\n\\nThe cross-validation predictions are obtained through the following, assuming 5-fold cross-validation:\\n1. Train a Random Forest with hyperparamters h on Folds 1–4.\\n2. Used the trained Random Forest to make predictions for Fold 5. These are the cross-validation predictions for Fold 5.\\n3. Repeat the above to obtain cross-validation predictions for each fold. After which, cross-validation predictions for the target will be obtained for the entire training set.\\n\\nFor the meta-model:\\n1. Obtain the features for training the meta-model. These are the predictions of each of the base models.\\n2. Obtain the target for training the meta-model. This is the original target from the training set.\\n3. Pick an algorithm (eg. Linear Regression).\\n4. Use cross-validation to obtain the best set of hyperparameters for the algorithm.\\n\\nAnd voila! You now have:\\n- Multiple base models that are trained with optimal hyperparameters\\n- One meta-model that is also trained with optimal hyperparameters\\n\\nWhich means you have successfully trained a stacked ensemble!\\n\\n2. How to Train Stacked Ensembles with H2O.ai\\n\\nNow, let’s jump into coding it out!\\n\\nAs mentioned, this section covers my full code for training a stacked ensemble for the prediction task posed in the 2023 Cloudflight Coding Competition (AI Category), which is a regression task using tabular data. Within the competition’s time constraints, I created a stacked ensemble from 40 base models of 3 algorithm types - Deep Neural Network, XGBoost, and LightGBM, with these specific algorithms chosen as they often achieve superior performance in practice.\\n\\n2.1. Data Preparation\\n\\nFirst, let’s import the necessary libraries.\\n\\nimport pandas as pd\\nimport h2o\\nfrom h2o.estimators.deeplearning import H2ODeepLearningEstimator\\nfrom h2o.estimators import H2OXGBoostEstimator\\nfrom h2o.estimators.stackedensemble import H2OStackedEnsembleEstimator\\nimport optuna\\nfrom tqdm import tqdm\\n\\nseed = 1\\n\\nAnd initialize the H2O cluster.\\n\\nh2o.init()\\n\\nNext, load in the dataset.\\n\\ndata = pd.read_csv('path_to_your_tabular_dataset')\\n\\nBefore moving on to model building using H2O, let’s first understand the following traits of H2O models:\\n\\nH2O models cannot take in Pandas DataFrame objects, so data must be converted from a Pandas DataFrame to its H2O equivalent, which is a H2OFrame.\\n\\nH2O models can encode categorical features automatically, which is great as it takes this preprocessing step out of our hands. To ensure that such features are understood by the models to be categorical, they must be explicitly converted into the factor (categorical) data type.\\n\\ndata_h2o = h2o.H2OFrame(data)\\n\\ncategorical_cols = [...]  #insert the names of the categorical features here\\nfor col in categorical_cols:\\n  data_h2o[col] = data_h2o[col].asfactor()\\n\\nNow we can proceed to split our dataset into train (90%) and validation (10%) sets, using the split_frame() method of H2OFrame objects.\\n\\nsplits = data_h2o.split_frame(ratios=[0.9], seed=seed)\\ntrain = splits[0]\\nval = splits[1]\\n\\nLastly, let’s obtain the features and target for modelling. Unlike Scikit-Learn models which take as input the values of the features and the target, H2O models take as input the names of the features and the target.\\n\\ny = '...'  #insert name of the target column here\\nx = list(train.columns)\\nx.remove(y) \\n\\nNow, let the model training fun begin!\\n\\n2.2. Training Deep Neural Networks (DNN) as Base Models\\n\\nLet’s start by training the DNNs that will form our set of base models for the stacked ensemble, using H2O’s H2ODeepLearningEstimator.\\n\\nAside: Why train DNNs in H2O, instead of Tensorflow, Keras, or PyTorch?\\n\\nBefore jumping into the code for this, you might be wondering why I chose to train DNNs using H2O’s H2ODeepLearningEstimator, as opposed to using Tensorflow, Keras, or PyTorch, which are the common libraries used to build DNNs.\\n\\nThe straightforward answer is that building a stacked ensemble in H2O uses the H2OStackedEnsembleEstimator, which can only accept base models that are part of the H2O model family. However, the more critical reason is that H2O’s H2ODeepLearningEstimator enables far easier tuning of DNNs than these other frameworks, and here’s why.\\n\\nIn TensorFlow, Keras, or PyTorch, regularization effects like dropout layers must be manually added into the model architecture, such as using keras.layers.Dropout(). This allows for greater customization, but also requires more detailed knowledge and effort. For example, you have to decide where and how many times to include the keras.layers.Dropout() layer within your model architecture.\\n\\nOn the other hand, H2O's H2ODeepLearningEstimator is more abstracted and accessible to the layman. Regularization can be enabled in a straightforward manner through model hyperparameters, reducing the need for manual setup of these components as layers. Furthermore, the default model hyperparameters already includes regularization. The common feature preprocessing steps, such as scaling of numerical features and encoding of categorical features, are also included as model hyperparameters for automatic feature preprocessing. These enable the tuning of DNNs to be a far more straightforward and easy process, without having to dive into the complexities of deep learning model architecture. In the context of a time crunch in the competition, this was extremely useful for me!\\n\\nBut which set of hyperparameters should we train H2ODeepLearningEstimator with? This is where optuna comes in. Optuna is a hyperparameter optimization framework, similar to the traditional grid search and random search approaches, but better in that it employs a more sophisticated approach.\\n\\nGrid search systematically explores a predefined range of hyperparameter values, while random search selects random combinations within these specified limits. However, optuna uses Bayesian optimization to learn from previous searches to propose better-performing hyperparameter sets in each subsequent search, increasing the efficiency of its search for the optimal model hyperparameters. This is especially effective in complex and large hyperparameter spaces where traditional search methods can be prohibitively time-consuming and may eventually still fail to locate the optimal set of hyperparameters.\\n\\nNow, let’s get into the code. We’ll use optuna to tune the hyperparameters of H2O’s H2ODeepLearningEstimator, and keep track of all the trained models inside the list dnn_models.\\n\\ndnn_models = []\\n\\ndef objective(trial):\\n    #params to tune\\n    num_hidden_layers = trial.suggest_int('num_hidden_layers', 1, 10)\\n    hidden_layer_size = trial.suggest_int('hidden_layer_size', 100, 300, step=50)\\n    \\n    params = {\\n        'hidden': [hidden_layer_size]*num_hidden_layers,\\n        'epochs': trial.suggest_int('epochs', 5, 100),\\n        'input_dropout_ratio': trial.suggest_float('input_dropout_ratio', 0.1, 0.3),  #dropout for input layer\\n        'l1': trial.suggest_float('l1', 1e-5, 1e-1, log=True),  #l1 regularization\\n        'l2': trial.suggest_float('l2', 1e-5, 1e-1, log=True),  #l2 regularization\\n        'activation': trial.suggest_categorical('activation', ['rectifier', 'rectifierwithdropout', 'tanh', 'tanh_with_dropout', 'maxout', 'maxout_with_dropout'])\\n}\\n    \\n    #param 'hidden_dropout_ratios' is applicable only if the activation type is rectifier_with_dropout, tanh_with_dropout, or maxout_with_dropout\\n    if params['activation'] in ['rectifierwithdropout', 'tanh_with_dropout', 'maxout_with_dropout']:\\n        hidden_dropout_ratio = trial.suggest_float('hidden_dropout_ratio', 0.1, 1.0)  \\n        params['hidden_dropout_ratios'] = [hidden_dropout_ratio]*num_hidden_layers  #dropout for hidden layers\\n\\n    #train model\\n    model = H2ODeepLearningEstimator(**params,\\n                                     standardize=True,  #h2o models can do this feature preprocessing automatically\\n                                     categorical_encoding='auto',  #h2o models can do this feature preprocessing automatically\\n                                     nfolds=5,\\n                                     keep_cross_validation_predictions=True,  #need this for training the meta-model later\\n                                     seed=seed)\\n    model.train(x=x, y=y, training_frame=train)\\n    \\n    #store model\\n    dnn_models.append(model)\\n\\n    #get cross-validation rmse \\n    cv_metrics_df = model.cross_validation_metrics_summary().as_data_frame()\\n    cv_rmse_index = cv_metrics_df[cv_metrics_df[''] == 'rmse'].index\\n    cv_rmse = cv_metrics_df['mean'].iloc[cv_rmse_index]\\n    return cv_rmse\\n\\nstudy = optuna.create_study(direction='minimize')\\nstudy.optimize(objective, n_trials=20)\\n\\nAbove, an optuna study is created to search for the best set of H2ODeepLearningEstimator hyperparameters that minimizes the cross-validation RMSE (as this is a regression task), with the optimization process running for 20 trials using the parameter n_trials=20. This means that 20 DNNs are trained and stored in the list dnn_models for usage as base models for the stacked ensemble later on, each with a different set of hyperparameters. In the interest of time under the competition’s time constraints, I chose to train 20 DNNs, but you can set n_trials to be however many DNNs you wish to train for your stacked ensemble.\\n\\nImportantly, the H2ODeepLearningEstimator must be trained with keep_cross_validation_predictions=True, as these cross-validation predictions will be used as features for training the meta-model later.\\n\\n2.3. Training XGBoost and LightGBM as Base Models\\n\\nNext, let’s train the XGBoost and LightGBM models that will also form our set of base models for the stacked ensemble. We’ll again use optuna to tune the hyperparameters of H2O’s H2OXGBoostEstimator, and keep track of all the trained models inside the list xgboost_lightgbm_models.\\n\\nBefore diving into the code for this, we must first understand that H2OXGBoostEstimator is the integration of the XGBoost framework from the popular xgboost library into H2O. On the other hand, H2O does not integrate the lightgbm library. However, it does provide a method for emulating the LightGBM framework using a certain set of parameters within H2OXGBoostEstimator- and this is exactly what we will implement in order to train both XGBoost and LightGBM models using H2OXGBoostEstimator.\\n\\nxgboost_lightgbm_models = []\\n\\ndef objective(trial):\\n    #common params between xgboost and lightgbm\\n    params = {\\n        'ntrees': trial.suggest_int('ntrees', 50, 5000),\\n        'max_depth': trial.suggest_int('max_depth', 1, 9),\\n        'min_rows': trial.suggest_int('min_rows', 1, 5),\\n        'sample_rate': trial.suggest_float('sample_rate', 0.8, 1.0),\\n        'col_sample_rate': trial.suggest_float('col_sample_rate', 0.2, 1.0),\\n        'col_sample_rate_per_tree': trial.suggest_float('col_sample_rate_per_tree', 0.5, 1.0)\\n    }\\n    \\n    grow_policy = trial.suggest_categorical('grow_policy', ['depthwise', 'lossguide'])\\n    \\n     #######################################################################################################################\\n     #from H2OXGBoostEstimator's documentation, (https://docs.h2o.ai/h2o/latest-stable/h2o-docs/data-science/xgboost.html) # \\n     #lightgbm is emulated when grow_policy=lossguide and tree_method=hist                                                 #\\n     #so we will tune lightgbm-specific hyperparameters when this set of hyperparameters is used                           #\\n     #and tune xgboost-specific hyperparameters otherwise                                                                  #\\n     #######################################################################################################################\\n\\n    #add lightgbm-specific params\\n    if grow_policy == 'lossguide':  \\n        tree_method = 'hist'  \\n        params['max_bins'] = trial.suggest_int('max_bins', 20, 256)\\n        params['max_leaves'] = trial.suggest_int('max_leaves', 31, 1024)\\n        \\n    #add xgboost-specific params\\n    else:\\n        tree_method = 'auto'\\n        params['booster'] = trial.suggest_categorical('booster', ['gbtree', 'gblinear', 'dart'])\\n        params['reg_alpha'] = trial.suggest_float('reg_alpha', 0.001, 1)\\n        params['reg_lambda'] = trial.suggest_float('reg_lambda', 0.001, 1)\\n        params['min_split_improvement'] = trial.suggest_float('min_split_improvement', 1e-10, 1e-3, log=True)\\n    \\n    #add grow_policy and tree_method into params dict\\n    params['grow_policy'] = grow_policy\\n    params['tree_method'] = tree_method\\n\\n    #train model\\n    model = H2OXGBoostEstimator(**params,\\n                                learn_rate=0.1,\\n                                categorical_encoding='auto',  #h2o models can do this feature preprocessing automatically\\n                                nfolds=5,\\n                                keep_cross_validation_predictions=True,  #need this for training the meta-model later\\n                                seed=seed) \\n    model.train(x=x, y=y, training_frame=train)\\n\\n    #store model\\n    xgboost_lightgbm_models.append(model)\\n\\n    #get cross-validation rmse\\n    cv_metrics_df = model.cross_validation_metrics_summary().as_data_frame()\\n    cv_rmse_index = cv_metrics_df[cv_metrics_df[''] == 'rmse'].index\\n    cv_rmse = cv_metrics_df['mean'].iloc[cv_rmse_index]\\n    return cv_rmse\\n\\nstudy = optuna.create_study(direction='minimize')\\nstudy.optimize(objective, n_trials=20)\\n\\nSimilarly, 20 XGBoost and LightGBM models are trained and stored in the list xgboost_lightgbm_models for usage as base models for the stacked ensemble later on, each with a different set of hyperparameters. You can set n_trials to be however many XGBoost/LightGBM models you wish to train for your stacked ensemble.\\n\\nImportantly, the H2OXGBoostEstimator must also be trained with keep_cross_validation_predictions=True, as these cross-validation predictions will be used as features for training the meta-model later.\\n\\n2.4. Training the Meta-Model\\n\\nWe will use all of the Deep Neural Network, XGBoost and LightGBM models trained above as base models. However, this does not mean that all of them will be used in the stacked ensemble, as we will perform automatic base model selection when tuning our meta-model (more on this later)!\\n\\nRecall that we had stored each trained base model inside the lists dnn_models (20 models) and xgboost_lightgbm_models (20 models), giving a total of 40 base models for our stacked ensemble. Let’s combine them into a final list of base models, base_models.\\n\\nbase_models = dnn_models + xgboost_lightgbm_models\\n\\nNow, we are ready to train the meta-model using these base models. But first, we have to decide on the meta-model algorithm, where a few concepts come into play:\\n\\nMost academic papers on stacked ensembles recommend choosing a simple linear-based algorithm for the meta-model. This is to avoid the meta-model overfitting to the predictions from the base models.\\n\\nH2O recommends the usage of a Generalized Linear Model (GLM) over a Linear Regression (for regression tasks) or Logistic Regression (for classification tasks). This is because the GLM is a flexible linear model that does not impose the key assumptions of normality and homoscedasticity that the latter do, allowing it to model the true behavior of the target values better, since such assumptions can be difficult to be met in practice. Further explanations on this can be found in this academic thesis, on which H2O’s work was based upon.\\n\\nAs such, we will instantiate the meta-model using H2OStackedEnsembleEstimator with metalearner_algorithm='glm', and use optuna to tune the hyperparameters of the GLM meta-model to optimize performance.\\n\\ndef objective(trial):\\n    #GLM params to tune\\n    meta_model_params = {\\n        'alpha': trial.suggest_float('alpha', 0, 1),  #regularization distribution between L1 and L2\\n        'family': trial.suggest_categorical('family', ['gaussian', 'tweedie']),  #read the documentation here on which family your target may fall into: https://docs.h2o.ai/h2o/latest-stable/h2o-docs/data-science/glm.html\\n        'standardize': trial.suggest_categorical('standardize', [True, False]),\\n        'non_negative': True  #predictions of each base model cannot be subtracted from one another\\n    }\\n\\n    ensemble = H2OStackedEnsembleEstimator(metalearner_algorithm='glm',\\n                                             metalearner_params=meta_model_params,\\n                                             metalearner_nfolds=5,\\n                                             base_models=base_models,  \\n                                             seed=seed)\\n\\n    ensemble.train(x=x, y=y, training_frame=train)\\n    \\n    #get cross-validation rmse\\n    cv_metrics_df = ensemble.cross_validation_metrics_summary().as_data_frame()\\n    cv_rmse_index = cv_metrics_df[cv_metrics_df[''] == 'rmse'].index\\n    cv_rmse = cv_metrics_df['mean'].iloc[cv_rmse_index]\\n    return cv_rmse\\n\\nstudy = optuna.create_study(direction='minimize')\\nstudy.optimize(objective, n_trials=20)\\n\\nNotice that the cross-validation predictions of each base model were not explicitly passed into H2OStackedEnsembleEstimator. This is because H2O does this automatically under the hood, making things easier for us! All we had to do was set keep_cross_validation_predictions=True when training our base models previously, and instantiate H2OStackedEnsembleEstimator with the parameter base_models=base_models.\\n\\nNow, we can finally build the best_ensemble model, using the optimal hyperparameters found by optuna.\\n\\nbest_meta_model_params = study.best_params\\nbest_ensemble = H2OStackedEnsembleEstimator(metalearner_algorithm='glm',\\n                                            metalearner_params=best_meta_model_params,\\n                                            base_models=base_models,\\n                                            seed=seed)\\n\\nbest_ensemble.train(x=x, y=y, training_frame=train)\\n\\nAnd voila, we have successfully trained a stacked ensemble in H2O! Let’s take a look at it.\\n\\nbest_ensemble.summary()\\n\\nImage by author\\n\\nNotice that the stacked ensemble uses only 16 out of the 40 base models we passed to it, of which 3 are XGBoost/LightGBM and 13 are Deep Neural Networks. This is due to the hyperparameter alpha that we tuned for the GLM meta-model, which represents the distribution of regularization between L1 (LASSO) and L2 (Ridge). A value of 1 entails only L1 regularization, while a value of 0 entails only L2 regularization.\\n\\nAs reflected above, its optimal value was found to be alpha=0.16, thus a mix of L1 and L2 was employed. Some of the base models’ predictions had their coefficients in the regression set to 0 under L1 regularization, meaning that these base models were not used in the stacked ensemble at all, therefore fewer than 40 base models ended up being used.\\n\\nThe key takeaway here is that our setup above also performs automatic selection of which base models to use for optimal performance, through the meta-model’s regularization hyperparameters, instead of simply using all 40 base models provided.\\n\\n3. Comparing Performance: Stacked Ensemble Versus Standalone Base Models\\n\\nTo demonstrate the power of stacked ensembles, let’s use it to generate predictions for the validation set, which was held out from the beginning. The RMSE figures below are specific only to the dataset I am using, but feel free to run this article’s codes on your own dataset too, and see the difference in model performance for yourself!\\n\\nensemble_val_rmse = best_ensemble.model_performance(val).rmse()\\nensemble_val_rmse   #0.31475634111745304\\n\\nThe stacked ensemble produces an RMSE of 0.31 on the validation set.\\n\\nNext, let’s dig into the performance of each of the base models on this same validation set.\\n\\nbase_val_rmse = []\\nfor i in range(len(base_models)):\\n    base_val_rmse = base_models[i].model_performance(val).rmse()\\n    \\nmodels = ['H2ODeepLearningEstimator'] * len(dnn_models) + ['H2OXGBoostEstimator'] * len(xgboost_lightgbm_models)\\n\\nbase_val_rmse_df = pd.DataFrame([models, base_val_rmse]).T\\nbase_val_rmse_df.columns = ['model', 'val_rmse']\\nbase_val_rmse_df = base_val_rmse_df.sort_values(by='val_rmse', ascending=True).reset_index(drop=True)\\nbase_val_rmse_df.head(15)  #show only the top 15 in terms of lowest val_rmse\\n\\nImage by author\\n\\nCompared to the stacked ensemble which achieved an RMSE of 0.31, the best-performing standalone base model achieved an RMSE of 0.35.\\n\\nThis means that Stacking was able to improve predictive performance by 11% on unseen data!\\n\\nNow that you’ve witnessed the power of stacked ensembles, it’s your turn to try them out!\\n\\nI had a lot of fun writing this, and if you had fun reading, I would really appreciate if you took a second to leave some claps and a follow! You can also buy me a matcha latte 🍵 to fuel my next article :)\\n\\nSee you in the next one!\\nSheila\"}}],\n",
       " 'e10ad955760c': [{'id': '0d11918ee0b3',\n",
       "   'title': 'Create a Stock Chatbot with your own CSV Data',\n",
       "   'subtitle': 'An Explorative Study with Python',\n",
       "   'author': 'e10ad955760c',\n",
       "   'publication_id': '32881626c9c9',\n",
       "   'published_at': '2024-02-15 05:08:49',\n",
       "   'last_modified_at': '2024-02-15 10:22:46',\n",
       "   'tags': ['programming',\n",
       "    'artificial-intelligence',\n",
       "    'data-science',\n",
       "    'technology',\n",
       "    'python'],\n",
       "   'topics': ['machine-learning', 'data-science'],\n",
       "   'claps': 67,\n",
       "   'voters': 10,\n",
       "   'word_count': 2140,\n",
       "   'responses_count': 0,\n",
       "   'reading_time': 9.275471698113208,\n",
       "   'url': 'https://medium.datadriveninvestor.com/create-a-stock-chatbot-with-your-own-csv-data-0d11918ee0b3',\n",
       "   'unique_slug': 'create-a-stock-chatbot-with-your-own-csv-data-0d11918ee0b3',\n",
       "   'image_url': 'https://miro.medium.com/0*DCZrugG03DH7dlty',\n",
       "   'lang': 'en',\n",
       "   'is_series': False,\n",
       "   'is_locked': False,\n",
       "   'is_shortform': False,\n",
       "   'top_highlight': '',\n",
       "   'content': {'id': '0d11918ee0b3',\n",
       "    'content': 'Create a Stock Chatbot with your own CSV Data\\n\\nAn Explorative Study with Python\\n\\nPhoto by Google DeepMind on Unsplash\\n\\nIsn’t it fascinating to communicate with your data instead of solely relying on coding to gain insights? Imagine being able to engage with your CSV files through conversation. Yes, it’s true! AI has progressed to the point where Retrieval-Augmented Generation (RAG) emerges as a great tool in real-world data scenarios gaining insights from the amazing data that can be obtained from FinancialModelingPrep (FMP) making our life easier. But what exactly is RAG?\\n\\nRetrieval-Augmented Generation (RAG)\\n\\nIt represents a model architecture blending features of both retrieval-based and generation-based approaches in natural language processing (NLP). It was pioneered by researchers at Facebook AI in 2020.\\n\\nThe fundamental concept underlying RAG is to amalgamate the advantages of retrieval-based methods, proficient at leveraging pre-existing knowledge from extensive text corpora, with the adaptability and inventiveness of generation-based methods, capable of crafting novel and coherent text.\\n\\nWithin the RAG architecture, a retriever module initially fetches pertinent documents or passages from a vast corpus of text, based on an input query or prompt. These retrieved passages function as context or knowledge for the generation model. Subsequently, a generation model, often rooted in transformers like GPT (Generative Pre-trained Transformer) or BERT (Bidirectional Encoder Representations from Transformers), employs this retrieved context to produce responses or outputs.\\n\\n\\n\\nVector databases are an important component of RAG and are a great concept to understand let’s understand them in the next section.\\n\\nVector Databases\\n\\nLet’s begin by defining vector embedding. Vector embedding serves as a form of data representation imbued with semantic information, aiding AI systems in comprehending data effectively while maintaining long-term memory. Fundamental to learning any new concept is grasping its essence and retaining it over time.\\n\\nAI models, such as Large Language Models (LLMs), generate embeddings with numerous features, making their representation intricate. These embeddings delineate various dimensions of the data, facilitating the comprehension of diverse relationships, patterns, and latent structures.\\n\\nHowever, employing traditional scalar-based databases for vector embedding poses a challenge, given their incapacity to handle the scale and complexity of the data. The intricacies inherent in vector embedding underscore the necessity for specialized databases tailored to accommodate such complexity, thus giving rise to vector databases.\\n\\nVector databases offer optimized storage and query capabilities uniquely suited to the structure of vector embeddings. They streamline the search process, ensuring high performance, scalability, and efficient data retrieval by comparing values and identifying similarities.\\n\\nWhile the prospect of utilizing vector databases to address the complexities of vector embeddings appears promising, the implementation of such databases poses significant challenges.\\n\\n\\n\\nWe will harness RAG’s capabilities alongside the prowess of Large Language Models, complemented by the assistance of Langchain.\\n\\nLangChain\\n\\nThe library serves as an open-source framework, enabling software developers engaged in artificial intelligence (AI) and its machine learning subset to amalgamate large language models with various external components for the creation of LLM-driven applications. The primary objective of LangChain is to establish connections between robust LLMs, such as OpenAI’s GPT-3.5 and GPT-4, and a diverse array of external data sources, thereby facilitating the development and utilization of natural language processing (NLP) applications.\\n\\nAgents, tools, and Langchain CSV agent\\n\\n\\n\\nIn LangChain, agents are systems that leverage a language model to engage with various tools. These agents serve a range of purposes, from grounded question/answering to interfacing with APIs or executing actions.\\n\\nWithin the LangChain framework, tools and toolkits augment agents with additional functionalities and capabilities. Tools represent distinct components designed for specific tasks, such as fetching information from external sources or processing data.\\n\\n\\n\\nSome Applications based on LLMs with Langchain\\n\\nUsing LLMs using Langchain\\n\\nfrom langchain.chat_models import ChatOpenAI\\nfrom langchain.schema import HumanMessage, SystemMessage, AIMessage\\n\\nchat = ChatOpenAI(temperature = .7, openai_api_key = \\'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\\')\\n\\nchat(\\n    [\\n        SystemMessage(content = \"You are a nice AI bot that helps a user figure out where to travel in one short sentence\"),\\n        HumanMessage(content = \"I like the beaches where should I go?\"),\\n        AIMessage(content = \"You should go to Nice, France\"),\\n        HumanMessage(content = \"What else should I do when I\\'m there?\")\\n    ]\\n)\\n\\nOutput:\\n\\nAIMessage(content=\\'You should explore the charming streets of the Old Town and indulge in delicious French cuisine.\\')\\n\\nQuerying Tabular Data using Langchain\\n\\nTabular data is widely used across various domains, offering structured information for analysis. LangChain presents an opportunity to seamlessly query this data using natural language and interact with a Large Language Model (LLM) for insightful responses.\\n\\nLet’s delve into a practical example by querying an SQLite database, focusing on the San Francisco Trees dataset.\\n\\nfrom langchain.llms import OpenAI\\nfrom langchain.sql_database import SQLDatabase\\nfrom langchain_experimental.sql import SQLDatabaseChain\\n\\nllm = OpenAI(temperature=0, openai_api_key=\\'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\\')\\n\\n# Specify the data location and establish a connection\\nsqlite_db_path = \\'data/San_Francisco_Trees.db\\'\\ndb = SQLDatabase.from_uri(f\"sqlite:///{sqlite_db_path}\")\\n\\n# Create a chain with the LLM and DB, enabling verbose mode for transparency\\ndb_chain = SQLDatabaseChain(llm=llm, database=db, verbose=True)\\n\\n# Query: \"How many species of trees are there in San Francisco?\"\\nresult = db_chain.run(\"How many species of trees are there in San Francisco?\")\\nprint(result)\\n\\nOutput:\\n\\n> Entering new SQLDatabaseChain chain...\\nHow many species of trees are there in San Francisco?\\nSQLQuery: SELECT COUNT(DISTINCT \"qSpecies\") FROM \"SFTrees\";\\nSQLResult: [(578,)]\\nAnswer: There are 578 species of trees in San Francisco.\\n> Finished chain.\\n\\'There are 578 species of trees in San Francisco.\\'\\n\\nTo validate the result using Pandas:\\n\\nimport sqlite3\\nimport pandas as pd\\n \\n# Connect to the SQLite database\\nconnection = sqlite3.connect(sqlite_db_path)\\n\\n# Define the SQL query\\nquery = \"SELECT count(distinct qSpecies) FROM SFTrees\"\\n\\n# Read the query into a Pandas DataFrame\\ndf = pd.read_sql_query(query, connection)\\n\\n# Close the connection\\nconnection.close()\\n\\n# Display the result\\nprint(df.iloc[0,0])\\n\\nOutput:\\n\\n578\\n\\nIndeed, the consistency between the LangChain response and the Pandas validation confirms the accuracy of the query.\\n\\nNow we will look at the step-by-step process of how can we talk with the data obtained from FMP API. Let\\'s dive into it.\\n\\nCSV Chatbot with FMP’s Data\\n\\nInstalling the necessary Packages\\n\\nWith the recent introduction of two additional packages, namely langchain_experimental and langchain_openai in their latest version, LangChain has expanded its offerings alongside the base package. Therefore, we incorporate these two packages alongside LangChain during installation.\\n\\nDuring the import phase, we include necessary packages such as pandas for manipulating CSV files, numpy for array and vector operations, requests for accessing data from APIs, and various objects from sklearn for data splitting, training, and testing. Additionally, we import the agents and tools as described earlier.\\n\\n# Import necessary libraries\\nimport pandas as pd\\nimport numpy as np\\nimport requests\\nfrom sklearn.model_selection import train_test_split\\nfrom sklearn.linear_model import LinearRegression\\nfrom sklearn.metrics import mean_squared_error\\nimport matplotlib.pyplot as plt\\nimport os\\n\\nos.environ[\"OPENAI_API_KEY\"] = \"YOUR OPENAI API KEY\"\\n\\nfrom langchain.agents.agent_types import AgentType\\nfrom langchain_experimental.agents.agent_toolkits import create_csv_agent\\nfrom langchain_openai import ChatOpenAI, OpenAI\\n\\nFetching the data\\n\\nIn this section, we are fetching historical dividend data for a specific stock, AAPL (Apple Inc.), using an API provided by FinancialModelingPrep (FMP). We first specify our API key, then construct a URL with the appropriate endpoint and query parameters. After sending a GET request to the URL, we retrieve the response and convert it to a JSON format for further processing.\\n\\napi_key = \\'YOUR API KEY\\'\\n\\n# Fetch historical dividend data\\nurl = f\"https://financialmodelingprep.com/api/v3/historical-price-full/stock_dividend/AAPL?apikey={api_key}\"\\nresponse = requests.get(url)\\ndata = response.json()\\n\\n# Extract relevant data from the API response\\ndf_dividends = pd.DataFrame(data[\\'historical\\'])\\n\\ndf_dividends\\n\\nOutput:\\n\\nImage by Author\\n\\nAPI Key: api_key = ‘YOUR API KEY’\\n\\nThis variable stores the API key required to access the financial data API. It’s essentially a unique identifier that grants permission to access the data.\\n\\nConstructing the URL:\\n\\nurl = f\"https://financialmodelingprep.com/api/v3/historical-price-full/stock_dividend/AAPL?apikey={api_key}\"\\n\\nThis line constructs the URL needed to access the historical dividend data for the stock AAPL. It includes the base URL of the API along with the endpoint for historical dividend data, the stock ticker symbol (AAPL in this case), and the API key appended as a query parameter.\\n\\nMaking the API Request:\\n\\nresponse = requests.get(url)\\n\\nThis line sends an HTTP GET request to the constructed URL to retrieve the historical dividend data.\\n\\nParsing the Response:\\n\\ndata = response.json()\\n\\nThis line parses the JSON-formatted response content into a Python dictionary, making it easier to work with the data.\\n\\nCreating a DataFrame:\\n\\ndf_dividends = pd.DataFrame(data[‘historical’])\\n\\nThis line creates a pandas DataFrame from the historical dividend data extracted from the API response. The ‘historical’ key in the data dictionary contains a list of dictionaries, where each dictionary represents historical dividend data for a specific date.\\n\\nMaking the agent\\n\\nWe will now make the csv agent with just a few lines of code, which is explained line-by-line.\\n\\nagent = create_csv_agent(\\n    OpenAI(temperature = 0),\\n    \"/content/df.csv\",\\n    verbose = True,\\n    agent_type = AgentType.ZERO_SHOT_REACT_DESCRIPTION,\\n)\\n\\nagent.agent.llm_chain.prompt.template\\n\\nOutput:\\n\\nnYou are working with a pandas dataframe in Python. The name of the dataframe \\nis `df`.\\\\nYou should use the tools below to answer the question posed of you:\\n\\\\n\\\\npython_repl_ast: A Python shell. Use this to execute python commands. Input\\nshould be a valid python command. When using this tool, sometimes output is \\nabbreviated - make sure it does not look abbreviated before using it in your \\nanswer.\\\\n\\\\nUse the following format:\\\\n\\\\nQuestion: the input question you must \\nanswer\\\\nThought: you should always think about what to do\\\\nAction: the action \\nto take, should be one of [python_repl_ast]\\\\nAction Input: the input to the \\naction\\\\nObservation: the result of the action\\\\n... (this Thought/Action/Action \\nInput/Observation can repeat N times)\\\\nThought: I now know the final \\nanswer\\\\nFinal Answer: the final answer to the original input question\\\\n\\\\n\\\\nThis\\nis the result of `print(df.head())`:\\\\n{df_head}\\\\n\\\\nBegin!\\\\nQuestion: {input}\\\\n\\n{agent_scratchpad}\\n\\nCreating a CSV Agent:\\n\\nThe code is calling a function named create_csv_agent to create a CSV agent. This agent will interact with CSV (Comma-Separated Values) files, which are commonly used for storing tabular data.\\n\\nSpecifying OpenAI Configuration:\\n\\nThe OpenAI function is being used to configure the OpenAI model. In this case, it’s setting the temperature parameter to 0, which likely influences the randomness or creativity of the responses generated by the model.\\n\\nFile Path:\\n\\n\"/content/df.csv\": This specifies the file path where the CSV agent will operate. It seems like the agent will read from this file.\\n\\nVerbosity:\\n\\nverbose=True: This enables verbose mode, meaning the agent will provide more detailed output or logs during its operation. It’s helpful for debugging or understanding what the agent is doing.\\n\\nAgent Type:\\n\\nagent_type=AgentType.ZERO_SHOT_REACT_DESCRIPTION: This specifies the type of agent being created. In this case, it appears to be a zero-shot reaction description agent, which suggests that the agent generates descriptions or reactions based on the input data without any specific training for those tasks.\\n\\nAccessing Agent Properties:\\n\\nagent.agent.llm_chain.prompt.template: This accesses a property or attribute of the agent object. Specifically, it’s accessing the llm_chain attribute, which likely refers to some aspect of the language model chain used by the agent. Then, it’s accessing the prompt attribute and further accessing the template attribute within it.\\n\\n\\n\\nUsing the model\\n\\nLet\\'s test the model now by asking a few questions that can be useful for making financial decisions.\\n\\nagent.run(\"Which date has the highest dividend?\")\\n\\n\\n\\nagent.run(\"When is the best day to invest in the stock and why?\")\\n\\n\\n\\nFrom the output, the agent receives the task as input, and it initiates thought on knowing what is the task about. It moves on to the next action i.e. to execute a Python REPL command (which is to work interactively with the Python interpreter) that calculates the ratio of survived passengers to total passengers.\\n\\nThe pandas_dataframe_agent is more versatile and suitable for advanced data analysis tasks, while the csv_agent is more specialized for working with CSV files.\\n\\nConclusion\\n\\nThe amalgamation of advanced AI technologies with accessible data sources has ushered in a new era of data interaction and analysis. Retrieval-Augmented Generation (RAG), for instance, has emerged as a game-changer by seamlessly blending retrieval-based and generation-based approaches in natural language processing (NLP). This integration empowers systems to furnish precise and contextually relevant responses across a spectrum of applications, including question-answering, summarization, and dialogue generation.\\n\\nCentral to this ecosystem is the Financial Modeling Prep API, offering comprehensive access to financial data for analysis and modeling. By leveraging this API alongside RAG and LangChain, developers can construct powerful systems capable of extracting invaluable insights from financial data. This synergy enables sophisticated financial data analysis and modeling, propelling transformative advancements in AI-driven financial analysis and decision-making.\\n\\nWith that being said, you’ve reached the end of the article. Hope you learned something new and useful today. Thank you for your time.\\n\\nVisit us at DataDrivenInvestor.com\\n\\nSubscribe to DDIntel here.\\n\\nHave a unique story to share? Submit to DDIntel here.\\n\\nJoin our creator ecosystem here.\\n\\nDDIntel captures the more notable pieces from our main site and our popular DDI Medium publication. Check us out for more insightful work from our community.\\n\\nDDI Official Telegram Channel: https://t.me/+tafUp6ecEys4YjQ1\\n\\nFollow us on LinkedIn, Twitter, YouTube, and Facebook.'}},\n",
       "  {'id': 'ea2e2261fcbf',\n",
       "   'title': 'Stock Market Sentiment Prediction with OpenAI and Python',\n",
       "   'subtitle': 'An interesting exploration of the power of LLMs in stock analysis',\n",
       "   'author': 'e10ad955760c',\n",
       "   'publication_id': '5517fd7b58a6',\n",
       "   'published_at': '2024-02-04 18:46:05',\n",
       "   'last_modified_at': '2024-02-06 03:51:20',\n",
       "   'tags': ['programming',\n",
       "    'artificial-intelligence',\n",
       "    'technology',\n",
       "    'python',\n",
       "    'data-science'],\n",
       "   'topics': ['programming'],\n",
       "   'claps': 691,\n",
       "   'voters': 147,\n",
       "   'word_count': 2496,\n",
       "   'responses_count': 4,\n",
       "   'reading_time': 10.3688679245283,\n",
       "   'url': 'https://levelup.gitconnected.com/stock-market-sentiment-prediction-with-openai-and-python-ea2e2261fcbf',\n",
       "   'unique_slug': 'stock-market-sentiment-prediction-with-openai-and-python-ea2e2261fcbf',\n",
       "   'image_url': 'https://miro.medium.com/0*PDMtUUdUatJPSaZ_',\n",
       "   'lang': 'en',\n",
       "   'is_series': False,\n",
       "   'is_locked': False,\n",
       "   'is_shortform': False,\n",
       "   'top_highlight': '',\n",
       "   'content': {'id': 'ea2e2261fcbf',\n",
       "    'content': 'Stock Market Sentiment Prediction with OpenAI and Python\\n\\nAn interesting exploration of the power of LLMs in stock analysis\\n\\nPhoto by Levart_Photographer on Unsplash\\n\\nIn today’s stock market, staying informed about news and events is crucial for making strategic decisions. Recognizing the impact of sentiment on market trends is essential to adjust strategies accordingly. The process begins with accessing vast amounts of market news available through various sources. Foremost among these are the requirements for data quality (such as the number of sources, data update rate, etc.) and ease of use.\\n\\nAlthough the data is available online and easily accessible, one of the most convenient methods for our needs is to use an API endpoint to integrate market data and news directly into our code. There is a variety of financial data providers that offer API connections; they vary in the data packages, support approach, and quality of data they provide.\\n\\nIn this article, we are going to use the Stock Market and Financial News API provided by one of the Market Data providers named EODHD, which, in my opinion, boasts a great balance of quality and price. The API provides an endpoint for extracting insights from financial news, facilitating easy analysis of market sentiment. With its ease of use, users can query and retrieve news articles, enabling a dynamic assessment of the market’s positive or negative tones.\\n\\nBy showcasing the capabilities of the API, I aim to demonstrate its seamless integration into sentiment analysis, enabling us to make informed decisions based on prevailing market sentiments. In the fast-paced environment of the stock market, having access to such a resource ensures a more adaptive and strategic approach to investing.\\n\\nWithout further ado, let’s dive into the article.\\n\\nImporting Packages\\n\\nLet’s start with importing the required packages into our Python environment. We’ll be using three packages in this article which are pandas for working with dataframes, eodhd for extracting data, and langchain for building the LLM model. Apart from these, we will also be using other secondary packages like config and re. Import all the necessary packages using the following code:\\n\\n!pip install openai\\n!pip install langchain\\n!pip install eodhd\\n!pip install config\\n\\nimport re\\nimport requests\\nimport pandas as pd\\nimport config as cfg\\nfrom eodhd import APIClient\\nfrom langchain.chains import LLMChain\\nfrom langchain.prompts import PromptTemplate\\nfrom langchain.chat_models import ChatOpenAI\\n\\nBefore importing, make sure to install the packages using the command line. Now that we have all the required packages imported into our Python environment, we can proceed to the next step which is activating the API key.\\n\\nAPI Key Activation\\n\\nIt is essential to register the EODHD API key with the package in order to use its functions. If you don’t have an EODHD API key, firstly, head over to their website, then, finish the registration process to create an EODHD account, and finally, navigate to the ‘Settings’ page where you can find your secret EODHD API key. It is important to ensure that this secret API key is not revealed to anyone. You can activate the API key by following this code:\\n\\napi_key = \\'<YOUR API KEY>\\'\\napi = APIClient(api_key)\\n\\nThe code is pretty simple. In the first line, we are storing the secret EODHD API key into api_key, and then in the second line, we are using the APIClient class provided by the eodhd package to activate the API key and stored the response in the client variable.\\n\\nNote that you need to replace <YOUR API KEY> with your secret EODHD API key. Apart from directly storing the API key with text, there are other ways for better security such as utilizing environmental variables, and so on.\\n\\nExtracting the Data\\n\\nWe are going to use the Stock Market and Financial News API by accessing the Python library provided by EODHD as follows:\\n\\nresp = api.financial_news(s = \"AAPL.US\", from_date = \\'2024-01-01\\', to_date = \\'2024-01-30\\', limit = 100)\\ndf = pd.DataFrame(resp) # converting the json output into datframe\\ndf.tail()\\n\\nLet me explain the parameters in the API:\\n\\ns: String. REQUIRED if parameter ‘t’ is not set. The ticker code to get news for.\\n\\nt: String. REQUIRED if parameter ‘s’ is not set. The tag to get news on a given topic. you can find the provided topic list on this page: https://eodhd.com/financial-apis/stock-market-financial-news-api/\\n\\napi_token: String. REQUIRED. Your api_token to access the API. You will get it after registration.\\n\\nfrom and to: the format is ‘YYYY-MM-DD’. If you need data from Mar 1, 2021, to Mar 10, 2021, you should use from=2021–03–01 and to=2021–03–10.\\n\\nlimit: Number. OPTIONAL. The number of results should be returned with the query. Default value: 50, minimum value: 1, maximum value: 1000.\\n\\noffset: Number. OPTIONAL. The offset of the data. Default value: 0, minimum value: 0. For example, to get 100 symbols starting from 200 you should use limit=100 and offset=200.\\n\\nThe data would look like this:\\n\\nAAPL news data (Image by Author)\\n\\nThe output data has the following fields:\\n\\ndate: The date and time of the article are in ISO 8601 format.\\n\\ntitle: The title of the article.\\n\\ncontent: The full body of the article.\\n\\nlink: The link to the source.\\n\\nsymbols: The array of ticker symbols is mentioned in the article.\\n\\nCleaning the Data\\n\\nNow this data is unclean and contains lots of line breaks and different commands. So we are going to clean them:\\n\\n#funtion to clean the textual data\\ndef clean_text(text):\\n    cleaned_text = re.sub(r\\'\\\\s+\\', \\' \\', text)\\n    return cleaned_text.strip()\\n\\n# Apply the replacement function to the entire column\\ndf[\\'content\\'] = df[\\'content\\'].apply(clean_text)\\n\\nNow we have applied it to all the data and we can move forward with our chatbot.\\n\\nLLM\\n\\nNow we will use Langchain to form an LLM chain with the OpenAI model.\\n\\nllm = ChatOpenAI(model = \"gpt-3.5-turbo\",\\n                 openai_api_key = \\'YOUR OPENAI API KEY\\', \\n                 temperature = 0)\\n\\nNOTE: You should replace YOUR OPENAI API KEYwith your own OpenAI API key for the smooth functioning of the code without any errors.\\n\\nThis code snippet initializes the Language Model (LM) by instantiating GPT-2.5-turbo with a temperature of 0. The choice of temperature 0 ensures determinism in our model, preventing it from getting sidetracked and maintaining a focused and consistent generation.\\n\\nNow, we are going to use different techniques to make it precise for our downstream task i.e. Sentiment analysis. There are lots of different ways to do it:\\n\\n1) Prompt Engineering:\\n\\nPrompt engineering is a growing field that involves designing and optimizing prompts to maximize the performance of large language models like GPT. As these models advance, the way we prompt them becomes increasingly important. Recent research shows that well-crafted prompts can significantly improve reliability and enable models to tackle more complex tasks than previously believed.\\n\\nFollowing are some prompt engineering techniques that are commonly used:\\n\\nZero-shot prompting: This method enables large language models (LLMs) to handle new tasks even without prior examples or understanding of the task. It operates through a technique called ‘prompting,’ where you simply give the LLM a natural language description of the desired task.\\n\\nFew-shot prompting: While large-language models demonstrate remarkable zero-shot capabilities, they still fall short on more complex tasks when using the zero-shot setting. Few-shot prompting can be used as a technique to enable in-context learning where we provide demonstrations in the prompt to steer the model to better performance. The demonstrations serve as conditioning for subsequent examples where we would like the model to generate a response.\\n\\nChain of Thought Prompting: Chain of thought prompting is a helpful technique for AI systems to simplify complex tasks by breaking them down into manageable steps. Instead of tackling a challenging problem in one go, this method promotes explaining the reasoning process by breaking the solution into a series of smaller, incremental steps. It begins by clearly defining the end goal and then considers the logical prerequisites and sub-tasks required to reach that goal.\\n\\n2) Fine-tuning\\n\\nFine-tuning is a useful process that lets users tailor pre-trained language models (LLMs) for specific tasks. By fine-tuning a model on a small dataset containing task-specific data, you can enhance its performance for that particular task while keeping its overall language understanding intact.\\n\\nThe two main Fine-tuning Methods are as follows:\\n\\nFull instruction fine-tuning: Full instruction fine-tuning is a technique used to adapt Large Language Models (LLMs) to specific tasks. The process involves adjusting all parameters of the LLM using task-specific data. This adaptation allows the model to perform more effectively on specific tasks, potentially leading to improved performance. The need for full instruction fine-tuning arises because even the most powerful pre-trained LLM might not always meet specific needs right out of the box. For instance, an application might require a unique structure or style, or the pre-trained LLM might lack knowledge about specific documents crucial to the application. Furthermore, certain domains, industries, and even particular enterprises often have unique terminologies, concepts, and structures not prominently represented in the general pretraining data. Therefore, full instruction fine-tuning is a valuable method for tailoring LLMs to more specific use cases.\\n\\nParameter-efficient fine-tuning: Parameter-efficient fine-tuning (PEFT) is a technique used to adapt large pre-trained models to various downstream applications without fine-tuning all of a model’s parameters. This is because fine-tuning all parameters can be prohibitively costly. Instead, PEFT methods only fine-tune a small number of (extra) model parameters. This significantly decreases computational and storage costs while yielding performance comparable to a fully fine-tuned model. PEFT addresses issues such as the infeasibility of full fine-tuning on consumer hardware and the high cost of storing and deploying fine-tuned models independently for each downstream task. It also overcomes the problem of catastrophic forgetting, a behavior observed during the full fine-tuning of Large Language Models (LLMs).\\n\\nIn this instance, we will leverage prompt engineering techniques, utilizing the Langchain template functionality, to construct an optimized prompt for conducting sentiment analysis in the stock market. The objective is to create a prompt that not only provides sentiment Analysis but also offers explanations for the model’s inferences.\\n\\ntemplate = \"\"\"\\nIdentify the sentiment towards the Apple(AAPL) stocks from the news article , where the sentiment score should be from -10 to +10 where -10 being the most negative and +10 being the most positve , and 0 being neutral\\n\\nAlso give the proper explanation for your answers and how would it effect the prices of different stocks\\n\\nArticle : {statement}\\n\"\"\"\\n\\n#forming prompt using Langchain PromptTemplate functionality\\nprompt = PromptTemplate(template = template, input_variables = [\"statement\"])\\nllm_chain = LLMChain(prompt = prompt, llm = llm)\\n\\nNow that we’ve established the LLM chain, let me give you an example of its inference.\\n\\nRunning the LLM chain :\\n\\nprint(llm_chain.run(df[\\'content\\'][13]))\\n\\nThe output would look like this:\\n\\nAAPL sentiment prediction by the model (Image by Author)\\n\\nAnalysis\\n\\nNow to to analyze the market condition of AAPL (Apple) stocks let’s analyze 100 articles and draw some conclusions.\\n\\nSo, first, we have to make sure we don’t cross the token limit of our model, which is 4097 for me. So we will filter out articles with a number of tokes < 3500:\\n\\n#A function to count the number of tokens\\ndef count_tokens(text):\\n    tokens = text.split()  \\n    return len(tokens)\\n\\nCounting tokes for all the rows in a dataframe:\\n\\n# Applying the tokenization function to the DataFrame column\\ndf[\\'TokenCount\\'] = df[\\'content\\'].apply(count_tokens)\\n\\nFiltering the data frame according to TokenCount:\\n\\n# Define a token count threshold (for example, keep rows with more than 2 tokens)\\ntoken_count_threshold = 3500\\n\\n# Create a new DataFrame by filtering based on the token count\\nnew_df = df[df[\\'TokenCount\\'] < token_count_threshold]\\n\\n# Drop the \\'TokenCount\\' column from the new DataFrame if you don\\'t need it\\nnew_df = new_df.drop(\\'TokenCount\\', axis = 1)\\n\\n# Resetting the index\\nnew_df = new_df.reset_index(drop = True)\\n\\nNow, this time I would change my prompt template so that I would get a concise output:\\n\\ntemplate_2 = \"\"\"\\nIdentify the sentiment towards the Apple(AAPL) stocks of the news article from -10 to +10 where -10 being the most negative and +10 being the most positve , and 0 being neutral\\n\\nGIVE ANSWER IN ONLY ONE WORD AND THAT SHOULD BE THE SCORE\\n\\nArticle : {statement}\\n\"\"\"\\n\\n#forming prompt using Langchain PromptTemplate functionality\\nprompt_2 = PromptTemplate(template = template_2, input_variables = [\"statement\"])\\n\\nLet’s form the new LLM chain:\\n\\nllm_chain_2 = LLMChain(prompt = prompt_2, llm = llm)\\n\\nLet me demonstrate one inference here:\\n\\nprint(new_df[\\'content\\'][2])\\nprint(\\'\\')\\nprint(\\'News sentiment: \\', llm_chain_2.run(new_df[\\'content\\'][2]))\\n\\nUpdated model’s sentiment prediction (Image by Author)\\n\\nGreat, we are now able to get a concise output. Now, we are going to create a for-loop to iterate through the data and get the sentiment of each news:\\n\\nx = []\\nfor i in range(0,new_df.shape[0]):\\n    x.append(llm_chain_2.run(new_df[\\'content\\'][i]))\\n\\nVisualization\\n\\nNow let’s form some pie charts to see the market sentiment of AAPL stocks:\\n\\nimport matplotlib.pyplot as plt\\n\\ndt = pd.DataFrame(x) #Converting into Dataframe\\ncolumn_name = 0 # this is my column name you should change it according to your data\\nvalue_counts = dt[column_name].value_counts()\\n\\n# Plotting the pie chart\\nplt.pie(value_counts, labels = value_counts.index, autopct = \\'%1.1f%%\\', startangle = 140)\\nplt.title(f\\'Pie Chart\\')\\nplt.axis(\\'equal\\')  # Equal aspect ratio ensures that the pie is drawn as a circle.\\n\\n# Show the pie chart\\nplt.show()\\n\\nAAPL market sentiment (Image by Author)\\n\\nThe pie chart indicates that a significant number of articles were neutral. However, to ensure accuracy, we should filter our data and focus on analyzing only the non-neutral information.\\n\\nRemoving neutral values:\\n\\nvalue_to_remove = \\'0\\'\\n# Remove all rows where the specified value occurs in the column\\ndt_new = dt[dt[0] != value_to_remove]\\n\\nVisualizing the new data:\\n\\nvalue_counts = dt_new[column_name].value_counts()\\n\\n# Plotting the pie chart\\nplt.pie(value_counts, labels = value_counts.index, autopct = \\'%1.1f%%\\', startangle = 140)\\nplt.title(f\\'Pie Chart\\')\\nplt.axis(\\'equal\\')  # Equal aspect ratio ensures that the pie is drawn as a circle.\\n\\n# Show the pie chart\\nplt.show()\\n\\nAAPL market sentiment, excluding neutral values (Image by Author)\\n\\nObserving the trends, the combination of +5 and +7 contributes to nearly 40% of the data. Factoring in additional values like +10, +8, and +3, the cumulative percentage of positive articles rises to 52.5%. This pattern indicates a prevailing optimistic sentiment, implying a favorable perception of Apple Inc. in recent articles. The positive outlook identified may have potential implications for shaping overall sentiments regarding Apple’s market performance.\\n\\nConclusion\\n\\nIn our study, we employed the Stock Market Financial News API provided by EODHD to collect stock market news articles and utilized OpenAI’s sentiment analysis model to assess the sentiments conveyed in these articles.\\n\\nTo ensure seamless compatibility between our data and the OpenAI model, LangChain, a language processing tool, was utilized. To refine the inputs for the OpenAI model and improve the accuracy of our sentiment analysis, we implemented prompt engineering techniques. We conducted sentiment analysis on 100 articles to gauge the current market sentiment surrounding APPL stocks.\\n\\nThis holistic methodology enabled us to extract meaningful insights into market trends based on the sentiments expressed in the news. With that being said, you’ve reached the end of the article. Hope you learned something new and useful today. Thank you very much for your time.'}},\n",
       "  {'id': '54948a3da389',\n",
       "   'title': 'Stock Price Prediction with Quantum Machine Learning in Python',\n",
       "   'subtitle': 'An overview of the challenges and opportunities',\n",
       "   'author': 'e10ad955760c',\n",
       "   'publication_id': '32881626c9c9',\n",
       "   'published_at': '2024-01-23 05:41:09',\n",
       "   'last_modified_at': '2024-02-13 13:27:06',\n",
       "   'tags': ['machine-learning',\n",
       "    'data-science',\n",
       "    'programming',\n",
       "    'artificial-intelligence',\n",
       "    'python'],\n",
       "   'topics': ['machine-learning', 'programming'],\n",
       "   'claps': 1581,\n",
       "   'voters': 332,\n",
       "   'word_count': 3687,\n",
       "   'responses_count': 21,\n",
       "   'reading_time': 16.013207547169813,\n",
       "   'url': 'https://medium.datadriveninvestor.com/stock-price-prediction-with-quantum-machine-learning-in-python-54948a3da389',\n",
       "   'unique_slug': 'stock-price-prediction-with-quantum-machine-learning-in-python-54948a3da389',\n",
       "   'image_url': 'https://miro.medium.com/0*xGjBwo2cGCdAky8J',\n",
       "   'lang': 'en',\n",
       "   'is_series': False,\n",
       "   'is_locked': False,\n",
       "   'is_shortform': False,\n",
       "   'top_highlight': \"These quantum systems (particles or circuits) do some interesting things. They can be in different states at the same time (superposition), connect in a special way (entanglement), and even go through barriers they shouldn't (tunneling).\",\n",
       "   'content': {'id': '54948a3da389',\n",
       "    'content': 'Stock Price Prediction with Quantum Machine Learning in Python\\n\\nAn overview of the challenges and opportunities\\n\\nPhoto by Anton Maksimov 5642.su on Unsplash\\n\\nToday, we’re diving into the intersection of quantum computing and machine learning, exploring quantum machine learning. Our main goal is to compare the performance of a quantum neural network for stock price time series forecasting with a simple single-layer MLP.\\n\\nTo facilitate this project, we’ll be utilizing the Historical API endpoint offered by Financial Modeling Prep (FMP) for reliable and accurate data which is very critical. With that being said, let’s dive into the article.\\n\\nImporting the Data\\n\\nLet’s start by importing the necessary libraries for our analysis. These libraries will provide the basic tools required to explore and implement our project.\\n\\nimport numpy as np\\nimport pandas as pd\\nimport requests\\nimport json\\nimport tensorflow as tf\\nfrom sklearn.model_selection import train_test_split\\nfrom tensorflow.keras.models import Sequential\\nfrom tensorflow.keras.layers import Dense\\nfrom sklearn.metrics import mean_squared_error\\nfrom qiskit import QuantumCircuit\\nfrom qiskit.circuit.library import PauliFeatureMap\\nfrom qiskit.algorithms.optimizers import ADAM\\nfrom qiskit.circuit import Parameter\\nfrom qiskit.primitives import Sampler\\n\\nWe’ve set up our environment by installing the Qiskit library for working with quantum computing networks, along with other essential libraries. To extract the data, we’ll use the historical data API endpoint provided by Financial Modeling Prep.\\n\\nFMP’s historical data API offers a conveniently accessible endpoint, providing a diverse and extensive collection of historical stock data that proves invaluable at every step of our project. This resource enables us to access a wide range of financial information, enhancing the depth and accuracy of our analysis. Its user-friendly interface and comprehensive dataset contribute significantly to the success and efficiency of our research and implementation.\\n\\nNow we are going to extract historical data as follows:\\n\\napi_url = \"https://financialmodelingprep.com/api/v3/historical-price-full/AAPL?apikey=YOUR API KEY\"\\n\\n# Make a GET request to the API\\nresponse = requests.get(api_url)\\n\\n# Check if the request was successful (status code 200)\\nif response.status_code == 200:\\n    # Parse the response JSON\\n    data = response.json()\\nelse:\\n    print(f\"Error: Unable to fetch data. Status code: {response.status_code}\")\\n\\ndata\\n\\nReplace YOUR API KEYwith your secret API key which you can obtain by creating an FMP account. The output is a JSON response which looks as follows:\\n\\nHistorical Data API response\\n\\nIntroduction to quantum computing\\n\\nIn regular computers, we have tiny switches called \"digital gates.\" These switches control how information moves around. They work with basic units of data called \"bits,\" which can be either 0 or 1. The gates help computers do calculations and process stuff. Now, in quantum computers, we use something called \"qubits\" instead of bits. Qubits are special because they can be both 0 and 1 at the same time. It’s like having a coin that’s spinning and showing both heads and tails until you catch it, and then it picks one side.\\n\\nWhen we say the \"wave function collapses,\" it’s just a fancy way of saying the qubit decides to be either 0 or 1 when we check it. We make these qubits using different things like light particles (photons), tiny particles that make up stuff (atoms), or even small electrical circuits (Josephson junctions). These are like the building blocks for our special qubits.\\n\\nThese quantum systems (particles or circuits) do some interesting things. They can be in different states at the same time (superposition), connect in a special way (entanglement), and even go through barriers they shouldn’t (tunneling).\\n\\nWhat’s cool is that quantum computers, with their qubits and special behaviors, use certain algorithms to solve some problems faster than regular computers. It’s like having a new tool that might help us solve tough puzzles more efficiently in the future.\\n\\nOperators in Quantum Computing\\n\\nIn traditional computing, we perform operations using basic logic gates like AND, NOT, and OR. These gates work with 0s and 1s, and their rules are based on a simple mathematical system called:\\n\\n\\n\\nwhich essentially deals with counting modulo 2.\\n\\nNow, imagine a quantum computer - it also has gates, but these are like supercharged versions. Instead of dealing with simple bits, quantum gates work with quantum bits or qubits. The math behind these quantum gates involves complex numbers and Matrix operations.\\n\\nLet’s take the quantum NOT gate, called:\\n\\n\\n\\nas an example. Apply it to a qubit initially in the state ∣0⟩, and the operator flips it to ∣1⟩ , and if you apply it again, it goes back to ∣0⟩. It’s a bit like flipping a coin.\\n\\n\\n\\nThere’s also the Hadamard gate (H) that does something really cool. Applying it to a qubit initially in the state ∣0⟩ puts it in this special mix of 0 and 1 states at the same time to show mathematically H operates on |0⟩ and converts it into the standard superposition of the basis states:\\n\\n\\n\\nIt’s like having a coin spinning in the air, showing both heads and tails until it lands.\\n\\n\\n\\nNow, let’s talk about the Controlled-NOT (CNOT) gate. This one works on two qubits. If the first qubit is ∣1⟩, it flips the second qubit from ∣0⟩ to ∣1⟩ or vice versa. It’s like a quantum switch that depends on the state of the first qubit.\\n\\nIn the quantum world, things get more interesting. If you have two qubits in a special state, the CNOT gate uniquely rearranges their combinations, creating what we call entanglement. This entanglement is like a special connection between the qubits, making them behave in a coordinated manner.\\n\\n\\n\\nSo, in a nutshell, while regular computers use basic rules with 0s and 1s, quantum computers have these fascinating gates that play with probabilities, mix states, and create connections between qubits, opening up a world of possibilities for solving complex problems more efficiently.\\n\\nIn our project, we place special emphasis on a category of gates known as parameterized gates. These gates exhibit behavior that is contingent on specific input parameters, denoted by the symbol θ. Notably, we focus on rotation gates such as:\\n\\n\\n\\neach characterized by a unitary matrix as described in the below figure:\\n\\n\\n\\nLet’s delve a bit deeper into these rotation gates. Consider:\\n\\n\\n\\nenvision it as a quantum gate resembling a rotating door that allows for the rotation of a qubit by a specific angle θ. The\\n\\n\\n\\nand,\\n\\n\\n\\ngates function similarly, introducing rotations around different axes.\\n\\nThe significance of these gates lies in their parameterized nature. By adjusting the input parameter θ, we essentially introduce a customizable element into our quantum algorithms. These gates serve as the foundational components for constructing the quantum neural network integral to our Project.\\n\\nIn essence, θ acts as a tuning parameter, akin to a knob, enabling us to finely adjust and tailor the behavior of our quantum algorithms within the framework of the quantum neural network. This flexibility becomes pivotal in optimizing and customizing the performance of our quantum algorithms for specific tasks.\\n\\nQuantum Circuits\\n\\nQuantum algorithms can be thought of as a series of operations performed on a quantum state, represented by expressions like:\\n\\n\\n\\nThese algorithms are translated into quantum circuits, as illustrated in Figure below. In this depiction, the algorithm starts from the initial state |q_0 q_1⟩ = |00⟩ and concludes with a measurement resulting in either |00⟩ or |11⟩ with an equal probability of 0.5, recorded into classical bits (line c).\\n\\n\\n\\nIn a quantum circuit, each horizontal line corresponds to a single qubit, and gates are applied sequentially until measurement. It’s important to note that loops are not allowed in a quantum program. A specific type of quantum circuit is the Variational Quantum Circuit (VQC). Notably, VQC incorporates parameterized gates like the aforementioned R_x(θ), R_y(θ), R_z(θ).\\n\\nIn simpler terms, quantum algorithms are like step-by-step instructions for a quantum computer, and quantum circuits visually represent these steps. The Variational Quantum Circuit introduces a special kind of flexibility with parameterized gates, allowing for customization based on specific values, denoted by θ.\\n\\nQuantum Machine Learning\\n\\nThe primary objective of QML is to devise and deploy methods capable of running on quantum computers to address conventional supervised, unsupervised, and reinforcement learning tasks encountered in classical Machine Learning.\\n\\nWhat makes QML distinct is its utilization of quantum operations, leveraging unique features like superposition, tunneling, entanglement, and quantum parallelism inherent to Quantum Computing (QC). In our study, we specifically concentrate on Quantum Neural Network (QNN) design. A QNN serves as the quantum counterpart of a classical neural network.\\n\\nBreaking it down, each layer in a QNN is a Variational Quantum Circuit (VQC) comprising parameterized gates. These parameters act as the quantum equivalents of the weights in a classical neural network. Additionally, the QNN incorporates a mechanism to exchange information among existing qubits, resembling the connections between neurons in different layers of a classical network. Typically, this information exchange is achieved through entanglements, employing operators such as the CNOT gate.\\n\\n\\n\\nCreating a Quantum Machine Learning (QML) model typically involves several steps, as illustrated in Figure above. First, we load and preprocess the dataset on a classical CPU. Next, we use a quantum embedding technique to encode this classical data into quantum states on a Quantum Processing Unit (QPU) or quantum hardware. Once the classic data is represented in quantum states, the core model, implemented in the ansatz, is executed, and the results are measured using classical bits. Finally, if needed, we post-process these results on the CPU to obtain the expected model output. In our study, we follow this overall process to investigate the application of a Quantum Neural Network for time series forecasting.\\n\\nQuantum Neural Network\\n\\nA Quantum Neural Network (QNN) typically consists of three main layers:\\n\\n1. Input Layer: This layer transforms classical input data into a quantum state. It uses a parameterized variational circuit with rotation and controlled-rotation gates to prepare the desired quantum state for a given input. This step, known as quantum embedding, employs techniques like basis encoding, amplitude encoding, Hamiltonian encoding, or tensor product encoding.\\n\\n2. Ansatz Layer: The heart of the QNN, this layer contains a Variational Quantum Circuit, repeated L times to simulate L network layers classically. It’s responsible for processing and manipulating quantum information.\\n\\n3. Output Layer: This layer performs measurements on qubits, providing the final expected outcome.\\n\\nFor the input layer, we use a tensor product encoding technique. It involves a simple X-rotation gate for each qubit, where the gate parameter is set by scaling the classic data to the range [-π, π]. Although it’s a quick and straightforward encoding method (O(1) operations), it has limitations. The number of qubits needed scales linearly with the input classic data. To address this, we introduce learnable parameters for scaling and bias in the input data, enhancing the flexibility of the quantum embedding. In Figure 3, you can see an example of the input layer for a network with 3 qubits, where classic data features:\\n\\n\\n\\n, input scale parameters:\\n\\n\\n\\n, and bias parameters:\\n\\n\\n\\ncome into play.\\n\\nCreating quantum embeddings\\n\\nRegarding the ansatz, it’s interesting to note that, unlike classical neural networks, there isn’t a fixed set of quantum layer structures commonly found in the literature (such as fully connected or recurrent layers). The realm of possible gates for quantum information transfer between qubits is extensive, and the optimal organization of these gates for effective data transfer is an area that hasn’t been thoroughly explored yet.\\n\\nIn our Project, we adopt the Real Amplitudes ansatz, a choice inspired by its success in various domains like policy estimation for quantum reinforcement learning and classification. This ansatz initiates with full rotation X/Y/Z parameterized gates, akin to the quantum version of connection weights. It is then followed by a series of CNOT gates arranged in a ring structure to facilitate qubit information transfer. Figure 4 provides a visual representation of how this ansatz is implemented, serving as the quantum equivalent of a network layer for a 3-qubit network.\\n\\nTo break it down, a quantum network layer in our work involves a set of parameters totaling 3 times the number of qubits (3*n), where ’n’ represents the number of qubits in the quantum network.\\n\\nAnstaz circuit\\n\\nNow, let’s talk about the output layer, which is a critical part of our quantum model. In quantum computing, when we want to extract information from our quantum state, we often perform measurements using a chosen observable. One such commonly used observable is represented by the σ_z operator over the computational basis. To understand this, think of it as a way to extract information from our quantum state.\\n\\n\\n\\nThe network output is determined by calculating the expectation of this observable over our quantum state. This is expressed as ⟨ψ|σ_z|ψ⟩, where ⟨ψ| denotes the complex conjugate of |ψ⟩. The result falls within the range of [-1, 1].\\n\\nNo need to stress over those complex mathematical equations - our trusty library, Qiskit, has got it covered! Qiskit will handle all the intricate quantum calculations seamlessly, making the quantum computing process much more accessible for us. So, you can focus on exploring the quantum world without getting bogged down by the nitty-gritty math\\n\\nNow, to make our network output less sensitive to biases and scales inherent in the dataset, we introduce a final scale parameter and bias to be learned. This step adds a layer of adaptability to our model, allowing it to fine-tune and adjust the output based on the specific characteristics of our data. The entire model architecture is visually represented in the figure below.\\n\\n\\n\\nThe training of our proposed Quantum Neural Network (QNN) happens on a regular CPU using classical algorithms like the Adam optimizer. The CPU handles the gradient computation through traditional propagation rules, while on the Quantum Processing Unit (QPU), we calculate the gradient using the parameter-shift rule. It’s a bit like having a dual system where the CPU manages the main training, and the QPU comes into play for specific quantum computations.\\n\\nVisualize the training process pipeline in Figure 6, where θ¹ represents the scale/bias parameters in the input layer, θ² corresponds to the parameters of the layers containing the ansatz, and θ³ are the scale/bias parameters for the network outputs. This orchestration ensures a cohesive training approach, leveraging both classical and quantum computing resources.\\n\\n\\n\\nAs a Quantum Neural Network (QNN) operates as a feedforward model, our initial step involves defining a time horizon, denoted as T. To adapt the time series data for the QNN, we transform it into a tabular format. Here, the target is the time series value at time t, denoted as x(t), while the inputs encompass the values x(t-1), x(t-2), …, x(t-T). This restructuring facilitates the model’s understanding of the temporal relationships in the data, allowing it to make predictions based on past values.\\n\\nForming QNN with Qiskit\\n\\nExtracting data & Data Preprocessing\\n\\nFirst, we fetch the data using the historical Data API endpoint provided by Financial Modeling Prep as follows:\\n\\napi_url = \"https://financialmodelingprep.com/api/v3/historical-price-full/AAPL?apikey=YOUR API KEY\"\\n\\n# Make a GET request to the API\\nresponse = requests.get(api_url)\\n\\n# Check if the request was successful (status code 200)\\nif response.status_code == 200:\\n    # Parse the response JSON\\n    data = response.json()\\nelse:\\n    print(f\"Error: Unable to fetch data. Status code: {response.status_code}\")\\n\\ndf = pd.json_normalize(data, \\'historical\\', [\\'symbol\\']) #convert into a datframe\\ndf.tail()\\n\\nThe output is a Pandas dataframe which looks something like this (before that, make sure to replace YOUR API KEY with your secret API key):\\n\\nAAPL Historical Data\\n\\nFrom this plethora of data, we are going to use open price as our temporal variable and we will work with 500 data points each representing daily open prices, and our window size for prediction would be 2.\\n\\nfinal_data = df[[\\'open\\', \\'date\\']][0:500] #forming filtered dataframe\\ninput_sequences = []\\nlabels = []\\n\\n#Creating input and output data for time series forecasting\\nfor i in range(len(final_data[\\'open\\'])):\\n    if i > 1:\\n        labels.append(final_data[\\'open\\'][i])\\n        input_sequences.append(final_data[\\'open\\'][i-2:i+1].tolist())\\n        \\n#creating train test split\\nx_train = np.array(input_sequences[0:400])\\nx_test = np.array(input_sequences[400:])\\ny_train = np.array(labels[0:400])\\ny_test = np.array(labels[400:])\\n\\nNow, let’s plot the data we acquired.\\n\\nimport matplotlib.pyplot as plt\\nplt.style.use(\\'ggplot\\')\\n\\n# Convert the \\'date\\' column to datetime format\\ndf[\\'date\\'] = pd.to_datetime(df[\\'date\\'])\\n\\n# Plotting the time series data\\nplt.figure(figsize=(10, 6))\\nplt.plot(df[\\'date\\'][0:500], df[\\'open\\'][0:500], marker=\\'o\\', linestyle=\\'-\\')\\n\\n# Adding labels and title\\nplt.xlabel(\\'date\\')\\nplt.ylabel(\\'open\\')\\nplt.title(\\'Time Series Data\\')\\n\\n# Display the plot\\nplt.grid(True)\\nplt.show()\\n\\nFollowing is the output:\\n\\nAAPL Historical Data Graph\\n\\nQuantum Neural Network\\n\\nPauli Feature Map:\\n\\nnum_features =  2\\nfeature_map = PauliFeatureMap(feature_dimension = num_features, reps = 2)\\noptimizer = ADAM(maxiter = 100)\\n\\nIn our approach, we employ the Pauli Feature Map to encode our data into qubits, specifically leveraging 2 features. The encoding circuit is structured as follows:\\n\\n\\n\\nFurthermore, for optimizing our model, we utilize the ADAM optimizer. This choice helps fine-tune the parameters of the quantum neural network, enhancing its overall performance.\\n\\nQuantum Circuit:\\n\\ndef ans(n, depth):\\n    qc = QuantumCircuit(n)\\n    for j in range(depth):\\n        for i in range(n):\\n            param_name = f\\'theta_{j}_{i}\\'\\n            theta_param = Parameter(param_name)\\n            qc.rx(theta_param, i)\\n            qc.ry(theta_param, i)\\n            qc.rz(theta_param, i)\\n    for i in range(n):\\n        if i == n-1:\\n            qc.cnot(i, 0)\\n        else:\\n            qc.cnot(i, i+1)\\n    return qc\\n\\nThis function initializes a quantum circuit with the number of qubits equal to the number of features. In the first loop, it appends rotation gates to the circuit, each with parameterized rotational angles. The second loop adds CNOT gates to the circuit. For each iteration, a CNOT gate is appended with the current qubit as the control (0th qubit) and the target qubit determined by the loop index. Additionally, another CNOT gate is appended with the current qubit as the control and the next qubit as the target.\\n\\nThis process constructs the ansatz for our quantum circuit, essentially creating the quantum neural network structure we defined earlier. The diagram for this circuit has been presented previously for reference.\\n\\nInitializing the Anstaz circuit:\\n\\nansatz = ans(num_features, 5) #anstaz(num_qubits=num_features, reps=5)\\n\\n#creating train test split\\nx_train = np.array(input_sequences[0:400])\\nx_test = np.array(input_sequences[400:])\\ny_train = np.array(labels[0:400])\\ny_test = np.array(labels[400:])\\n\\nNow, we proceed to create a Variational Quantum Circuit (VQC) that functions as a neural network. In this circuit, we incorporate both the ansatz, which defines the structure of our quantum neural network, and the encoding for our features. For this purpose, we import the VQC module from qiskit_machine_learning.classifiers. The VQC encapsulates the quantum processing aspects of our neural network, and its integration with Qiskit simplifies the implementation of quantum machine learning algorithms.\\n\\nVQC:\\n\\nvqr = VQR(\\n    feature_map = feature_map,\\n    ansatz = ansatz,\\n    optimizer = optimizer,\\n)\\n\\nvqr.fit(x_train,y_train)\\nvqr_mse = mean_squared_error(y_test, vqr.predict(x_test))\\n\\n# Calculate root mean squared error\\nvqr_rmse = np.sqrt(vqr_mse)\\n\\nIn the final step, we fit the Variational Quantum Circuit (VQC) to our features. This involves training the quantum neural network on our dataset. Once fitted, we assess the performance by calculating the mean and root mean errors. This evaluation step helps us gauge the accuracy and effectiveness of our Variational Quantum Circuit in handling the given features and predicting outcomes.\\n\\nClassical neural network\\n\\nNow, let’s construct a straightforward classical neural network to serve as a benchmark for comparison with the quantum neural network. Our chosen architecture will be a simple Multilayer Perceptron (MLP) featuring a single hidden layer equipped with 64 nodes. This classical neural network will provide us with a reference point against which we can evaluate the performance of the quantum neural network.\\n\\nClassical ANN:\\n\\nmodel = Sequential()\\nmodel.add(Dense(64,activation = \\'relu\\', input_shape = (4,)))\\nmodel.add(Dense(1))\\n\\nmodel.compile(optimizer = \\'adam\\', loss = \\'mean_squared_error\\')\\n\\nmodel.fit(x_train, y_train, epochs = 20, batch_size = 32, validation_data = (x_test,y_test))\\n\\nloss = model.evaluate(x_test, y_test)\\nprediction = model.predict(x_test)\\n\\nann_mse = mean_squared_error(y_test, prediction.flatten())\\nann_rmse = np.sqrt(ann_mse)\\n\\nResult and Comparison\\n\\nThe following are the results:\\n1)QNN: < 3.5 RMSE\\n2)ANN: > 3.6 RMSE\\n\\nIn this evaluation, it is evident that the Quantum Neural Network (QNN) has shown promise by outperforming the Artificial Neural Network (ANN). Nevertheless, it’s crucial to acknowledge that the Root Mean Squared Error (RMSE) values obtained may fall short of meeting the desired level of satisfaction. The primary objective of this experiment was to spotlight the potential of quantum computing, showcasing its ability to generate superior results and construct models applicable for commercial use.\\n\\nThis study anticipates that as quantum computers continue to advance, attaining a heightened level of robustness for effectively training these models, the technology will progressively become more practical for real-world applications in the near future.\\n\\nBuilding upon these findings, it becomes evident that Quantum Neural Networks (QNN) hold promise for further development and practical implementation. While current benchmarks in time series forecasting may currently outshine QNN, there exists significant potential for improvement. Addressing the current limitations is foreseeable, especially with ongoing advancements in quantum computing. Successfully developing robust quantum computers could unlock the door to achieving even more superior results in the realm of time series forecasting.\\n\\nNOTE: I’ve presented a basic demonstration of both a Quantum Neural Network (QNN) and a Classical Neural Network (CNN) to illustrate their construction and highlight differences in outcomes. It’s important to note that discrepancies may arise in QNN, so feel free to adapt the provided examples to better suit your specific use case. Adjust the code and parameters accordingly to optimize performance and address any challenges that may arise in the implementation of Quantum Neural Networks for your particular application.\\n\\nConclusion\\n\\nIn summary, this project explored quantum computing and the creation of neural networks, highlighting their potential for future growth. As technology advances, there is an opportunity to develop more sophisticated quantum machine learning algorithms with quantum computers. These systems can significantly reduce training times, benefitting from the efficiency of qubits and enabling the use of a greater number of qubits in circuit formation. This progress opens doors to enhanced computational power and problem-solving capabilities, indicating a promising path for the future of quantum computing in machine learning applications.\\n\\nWith that being said, you’ve reached the end of the article. Hope you learned something new and useful today. Also, let me know in the comments about your take on Quantum Machine Learning and its impact on the stock market sector. Thank you for your time.\\n\\nVisit us at DataDrivenInvestor.com\\n\\nSubscribe to DDIntel here.\\n\\nHave a unique story to share? Submit to DDIntel here.\\n\\nJoin our creator ecosystem here.\\n\\nDDIntel captures the more notable pieces from our main site and our popular DDI Medium publication. Check us out for more insightful work from our community.\\n\\nDDI Official Telegram Channel: https://t.me/+tafUp6ecEys4YjQ1\\n\\nFollow us on LinkedIn, Twitter, YouTube, and Facebook.'}},\n",
       "  {'id': '750d5520b20b',\n",
       "   'title': 'Use ChatGPT to get All-Time views on your Medium Stories',\n",
       "   'subtitle': \"An untold secret to get what Medium doesn't provide to its authors\",\n",
       "   'author': 'e10ad955760c',\n",
       "   'publication_id': '5517fd7b58a6',\n",
       "   'published_at': '2024-01-23 04:00:48',\n",
       "   'last_modified_at': '2024-01-23 04:00:48',\n",
       "   'tags': ['data-science',\n",
       "    'artificial-intelligence',\n",
       "    'chatgpt',\n",
       "    'medium',\n",
       "    'blogging'],\n",
       "   'topics': ['programming'],\n",
       "   'claps': 210,\n",
       "   'voters': 12,\n",
       "   'word_count': 957,\n",
       "   'responses_count': 1,\n",
       "   'reading_time': 4.311320754716981,\n",
       "   'url': 'https://levelup.gitconnected.com/use-chatgpt-to-get-all-time-views-on-your-medium-stories-750d5520b20b',\n",
       "   'unique_slug': 'use-chatgpt-to-get-all-time-views-on-your-medium-stories-750d5520b20b',\n",
       "   'image_url': 'https://miro.medium.com/0*-LgsPM4boW7h0zGE',\n",
       "   'lang': 'en',\n",
       "   'is_series': False,\n",
       "   'is_locked': False,\n",
       "   'is_shortform': False,\n",
       "   'top_highlight': '',\n",
       "   'content': {'id': '750d5520b20b',\n",
       "    'content': 'Use ChatGPT to get All-Time views on your Medium Stories\\n\\nAn untold secret to get what Medium doesn\\'t provide to its authors\\n\\nPhoto by Markus Winkler on Unsplash\\n\\nMedium is one of the greatest websites on the internet and it has given me numerous opportunities to both grow my career and myself. Its ad-free policy is awe-inspiring and in today’s world where views are focused more than anything else, Medium’s \"content first, views second\" mission is a light of hope for a lot of aspiring writers.\\n\\nBut that being said, Medium’s stats page sucks. Yeah, I just said it out loud and everyone knows that too but it has never been raised as a major concern. We, writers, deserve a lot more stats to understand our audience than what Medium is providing. Medium revised its stats page recently to incorporate more advanced stats but personally, I think it’s not enough. So I decided to take things on my own.\\n\\nStarting Point\\n\\nI work with a lot of clients for technical content writing and one of my clients asked about the stats of my Medium stories. Since it’s not possible to articulate the stats of each story, I gave my client some approximates along with some explanations on how Medium works and its distribution system (which in reality is more complicated than the Pyramid of Giza).\\n\\nHowever, my client demanded more in-depth stats. Though I justified myself that Medium provides only so many stats, the client wanted to know at least the overall views on my Medium articles. I started scratching my head to find a good solution.\\n\\nI started with some Chrome extensions but boy did they load forever. Every extension was the same. It would keep on loading just to show nothing. At this point, I was really frustrated but out of the blue, I was struck with an idea, \"a special idea\". And that is ChatGPT.\\n\\nChatGPT to the rescue\\n\\nNow enough with the stories and let’s get into action.\\n\\nFirst, head over to the Medium stats page: https://medium.com/me/stats\\n\\nNow, scroll down till the end of the page where it stops loading further content. Medium has this system called \"infinite-scrolling\" which loads content as you drag down the page. In order to get the all-time views, you need to load the views of all your Medium stories, and to ensure this, drag down the page till it stops loading.\\n\\nThis next step is the most important one. You have to copy the stats from the page exactly as shown in the below video (don’t worry, it’s easy):\\n\\nHow to copy stats from Medium (Video by Author)\\n\\nCopy the text and head over to ChatGPT. Inside ChatGPT, create a new chat and name it whatever you want. From my experience, naming each and every chat can be a huge time-saver, so, follow a naming convention or go with meaningful names for each and every chat and you will definitely thank me later for that.\\n\\nInside this new chat that you’ve just created, paste what you’ve copied from the Medium stats page and add this message at the end of the prompt:\\n\\nall these are taken from the stats page of Medium.com. here the views number is below each\"view story\" i want you to sum up all the views number\\n\\nI want you to copy and paste the exact text into the message. For even more clarity, it would look something like this in ChatGPT:\\n\\nYes, some of my articles had such low views\\n\\nLet me explain this prompt. This is the structure of each story stat which we just copied:\\n\\nBragging about my most-viewed article\\n\\nIt starts with the publishing date of the article, followed by the title of the article. After a line space comes the duration of the article, again the publishing date, and \"View story\". Finally, after another line space, the first figure is the number of views and the second is the reads.\\n\\nThis structure follows throughout each and every article and there is a pattern that can be exploited. The number of views always comes after the \"View story\" at all places. So we’re telling ChatGPT to extract the figure that comes right after \"View Story\" and sum all the extracted numbers. Pretty simple, right?!\\n\\nAt first, I thought ChatGPT would blabber some non-related stuff as it always does but its response was very interesting and it looked something like this:\\n\\nChatGPT’s insane addition method\\n\\nIt started adding all the numbers as it was extracting simultaneously and I swear it was so cool to see doing it live.\\n\\nAfter a few seconds, it popped out the all-time views by saying The sum of all the \"Views\" numbers is {secret} . I would love to reveal the number but I’m keeping it as a mystery. But I’ll definitely share when you guys reveal your stats number in the comments by following this same method.\\n\\nFinal Thoughts\\n\\nChatGPT is such a great application but nowadays people drown in the \"money-making\" realm of ChatGPT and we tend to look past its creative applications.\\n\\nThe mechanism behind ChatGPT is so powerful and it’s only getting better and better but I think we’re restricting ourselves to a certain extent by asking it about money-making methods, finishing code, writing articles, etc. ChatGPT is created to replicate humans who are all about creativity and innovation but definitely not a money bot.\\n\\nSo let’s hit a pause button to the \"ChatGPT side hustle\" culture and I suggest we simply play the intricacies of ChatGPT to explore true creative abilities.\\n\\nWith that being said, you’ve reached the end of the article. I know the conclusion is a bit too dramatic but I’ve been wanting to share this message for a while and I couldn\\'t find a better chance. Hope you learning something new today and thank you very much for your time.'}},\n",
       "  {'id': 'e50392d5e7f3',\n",
       "   'title': 'Implementing a Forex Hedging Strategy with Python',\n",
       "   'subtitle': 'A step-by-step guide to creating a risk-averse portfolio',\n",
       "   'author': 'e10ad955760c',\n",
       "   'publication_id': '32881626c9c9',\n",
       "   'published_at': '2024-01-14 06:06:59',\n",
       "   'last_modified_at': '2024-02-05 16:31:54',\n",
       "   'tags': ['finance', 'data-science', 'python', 'programming', 'technology'],\n",
       "   'topics': ['data-science', 'programming'],\n",
       "   'claps': 157,\n",
       "   'voters': 31,\n",
       "   'word_count': 2943,\n",
       "   'responses_count': 6,\n",
       "   'reading_time': 12.905660377358492,\n",
       "   'url': 'https://medium.datadriveninvestor.com/implementing-a-forex-hedging-strategy-with-python-e50392d5e7f3',\n",
       "   'unique_slug': 'implementing-a-forex-hedging-strategy-with-python-e50392d5e7f3',\n",
       "   'image_url': 'https://miro.medium.com/0*kPeEbruJtv9UxubJ',\n",
       "   'lang': 'en',\n",
       "   'is_series': False,\n",
       "   'is_locked': False,\n",
       "   'is_shortform': False,\n",
       "   'top_highlight': '',\n",
       "   'content': {'id': 'e50392d5e7f3',\n",
       "    'content': 'Implementing a Forex Hedging Strategy with Python\\n\\nA step-by-step guide to creating a risk-averse portfolio\\n\\nPhoto by Viktor Forgacs on Unsplash\\n\\nToday, we’re delving into the practical side of Forex trading, aiming to create a solid hedging strategy. To navigate this financial landscape effectively, we’ll be relying on the TraderMade Forex API, a user-friendly tool that grants us easy access to a diverse range of market data.\\n\\nThis API becomes our window into the dynamic world of currency pairs, enabling us to visualize trends, analyze price movements, and ultimately craft a robust hedging approach. Join us as we explore the synergy between forex trading, hedging strategies, and the invaluable insights provided by TraderMade Forex API endpoints.\\n\\nImporting the Data\\n\\nTo kick off our processes, we’ll initiate data extraction through TraderMade Forex API endpoints. Given the inherent volatility of the forex market, we’ll avoid extensive timeframes like a year or two. Our approach is to start with more granular data - specifically, Daily data for initial testing, followed by hourly data for subsequent analysis. This allows us to capture nuances and make informed decisions without losing sight of crucial details.\\n\\nHere, I’m making use of the TradeMade Python SDK, a remarkably helpful tool that not only eases the data extraction process but also makes it exceptionally user-friendly for a seamless experience in our operations.\\n\\nNow, let’s start by importing the necessary libraries required:\\n\\nimport tradermade as tm\\nimport pandas as pd\\nimport numpy as np\\nimport seaborn as sns\\nimport matplotlib.pyplot as plt\\n\\nNext, our objective is to systematically extract the closing prices of the G10 USD-quoted pairs, facilitating a comprehensive analysis of correlations among these major currency pairs. Data for AUDUSD, CADUSD, EURUSD, JPYUSD, NZDUSD, NOKUSD, GBPUSD, SEKUSD, and CHFUSD for both 1-month on a daily basis and 1-day on an hourly basis time frames will be extracted.\\n\\ntm.set_rest_api_key(\"YOUR API KEY\") #Setting up the REST API token (Replace YOUR API KEY with your secret API key)\\n\\ndf_month = tm.timeseries(currency=\\'AUDUSD,CADUSD,EURUSD,JPYUSD,NZDUSD,NOKUSD,GBPUSD,SEKUSD,CHFUSD\\',start=\"2023-11-10\",end=\"2023-12-10\",interval=\"daily\",fields=[\"close\"])\\ndf_day = tm.timeseries(currency=\\'AUDUSD,CADUSD,EURUSD,JPYUSD,NZDUSD,NOKUSD,GBPUSD,SEKUSD,CHFUSD\\',start=\"2023-12-13-00:00\",end=\"2023-12-14-00:00\",interval=\"hourly\",fields=[\"close\"])\\n\\nTo initiate data extraction, begin by configuring the REST API token (Replace YOUR API KEY with your secret API key). Utilizing the time series data endpoints, input the desired currencies, start and end date and time, preferred interval (daily, hourly, minute), and the selected field (open, high, low, close). Subsequently, storing the monthly and weekly datasets in distinct data frames named df_month and df_day. The resulting data extracted will appear as follows:\\n\\nMonth data:\\n\\nImage by Author\\n\\nDay Data:\\n\\nImage by Author\\n\\nUnderstanding Hedging in Forex Trading\\n\\nIn Forex Trading, hedging is a tactic to safeguard your position in a currency pair from unexpected shifts. It’s a short-term move often used when there’s concern about news or an event causing turbulence in currency markets.\\n\\nWhen it comes to hedging forex pairs, there are three main strategies followed:\\n\\n1. Direct hedging Strategy:\\n\\nA direct hedging strategy in Forex involves simultaneously initiating both a buy and sell position for the same currency pair, providing a means to mitigate potential risks by offsetting market exposure. This approach allows traders to navigate market fluctuations more effectively through a balanced position in the selected currency pair.\\n\\n2. Correlation hedging strategy:\\n\\nUtilizing the correlation between currency pairs is a widely adopted Forex hedging strategy, allowing traders to navigate market volatility by simultaneously trading highly positively or negatively correlated pairs for effective risk mitigation.\\n\\n3. Options Hedging Strategy:\\n\\nEngaging in options trading serves as an alternative method to hedge trading risks, offering a less intricate approach compared to concurrently managing long and short positions in specific currency pairs. Options, as contractual instruments, grant traders the right, without obligation, to buy or sell currency at a predetermined rate on or before a specified future date, typically characterized by expiration dates.\\n\\nHere, we’re diving into the Correlation hedging strategy. The approach involves selecting the optimal basket (commonly used to denote pairs of currency pairs) by assessing the correlation between them. Our focus is on identifying pairs that exhibit a notably positive correlation - where movements positively impact each other - hence opening opposite positions for the currency pairs in the basket. Subsequently, employing the hedging ratio, we’ll analyze the most effective way to construct our hedging portfolio.\\n\\nYou might be wondering about the concept of the hedging ratio. Let me break it down for you.\\n\\nHedging Ratio\\n\\nThe hedge ratio is essentially the proportion or comparative value of a hedge in relation to the overall position. It serves as a crucial risk management metric, providing insights into the potential risk associated with movements in the hedging instrument.\\n\\n\\n\\nAnother significant factor in hedging is the optimal hedge ratio, also known as the minimum variance hedge ratio. This ratio plays a crucial role in investment risk management, indicating the percentage of a hedging instrument - be it an asset or liability - that an investor should use for effective hedging. The optimal hedge ratio is particularly relevant in cross-hedging scenarios, where there might not be a perfect match between the hedging instrument and the asset being hedged. It helps minimize variance and optimize risk management strategies in the dynamic landscape of financial markets.\\n\\n\\n\\nWhere:\\n\\nρ = The correlation coefficient of the changes in the spot and futures prices\\n\\nσs = Standard deviation of changes in the spot price ‘s’\\n\\nσp = Standard deviation of changes in the futures price ‘f’\\n\\nExpanding on this concept to suit our needs, we apply a formula for the hedging factor in a pair of currency pairs X and Y:\\n\\n\\n\\nThis formula helps us determine the hedging factor, offering insights into the relationship between the two currency pairs and aiding in the construction of an effective hedging portfolio.\\n\\nIdentifying Correlated Pairs\\n\\nNow, in the process of selecting our optimal basket of currency pairs, we’ll start by creating a correlation heatmap. This visual representation allows us to identify pairs with the most negative correlation, laying the foundation for our hedging strategy.\\n\\nCorrelation heatmap for Month Data\\n\\ncorrelation_matrix_month = df_month.corr()\\n\\n# Create a heatmap using seaborn\\nplt.figure(figsize=(12, 10))\\nsns.heatmap(correlation_matrix_month, annot=True, cmap=\\'coolwarm\\', fmt=\".2f\", linewidths=.5)\\nplt.title(\\'Correlation Matrix of Forex Codes\\')\\nplt.show()\\n\\nImage by Author\\n\\nCorrelation heatmap for Day Data\\n\\ncorrelation_matrix_day = df_day.corr()\\n\\n# Create the day Data heatmap using seaborn\\nplt.figure(figsize=(12, 10))\\nsns.heatmap(correlation_matrix_day, annot=True, cmap=\\'coolwarm\\', fmt=\".2f\", linewidths=.5)\\nplt.title(\\'Correlation Matrix of Forex Codes\\')\\nplt.show()\\n\\nImage by Author\\n\\nLooking at the data, we’ve identified two separate groups of currency pairs - one for daily data for a month and another for hourly data. This highlights the inherent volatility of the forex market, where the relationships between currency pairs constantly shift, impacting our hedging strategies in different ways.\\n\\nNow let\\'s identify the most positively correlated pairs for month and day data:\\n\\nFor Monthly data:\\n\\nstacked_corr = correlation_matrix_month.stack()\\nfiltered_corr = stacked_corr[stacked_corr < 1]\\nsorted_corr = filtered_corr.sort_values(ascending=False)\\nsorted_corr\\n\\nImage by Author\\n\\nHence through Monthly Data analysis, we choose NZDUSD and CHFUSD as our basket with a correlation equal to 0.97 (most positively correlated basket)\\n\\nFor Day data:\\n\\nstacked_corr_day = correlation_matrix_day.stack()\\nfiltered_corr_day = stacked_corr_day[stacked_corr_day < 1]\\nsorted_corr_day = filtered_corr_day.sort_values(ascending=False)\\nsorted_corr_day\\n\\nImage by Author\\n\\nHence through Day Data analysis, we choose SEKUSD and EURUSD as our basket with a correlation equal to 0.99 (most positively correlated basket)\\n\\nVisualizations\\n\\nNow that we have identified our basket of currency pairs for both daily and hourly data, let’s enhance our understanding by creating visualizations.\\n\\nNow, to visualize the daily return values, we need to calculate the daily returns for each individual currency pair as follows:\\n\\n# Daily Returns for Month Data\\n\\ndf_month_CHFUSD = tm.timeseries(currency=\\'CHFUSD\\', start=\"2023-11-10\", end=\"2023-12-10\", interval=\"daily\", fields=[\"open\", \"high\", \"low\", \"close\"])  # Fetching Month Data for CHFUSD\\ndf_month_CHFUSD[\\'Daily_Return\\'] = ((df_month_CHFUSD[\\'close\\'] - df_month_CHFUSD[\\'open\\']) / df_month_CHFUSD[\\'open\\']) * 100  # Creating Daily Return Value for CHFUSD\\ndf_month_NZDUSD = tm.timeseries(currency=\\'NZDUSD\\', start=\"2023-11-10\", end=\"2023-12-10\", interval=\"daily\", fields=[\"open\", \"high\", \"low\", \"close\"])  # Fetching Month Data for NZDUSD\\ndf_month_NZDUSD[\\'Daily_Return\\'] = ((df_month_NZDUSD[\\'close\\'] - df_month_NZDUSD[\\'open\\']) / df_month_NZDUSD[\\'open\\']) * 100  # Creating Daily Return Value for NZDUSD\\n\\n# Daily Returns for Day Data\\n\\ndf_day_SEKUSD = tm.timeseries(currency=\\'SEKUSD\\', start=\"2023-12-13-00:00\", end=\"2023-12-14-00:00\", interval=\"hourly\", fields=[\"open\", \"high\", \"low\", \"close\"])  # Fetching day Data for SEKUSD\\ndf_day_SEKUSD[\\'Daily_Return\\'] = ((df_day_SEKUSD[\\'close\\'] - df_day_SEKUSD[\\'open\\']) / df_day_SEKUSD[\\'open\\']) * 100  # Creating hourly Return Value for SEKUSD\\ndf_day_EURUSD = tm.timeseries(currency=\\'EURUSD\\', start=\"2023-12-13-00:00\", end=\"2023-12-14-00:00\", interval=\"hourly\", fields=[\"open\", \"high\", \"low\", \"close\"])  # Fetching day Data for EURUSD\\ndf_day_EURUSD[\\'Daily_Return\\'] = ((df_day_EURUSD[\\'close\\'] - df_day_EURUSD[\\'open\\']) / df_day_EURUSD[\\'open\\']) * 100  # Creating hourly Return Value for EURUSD\\ndf_day_CHFUSD = tm.timeseries(currency=\\'CHFUSD\\', start=\"2023-12-13-00:00\", end=\"2023-12-14-00:00\", interval=\"hourly\", fields=[\"open\", \"high\", \"low\", \"close\"])  # Fetching day Data for CHFUSD\\ndf_day_CHFUSD[\\'Daily_Return\\'] = ((df_day_CHFUSD[\\'close\\'] - df_day_CHFUSD[\\'open\\']) / df_day_CHFUSD[\\'open\\']) * 100  # Creating hourly Return Value for CHFUSD\\ndf_day_NZDUSD = tm.timeseries(currency=\\'NZDUSD\\', start=\"2023-12-13-00:00\", end=\"2023-12-14-00:00\", interval=\"hourly\", fields=[\"open\", \"high\", \"low\", \"close\"])  # Fetching day Data for NZDUSD\\ndf_day_NZDUSD[\\'Daily_Return\\'] = ((df_day_NZDUSD[\\'close\\'] - df_day_NZDUSD[\\'open\\']) / df_day_NZDUSD[\\'open\\']) * 100  # Creating hourly Return Value for NZDUSD\\n\\n1. Comparison of Daily Returns of CHFUSD & NZDUSD on a monthly timeframe\\n\\nplt.figure(figsize=(10, 6))\\nplt.style.use(\\'ggplot\\')\\n\\nplt.plot(df_month_CHFUSD[\\'date\\'], df_month_CHFUSD[\\'Daily_Return\\'], label=\\'CHFUSD\\', marker=\\'o\\')\\nplt.plot(df_month_CHFUSD[\\'date\\'], df_month_NZDUSD[\\'Daily_Return\\'], label=\\'NZDUSD\\', marker=\\'o\\')\\n\\nplt.title(\\'CHFUSD/NZDUSD Returns Comparison\\')\\nplt.xlabel(\\'Date\\')\\nplt.ylabel(\\'Returns\\')\\nplt.legend()\\nplt.xticks(rotation = 50)\\nplt.grid(True)\\nplt.show()\\n\\nImage by Author\\n\\nExamining the visual representation, a clear pattern emerges: when one currency pair experiences an upward movement, the other tends to move in the opposite direction, underscoring our negative correlation. This observable inverse relationship is crucial for our hedging strategy, as movements in one pair act as a counterbalance to the other within our selected basket. Similarly, let’s visualize the data for the 1-day timeframe.\\n\\n2. Comparison of Hourly Returns of SEKUSD & EURUSD on a 1-day timeframe\\n\\nplt.figure(figsize=(10, 6))\\nplt.style.use(\\'ggplot\\')\\n\\nplt.plot(df_day_SEKUSD[\\'date\\'], df_day_SEKUSD[\\'Daily_Return\\'], label=\\'SEKUSD\\', marker=\\'o\\')\\nplt.plot(df_day_SEKUSD[\\'date\\'], df_day_EURUSD[\\'Daily_Return\\'], label=\\'EURUSD\\', marker=\\'o\\')\\n\\nplt.title(\\'SEKUSD/EURUSD Returns Comparison\\')\\nplt.xlabel(\\'Hour\\')\\nplt.ylabel(\\'Returns\\')\\nplt.legend()\\nplt.xticks(rotation = 50)\\nplt.grid(True)\\nplt.show()\\n\\nImage by Author\\n\\n3. Comparison of Hourly Returns of CHFUSD & NZDUSD on a 1-day timeframe\\n\\nplt.figure(figsize=(10, 6))\\nplt.style.use(\\'ggplot\\')\\n\\nplt.plot(df_day_CHFUSD[\\'date\\'], df_day_CHFUSD[\\'Daily_Return\\'], label=\\'CHFUSD\\', marker=\\'o\\')\\nplt.plot(df_day_CHFUSD[\\'date\\'], df_day_NZDUSD[\\'Daily_Return\\'], label=\\'NZDUSD\\', marker=\\'o\\')\\n\\nplt.title(\\'CHFUSD/NZDUSD Returns Comparison\\')\\nplt.xlabel(\\'Hour\\')\\nplt.ylabel(\\'Returns\\')\\nplt.legend()  \\nplt.xticks(rotation = 50) \\nplt.grid(True)\\nplt.show()\\n\\nImage by Author\\n\\nComparing the visualizations of the hourly data for CHFUSD & NZDUSD and SEKUSD & EURUSD, it’s apparent that they share a high degree of similarity. However, based on the correlation data, a more significant positive correlation is between SEKUSD & EURUSD at the hourly level. Therefore, we will opt for SEKUSD & EURUSD for our hourly analysis.\\n\\nUtilizing Hedge Ratios for Constructing Effective Hedge Profiles\\n\\nIn the initiation of forming hedging profiles, a pivotal metric comes into play - the hedge ratio. This metric not only illuminates the trend that the hedge is following but also provides a critical ratio guiding our investment decisions. The hedge ratio acts as a quantitative indicator, offering insights into the optimal allocation for effective risk management. By understanding and leveraging this metric, traders can make informed decisions on how to allocate their investments in alignment with market trends and potential risks.\\n\\nNow, to compute hedge ratios, we’ll need to calculate both the correlation and standard deviation. Let’s streamline the process by combining these calculations into a single function, as outlined below:\\n\\nHedge Ratio Function\\n\\ndef calculate_hedging_ratio(df1, df2):\\n    \\n    # Merge the two DataFrames on the \\'date\\' column\\n    merged_df = pd.merge(df1[[\\'date\\', \\'Daily_Return\\']], df2[[\\'date\\', \\'Daily_Return\\']], on=\\'date\\', suffixes=(\\'_1\\', \\'_2\\'))\\n\\n    # Calculate the correlation coefficient between the returns of the two currency pairs\\n    correlation = merged_df[\\'Daily_Return_1\\'].corr(merged_df[\\'Daily_Return_2\\'])\\n\\n    # Calculate the hedging ratio\\n    hedging_ratio = - correlation * (df1[\\'Daily_Return\\'].std() /    df2[\\'Daily_Return\\'].std())\\n    \\n    print(f\"Correlation between the two currency pairs: {correlation}\")\\n    print(f\"Hedging Ratio: {hedging_ratio}\")\\n\\n#Calling the function to get the results\\n\\ncalculate_hedging_ratio(df_month_CHFUSD,df_month_NZDUSD) #for daily data\\ncalculate_hedging_ratio(df_day_SEKUSD,df_day_EURUSD) #for hourly data\\n\\nThe results obtained for the ‘calculate_hedging_ratio’ function are as follows:\\n\\n1. Hourly data:\\n\\nImage by Author\\n\\n2. Daily data:\\n\\nImage by Author\\n\\nNow that we have the hedging ratio values, let’s begin creating hedging profiles.\\n\\nThe initial phase in creating a hedging profile entails the assignment of weights to each individual currency pair within a basket based on the corresponding hedging ratio\\n\\nAssigning Weights to individual currency pairs\\n\\n# For Daily Data\\nhedging_ratio_CHFUSD_NZDUSD = 0.5203035958912856\\n\\n# Calculate weights based on hedging ratio\\nweights_CHFUSD_NZDUSD = {\\'CHFUSD\\': 1 / (1 + abs(hedging_ratio_CHFUSD_NZDUSD)),\\n                         \\'NZDUSD\\': abs(hedging_ratio_CHFUSD_NZDUSD) / (1 + abs(hedging_ratio_CHFUSD_NZDUSD))}\\n#For Hourly Data\\nhedging_ratio_SEKUSD_EURUSD = 1.4597042985219284\\n\\n# Calculate weights based on the hedging ratio\\nweights_SEKUSD_EURUSD = {\\'SEKUSD\\': 1 / (1 + abs(hedging_ratio_SEKUSD_EURUSD)),\\n                         \\'EURUSD\\': abs(hedging_ratio_SEKUSD_EURUSD) / (1 + abs(hedging_ratio_SEKUSD_EURUSD))}\\n\\nNow, with the weights duly assigned, constructing a hedging profile becomes a straightforward process. The resulting profile would appear as follows:\\n\\nImage by Author\\n\\nEvaluation\\n\\nWe will assess the daily portfolio based on the data of the next day, while the hourly portfolio will be evaluated on the very next hour. To facilitate this, we will export new data using the historical data endpoints of the TraderMade Forex API, which provides a wealth of diverse historical data.\\n\\nImporting New Day Data\\n\\n# For Daily Data\\ndf_next_day = tm.historical(currency=\\'CHFUSD,NZDUSD\\', date=\"2023-12-11\", interval=\"daily\", fields=[\"open\", \"high\", \"low\", \"close\"])  # Fetching new Day data\\ndf_next_day[\\'Daily_Return\\'] = ((df_next_day[\\'close\\'] - df_next_day[\\'open\\']) / df_next_day[\\'open\\']) * 100  # Calculating Daily Return\\n\\n# For Hourly Data\\ndf_next_hour_SEKUSD = tm.timeseries(currency=\\'SEKUSD\\', start=\"2023-12-14-00:05\", end=\"2023-12-14-01:00\", interval=\"hourly\", fields=[\"open\", \"high\", \"low\", \"close\"])  # Fetching Hourly Data for SEKUSD\\ndf_next_hour_SEKUSD[\\'Hourly_Return\\'] = ((df_next_hour_SEKUSD[\\'close\\'] - df_next_hour_SEKUSD[\\'open\\']) / df_next_hour_SEKUSD[\\'open\\']) * 100  # Calculating Hourly Return for SEKUSD\\ndf_next_hour_EURUSD = tm.timeseries(currency=\\'EURUSD\\', start=\"2023-12-14-00:05\", end=\"2023-12-14-01:00\", interval=\"hourly\", fields=[\"open\", \"high\", \"low\", \"close\"])  # Fetching Hourly Data for EURUSD\\ndf_next_hour_EURUSD[\\'Hourly_Return\\'] = ((df_next_hour_EURUSD[\\'close\\'] - df_next_hour_EURUSD[\\'open\\']) / df_next_hour_EURUSD[\\'open\\']) * 100  # Calculating Hourly Return for EURUSD\\n\\nNow, let’s evaluate the portfolio return for the upcoming day/hour based on the previously formulated portfolio:\\n\\n# Calculate next hour portfolio return\\nportfolio_return_next_hour = weights_SEKUSD_EURUSD[\\'SEKUSD\\'] * df_next_hour_SEKUSD[\\'Hourly_Return\\'].item() + weights_SEKUSD_EURUSD[\\'EURUSD\\'] * df_next_hour_EURUSD[\\'Hourly_Return\\'].item()\\n\\n# Calculate next day portfolio return\\nportfolio_return_next_day = weights_CHFUSD_NZDUSD[\\'CHFUSD\\'] * df_next_day.loc[df_next_day[\\'instrument\\'] == \\'CHFUSD\\', \\'Daily_Return\\'].values[0] + weights_CHFUSD_NZDUSD[\\'NZDUSD\\'] * df_next_day.loc[df_next_day[\\'instrument\\'] == \\'NZDUSD\\', \\'Daily_Return\\'].values[0]\\n\\nSubsequently, we assess the final output using a metric known as total return. The total return is a metric that reflects the overall percentage change in the value of an investment, encompassing both capital appreciation and income like dividends. A positive total return indicates a gain, while a negative one signals a loss. In addition, annualized returns provide a standardized measure on an annual basis, considering the compounding effect of gains or losses over time. These metrics are essential for assessing the comprehensive performance of a portfolio or investment strategy, offering insights into both short-term gains and long-term compounding effects.\\n\\n\\n\\ndef calculate_and_print_total_return(starting_portfolio_value, portfolio_return_next_day):\\n    ending_portfolio_value = starting_portfolio_value * (1 + portfolio_return_next_day / 100)\\n    total_return = (ending_portfolio_value - starting_portfolio_value) / starting_portfolio_value * 100\\n    print(f\"Total Return: {total_return:.2f}%\")\\n\\n# Calling the ‘calculate_and_print_total_return’ function\\ncalculate_and_print_total_return(1, portfolio_return_next_day)# For Daily Data \\ncalculate_and_print_total_return(1, portfolio_return_next_hour)# For Hourly Data\\ntrading_days_in_year_daily = 252  #assuming 252 trading days in a year\\ntrading_hours_per_day_hourly = 8  # Assuming 8 trading hours per day\\n\\n# Calculate annualized total return for daily data\\nannualized_total_return_daily = ((1 + total_return_daily / 100) ** (trading_days_in_year_daily / 1)) - 1\\nprint(f\"Annualized Total Return (Daily Data): {annualized_total_return_daily * 100:.2f}%\")\\n\\n# Calculate annualized total return for hourly data\\nannualized_total_return_hourly = ((1 + total_return_hourly / 100) ** (trading_days_in_year_hourly * trading_hours_per_day_hourly / 1)) - 1\\nprint(f\"Annualized Total Return (Hourly Data): {annualized_total_return_hourly * 100:.2f}%\")\\n\\nAfter applying the total return function to both our portfolios, the resulting outcomes are as follows:\\n\\n1. Profile based on daily Data:\\n\\n\\n\\nImages by Author\\n\\n2. Profile based on hourly Data:\\n\\n\\n\\nImages by Author\\n\\nIn this analysis, the impact of data granularity on trading outcomes is evident. The portfolio based on daily data generated a profit of 0.19%, emphasizing the effectiveness of a strategic approach capturing longer-term trends. In contrast, the one formulated using hourly data yielded a smaller profit of 0.03%, reflecting the trade-off between accuracy and responsiveness in forex trading strategies. The Annualized Total Return for the daily data portfolio was 61.63%, while the hourly data portfolio showed a higher Annualized Total Return of 70.07%. This reinforces the importance of carefully balancing historical data noise and real-time responsiveness for optimal decision-making in forex trading.\\n\\nNOTE:\\n\\nThis project utilizes basic and clear-cut definitions to showcase the application of various financial tools, including the hedging ratio. It is crafted for instructional purposes, placing emphasis on fundamental concepts. It is imperative to acknowledge that, in real-world scenarios, the inclusion of transaction costs can substantially impact overall profitability. The outcomes shared in this project are derived solely from the model and algorithm. Users are encouraged to customize and refine the methodology to align with their unique requirements and environmental factors. It’s essential to recognize that actual profits, accounting for transaction costs, may deviate from the simplified representations presented in this project. Furthermore, alternative and modified equations for the hedge ratio exist, and the one employed here is intentionally basic for clarity; users are encouraged to adapt it based on their specific context.\\n\\nConclusion\\n\\nIn conclusion, we devised a forex trading strategy employing two types of data - 1) daily and 2) hourly. This strategy involved calculating correlations to identify the optimal currency pair basket, followed by determining the hedging ratio. Utilizing the obtained hedging ratio, we constructed two portfolios and evaluated their performance.\\n\\nThe key takeaway from our analysis is the substantial impact of data granularity on trading outcomes, with the daily data approach yielding a higher profit (0.19%) compared to the hourly strategy (0.03%), emphasizing the importance of selecting an appropriate time frame for more effective decision-making in forex trading.\\n\\nThroughout this process, the TraderMade Forex API proved instrumental, offering an easily accessible SDK and diverse datasets that significantly facilitated the workflow.\\n\\nWith that being said, you’ve reached the end of the article. Hope you learned something new and useful today. Thank you very much for your time.\\n\\nVisit us at DataDrivenInvestor.com\\n\\nSubscribe to DDIntel here.\\n\\nHave a unique story to share? Submit to DDIntel here.\\n\\nJoin our creator ecosystem here.\\n\\nDDIntel captures the more notable pieces from our main site and our popular DDI Medium publication. Check us out for more insightful work from our community.\\n\\nDDI Official Telegram Channel: https://t.me/+tafUp6ecEys4YjQ1\\n\\nFollow us on LinkedIn, Twitter, YouTube, and Facebook.'}},\n",
       "  {'id': '4a80d94a7851',\n",
       "   'title': 'How to use Deep Learning for Real-Time Trading Decisions',\n",
       "   'subtitle': 'A hands-on guide to building a deep learning model with Python and APIs',\n",
       "   'author': 'e10ad955760c',\n",
       "   'publication_id': '5517fd7b58a6',\n",
       "   'published_at': '2024-01-09 16:01:00',\n",
       "   'last_modified_at': '2024-02-05 05:21:53',\n",
       "   'tags': ['technology',\n",
       "    'artificial-intelligence',\n",
       "    'data-science',\n",
       "    'python',\n",
       "    'programming'],\n",
       "   'topics': ['machine-learning', 'data-science'],\n",
       "   'claps': 514,\n",
       "   'voters': 111,\n",
       "   'word_count': 2891,\n",
       "   'responses_count': 5,\n",
       "   'reading_time': 11.959433962264152,\n",
       "   'url': 'https://levelup.gitconnected.com/how-to-use-deep-learning-for-real-time-trading-decisions-4a80d94a7851',\n",
       "   'unique_slug': 'how-to-use-deep-learning-for-real-time-trading-decisions-4a80d94a7851',\n",
       "   'image_url': 'https://miro.medium.com/0*1j53jWdN1Yh1UPwj',\n",
       "   'lang': 'en',\n",
       "   'is_series': False,\n",
       "   'is_locked': False,\n",
       "   'is_shortform': False,\n",
       "   'top_highlight': '',\n",
       "   'content': {'id': '4a80d94a7851',\n",
       "    'content': 'How to use Deep Learning for Real-Time Trading Decisions\\n\\nA hands-on guide to building a deep learning model with Python and APIs\\n\\nPhoto by Sajad Nori on Unsplash\\n\\nToday, we’re delving into real-time trading using Q-learning, a model-free reinforcement learning algorithm. This approach empowers an agent to discern optimal actions within a given environment by iteratively adjusting Q-values in response to observed rewards.\\n\\nTo facilitate this exploration, we’ll leverage Intrinio’s Nasdaq Basic API, a valuable resource providing real-time data for our analysis and decision-making processes in the dynamic realm of financial markets.\\n\\nSetting up an Account & Acquiring Data\\n\\nBefore heading to start coding in Python, it is essential to first have an Intrinio account and then purchase the Nasdaq Basic API endpoints. Firstly, to create an account, head over to Intrinio’s homepage and select the Sign Up button on the top-right corner which leads you to the user registration page.\\n\\nIntrinio’s Sign-up page (Image by Author)\\n\\nAfter creating an account, you can purchase the API endpoints from this product page which contains all the details about the real-time stock data that comes with the API: https://intrinio.com/financial-market-data/nasdaq-basic\\n\\nIntrinio Nasdaq Basic Product details (Image by Author)\\n\\nNow that you have an Intrinio account which allows you to have your own API keys (vital for extracting data) and ownership of the Nasdaq Basic API for real-time stock data, we can now proceed to coding in Python and get our hands dirty.\\n\\nImporting Packages & Extracting Data\\n\\nLet’s start by importing the necessary libraries for our analysis. These libraries will provide the basic tools required to explore and implement our trading strategy. To extract the data, we’ll use Intrinio’s Python SDK, making the process straightforward and efficient.\\n\\nBut before moving further, let’s gain some background about Intrinio’s Nasdaq Basic API. The Nasdaq Basic API, facilitated by Intrinio, allows for efficient extraction of financial data in just a few lines of code. Its user-friendly interface provides flexibility, enabling us to customize its utilization according to our specific needs. Additionally, the API furnishes diverse and accurate information, offering a wide array of options for analysis and application.\\n\\nThe following code imports the necessary packages and extracts the data of Apple stock:\\n\\n!pip install intrinio-sdk\\n\\nimport intrinio_sdk as intrinio\\nimport numpy as np\\nimport pandas as pd\\nimport time\\n\\nintrinio.ApiClient().set_api_key(\\'YOUR API KEY\\') #setting up the API key\\n#NOTE : Replace YOUR API KEY with you actual API key\\n\\nidentifier = \\'AAPL\\' # Setting up the identifier\\nsource = \\'nasdaq_basic\\' # Setting up the source\\n\\nresponse = intrinio.SecurityApi().get_security_realtime_price(identifier, source=source) # Extracting the data\\nprint(response)\\n\\nTo retrieve the data, start by installing the Intrinio Python SDK with a straightforward pip command. After installation, set your API key for authorization. Next, input the identifier (e.g., AAPL) and the data source (in this case, nasdaq_basic). With just one line of code, you’ll receive the desired response. It’s a streamlined process, making data extraction quick and simple.\\n\\nThe output will look like this :\\n\\nIntrinio Nasdaq Basic JSON Response (Image by Author)\\n\\nNow, let’s step back to focus on understanding the Q-learning algorithm. After that, we’ll return to our data extraction process and identify the key features we need from the data.\\n\\nQ - learning\\n\\nReinforcement Learning (RL) is a subfield of machine learning dedicated to training agents to make decisions through iterative interactions with an environment. In the RL paradigm, agents navigate an environment by taking actions and subsequently receiving feedback in the form of rewards or penalties. This feedback guides the agent’s learning process, enabling it to develop a strategy that aims to maximize the cumulative reward over time. Q-learning is a specific type of reinforcement learning method that plays a crucial role in this process, helping agents optimize their decision-making strategies based on the environmental feedback received during the exploration and exploitation phases.\\n\\nQ-learning stands out as a model-free reinforcement learning algorithm designed to empower an agent in learning optimal actions within a given environment. Through an iterative process, Q-learning updates Q-values, which serve as representations of the anticipated cumulative rewards linked to taking a particular action in a specific state. This method enables the agent to refine its decision-making strategy over time, honing in on the actions that yield the most favorable outcomes based on the learned Q-values. Now, let’s break down the key components of Q-learning.\\n\\nQ-Table:\\n\\nAt the core of Q-learning, the Q-table assumes a pivotal role. This matrix features rows corresponding to diverse actions and columns corresponding to various states or environmental features. The Q-values within this table serve as the agent’s estimates for the expected cumulative rewards associated with taking a specific action in a particular state.\\n\\n\\n\\nExploration vs. Exploitation:\\n\\nAn inherent challenge in reinforcement learning lies in striking a balance between exploration and exploitation. The agent must explore novel actions to uncover potentially superior strategies while exploiting familiar actions to maximize immediate rewards. The exploration probability plays a pivotal role in mitigating this challenge. At each decision point, the agent faces a choice: either delve into unexplored actions with a certain probability or leverage its existing knowledge by selecting the action linked to the highest Q-value. This probability parameter allows the agent to balance between curiosity-driven exploration and knowledge-driven exploitation intelligently.\\n\\nWhen the exploration probability is high, the agent is more likely to opt for random actions, fostering a broad exploration of the environment. This is crucial for discovering potentially superior strategies or navigating unfamiliar scenarios. On the other hand, when the exploration probability is low, the agent tends to exploit its existing knowledge, focusing on actions that have historically yielded higher rewards.\\n\\nEffectively managing the exploration-exploitation trade-off is essential for the long-term success of reinforcement learning algorithms. Q-learning, with its incorporation of a dynamic exploration probability, exemplifies a strategy that enables agents to learn and adapt to their environments over time, achieving a fine-tuned balance between exploration and exploitation.\\n\\nLearning Rate (α) and Discount Factor (γ):\\n\\nThe learning rate (α) plays a pivotal role in determining how extensively the agent adjusts its Q-values based on newfound information. A higher learning rate places more emphasis on recent experiences in shaping the agent’s decisions.\\n\\nMeanwhile, the discount factor (γ) modulates the significance of future rewards. A lower discount factor prompts the agent to prioritize short-term rewards, while a higher discount factor encourages thoughtful consideration of long-term rewards in the decision-making process.\\n\\nUpdating the Q-value:\\n\\nThe process of updating the Q-value function in Q-Learning is a crucial step in reinforcing the learning algorithm. The Q-values represent the expected cumulative rewards for taking a specific action in a particular state. The update is performed using a mathematical equation that accounts for the current Q-value, the immediate reward received, and the maximum Q-value for the next state. This equation iteratively refines the Q-values through the learning process, helping the agent make more informed decisions over time. Essentially, the update aims to balance the immediate rewards with the expected future rewards, guiding the agent to learn optimal strategies for navigating its environment.\\n\\n\\n\\nLet’s delve deeper into each step of the Q-learning algorithm.\\n\\nBuilding the Q-Learning Algorithm\\n\\nStep-1: Initialization:\\n\\nAt the outset, the Q-table is initialized with zeros. The Q-table is a matrix where each row corresponds to a different action, and each column corresponds to different states or features of the environment. The values in the Q-table represent the agent’s estimations of the expected cumulative rewards for taking a specific action in a specific state. Initialization sets the groundwork for the learning process to begin.\\n\\nCreating a Qlearning Trader class and defining the Q-table:\\n\\nclass QLearningTrader:\\n\\n    def __init__(self, num_actions, num_features, learning_rate, discount_factor, exploration_prob):\\n        self.num_actions = num_actions\\n        self.num_features = num_features\\n        self.learning_rate = learning_rate\\n        self.discount_factor = discount_factor\\n        self.exploration_prob = exploration_prob\\n\\n        # Initialize Q-table with zeros\\n        self.q_table = np.zeros((num_actions, num_features))\\n\\n        # Initialize state and action\\n        self.current_state = None\\n        self.current_action = None\\n\\nStep-2: Action Selection:\\n\\nThe agent faces a crucial decision in choosing an action. This decision is influenced by the exploration-exploitation trade-off. With a certain probability, the agent may decide to explore new actions, selecting one at random. Alternatively, it may opt to exploit its existing knowledge by choosing the action associated with the highest Q-value. This step reflects the delicate balance between trying out new possibilities and leveraging what the agent has already learned.\\n\\nCreating a function for choosing an action based on Exploration-Exploitation Trade-Off:\\n\\ndef choose_action(self, state):\\n\\n        # Exploration-exploitation trade-off\\n        if np.random.uniform(0, 1) < self.exploration_prob:\\n            return np.random.choice(self.num_actions)  # Explore\\n        else:\\n            feature_index = np.argmax(state)\\n            return np.argmax(self.q_table[:, feature_index])  # Exploit\\n\\nStep-3: Observation and Reward:\\n\\nThe chosen action is executed in the environment. The agent then observes the resulting state and receives a reward from the environment. This step represents the interaction between the agent and its surroundings, where the consequences of the chosen action become apparent.\\n\\nReward Function:\\n\\ndef calculate_reward(action, current_close, next_close):\\n\\n    if action == 0:  # Buy\\n        return 1.0 if next_close > current_close else -1.0\\n    elif action == 1:  # Sell\\n        return 1.0 if next_close < current_close else -1.0\\n    else:  # Hold\\n        return 1.0 if next_close > current_close else -1.0 if next_close < current_close else 0.0\\n\\nThe ‘calculate_reward’ function determines the reward associated with a specific trading action in a Q-learning framework for real-time trading.\\n\\nIf the action is to buy (action == 0), the function assigns a positive reward of 1.0 if the next closing price is higher, indicating a profitable decision, and -1.0 if it is lower, signaling a loss.\\n\\nSimilarly, for a sell action (action == 1), a positive reward is assigned for a successful short position (next closing price lower) and a negative reward for an unsuccessful one.\\n\\nIn the case of holding (action != 0 and action != 1), the function evaluates whether the next closing price is higher, lower, or equal to the current closing price, assigning rewards of 1.0, -1.0, or 0.0, respectively, reflecting the outcome of holding the position.\\n\\nFunction to extract Real-time Data:\\n\\ndef fetch_real_time_data(identifier):\\n\\n    source = \\'nasdaq_basic\\'\\n    response = intrinio.SecurityApi().get_security_realtime_price(identifier, source=source)\\n\\n    return {\\n        \\'open\\': response.open_price,\\n        \\'high\\': response.high_price,\\n        \\'low\\': response.low_price,\\n        \\'close\\': response.last_price,\\n        \\'volume\\': response.last_size\\n    }\\n\\nWe will be selecting the top five crucial features: 1) open price, 2) high price, 3) low price, 4) last price, and 5) last price.\\n\\nFunction to extract Current real-time and next state:\\n\\ndef observe_real_time_data(self,identifier):\\n  # Fetch real-time data\\n  real_time_data = fetch_real_time_data(identifier)\\n\\n  # Extract features from real-time data\\n  self.current_state = np.array([real_time_data[\\'open\\'], real_time_data[\\'high\\'],real_time_data[\\'low\\'], real_time_data[\\'close\\'],real_time_data[\\'volume\\']])\\n\\ndef observe_next_state(self,identifier):\\n  # Update the current state with the observed next state\\n  self.current_state = fetch_real_time_data(identifier)\\n\\nStep-4: Update Q-Values:\\n\\nBuilding on the observed reward, the Q-value for the current state-action pair is updated. The new Q-value is a combination of the agent’s existing knowledge (current Q-value) and the new information gained (reward and the expected future rewards). This step is crucial for the Q-table to adapt and refine its estimations over time. The Q-value is updated according to the following function:\\n\\ndef take_action(self, action, reward):\\n\\n  # Update Q-table based on the observed reward\\n  if self.current_action is not None:\\n    feature_index = np.argmax(self.current_state)\\n    current_q_value = self.q_table[self.current_action, feature_index]\\n    new_q_value = (1 - self.learning_rate) * current_q_value + self.learning_rate * (reward + self.discount_factor *np.max(self.q_table[:, feature_index]))\\n    self.q_table[self.current_action, feature_index] = new_q_value\\n\\n  # Update current state and action\\n  self.current_state = None\\n  self.current_action = action\\n\\nStep-5: Iteration:\\n\\nThe agent goes through a repeated process, moving to the next state, making choices, and adjusting Q-values. This loop continues until it reaches a predetermined number of iterations. Once done, the algorithm generates an output based on the current Q-table, showing the learned values for effective decision-making in the environment. We also create a function to calculate profit or loss based on actions and formulate a final function to give suggestions and the resulting profit.\\n\\nProfit-Loss Function:\\n\\ndef calculate_profit_loss(initial_balance, suggested_action, current_close, next_close, quantity):\\n\\n    if suggested_action == \"Buy\":\\n        return (next_close - current_close) * quantity\\n    elif suggested_action == \"Sell\":\\n        return (current_close - next_close) * quantity\\n    else:  # Hold\\n        return 0.0\\n\\nIteration Function:\\n\\ndef calculate_final_profit(identifier, initial_balance, quantity, num_iterations, learning_rate, discount_factor, exploration_prob):\\n    num_actions = 3\\n    num_features = 5\\n    q_trader = QLearningTrader(num_actions, num_features, learning_rate, discount_factor, exploration_prob)\\n\\n    for i in range(num_iterations):\\n        q_trader.observe_real_time_data(identifier)\\n\\n        action = q_trader.choose_action(q_trader.current_state)\\n        current_close = q_trader.current_state[3]\\n\\n        time.sleep(1)  # Introduce a delay before fetching the next real-time data\\n\\n        q_trader.observe_next_state(identifier)\\n        next_close = q_trader.current_state[\\'close\\']\\n\\n        reward = calculate_reward(action, current_close, next_close)\\n        q_trader.take_action(action, reward)\\n\\n    # Fetch real-time data just after the last iteration\\n    final_real_time_data = fetch_real_time_data(identifier)\\n\\n    # Get the final suggested action based on the last state in the Q-table\\n    final_suggested_action = [\"Buy\", \"Sell\", \"Hold\"][np.argmax(q_trader.q_table[:, np.argmax(q_trader.current_state)])]\\n\\n    # Calculate profit based on the final suggested action\\n    final_profit = calculate_profit_loss(initial_balance, final_suggested_action, current_close, final_real_time_data[\\'close\\'], quantity)\\n\\n    print(f\"Final Suggested Action: {final_suggested_action}, Final Profit: {final_profit}\")\\n\\nThrough these steps, the Q-learning algorithm continuously improves its grasp of the environment, allowing the agent to make more knowledgeable decisions as time progresses. The balance between exploration and exploitation, along with ongoing updates to the Q-table, lays the groundwork for the algorithm’s learning process.\\n\\nPutting it all together\\n\\nNow combining all the functions developed till now we get:\\n\\nclass QLearningTrader:\\n    def __init__(self, num_actions, num_features, learning_rate, discount_factor, exploration_prob):\\n        self.num_actions = num_actions\\n        self.num_features = num_features\\n        self.learning_rate = learning_rate\\n        self.discount_factor = discount_factor\\n        self.exploration_prob = exploration_prob\\n\\n        # Initialize Q-table with zeros\\n        self.q_table = np.zeros((num_actions, num_features))\\n\\n        # Initialize state and action\\n        self.current_state = None\\n        self.current_action = None\\n\\n\\n    def choose_action(self, state):\\n        # Exploration-exploitation trade-off\\n        if np.random.uniform(0, 1) < self.exploration_prob:\\n            return np.random.choice(self.num_actions)  # Explore\\n        else:\\n            feature_index = np.argmax(state)\\n            return np.argmax(self.q_table[:, feature_index])  # Exploit\\n\\n\\n    def take_action(self, action, reward):\\n        # Update Q-table based on the observed reward\\n        if self.current_action is not None:\\n            feature_index = np.argmax(self.current_state)\\n            current_q_value = self.q_table[self.current_action, feature_index]\\n            new_q_value = (1 - self.learning_rate) * current_q_value + \\\\\\n                           self.learning_rate * (reward + self.discount_factor * np.max(self.q_table[:, feature_index]))\\n            self.q_table[self.current_action, feature_index] = new_q_value\\n\\n\\n        # Update current state and action\\n        self.current_state = None\\n        self.current_action = action\\n\\n\\n    def observe_real_time_data(self, identifier):\\n        # Fetch real-time data\\n        real_time_data = fetch_real_time_data(identifier)\\n\\n\\n        # Extract features from real-time data\\n        self.current_state = np.array([real_time_data[\\'open\\'], real_time_data[\\'high\\'],\\n                                       real_time_data[\\'low\\'], real_time_data[\\'close\\'],\\n                                       real_time_data[\\'volume\\']])\\n\\n\\n    def observe_next_state(self, identifier):\\n        # Update the current state with the observed next state\\n        self.current_state = fetch_real_time_data(identifier)\\n\\n\\ndef fetch_real_time_data(identifier):\\n    source = \\'nasdaq_basic\\'\\n    response = intrinio.SecurityApi().get_security_realtime_price(identifier, source=source)\\n\\n\\n    return {\\n        \\'open\\': response.open_price,\\n        \\'high\\': response.high_price,\\n        \\'low\\': response.low_price,\\n        \\'close\\': response.last_price,\\n        \\'volume\\': response.last_size\\n    }\\n\\n\\ndef calculate_reward(action, current_close, next_close):\\n    if action == 0:  # Buy\\n        return 1.0 if next_close > current_close else -1.0\\n    elif action == 1:  # Sell\\n        return 1.0 if next_close < current_close else -1.0\\n    else:  # Hold\\n        return 1.0 if next_close > current_close else -1.0 if next_close < current_close else 0.0\\n\\n\\ndef calculate_profit_loss(initial_balance, suggested_action, current_close, next_close, quantity):\\n    if suggested_action == \"Buy\":\\n        return (next_close - current_close) * quantity\\n    elif suggested_action == \"Sell\":\\n        return (current_close - next_close) * quantity\\n    else:  # Hold\\n        return 0.0\\n\\n\\ndef calculate_final_profit(identifier, initial_balance, quantity, num_iterations, learning_rate, discount_factor, exploration_prob):\\n    num_actions = 3\\n    num_features = 5\\n    q_trader = QLearningTrader(num_actions, num_features, learning_rate, discount_factor, exploration_prob)\\n\\n\\n    for i in range(num_iterations):\\n        q_trader.observe_real_time_data(identifier)\\n\\n\\n        action = q_trader.choose_action(q_trader.current_state)\\n        current_close = q_trader.current_state[3]\\n\\n\\n        time.sleep(1)  # Introduce a delay before fetching the next real-time data\\n\\n\\n        q_trader.observe_next_state(identifier)\\n        next_close = q_trader.current_state[\\'close\\']\\n\\n\\n        reward = calculate_reward(action, current_close, next_close)\\n        q_trader.take_action(action, reward)\\n\\n\\n    # Fetch real-time data just after the last iteration\\n    final_real_time_data = fetch_real_time_data(identifier)\\n\\n\\n    # Get the final suggested action based on the last state in the Q-table\\n    final_suggested_action = [\"Buy\", \"Sell\", \"Hold\"][np.argmax(q_trader.q_table[:, np.argmax(q_trader.current_state)])]\\n\\n\\n    # Calculate profit based on the final suggested action\\n    final_profit = calculate_profit_loss(initial_balance, final_suggested_action, current_close, final_real_time_data[\\'close\\'], quantity)\\n\\n\\n    print(f\"Final Suggested Action: {final_suggested_action}, Final Profit: {final_profit}\")\\n\\nNow, let’s conduct the ultimate experiment to analyze the results:\\n\\nsecurity_identifier = \\'AAPL\\'\\ncalculate_final_profit(security_identifier, initial_balance = 100, \\n                       quantity = 10, num_iterations = 180, learning_rate = 0.1, \\n                       discount_factor = 0.9, exploration_prob = 0.2)\\n\\nResult:\\n\\nImage by Author\\n\\nHere, I’ve selected the identifier as AAPL (Apple), set the initial balance to 100, quantity to 10 and determined a total time of 180 iterations, equivalent to 180 seconds or 3 minutes. The strategy resulted in a profit of 0.3 units upon selling. It’s important to note that these parameters are adjustable based on specific preferences and market conditions. Feel free to modify them to better suit your needs and objectives.\\n\\nNOTE: This strategy is intentionally kept simple, employing a straightforward reward function and incorporating randomization in exploration. It’s crucial to recognize that due to the inherent randomness and simplicity, different outcomes may arise for the same dataset snapshot. This article serves as an introductory and simplified overview of the strategy. It is recommended to tailor and adjust the approach based on specific requirements and objectives.\\n\\nFinal Thoughts\\n\\nIn conclusion, our exploration of Q-Learning, emphasizing key features such as open, high, low, and last prices, provides practical insights into the algorithm’s adaptability.\\n\\nThe iterative cycles striking a balance between exploration and exploitation contribute to its functionality. Additionally, leveraging Intrinio’s Nasdaq Basic API enhances our experiment, allowing us to incorporate diverse and accurate financial data. The performance evaluation, considering profits and losses, offers a hands-on perspective on the algorithm’s real-world applicability.\\n\\nIn essence, this journey not only sheds light on Q-Learning but also showcases its potential when coupled with powerful financial data extraction tools like Intrinio’s Nasdaq Basic API.\\n\\nWith that being said, you’ve reached the end of the article. Hope you learned something new and useful. If you’ve used Intrinio’s APIs for extracting data, let me know your user experience in the comments. Thank you very much for your time.'}},\n",
       "  {'id': 'f566e3fdcbc5',\n",
       "   'title': 'Using AI + Dividends to Manage Risk',\n",
       "   'subtitle': 'A practical case-study using Python and APIs',\n",
       "   'author': 'e10ad955760c',\n",
       "   'publication_id': '5517fd7b58a6',\n",
       "   'published_at': '2023-12-19 13:47:41',\n",
       "   'last_modified_at': '2024-01-08 04:18:07',\n",
       "   'tags': ['data-science',\n",
       "    'artificial-intelligence',\n",
       "    'python',\n",
       "    'programming',\n",
       "    'finance'],\n",
       "   'topics': ['data-science', 'programming'],\n",
       "   'claps': 129,\n",
       "   'voters': 11,\n",
       "   'word_count': 1303,\n",
       "   'responses_count': 0,\n",
       "   'reading_time': 6.1169811320754715,\n",
       "   'url': 'https://levelup.gitconnected.com/using-ai-dividends-to-manage-risk-f566e3fdcbc5',\n",
       "   'unique_slug': 'using-ai-dividends-to-manage-risk-f566e3fdcbc5',\n",
       "   'image_url': 'https://miro.medium.com/0*yYSJhO5S8bBWDF1A',\n",
       "   'lang': 'en',\n",
       "   'is_series': False,\n",
       "   'is_locked': False,\n",
       "   'is_shortform': False,\n",
       "   'top_highlight': '',\n",
       "   'content': {'id': 'f566e3fdcbc5',\n",
       "    'content': 'Using AI + Dividends to Manage Risk\\n\\nA practical case-study using Python and APIs\\n\\nPhoto by Edge2Edge Media on Unsplash\\n\\nIntroduction\\n\\nFiguring out the risks before they happen is the best way to go, just like the saying \"prevention is better than cure.\" Risk management is itself a very vast and interesting topic that needs investors\\' utmost attention. Everybody wants to take calculated risks. In this process of calculating the risk, we are here with a solution to further ease the process using the Financial Modeling Prep (FMP) API. We are using the dividend historical endpoint along with the other comprehensive endpoints of the FMP API to assess the risk of investment in a stock.\\n\\nWhat is a dividend? It is a sum of money paid regularly (typically annually) by a company to its shareholders out of its profits (or reserves) and an important indicator of classifying risk on a stock. Let’s dive in now to make the problem easier with artificial intelligence.\\n\\nImporting the necessary packages\\n\\nIn this section, we will get to know all the tools that will help us form a system for accessing the risks involved.\\n\\n# Import necessary libraries\\n\\nimport pandas as pd\\nimport requests\\nfrom sklearn.model_selection import train_test_split\\nfrom xgboost import XGBClassifier\\nfrom sklearn.metrics import accuracy_score, classification_report, confusion_matrix\\n\\nPandas is a powerful data manipulation and analysis library, particularly for working with structured data through DataFrames.\\n\\nRequests simplify HTTP requests, commonly used for retrieving data from web APIs.\\n\\nsklearn.model_selection (import train_test_split) is a part of scikit-learn that facilitates the essential task of splitting datasets into training and testing sets.\\n\\nxgboost implements models, including the xgboost classifier, for predictive modeling tasks.\\n\\nsklearn.metrics provides metrics for evaluating machine learning models, with mean squared error measuring the average squared difference between predicted and actual values.\\n\\nData retrieval and preparation\\n\\nIn this section, we will fetch various data from different endpoints of the Financial Modeling Prep API, including the Dividend Historical, Statement Analysis, and Income Statement. We will extract the important columns from them, merge them, and modify them to form the correct dataset for our needs.\\n\\nDividend payments are a key indicator of a company’s financial health and stability. Investors often rely on consistent and growing dividend payments as a sign of a company’s profitability and long-term viability. Assessing dividend risk helps investors identify potential pitfalls and make more informed decisions about their investments.\\n\\nWe will access this data from the Financial Modeling Prep API.\\n\\napi_key = \\'YOUR_API_KEY\\'\\n\\n# Fetch historical dividend data\\nurl = f\"https://financialmodelingprep.com/api/v3/historical-price-full/stock_dividend/AAPL?apikey={api_key}\"\\nresponse = requests.get(url)\\ndata = response.json()\\n\\n# Extract relevant data from the API response\\ndf_dividends = pd.DataFrame(data[\\'historical\\'])\\n\\ndf_dividends\\n\\nImage by Author\\n\\nThe code fetches historical dividend data using the FMP API. Make sure to replace YOUR API KEY with your secret API key which you can obtain after registering an FMP developer account. The data includes dates, dividend amounts, and other relevant details.\\n\\n# Fetch Statement Analysis\\nurl = f\"https://financialmodelingprep.com/api/v3/key-metrics/AAPL?period=quater&apikey={api_key}\"\\nresponse = requests.get(url)\\ndata = response.json()\\n\\n# Extract relevant data from the API response\\ndf_statement_analysis = pd.DataFrame(data)\\n\\ndf_statement_analysis\\n\\nImage by Author\\n\\nThe data obtained contains the statement analysis of a company and is essential for evaluating a company’s financial health, profitability, and overall performance, providing valuable insights into its operational efficiency and strategic standing in the market.\\n\\n# Fetch Income Statement\\nurl = f\"https://financialmodelingprep.com/api/v3/income-statement/AAPL?period=quater&apikey={api_key}\"\\nresponse = requests.get(url)\\ndata = response.json()\\n\\n# Extract relevant data from the API response\\ndf_income_statement = pd.DataFrame(data)\\n\\ndf_income_statement.head(5)\\n\\nImage by Author\\n\\nThe income_statement endpoint in the Financial Modeling Prep API delivers detailed information about a company’s income statement, including revenue, expenses, and net profit.\\n\\nWe are now extracting the relevant features from the obtained data to assess the risk of a stock. We chose earning per share and profit-to-earnings ratio as the two parameters; you can use more to form a more robust system.\\n\\ndf_financial = pd.DataFrame()\\ndf_financial[\\'date\\'] =  df_statement_analysis[\\'date\\']\\ndf_financial[\\'earnings_per_share\\'] = df_income_statement[\\'eps\\']\\ndf_financial[\\'price_earning_ratio\\'] = df_statement_analysis[\\'peRatio\\']\\n\\ndf_financial.head(5)\\n\\nImage by Author\\n\\nWe merged the financial data with the dividend data annually to get the mean score for each year using the following:\\n\\n# Convert the \\'Date\\' column to datetime format\\ndf_dividends[\\'date\\'] = pd.to_datetime(df_dividends[\\'date\\'])\\n# Extract the year from the \\'Date\\' column\\ndf_dividends[\\'Year\\'] = df_dividends[\\'date\\'].dt.year\\n# Group by year and calculate the mean for each column\\ndividends_yearly = df_dividends.groupby(\\'Year\\').mean()\\n\\n# Convert the \\'Date\\' column to datetime format\\ndf_financial[\\'date\\'] = pd.to_datetime(df_financial[\\'date\\'])\\n# Extract the year from the \\'Date\\' column\\ndf_financial[\\'Year\\'] = df_financial[\\'date\\'].dt.year\\n\\n# Merge dividend data with financial metrics data based on the date\\nmerged_yearly = pd.merge(dividends_yearly, df_financial, left_on=\"Year\", right_on=\"Year\", how=\"left\")\\nmerged_yearly\\n\\nImage by Author\\n\\nFinancial metrics are used to create additional features, such as the dividend payout ratio and dividend coverage ratio. These features contribute to the assessment of a company’s financial stability.\\n\\nDividend Payout Ratio:\\n\\nIt reveals the percentage of a company’s earnings distributed as dividends, helping investors gauge how much profit is returned to shareholders.\\n\\nDividend Coverage Ratio:\\n\\nThis metric assesses a company’s ability to cover dividend payments with earnings, showing how many times the earnings can support the dividends.\\n\\n# Fill missing financial metric values with 0 (assuming no data on those days)\\nmerged_yearly.fillna(0, inplace=True)\\n\\n# Feature engineering: Calculate additional financial ratios or use existing ones\\n# For simplicity, we\\'ll use the earnings per share and price-to-earnings ratio\\nmerged_yearly[\"dividend_payout_ratio\"] = merged_yearly[\"dividend\"] / merged_yearly[\"earnings_per_share\"]\\nmerged_yearly[\"dividend_coverage_ratio\"] = 1 / merged_yearly[\"price_earning_ratio\"]\\n\\nmerged_yearly\\n\\nImage by Author\\n\\nA risk label is assigned based on predefined thresholds for financial metrics. If a company surpasses these thresholds, it is labeled as high risk (1); otherwise, it is labeled as low risk (0).\\n\\nprice_earning_threshold = 15  # Example threshold, adjust as needed\\ndividend_payout_threshold = 5  # Example threshold, adjust as needed\\ndividend_coverage_threshold = 0.1  # Example threshold, adjust as needed\\n\\n# Create a target variable \\'risk\\'\\nmerged_yearly[\\'risk\\'] = (\\n    (merged_yearly[\\'price_earning_ratio\\'] > price_earning_threshold) &\\n    (merged_yearly[\\'dividend_payout_ratio\\'] > dividend_payout_threshold) &\\n    (merged_yearly[\\'dividend_coverage_ratio\\'] < dividend_coverage_threshold)\\n).astype(int)\\n\\nmerged_yearly = merged_yearly.drop(\\'date\\',axis =1)\\nmerged_yearly = merged_yearly.set_index(\\'Year\\')\\nmerged_yearly\\n\\nImage by Author\\n\\nTraining the model and making predictions\\n\\nIn this section, we utilized the XGBoost Classifier to train the model using the classified data from the preceding section. The data is categorized as either low risk or high risk for investment based on specific thresholds. The model is subsequently evaluated using metrics such as accuracy, confusion matrix, and classification report.\\n\\nX = merged_yearly.drop(\\'risk\\', axis=1)\\ny = merged_yearly[\\'risk\\']\\n\\n# Train-test split\\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\\n\\n# Train an XGBoost classifier\\nxgb_classifier = XGBClassifier()\\nxgb_classifier.fit(X_train, y_train)\\n\\nThe trained model is now used for predictions of risk for certain stock data and is evaluated using metrics.\\n\\n# Make predictions on the test set\\ny_pred = xgb_classifier.predict(X_test)\\n\\n# Evaluate the classifier\\naccuracy = accuracy_score(y_test, y_pred)\\nconf_matrix = confusion_matrix(y_test, y_pred)\\nclassification_rep = classification_report(y_test, y_pred)\\n\\nprint(f\\'Accuracy: {accuracy:.2f}\\')\\nprint(f\\'Confusion Matrix:\\\\n{conf_matrix}\\')\\nprint(f\\'Classification Report:\\\\n{classification_rep}\\')\\n\\nImage by Author\\n\\nGiven the limited size of our dataset, the test data is also constrained. A review of the confusion matrix reveals that the model accurately predicts 4 out of 5 low-risk stocks (0) but misclassifies one as a high-risk stock.\\n\\nA classification report, a performance evaluation metric in machine learning, furnishes a summary of positives and negatives. In our scenario, the low-risk class is predicted more accurately than the high-risk class due to the dataset imbalance, leading to an accuracy of 0.80.\\n\\nConclusion\\n\\nAssessing dividend risk is a crucial aspect of intelligent investing. This article provides a foundation for constructing a dividend risk assessment model, incorporating historical dividend data and financial metrics obtained from the Financial Modeling Prep API - a remarkable source of vast data.\\n\\nInvestors can leverage such models to make more informed decisions, optimize their portfolios, and navigate the dynamic stock market landscape with increased confidence. As is the case with any financial model, continuous refinement and adaptation are essential to ensuring its relevance and effectiveness in ever-changing market conditions.\\n\\nWith that being said, you’ve reached the end of the article. Hope you learned something new and useful today. Thank you very much for your time.'}},\n",
       "  {'id': '05da6551637c',\n",
       "   'title': 'Real-Time Options Analysis with Python',\n",
       "   'subtitle': 'A Python case study to dive deep into the options realm using APIs',\n",
       "   'author': 'e10ad955760c',\n",
       "   'publication_id': '32881626c9c9',\n",
       "   'published_at': '2023-12-19 10:19:54',\n",
       "   'last_modified_at': '2023-12-19 10:23:43',\n",
       "   'tags': ['finance', 'technology', 'programming', 'data-science', 'python'],\n",
       "   'topics': ['data-science', 'programming'],\n",
       "   'claps': 366,\n",
       "   'voters': 72,\n",
       "   'word_count': 2247,\n",
       "   'responses_count': 6,\n",
       "   'reading_time': 9.312578616352202,\n",
       "   'url': 'https://medium.datadriveninvestor.com/real-time-options-analysis-with-python-05da6551637c',\n",
       "   'unique_slug': 'real-time-options-analysis-with-python-05da6551637c',\n",
       "   'image_url': 'https://miro.medium.com/0*zBAobsC5ItBX5f28',\n",
       "   'lang': 'en',\n",
       "   'is_series': False,\n",
       "   'is_locked': False,\n",
       "   'is_shortform': False,\n",
       "   'top_highlight': '',\n",
       "   'content': {'id': '05da6551637c',\n",
       "    'content': 'Real-Time Options Analysis with Python\\n\\nA Python case study to dive deep into the options realm using APIs\\n\\nPhoto by Tobias Carlsson on Unsplash\\n\\nToday, we’re diving into an interesting product called SpiderRock Mlink which provides real-time and delayed data to delve into the options world. It’s a user-friendly tool with extensive and diverse datasets, making it easy to access and use. Join us as we explore the practical side of options trading with the reliable support of SpiderRock Mlink.\\n\\nImporting the Data\\n\\nFirst, we’ll import the necessary libraries for our analysis. These libraries will provide the fundamental tools needed to explore and implement our options trading strategy -\\n\\nImporting the Libraries\\n\\nimport math\\nimport requests\\nfrom datetime import datetime\\n\\nTo craft an effective options trading strategy, we’ll use the Spiderock Mlink API. Spiderock offers a broad and diverse dataset that makes analyzing and planning our trades a breeze. This rich dataset includes real-time and delayed information, covering various metrics related to stocks, options, futures, and more. It equips us with valuable insights to enhance decision-making in the dynamic realm of options trading.\\n\\nTo obtain option data, we’ll be making an API request to a specific URL, and this request will facilitate the retrieval of the data we require.\\n\\nSpiderRock Mlink offers two main avenues to access their data: one through the Rest API and the other through Mlink WebSocket. This dual approach ensures ease and flexibility in extracting and working with data across diverse environments.\\n\\nIn this instance, I’ve employed the Rest API to retrieve LiveImpliedQuote data for AAPL. The URL construction for this API adheres to a set format:\\n\\nhttps://mlink-delay.spiderrockconnect.com/rest/json?apikey={YOUR API KEY}&cmd=getmsgs&msgtype={DataName}&where=okey.tk:eq:{symbol}.\\n\\nSimply substitute {YOUR API KEY} with your secret API key to ensure proper authentication when using the code, {DataName} with the preferred dataset or real-time data type, and {symbol} with the token sequence corresponding to the specific equity of your interest\\n\\nRequesting Data through REST API URL\\n\\nimport requests\\n\\napi_url = \"https://mlink-delay.spiderrockconnect.com/rest/json?apikey=YOUR_API_KEY&cmd=getmsgs&msgtype=LiveImpliedQuote&where=okey.tk:eq:AAPL\"\\n\\n# Make a GET request to the API\\nresponse = requests.get(api_url)\\n\\n# Check if the request was successful (status code 200)\\nif response.status_code == 200:\\n    # Parse the response JSON\\n    data = response.json()\\nelse:\\n    print(f\"Error: Unable to fetch data. Status code: {response.status_code}\")\\n\\nReplace the apikey parameter from YOUR API KEY in the provided code with your secret API key.\\n\\nThis will yield a result comprising various metrics. However, we selectively opt for a subset of these metrics, focusing on the most relevant ones for our specific purpose. These include:\\n\\n[Underlier Price, Years to Expiration, Option Moneyness, Discount Rate, Continuous Stock Dividend Rate, Option Bid Price, Option Ask Price, Volatility implied by the Option Bid Price, Volatility implied by Option Ask Price]\\n\\nWe only need the most latest data hence we choose the second last one (cause the last one is just the task completion statement)\\n\\ndata = data[-2]\\n\\nThe output data will be in the following format :\\n\\nImage by Author\\n\\nCalculating Options Metrics\\n\\nNow that we have all the necessary data, let’s kick off calculating various options metrics. To get started, we’ll introduce you to a few options metrics we’ll be using for this task and provide a brief explanation about each.\\n\\nThe primary metrics we will be calculating in this article are:\\n\\n1) Implied Volatility\\n\\n2) Likelihood that the Option will Expire in the Money (ITM)\\n\\n3) Bid-Ask Spread\\n\\nThese might seem a bit overwhelming at the moment, but as we progress through each step of understanding, they will become clear and straightforward to you. Now, let’s proceed to understand and calibrate these metrics one by one for our task.\\n\\n1. Implied Volatility\\n\\nSimply put, implied volatility tells us what the market thinks about current and future price swings. It’s like a forecast for future changes, and that’s why it’s crucial for us to assess and manage risks\\n\\nImplied volatility is derived by plugging the market price of the option into the Black-Scholes formula and reverse-engineering to determine the volatility value. However, various methods exist for calculating implied volatility, such as the example below where we utilized Newton’s method for numerical solution.\\n\\nNow, diving a bit into the math, let’s define Implied Volatility (IV) :\\n\\nImage by Author\\n\\nWhere:\\n\\nEM = 1SD expected move\\n\\nS = stock price\\n\\nIV = implied volatility of your option’s expiration cycle\\n\\nDTE = days to the expiration of your option contract\\n\\nI’d like to highlight a crucial point regarding the \"Days to Expiry\" variable (DTE) in our implementation. Currently, it is normalized for the entire year, considering 365 days. However, we need to align our calculations with the total working days, which is 252 days. Therefore, we should adjust the time-to-expiry (T) in our code to be normalized to 252 working days instead of the whole year.\\n\\nI mentioned the Black-Scholes equation in the paragraph before, but what exactly is it? What is it used for, and how does it benefit us? Let’s take a closer look:\\n\\nImage by Author\\n\\nWhere:\\n\\nS = current stock price\\n\\nK = option striking price\\n\\nt = time until option exercise\\n\\nr = risk-free interest rate\\n\\nIV = implied volatility\\n\\nC = call premium\\n\\nN = exponential term\\n\\nln = natural log\\n\\nIn simple terms, the Black-Scholes formula is used to estimate the value of financial options. It helps us understand how the price of an option might change based on various factors, making it a valuable tool for option pricing and trading decisions.\\n\\nNow that we understand the significance of Implied Volatility and the role of the Black-Scholes equation in deriving its value, the next question is: How do we calculate Implied Volatility?\\n\\nExactly! When thinking about calculating implied volatility, the process we discussed earlier naturally comes to mind, doesn’t it? That’s because it’s not only the primary but also the most effective way to derive implied volatility. Here’s a function that gets the job done.\\n\\n#creating a function to calculate the implied volatility\\ndef calculate_implied_volatility(option_data):\\n    S = option_data[\"current_stock_price\"]\\n    K = option_data[\"strike_price\"]\\n    T = option_data[\"time_to_expiry_in_days\"] / 252 #Normalize to 252 days\\n    r = option_data[\"risk_free_rate\"]\\n    C = (option_data[\"bid_price\"] + option_data[\"ask_price\"]) / 2  # Use average of bid and ask as option price\\n\\n    # Black-Scholes-Merton formula for implied volatility\\n    def black_scholes(volatility):\\n        d1 = (math.log(S / K) + (r + (volatility**2) / 2) * T) / (volatility * math.sqrt(T))\\n        d2 = d1 - volatility * math.sqrt(T)\\n        return S * norm_cdf(d1) - K * math.exp(-r * T) * norm_cdf(d2) - C\\n\\n    # Newton\\'s method for numerical solution\\n    def implied_volatility_newton(initial_guess, tolerance=1e-6, max_iterations=100):\\n        vol = initial_guess\\n        for _ in range(max_iterations):\\n            diff = black_scholes(vol) / black_scholes_derivative(vol)\\n            vol -= diff\\n            if abs(diff) < tolerance:\\n                return vol\\n        return None\\n\\n    # Helper function for the standard normal cumulative distribution function\\n    def norm_cdf(x):\\n        return (1.0 + math.erf(x / math.sqrt(2.0))) / 2.0\\n\\n    # Helper function for the derivative of the standard normal cumulative distribution function\\n    def norm_cdf_derivative(x):\\n        return math.exp(-x**2 / 2.0) / math.sqrt(2.0 * math.pi)\\n\\n    # Derivative of the Black-Scholes-Merton formula with respect to volatility\\n    def black_scholes_derivative(volatility):\\n        d1 = (math.log(S / K) + (r + (volatility**2) / 2) * T) / (volatility * math.sqrt(T))\\n        return S * norm_cdf_derivative(d1) * math.sqrt(T)\\n\\n    implied_volatility = implied_volatility_newton(initial_guess=0.2)  # Initial guess for volatility\\n\\n    return implied_volatility\\n\\nBut you know what? Dealing with all those calculations seems a bit messy and could take quite a while every time we need to access the code. To make things easier and save us a lot of time, we’ve got a shortcut - the SpiderRock API endpoints. They’ve got all the data we need, and it’s already present in the data we extracted. Isn’t it convenient?\\n\\n2. Expire in-The-Money (ITM)\\n\\nWhen an option expires in-the-money (ITM), it means the option has ended up profitable. It’s like the option did exactly what we wanted it to do. For example, if we bought a call option and the stock price went up, making that option profitable at the end - that’s an ITM expiration. It’s a bit like scoring a win in the world of options trading!\\n\\nProfitability at expiration is the likelihood that the option will end up in the money (ITM). This is calculated using the Black-Scholes-Merton model, a common mathematical method for pricing European-style options.\\n\\nNow, consider the mathematical equation for the probability distribution:\\n\\nProbability = CDF(d1)\\n\\nWhere:\\n\\nd1 is part of the Black-Scholes formula.\\n\\nCDF is the cumulative distribution function of the standard normal distribution.\\n\\nIn simpler terms, we calculate probability by looking at the standard normal distribution function at a particular point (determined by d1). The higher the probability, the more we expect the option to be profitable at expiration. It’s essential to note that this probability isn’t a statistical probability of profit but rather a measure derived from option pricing models.\\n\\nWe Calculate probability by defining a function as below :\\n\\ndef calculate_probability(option_data):\\n    S = option_data[\"underlier_price\"]\\n    K = option_data[\"strike_price\"]\\n    r = option_data[\"discount_rate\"]\\n    sigma = option_data[\"implied_volatility\"]\\n    T = option_data[\"years_to_expiration\"]\\n\\n    d1 = (math.log(S / K) + (r + (sigma**2) / 2) * T) / (sigma * math.sqrt(T))\\n    probability = norm.cdf(d1)\\n\\n    return probability\\n\\nHere, we’re using the ‘option_data’ dictionary directly in the calculation. Before proceeding, let’s define this dictionary with the following values:\\n\\noption_data = {\\n    \\'underlier_price\\': data[\\'message\\'][\\'uPrc\\'],\\n    \\'strike_price\\': data[\\'message\\'][\\'pkey\\'][\\'okey\\'][\\'xx\\'],\\n    \\'years_to_expiration\\': data[\\'message\\'][\\'years\\'],\\n    \\'discount_rate\\': data[\\'message\\'][\\'rate\\'],\\n    \\'bid_price\\': data[\\'message\\'][\\'oBid\\'],\\n    \\'ask_price\\': data[\\'message\\'][\\'oAsk\\'],\\n    \\'implied_volatility\\': data[\\'message\\'][\\'oAskIv\\']\\n}\\n\\nIn short, option_data takes values from our original data and organizes them into a more manageable format.\\n\\n3. Bid-Ask spread\\n\\nThe Bid-Ask spread is the difference between the highest price a buyer is willing to pay (Bid) and the lowest price a seller is willing to accept (Ask) for a security. It serves as an indicator of market liquidity, transaction costs, and the balance between supply and demand. A narrow spread indicates a liquid market with lower transaction costs, while a wider spread may suggest reduced liquidity or increased market uncertainty.\\n\\nTraders often consider the Bid-Ask spread when making decisions, aiming to minimize costs and navigate market conditions effectively. Market makers profit from this spread by facilitating trades between buyers and sellers.\\n\\nTo calculate the Bid-Ask spread, we define a function as follows:\\n\\ndef bid_ask_spread_analysis(option_data):\\n    bid_ask_spread = option_data[\"ask_price\"] - option_data[\"bid_price\"]\\n    return bid_ask_spread\\n\\nCompiling all the tools\\n\\nNow, for our final step, we calculate the comprehensive set of metrics by utilizing the previously defined functions. This involves computing the Implied Volatility, Expire-in-the-money (ITM), and Bid-Ask spread, providing us with a well-rounded evaluation of the option’s characteristics and potential profitability. This multi-faceted approach allows us to make informed decisions and gain valuable insights into the dynamics of the specific option under consideration:\\n\\n# Calculate probability\\noption_data[\"probability\"] = calculate_probability(option_data)\\n\\n# Bid-Ask Spread Analysis\\noption_data[\"bid_ask_spread\"] = bid_ask_spread_analysis(option_data)\\n\\n# Print results\\nprint(\"Implied Volatility:\", option_data[\"implied_volatility\"])\\nprint(\"Probability:\", option_data[\"probability\"])\\nprint(\"Bid-Ask Spread:\", option_data[\"bid_ask_spread\"])\\n\\nProviding us with the output for this specific case, the resulting metrics are as follows:\\n\\nImage by Author\\n\\nFinally, we piece together a complete function for the operation. :\\n\\nUnified Function for Calculation Metrics\\n\\nimport requests\\nimport math\\nfrom scipy.stats import norm\\n\\ndef fetch_option_data(YOUR API KEY, symbol):\\n    api_url = f\"https://mlink-delay.spiderrockconnect.com/rest/json?apikey={YOUR APIKEY}&cmd=getmsgs&msgtype=LiveImpliedQuote&where=okey.tk:eq:{symbol}\"\\n\\n    # Make a GET request to the API\\n    response = requests.get(api_url)\\n\\n    # Check if the request was successful (status code 200)\\n    if response.status_code == 200:\\n        # Parse the response JSON\\n        data = response.json()\\n\\n        # Extract the relevant data from the response\\n        data = data[-2]  # Assuming the data is in a specific format, adjust as needed\\n\\n        option_data = {\\n            \\'underlier_price\\': data[\\'message\\'][\\'uPrc\\'],\\n            \\'strike_price\\': data[\\'message\\'][\\'pkey\\'][\\'okey\\'][\\'xx\\'],\\n            \\'years_to_expiration\\': data[\\'message\\'][\\'years\\'],\\n            \\'discount_rate\\': data[\\'message\\'][\\'rate\\'],\\n            \\'bid_price\\': data[\\'message\\'][\\'oBid\\'],\\n            \\'ask_price\\': data[\\'message\\'][\\'oAsk\\'],\\n            \\'implied_volatility\\': data[\\'message\\'][\\'oAskIv\\']\\n        }\\n\\n        return option_data\\n    else:\\n        print(f\"Error: Unable to fetch data. Status code: {response.status_code}\")\\n        return None\\n\\ndef calculate_metrics(option_data):\\n    result = {}\\n\\n    S = option_data[\"underlier_price\"]\\n    K = option_data[\"strike_price\"]\\n    r = option_data[\"discount_rate\"]\\n    sigma = option_data[\"implied_volatility\"]\\n    T = option_data[\"years_to_expiration\"]\\n\\n    d1 = (math.log(S / K) + (r + (sigma**2) / 2) * T) / (sigma * math.sqrt(T))\\n    probability = norm.cdf(d1)\\n\\n    bid_ask_spread = option_data[\"ask_price\"] - option_data[\"bid_price\"]\\n\\n    result[\"implied_volatility\"] = option_data[\"implied_volatility\"]\\n    result[\"probability\"] = probability\\n    result[\"bid_ask_spread\"] = bid_ask_spread\\n\\n    return result\\n\\ndef main(YOUR API KEY, symbol):\\n    option_data = fetch_option_data(YOUR API KEY, symbol)\\n\\n    if option_data:\\n        metrics_result = calculate_metrics(option_data)\\n        print(metrics_result)\\n\\nWorking Example:\\n\\napi_key = \"YOUR API KEY\"\\nsymbol = \"AAPL\"\\nmain(api_key, symbol)\\n\\nOutput:\\n\\n{\\'implied_volatility\\': -1, \\'probability\\': 0.43198086037435784, \\'bid_ask_spread\\': 1.0499999999999972}\\n\\nNote: Please replace the YOUR API KEY in the working example with your secret API key to ensure proper authentication when using the code.\\n\\nConclusion\\n\\nAnd with this, we’ve crafted a versatile foundation for option trading. We seamlessly integrate key metrics like volatility, probability, and bid-ask spread into a comprehensive function that offers valuable insights for any given option. SpiderRock Mlink plays a pivotal role, streamlining our access to this data and enhancing our overall efficiency. Now, armed with these metrics, traders can navigate their strategies with precision.\\n\\nWhether analyzing volatility trends, evaluating probability scenarios, or considering bid-ask spread dynamics, our approach to options trading is flexible and adaptive. SpiderRock Mlink has truly proven instrumental in simplifying our processes and empowering strategic decision-making in various market conditions.\\n\\nWith that being said, you’ve reached the end of the article. Hope you learned something new and useful today. Thank you for your time and let me know in the comments what you think of this product.\\n\\nVisit us at DataDrivenInvestor.com\\n\\nSubscribe to DDIntel here.\\n\\nHave a unique story to share? Submit to DDIntel here.\\n\\nJoin our creator ecosystem here.\\n\\nDDIntel captures the more notable pieces from our main site and our popular DDI Medium publication. Check us out for more insightful work from our community.\\n\\nDDI Official Telegram Channel: https://t.me/+tafUp6ecEys4YjQ1\\n\\nFollow us on LinkedIn, Twitter, YouTube, and Facebook.'}},\n",
       "  {'id': '58ed12a492dc',\n",
       "   'title': 'An Algo Trading Strategy which made +8,371%: A Python Case Study',\n",
       "   'subtitle': 'Backtesting of a simple breakout trading strategy with APIs and Python',\n",
       "   'author': 'e10ad955760c',\n",
       "   'publication_id': '5517fd7b58a6',\n",
       "   'published_at': '2023-11-28 20:54:51',\n",
       "   'last_modified_at': '2023-11-30 03:21:05',\n",
       "   'tags': ['finance', 'programming', 'python', 'data-science', 'technology'],\n",
       "   'topics': ['programming'],\n",
       "   'claps': 2814,\n",
       "   'voters': 844,\n",
       "   'word_count': 1564,\n",
       "   'responses_count': 53,\n",
       "   'reading_time': 6.85188679245283,\n",
       "   'url': 'https://levelup.gitconnected.com/an-algo-trading-strategy-which-made-8-371-a-python-case-study-58ed12a492dc',\n",
       "   'unique_slug': 'an-algo-trading-strategy-which-made-8-371-a-python-case-study-58ed12a492dc',\n",
       "   'image_url': 'https://miro.medium.com/0*NVcgICnCBFvG0gM7',\n",
       "   'lang': 'en',\n",
       "   'is_series': False,\n",
       "   'is_locked': False,\n",
       "   'is_shortform': False,\n",
       "   'top_highlight': \"Before moving to the coding part, it's essential to have a good background on the strategy we're going to build in this article. Our trading strategy follows the principle of simplicity yet a very effective breakout strategy.\",\n",
       "   'content': {'id': '58ed12a492dc',\n",
       "    'content': 'An Algo Trading Strategy which made +8,371%: A Python Case Study\\n\\nBacktesting of a simple breakout trading strategy with APIs and Python\\n\\nPhoto by Behnam Norouzi on Unsplash\\n\\nIntroduction\\n\\nThere is literally no point in going after traditional algo trading strategies like SMA crossover or RSI threshold breakout strategy as it has proven to be obsolete given their simplistic nature and more importantly, the massive volume of participants who are trying to implement them in the market.\\n\\nSo instead of embracing those strategies, it’s time to try something new. In this article, we’ll be using Python and Benzinga’s APIs to construct and backtest a new trading strategy that will help us beat the market.\\n\\nWith that being said, let’s dive into the article!\\n\\nThe Trading Strategy\\n\\nBefore moving to the coding part, it’s essential to have a good background on the strategy we’re going to build in this article. Our trading strategy follows the principle of simplicity yet a very effective breakout strategy.\\n\\nWe enter the market if: the stock’s current high exceeds the 50-week high\\n\\nWe exit the market if: the stock’s current low sinks below the 40-week low\\n\\nWe’ll be using the Donchian Channel indicator in order to keep track of the 50-week high and the 40-week low. This strategy is a weekly trading system, so, we’ll be backtesting it on the weekly timeframe.\\n\\nAnd, there you go! This is the strategy we’re going to backtest in this article. As simple as it is, right?! Now, let’s move on to the coding part of the article.\\n\\nImporting Packages\\n\\nIn this article, we are going to use four primary packages which are pandas, requests, pandas_ta and matplotlib , and the secondary/optional packages include termcolor and math. The following code will import all the mentioned packages into our Python environment:\\n\\n# IMPORTING PACKAGES\\n\\nimport pandas as pd\\nimport requests\\nimport pandas_ta as ta\\nimport matplotlib.pyplot as plt\\nfrom termcolor import colored as cl\\nimport math \\n\\nplt.rcParams[\\'figure.figsize\\'] = (20,10)\\nplt.style.use(\\'fivethirtyeight\\')\\n\\nIf you haven’t installed any of the imported packages, make sure to do so using the pip command in your terminal.\\n\\nExtracting Historical Data\\n\\nWe are going to backtest our breakout strategy on Apple’s stock. So in order to obtain the historical stock data of Apple, we are going to use Benzinga’s Historical Bar Data API endpoint. The following Python code uses the endpoint to extract Apple’s stock data from 1993:\\n\\n# EXTRACTING HISTORICAL DATA\\n\\ndef get_historical_data(symbol, start_date, interval):\\n    url = \"https://api.benzinga.com/api/v2/bars\"\\n    querystring = {\"token\":\"YOUR API KEY\",\"symbols\":f\"{symbol}\",\"from\":f\"{start_date}\",\"interval\":f\"{interval}\"}\\n\\n    hist_json = requests.get(url, params = querystring).json()\\n    df = pd.DataFrame(hist_json[0][\\'candles\\'])\\n    \\n    return df\\n\\naapl = get_historical_data(\\'AAPL\\', \\'1993-01-01\\', \\'1W\\')\\naapl.tail()\\n\\nIn the above code, we are defining a function named get_historical_data which takes the stock symbol, the starting date of the data, and the interval between the data points.\\n\\nInside the function, we are storing the API URL and the query strings into their respective variables. Make sure to replace YOUR API KEY with secret Benzinga API key which you can obtain after creating an account with them. Then, we are making an API call to obtain the data and converting the JSON response into a Pandas dataframe which we are returning at the end.\\n\\nUsing the defined function, we are extracting Apple’s historical stock data from 1993 on a weekly timeframe. This is the end output:\\n\\nApple’s historical data (Image by Author)\\n\\nAwesome, now let’s move on to calculating the Donchian Channel indicator for the extracted historical data of Apple.\\n\\nDonchian Channel Calculation\\n\\nIf we dive deep into the mathematics of the indicator, it will demand a separate article on its own for the explanations. So here\\'s a general overview of the indicator. Basically, the Donchian Channel reveals the highest high and the lowest low of a stock over a specified period of time.\\n\\nThe following code uses pandas_ta for the calculation of the indicator:\\n\\n# CALCULATING DONCHIAN CHANNEL\\n\\naapl[[\\'dcl\\', \\'dcm\\', \\'dcu\\']] = aapl.ta.donchian(lower_length = 40, upper_length = 50)\\naapl = aapl.dropna().drop(\\'time\\', axis = 1).rename(columns = {\\'dateTime\\':\\'date\\'})\\naapl = aapl.set_index(\\'date\\')\\naapl.index = pd.to_datetime(aapl.index)\\n\\naapl.tail()\\n\\nIn the first line, we are using the donchian function provided by pandas_ta to calculate the indicator. The function takes two parameters: the lower length and the upper length which are the lookback periods for the lowest low and highest high respectively. We are mentioning the lower and upper lengths as 40 and 50 respectively since our strategy demands 40-week low and 50-week high.\\n\\nAfter the calculation, we are performing some data manipulation tasks to clean and format the data. This is the final dataframe:\\n\\nDonchian Channel of Apple stock (Image by Author)\\n\\nTo get a better view of the Donchian Channel indicator, let’s plot the calculated values using the Matplotlib library:\\n\\n# PLOTTING DONCHIAN CHANNEL\\n\\nplt.plot(aapl[-300:].close, label = \\'CLOSE\\')\\nplt.plot(aapl[-300:].dcl, color = \\'black\\', linestyle = \\'--\\', alpha = 0.3)\\nplt.plot(aapl[-300:].dcm, color = \\'orange\\', label = \\'DCM\\')\\nplt.plot(aapl[-300:].dcu, color = \\'black\\', linestyle = \\'--\\', alpha = 0.3, label = \\'DCU,DCL\\')\\nplt.legend()\\nplt.title(\\'AAPL DONCHIAN CHANNELS 50\\')\\nplt.xlabel(\\'Date\\')\\nplt.ylabel(\\'Close\\')\\n\\nThere is nothing much going on with this code. We are utilizing all the essential functions provided by matplotlib to create the visualization and this is the final chart:\\n\\nApple Donchian Channel Plot (Image by Author)\\n\\nFrom the plot it can be observed that there are three important components in the Donchian Channel Indicator:\\n\\nUpper Band: The upper band reveals the highest high of the stock over a specified period of time.\\n\\nLower Band: Basically the opposite of the upper band, it shows the lowest low of the stock over a specified period of time.\\n\\nMiddle Band: This component is a little different. It shows the average between the upper band and the lower band.\\n\\nDonchian Channel is one of the most widely used indicators for observing breakouts happening in stock price movements and that\\'s one of the core reasons for using it in this article.\\n\\nBacktesting the Strategy\\n\\nWe have arrived at one of the most important steps in this article which is backtesting our breakout strategy. We are going to follow a very basic and straightforward system of backtesting for the sake of simplicity. The following code backtests the strategy and reveals its results:\\n\\n# BACKTESTING THE STRATEGY\\n\\ndef implement_strategy(aapl, investment):\\n    \\n    in_position = False\\n    equity = investment\\n    \\n    for i in range(3, len(aapl)):\\n        if aapl[\\'high\\'][i] == aapl[\\'dcu\\'][i] and in_position == False:\\n            no_of_shares = math.floor(equity/aapl.close[i])\\n            equity -= (no_of_shares * aapl.close[i])\\n            in_position = True\\n            print(cl(\\'BUY: \\', color = \\'green\\', attrs = [\\'bold\\']), f\\'{no_of_shares} Shares are bought at ${aapl.close[i]} on {str(aapl.index[i])[:10]}\\')\\n        elif aapl[\\'low\\'][i] == aapl[\\'dcl\\'][i] and in_position == True:\\n            equity += (no_of_shares * aapl.close[i])\\n            in_position = False\\n            print(cl(\\'SELL: \\', color = \\'red\\', attrs = [\\'bold\\']), f\\'{no_of_shares} Shares are bought at ${aapl.close[i]} on {str(aapl.index[i])[:10]}\\')\\n    if in_position == True:\\n        equity += (no_of_shares * aapl.close[i])\\n        print(cl(f\\'\\\\nClosing position at {aapl.close[i]} on {str(aapl.index[i])[:10]}\\', attrs = [\\'bold\\']))\\n        in_position = False\\n\\n    earning = round(equity - investment, 2)\\n    roi = round(earning / investment * 100, 2)\\n    print(cl(f\\'EARNING: ${earning} ; ROI: {roi}%\\', attrs = [\\'bold\\']))\\n    \\nimplement_strategy(aapl, 100000)\\n\\nI’m not going to dive deep into the dynamics of this code as it will take some time to explain it. Basically, the program executes the trades based on the conditions that are satisfied. It enters the market when our entry condition is satisfied and exits when the exit condition is satisfied. These are trades executed by our program followed by the backtesting results:\\n\\nAAPL Backtesting Results (Image by Author)\\n\\nAs I’ve claimed in the title of the article, our strategy has made an ROI of 8371% which is humongous. But it’s time to see if our strategy has really outperformed the market.\\n\\nSPY ETF Comparison\\n\\nDrawing a comparison between the backtesting results of our strategy and the buy/hold returns of the SPY ETF helps us get a true sense of our strategy’s performance. The following code calculates the returns of SPY ETF over the years:\\n\\nspy = get_historical_data(\\'SPY\\', \\'1993-01-01\\', \\'1W\\')\\nspy_ret = round(((spy.close.iloc[-1] - spy.close.iloc[0])/spy.close.iloc[0])*100)\\n\\nprint(cl(\\'SPY ETF buy/hold return:\\', attrs = [\\'bold\\']), f\\'{spy_ret}%\\')\\n\\nIn the above code, we are first extracting the historical data of SPY with the same specifications we used for AAPL. Then we are calculating the returns percentage of the index using a simple formula and this is the result:\\n\\nSPY ETF buy/hold return (Image by Author)\\n\\nThe return of the index is 936% which is actually pretty good but when compared to that of our strategy, there is a vast difference. Our strategy has outperformed the benchmark substantially and that’s great news!\\n\\nClosing Notes\\n\\nIn this article, we went through an extensive process of coding to backtest a simple yet very effective breakout strategy. And as expected, the results of the strategy were amazing. We started off with extracting the historical data of Apple using Benzinga’s API, then slowly explored the Donchian Channel, and finally proceeded to backtest the strategy and compare the results with SPY ETF.\\n\\nThere are still a lot of aspects that can be improved. The backtesting system can be even more complex and realistic with the addition of brokerage commission and slippage. A proper risk management system must be in place, especially in the case of algo trading. Like these, there are many aspects to be improved which I’m leaving to you guys to explore.\\n\\nWith that being said, you’ve reached the end of the article. Before ending the article, I would like to give a shoutout to Benzinga for creating such a great library of APIs which includes institutional-grade market news & data APIs and I would suggest you guys check it out too. Hope you learned something new and useful today. Thank you for your time.'}},\n",
       "  {'id': '936934fea7d0',\n",
       "   'title': 'Finding the Best Sector to Invest in using Python',\n",
       "   'subtitle': 'Navigating the task of picking the right sector using APIs',\n",
       "   'author': 'e10ad955760c',\n",
       "   'publication_id': '5517fd7b58a6',\n",
       "   'published_at': '2023-11-13 00:17:43',\n",
       "   'last_modified_at': '2023-11-13 00:17:43',\n",
       "   'tags': ['finance', 'python', 'data-science', 'programming', 'technology'],\n",
       "   'topics': ['programming'],\n",
       "   'claps': 276,\n",
       "   'voters': 49,\n",
       "   'word_count': 1043,\n",
       "   'responses_count': 4,\n",
       "   'reading_time': 4.6358490566037736,\n",
       "   'url': 'https://levelup.gitconnected.com/finding-the-best-sector-to-invest-in-using-python-936934fea7d0',\n",
       "   'unique_slug': 'finding-the-best-sector-to-invest-in-using-python-936934fea7d0',\n",
       "   'image_url': 'https://miro.medium.com/0*ldsDKhn0hLacv7S8',\n",
       "   'lang': 'en',\n",
       "   'is_series': False,\n",
       "   'is_locked': False,\n",
       "   'is_shortform': False,\n",
       "   'top_highlight': '',\n",
       "   'content': {'id': '936934fea7d0',\n",
       "    'content': \"Finding the Best Sector to Invest in using Python\\n\\nNavigating the task of picking the right sector using APIs\\n\\nPhoto by Wance Paleri on Unsplash\\n\\nIntroduction\\n\\nIn your trading journey, whether you’re looking for the ideal stock, sector, or indicators, making informed decisions is paramount for your success. However, gathering and analyzing the vast amount of data required can be quite daunting. Bulk Endpoint of the Financial Modeling Prep (FMP) API simplifies this process by providing data for numerous companies with just a single click.\\n\\nWhy is this data so valuable? Well, it’s an asset that can be applied in various ways, especially for both Fundamental and Technical analysis. By comparing data from different companies, you can uncover which one is your best choice in the current market scenario, based on past and present data.\\n\\nFor instance, you can use this data to identify the most promising sector to invest in.\\n\\nIn this article, we’ll guide you through exploring and effectively applying the data from the Bulk Endpoints of the FMP API, making the complex world of trading data accessible and actionable.\\n\\n1. Importing the Packages\\n\\nIt’s essential to set up the right tools. These packages will help you with the capabilities needed to access, process, and analyze the wealth of data you’re about to explore.\\n\\n# IMPORTING PACKAGES\\n\\nimport requests\\nimport pandas as pd\\nfrom io import StringIO\\n\\nRequests: Used for making HTTP requests to access data from web APIs.\\n\\nPandas: Provides data manipulation and analysis tools for working with structured data.\\n\\nStringIO: Allows working with in-memory text data as if it were a file.\\n\\nIf you haven’t installed any of the imported packages, make sure to do so using the pip command in your terminal.\\n\\n2. Exploring the bulk endpoints\\n\\nWith your tools in place, it’s time to navigate to the bulk endpoints of the FMP API. The endpoints are a source of immense data.\\n\\nAccessing any of these endpoints follows the same steps, detailed further as a code snippet. Exploring these endpoints provides a comprehensive understanding of the available data, offering a wide range of information accessible with a single click, covering multiple companies and various financial aspects. This step aims to make you familiar with the data sources at your disposal.\\n\\nFor our application, we will utilize the income statement endpoint to analyze a sector for potential investment. Feel free to combine multiple data points to suit your needs.\\n\\napi_key = 'YOUR API KEY'\\nurl = f'https://financialmodelingprep.com/api/v4/income-statement-bulk?year=2020&period=annual&apikey={api_key}'\\nresponse = requests.get(url)\\ndf_income = pd.read_csv(StringIO(response.text))\\n\\nUse your API to make requests to the various URL endpoints and convert them to dataframes using the above code.\\n\\n3. Data Preprocessing\\n\\nData preprocessing is the vital step of cleaning and organizing the information you’ve acquired. The process transforms raw data into a usable form, making it ready for your trading insights.\\n\\ndf_income  = df_income[['symbol','date','revenue', 'grossProfit', 'operatingIncome', 'EBITDA', 'netIncome']]\\n\\nWe choose these columns from the dataset to decide the sector.\\n\\n‘revenue’: Total revenue is a fundamental indicator of a company’s financial health.\\n\\n‘grossProfit’: Gross profit is a measure of profitability before operating expenses.\\n\\n‘operatingIncome’: Operating income shows how well a company is performing in its core operations.\\n\\n‘EBITDA’: Earnings Before Interest, Taxes, Depreciation, and Amortization is a key metric for assessing operating performance.\\n\\n‘netIncome’: Net income is the bottom line and represents the company’s profitability after all expenses.\\n\\nUsing these three industry giants as representative examples for each sector, we have selected Apple, Google, and Microsoft to symbolize the technology sector. In the same lines, for healthcare and finance sectors, we chose Johnson & Johnson (JNJ), Pfizer Inc. (PFE), UnitedHealth Group Inc. (UNH), JPMorgan Chase & Co. (JPM), The Goldman Sachs Group, Inc. (GS), and Citigroup Inc. ©. These companies serve as barometers for their respective sectors. A decline in their performance parameters often signals a weakening sector. Feel free to use multiple companies as sector indicators.\\n\\nTechnology = df_income.loc[(df_income['symbol'] == 'AAPL') | (df_income['symbol'] == 'GOOGL') | (df_income['symbol'] == 'MSFT')]\\nHealthcare = df_income.loc[(df_income['symbol'] == 'JNJ') | (df_income['symbol'] == 'PFE') | (df_income['symbol'] == 'UNH')]3\\nFinance = df_income.loc[(df_income['symbol'] == 'JPM') | (df_income['symbol'] == 'GS') | (df_income['symbol'] == 'C')]\\n\\nTechnology.sum(axis = 0)\\n\\nTechnology\\n\\nHealthcare.sum()\\n\\nHealthcare\\n\\nFinance.sum()\\n\\nFinance\\n\\n4. Finding the right sector\\n\\nBy comparing and analyzing this data, you’ll be able to pinpoint the sectors that show the most potential for your investment strategies. It strengthens us to make informed decisions when selecting the right sector to invest in.\\n\\ndef findSector(tech, health, finance):\\n    h = 0\\n    t = 0\\n    f = 0\\n    \\n    for i in ['revenue', 'grossProfit', 'operatingIncome', 'EBITDA', 'netIncome']:\\n        if tech.sum()[i] > health.sum()[i] and tech.sum()[i] > finance.sum()[i]:\\n            t = t + 1\\n        if health.sum()[i] > tech.sum()[i] and health.sum()[i] > finance.sum()[i]:\\n            h = h + 1\\n        if finance.sum()[i]>tech.sum()[i] and finance.sum()[i]>health.sum()[i]:\\n            f = f + 1  \\n    if f > t and f > h:\\n        print('Invest In Finance')\\n    if h > t and h > f:\\n        print('Invest in Healthcare')\\n    else:\\n        print('Invest in Healthcare')  \\n\\nfindSector(Technology, Healthcare, Finance)\\n\\nOutput:\\n\\nInvest in Healthcare\\n\\nThis function takes three data frames as arguments: tech, health, and finance. It compares the total sums of specific financial metrics, such as revenue, gross profit, operating income, EBITDA, and net income, for three sectors: technology (tech), healthcare (health), and finance (finance). The code iterates through these metrics, counting how many times one sector’s total sum is greater than the other two sectors for each metric. Based on these counts, it determines which sector has the highest total sum across the metrics.\\n\\nIn our case, it is the healthcare sector to invest in rather than the other two sectors, by comparing the important indicators of the representative companies.\\n\\nConclusion\\n\\nThe article demonstrates the remarkable potential of the Financial Modeling Prep (FMP) API’s Bulk Endpoints in streamlining access to trading data. It acts as a pivotal tool for well-informed trading choices by providing a dataset suitable for both Fundamental and Technical analysis.\\n\\nIn the world of trading, where data reigns supreme, the FMP API’s Bulk Endpoints offer traders and investors a powerful means to make data-backed decisions. It’s a transformative resource for those seeking success in their trading endeavors.\\n\\nWith that being said, you’ve reached the end of the article. Hope you learned something new and useful today. Let me know what you think of this API in the comments. Thank you for your time.\"}}],\n",
       " '76398be9016': [{'id': '5d39cff63d52',\n",
       "   'title': 'Understanding Google’s GPT Killer- The Pathways Architecture',\n",
       "   'subtitle': 'The reason why their model Bard will be much more than a language model',\n",
       "   'author': '76398be9016',\n",
       "   'publication_id': '9758482ba857',\n",
       "   'published_at': '2023-02-18 11:44:10',\n",
       "   'last_modified_at': '2023-04-27 03:18:12',\n",
       "   'tags': ['machine-learning',\n",
       "    'artificial-intelligence',\n",
       "    'technology',\n",
       "    'programming',\n",
       "    'data-science'],\n",
       "   'topics': ['artificial-intelligence', 'machine-learning'],\n",
       "   'claps': 315,\n",
       "   'voters': 70,\n",
       "   'word_count': 2156,\n",
       "   'responses_count': 4,\n",
       "   'reading_time': 9.335849056603774,\n",
       "   'url': 'https://medium.com/geekculture/understanding-googles-gpt-killer-the-pathways-architecture-5d39cff63d52',\n",
       "   'unique_slug': 'understanding-googles-gpt-killer-the-pathways-architecture-5d39cff63d52',\n",
       "   'image_url': 'https://miro.medium.com/0*TPGsdVpfJ5-bmA9Z.jpeg',\n",
       "   'lang': 'en',\n",
       "   'is_series': False,\n",
       "   'is_locked': False,\n",
       "   'is_shortform': False,\n",
       "   'top_highlight': '',\n",
       "   'content': {'id': '5d39cff63d52',\n",
       "    'content': 'Understanding Google’s GPT Killer- The Pathways Architecture\\n\\nThe reason why their model Bard will be much more than a language model\\n\\nJoin 31K+ AI People keeping in touch with the most important ideas in Machine Learning through my free newsletter over here\\n\\nIn one of my recent articles, I wrote about why Bard will be much more powerful than ChatGPT. One of the reasons I gave was their unique system for training models, Pathways. A lot of you reached out and asked me to cover the Pathways architecture in more detail. So that is what I will be doing. In this article/post, I will be covering the key design decisions that differentiate the Pathways architecture from competitors.\\n\\nTo highlight how powerful these design ideas are, we will also be looking at the results of an amazing model that was created using Pathways last year Google’s Pathways Language Model (PaLM). PaLM is \"a 540-billion parameter, dense decoder-only Transformer model trained with the Pathways system\". It gained a lot of notoriety in the AI space for its ability to explain jokes-\\n\\nThis ability to explain jokes is an indication that the PaLM model has a deeper understanding of meaning and sentence structure, and relationships between words. If I had to guess, this was made possible by the attention mechanism and the scale of the model itself.\\n\\nHowever, people mostly overlooked the Pathways architecture. We will not. Some of the innovations covered it implemented are very unique and might be huge in AI in the coming decades. To understand this, let’s go over the amazing Pathways system, which debuted in the writeup, Introducing Pathways: A next-generation AI architecture.\\n\\nWhy Pathways is a revolution.\\n\\nThe inspiration for the infrastructure is our brain. I know every Neural Network says that, but this is much closer than others. How? Think back to how our brains work. We have a ton of neurons with hundreds of trillions of potential wiring. As we learn certain skills, neurons fire together and build certain pathways. These pathways solidify as we practice. The next time we use that skill, our pathways will fire up, allowing us to remember that skill.\\n\\nResearchers at Google did something similar. They built a giant model with tons of neurons and connections. They trained that one model on multiple tasks. And they implemented Sparse Activation so to save resources. It’s hard to argue with the results.\\n\\nKeep in mind, that the y-axis is an improvement over SOTA (State of the Art). This is all one model. Insane\\n\\nThese implementation decisions are uncommon when compared to the way Machine Learning is conducted now. The researchers at Google raise a lot of points about why their approach is better than what is being done right now. Let’s cover these, and talk about how they add another dimension to the current discourse around Deep Learning. To do that, let’s first list out what makes Pathways closer to our own way of learning.\\n\\nHow Pathways takes inspiration from NeuroScience\\n\\nThere are several design choices that make the Pathways infrastructure much closer to our own minds. The big ones include\\n\\nMulti-Task Training- Instead of training 1 Model for one Task, Pathways trains one model to do multiple things. Not transfer to multiple tasks. Directly do them. Like how we can learn to do multiple things over the same time frame.\\n\\nUse of Multiple Senses- What will your input be? Video, Text, Sounds, Binary…? Why not all of the above. Think about how our minds combine multiple senses every day.\\n\\nSparse Activation- Training large models is expensive because you have to propagate through all those parameters. What if for a specific task, you only used a small portion of the network to train and run. We don’t use all our minds for all the tasks. Writing and dancing use different neurons.\\n\\nLet’s explore this in more detail.\\n\\nMulti-Task Training\\n\\nIn normal Machine Learning, we take a model architecture and train it from Scratch to teach it our specific task. But Google researchers are like edgy teens and are terrified of being seen as normal. They strive to express their individuality.\\n\\nPathways will enable us to train a single model to do thousands or millions of things\\n\\n-From the Pathways introduction article.\\n\\nInstead, they train the same model on many different tasks. The same model. Not the same architecture. The exact same model. Imagine a translation app also helping you solve some math problems.\\n\\n\\n\\nWhat is the logic behind this? Let’s take a simple example. We know Cristiano Ronaldo plays Football. To be the freak of nature he is, he takes his physical conditioning very seriously. Thus, when it comes to activities like Running and Jumping, he is going to be much better than your average Joe, even though this is not his focus. Similarly, for a model becomes excellent at one task, it will probably develop some tertiary skills that will carry over to other tasks. In my more advanced readers, this might be ringing a few bells. You have one question-\\n\\nHow is Pathways Training Different from Transfer Learning\\n\\nTransfer Learning is the practice of taking Large Models trained on generic tasks, and then using the insights gained from that to train a related model on a related example. The idea is that the knowledge from the related tasks will \"carry over\" to our new task. In our earlier example, Ronaldo’s training in Football allows him to also be a good Runner.\\n\\n\\n\\nPathways is different because they take this to the next level. When they say millions of things, they mean it. Pathways is trained on tasks that are almost completely unrelated to each other (look at the visualization above). This would be like teaching Ronaldo Differential Equations, while also training him to be an archeologist, as he was prepping to play Football. This is much closer to the idea behind AGI, and what has allowed the PaLM model to develop its much deeper understanding of meaning and language. It is also much closer to how we learn.\\n\\nMultiple Senses\\n\\nSenses are how we perceive the world. This is often overlooked in Machine Learning (especially if you’re primarily a statistical analyst like me) but senses literally determine your input. One of the biggest challenges in converting Machine Learning research into working solutions is in translating the input data into valuable information that can be analyzed. Preprocessing is a big deal. This is why people say that ML is mostly data cleaning and preprocessing.\\n\\nFor AI purposes, each Data Source can be treated as a sense. Most ML applications use limited sources and typically work on only one kind of data (NLP, Computer Vision, Behavior, etc). As you can see in the following passage, Pathways will not be doing this.\\n\\n\\n\\nMore Senses → More sources of Error. This can lead to models more robust than before since they consider more factors.\\n\\nMore senses lead to an exponential increase in capabilities. This is because each sense can be treated as its own space. More senses allow for more possible ways to encode the relations between objects, leading to far more possible embeddings. This will allow you to handle more kinds of inputs and generate more kinds of outputs.\\n\\nThis also mimics the way we interact with the world. We learn by interacting with objects using both our physical (touch, taste, smell, etc.) and mental (creating models, theories, abstractions) senses. Integrating more senses is much harder, but the pay-off is worth it. As the paper, \"Accounting for Variance in Machine Learning Benchmarks\" showed us, adding more sources of variance improves estimators. You can read my breakdown of the paper here, or watch the following YouTube video for a quick explanation. Either way, don’t miss out on this paper.\\n\\nSparse Activation\\n\\nThis is probably the most interesting idea to me in the entire paper. To understand why this is so cool, think back to how Neural Networks work. When we train them, input flows through all the neurons, both in the forward and backward passes. This is why adding more parameters to a Neural Network adds to the cost exponentially.\\n\\nAdding more neurons to our network allows for our model to learn from more complex data (like data from multiple tasks and data from multiple senses). However, this adds a lot of computational overhead. I know that this will come as a complete shock to you, but make sure to breathe. It helps when dealing with such shocking information.\\n\\nPaLM also translates code. They really made their model do everything.\\n\\nSparse Activation allows for a best-of-both-worlds scenario. Adding a lot parameters allows for our computation power. Palm does have 540 Billion Parameters. However, for any given task, only a portion of the network is activated. This allows the network to learn and get good at multiple tasks, without being too costly.\\n\\nWe can build a single model that is \"sparsely\" activated, which means only small pathways through the network are called into action as needed. In fact, the model dynamically learns which parts of the network are good at which tasks - it learns how to route tasks through the most relevant parts of the model. A big benefit to this kind of architecture is that it not only has a larger capacity to learn a variety of tasks, but it’s also faster and much more energy efficient, because we don’t activate the entire network for every task.\\n\\nThe concept kind of reminds me of a more modern twist on the Mixture of Experts learning protocol. Instead of deciphering which expert can handle the task best, we are instead routing the task to the part of the neural network that handles it best. This is similar to our brain, where different parts of our brain are good at different things.\\n\\nSparse Activation is such a cheat code that it provides much cheaper training while giving the same performance. Take a look at this quote from the Pathways writeup-\\n\\nFor example, GShard and Switch Transformer are two of the largest machine learning models we’ve ever created, but because both use sparse activation, they consume less than 1/10th the energy that you’d expect of similarly sized dense models - while being as accurate as dense models.\\n\\nThis shows itself with the PaLM model. Adding more parameters allows for a much greater ability when it comes to tackling challenges. Inferring the nature of the task given, training for it, and being handle to handle it are all expensive procedures. Sparse Activation allows the model to handle all this better.\\n\\n\\n\\nA pretty nifty visualization of the increase in capabilities upon adding more parameters for the PaLM model.\\n\\nI looked around for more details on the Sparsity Algorithm at Google, but couldn’t find too many details on it. If you have any insights/thoughts on it, please do let me know. However, this idea of Sparsity intrigued me a lot when I was researching it. So I looked into a few algorithms. My favorite was Sparse Weight Activation Training or SWAT. I have a video going into more details on it linked below. To those of you that need a reason to watch it- this algorithm can lead to an 8x reduction in FLOPs while keeping your performance drop within 5%.\\n\\n\\n\\nClearly, you can now see how Pathways will be a game-changer for AI research in the upcoming decade. It combines ideas from neuroscience, Machine Learning, and Software Engineering with the scale of Large Language Models to create something exceptional. The training protocols will be era-defining, even as people create other, better ML models. Before we finish, I’d appreciate it if you answered the following poll. You will find it over here on LinkedIn. If you’d like to have more influence on my content, make sure we’re connected over there.\\n\\n\\n\\nThat is it for this piece. I appreciate your time. As always, if you’re interested in working with me or checking out my other work, links will be at the end of this email/post. If you like my writing, I would really appreciate an anonymous testimonial. You can drop it here. And if you found value in this write-up, I would appreciate you sharing it with more people.\\n\\nFor those of you interested in taking your skills to the next level, keep reading. I have something that you will love.\\n\\n\\n\\nUpgrade your tech career with my newsletter ‘Tech Made Simple’! Stay ahead of the curve in AI, software engineering, and tech industry with expert insights, tips, and resources. 20% off for new subscribers by clicking this link. Subscribe now and simplify your tech journey!\\n\\n\\n\\nUsing this discount will drop the prices-\\n\\n800 INR (10 USD) → 533 INR (8 USD) per Month\\n\\n8000 INR (100 USD) → 6400INR (80 USD) per year\\n\\nGet 20% off for upto 1 year\\n\\nReach out to me\\n\\nUse the links below to check out my other content, learn more about tutoring, reach out to me about projects, or just to say hi.\\n\\nIf you like my writing, I would really appreciate an anonymous testimonial. You can drop it here.\\n\\nTo help me understand you fill out this survey (anonymous)\\n\\nCheck out my other articles on Medium. : https://rb.gy/zn1aiu\\n\\nMy YouTube: https://rb.gy/88iwdd\\n\\nReach out to me on LinkedIn. Let’s connect: https://rb.gy/m5ok2y\\n\\nMy Instagram: https://rb.gy/gmvuy9\\n\\nMy Twitter: https://twitter.com/Machine01776819'}},\n",
       "  {'id': '5e142b8931e6',\n",
       "   'title': 'Improve Neural Networks by using Complex Numbers',\n",
       "   'subtitle': 'Can Complex Functions be the next breakthrough in Computer Vision?',\n",
       "   'author': '76398be9016',\n",
       "   'publication_id': '9758482ba857',\n",
       "   'published_at': '2022-11-17 00:59:57',\n",
       "   'last_modified_at': '2023-04-26 21:31:16',\n",
       "   'tags': ['machine-learning',\n",
       "    'artificial-intelligence',\n",
       "    'technology',\n",
       "    'data-science',\n",
       "    'self-improvement'],\n",
       "   'topics': ['machine-learning'],\n",
       "   'claps': 577,\n",
       "   'voters': 116,\n",
       "   'word_count': 1846,\n",
       "   'responses_count': 6,\n",
       "   'reading_time': 8.466037735849056,\n",
       "   'url': 'https://medium.com/geekculture/improve-neural-networks-by-using-complex-numbers-5e142b8931e6',\n",
       "   'unique_slug': 'improve-neural-networks-by-using-complex-numbers-5e142b8931e6',\n",
       "   'image_url': 'https://miro.medium.com/1*huvbsdKFNJp45SoOcgwmHw.png',\n",
       "   'lang': 'en',\n",
       "   'is_series': False,\n",
       "   'is_locked': False,\n",
       "   'is_shortform': False,\n",
       "   'top_highlight': 'Recently, someone in my LinkedIn network shared this very interesting paper with me. Titled, \"CoShNet: A Hybrid Complex Valued Neural Network using Shearlets\", this paper proposes the use of complex functions in a hybrid neural network. If you are very confused by those words, don\\'t worry I was too. In this article, I will explain the idea of hybrid neural networks and how they can be used to improve traditional Convolutional Neural Networks. Then we will cover how using Complex Functions can be used to boost the performance of these models even further. This is going to be a very fun one.',\n",
       "   'content': {'id': '5e142b8931e6',\n",
       "    'content': 'Improve Neural Networks by using Complex Numbers\\n\\nCan Complex Functions be the next breakthrough in Computer Vision?\\n\\nJoin 31K+ AI People keeping in touch with the most important ideas in Machine Learning through my free newsletter over here\\n\\nRecently, someone in my LinkedIn network shared this very interesting paper with me. Titled, \"CoShNet: A Hybrid Complex Valued Neural Network using Shearlets\", this paper proposes the use of complex functions in a hybrid neural network. If you are very confused by those words, don’t worry I was too. In this article, I will explain the idea of hybrid neural networks and how they can be used to improve traditional Convolutional Neural Networks. Then we will cover how using Complex Functions can be used to boost the performance of these models even further. This is going to be a very fun one.\\n\\nThe resulting network is called Complex Shearlets Network (CoShNet). It was tested on Fashion-MNIST against ResNet-50 and Resnet-18, obtaining 92.2% versus 90.7% and 91.8% respectively. The proposed network has 49.9k parameters versus ResNet-18 with 11.18m and use 52 times fewer FLOPs. Finally, we trained in under 20 epochs versus 200 epochs required by ResNet and do not need any hyperparameter tuning nor regularization.\\n\\n-In case you’re looking for a reason to be excited about the this idea.\\n\\nUnderstanding Convolutional Neural Networks\\n\\nConvolutional Neural Networks have been the OG Computer Vision Architecture since their inception. In fact, the foundations of CNNs are older than I am. CNNs were literally built for vision.\\n\\nThe feature extraction is the true CNN revolution. Taken from IBM’s Writeup on ConvNets\\n\\nSo what’s so good about CNNs? The main idea behind Convolutional Neural Nets is that they go through the image, segment by segment, and extract the main features from it. The earlier layers of the CNN often extract the more crude features, such as edges and colors. However, adding more layers allows for feature extraction at a very high resolution of detail.\\n\\nCNNs use the sliding window technique to build their feature maps. As you can see, Good Machine Learning requires good software engineering. Image Source\\n\\nThis article goes into CNNs in more detail. For our purposes one thing is important: CNNs have been the go-to for Computer Vision primarily due to their ability to build feature maps. Even with the rise of Vision Transformers, CNNs have held strong (provided you modernize the pipeline using the techniques given below).\\n\\nFacebook AI and UC Berkley pick a fight with Transformers\\nWith all the insane hype around GPT3, DALLE, PaLM, and many more, now is the perfect time to cover this paper.medium.com\\n\\nSo far, so good. So what’s the catch? There is one problem with their approach. The convolutions (building feature maps) can get really expensive.\\n\\nEnter Hybrid Neural Networks\\n\\nIf you’ve studied even a bit of Computer Science (which you should do be effective at ML), you will realize something about the Feature Mapping process. It is really expensive. You have to slide the window across multiple times. As we’ve already stated, the earlier layers only extract the crude features. The high-resolution features are only spotted at the later levels. This is where some really smart people saw an opportunity. What if we did some Math to find a function that can help us spot some low-level features directly? This way we can spot the features without going through the expensive early convolutions-\\n\\nIn a hybrid neural network, the expensive convolutional layers are replaced by a non-trainable fixed transform with a great reduction in parameters.\\n\\nIf you could find a good function, then you’ve significantly reduced your computational overhead. And we have some great functions that can do this. Turns out Complex Functions just work better. Look at the image below and the difference in results.\\n\\n\\n\\nThis image is the perfect segue into the next section. Let’s now talk about all the advantages that Complex Functions bring to our Neural Networks, and why they work so well in the first place. Some of this can get pretty mathematical, but if you feel that way, make sure you close your eyes and think about what the Deep Learning bros on Twitter tell you about not needing Math for Machine Learning. True Machine Learning is about overfitting big models to neat data, and not this technical mathy stuff (that involves a lot of experimentation).\\n\\nWhy You need Math for Machine Learning\\nAnd how much you need to do well in Machine Learningmedium.com\\n\\nSo let’s get into Complex Functions in Hybrid Networks (and specifically the Complex Shearlets function).\\n\\nThe basic idea behind Hybrid NNs and this paper\\n\\nThe amazing CoSh Network\\n\\nBefore I get into the details, here is a concise look at some of the amazing things this network can accomplish. This should tell you why I’m covering this idea (and hopefully illustrate why I spend my weekend reading random ML papers).\\n\\n\\n\\nYou already know I’m very excited about these results. A cost-effective ML solution built using Math? One that generalizes very well? I’m getting excited just typing this. However, one thing that really stood out to me was this network\\'s resilience to noise and perturbation. This is something that I’ve been covering since I started writing and these results are very exciting as a way to counter that.\\n\\nResearchers Discover Possible Reason why Adversarial Perturbation Works\\nThis was an interesting papermedium.com\\n\\nTake a look at this graph where they tested the network with permutations of clean and perturbed datasets. The results are shockingly stable, especially considering the relatively small training dataset size. I normally expect this robustness from bigger datasets.\\n\\n\\n\\nFanboying out of the way, why does this happen? What is the reason that this can work so well? Is this a fluke, or is there something about Complex Function that works very well?\\n\\nIf we can understand what makes these amazing results tick, we can create much better solutions.\\n\\nLet’s move on to why Complex Functions might be the next leap in Deep Learning.\\n\\nThis is in stark contrast to a recent paper [41] \".. the necessity to optimize jointly the architecture and the training procedure: ..having the same training procedure is not sufficient for comparing the merits of different architectures.\" Which is the opposite of what one wants to have - a no-fuss, reliable training procedure for different datasets and models.\\n\\n— The authors show that tuning and expensive search is not the only way.\\n\\nThe Magical Properties of Complex Functions\\n\\nThere are some very interesting properties that make Complex Neural Networks special. First, let’s talk about the decision boundaries. Complex Neurons create the following boundaries-\\n\\n\\n\\nNothing surprising here. However, this brings up some interesting properties, especially with generalization. According to the authors-\\n\\nThe decision boundary of a CVnn consists of two hypersurfaces that intersect orthogonally (Fig. 7) and divides a decision region into four equal sections. Furthermore, the decision boundary of a 3-layer CVnn stays almost orthogonal [27]. This orthogonality improves generalization. As an example, several problems (e.g. Xor) that cannot be solved with a single real neuron, can be solved with a single complex-valued neuron using the orthogonal property\\n\\nThe next stand-out to me is the presence of Saddle-Points. Saddle points occur in multivariable functions. They are critical points where the function attains neither a local maximum value nor a local minimum value.\\n\\nImage Source\\n\\nWhy does this matter? At saddle points, the derivatives of loss functions are still equal to 0. However, as the authors state, \"SGD with random inits can largely avoid saddle points [29] [30], but not a local minimum.\" This behavior is probably what allows for much faster convergence since the algorithms won’t get stuck in local minima. Such an approach provides very similar benefits to the integration of Random Restarts to sample a larger search space. The authors even mention that this CoShNet doesn’t need data augmentation to reach Stable Embeddings (with respect to perturbation).\\n\\nIf you have experience with split-ReLU, let me know.\\n\\nBoth of these properties act in the same direction- they allow the network to achieve more with much less.\\n\\n\\n\\nThere is one final property that deserves its own section. Time to get into Phase Congruency and how it helps in adversarial robustness.\\n\\nPhase Congruency\\n\\nIn electronic signaling, phase is a definition of the position of a point in time (instant) on a waveform cycle. Phase can also be an expression of relative displacement between or among waves having the same frequency (source). This video provides a visual representation. Phases are very important in signal processing.\\n\\n\\n\\nIf the Phase can stay stable after perturbation, then we can extract stable features. This aligns well with the analysis MIT paper I shared earlier on why perturbation happens. \"CoShRem can extract stable features - edges, ridges and blobs - that are contrast invariant. In Fig 6.b we can see a stable and robust (immune to noise and contrast variations) localization of critical features in an image by using agreement of phase.\"\\n\\nGradients fluctuate wildly across scale but phase remains very stable at critical parts of the image. This makes phase a great base for detecting important features.\\n\\nWhen it comes to detecting features (and their magnitudes) in images where perturbation applies, this works very well.\\n\\n\"Fig 4 shows despite the considerable perturbations (blurring and Gaussian noise), CoShRem remain stable to most of the characteristic edges and ridges (two step discontinuity in close proximity).\"\\n\\nThis phase congruency works wonders in creating models that are robust. I would be interested in seeing how this performance stacks up against more specialized adversarial networks (like the One Pixel Attack). That would be a true test of robustness.\\n\\nI would like to talk more about this, but a lot of this is related to signal processing. And I know nothing about that. I know enough Math to look through and understand the major ideas/derivations but I’m not fully confident I understand some of the details about phase and complex wavelets. If you have any experiences/resources on this topic leave them in the comments. I’d love to learn from you.\\n\\nI’ll be looking more into complex functions and analysis after this paper, because it seems extremely powerful. Expect a follow-up with more details/ideas on how complex functions might be usable in networks. If you have any questions/clarifications, you can reach out to Manny Ko. He is a Principal Engineer at Apple and one of the authors of this paper. He shared this writeup with me, and definitely knows more than me about this subject.\\n\\n\\n\\nIf you liked this write-up, you would like my daily email newsletter Technology Made Simple. It covers topics in Algorithm Design, Math, AI, Data Science, Recent Events in Tech, Software Engineering, and much more to make you a better developer. I am currently running a 20% discount for a WHOLE YEAR, so make sure to check it out. Using this discount will drop the prices-\\n\\n800 INR (10 USD) → 533 INR (8 USD) per Month\\n\\n8000 INR (100 USD) → 6400INR (80 USD) per year\\n\\nYou can learn more about the newsletter here\\n\\n\\n\\nReach out to me\\n\\nUse the links below to check out my other content, learn more about tutoring, or just to say hi. Also, check out the free Robinhood referral link. We both get a free stock (you don’t have to put any money), and there is no risk to you. So not using it is just losing free money.\\n\\nTo help me understand you fill out this survey (anonymous)\\n\\nCheck out my other articles on Medium. : https://rb.gy/zn1aiu\\n\\nMy YouTube: https://rb.gy/88iwdd\\n\\nReach out to me on LinkedIn. Let’s connect: https://rb.gy/m5ok2y\\n\\nMy Instagram: https://rb.gy/gmvuy9\\n\\nMy Twitter: https://twitter.com/Machine01776819\\n\\nIf you’re looking to build a career in tech: https://codinginterviewsmadesimple.substack.com/\\n\\nGet a free stock on Robinhood: https://join.robinhood.com/fnud75'}},\n",
       "  {'id': '92296297a541',\n",
       "   'title': 'How Amazon makes Machine Learning Trustworthy',\n",
       "   'subtitle': 'With all the discussion around Bias in ChatGPT and Machine Learning, these techniques might be very helpful',\n",
       "   'author': '76398be9016',\n",
       "   'publication_id': '9758482ba857',\n",
       "   'published_at': '2022-12-12 11:48:18',\n",
       "   'last_modified_at': '2023-05-06 19:42:01',\n",
       "   'tags': ['machine-learning',\n",
       "    'artificial-intelligence',\n",
       "    'technology',\n",
       "    'data-science',\n",
       "    'programming'],\n",
       "   'topics': ['artificial-intelligence', 'machine-learning'],\n",
       "   'claps': 41,\n",
       "   'voters': 13,\n",
       "   'word_count': 1776,\n",
       "   'responses_count': 1,\n",
       "   'reading_time': 8.05188679245283,\n",
       "   'url': 'https://medium.com/geekculture/how-amazon-makes-machine-learning-trustworthy-92296297a541',\n",
       "   'unique_slug': 'how-amazon-makes-machine-learning-trustworthy-92296297a541',\n",
       "   'image_url': 'https://miro.medium.com/0*_ej-xHk4ROErgvkz',\n",
       "   'lang': 'en',\n",
       "   'is_series': False,\n",
       "   'is_locked': False,\n",
       "   'is_shortform': False,\n",
       "   'top_highlight': 'Machine Learning has swept the world recently. Thanks to all the amazing results companies have been rushing to adopt Data-Driven decision-making into their processes. Given all the amazing demos by DALLE, StableDiffusion, and now ChatGPT, more and more people are waking up to the potential of AI. However, some people have been raising concerns about the potential for harm that these models have. Recently, ChatGPT has gained some attention, because users have discovered that it can generate some spicy outputs. Take a look at how ChatGPT can identify good scientists based on their race and gender.',\n",
       "   'content': {'id': '92296297a541',\n",
       "    'content': 'How Amazon makes Machine Learning Trustworthy\\n\\nWith all the discussion around Bias in ChatGPT and Machine Learning, these techniques might be very helpful\\n\\nJoin 31K+ People keeping in touch with the most important ideas and development in AI and Machine Learning through my free newsletter over here\\n\\nMachine Learning has swept the world recently. Thanks to all the amazing results companies have been rushing to adopt Data-Driven decision-making into their processes. Given all the amazing demos by DALLE, StableDiffusion, and now ChatGPT, more and more people are waking up to the potential of AI. However, some people have been raising concerns about the potential for harm that these models have. Recently, ChatGPT has gained some attention, because users have discovered that it can generate some spicy outputs. Take a look at how ChatGPT can identify good scientists based on their race and gender.\\n\\nFor a non-clickbait, non-inflammatory analysis of this output and why this matters, check out this post. Too many commentators have been focusing on the wrong things.\\n\\nBias in Data Science and Deep Learning is nothing new. Neither is the susceptibility of large models to bias and replicating the prejudice encoding in datasets. I’ve been talking about it for 2 years now. But understanding how to handle this is now more important than ever. And luckily, the tech giant Amazon has made some great strides in this area. In this article, I will be breaking down their publication- Advances in trustworthy machine learning at Alexa AI- where they share some of the techniques they use to create AI that is safer and fairer.\\n\\nOne example of trying to get rid of bias in the dataset. Amazon’s Model ignores the gendered language in the prompt. FROM \"MITIGATING GENDER BIAS IN DISTILLED LANGUAGE MODELS VIA COUNTERFACTUAL ROLE REVERSAL\"\\n\\nIf you are interested in creating better ML pipelines, then this is not a topic you want to miss out on. Let’s get right into it.\\n\\nTechnique 1: Privacy-preserving ML\\n\\nTo understand this and why this is important, let’s first understand a fundamental fact about machine learning. ML models take some input and generate some outputs. The outputs generated depend on the rules that the model discovered during the training phase. This goes without saying, but the rules depend on the input we feed the model. Pretty obvious to most people. So why am I talking about it?\\n\\nTurns out this carries some privacy risks with it. There is a chance that outputs can be used to infer details about the inputs. Your data can end up in the hands of people you never consented to. This is where the idea of differential privacy comes in. To quote the publication, \"The intuition behind differential privacy (DP) is that access to the outputs of a model should not provide any hint about what inputs were used to train the model.\"\\n\\nHow is this calculated? \"DP quantifies that intuition as a difference (in probabilities) between the outputs of a model trained on a given dataset and the outputs of the same model trained on the same dataset after a single input is removed. \" In this manner, it reminds me of the permutation-based feature importance, but instead of shuffling through features, we are dropping values. This is an interesting way to quantify the impact of a single sample on your training process.\\n\\n\\n\\nOne of the primary ways that Amazon accomplishes this is through the use of input noise. I’ve covered the greatness of adding randomness to your Deep Learning pipelines extensively. However, based on their writing, it seems Amazon tries a slightly different direction. Instead of using noise as a means of adding chaos, they use the noise to hide the relationship of parameters to the training data. The image below gives an example.\\n\\nTaken from their publication Improving the accuracy of privacy-preserving neural networks\\n\\nThe way I normally recommend is meant to improve the generalization and robustness of pipelines. And obviously, adding completely random noise would help with privacy. However, it can lead to a drop in performance. Amazon’s approach is better for maintaining higher performance. However, remember that to make the most of Amazon’s approach, you need to make sensible substitutions. You can’t replace Boston with Sausage. Finding the right substitutions might add to your computing costs. This is acknowledged by the authors-\\n\\nAnother side effect of adding a DP mechanism is increased training time.\\n\\nAmazon also did some pretty interesting research into how people could reconstruct training samples using various techniques. To learn more about it, and its defensive countermeasures, check out their publication Canary extraction in natural language understanding models\\n\\n\\n\\nAlphaSignal is a free weekly Summary of the top developments in Machine Learning. They use AI to rank and send you the top developments in the field. If you’re looking for something to help stay in touch with the pace of Machine Learning, check them out. Reading them is a great way to stay in touch with the field and support my writing at no cost to yourself.\\n\\nAlpha Signal | The Best of Machine Learning. Summarized by AI.\\nStay in the loop without spending countless hours browsing for the next breakthrough; our algorithm identifies the…alphasignal.ai\\n\\nTechnique 2: Federated Learning\\n\\nThink of all the Alex Devices, Prime Video apps, and different devices people use for their Amazon accounts. If Amazon directly sent the data back to the centers, their costs would spiral out of control. Not to mention, the huge privacy red flag of Amazon Data centers storing your conversations, shopping, etc. Clearly, this is not a good idea. But then, how would you update the models based on new user interactions?\\n\\nWhat if you just let the models be updated on the local device? Say, one day I watch a lot of horror movies on Prime on my phone. So we update the recommendation systems on my phone to account for my new tastes. Once these updates have been made, I share the updates with the Amazon centers. You, my love, have just learned about federated learning.\\n\\n\\n\\nThis has several benefits. Firstly, the data of model updates are much smaller than the raw data, which makes it much cheaper to process and store. Secondly, this comes with a huge benefit when it comes to privacy. Even if someone did gain access to this data, all they’d see is mumbo jumbo. The model update data is not human-readable, so no one can see what shows you’ve been binging. And without knowing the exact architecture, it can’t be plugged into models to reconstruct your habits.\\n\\nPhoto by Mick Haupt on Unsplash\\n\\nTechnique 3: Fairness in ML\\n\\nAn overlooked problem in Machine Learning is the presence of biased datasets. Biased datasets typically occur when you sample data from data sources that don’t accurately represent underlying stats. For example, imagine you wanted to get the national opinion on a new policy. But in your survey, you get responses from mostly college kids. In this case, your analysis will be biased because your nation is not mostly college kids. Biased datasets are a bigger problem than most people realize.\\n\\nTake the racist ChatGPT example I shared at the start of this article. Most big-brained LinkedIn influencers were happy just calling it racist and ending their analysis there. However, that is inaccurate. In reality, this is most likely the case of biased data samples. ChatGPT probably scraped datasets that were predominately American, and thus created its analysis on that. I’m basing this on the fact that my race (Indian/South-East Asian) wasn’t even mentioned in its ranking of races based on intellect (we were put in the other category). Given how many SE Asians there are, it doesn’t make sense to not have them as their own race. Unless you consider the fact that in American datasets, Latinos are mentioned a lot more than SE-Asians (or Aboriginals, etc). Here is the aforementioned ranking-\\n\\n\\n\\nThe problem of LLMs having biased datasets was mentioned by Amazon-\\n\\nNatural-language-processing applications’ increased reliance on large language models trained on intrinsically biased web-scale corpora has amplified the importance of accurate fairness metrics and procedures for building more robust models.\\n\\nTheir publication \"Mitigating social bias in knowledge graph embeddings\" goes into this in a lot more detail. It covers several interesting ways the biases exist.\\n\\n\\n\\nThey use various techniques like attribute substitution to counter the biases that would otherwise become encoded in the knowledge graphs.\\n\\n\\n\\nAside from this, they also studied the metrics used to quantify fairness. In the paper, \"On the intrinsic and extrinsic fairness evaluation metrics for contextualized language representations\", they showed that the usual metrics used to measure fairness reflect the biases of their datasets-\\n\\n\\n\\nTo combat this, Amazon created a few metrics of its own.\\n\\nFROM \"MEASURING FAIRNESS OF TEXT CLASSIFIERS VIA PREDICTION SENSITIVITY\"\\n\\nTo overcome the problem of gendered biases in public datasets, Amazon implements the following procedure-\\n\\nWe propose two modifications to the base knowledge distillation based on counterfactual role reversal - modifying teacher probabilities and augmenting the training set.\\n\\n-Source, Mitigating gender bias in distilled language models via counterfactual role reversal\\n\\nOnce again, Data Augmentation seems to be a very important element. In this case, it is used to balance the underlying data distributions. By doing so, they are able to create much fairer models.\\n\\nI’m going to end this article with an interesting observation. Much of the procedures that Amazon uses to achieve are nothing special. There are no gimmicks, nothing that really makes you scratch your head. Instead, the majority of techniques mentioned here (and in their papers) are just reasonable solutions executed at very high levels. Yes, AI is a rapidly changing field with constant changes. However, many of these improvements are based on good solid fundamentals. Learning about them will allow you to stay in touch with the most important developments.\\n\\n\\n\\nIf you liked this write-up, you would like my daily email newsletter Technology Made Simple. It covers topics in Algorithm Design, Math, AI, Data Science, Recent Events in Tech, Software Engineering, and much more to make you a better developer. I am currently running a 20% discount for a WHOLE YEAR, so make sure to check it out. Using this discount will drop the prices-\\n\\n800 INR (10 USD) → 533 INR (8 USD) per Month\\n\\n8000 INR (100 USD) → 6400INR (80 USD) per year\\n\\nYou can learn more about the newsletter here. If you’d like to talk to me about your project/company/organization, scroll below and use my contact links to reach out to me.\\n\\nReach out to me\\n\\nUse the links below to check out my other content, learn more about tutoring, reach out to me about projects, or just to say hi.\\n\\nFree Weekly Summary of the important updates in Machine Learning(sponsored)- https://lnkd.in/gCFTuivn\\n\\nTo help me understand you fill out this survey (anonymous)\\n\\nCheck out my other articles on Medium. : https://rb.gy/zn1aiu\\n\\nMy YouTube: https://rb.gy/88iwdd\\n\\nReach out to me on LinkedIn. Let’s connect: https://rb.gy/m5ok2y\\n\\nMy Instagram: https://rb.gy/gmvuy9\\n\\nMy Twitter: https://twitter.com/Machine01776819\\n\\nIf you’re looking to build a career in tech: https://codinginterviewsmadesimple.substack.com/\\n\\nGet a free stock on Robinhood: https://join.robinhood.com/fnud75'}},\n",
       "  {'id': 'fcad692b1456',\n",
       "   'title': 'Why Tree-Based Models Beat Deep Learning on Tabular Data',\n",
       "   'subtitle': 'A much-needed reality check for AI Researchers and Engineers caught up in the hype around Deep Learning',\n",
       "   'author': '76398be9016',\n",
       "   'publication_id': '9758482ba857',\n",
       "   'published_at': '2022-08-27 00:08:15',\n",
       "   'last_modified_at': '2023-05-01 22:04:24',\n",
       "   'tags': ['data-science',\n",
       "    'artificial-intelligence',\n",
       "    'machine-learning',\n",
       "    'technology',\n",
       "    'programming'],\n",
       "   'topics': ['artificial-intelligence', 'machine-learning', 'data-science'],\n",
       "   'claps': 609,\n",
       "   'voters': 179,\n",
       "   'word_count': 1691,\n",
       "   'responses_count': 5,\n",
       "   'reading_time': 7.581132075471698,\n",
       "   'url': 'https://medium.com/geekculture/why-tree-based-models-beat-deep-learning-on-tabular-data-fcad692b1456',\n",
       "   'unique_slug': 'why-tree-based-models-beat-deep-learning-on-tabular-data-fcad692b1456',\n",
       "   'image_url': 'https://miro.medium.com/1*TXcH3Sgw-prj4DrM0GUmWQ.png',\n",
       "   'lang': 'en',\n",
       "   'is_series': False,\n",
       "   'is_locked': False,\n",
       "   'is_shortform': False,\n",
       "   'top_highlight': \"This was the first reason that the authors shared that Deep Learning Neural Networks couldn't compete with Random Forests. Simply put, when it comes to non-smooth functions/decision boundaries, Neural Networks struggle to create the best-fit functions. Random Forests do much better with weird/jagged/irregular patterns.\",\n",
       "   'content': {'id': 'fcad692b1456',\n",
       "    'content': 'Why Tree-Based Models Beat Deep Learning on Tabular Data\\n\\nA much-needed reality check for AI Researchers and Engineers caught up in the hype around Deep Learning\\n\\nJoin 31K+ AI People keeping in touch with the most important ideas in Machine Learning through my free newsletter over here\\n\\nWith all the hype around Deep Learning and the new 100-Million Parameter models, it can be easy to forget that these large neural networks are just tools, and they have all their biases and weaknesses. One of the ideas that I stress through my content is that you should have a strong base of diverse skill-sets so that you can solve problems in an effective and efficient manner.\\n\\nIn this article, I will be breaking down the paper- Why do tree-based models still outperform deep learning on tabular data? The paper explains a phenomenon observed by Machine Learning Practitioners all over the world working in all kinds of domains- Tree Based models (like Random Forests), have been much better than Deep Learning/Neural Networks when it comes to analyzing tabular data. I will be sharing their findings to help you understand why this happens, and how you can use these lessons to create the best AI pipelines to handle the challenges you come across.\\n\\nDon’t show this graph to all the people with ‘Deep Learning Expert|Podcaster|Blockchain|Software’ in their bio. They will probably start screeching and get violent.\\n\\nPoints to note about the Paper\\n\\nBefore we start looking at the discoveries made by the paper, we should first understand some important aspects of the paper. This will help us contextualize the findings and better evaluate the results. Too many people skip straight to the results and don’t take enough time to evaluate the context. This is a fatal sin, and if you do this, I will stop loving you.\\n\\nOne thing that stood out to me was that the paper had a lot of preprocessing. Some like removing Missing Data will handicap Tree Performance. As I’ve covered in this article- How to handle missing environmental data, Random Forests are very good for situations with missing data. I used them a lot when I was working with Johns Hopkins University to build a system to predict how changing health-system policy would affect public health. The data was extremely noisy, with tons of features and dimensions. The robustness and benefits of RF made them better than more ‘advanced’ solutions, which would break very easily.\\n\\n\\n\\nMost of this is pretty standard stuff. I’m personally not a huge fan of applying too many preprocessing techniques because it can lead to you losing a lot of nuance about your dataset, but the steps taken here would produce datasets that are similar to the ones found when working. However keep these constraints in mind when evaluating your final results, because they will matter. If your datasets look very different, then take these results with a pinch of salt.\\n\\nThey also used random search for hyperparameter tuning. This is also industry standard, but in my experience, Bayesian Search is much better for sweeping through more extensive search spaces. I’ll make a video on it soon, so make sure you’re following my YouTube channel to stay updated with it. The link to that (and all my other work) will be at the end of this article.\\n\\nWith that out of the way, time to answer the main question that you clicked this article- Why do Tree-Based Methods beat Deep Learning?\\n\\nReason 1: Neural Nets are biased to overly smooth solutions\\n\\nThis was the first reason that the authors shared that Deep Learning Neural Networks couldn’t compete with Random Forests. Simply put, when it comes to non-smooth functions/decision boundaries, Neural Networks struggle to create the best-fit functions. Random Forests do much better with weird/jagged/irregular patterns.\\n\\n\\n\\nIf I had to guess why, one possible reason could be the use of a gradient in Neural Networks. Gradients rely on differentiable search spaces, which are by definition smooth. Pointy, broken, and random functions can’t be differentiated. This is one of the reasons that I recommend learning about AI concepts like Evolutionary Algorithms, traditional searches, and more basic concepts, that can be used for great results in a variety of situations when NNs fail.\\n\\nFor a more concrete example of the difference in Decision Boundaries between the tree-based methods(RandomForests) and Deep Learners take a look at the image below-\\n\\nThe better performance of RFs can be attributed to the more precise decision boundaries they generate.\\n\\nIn the Appendix, the authors had the following statement wrt to the above visualization\\n\\nIn this part, we can see that the RandomForest is able to learn irregular patterns on the x-axis (which corresponds to the date feature) that the MLP does not learn. We show this difference for default hyperparameters but it seems to us that this is a typical behavior of neural networks, and it is actually hard, albeit not impossible, to find hyperparameters to successfully learn these patterns.\\n\\nThis is obviously really important. This becomes even more remarkable when you realize that Tree-Based methods have much lower tuning costs, making them much better when it comes to bang-for-buck solutions.\\n\\nFinding 2: Uninformative features affect more MLP-like NNs\\n\\nAnother huge factor, especially for those of you that work with giant datasets that encode multiple relationships at once. If you’re feeding irrelevant features to your Neural Network, the results will be terrible (and you will waste a lot more resources training your models). This is why spending a lot of time on EDA/Domain Exploration is so important. This will help understand the features, and ensure that everything runs smoothly.\\n\\nThe authors of the paper test the model performances when adding (random)and removing useless (more correctly-less important)features. Based on their results two interesting things showed up-\\n\\nRemoving a lot of features reduced the performance gap between the models. This clearly implies that a big advantage of Trees is their ability to stay insulated from the effects of worse features.\\n\\nAdding random features to the dataset shows us a much sharper decline in the networks than in the tree-based methods. ResNet especially gets hammered by these useless features. I’m assuming the attention mechanism in the transformer protects it to some degree.\\n\\nTree Supremacy. One thing to note is that they used only the Random Forest feature importance. Involving more protocols to create a better feature accuracy score would make things much better.\\n\\nA possible explanation for this phenomenon might just be in the way Decision Trees are designed. Anyone who has taken an intro to AI class will know about the concepts of Information Gain and Entropy in Decision Trees. These allow Decision Trees to pick the best Paths going forward by comparing the remaining features to pick the one that would allow for the best choices. To those not familiar with the concept (or RFs), I would suggest watching StatQuests videos on these concepts. I’m linking his guide to RandomForests here.\\n\\nGetting back to the point, there is one final thing that makes RFs better performers than NNs when it comes to tabular data. That is rotational invariance.\\n\\nFinding 3: NNs are invariant to rotation. Actual Data is not\\n\\nNeural Networks are invariant to rotation. That means if you rotate the dataset, it will not change their performance. After rotating the datasets, the performance ranking of different learners flips, with ResNets (which were the worst), coming out on top. They maintain their original performance, while all other learners actually lose quite a bit of performance.\\n\\n\\n\\nThis is pretty interesting, but I have to learn more about it. Specifically, what does rotating datasets actually mean? I looked through the paper, but couldn’t find the details. I have reached out to the authors and will write a follow-up. Seeing some examples of rotated datasets would help me understand the implications of this finding better. If any of you have any ideas, share them with me in the comments/through my links.\\n\\nMeanwhile, let’s look into why rotational variance is important. According to the authors, taking linear combinations of features (which is what makes ResNets invariant) might actually misrepresent features and their relationships.\\n\\n…there is a natural basis (here, the original basis) which encodes best data-biases, and which can not be recovered by models invariant to rotations which potentially mixes features with very different statistical properties\\n\\nBased on the performance drops, this is clearly a very important factor that needs to be considered. Going forward, I can see a lot of value in investigating the best data orientations. But I want to learn more about this before making any real comments on this. I’ve spent the last 4 days trying to learn about this, and so far (just like Jon Snow), I know nothing. For now, I’ll end things here.\\n\\nIf you’re looking to get into ML, this article gives you a step-by-step plan to develop proficiency in Machine Learning. It uses FREE resources. Unlike the other boot camps/courses, this plan will help you develop your foundational skills and set yourself up for long-term success in the field.\\n\\n\\n\\nFor Machine Learning a base in Software Engineering, Math, and Computer Science is crucial. It will help you conceptualize, build, and optimize your ML. My daily newsletter, Technology Interviews Made Simple covers topics in Algorithm Design, Math, Recent Events in Tech, Software Engineering, and much more to make you a better developer. I am currently running a 20% discount for a WHOLE YEAR, so make sure to check it out.\\n\\n\\n\\nI created Technology Interviews Made Simple using new techniques discovered through tutoring multiple people into top tech firms. The newsletter is designed to help you succeed, saving you from hours wasted on the Leetcode grind. I have a 100% satisfaction policy, so you can try it out at no risk to you. You can read the FAQs and find out more here\\n\\n\\n\\nFeel free to reach out if you have any interesting jobs/projects/ideas for me as well. Always happy to hear you out.\\n\\nReach out to me\\n\\nUse the links below to check out my other content, learn more about tutoring, or just to say hi.\\n\\nFree Weekly Summary of the important updates in Machine Learning(sponsored)- https://lnkd.in/gCFTuivn\\n\\nCheck out my other articles on Medium. : https://rb.gy/zn1aiu\\n\\nMy YouTube: https://rb.gy/88iwdd\\n\\nReach out to me on LinkedIn. Let’s connect: https://rb.gy/m5ok2y\\n\\nMy Instagram: https://rb.gy/gmvuy9\\n\\nMy Twitter: https://twitter.com/Machine01776819\\n\\nIf you’re preparing for coding/technical interviews: https://codinginterviewsmadesimple.substack.com/\\n\\nGet a free stock on Robinhood: https://join.robinhood.com/fnud75'}},\n",
       "  {'id': '9ef2ea904986',\n",
       "   'title': 'How to learn Machine Learning in 2022',\n",
       "   'subtitle': 'A step by step guide to getting into machine learning',\n",
       "   'author': '76398be9016',\n",
       "   'publication_id': '9758482ba857',\n",
       "   'published_at': '2022-01-20 21:23:05',\n",
       "   'last_modified_at': '2022-12-11 22:13:47',\n",
       "   'tags': ['machine-learning',\n",
       "    'artificial-intelligence',\n",
       "    'data-science',\n",
       "    'programming',\n",
       "    'technology'],\n",
       "   'topics': ['machine-learning'],\n",
       "   'claps': 236,\n",
       "   'voters': 69,\n",
       "   'word_count': 1426,\n",
       "   'responses_count': 3,\n",
       "   'reading_time': 6.431132075471698,\n",
       "   'url': 'https://medium.com/geekculture/how-to-learn-machine-learning-in-2022-9ef2ea904986',\n",
       "   'unique_slug': 'how-to-learn-machine-learning-in-2022-9ef2ea904986',\n",
       "   'image_url': 'https://miro.medium.com/1*18fasTe1sOKBcDoyYY5Nbw.png',\n",
       "   'lang': 'en',\n",
       "   'is_series': False,\n",
       "   'is_locked': False,\n",
       "   'is_shortform': False,\n",
       "   'top_highlight': '',\n",
       "   'content': {'id': '9ef2ea904986',\n",
       "    'content': 'How to learn Machine Learning in 2022\\n\\nA step by step guide to getting into machine learning\\n\\nTo help me understand you fill out this survey (anonymous)\\n\\nAs my content becomes more popular, I have more people reach out to me with a variety of questions. A common theme among them is from people looking to break into Machine Learning. More specifically, this is from people trying to teach themselves Machine Learning. They tell me about various struggles as they float around from courses, projects, and ebooks/guides without fully understanding what they’re doing and developing confidence in their ML. What’s more, they find themselves forgetting the basics, which further saps their confidence, and makes it hard to know how to proceed.\\n\\nSince there are so many ways to do ML, people are trapped by the Paradox of Choice\\n\\nYou would think that with all the fantastic resources, it would be much easier to get started. There are tons of great libraries, tutorials, and courses for you to take. You can even get all kinds of certifications to know where you stand. However, the opposite is true. With all this information out there, it’s easy to get overwhelmed. I received the above message on Tuesday. Notice that despite being a Computer Science Major (the sender of the message is a Master’s student)at a well-known school, he still feels overwhelmed. This is due to the Paradox of Choice, a phenomenon where people feel overwhelmed by too many choices. Below is a well-known study.\\n\\nAll the options can really overwhelm people, causing them to get stuck and not even take the first step\\n\\nIn this article, I will give you a detailed step-by-step plan that will help you learn Machine Learning. There will be no paid courses/links so that this is accessible to more people. Make sure to take your time and really understand the basics before moving on. If you have any great resources, link them in the comments below/message me about them. Let’s help each other make it.\\n\\nStep 1: Get familiar with Coding\\n\\nThis is a must. The absolute step 1. This should be a no-brainer, but people keep missing the extent to which coding is required. Yes, no code is a thing. Yes, packages like Tensorflow and Keras make creating models very easy. BUT they are a minuscule portion of the work you do. You’ll spend a lot of time going over the pipelines written by other people. You’ll have to look at the models published online with their documentation. You will spend a lot of time on very specific implementation details. All of this requires you to comfortable with coding. One of the best resources for this is freecodecamp’s Scientific Computing with Python. It covers most of the details and structures very well. Alongside it, get yourself familiar with recursion and backtracking. These are skills that are crucial in ML.\\n\\nThe course description. I love that they cover both DS and databases.\\n\\nAs you start getting familiar with creating your own classes, most simple automation, logging to files, and working with databases, you can proceed to step 2.\\n\\nStep 2: Do the Math\\n\\nA personal pet peeve of mine is when people confidently tell me that they don’t need math to do Deep Learning (Tensorflow is literally named after a math concept). I don’t know who started this silly rumor, but nothing could be further from the truth. Math is more than calculations. It teaches you how to think. It’s a language that you use to articulate exactly how you can frame and solve a problem. It is non-negotiable.\\n\\nThe reason I was able to come up with novel and effective solutions was because of my math training.\\n\\nNow that we are on the same page, let’s talk about how much you need. It’s not a lot. As long as you get familiar with mathematical thinking, and understand the core concepts, you will be effective. Naturally, as you try to get better, Math will be more and more important. Make sure you watch the following video till the end. It goes into detail on the four math topics you need (and how much you need). It is a guide to help you get to a good baseline level. If you decide to proceed beyond that, it will only help.\\n\\nAs for the sources you can learn Math, Khan Academy is king. Fantastic courses, tons of problems, and a great system. Professor Leonard has good upper-level calculus. YouTube is a great place where you can learn and improve your mathematical skills.\\n\\nStep 3: Basic ML\\n\\nOnce you start to get a mathematical intuition, start looking into understanding basic Machine Learning. ThreeBlueOneBrown has a great playlist on Neural Networks. StatsQuests and RitvikMath are two fantastic channels that talk about a lot of Machine Learning/Data Science related concepts in a clear manner. There’s also a certain YouTuber that explains different Machine Learning ideas and concepts in a clear and applicable manner (wink wink).\\n\\nThis video explains how to design and build ML projects to maximize your learning and employability.\\n\\nIf you’ve kept up with the basics, this is when you will notice how useful the basics are for ML. You will be able to read the documentation, go through people’s GitHub projects, and mostly understand the resources. This is when you should get into developing projects. The above video is a guide on exactly how you should design your ML projects to have the greatest carryover to practical learning.\\n\\nAt this point, you’re still going to be a relative beginner. However, as you start to engage with ML channels and learn more about things, you will start to notice patterns and thoughts. And now you’re competent at Machine Learning. Now is when your growth will start to accelerate. How? Look at the next step.\\n\\nStep 4: Deep dive deeper into the Papers/ML community\\n\\nUp to this point, we have focused on equipping you with the right tools. You have developed the ability to understand Machine Learning both theoretically (through your mathematical grounding), and implementation-wise (through coding). You should be able to explain the idea and concept behind the common algorithms and implementations.\\n\\nVariants of this quote are around the internet. This is what we have focused on.\\n\\nThe next step comes in with engaging with more complex literature. This can be disheartening at first. You will open papers, and see papers and notation that you are confused about. The ML talks shared will seem like 5 minutes of English and 40 minutes of Jargon. That’s okay. It’s a gradual process. The more papers you read/learn about, the more you will be able to understand. In the beginning, you can focus on understanding just one or two things from each paper (my annotated papers can help with that). The more you do, the better you will get at gaining insight from them. This article goes into detail about how you should interact with these complex ML papers to boost your Machine Learning skills. It is one of my best-received articles to date.\\n\\nOnce you get to this stage, it’s a lifelong process. You’ll keep learning from the tons of smart people that share their knowledge online. Some good starting places are Henry AI Labs, Yannic Kilcher, Robert Miles, Mathematical Monk, and Primer. You should also attempt harder projects such as the one detailed here.\\n\\n\\n\\nFor best results, make sure you subscribe to my daily newsletter, Coding Interviews Made Simple. It covers topics in Algorithm Design, Math, Recent Events in Tech, Software Engineering, and much more to make you a better developer. I am currently running a 20% discount for a WHOLE YEAR, so make sure to check it out.\\n\\n\\n\\nI created Coding Interviews Made Simple using new techniques discovered through tutoring multiple people into top tech firms. The newsletter is designed to help you succeed, saving you from hours wasted on the Leetcode grind. You can read the FAQs and find out more here\\n\\nFeel free to reach out if you have any interesting jobs/projects/ideas for me as well. Always happy to hear you out.For monetary support of my work following are my Venmo and Paypal. Any amount is appreciated and helps a lot. Donations unlock exclusive content such as paper analysis, special code, consultations, and specific coaching:\\n\\nVenmo: https://account.venmo.com/u/FNU-Devansh\\n\\nPaypal: paypal.me/ISeeThings\\n\\nReach out to me\\n\\nYou can reach out to me on any of the platforms, or check out any of my other content. If you’d like to discuss tutoring, text me on LinkedIn, IG, or Twitter. Check out the free Robinhood referral link. We both get a free stock (you don’t have to put any money), and there is no risk to you. So not using it is just losing free money.\\n\\nFree Weekly Summary of the important updates in Machine Learning(sponsored)- https://lnkd.in/gCFTuivn\\n\\nCheck out my other articles on Medium. : https://rb.gy/zn1aiu\\n\\nMy YouTube: https://rb.gy/88iwdd\\n\\nReach out to me on LinkedIn. Let’s connect: https://rb.gy/m5ok2y\\n\\nMy Instagram: https://rb.gy/gmvuy9\\n\\nMy Twitter: https://twitter.com/Machine01776819\\n\\nIf you’re preparing for coding/technical interviews: https://codinginterviewsmadesimple.substack.com/\\n\\nGet a free stock on Robinhood: https://join.robinhood.com/fnud75'}},\n",
       "  {'id': 'bf4cb36751ea',\n",
       "   'title': 'Why some CEOs hate Remote Work',\n",
       "   'subtitle': 'Is it truly a lack of productivity or is it something more?',\n",
       "   'author': '76398be9016',\n",
       "   'publication_id': '32881626c9c9',\n",
       "   'published_at': '2024-02-17 06:42:03',\n",
       "   'last_modified_at': '2024-02-18 09:45:38',\n",
       "   'tags': ['business',\n",
       "    'technology',\n",
       "    'programming',\n",
       "    'software-development',\n",
       "    'culture'],\n",
       "   'topics': ['work'],\n",
       "   'claps': 242,\n",
       "   'voters': 9,\n",
       "   'word_count': 1072,\n",
       "   'responses_count': 0,\n",
       "   'reading_time': 4.595283018867924,\n",
       "   'url': 'https://medium.datadriveninvestor.com/why-some-ceos-hate-remote-work-bf4cb36751ea',\n",
       "   'unique_slug': 'why-some-ceos-hate-remote-work-bf4cb36751ea',\n",
       "   'image_url': 'https://miro.medium.com/0*00ERjm7K0uAn-blF.jpeg',\n",
       "   'lang': 'en',\n",
       "   'is_series': False,\n",
       "   'is_locked': False,\n",
       "   'is_shortform': False,\n",
       "   'top_highlight': 'The remote work vs in-person debate seems to be more divisive than ever.',\n",
       "   'content': {'id': 'bf4cb36751ea',\n",
       "    'content': 'Why some CEOs hate Remote Work\\n\\nIs it truly a lack of productivity or is it something more?\\n\\nThe remote work vs in-person debate seems to be more divisive than ever.\\n\\nThe debate seemed to be settling towards remote work, with many companies making declarations that were switching to fully remote. However, many of these names are now switching back-\\n\\nGoldman Sachs wants employees in five days a week. Google is factoring employees’ in-office attendance into their performance reviews.\\n\\nA whopping 90% of companies plan to implement return-to-office policies by the end of 2024, according to an Aug. report from Resume Builder, which surveyed 1,000 company leaders. Nearly 30% say their company will threaten to fire employees who don’t comply with in-office requirements.\\n\\n-Source\\n\\nThere have been multiple reasons given for this change- including productivity, culture, and increased collaboration- but the financial reasons are often overlooked. In this piece, we will look at the financial incentives driving upper-level management to embrace in-person work, even when there is no obvious benefit (unlike certain fields, where security measures, work requirements, etc might require in-person work). As an employee, it’s always important to understand the parts not said out loud to make better decisions.\\n\\n\\n\\nJoin 150K+ tech leaders and get insights on the most important ideas in AI straight to your inbox through my free newsletter- AI Made Simple\\n\\nBusiness Reasons for In-Person Work\\n\\nIncreased Turnover: Some companies need to cut costs to maintain margins. Manpower is expensive. However, laying off employees can also damage a company’s reputation and make it harder to hire new employees in the future. Forcing employees to return to the office can lead to higher staff turnover, which saves the company from bad press and expensive severance packages associated with layoffs.\\n\\nUnispace found that nearly half (42%) of companies with return-to-office mandates witnessed a higher level of employee attrition than they had anticipated. And almost a third (29%) of companies enforcing office returns are struggling with recruitment. In other words, employers knew the mandates would cause some attrition, but they weren’t ready for the serious problems that would result.\\n\\nMeanwhile, a staggering 76% of employees stand ready to jump ship if their companies decide to pull the plug on flexible work schedules, according to the Greenhouse report.\\n\\n-Source\\n\\nReal estate: Some companies have a lot of invested in real estate, and they are now stuck with empty office buildings. This is a problem for companies that own their office buildings since the office space has turned from an asset into a massive liability- for eg. Apple ended up spending 5B on their Cupertino office, would’ve looked very stupid if no one used it. Companies that lease office space are often stuck in long-term leases, and they may be unable to sublease the space if they don’t need it. Thus many companies use RTO as a way of justify the massive cap-ex on offices. If you’re skeptical about this, consider that Google leasing some buildings to C3.ai makes them$103.1 million in base rent payments (If you’re wondering what C3 gained from this, consider that this rent payment was a tiny bribe to secure the Google Cloud partnership that shot their valuation up.) When it’s not in use, commercial real estate is a big hole in the balance sheets.\\n\\nThat monthly payment is insane when you consider C3’s awful financials. You can find the lease between Google and C3 here\\n\\nManagement reasons: Some managers feel that they have more power over their employees when they are in the office. This is because it is easier to micromanage employees in person, and it is also easier to build relationships with employees in person. However, studies have shown that remote workers can be just as productive as in-office workers, remote work can be better for inclusivity, and can even reduce distractions- boosting creativity and performance.\\n\\nCultural reasons: Some companies simply prefer the traditional office culture. They believe that face-to-face interaction is important for building relationships and collaboration. However, there are many ways to build relationships and collaborate remotely, and there is no evidence that remote workers are less productive or collaborative than in-office workers (especially when given the right tools/spaces for this).\\n\\nNow some of you might prefer working from an office for mental or social reasons. That’s fine, we don’t judge any kinks here. The good news for you is that there are plenty of orgs looking for people like you. And if you are someone who hates commuting as much as me, I hope this gave you some insight into the market dynamics causing some companies to push against remote work. Either way, hope you have a great weekend. Fellow UFC fans who you got for the title fight? It’s impossible to bet against Volk but as someone whose game is built around pocket-boxing and top-pressure, I will be rooting for Topuria.\\n\\nThat is it for this piece. I appreciate your time. As always, if you’re interested in working with me or checking out my other work, my links will be at the end of this email/post. If you like my writing, I would really appreciate an anonymous testimonial. You can drop it here. And if you found value in this write-up, I would appreciate you sharing it with more people. It is word-of-mouth referrals like yours that help me grow.\\n\\nSave the time, energy, and money you would burn by going through all those videos, courses, products, and ‘coaches’ and easily find all your needs met in one place at ‘Tech Made Simple’! Stay ahead of the curve in AI, software engineering, and the tech industry with expert insights, tips, and resources. 20% off for new subscribers by clicking this link. Subscribe now and simplify your tech journey!\\n\\n\\n\\nUsing this discount will drop the prices-\\n\\n800 INR (10 USD) → 640 INR (8 USD) per Month\\n\\n8000 INR (100 USD) → 6400INR (80 USD) per year (533 INR /month)\\n\\nGet 20% off for 1 year\\n\\nReach out to me\\n\\nUse the links below to check out my other content, learn more about tutoring, reach out to me about projects, or just to say hi.\\n\\nSmall Snippets about Tech, AI and Machine Learning over here\\n\\nAI Newsletter- https://artificialintelligencemadesimple.substack.com/\\n\\nMy grandma’s favorite Tech Newsletter- https://codinginterviewsmadesimple.substack.com/\\n\\nCheck out my other articles on Medium. : https://rb.gy/zn1aiu\\n\\nMy YouTube: https://rb.gy/88iwdd\\n\\nReach out to me on LinkedIn. Let’s connect: https://rb.gy/m5ok2y\\n\\nMy Instagram: https://rb.gy/gmvuy9\\n\\nMy Twitter: https://twitter.com/Machine01776819\\n\\nVisit us at DataDrivenInvestor.com\\n\\nSubscribe to DDIntel here.\\n\\nHave a unique story to share? Submit to DDIntel here.\\n\\nJoin our creator ecosystem here.\\n\\nDDIntel captures the more notable pieces from our main site and our popular DDI Medium publication. Check us out for more insightful work from our community.\\n\\nDDI Official Telegram Channel: https://t.me/+tafUp6ecEys4YjQ1\\n\\nFollow us on LinkedIn, Twitter, YouTube, and Facebook.'}},\n",
       "  {'id': '7b104513834e',\n",
       "   'title': 'Google’s High-Performance Computing Expert shares his thoughts on how to use AI',\n",
       "   'subtitle': 'Partnering with AI to reimagine problem-solving: the ‘intelligence’ that is artificial may be our own',\n",
       "   'author': '76398be9016',\n",
       "   'publication_id': '*Self-Published*',\n",
       "   'published_at': '2024-02-15 17:11:21',\n",
       "   'last_modified_at': '2024-02-15 17:11:21',\n",
       "   'tags': ['machine-learning',\n",
       "    'technology',\n",
       "    'artificial-intelligence',\n",
       "    'data-science',\n",
       "    'philosophy'],\n",
       "   'topics': ['artificial-intelligence'],\n",
       "   'claps': 2,\n",
       "   'voters': 2,\n",
       "   'word_count': 3079,\n",
       "   'responses_count': 0,\n",
       "   'reading_time': 12.002201257861635,\n",
       "   'url': 'https://machine-learning-made-simple.medium.com/googles-high-performance-computing-expert-shares-his-thoughts-on-how-to-use-ai-7b104513834e',\n",
       "   'unique_slug': 'googles-high-performance-computing-expert-shares-his-thoughts-on-how-to-use-ai-7b104513834e',\n",
       "   'image_url': 'https://miro.medium.com/1*b9LTaujSPgYWZL-qD3Zf1Q.jpeg',\n",
       "   'lang': 'en',\n",
       "   'is_series': False,\n",
       "   'is_locked': False,\n",
       "   'is_shortform': False,\n",
       "   'top_highlight': '',\n",
       "   'content': {'id': '7b104513834e',\n",
       "    'content': 'Google’s High-Performance Computing Expert shares his thoughts on how to use AI\\n\\nPartnering with AI to reimagine problem-solving: the ‘intelligence’ that is artificial may be our own\\n\\nBarak Epstein has been a senior technology leader for over a decade. He has led efforts in Cloud Computing and Infrastructure at Dell and now at Google. Currently, he is leading efforts to leverage the ambitious DAOS open-source project for Google Cloud’s High-Performance Computing initiatives. Barak and I have had several interesting conversations about infrastructure, strategy, and how investments in large-scale computing can introduce new paradigms for next-gen AI (instead of just enabling more of the same, which has been the current approach). This piece will be a summary of some of the conversations we had around strategy, how what we choose to solve is a key signal about our own priorities and about those of the organizations we work in, and on navigating changing Human-Computer interaction dynamics.\\n\\nDisclosure: I am currently in conversations with two members from the DAOS Foundation (Intel and HPE) exploring partnerships to speed up Open Source adoption of DAOS. This post has not been sponsored by anyone and has very little to do with the those partnerships, but given Barak’s role in the DAOS community, I wanted to disclose that relationship.\\n\\nI work in tech and live in Brooklyn. I help shape cloud storage products that support AI/ML use cases (among others) and have extensively studied data science as a professional; but studied history in college, have a master’s in education (before my MBA), and read philosophy in my free time. My digital life and working hours are tied in with Silicon Valley, AI researchers, and, generally, techno-optimists. During weekends and evenings, and at parties, though, I am more likely to hear friends give voice to dyspepsia about the pace of development and (lack of) governance of AI and other rapidly advancing technologies.\\n\\nAs such, I’ve spent a lot of time thinking about how to engage with technology generally, and AI specifically, in a way that is dynamic, safeguards humanistic values, and leads to a sense of well-being and productive partnership.\\n\\nThe article below is a first attempt to weave together the human-centric values of the traditional, East Coast cultural elite with the technocentrism (often technophilia) of the Silicon Valley Tribe. I hope that my day-to-day experience in the tech industry grounds this piece enough to make it interesting to tech professionals and AI experts, and that my background in \"Letters\" will make this piece interesting to the ‘tech-anxious’.\\n\\nJoin 150K+ tech leaders and get insights on the most important ideas in AI straight to your inbox through my free newsletter- AI Made Simple\\n\\nUltimately, we will need a more fluid and generative way to think about how human and machine intelligence interact and inform each other; and a more courageous way to think about how our identities and goals are shaped by tech, and shape it.\\n\\n\"The Future We Simulate is the One We Create\" grabbed my intention, partly due to the suggestion from the headline, that the problems we choose to investigate help shape not only our computing investments but also who we are to become. In my mind’s eye, I draw a straight line from early human cave paintings to computer simulation: Hasn’t the attempt to simulate our world been an ongoing obsession since, at least, the Cognitive Revolution?\\n\\nMore concretely, the article presents an argument for increased investment in High Performance Computing, positing that major advances in cancer and climate research, weather prediction, and nuclear fusion are worth the investment and the risk. The author knowledgeably and practically includes nuclear bomb simulation as one focal point for expanded HPC investment, understanding that the past of HPC investment was disproportionately motivated by this target, and that governments are likely to be motivated by a similar focus in the future (for those to whom this causes moral qualms, please consider that such simulations helped to replace real world nuclear testing).\\n\\nThe author states, \"HPC is a bit like machine learning back in the 1980s, when all of the groundwork was laid for success in the 2010s and beyond.\"\\n\\nThis argument, that HPC development is in its infancy, is transparently attractive to those of us whose careers are invested in this domain, and it may also be true. The title of the piece, though, and as noted, suggests a deeper philosophical argument than the article explicitly presents. Namely, the simulations we choose to invest in do not only improve our odds for solving problems such as those identified above, but they help to define who we are as humans, at least on the generational time scale. By investing deeply in addressing climate change or cancer or nuclear bomb simulation, we state to ourselves, even before any particular problem is solved, \"Yes! These are the problems worth solving!\"\\n\\nThis is all to say: humans are remarkable not only because we sometimes solve grand problems, but also (even more so?) because we select the problems we wish to solve. This perspective is often overlooked in breathless conversations ongoing in HPC’s (now) ‘sister field’ of Artificial Intelligence. Fears (and promises) of Artificial General Intelligence generally(!) ignore the question of how the goals of any calculation are chosen.\\n\\nWe are not talking about the famous AI Paperclip Problem, since that thought experiment problematizes the methods that an AI may choose to pursue a human-determined goal. We are talking instead about how the goals of an AI are selected. If humans select the goal, then we are still ‘in the loop’ and the AI is not, in fact, acting Generally. AGI proponents and opponents are then missing the critical question of \"What should the AI be used for?\" - in other words, \"The AI We Select is the Future We Create.\"\\n\\nOur interaction with AI models has accordingly changed us already, and will continue to do so. For example, our collective sense of what a conversation is was upended in late 2022/early 2023 and our sense of how decisions are made (i.e. through a hybrid carbon-silicon substrate) will be the next to change. Those interested in preserving a continuous sense of human purpose would be best served by engaging in the accelerating vortex of human-computer interaction and identifying those critical points at which humans can determine and/or influence the goals of the AIs that are destined to become our partners. Yes, we should be (very) concerned about AIs that run amok, but the more persistent (and more fruitful) challenge to take on has to do with governing the goals of AIs.\\n\\nA focus on our human agency over ‘goal-setting’ challenge would, to take one specific example, encourage more careful thinking about how the low-fidelity, \"parametric identification\" methods of AI could be married with the higher-fidelity, outcome-centric approach of HPC to deliver more useful output. Such a combination of low-precision and high-precision methods has been demonstrated where LLMs have been integrated with math libraries to better leverage the strengths of each respective tool. Human judgment will continue to be relevant as we attempt to strike a balance between methods with varying strengths, and inevitably incorporate normative evaluations about which types of output are useful and meaningful.\\n\\nLet’s focus more deeply on two of the broader ideas from the section above, before returning to more grounded examples:\\n\\nIdea 1: Humans \"select the problems we wish to solve.\"\\n\\nTranslated into AI Techspeak, we would say that \"humans select the objective function that the model must optimize for.\"\\n\\nIdea 2: \"Our interaction with AI models has changed us, and will continue to do so.\"\\n\\nThe objective functions we choose are, in turn, influenced by the tools we have at our disposal.\\n\\nTo be more concrete, before my high school-aged daughter had the use of an AI Chat tool, her objective function was to \"write a good essay.\" Now that she has an AI Chat tool, her objective function is to \"use the AI Chat tool without getting into trouble.\" As a parent, my objective function used to be \"make sure she writes a good essay\" but it is now, \"make sure she reads the output of the AI Chat, understands it, edits it, and uses it to build her understanding\" and also to ensure that she \"follows the rules of the school in letter and in spirit.\" The AI Chat tool has forced me to think more deeply about what I want her to learn and what I think she will need in ordwr to survive in the future. The use of AI Chat will, in her specific case, be part of the scaffolding for her to become a better writer, but I also must acknowledge that the world and its tools changed, and that the skills necessary for survival and happiness change in the context of these changes.\\n\\nThe Philosopher Jose Ortega y Gasset (Man the Technician, p. 92) contrasts humans with animals and expounds on how humans reshape and determine their goals according to the tools available in their environment.\\n\\nIf, for lack of fire or a cave, he is unable to perform the act of warming himself . . . man mobilizes a second line of activities . . . he lights a fire . . . the animal, when it cannot satisfy its vital needs - when there is neither fire nor a cave, for example - does nothing about it and lets itself die. Man, on the other hand, comes forward with a new type of activity; he produces what he does not find in nature . . . Thus he lights a fire . . . Be it well noted: making a fire is an act very different from keeping warm.\\n\\nIn this sense, the development of the \"AI Tool\" falls into accord with millions of years of human history, as well as with Ortega y Gasset’s discourse–tool building activities have (increasingly) often displaced direct reward-collection activities. But AI is more revolutionary than most other New Tools, since it intervenes, so far as we can tell, in the goal-setting and meaning-making that Ortega y Gasset defines as fundamentally human.\\n\\nThe fact that AI participates in our decision process ‘so far as we can tell’ is what makes it appear intelligent. In that sense, it doesn’t matter whether we say that AI is intelligent or that it just appears intelligent. Once AI appears intelligent, it becomes part of our thought process.\\n\\nOne of my favorite (ok, my favorite) Digital Age Philosophers, Venkatesh Rao, quotes the well-known (in some circles), saying that \"computers are ‘rocks we tricked into thinking with lightning.’ \" He extends the thought:\\n\\nWhile lithography is a more complex transformation process than simple cooling, there’s a deep thought lurking there. \"Tricking\" rocks with suspiciously simple physical/chemical processes and structural patterns (compared to CPUs, GPUs and AI accelerator chips have remarkably simple physical layouts; more like crystal structure patterns than complicated machinery) doesn’t seem like it should be enough to spark \"thinking\" but apparently it is . . .\\n\\nSo in 2023, we discovered that \"intelligence,\" far from being the culmination of an evolutionary ascent construed in linear terms, is simply a natural phenomenon that can emerge in more than one way through relatively simple transformations of matter . . .\\n\\nTo me, it is actually kinda exciting that \"intelligence\" appears to be a latent property of data [emph. mine], which can be transformed into an explicit property, rather than an attribute of a processing technology.\\n\\nThe takeaway is that AI is not only competing with our intelligence or participating in our process of thought. More deeply, it is upsetting our sense of what intelligence is.\\n\\nSo:\\n\\nbeing human is (in part) about choosing our own objective functions → we must think smarter\\n\\nAI (now and increasingly) participates in that choice, that thinking → we must think in partnership with AI\\n\\nAI upsets our foundational assumptions about what thinking is → we must have a sense of self that does not depend on our intelligence\\n\\nThe last point is the most challenging, but it’s also the one that opens up the most creativity in our relationship to AI and to nature and experience more broadly. By choosing the future we wish to simulate, we are not just making a functional choice, but a spiritual choice, about who we wish to be as we partner with AI in World Design. That choice is fraught but also expansive.\\n\\nThe perspectives above will not only help us keep our sanity and sense of purpose as we interact with AI, but they will help us to more flexibly think about how to manipulate, intertwine, and extend AI models. I addressed this opportunity lightly above, but here is a bit of a deeper look at some ‘’meta-AI\" problems that a less-technical person could help us all think about:\\n\\nCombining low-precision and high-precision methods to solve problems\\n\\nGoogle DeepMind’s AlphaGeometry recently demonstrated the great strides that AIs have taken in solving problems from the Mathematical Olympiad. From SingularityHub:\\n\\nIn a way, solving geometry problems is a bit like playing chess. Given some rules - called theorems and proofs - there’s a limited number of solutions to each step, but finding which one makes sense relies on flexible reasoning conforming to stringent mathematical rules.\\n\\nIn other words, tackling geometry requires both creativity and structure. While humans develop these mental acrobatic skills through years of practice, AI has always struggled.\\n\\nAlphaGeometry cleverly combines both features into a single system. It has two main components: A rule-bound logical model that attempts to find an answer, and a large language model to generate out-of-the-box ideas. If the AI fails to find a solution based on logical reasoning alone, the language model kicks in to provide new angles. The result is an AI with both creativity and reasoning skills that can explain its solution.\\n\\nConceptually, the idea of combining language-based reasoning and mathematical reasoning is also represented by the Wolfram plugin for ChatGPT. On the hardware side of things, HPC engineers are leveraging their human judgment to optimally apply various levels of operational precision to different parts of their calculations.\\n\\nDeveloping greater and greater levels of abstraction in learning methods\\n\\nThis article is about how AI models can develop the \"systematic generalization\" that characterizes human learning. In the process of thinking about this problem, you may also gain insight into how your mind works. In other words, developing AI is not just an opportunity to build new tools. It’s also an opportunity to think more deeply about what makes us human, and how our brains work:\\n\\nLake & Baroni wanted to teach neural networks to solve a more general task: performing systematic generalization from just a few examples on tasks generated from different grammars.\\n\\nTo automatically generate tasks from different grammars, Lake & Baroni needed an automatic way to generate different grammars - namely, a \"meta-grammar.\" The meta-grammar had simple rules for generating grammars [detail follows].\\n\\nHow much are we interested in solving problems vs just \"looking in the mirror\"?\\n\\nThe author of the same article on meta-learning asked why AI models were specifically being trained to make mistakes in patterns similar to those made by humans:\\n\\nOne thing that confused me in this paper was the explicit training to make the system act more \"human-like.\" As I described above, after cataloging the frequency and kinds of errors made by humans on these tasks, Lake & Baroni trained their network explicitly on examples having the same frequency and kinds of errors.\\n\\nThis last observation points to an interesting aspect of our research in, and discussion of, AI. We aren’t always interested in how AI can help be \"Faster, Higher, Stronger\" but sometimes are just obsessively interested in how (and whether) it can be \"more like us\".\\n\\nThe pursuit of Artificial Intelligence (as well as the fear of it) is often motivated by fascination and/or discomfort with our ability to make \"carbon\" copies of ourselves.\\n\\nUltimately, the invitation here is to think more deeply about what AI is, how to use it, and how we might partner with it. Non-mathy and non-computery types should not be overwhelmed; rather, they should engage more deeply, seeking out the subtle junctures at which their reflection and insight can help guide us and our Machines of Growing Capability. There is so much about this interaction that is non-obvious, open-ended, and dynamic. It turns out that there is one constant in this whirling and refractory universe: the greatest thing to fear is fear itself.\\n\\nIf you liked this article and wish to share it, please refer to the following guidelines.\\n\\nThat is it for this piece. I appreciate your time. As always, if you’re interested in working with me or checking out my other work, my links will be at the end of this email/post. And if you found value in this write-up, I would appreciate you sharing it with more people. It is word-of-mouth referrals like yours that help me grow.\\n\\nIf you find AI Made Simple useful and would like to support my writing- please consider becoming a premium member of my cult by subscribing below. Subscribing gives you access to a lot more content and enables me to continue writing. This will cost you 400 INR (5 USD) monthly or 4000 INR (50 USD) per year and comes with a 60-day, complete refund policy. Understand the newest developments and develop your understanding of the most important ideas, all for the price of a cup of coffee.\\n\\nBecome a premium member\\n\\n\\n\\nI regularly share mini-updates on what I read on the Microblogging sites X(https://twitter.com/Machine01776819), Threads(https://www.threads.net/@iseethings404), and TikTok(https://www.tiktok.com/@devansh_ai_made_simple)- so follow me there if you’re interested in keeping up with my learnings.\\n\\nReach out to me\\n\\nUse the links below to check out my other content, learn more about tutoring, reach out to me about projects, or just to say hi.\\n\\nSmall Snippets about Tech, AI and Machine Learning over here\\n\\nAI Newsletter- https://artificialintelligencemadesimple.substack.com/\\n\\nMy grandma’s favorite Tech Newsletter- https://codinginterviewsmadesimple.substack.com/\\n\\nCheck out my other articles on Medium. : https://rb.gy/zn1aiu\\n\\nMy YouTube: https://rb.gy/88iwdd\\n\\nReach out to me on LinkedIn. Let’s connect: https://rb.gy/m5ok2y\\n\\nMy Instagram: https://rb.gy/gmvuy9\\n\\nMy Twitter: https://twitter.com/Machine01776819'}},\n",
       "  {'id': 'cd3a824ba81f',\n",
       "   'title': 'Interesting Content in AI, Software, Business, and Tech- 02/14/2024',\n",
       "   'subtitle': 'Content to help you keep up with Machine Learning, Deep Learning, Data Science, Software Engineering, Finance, Business, and more',\n",
       "   'author': '76398be9016',\n",
       "   'publication_id': '*Self-Published*',\n",
       "   'published_at': '2024-02-14 19:33:45',\n",
       "   'last_modified_at': '2024-02-14 19:33:45',\n",
       "   'tags': ['machine-learning',\n",
       "    'artificial-intelligence',\n",
       "    'software-development',\n",
       "    'technology',\n",
       "    'business'],\n",
       "   'topics': ['artificial-intelligence', 'programming'],\n",
       "   'claps': 62,\n",
       "   'voters': 7,\n",
       "   'word_count': 2592,\n",
       "   'responses_count': 0,\n",
       "   'reading_time': 10.331132075471698,\n",
       "   'url': 'https://machine-learning-made-simple.medium.com/interesting-content-in-ai-software-business-and-tech-02-14-2024-cd3a824ba81f',\n",
       "   'unique_slug': 'interesting-content-in-ai-software-business-and-tech-02-14-2024-cd3a824ba81f',\n",
       "   'image_url': 'https://miro.medium.com/1*b9LTaujSPgYWZL-qD3Zf1Q.jpeg',\n",
       "   'lang': 'en',\n",
       "   'is_series': False,\n",
       "   'is_locked': False,\n",
       "   'is_shortform': False,\n",
       "   'top_highlight': '',\n",
       "   'content': {'id': 'cd3a824ba81f',\n",
       "    'content': 'Interesting Content in AI, Software, Business, and Tech- 02/14/2024\\n\\nContent to help you keep up with Machine Learning, Deep Learning, Data Science, Software Engineering, Finance, Business, and more\\n\\nA lot of people reach out to me for reading recommendations. I figured I’d start sharing whatever AI Papers/Publications, interesting books, videos, etc I came across each week. Some will be technical, others not really. I will add whatever content I found really informative (and I remembered throughout the week). These won’t always be the most recent publications- just the ones I’m paying attention to this week. Without further ado, here are interesting readings/viewings for 02/14/2024. If you missed last week’s readings, you can find it here.\\n\\nReminder- We started an AI Made Simple Subreddit. Come join us over here- https://www.reddit.com/r/AIMadeSimple/. If you’d like to stay on top of community events and updates, join the discord for our cult here: https://discord.com/invite/EgrVtXSjYf.\\n\\nCommunity Spotlight: Ravindranath Nemani\\n\\nRavindranath Nemani is a data scientist at IBM. If you’re looking to go deep into technical research, you should check out his profile. He shares a ton of resources, notes, and publications on a variety of topics. If you are looking for ideas that might define the next 2–3 decades, then his profile is a great place to go looking.\\n\\nIf you’re doing interesting work and would like to be featured in the spotlight section, just drop your introduction in the comments/by reaching out to me. There are no rules- you could talk about a paper you’ve written, an interesting project you’ve worked on, some personal challenge you’re working on, ask me to promote your company/product, or anything else you consider important. The goal is to get to know you better, and possibly connect you with interesting people in our chocolate milk cult. No costs/obligations are attached.\\n\\nPreviews\\n\\nCurious about what what articles I’m working on? Here are the previews for the next planned articles-\\n\\nTech Made Simple\\n\\n\\n\\nAI Made Simple\\n\\n\\n\\nHighly Recommended\\n\\nThese are pieces that I feel are particularly well done. If you don’t have much time, make sure you at least catch these works.\\n\\nMicrosoft’s New Future of Work Report\\n\\nThere are many good resources on software engineering productivity, but Abi Noda is one of them. His newsletter is a cut above the generic, \"10x your career by stealing my email template\" style of career gurus. He goes into research into what defines high-performers to give you useful advice (his newsletter was how I found the excellent Microsoft paper, \"What distinguishes great software engineers?\"). In my top 5 resources for Software Engineers and Engineering managers.\\n\\n\"There have been many excellent papers published about the ways in which work may change as LLMs, such as GitHub’s Copilot, are integrated. Microsoft’s report synthesizes some of the most important or emerging themes from this research.\\n\\nIn the future, I’ll cover papers on AI and software development in more depth. This issue gives an overview of the most important ideas and emerging research themes related to AI in the workplace.\"\\n\\nKVQuant: Towards 10 Million Context Length LLM Inference with KV Cache Quantization\\n\\nFound this gem while doing some market research on how to to handle really large documents. Based on some early experiments, the results don’t carry over perfectly (you need to do a lot of tinkering with good design to meaningfully process large documents), but this is a great foundation to build upon.\\n\\n\"LLMs are seeing growing use for applications such as document analysis and summarization which require large context windows, and with these large context windows KV cache activations surface as the dominant contributor to memory consumption during inference. Quantization is a promising approach for compressing KV cache activations; however, existing solutions fail to represent activations accurately in ultra-low precisions, such as sub-4-bit. In this work, we present KVQuant, which addresses this problem by incorporating novel methods for quantizing cached KV activations, including: (i) Per-Channel Key Quantization, where we adjust the dimension along which we quantize the Key activations to better match the distribution; (ii) Pre-RoPE Key Quantization, where we quantize Key activations before the rotary positional embedding to mitigate its impact on quantization; (iii) Non-Uniform KV Cache Quantization, where we derive per-layer sensitivity-weighted non-uniform datatypes that better represent the distributions; (iv) Per-Vector Dense-and-Sparse Quantization, where we isolate outliers separately for each vector to minimize skews in quantization ranges; and (v) Q-Norm, where we normalize quantization centroids in order to mitigate distribution shift, providing additional benefits for 2-bit quantization. By applying our method to the LLaMA, LLaMA-2, and Mistral models, we achieve <0.1 perplexity degradation with 3-bit quantization on both Wikitext-2 and C4, outperforming existing approaches. Our method enables serving the LLaMA-7B model with a context length of up to 1 million on a single A100–80GB GPU and up to 10 million on an 8-GPU system. \"\\n\\nWhy Green Skyscrapers are a Terrible Idea\\n\\nGreen Skyscrapers are a very strong example of greenwashing. This is a great video on all the logistical issues of green skyscrapers, and proposes alternatives that would be cheaper, better, and more eco-friendly.\\n\\nDiffusion World Model\\n\\nAs someone who has dealt with the nightmare of multi-step time forecasting on more than one occasion, this is an interesting approach. Will have to experiment more before drawing conclusions, but the idea is worth checking out.\\n\\n\"We introduce Diffusion World Model (DWM), a conditional diffusion model capable of predicting multistep future states and rewards concurrently. As opposed to traditional one-step dynamics models, DWM offers long-horizon predictions in a single forward pass, eliminating the need for recursive queries. We integrate DWM into model-based value estimation, where the short-term return is simulated by future trajectories sampled from DWM. In the context of offline reinforcement learning, DWM can be viewed as a conservative value regularization through generative modeling. Alternatively, it can be seen as a data source that enables offline Q-learning with synthetic data. Our experiments on the D4RL dataset confirm the robustness of DWM to long-horizon simulation. In terms of absolute performance, DWM significantly surpasses one-step dynamics models with a 44% performance gain, and achieves state-of-the-art performance.\"\\n\\nCompare GPT-4 and Gemini Ultra, side-by-side\\n\\nOur boy Adam Binks put a lot of work into this comparison. While comparisons like this are a dime a dozen, Adam has put a lot of effort into designing creative prompts and building a website that makes it easy to search through multiple criteria.\\n\\nLLM Paper Reading Notes - January 2024\\n\\nAny time an expert like Jean David Ruvini shares their notes on a topic, you want to listen. Seeing what kinds of things they focus on is very useful as a proxy for identifying underappreciated but very important metrics.\\n\\n\"Sharing short notes about LLM research papers I came across in December. These notes, intended for my future self, differ in their level of detail and precision. I hope they’re still useful in piquing your curiosity and helping you breathe under the waterfall. At the current pace of AI, it takes the power of all of us to keep up.\"\\n\\nBlink: The Power of Thinking Without Thinking\\n\\nI wish I found this talk before writing my article on the limitations of data. This is a great overview of how our data collection methods/analysis can introduce lots of flaws and hidden assumptions.\\n\\n\"How do we make decisions - good and bad - and why are some people so much better at it than others? Utilizing case studies as diverse as speed dating, pop music, and the shooting of Amadou Diallo, Gladwell reveals that what we think of as decisions made in the blink of an eye are much more complicated than assumed. Drawing on cutting-edge neuroscience and psychology, he shows how the difference between good decision-making and bad has nothing to do with how much information we can process quickly, but on the few particular details on which we focus. Gladwell reveals how we can become better decision makers - in our homes, our offices, and in everyday life. Never again will you think about thinking the same way.\"\\n\\nHow Taco Bell Crippled KFC & Pizza Hut\\n\\nA brilliant case-study on how disadvantages can become strengths and\\n\\n\"Taco Bell is an extraordinary outlier by every measure. It’s a fast food chain that boasts a deeply passionate fanbase, enjoys a reputation for reliability, speed, and accuracy, and when it comes to business - Taco Bell has grown at such a breakneck pace over the past 20 years that it outperforms giants like McDonald’s, Burger King, and KFC in per-store earnings. The Mexican chain is so popular that it’s one of the few companies whose per-store earnings have stayed ahead of inflation.\\n\\nRemarkably, Taco Bell boasts some of the highest ever profit margins ever reported in not just fast food, but also in the restaurant industry. Taco Bell’s renaissance is a miracle in an era where fast food chains all follow the same cookie-cutter playbook of cost-cutting and international expansion to cover up domestic decline like KFC, McDonald’s, and Starbucks.\\n\\nBusiness is a zero-sum game where every decision is connected, every action has a cause and effect, and the rise of one brand contributes to the fall of another. In this episode, we’ll cover the rise of Taco Bell, their strategy that’s made them so successful, and why Taco Bell is the missing puzzle piece behind the downfall of KFC and Pizza Hut and how their struggles in fried chicken and pizza have molded Taco Bell to what it is today, for better and for worse.\"\\n\\nAI Content\\n\\nWeak-to-Strong Jailbreaking on Large Language Models\\n\\nS/o to Ujjawal Panchal for this fantastic find.\\n\\nLarge language models (LLMs) are vulnerable to jailbreak attacks - resulting in harmful, unethical, or biased text generations. However, existing jailbreaking methods are computationally costly. In this paper, we propose the weak-to-strong jailbreaking attack, an efficient method to attack aligned LLMs to produce harmful text. Our key intuition is based on the observation that jailbroken and aligned models only differ in their initial decoding distributions. The weak-to-strong attack’s key technical insight is using two smaller models (a safe and an unsafe one) to adversarially modify a significantly larger safe model’s decoding probabilities. We evaluate the weak-to-strong attack on 5 diverse LLMs from 3 organizations. The results show our method can increase the misalignment rate to over 99% on two datasets with just one forward pass per example. Our study exposes an urgent safety issue that needs to be addressed when aligning LLMs. As an initial attempt, we propose a defense strategy to protect against such attacks, but creating more advanced defenses remains challenging. The code for replicating the method is available at this https URL\\n\\nThe boundary of neural network trainability is fractal\\n\\nAnother argument for Complex NNs. When CVNNs take over, remember where you heard about them. Credit to Lior Sinclair for this find (he’s another great resource for keeping in touch with AI).\\n\\nSome fractals - for instance those associated with the Mandelbrot and quadratic Julia sets - are computed by iterating a function, and identifying the boundary between hyperparameters for which the resulting series diverges or remains bounded. Neural network training similarly involves iterating an update function (e.g. repeated steps of gradient descent), can result in convergent or divergent behavior, and can be extremely sensitive to small changes in hyperparameters. Motivated by these similarities, we experimentally examine the boundary between neural network hyperparameters that lead to stable and divergent training. We find that this boundary is fractal over more than ten decades of scale in all tested configurations.\\n\\nReplicability and stability in learning\\n\\nHave to learn some math to really make assessments, but the first read seems pretty damming.\\n\\nReplicability is essential in science as it allows us to validate and verify research findings. Impagliazzo, Lei, Pitassi and Sorrell (`22) recently initiated the study of replicability in machine learning. A learning algorithm is replicable if it typically produces the same output when applied on two i.i.d. inputs using the same internal randomness. We study a variant of replicability that does not involve fixing the randomness. An algorithm satisfies this form of replicability if it typically produces the same output when applied on two i.i.d. inputs (without fixing the internal randomness). This variant is called global stability and was introduced by Bun, Livni and Moran (’20) in the context of differential privacy.\\n\\nImpagliazzo et al. showed how to boost any replicable algorithm so that it produces the same output with probability arbitrarily close to 1. In contrast, we demonstrate that for numerous learning tasks, global stability can only be accomplished weakly, where the same output is produced only with probability bounded away from 1. To overcome this limitation, we introduce the concept of list replicability, which is equivalent to global stability. Moreover, we prove that list replicability can be boosted so that it is achieved with probability arbitrarily close to 1. We also describe basic relations between standard learning-theoretic complexity measures and list replicable numbers. Our results, in addition, imply that besides trivial cases, replicable algorithms (in the sense of Impagliazzo et al.) must be randomized.\\n\\nThe proof of the impossibility result is based on a topological fixed-point theorem. For every algorithm, we are able to locate a \"hard input distribution\" by applying the Poincaré-Miranda theorem in a related topological setting. The equivalence between global stability and list replicability is algorithmic.\\n\\nOther Content\\n\\nHow Prime Video ingests, processes, and distributes live TV to millions of customers around the world, while reducing costs\\n\\nPrime Video began its live streaming journey in October 2015, with the launch of subscriptions for Showtime and Starz channels in the United States, which included eight linear stations from each channel partner. Since then, in partnership with broadcasters and content owners, we have launched over 1,000 TV stations, bringing a mix of simulcast subscription, traditional free linear, and free ad-supported TV (FAST) services spanning multiple genres such as entertainment, news, and live sports to a global audience.\\n\\nThis article will explain how we built, scaled, and operate our platform globally, and how we think about reliability, availability, cost, security, and sustainability as we grow the content selection and customer base. The article will discuss multiple aspects of our linear TV services and provide an introduction as to how we do live streaming at a global scale.\\n\\nHow Logan Paul & KSI Tricked Millions To Drink Prime\\n\\nThe Ridiculous Rise and Fall of WeWork\\n\\nNow that Adam Neumann is back in the news about wanting to buy WeWork, this is worth remembering.\\n\\nThe Deadly Monetization of Nursing Homes\\n\\nDarin Soat did a great look into the business of nursing homes and how bad business practices are leading to premature deaths and bad service. Worth a watch.\\n\\nIf you liked this article and wish to share it, please refer to the following guidelines.\\n\\nReach out to me\\n\\nUse the links below to check out my other content, learn more about tutoring, reach out to me about projects, or just to say hi.\\n\\nSmall Snippets about Tech, AI and Machine Learning over here\\n\\nAI Newsletter- https://artificialintelligencemadesimple.substack.com/\\n\\nMy grandma’s favorite Tech Newsletter- https://codinginterviewsmadesimple.substack.com/\\n\\nCheck out my other articles on Medium. : https://rb.gy/zn1aiu\\n\\nMy YouTube: https://rb.gy/88iwdd\\n\\nReach out to me on LinkedIn. Let’s connect: https://rb.gy/m5ok2y\\n\\nMy Instagram: https://rb.gy/gmvuy9\\n\\nMy Twitter: https://twitter.com/Machine01776819'}},\n",
       "  {'id': '68896a42b991',\n",
       "   'title': 'Understanding Space-Based Architecture for efficient Data Processing',\n",
       "   'subtitle': 'A possible game-changer for edge AI, real-time supply chain analysis, and more',\n",
       "   'author': '76398be9016',\n",
       "   'publication_id': '*Self-Published*',\n",
       "   'published_at': '2024-02-12 06:10:32',\n",
       "   'last_modified_at': '2024-02-12 06:10:32',\n",
       "   'tags': ['machine-learning',\n",
       "    'artificial-intelligence',\n",
       "    'data-science',\n",
       "    'technology',\n",
       "    'programming'],\n",
       "   'topics': ['machine-learning', 'data-science', 'programming'],\n",
       "   'claps': 143,\n",
       "   'voters': 5,\n",
       "   'word_count': 1519,\n",
       "   'responses_count': 0,\n",
       "   'reading_time': 6.5654088050314465,\n",
       "   'url': 'https://machine-learning-made-simple.medium.com/understanding-space-based-architecture-for-efficient-data-processing-68896a42b991',\n",
       "   'unique_slug': 'understanding-space-based-architecture-for-efficient-data-processing-68896a42b991',\n",
       "   'image_url': 'https://miro.medium.com/0*DNzgMaNXu8TWw4zj.png',\n",
       "   'lang': 'en',\n",
       "   'is_series': False,\n",
       "   'is_locked': False,\n",
       "   'is_shortform': False,\n",
       "   'top_highlight': '',\n",
       "   'content': {'id': '68896a42b991',\n",
       "    'content': 'Understanding Space-Based Architecture for efficient Data Processing\\n\\nA possible game-changer for edge AI, real-time supply chain analysis, and more\\n\\nRecently, I spoke to a reader of AI Made Simple (who wished to remain anonymous) while doing some market research for designing scalable AI applications in the finance industry. They asked me to look into Space Based Architecture (SBA) for data processing and pipelining. SBA seems to be gaining some attention recently, and some of its core ideas are very interesting to me. I have two main motivations for writing this post-\\n\\nTo introduce y’all to this idea that might potentially be big in the coming times.\\n\\nTo get your thoughts/experience with this/similar patterns to get a deeper understanding of the pros and cons of this system (right now, my understanding is limited mostly to what I’ve read).\\n\\nThe systems that supply this data must offer reliable, secure data processing and analysis, in near real-time. This is particularly important in mission-critical industries such as finance, healthcare, and ecommerce, where real-time data processing can make a significant difference in the success of the health of the business - or the patient. Space-Based Data Hubs also enable the creation of real-time applications that can react quickly to changing data.\\n\\n-Source\\n\\nHope you’re ready to have some fun with this-\\n\\nThe core insight of this architecture is to remove the database as a synchronous constraint in the system and instead leverage replicated in-memory data grids. Source\\n\\nJoin 150K+ tech leaders and get insights on the most important ideas in AI straight to your inbox through my free newsletter- AI Made Simple\\n\\nKey Highlights\\n\\nWhat is Space-Based Architecture?\\n\\nEssentially, in SBA applications are built out of a set of self-sufficient units, known as processing-units (PU). These units are independent of each other, so that the application can scale by adding more units.\\n\\n\"At its core, SBA is a software architecture design aimed at achieving linear scalability for high-performance applications and systems. This architecture accomplishes scalability by distributing both processing and storage across multiple servers, effectively creating a \"shared nothing\" system. The term \"space-based\" is derived from the concept of tuple space, a form of shared memory where all data resides and is accessible to every processing unit.\"\\n\\n-Source\\n\\nThe sharing of a common memory allows for a strong fault tolerance (in the PUs) and data availability. Since data is stored in memory, across multiple nodes, it offers fast access and reduces the need for expensive disk I/O. For applications that require high scalability, fault tolerance, and low latency, such as real-time data processing, analytics, and ML modeling, the Space Based Data Hub is a particularly powerful platform.\\n\\nThe main components of Space Based Architectures-\\n\\nSBAs are built from the following components\\n\\nProcessing Units (PU): The part that will perform the business logic and has all the data required to execute. Since they rely on shared data spaces, PUs can be replicated, allowing for efficient load balancing (the work is spread evenly across PUs) and failover (if a PU fails, others can take over its tasks).\\n\\n\\n\\nVirtualized Middleware: This layer handles the shared infrastructure concerns for this architecture. It has the following components:\\n\\nThe Data grid: The backbone this architecture. A given request can be assigned to any of the available processing units, so each PU must contain the same data in its in-memory grid. The data grid is responsible for synchronizing data between the processing units by building the Tuple space (a repository, where processes can add, withdraw or read tuples by means of atomic operations).\\n\\nThe Messaging grid: Handles the flow of incoming transactions as well as the communication between services\\n\\nThe processing grid: Parallel processing component based on the master/worker pattern (also known as a blackboard pattern) that enables parallel processing of events among different services.\\n\\nDeployment manager: Manages the startup and shutdown of the PUs, starts up new PUs to handle any additional load, and shuts down PUs once they are no longer needed.\\n\\nData Pumps: Data pumps are responsible for marshaling data between the database and the processing units.\\n\\nData Writers and Readers: Names are self-explainatory\\n\\nPerformance of SBA vs Architectures-\\n\\nFor a good overview, take a look at the table below-\\n\\n\\n\\nLet’s do a deeper dive into the pros and cons.\\n\\nProblems it solves:\\n\\nScalability: Adding more processing units allows the system to handle exponentially more data without performance bottlenecks.\\n\\nPerformance: Direct access to shared data in memory provides low-latency, high-throughput communication.\\n\\nFault tolerance: Data remains accessible even if individual components fail due to redundancy within the space.\\n\\nFlexibility: Processing units can be added or removed dynamically, adapting to changing needs.\\n\\nLimitations to consider:\\n\\nComplexity: Design and implementation require deep understanding of data flow and concurrency. The key to implementing SBA properly seems to be in breaking down the process into functional units that can be turned into PUs.\\n\\nDebugging: Troubleshooting issues within the shared space can be challenging.\\n\\nSecurity: Ensuring data integrity and access control within the shared space is crucial.\\n\\nLimited adoption: The concept seems to be very unpopular, and mature tooling and best practices are still evolving. I tried to look into case-studies of software firms using it, but couldn’t find any direct sources (only indirect claims where a blog post claims that some other company used it).\\n\\nSBA and AI\\n\\nWhile researching this piece, I thought about some interesting overlaps between AI and SBA. Here are some ways I would think about using SAB/SBA adjacent principles to improve your AI:\\n\\nFederated Learning: FL is a way to improve ML Security, Efficiency, and Privacy all in one. Instead of sending data back to the server of an AI Application, we send, the AI Model updates. The server aggregates the updates from multiple devices (as appropriate), and then sends the models updates back to the devices. It’s one of Amazon’s mainstays, and we covered it in our deep five- How Amazon makes Machine Learning Trustworthy\\n\\n\\n\\nReal-time AI at the Edge: SBA’s low-latency communication can facilitate real-time AI processing at the edge of networks, enabling applications like autonomous vehicles or predictive maintenance in IoT scenarios. A few years ago, I briefly worked with someone looking to build automated robots that can help in detecting survives in disasters. I can see this being super useful there (especially the idea of a tuple space). Also, here is my obligatory plug for how cool and universal self-organizing AI can be because I’m definitely seeing parallels here\\n\\n\\n\\nSupply Chains: Another idea that this might work well in. You could load the supply chain into a shared space, and let clusters of PUs handle different regions. By only having an AI focus on one area, you would keep your AI costs down, and would be able to quickly identify data drift in various regions (you would be able to see if there is data from one region/time that doesn’t match with the protocols of your analysis)\\n\\nImproved Explainability and Debugging: The idea of splitting the decision system into smaller units can be really useful for a deeper level insight into your system (what sub-problem is your AI messing up at).\\n\\nSomething tells me that Mixture of Experts might benefit a lot from an approach inspired by SBA. For multi-modal tasks, imagine having access to a shared pretraining space + input, and then using a gating protocol to call specialized PUs. Here you’d combine the inherent expressivity of multi-modal processing with the performance + cost of specialized setups. I’m a bit fuzzy on details, but if one of you applied researchers has some money + a troop of PhD grunts lying around, this would be a very cool investigation.\\n\\nThat is it for this piece. I appreciate your time. As always, if you’re interested in working with me or checking out my other work, my links will be at the end of this email/post. And if you found value in this write-up, I would appreciate you sharing it with more people. It is word-of-mouth referrals like yours that help me grow.\\n\\n\\n\\nSave the time, energy, and money you would burn by going through all those videos, courses, products, and ‘coaches’ and easily find all your needs met in one place at ‘Tech Made Simple’! Stay ahead of the curve in AI, software engineering, and the tech industry with expert insights, tips, and resources. 20% off for new subscribers by clicking this link. Subscribe now and simplify your tech journey!\\n\\nUsing this discount will drop the prices-\\n\\n800 INR (10 USD) → 640 INR (8 USD) per Month\\n\\n8000 INR (100 USD) → 6400INR (80 USD) per year (533 INR /month)\\n\\nGet 20% off for 1 year\\n\\nReach out to me\\n\\nUse the links below to check out my other content, learn more about tutoring, reach out to me about projects, or just to say hi.\\n\\nSmall Snippets about Tech, AI and Machine Learning over here\\n\\nAI Newsletter- https://artificialintelligencemadesimple.substack.com/\\n\\nMy grandma’s favorite Tech Newsletter- https://codinginterviewsmadesimple.substack.com/\\n\\nCheck out my other articles on Medium. : https://rb.gy/zn1aiu\\n\\nMy YouTube: https://rb.gy/88iwdd\\n\\nReach out to me on LinkedIn. Let’s connect: https://rb.gy/m5ok2y\\n\\nMy Instagram: https://rb.gy/gmvuy9\\n\\nMy Twitter: https://twitter.com/Machine01776819'}},\n",
       "  {'id': '5204dd12bc73',\n",
       "   'title': 'Why Data is an Incomplete Representation of Reality',\n",
       "   'subtitle': 'A look at some major limitations of Data',\n",
       "   'author': '76398be9016',\n",
       "   'publication_id': '*Self-Published*',\n",
       "   'published_at': '2024-02-10 01:37:21',\n",
       "   'last_modified_at': '2024-02-10 01:37:21',\n",
       "   'tags': ['machine-learning',\n",
       "    'artificial-intelligence',\n",
       "    'technology',\n",
       "    'data-science',\n",
       "    'mathematics'],\n",
       "   'topics': ['artificial-intelligence'],\n",
       "   'claps': 336,\n",
       "   'voters': 18,\n",
       "   'word_count': 4016,\n",
       "   'responses_count': 2,\n",
       "   'reading_time': 16.28805031446541,\n",
       "   'url': 'https://machine-learning-made-simple.medium.com/why-data-is-an-incomplete-representation-of-reality-5204dd12bc73',\n",
       "   'unique_slug': 'why-data-is-an-incomplete-representation-of-reality-5204dd12bc73',\n",
       "   'image_url': 'https://miro.medium.com/0*WQ0fY_kNLiVHfH0E.png',\n",
       "   'lang': 'en',\n",
       "   'is_series': False,\n",
       "   'is_locked': False,\n",
       "   'is_shortform': False,\n",
       "   'top_highlight': '',\n",
       "   'content': {'id': '5204dd12bc73',\n",
       "    'content': 'Why Data is an Incomplete Representation of Reality\\n\\nA look at some major limitations of Data\\n\\nWords are a medium that reduces reality to abstraction for transmission to our reason, and in their power to corrode reality inevitably lurks the danger that the words themselves will be corroded too.\\n\\n-\"Sun and Steel\", Yukio Mishima. Mistake data for reality, and you will soon be enveloped by a basterdisized version of reality.\\n\\nPS- \"Sun and Steel\" is one of the most beautiful books I’ve ever read. If you appreciate well-written prose, I highly recommend it. I don’t know what they feed their authors, but b/w Murakami, Musashi, Akutagawa, Dazai, and Mishima- Japanese literature has some of the best-written works I’ve ever seen.\\n\\nExecutive Highlights\\n\\nRecently a Yann LeCunn tweet gained a lot of attention. In it, he states that \"In 4 years, a child has seen 50 times more data than the biggest LLMs... Text is simply too low bandwidth and too scarce a modality to learn how the world works.\" Combined with Meta’s entry into the AGI race, this has led a lot of people to assume that superhuman AI is all about scale and good data.\\n\\nWhile good quality data and appropriate scale are both extremely important for the development of AI systems, it is extremely simplistic to only account for these when making decisions (even Yann’s followers pointed this out in the several great refutations/responses to his tweet). Not accounting for other factors can lead to incomplete, misaligned, or even ultimately harmful systems.\\n\\nInstead of simply responding to the Tweet/some extensions of it, I wanted to try something new. In this article, I want to explore the limitations of data. While data can be an incredibly important tool, there are other kinds of intelligences that aren’t encoded properly into our datasets. Acknowledging this is critical to understanding what Data/AI can and can’t do.\\n\\nSpecifically, here are 3 kinds of intelligence that data can often overlook-\\n\\nCultural Intelligence is the type of intelligence that gets encoded into societal norms and practices w/o a strictly rational explanation. We often underestimate how much of our intelligence is cultural, and our (in)ability to encode this type of intelligence into data can hamper AI training. This shows up in tasks like LLM alignment and Self-Driving Cars.\\n\\nDelusional Intelligence is the ability to create models based on incomplete sensory inputs (creating 3D world models from 2D projections or narratives out of incomplete intelligence). But the principle goes beyond that. What is called ‘reading between the lines’ is nothing more than our ability to hallucinate implications out of data points. By its very nature, such intelligence is not encoded into Data.\\n\\nSubjective Intelligence is the intelligence of a particular person/group that goes against the norm. Population-level studies can often overwrite conflicting narratives from smaller subgroups, which can lead to suppression and a lack of diversity. This is shown with employee tracking AI, which tries to utilize Data to measure productivity. Normative metrics of productivity (which are dubious enough as is), especially hurt disabled people and other ‘outsiders’. Similar problems occur in AI for applicant evaluations.\\n\\nIn this piece, we will explore the implications of missing these intelligences. I won’t make any claims about how useful this article will be to your needs, but hopefully, it does help you see things in a different light.\\n\\nBefore we dive into it, let’s first take a look at what it is that Data and AI actually tell us.\\n\\nJoin 150K+ tech leaders and get insights on the most important ideas in AI straight to your inbox through my free newsletter- AI Made Simple\\n\\nWhat do we Really Learn from Data?\\n\\nTake a second to think about the above question. What kind of insights do we hope to glean from our data or the AI we build?\\n\\nThe way I see it, Data (and the AI we build on it) acts as a mirror that reflects information about our systems and processes back at us. People drastically underestimate how much of what we conceive, build, and measure is influenced by our personal and societal biases. Data is not so much an objective statement about the world, as much as it is a crystallization of our subjectivity. Show me what metrics an organization chooses to measure and improve, and I can tell you what that organization values. By putting data/AI out there, we have a way to analyze our own internal biases (we covered this idea when we discussed how Prompt Engineering would change the world). After all, we are all much better at identifying problems with others than doing some self-reflection.\\n\\nEliminating Bias in AI/ML is a great read.\\n\\nThis is reflected in all kinds of processes. Recently, I did a comprehensive health check-up. The process took hours and helped me learn a bunch of things. However, what stood out to me most was all the things that the test chose to not measure. Here are a few attributes that weren’t measured in my \"complete health check-up\"-\\n\\nVO2 Max. FYI, this is one of the best predictors of your long-term health- \"In one large-scale meta-analysis in 2022, for instance, subjects who ranked in the top one-third of aerobic fitness - as measured by VO2 max - had a 45% reduced risk of death from any cause compared with individuals in the lower third.\"\\n\\nMuscle Strength\\n\\nJoint Flexibility\\n\\nTendon Strength\\n\\nAny kind of mental health checks.\\n\\nGenerally, as people age, they struggle with the above attributes. Given their importance to our long-term wellness, it is very interesting that all of these were omitted from my health checks. Even w/o reading any scientific research, I’m sure you would agree that all of these attributes are key for longevity.\\n\\nGrip Strength: An Indispensable Biomarker For Older Adults. When was the last time you measured this?\\n\\nBut that’s not all. Ancient Greeks would start glitching if they saw that my measurement of health didn’t contain any information about my beauty. Someone inspired by Confucius might label me mentally and ethically deficient b/c of my very deep lack of appreciation for poetry (and/or my generally awful aesthetic sensibilities). Other health standards might be worried about whether I was possessed by evil spirits or whether my energies ‘were aligned’. Even for something as objective and scientific as health, what we choose to value as markers of good health can be based heavily on societal assumptions of what is important to be healthy. If an alien were to study my health reports, it would probably learn as much about our health system and what it considers important for health as it would about how healthy I am.\\n\\nGodel’s Incompleteness explained through a meme.\\n\\nStudy any objective metric/measurement, and you will quickly learn about all kinds of limitations, exceptions, and axioms that come with it. This shouldn’t come as a shock. Ultimately by measuring Data, we are trying to impose rationality on an absurd world. Inconsistency is bound to happen. That doesn’t mean that data or the models aren’t useful. But it is important to always remember that any system we build always has very complex relationships, and things are rarely as cause and effect as simplified models can make it seem. Rely on one metric to base your decisions, and you will quickly learn that something you thought was unrelated ends up being a confounding variable.\\n\\nIn 2019, a bombshell study found that a clinical algorithm many hospitals were using to decide which patients need care was showing racial bias - Black patients had to be deemed much sicker than white patients to be recommended for the same care. This happened because the algorithm had been trained on past data on health care spending, which reflects a history in which Black patients had less to spend on their health care compared to white patients, due to longstanding wealth and income disparities.\\n\\n-AI Sees Race, Even When Humans Can’t\\n\\nOr the evolutionary pressure from prioritizing that metric creates new incentives that skew behaviors in unexpected ways (the incentive for Verra to raise money led to it giving out Carbon Credits that were completely useless, which is completely against why they were created). If you’ve ever wondered, this is why Goodhart’s Law is so ubiquitous.\\n\\nMake weight a primary metric, and companies will lobby the government to change the definition of a nail to sell huge chunks of impure iron as a nail.\\n\\nIt is not just the scale of data that impedes super-intelligent AI. Or an inefficient modality. Or that we have the wrong architecture. It’s that data is a fickle mistress. By itself, it’s completely useless. It is only useful because we interpret it. There are often lots of cultural connotations and unsaid things about our data, that we become numb to just based on familiarity. Our tasks are a few orders of magnitude more complex than our data might imply. Utilizing more data (even high-quality data) without considering that will invariably lead to overestimation of the systems we build. We’ve already seen this with Language Models and their struggle with understanding Language.\\n\\nFor the rest of this piece, I want to cover the kinds of information/intelligence that Datasets often overlook.\\n\\nCultural Intelligence (I wasn’t able to find a technical term for this, but if you do know it please lmk)\\n\\nWhen you think about it, there are all kinds of practices that different cultures follow, without an explicit scientific reason. Here, I’m not talking about superstitions, but practices that can be proven beneficial by our knowledge, but where the adherents might not have such justifications.\\n\\nA great example of this is our diet. Civilizations across the world were able to come up with diets that hit both macro and micronutrient needs, w/o necessarily understanding nutrition to the degree we understand it today. \"Daal, Chawal, and Subji\", \"Meat and Potatoes\", \"Rice, Fish, and Miso Soup\", the existence of unique fermented foods in different cultures, and other such parallels are all examples of cultures arriving at complete diets w/o modern nutrition science. Take a second to appreciate how insane that is.\\n\\nThe coolest example of this can be seen below. Tribes in the Amazon have been able to avoid cyanide ingestion for thousands of years, by following complicated routines w/o necessarily understanding how their process removed the cyanide.\\n\\nIn the Americas where cassava was first domesticated, locals consumed it for thousands of years without suffering from the effects of cyanide ingestion. Some Amazonian tribes rely on a complex transformation process to eliminate the cyanide from the cassava. This process consists of many steps including grating the root, pressing moisture off the grated pulp, washing it and drying it before finally boiling it. Interestingly, women from those tribes who dedicate a significant amount of their time to this activity don’t even know what these techniques are supposed to achieve\\n\\n-Tribal Knowledge & Change: Lessons Learnt from Cassava Travel to Africa\\n\\nRelying solely on traditional data from such tribes would do injustice to this evolutionary kind of intelligence. Would you document just the process, and ignore the reasoning? How would you know what practice and reason to follow and which ones to ignore? It’s impossible to track data without a framework on what we consider important.\\n\\nWith that, it’s not hard to imagine samples being dropped, and examples being ignored because they weren’t \"justified\" or b/c for the sake of cleaning data to match our predefined templates for data analysis (I can’t tell you how many teams rush to drop outliers/incomplete samples just to get better accuracy). Sometimes this is necessary. Other times, it’s a sign of incompetence and laziness. In all cases, it’s an imposition of a value judgment- a conscious decision to prioritize certain elements of a phenomenon and to disregard others.\\n\\nIgnoring cultural intelligence can lead to billions of dollars spent, only to come back to the place we started. A lot of tech companies have recently realized this. Uber, Spotify, and Crypto were introduced as disruptors that would innovate upon their old entrenched industries, bypassing regulations and providing access directly to the people. All of these have ended up becoming precisely the monster they set out to slay.\\n\\nCultural Norms are formed over decades. They can become so engrained into our psyche that we become invisible to them. This is a big reason why Alignment Efforts have struggled so much- we implicitly assume that our samples are teaching the bots something, but in reality, they only contain that information partially. The rest is our collective information filling in the details, w/o us realizing it.\\n\\nAI, which lacks this component, fails at doing so, leading to lots of unintended misalignment. This has shown up many times with LLMs. For a non-LLM related example, take a look at Self Driving Cars and their struggle with navigating merges-\\n\\nThey’re not wrong: Self-driving cars do find merges challenging. In fact, it’s a problem that points to one of the harshest realities facing everyone teaching computers to drive themselves: For the foreseeable future, they’ll be sharing the road with human drivers. Humans who tend to favor flexible, communication-based interaction over following rules by the letter. Humans who can be capricious and inattentive. Humans who can be jerks, humans who can be generous.\\n\\n\"Merging is one of these beautiful problems where you have to understand what someone else is going to do,\" says Ed Olson, the CEO and cofounder of the autonomous vehicle company May Mobility. \"You’re going to get in the way of someone’s plan, because everyone wants to keep going straight and not let you in. You need to change their mind and change their behavior, and you do that by driving in towards where you want to merge and they finally acquiesce.\"\\n\\n-How Robocars Handle the Frustratingly Human Act of Merging\\n\\nTheir data focuses on rules and protocols, not contextual and always changing communication cues. They are not trained to fill in these blanks, leading to inaction. Speaking about things being filled in, let’s talk about one of humanity\\'s biggest collective delusions.\\n\\nDelusional Intelligence\\n\\nOnce again, if you know the actual (or even a better name), please be my guest. Turns out I’m worse at naming things than I thought. Not Manchester United Transfer Policy bad, but getting dangerously close. Maybe Jon Jones eye pokes bad.\\n\\nDelusional Intelligence is the kind of intelligence that we develop specifically through our hallucinations. And you hallucinate a lot more than you realize. Take a look at the following panel from my recent manga addiction- Blue Lock (if you can ignore the over-the-topness and weird striker fetishization, this series is a masterpiece).\\n\\nIf you like Blue Lock, you have elite taste and I will gladly share my milk with you.\\n\\nYour mind probably processed that image in 3-D. This is a fictional story, with no actual characters for you to reference (and no color either). Even so, your mind has no problems constructing a 3D model of the world and placing these characters. You do this so naturally that it might seem trivial, but this is among the biggest challenges in Computer Vision.\\n\\nYour mind is 3D. The world is 3D. We can take 2D projections of 3D objects, and then visualize them as 3D. That is why an architect can look at floor plans, compare them against a set of guidelines, and tell you whether the plans are compliant.\\n\\nAI is trained on information that is 2D (even 3D images are just 2D projections of 3D objects). The world is 3D. That is a problem. Big problem.\\n\\nI don’t talk much about this - I obtained one of the first FDA approvals in ML + radiology and it informs much of how I think about AI systems and their impact on the world. If you’re a pure technologist, you should read the following:\\n\\n…Here’s a bunch of stuff you wouldn’t know about radiologists unless you built an AI company WITH them instead of opining about their job disappearing from an ivory tower.\\n\\n(1) Radiologists are NOT performing 2d pattern recognition - they have a 3d world model of the brain and its physical dynamics in their head. The motion and behavior of their brain to various traumas informs their prediction of hemorrhage determination.\\n\\n—This whole rant about why technologists often get predictions so wrong is worth reading every day.\\n\\nWhenever we see a 2D image, we hallucinate to create a 3D model. This allows us to solve challenges with it. A lot of image processing falls apart in production precisely because it’s unable to do the same. This is worth thinking about with the rise of multi-modality. As more capabilities are integrated, it will be important to account for how mechanical sensory systems differ from ours and design the tests accordingly.\\n\\nCombined with a loss of cultural intelligence in data samples, AI\\'s inability to hallucinate the way we do is probably why training on AI-generated outputs eventually leads to a breakdown in performance. Every AI-generated sample suffers from a Chinese Whispers style of loss of information. Perform enough iterations, and lost information will show up as artifacts, deviations, or divergent behavior.\\n\\nCheck the experiment- Looping ChatGPT & DALL-E: 20 Rounds of Describing & Recreating the Mona Lisa! The end result in just 20 iterations is completely different from the starting input-\\n\\n\\n\\nOur delusions do a lot more heavy lifting than you might be willing to give them credit for. They are so important that we have a name for this highly important skill- ‘reading between the lines’. To be successful in most complex endeavors, the ability to look through the data to grasp the hidden themes is considered a must.\\n\\nClean data often seeks to hammer out these delusions to standardize the systems. This leads to a lack of nuance and a loss of important context. Taken to the extreme, the drive to pursue standardization can skew narratives eliminating differing thoughts. Let’s cover that next.\\n\\nSubjective Intelligence\\n\\nMuch of Data Analysis works at the population-based level: we try to study members of a population to extract what is common, try to analyze that, and build trends on that. This Kantian attempt at regularizing the observation of phenomena has been the bedrock of a lot of innovation, but it is important to acknowledge its limitations.\\n\\nWhen I did health system analysis for a state government, one of the problems was the illiteracy of the citizens filling out our forms. They would often fill out information wrong, get intimidated by the sheets and leave fields blank, etc. Pretty much everything that can go wrong with a dataset went wrong with ours. Ignoring the data that didn’t match industry-defined standards would lead to the exclusion of information from the people who were most vulnerable and dependent on the services provided (the state had a population of 300 Million people, so any change could impact millions).\\n\\nThere is generally a large discrepancy between the people who design technologies and some of the vulnerable groups that are most impacted by the technologies. The UK government experienced this firsthand when its Universal Credit system failed to account for some of the differences b/w normal people and folks w/ irregular, low-paid work.\\n\\nIn 2013, the UK government’s roll out of its new Universal Credit system was designed to simplify access to benefits, cut administrative costs, and \"improve financial work incentives\" by combining six social security benefits into one monthly lump sum. However, in practice it has resulted in considerable harm to those depending on state benefits.\\n\\nA flawed algorithm failed to account for the way people with irregular, low-paid jobs were collecting their earnings via multiple paychecks a month. This meant that in some cases, individuals were assumed to receive earning above the relevant monthly earnings threshold, which, in turn, drastically shrank the benefits they received.\\n\\nBy requiring people to request their benefits online, the system also caused hardship amongst those who did not have reliable internet access, who lacked the digital skills to fill out long web forms about their personal and financial circumstances, or who could not meet cumbersome online identity verification requirements. Add to this the fact that applicants had to wait five weeks for their first payment, and it is easy to see that every day \"lost\" on not being able to complete a complicated online application process adds to existing hardship.\\n\\n-How Artificial Intelligence Impacts Marginalised Groups is an absolutely phenomenal read for examples of systems excluding certain groups.\\n\\nOr take Financial Systems. Credit Software often utilizes demographic information to predict whether someone is credit-worthy. This software might flag someone as risky based on historical demographic trends, denying them access to credit (or giving them higher interest rates). This will only increase the risk of default (worst case restrict them from access to credit), further perpetuating this pattern.\\n\\nAnother example can be seen in employee productivity software. The metrics used to measure productivity can penalize poor, disabled, or neurodivergent folk- who might otherwise be doing a great job. In marking them as lower productivity, the organization will end up pushing them out/relegating them. Any analysis done on top of this data will only further ‘prove’ that these folk were not good workers, entrenching this further. If decisions are made based on this, then it will only further alienate people from these groups, without us realizing it.\\n\\nWe discussed something similar in our look into Social Media, and how ‘the algorithm’ leads to the establishment of a dominant narrative and loss of critical thinking.\\n\\nThis is why good design and engaging multiple stakeholders are key. Without them, you can end up unwittingly excluding divergent viewpoints/characters.\\n\\nThis ties into a larger point about technology and how it reinforces existing power structures, if not deployed properly. Yes. it can be used to provide equal access to opportunities. But often it’s people in privileged positions that are in the right place to fully take advantage of these opportunities, have more chances to succeed, and can get back on their feet easier if they do fail. But I’m not sure how interested y’all are in these more meta pieces, so I won’t go into it too deeply now. Let me know if you are interested in that.\\n\\nI’ll end this with reading recommendations for those of you who are interested in more in-depth critiques of abstract systems and the limits of rationality. Firstly, I will never miss a chance to recommend my all-time favorite writer/philosopher- Soren Kierkegaard. His analysis of these topics is brilliant and he’s been at or near the top of my reading/recommendation list for about 7 years now (for very different reasons though). Another great work would be Nietzche’s, \"Twilight of the Idols\", where he critiques the enlightenment era view of an objective reality. In many ways, these two were the spiritual inspirations for this piece.\\n\\nIf you liked this article and wish to share it, please refer to the following guidelines.\\n\\nThat is it for this piece. I appreciate your time. As always, if you’re interested in working with me or checking out my other work, my links will be at the end of this email/post. And if you found value in this write-up, I would appreciate you sharing it with more people. It is word-of-mouth referrals like yours that help me grow.\\n\\nIf you find AI Made Simple useful and would like to support my writing- please consider becoming a premium member of my cult by subscribing below. Subscribing gives you access to a lot more content and enables me to continue writing. This will cost you 400 INR (5 USD) monthly or 4000 INR (50 USD) per year and comes with a 60-day, complete refund policy. Understand the newest developments and develop your understanding of the most important ideas, all for the price of a cup of coffee.\\n\\nBecome a premium member\\n\\n\\n\\nI regularly share mini-updates on what I read on the Microblogging sites X(https://twitter.com/Machine01776819), Threads(https://www.threads.net/@iseethings404), and TikTok(https://www.tiktok.com/@devansh_ai_made_simple)- so follow me there if you’re interested in keeping up with my learnings.\\n\\nReach out to me\\n\\nUse the links below to check out my other content, learn more about tutoring, reach out to me about projects, or just to say hi.\\n\\nSmall Snippets about Tech, AI and Machine Learning over here\\n\\nAI Newsletter- https://artificialintelligencemadesimple.substack.com/\\n\\nMy grandma’s favorite Tech Newsletter- https://codinginterviewsmadesimple.substack.com/\\n\\nCheck out my other articles on Medium. : https://rb.gy/zn1aiu\\n\\nMy YouTube: https://rb.gy/88iwdd\\n\\nReach out to me on LinkedIn. Let’s connect: https://rb.gy/m5ok2y\\n\\nMy Instagram: https://rb.gy/gmvuy9\\n\\nMy Twitter: https://twitter.com/Machine01776819'}}],\n",
       " 'd80580992695': [{'id': '6a7ab0b04d35',\n",
       "   'title': 'Don’t use loc/iloc with Loops In Python, Instead, Use This!',\n",
       "   'subtitle': 'Run your loops at a 60X faster speed',\n",
       "   'author': 'd80580992695',\n",
       "   'publication_id': '29038077e4c6',\n",
       "   'published_at': '2024-01-24 01:46:17',\n",
       "   'last_modified_at': '2024-01-30 10:42:58',\n",
       "   'tags': ['python',\n",
       "    'data-science',\n",
       "    'data-analysis',\n",
       "    'programming',\n",
       "    'loops-in-python'],\n",
       "   'topics': ['data-science', 'programming'],\n",
       "   'claps': 1311,\n",
       "   'voters': 331,\n",
       "   'word_count': 679,\n",
       "   'responses_count': 10,\n",
       "   'reading_time': 2.9455974842767296,\n",
       "   'url': 'https://medium.com/codex/dont-use-loc-iloc-with-loops-in-python-instead-use-this-6a7ab0b04d35',\n",
       "   'unique_slug': 'dont-use-loc-iloc-with-loops-in-python-instead-use-this-6a7ab0b04d35',\n",
       "   'image_url': 'https://miro.medium.com/1*SyvWzmE0YT19onb4ODlYrw.jpeg',\n",
       "   'lang': 'en',\n",
       "   'is_series': False,\n",
       "   'is_locked': True,\n",
       "   'is_shortform': False,\n",
       "   'top_highlight': 'loc and iloc are meant to access multiple elements(series/dataframe) at the same time, potentially to perform vectorized operations.',\n",
       "   'content': {'id': '6a7ab0b04d35',\n",
       "    'content': \"Don’t use loc/iloc with Loops In Python, Instead, Use This!\\n\\nRun your loops at a 60X faster speed\\n\\nPic Credit: Unsplash\\n\\nRecently, I was experimenting with loops in Python and realized that using ‘iloc’/ ‘loc’ within the loops takes a lot of time to execute. The immediate next question was why is ‘loc’ taking too much time and what is the alternative to ‘loc’?\\n\\nIn this blog, we will answer these questions by looking at some practical examples.\\n\\nWhat is loc - if you don’t know already!\\n\\nThe loc[] function is a pandas function that is used to access the values within a DataFrame using the row index and column name. It is used when you know which row and column you want to access.\\n\\nLet’s understand loc using an example. We have the following pandas DataFrame named df(shown below) and we want to access the value corresponding to the 2nd row in the column ‘a’ i.e. 10.\\n\\nDataFrame df (Image by Author)\\n\\nWe can access the value using the following code:\\n\\n##df.loc[index, column_name]\\n\\ndf.loc[1,'a']\\n\\n### Output: 10\\n\\nSimilarly, iloc is used to access the value using index and column numbers.\\n\\n##df.loc[index, column_number]\\n\\ndf.iloc[1,0]\\n\\n### Output: 10\\n\\nSo, the loc function is used to access columns using column names while the iloc function is used to access columns using column indexes.\\n\\nWhat happens if you use loc/iloc with loops in Python?\\n\\nImagine, we want to add a new column ‘c’, which is equal to the sum of values of column ‘a’ and column ‘b’, to our DataFrame df.\\n\\nUsing the ‘for’ loop, we can iterate through our DataFrame and add a new column ‘c’ using the loc function as shown below:\\n\\nimport timestart = time.time()\\n\\n# Iterating through the DataFrame df\\nfor index, row in df.iterrows():\\n        df.loc[index,'c'] = row.a + row.b\\n\\nend = time.time()\\nprint(end - start)\\n\\n### Time taken: 2414 seconds\\n\\nThe time taken to iterate and update values using loc is around 40 minutes, which is a lot.\\n\\nAlternative: Using ‘at’ in place of ‘loc’\\n\\nWe can perform the same manipulation by replacing ‘loc’ with ‘at’ (or replacing ‘iloc’ with ‘iat’) as shown below.\\n\\nimport timestart = time.time()\\n\\n# Iterating through DataFrame \\nfor index, row in df.iterrows():\\n    df.at[index,'c'] = row.a + row.b\\n\\nend = time.time()\\nprint(end - start)\\n### Time taken: 40 seconds\\n\\nThe code gets executed in ~ 0.7 minutes which is 60 times faster as compared to the time taken by the loc function.\\n\\n‘loc’ vs ‘at’ why the difference in the runtime?\\n\\n‘at’/ ‘iat’\\n\\nat and iat are meant to access a scalar, that is, a single element in the DataFrame, as shown below:\\n\\ndf.at[2,'a']\\n### Output: 22\\n\\ndf.iat[2,0]\\n### Output: 22\\n\\nIf we try to access a series using at and iat, then it throws an error as shown below:\\n\\n## This will give an error as we are trying to access multiple rows\\ndf.at[:3,'a']\\n### Output: ValueError: At based indexing on an integer index can only have integer indexers\\n\\n‘loc’/ ‘iloc’\\n\\nloc and iloc are meant to access multiple elements(series/dataframe) at the same time, potentially to perform vectorized operations.\\n\\ndf.loc[:3,'a']\\n### Output\\n##0    26\\n##1    10\\n##2    22\\n##3    22\\n\\ndf.loc[:3,0]\\n### Output\\n##0    26\\n##1    10\\n##2    22\\n##3    22\\n\\nAs, at is used to access a scaler value so it is lightweight (implementation is fast) as compared to loc which is used to access series/datafame and thus takes more space and time.\\n\\nThe following blog talks about the best practices of iterating through a pandas dataframe. I would recommend you to skim through this.\\n\\nDon’t use Apply in Python, follow these Best Practices!\\nAlternatives to the Apply function to improve the performance by 700xtowardsdatascience.com\\n\\nConclusion\\n\\nUsing ‘loc’/’iloc’ within the loops in Python is not optimal and should be avoided. Instead, we should use ‘at’ / ‘iat’ wherever required as they are much faster as compared to ‘loc’ / ‘iloc’.\\n\\nAlso, please keep in mind that ‘loc’/’iloc’ works amazingly well ‘outside’ the loops in python when we apply vectorized operations.\\n\\nThank You!\\n\\nI hope you found the story useful. You can get all my posts in your inbox. Do that here!\"}},\n",
       "  {'id': 'e8b0172b9581',\n",
       "   'title': 'Say Goodbye to Loops in Python, and Welcome Vectorization!',\n",
       "   'subtitle': 'Use Vectorization\\u200a—\\u200aa super-fast alternative to loops in Python',\n",
       "   'author': 'd80580992695',\n",
       "   'publication_id': '29038077e4c6',\n",
       "   'published_at': '2023-12-28 02:01:32',\n",
       "   'last_modified_at': '2023-12-29 08:28:02',\n",
       "   'tags': ['data-science',\n",
       "    'programming',\n",
       "    'python',\n",
       "    'data-analysis',\n",
       "    'python-programming'],\n",
       "   'topics': ['data-science', 'programming'],\n",
       "   'claps': 4313,\n",
       "   'voters': 1310,\n",
       "   'word_count': 966,\n",
       "   'responses_count': 55,\n",
       "   'reading_time': 4.595283018867924,\n",
       "   'url': 'https://medium.com/codex/say-goodbye-to-loops-in-python-and-welcome-vectorization-e8b0172b9581',\n",
       "   'unique_slug': 'say-goodbye-to-loops-in-python-and-welcome-vectorization-e8b0172b9581',\n",
       "   'image_url': 'https://miro.medium.com/0*OMVt9wKbfIPJIB_5.jpeg',\n",
       "   'lang': 'en',\n",
       "   'is_series': False,\n",
       "   'is_locked': True,\n",
       "   'is_shortform': False,\n",
       "   'top_highlight': \"Vectorization is the technique of implementing (NumPy) array operations on a dataset. In the background, it applies the operations to all the elements of an array or series in one go (unlike a 'for' loop that manipulates one row at a time).\",\n",
       "   'content': {'id': 'e8b0172b9581',\n",
       "    'content': 'Say Goodbye to Loops in Python, and Welcome Vectorization!\\n\\nUse Vectorization - a super-fast alternative to loops in Python\\n\\n\\n\\nIntroduction\\n\\nLoops come to us naturally, we learn about Loops in almost all programming languages. So, by default, we start implementing loops whenever there is a repetitive operation. But when we work with a large number of iterations (millions/billions of rows), using loops is a crime. You might be stuck for hours, to later realize that it won’t work. This is where implementing Vectorisation in Python becomes super crucial.\\n\\nWhat is Vectorization?\\n\\nVectorization is the technique of implementing (NumPy) array operations on a dataset. In the background, it applies the operations to all the elements of an array or series in one go (unlike a ‘for’ loop that manipulates one row at a time).\\n\\nIn this blog, we will look at some of the use cases where we can easily replace Python loops with Vectorization. This will help you save time and become more skillful in coding.\\n\\nUSE CASE 1: Finding the Sum of numbers\\n\\nFirst, we will look at a fundamental example of finding the sum of numbers using loops and Vectorization in Python.\\n\\nUsing Loops\\n\\nimport time \\nstart = time.time()\\n\\n# iterative sum\\ntotal = 0\\n# iterating through 1.5 Million numbers\\nfor item in range(0, 1500000):\\n    total = total + item\\n\\nprint(\\'sum is:\\' + str(total))\\nend = time.time()\\nprint(end - start)\\n#1124999250000\\n#0.14 Seconds\\n\\nUsing Vectorization\\n\\nimport numpy as np\\n\\nstart = time.time()\\n# vectorized sum - using numpy for vectorization\\n# np.arange create the sequence of numbers from 0 to 1499999\\nprint(np.sum(np.arange(1500000)))\\nend = time.time()\\nprint(end - start)\\n\\n##1124999250000\\n##0.008 Seconds\\n\\nVectorization took ~18x less time to execute as compared to the iteration using the range function. This difference will become more significant while working with Pandas DataFrame.\\n\\nUSE CASE 2: Mathematical Operations (on DataFrame)\\n\\nIn Data Science, while working with Pandas DataFrame, the developers use loops to create new derived columns using mathematical operations.\\n\\nIn the following example, we can see how easily the loops can be replaced with Vectorization for such use cases.\\n\\nCreating the DataFrame\\n\\nThe DataFrame is tabular data in the form of rows and columns.\\n\\nWe are creating a pandas DataFrame having 5 Million rows and 4 columns filled with random values between 0 and 50.\\n\\nimport numpy as np\\nimport pandas as pd\\ndf = pd.DataFrame(np.random.randint(0, 50, size=(5000000, 4)), columns=(\\'a\\',\\'b\\',\\'c\\',\\'d\\'))\\ndf.shape\\n# (5000000, 5)\\ndf.head()\\n\\nSnapshot of the top 5 rows (Image by Author)\\n\\nWe will create a new column ‘ratio’ to find the ratio of the column ‘d’ and ‘c’.\\n\\nUsing Loops\\n\\nimport time \\nstart = time.time()\\n\\n# Iterating through DataFrame using iterrows\\nfor idx, row in df.iterrows():\\n    # creating a new column \\n    df.at[idx,\\'ratio\\'] = 100 * (row[\"d\"] / row[\"c\"])  \\nend = time.time()\\nprint(end - start)\\n### 109 Seconds\\n\\nUsing Vectorization\\n\\nstart = time.time()\\ndf[\"ratio\"] = 100 * (df[\"d\"] / df[\"c\"])\\n\\nend = time.time()\\nprint(end - start)\\n### 0.12 seconds\\n\\nWe can see a significant improvement with DataFrame, the time taken by the Vectorization operation is almost 1000x faster as compared to the loops in Python.\\n\\nUSE CASE 3: If-else Statements (on DataFrame)\\n\\nWe implement a lot of operations that require us to use the ‘If-else’ type of logic. We can easily replace these logics with Vectorization operations in Python.\\n\\nLet’s look at the following example to understand it better (we will be using the DataFrame that we created in use case 2):\\n\\nImagine we want to create a new column ‘e’ based on some conditions on the exiting column ‘a’.\\n\\nUsing Loops\\n\\nimport time \\nstart = time.time()\\n\\n# Iterating through DataFrame using iterrows\\nfor idx, row in df.iterrows():\\n    if row.a == 0:\\n        df.at[idx,\\'e\\'] = row.d    \\n    elif (row.a <= 25) & (row.a > 0):\\n        df.at[idx,\\'e\\'] = (row.b)-(row.c)    \\n    else:\\n        df.at[idx,\\'e\\'] = row.b + row.c\\nend = time.time()\\nprint(end - start)\\n### Time taken: 177 seconds\\n\\nUsing Vectorization\\n\\n# using vectorization \\n\\nstart = time.time()\\ndf[\\'e\\'] = df[\\'b\\'] + df[\\'c\\']\\ndf.loc[df[\\'a\\'] <= 25, \\'e\\'] = df[\\'b\\'] -df[\\'c\\']\\ndf.loc[df[\\'a\\']==0, \\'e\\'] = df[\\'d\\']end = time.time()\\nprint(end - start)\\n## 0.28007707595825195 sec\\n\\nThe time taken by the Vectorization operation is 600x faster as compared to the Python loops with if-else statements.\\n\\nUSE CASE 4 (Advance): Solving Machine Learning/Deep Learning Networks\\n\\nDeep Learning requires us to solve multiple complex equations and that too for millions and billions of rows. Running loops in Python to solve these equations is very slow and Vectorization is the optimal solution.\\n\\nFor example, to calculate the value of y for millions of rows in the following equation of multi-linear regression:\\n\\nLinear Regression (Image by Author)\\n\\nwe can replace loops with Vectorization.\\n\\nThe values of m1,m2,m3… are determined by solving the above equation using millions of values corresponding to x1,x2,x3… (for simplicity, we will just look at a simple multiplication step)\\n\\nCreating the Data\\n\\nimport numpy as np\\n# setting initial values of m \\nm = np.random.rand(1,5)\\n\\n# input values for 5 million rows\\nx = np.random.rand(5000000,5)\\n\\nOutput of m (Image by Author)\\n\\nOutput of x (Image by Author)\\n\\nUsing Loops\\n\\nimport numpy as np\\nm = np.random.rand(1,5)\\nx = np.random.rand(5000000,5)\\n\\ntotal = 0\\ntic = time.process_time()\\nfor i in range(0,5000000):\\n    total = 0\\n    for j in range(0,5):\\n        total = total + x[i][j]*m[0][j] \\n        \\n    zer[i] = total \\ntoc = time.process_time()\\nprint (\"Computation time = \" + str((toc - tic)) + \"seconds\")\\n####Computation time = 28.228 seconds\\n\\nUsing Vectorization\\n\\nDot Product of 2 matrix (Image by Author)\\n\\ntic = time.process_time()\\n\\n#dot product \\nnp.dot(x,m.T) \\ntoc = time.process_time()\\nprint (\"Computation time = \" + str((toc - tic)) + \"seconds\")\\n####Computation time = 0.107 seconds\\n\\nThe np.dot implements Vectorized matrix multiplication in the backend. It is 165x faster as compared to loops in Python.\\n\\nConclusion\\n\\nVectorization in Python is super fast and should be preferred over loops, whenever we are working with very large datasets.\\n\\nStart implementing it over time and you will become comfortable with thinking along the lines of vectorization of your codes.\\n\\nThank You for reading!\\n\\nYou can get all my posts in your inbox. Do that here!'}},\n",
       "  {'id': '792181d2464a',\n",
       "   'title': 'Top 10 Data Visualizations of 2023 Worth Looking at!',\n",
       "   'subtitle': 'Level Up Your Visualization Game!',\n",
       "   'author': 'd80580992695',\n",
       "   'publication_id': '29038077e4c6',\n",
       "   'published_at': '2023-12-27 01:01:42',\n",
       "   'last_modified_at': '2023-12-29 08:28:09',\n",
       "   'tags': ['data-science',\n",
       "    'data-visualization',\n",
       "    'data',\n",
       "    'visualization',\n",
       "    'data-analysis'],\n",
       "   'topics': ['data-science'],\n",
       "   'claps': 993,\n",
       "   'voters': 297,\n",
       "   'word_count': 794,\n",
       "   'responses_count': 13,\n",
       "   'reading_time': 3.1962264150943396,\n",
       "   'url': 'https://medium.com/codex/top-10-data-visualizations-of-2023-worth-looking-at-792181d2464a',\n",
       "   'unique_slug': 'top-10-data-visualizations-of-2023-worth-looking-at-792181d2464a',\n",
       "   'image_url': 'https://miro.medium.com/1*qcQcxcTncHwVMBExIY5oZg.png',\n",
       "   'lang': 'en',\n",
       "   'is_series': False,\n",
       "   'is_locked': True,\n",
       "   'is_shortform': False,\n",
       "   'top_highlight': '',\n",
       "   'content': {'id': '792181d2464a',\n",
       "    'content': \"Top 10 Data Visualizations of 2023 Worth Looking at!\\n\\nLevel Up Your Visualization Game!\\n\\nWhy is data visualization a crucial skill?\\n\\nThe human brain can easily interpret and understand a visualization as compared to a spreadsheet filled with numbers. The message conveyed using a visual stays in the audience's mind for a long time. So, if you work with data or plan to do so, then data visualization is a must-have skill for you.\\n\\nIn this blog, I will take you through my list of top 10 data visualizations of 2023 and we will draw some inspirations from these.\\n\\n1. Adobe Income Statement\\n\\nPic Credit: Reddit\\n\\nSankey diagrams are very effective in visualizing the flow from one state(revenue) to another(profit & expenses). The above Sankey graph shows the income statement of Adobe for FY’23.\\n\\nThe choice of the graph and the color combination(Red for expenses, Green for profit, and Grey for revenue) make it very intuitive and easy to understand.\\n\\n2. Depreciation of luxury cars\\n\\n\\n\\nThe above visualization shows the fastest-depreciating cars and interestingly, it is not shown by a bar graph which most of us might have opted for.\\n\\nThe visualization becomes so real with the use of the images of the cars and the way of showing the depreciation is unique and easy to compare.\\n\\n3. Government Debt Ranking\\n\\n\\n\\nThe bar graph is one of the most intuitive and interpretable visualizations, so how can I not choose a bar graph in my top 10 list? The above graph shows the government debt across advanced economies.\\n\\nThe graph is simple yet effective - showing all the countries with the same color and the G7 average (added for benchmark) is shown with a neutral color - grey.\\n\\nDon’t Do this! Sometimes, when we create bar graphs we tend to represent each bar with a different color. This is not the right practice as it leads the observer to look for some correlation between color and the bar label and diverts attention.\\n\\n4. Spotify Most Streamed Albums\\n\\n\\n\\nThe above bar chart shows the most streamed albums on Spotify in 2023.\\n\\nThe bars have come lively with the use of the albums' themes and the winner - Bad Bunny - has been rightly highlighted with white-colored larger text showing 4.5 Billion streams.\\n\\n5. Most Popular Brand - CyberMonday\\n\\n\\n\\nThe above graph shows the most popular brand on Cyber Monday across states in the US.\\n\\nThe way of representing the brands over the map makes it easy to interpret and highlights the aspect of the popularity of the same brand in neighboring states too.\\n\\n6. Employee Retention\\n\\n\\n\\nThe above visualization shows companies with the worst employee retention. The information is represented as a ranked list.\\n\\nThe use of larger text at the start of the report to highlight the main theme of the report is spot on, followed by detailed information in small text size.\\n\\nThe list highlights the company name, and the magnitude of the tenure is represented in months by rectangles, making it very easy to interpret.\\n\\n7. Global Warming in 2023\\n\\n\\n\\nThe above chart shows the trajectory of global warming in 2023, highlighting that global warming is happening much faster now than in 2015 when the Paris Agreement was signed. So, now we know how seriously the Paris Agreement is being followed.\\n\\nThe chart shows the information perfectly - the heading of the chart shows the takeaway, and the use of a red dotted and a red solid line represents the current alarming trajectory and the thresholds(1.5C) respectively.\\n\\n8. 2023 Search Trends\\n\\n\\n\\nThe above plot is called the ridgeline plot. It summarizes the distribution of a numeric variable for several groups.\\n\\nIn the above example, the choice of the graph is appropriate for showing the Google search trends in 2023. We can find that there are consistently high search volumes for COVID across the year and GPT 4 dominated the search in March soon after its launch.\\n\\n9. Where do Christmas Trees Grow?\\n\\n\\n\\nThe visualization shows the counties where Christmas Trees are grown in the US.\\n\\nThe height of trees representing the number of trees grown is unique and effective in showing the comparison between the counties.\\n\\n10. Orbital Launches per Year\\n\\n\\n\\nThe above animation graphs show the successful orbital launches per year per country.\\n\\nIn the above animation, we can see that before 1990, most of the orbital lunches were by the Soviet Union/Russia but since 2015, China and the US have had a lot of successful orbital launches, and more countries have joined this list.\\n\\nWhich one is your favorite? Share in the comments which one you like and why.\\n\\nThank You!\\n\\nIf you find my blogs useful, then you can follow me to get direct notifications whenever I publish a story.\"}},\n",
       "  {'id': 'cb7975befa53',\n",
       "   'title': 'Follow this 10-Step Template for an Awesome Data Analysis!',\n",
       "   'subtitle': 'Pic Credit: Unsplash',\n",
       "   'author': 'd80580992695',\n",
       "   'publication_id': '78073def27b8',\n",
       "   'published_at': '2023-09-21 01:02:53',\n",
       "   'last_modified_at': '2024-01-27 19:11:28',\n",
       "   'tags': ['data-analysis',\n",
       "    'data-science',\n",
       "    'data-visualization',\n",
       "    'python',\n",
       "    'programming'],\n",
       "   'topics': ['data-science'],\n",
       "   'claps': 553,\n",
       "   'voters': 100,\n",
       "   'word_count': 1106,\n",
       "   'responses_count': 4,\n",
       "   'reading_time': 5.473584905660378,\n",
       "   'url': 'https://python.plainenglish.io/follow-this-10-step-template-for-an-awesome-data-analysis-cb7975befa53',\n",
       "   'unique_slug': 'follow-this-10-step-template-for-an-awesome-data-analysis-cb7975befa53',\n",
       "   'image_url': 'https://miro.medium.com/1*jwsGPNhgEMmjIaKH4u2HcA.jpeg',\n",
       "   'lang': 'en',\n",
       "   'is_series': False,\n",
       "   'is_locked': False,\n",
       "   'is_shortform': False,\n",
       "   'top_highlight': '',\n",
       "   'content': {'id': 'cb7975befa53',\n",
       "    'content': 'Follow this 10-Step Template for an Awesome Data Analysis!\\n\\nPic Credit: Unsplash\\n\\nAnalyzing data is like discovering gold in a vast mine of information. As data continues to accumulate, efficiently managing and analyzing it can feel like a daunting task. Fortunately, there’s a more straightforward and efficient approach to data analysis.\\n\\nThis 10-step method not only minimizes mistakes and inconsistencies but also guarantees higher accuracy and efficiency in reaching your objectives. Whether you’re an experienced data analyst or just starting your journey, this method provides a clear path to do an effective data analysis.\\n\\nLet’s delve into it and enhance your data analysis skills!\\n\\nThe Dataset!\\n\\nWe will be doing the analysis on the Titanic dataset, where we will try to understand what factors led to the survival or death of passengers.\\n\\nimport pandas as pd\\ntitanic_df = pd.read_csv(\\'titanic.csv\\')\\ntitanic_df.head()\\n\\nTop rows in the dataset (Image by Author)\\n\\nLooking at the top 5 rows we can get an overview of the data present in the columns.\\n\\nNow, let’s start with the 10-step template for the data analysis:\\n\\nSTEP 1: Summary\\n\\nThe first step is to get an overview of the dataset. We’ll examine various statistics for the columns, revealing insights like passenger counts, survival rate, average age, and fare, etc.\\n\\ntitanic_df.describe(include = \\'all\\')\\n\\n## 891 Passengers. \\n## 38% survived. \\n## Avg Age: 29.\\n## Max fare went till 512. \\n\\nSummary Stats (Image by Author)\\n\\nSome takeaways:\\n\\nThe dataset has 891 passengers.\\n\\nLooking at the mean of the Survived column, we can see that only 38% of passengers survived.\\n\\nThe average age of passengers was ~30 years.\\n\\nThe average fare of 32 was paid by the passengers.\\n\\nSTEP 2: Data Types\\n\\nIn the second step, we check if the data types of the columns are correct. If not, we will correct them to ensure our analysis is accurate. For example, we convert object data types to integers where needed.\\n\\n# STEP 2: Data Types\\ntitanic_df.dtypes\\n\\nDatatypes (Image by Author)\\n\\nSTEP 3: Missing values\\n\\nNext, we will identify how many values are missing in each column. Knowing this helps us decide whether we need to handle missing data and how.\\n\\n# STEP 3: Missing values\\ntitanic_df.isnull().sum()\\n\\nCount of missing values (Image by Author)\\n\\nStep 4: Missing Values Treatment\\n\\nAfter the detection of missing values, we proceed to treat them. In our example, we will fill in missing values for the numeric column with the column means and for the categorical column with the column mode, though there are more sophisticated methods available.\\n\\n## filling nulls with mean \\ntitanic_df[\\'Age\\'] = titanic_df[\\'Age\\'].fillna(titanic_df[\\'Age\\'].mean())\\n\\n## filling nulls with mode \\nembarked_mode = titanic_df[\\'Embarked\\'].mode()\\ntitanic_df[\\'Embarked\\'] = titanic_df[\\'Embarked\\'].fillna(embarked_mode[0])\\n\\n## count of nulls\\ntitanic_df.isnull().sum()\\n\\nNulls treated (Image by Author)\\n\\nStep 5: Finding Outliers\\n\\nIn the fifth step, we check for outliers - data points that are significantly different from the others. We’ll visualize these outliers using histograms, as done for the ‘Fare’ column below. We can find that almost all the values within the fare column are less than 300 except for a value around 500 in the fare column, which is an outlier.\\n\\nimport matplotlib.pyplot as plt\\nplt.hist(titanic_df[\\'Fare\\'],bins = 40)\\nplt.show()\\n\\nHistogram (Image by Author)\\n\\nStep 6: Outlier Treatment\\n\\nOnce we’ve identified outliers, we decide how to handle them. For instance, we might cap the minimum or maximum value of a variable to a more intuitive value. Let’s do the outlier treatment for the fare column:\\n\\ntitanic_df.loc[titanic_df[\\'Fare\\'] < 300,\\'Fare\\'].max()\\n## 263\\n\\n# capping the fare to 263\\ntitanic_df.loc[titanic_df[\\'Fare\\'] > 300,\\'Fare\\'] = 263\\n\\nStep 7: Who - A person, member, etc.\\n\\nHere, we answer questions related to people. For example, we can find who had more chances of survival - males or females, passengers who had parents/children with them, passengers who had siblings with them, etc.\\n\\n## Gender \\n\\nimport plotly.express as px\\n\\ngender_count[\"Survived\"] = gender_count[\"Survived\"].astype(str)\\n\\nfig = px.bar(gender_count, x=\"Sex\", y=\"count\", color=\"Survived\", title=\"Who were more probable to survive - Males or Females\")\\nfig.show()\\n\\nImage by Author\\n\\nFrom the above graph, we can see that most females survived while most males died.\\n\\nNext, we can check if the count of siblings/spouse had an impact on the survival rate.\\n\\n## siblling or spouse\\nsibsp_count = titanic_df.groupby([\\'SibSp\\',\\'Survived\\'])[\\'PassengerId\\'].count().reset_index().rename(columns = {\\'PassengerId\\':\\'count\\'}).\\\\\\nsort_values(\\'count\\',ascending = False).head(5)\\n\\n\\nsibsp_count[\"Survived\"] = sibsp_count[\"Survived\"].astype(str)\\n\\nfig = px.bar(sibsp_count, x=\"SibSp\", y=\"count\", color=\"Survived\", title=\"Impact of count of siblings/spouse on the survival\")\\nfig.show() \\n\\nImpact of the count of sibling/spouse on survival(Image by Author)\\n\\nPassengers having 1 sibling/spouse traveling with them had more chances of survival as compared to any other group. It might happen that we have more females in this group compared to other groups.\\n\\nStep 8: When - Time-related questions!\\n\\nThis step addresses time-related questions. In our use case, we don’t have anything related to time.\\n\\nStep 9: Where - Place related questions!\\n\\nWe examine questions related to place or location. In our example, we’d find that embarking from specific places or taking certain cabins leads to more chances of survival.\\n\\nEmbarked_count = titanic_df.groupby([\\'Embarked\\',\\'Survived\\'])[\\'PassengerId\\'].count().reset_index().rename(columns = {\\'PassengerId\\':\\'count\\'}).\\\\\\nsort_values(\\'count\\',ascending = False).head(5)\\n\\nEmbarked_count[\"Survived\"] = Embarked_count[\"Survived\"].astype(str)\\n\\nfig = px.bar(Embarked_count, x=\"Embarked\", y=\"count\", color=\"Survived\", title=\"Impact of embarked on the survival\")\\nfig.show()\\n\\nEmbarked analysis (Image by Author)\\n\\nPassengers who embarked from Port Q did not survive. One of the hypotheses could be that the passengers who embarked from port Q were poor and as a result were not preferred for survival, we can further look into their ticket fare to validate this.\\n\\nStep 10: What/Which\\n\\nLastly, we formulate questions about various aspects not covered in the previous steps. These are subjective and can vary widely. For instance, we can determine which age group was most likely to survive.\\n\\n## creating age groups \\ntitanic_df.loc[titanic_df[\\'Age\\']<=15,\\'age_group\\'] = \\'less than eq 15\\'\\ntitanic_df.loc[titanic_df[\\'Age\\']>15,\\'age_group\\'] = \\'15 and 30\\'\\ntitanic_df.loc[titanic_df[\\'Age\\']>30,\\'age_group\\'] = \\'30 and 40\\'\\ntitanic_df.loc[titanic_df[\\'Age\\']>40,\\'age_group\\'] = \\'40 and 50\\'\\ntitanic_df.loc[titanic_df[\\'Age\\']>50,\\'age_group\\'] = \\'>50\\'\\n\\n## bar graph \\nEmbarked_count = titanic_df.groupby([\\'age_group\\',\\'Survived\\'])[\\'PassengerId\\'].count().reset_index().rename(columns = {\\'PassengerId\\':\\'count\\'}).\\\\\\nsort_values(\\'count\\',ascending = False)\\n\\nEmbarked_count[\"Survived\"] = Embarked_count[\"Survived\"].astype(str)\\n\\nfig = px.bar(Embarked_count, x=\"age_group\", y=\"count\", color=\"Survived\", title=\"Impact of embarked on the survival\")\\nfig.show()\\n\\nAge group vs. count (Image by Author)\\n\\nFrom the above graph, we can infer that the passengers preferred to save children less than equal to 15 years of age.\\n\\nBy the end of the 10th step, you will be able to explore almost every potential question and thus generate some really useful insights.\\n\\nI hope you learned something new and useful from this blog. Happy Learning!\\n\\nConclusion\\n\\nBy following this 10-step approach, you can navigate the complexities of data analysis more effectively, regardless of your level of experience. It provides a structured way to extract valuable insights from your data, helping you make informed decisions and drive success in your projects.\\n\\nThank You!\\n\\nIf you find my blogs useful, you can follow me to get direct notifications whenever I publish a story.\\n\\nIn Plain English\\n\\nThank you for being a part of our community! Before you go:\\n\\nBe sure to clap and follow the writer! 👏\\n\\nYou can find even more content at PlainEnglish.io 🚀\\n\\nSign up for our free weekly newsletter. 🗞️\\n\\nFollow us on Twitter(X), LinkedIn, YouTube, and Discord.'}},\n",
       "  {'id': 'd30fa1b701f6',\n",
       "   'title': 'Don’t Start Your SQL Queries with the ‘Select’ Statement',\n",
       "   'subtitle': 'Follow this right approach to write your SQL queries',\n",
       "   'author': 'd80580992695',\n",
       "   'publication_id': '7f60cf5620c9',\n",
       "   'published_at': '2022-12-05 23:31:35',\n",
       "   'last_modified_at': '2022-12-08 20:35:19',\n",
       "   'tags': ['sql',\n",
       "    'programming',\n",
       "    'data-science',\n",
       "    'data-analysis',\n",
       "    'relational-databases'],\n",
       "   'topics': ['data-science', 'programming'],\n",
       "   'claps': 1921,\n",
       "   'voters': 569,\n",
       "   'word_count': 876,\n",
       "   'responses_count': 41,\n",
       "   'reading_time': 4.3556603773584905,\n",
       "   'url': 'https://towardsdatascience.com/dont-start-your-sql-queries-with-select-clause-d30fa1b701f6',\n",
       "   'unique_slug': 'dont-start-your-sql-queries-with-select-clause-d30fa1b701f6',\n",
       "   'image_url': 'https://miro.medium.com/1*ok4j2wjoNtVrYKhpENbgGw.jpeg',\n",
       "   'lang': 'en',\n",
       "   'is_series': False,\n",
       "   'is_locked': True,\n",
       "   'is_shortform': False,\n",
       "   'top_highlight': \"Don't Start Your SQL Queries with the 'Select' Statement\",\n",
       "   'content': {'id': 'd30fa1b701f6',\n",
       "    'content': \"Don’t Start Your SQL Queries with the ‘Select’ Statement\\n\\nFollow this right approach to write your SQL queries\\n\\nImage Credits: Unsplash\\n\\nThe Problem\\n\\nThe majority of developers start writing their SQL queries with the ‘SELECT’ clause, then write ‘FROM’, ‘WHERE’, ‘HAVING’….and so on. But this is not the ‘right’ way of writing your SQL queries as this is very prone to syntactic errors, especially if you are a beginner in SQL.\\n\\nThe Solution\\n\\nThe ‘ideal’ query writing sequence should be in line with how the SQL executor executes the queries. This will ensure that you don’t commit any syntactic errors and write efficient SQL queries. You will know how to filter data before performing join, when to use ‘HAVING’ or ‘WHERE’ clause and more.\\n\\nIn this blog post, we will look at the ‘ideal’ way of writing a SQL query that will help you become an efficient SQL developer.\\n\\nWe will be using the Customer and Order tables (below) to find the top 2 customers from the USA/UK who have a total spend of more than $300.\\n\\nCustomer Table (Image by Author)\\n\\nOrder Table (Image by Author)\\n\\nLet’s dive into the right way of writing SQL queries.\\n\\n1. Always start with FROM/JOIN\\n\\nIntuitively, the first step is to read the tables using the FROM clause and perform JOIN(if required). So, you should always start your query with the ‘FROM’/‘JOIN’ statement.\\n\\n\\nFROM Customers\\nINNER JOIN Orders\\nON Customers.customer_id = Orders.customer_id\\n\\nWe can also filter rows from the input tables even before the join is executed. We can do this by adding the ‘AND’ clause after the ‘ON’ clause of the join.\\n\\n-- Filter happens before Join\\n\\nFROM Customers\\nINNER JOIN Orders\\nON Customers.customer_id = Orders.customer_id\\nAND country in ('USA','UK')\\n\\n2. Then move to WHERE\\n\\nThe second clause in the order of execution is the WHERE clause. It is used to filter the data tables after the join has been applied.\\n\\nThe WHERE clause is very helpful to reduce the number of rows especially when we are working with big datasets having millions of rows.\\n\\nFROM Customers\\nINNER JOIN Orders\\nON Customers.customer_id = Orders.customer_id\\nWHERE country in ('USA','UK')\\n\\n3. Then use GROUP BY\\n\\nGroup By clause should be written after the Where clause. It is used to group the rows based on the selected column/columns.\\n\\nIn the following query, we are grouping the rows based on the customer id. After grouping, each customer id will have one row in the output. We generally use aggregations(sum, min, max, etc.) when we group the data. In this example, we will find the sum of the amount column in the Orders table.\\n\\nFROM Customers\\nINNER JOIN Orders\\nON Customers.customer_id = Orders.customer_id\\nWHERE country in ('USA','UK')\\nGROUP BY Customers.customer_id\\n\\n4. HAVING after GROUP BY\\n\\nThe HAVING clause gets executed after GROUP BY, it is used to filter the aggregated rows that were generated in the group by operation.\\n\\nIn our example, we will filter the sum of the amount spent by each customer to be greater than 300.\\n\\nFROM Customers\\nINNER JOIN Orders\\nON Customers.customer_id = Orders.customer_id\\nWHERE country in ('USA','UK')\\nGROUP BY Customers.customer_id\\nHAVING sum(amount) >300\\n\\nThe WHERE clause gets executed before GROUP BY while HAVING gets executed after it. So, the WHERE clause cannot filter aggregated data.\\n\\n5. Then write the SELECT clause\\n\\nColumns that we want to show in the output are selected using the SELECT clause.\\n\\nIf we group our data using the GROUP BY clause, we need to select the grouped column using the SELECT statement.\\n\\nIn our example, we will select the customer id and sum(amount) to show the spending corresponding to each customer.\\n\\nselect Customers.customer_id, sum(amount) as total_amount\\nFROM Customers\\nINNER JOIN Orders\\nON Customers.customer_id = Orders.customer_id\\nWHERE country in ('USA','UK')\\nGROUP BY Customers.customer_id\\nHAVING sum(amount) >300\\n\\nOutput (Image by Author)\\n\\n6. Use ORDER BY after the SELECT clause\\n\\nAfter selecting the columns, the next step is to provide the order in which we want to output the rows.\\n\\nIn our example, we can use the ORDER BY clause to order the rows in descending order of total spend.\\n\\nSELECT Customers.customer_id, sum(amount) as total_amount\\nFROM Customers\\nINNER JOIN Orders\\nON Customers.customer_id = Orders.customer_id\\nWHERE country in ('USA','UK')\\nGROUP BY Customers.customer_id\\nHAVING sum(amount) >=300\\nORDER BY total_amount desc\\n\\nOutput (Image By Author)\\n\\n7. Write the LIMIT clause at last!\\n\\nThe last step in the writing sequence is to limit the number of rows that we want to see in the output.\\n\\nIn our example, we can limit the total number of output rows to 2.\\n\\nSELECT Customers.customer_id, sum(amount) as total_amount\\nFROM Customers\\nINNER JOIN Orders\\nON Customers.customer_id = Orders.customer_id\\nWHERE country in ('USA','UK')\\nGROUP BY Customers.customer_id\\nHAVING sum(amount) >=300\\nORDER BY total_amount desc\\nLIMIT 2\\n\\nOutput (Image by Author)\\n\\nConclusion\\n\\nWe looked at the ideal way of writing the SQL queries which is in line with how the SQL queries are executed.\\n\\nI hope you will be writing your SQL queries in the below sequence if you are not doing that already.\\n\\nImage by Author\\n\\nThank You for reading!\\n\\nYou can get all my posts in your inbox. Do that here!\\n\\nIf you like to experience Medium yourself, consider supporting me and thousands of other writers by signing up for a membership. It only costs $5 per month, it supports us, writers, greatly, and you get to access all the amazing stories on Medium.\\n\\nFollow me to see my data science posts in your feed.\"}},\n",
       "  {'id': 'a97c4639c183',\n",
       "   'title': 'Don’t Write Another Line Of Code In Python Until You’ve Seen These Mistakes!',\n",
       "   'subtitle': 'Let’s start writing cleaner codes in Python',\n",
       "   'author': 'd80580992695',\n",
       "   'publication_id': '*Self-Published*',\n",
       "   'published_at': '2024-02-13 01:47:25',\n",
       "   'last_modified_at': '2024-02-13 01:47:25',\n",
       "   'tags': ['python', 'programming', 'data-science', 'analytics', 'coding'],\n",
       "   'topics': ['programming'],\n",
       "   'claps': 151,\n",
       "   'voters': 16,\n",
       "   'word_count': 757,\n",
       "   'responses_count': 2,\n",
       "   'reading_time': 3.056603773584906,\n",
       "   'url': 'https://anmol3015.medium.com/dont-write-another-line-of-code-in-python-until-you-ve-seen-these-mistakes-a97c4639c183',\n",
       "   'unique_slug': 'dont-write-another-line-of-code-in-python-until-you-ve-seen-these-mistakes-a97c4639c183',\n",
       "   'image_url': 'https://miro.medium.com/1*VBK3top74w5boIFOeOOtNw.jpeg',\n",
       "   'lang': 'en',\n",
       "   'is_series': False,\n",
       "   'is_locked': True,\n",
       "   'is_shortform': False,\n",
       "   'top_highlight': '',\n",
       "   'content': {'id': 'a97c4639c183',\n",
       "    'content': 'Don’t Write Another Line Of Code In Python Until You’ve Seen These Mistakes!\\n\\nLet’s start writing cleaner codes in Python\\n\\nPic Credit: Unsplash\\n\\nIntroduction\\n\\nPython, renowned for its simplicity and readability, can sometimes lure even the most seasoned developers into common traps and pitfalls. Whether you’re a beginner or an experienced developer, it’s essential to be aware of these common mistakes to write more efficient and maintainable code.\\n\\nIn this blog post, we’ll explore the top 10 Python programming mistakes and look at the coding examples for each, along with tips on how to avoid them.\\n\\nMisusing Indentation\\n\\nIndentation is crucial in Python as it defines the block of code. Forgetting to indent properly or mixing spaces with tabs can lead to syntax errors. Let’s see an example:\\n\\ndef my_function():\\nprint(\"Hello, world!\")  # Incorrect indentation\\n\\nmy_function()\\n\\nTo avoid this mistake, ensure consistent indentation using either spaces or tabs throughout your codebase.\\n\\ndef my_function():\\n    print(\"Hello, world!\")  # Incorrect indentation\\n\\nmy_function()\\n\\n2. Unnecessary Use of Global Variables\\n\\nOverusing global variables can lead to code that’s hard to understand and maintain. Instead, prefer passing variables as parameters or using class attributes. Here’s an example:\\n\\nx = 10\\n\\ndef increment():\\n    global x  # Unnecessary use of global variable\\n    x += 1\\n    print(x)\\nincrement()\\n\\nA better approach would be to pass x as a parameter to the function:\\n\\ndef increment(x):\\n    return x + 1\\n\\nx = 10\\nx = increment(x)\\nprint(x)\\n\\n3. Ignoring Exception Handling\\n\\nFailing to handle exceptions can result in runtime errors and unexpected program behavior. Always use try-except blocks to handle exceptions gracefully. Example:\\n\\ntry:\\n    result = 10 / 0  # Division by zero\\n    print(result)\\nexcept ZeroDivisionError:\\n    print(\"Error: Division by zero!\")\\n\\n4. Using Mutable Objects as Default Arguments\\n\\nUsing mutable objects like lists or dictionaries as default arguments can lead to unexpected behavior due to shared references. Example:\\n\\ndef append_to_list(value, my_list=[]):  # Mutable default argument\\n    my_list.append(value)\\n    return my_list\\n\\n\\nprint(append_to_list(1))  # Output: [1]\\nprint(append_to_list(2))  # Output: [1, 2] (Unexpected)\\n\\nInstead, use immutable objects or None as default arguments and initialize mutable objects inside the function:\\n\\ndef append_to_list(value, my_list=None):  # Using None as default\\n    if my_list is None:\\n        my_list = []\\n    my_list.append(value)\\n    return my_list\\n\\nprint(append_to_list(1))  # Output: [1]\\nprint(append_to_list(2))  # Output: [2] (Expected)\\n\\n5. Incorrect String Concatenation\\n\\nConcatenating strings using the + operator inside loops can lead to performance issues. Instead, use join() methods for better performance. Example:\\n\\nmy_list = [\\'apple\\', \\'banana\\', \\'cherry\\']\\nresult = \"\"\\nfor fruit in my_list:\\n    result += fruit  # Incorrect string concatenation\\nprint(result)\\n\\nA more efficient approach would be to use join() the method:\\n\\nresult = \"\".join(my_list)\\nprint(result)\\n\\n6. Not Using List Comprehensions\\n\\nUsing traditional loops instead of list comprehensions can make your code less readable and slower. Example:\\n\\n# Traditional loop\\nsquares = []\\nfor i in range(10):\\n    squares.append(i ** 2)\\nprint(squares)\\n\\nInstead, use list comprehensions:\\n\\n# List comprehension\\nsquares = [i ** 2 for i in range(10)]\\nprint(squares)\\n\\n7. Inefficient File Handling\\n\\nNot closing file handles or not using context managers can lead to resource leaks. Always use with statements for file handling. Example:\\n\\nfile = open(\"example.txt\", \"r\")  # File handle not closed\\ndata = file.read()\\nprint(data)\\n\\nBetter approach using context manager:\\n\\nwith open(\"example.txt\", \"r\") as file:\\n    data = file.read()\\n    print(data)\\n\\n8. Overusing eval() Function\\n\\nUsing eval() function can introduce security vulnerabilities and make your code harder to debug. Example:\\n\\nx = 10\\neval(\\'x + 5\\')  # Avoid using eval()\\n\\nInstead, prefer using alternative approaches such as parsing or using specific libraries for dynamic code execution.\\n\\nx = 10\\nresult = x + 5\\nprint(result)\\n\\n9. Mixing Tabs and Spaces\\n\\nMixing tabs and spaces for indentation can lead to syntax errors and inconsistent code style. Configure your editor to use spaces for indentation or stick to one convention throughout your project.\\n\\ndef my_function():\\n    if True:\\n    print(\"Hello, world!\")  # Incorrect indentation due to mixing tabs and spaces\\n\\nmy_function()\\n\\n10. Not Using Descriptive Variable Names\\n\\nUsing cryptic or unclear variable names can make your code difficult to understand and maintain. Always use descriptive names that reflect the purpose of the variable.\\n\\n\\n# Cryptic variable names\\nx = 10\\ny = 20\\nz = x + y\\nprint(z)\\n\\nInstead of using unclear variable names, use descriptive names that reflect the purpose of the variable:\\n\\n# Descriptive variable names\\ntotal_sum = 10\\nbonus_points = 20\\nfinal_score = total_sum + bonus_points\\nprint(final_score)\\n\\nConclusion\\n\\nBy avoiding these common Python programming mistakes, you can write cleaner, more efficient, and maintainable code. Remember to follow best practices, use appropriate tools and libraries, and continuously improve your coding skills to become a proficient Python developer.'}},\n",
       "  {'id': 'b0935bf96ee2',\n",
       "   'title': 'Pandas Crash Course: Top 30 Functions for ANY Data Analysis',\n",
       "   'subtitle': 'Become a Pro in using Pandas for Data Science',\n",
       "   'author': 'd80580992695',\n",
       "   'publication_id': '*Self-Published*',\n",
       "   'published_at': '2024-02-06 01:47:21',\n",
       "   'last_modified_at': '2024-02-06 01:47:21',\n",
       "   'tags': ['python',\n",
       "    'pandas',\n",
       "    'data-science',\n",
       "    'data-analysis',\n",
       "    'programming'],\n",
       "   'topics': ['data-science', 'programming'],\n",
       "   'claps': 421,\n",
       "   'voters': 63,\n",
       "   'word_count': 1271,\n",
       "   'responses_count': 3,\n",
       "   'reading_time': 7.046226415094339,\n",
       "   'url': 'https://anmol3015.medium.com/pandas-crash-course-top-30-functions-for-any-data-analysis-b0935bf96ee2',\n",
       "   'unique_slug': 'pandas-crash-course-top-30-functions-for-any-data-analysis-b0935bf96ee2',\n",
       "   'image_url': 'https://miro.medium.com/1*VBK3top74w5boIFOeOOtNw.jpeg',\n",
       "   'lang': 'en',\n",
       "   'is_series': False,\n",
       "   'is_locked': True,\n",
       "   'is_shortform': False,\n",
       "   'top_highlight': '',\n",
       "   'content': {'id': 'b0935bf96ee2',\n",
       "    'content': 'Pandas Crash Course: Top 30 Functions for Any Data Analysis\\n\\nBecome a Pro in using Pandas for Data Science\\n\\nPic Credit: Unsplash\\n\\nEmbarking on a data analysis journey often leads us to Pandas, the powerhouse library that transforms the way we handle and manipulate data in Python.\\n\\nIn this crash course, we’ll unravel the top 30 Pandas functions that serve as the backbone for any data analysis task. Whether you’re a seasoned data scientist or a beginner navigating the world of data, these functions will become your go-to functions for any data analysis.\\n\\nTo illustrate the use of the top 30 Pandas functions, we’ll create a simple DataFrame using a hypothetical real-world dataset. In this example, let’s consider a dataset related to sales transactions.\\n\\nimport pandas as pd\\nimport numpy as np\\n\\n# Creating a hypothetical sales dataset\\ndata = {\\n    \\'Date\\': pd.date_range(start=\\'2023-01-01\\', end=\\'2023-01-10\\'),\\n    \\'Product\\': [\\'A\\', \\'B\\', \\'A\\', \\'C\\', \\'B\\', \\'A\\', \\'C\\', \\'A\\', \\'B\\', \\'C\\'],\\n    \\'Sales\\': [100, 150, 120, 80, 200, 110, 90, 130, 160, 75],\\n    \\'Region\\': [\\'North\\', \\'South\\', \\'East\\', \\'West\\', \\'North\\', \\'South\\', \\'West\\', \\'North\\', \\'East\\', \\'South\\']\\n}\\ndf = pd.DataFrame(data)\\nprint(\"Original DataFrame:\")\\nprint(df)\\n\\nImage by Author\\n\\nNow, let’s apply the Pandas functions to this DataFrame:\\n\\n1. Importing Pandas and Loading Data\\n\\nimport pandas as pd\\n\\n# Read data from CSV file\\ndf = pd.read_csv(\\'your_data.csv\\')\\n# Display the first few rows\\ndf.head()\\n\\n2. Exploring Data Basics\\n\\nUse info() to get a concise summary of the DataFrame, including data types and non-null values. describe() provides statistical information such as mean, standard deviation, and quartiles for numeric columns.\\n\\n# Display basic information about the DataFrame\\ndf.info()\\n\\n# Summary statistics for numeric columns\\ndf.describe()\\n\\nInfo (Image by Author)\\n\\nDescribe (Image by Author)\\n\\n3. Handling Missing Data\\n\\nThese functions address missing data. dropna() removes rows with any missing values, while fillna() fills missing values with a specified value.\\n\\n# Drop rows with missing values\\ndf.dropna()\\n\\n#Fill missing values with a specified value\\ndf.fillna(\\'NA\\')\\n\\n4. Selecting Columns\\n\\nDemonstrates selecting columns from the DataFrame. Use single brackets for a single column and double brackets for multiple columns.\\n\\n# Select a single column\\ndf[\\'Product\\']\\n\\n# Select multiple columns\\ndf[[\\'Product\\', \\'Sales\\']]\\n\\nColumn Selection (Image by Author)\\n\\n5. Filtering Data\\n\\nFiltering allows you to extract rows based on conditions. The first example filters rows where sales are greater than 100. The second example introduces multiple conditions.\\n\\n# Filter rows based on a condition\\ndf[df[\\'Sales\\'] > 100]\\n\\nFiltering (Image by Author)\\n\\n# Multiple conditions\\ndf[(df[\\'Region\\'] == \\'North\\') & (df[\\'Sales\\'] > 100)]\\n\\nFiltering (Image by Author)\\n\\n6. Sorting Data\\n\\nSorting the DataFrame based on a specific column (Sales in this case) in descending order.\\n\\n# Sort DataFrame by a column\\ndf.sort_values(by=\\'Sales\\', ascending=False)\\n\\nSorting on Sale (Image by Author)\\n\\n7. Grouping and Aggregating Data\\n\\nGrouping data by a categorical column (Region) and calculating the mean of the \\'Sales\\' column for each group.\\n\\n# Group data by a column and calculate mean\\ndf.groupby(\\'Region\\')[\\'Sales\\'].mean()\\n\\nAggregation (Image by Author)\\n\\n8. Applying Functions to Data\\n\\nUsing apply() to apply a custom function (doubling in this case) to each element in the \\'Sales\\' column.\\n\\n# Apply a function to each element in a column\\ndf[\\'Sales\\'].apply(lambda x: x * 2)\\n\\nApply and Lambda (Image by Author)\\n\\n9. Concatenate DataFrames\\n\\nConcatenating two DataFrames vertically (stacking them on top of each other).\\n\\n# Concatenate DataFrames vertically\\ndf2 = pd.concat([df, df])\\n\\nConcatenate (Image by Author)\\n\\n10. Handling Time Series Data\\n\\nConverting a column containing date information to the datetime format and setting it as the DataFrame index, is crucial for time series analysis.\\n\\n# Convert a column to datetime format\\ndf[\\'Date\\'] = pd.to_datetime(df[\\'Date\\'])\\n\\n# Set the datetime column as the index\\ndf.set_index(\\'Date\\', inplace=True)\\n\\nDate (Image by Author)\\n\\n11. Resampling Time Series Data\\n\\nResampling time series data by month (\\'M\\') and calculating the mean. This is useful for changing the frequency of the data.\\n\\n# Resample time series data by day\\ndf.resample(\\'M\\').mean()\\n\\nImage by Author\\n\\n12. Creating New Columns\\n\\nCreating a new column (‘Revenue’) by performing a calculation based on existing columns (here, multiplying ‘Sales’ by 1.2).\\n\\n# Create a new column based on existing columns\\ndf[\\'Revenue\\'] = df[\\'Sales\\'] * 1.2\\n\\n\\n\\n13. Removing Duplicates\\n\\nEliminating duplicate rows based on all columns. This is useful to ensure unique records in the DataFrame.\\n\\n# Remove duplicate rows based on all columns\\ndf.drop_duplicates()\\n\\n14. Handling Text Data\\n\\nPerforming text operations. The first example converts text in the ‘Product’ column to lowercase. The second checks if each element contains the substring ‘A’.\\n\\n# Convert text to lowercase\\ndf[\\'Product\\'].str.lower()\\n\\n\\n\\n# Check for a substring in text\\ndf[\\'Product\\'].str.contains(\\'A\\')\\n\\n\\n\\n15. Handling Categorical Data\\n\\nConverting a column to a categorical data type. This is beneficial for saving memory and improving performance when dealing with limited unique values.\\n\\n# Convert a column to categorical\\ndf[\\'Region\\'] = pd.Categorical(df[\\'Region\\'])\\n\\n\\n\\n16. Pivot Tables\\n\\nCreating a pivot table to summarize and analyze data. This example calculates the sum of sales for each combination of ‘Region’ and ‘Product’.\\n\\n# Create a pivot table\\npivot_table = pd.pivot_table(df, values=\\'Sales\\', index=\\'Region\\', columns=\\'Product\\', aggfunc=np.sum)\\n\\n\\n\\n17. Merging DataFrames\\n\\nMerging two DataFrames based on a common column (‘Region’ in this case) to combine information from both datasets.\\n\\n# Merge two DataFrames\\ndf2 = pd.DataFrame({\\'Region\\': [\\'North\\', \\'South\\'], \\'Manager\\': [\\'John\\', \\'Jane\\']})\\nmerged_df = pd.merge(df, df2, on=\\'Region\\')\\n\\n\\n\\n18. Calculating Cumulative Sum\\n\\nCreating a new column (‘Cumulative_Sales’) to calculate the cumulative sum of the ‘Sales’ column over time.\\n\\n# Calculate cumulative sum of a column\\ndf[\\'Cumulative_Sales\\'] = df[\\'Sales\\'].cumsum()\\n\\nImage by Author\\n\\n19. Rolling Statistics\\n\\nComputing rolling statistics, such as the mean, over a specified window size (2 in this case). Useful for smoothing out fluctuations in time series data.\\n\\n# Calculate rolling mean of a column\\ndf[\\'Rolling_Mean\\'] = df[\\'Sales\\'].rolling(window=2).mean()\\n\\n\\n\\n20. Handling Outliers\\n\\nIdentifying and replacing outliers in the ‘Sales’ column. Outliers beyond a certain threshold are replaced with the median value.\\n\\n# Identify and replace outliers\\nupper_bound = df[\\'Sales\\'].mean() + 2 * df[\\'Sales\\'].std()\\ndf[\\'Sales\\'] = np.where(df[\\'Sales\\'] > upper_bound, df[\\'Sales\\'].median(), df[\\'Sales\\'])\\n\\nImage by Author\\n\\n21. Shifting Data\\n\\nShifting values in the ‘Sales’ column by one period. Useful for comparing current and previous values.\\n\\n# Shift values in a column\\ndf[\\'Shifted_Sales\\'] = df[\\'Sales\\'].shift(periods=1)\\n\\n\\n\\n22. Calculating Percentage Changes\\n\\nComputing the percentage change in the ‘Sales’ column. Useful for analyzing the rate of change between consecutive values.\\n\\n# Calculate percentage change in a column\\ndf[\\'Percentage_Change\\'] = df[\\'Sales\\'].pct_change() * 100\\n\\n\\n\\n23. Correlation Matrix\\n\\nGenerating a correlation matrix to quantify the relationship between numeric variables in the DataFrame.\\n\\n# Calculate correlation matrix\\ncorrelation_matrix = df.corr()\\n\\nCorrelation Matrix (Image by Author)\\n\\n24. Plotting Data\\n\\nVisualizing data by plotting the ‘Sales’ column as a line plot using Pandas and Matplotlib.\\n\\nimport matplotlib.pyplot as plt\\n\\n# Plot data using Pandas\\ndf[\\'Sales\\'].plot(kind=\\'line\\')\\nplt.show()\\n\\nLine Plot\\n\\n25. Saving Data\\n\\nSaving the DataFrame to a CSV file for future use or sharing. The file will be stored in the same location as that of the python code.\\n\\n# Save DataFrame to CSV file\\ndf.to_csv(\\'output_file.csv\\', index=False)\\n\\n26. Memory Usage Optimization\\n\\nChecking and optimizing the memory usage of the DataFrame to ensure efficient storage.\\n\\n# Optimize memory usage\\ndf.info(memory_usage=\\'deep\\')\\n\\n27. Custom Aggregation with agg\\n\\nUsing the agg function to apply custom aggregations to specific columns. In this example, we are calculating the sum of \\'Sales\\' and the mean of \\'Revenue\\'.\\n\\n# Apply custom aggregation to columns\\ndf.agg({\\'Sales\\': \\'sum\\', \\'Revenue\\': \\'mean\\'})\\n\\n\\n\\n28. Binning Numeric Data\\n\\nBinning numeric data (‘Sales’ column) into discrete intervals (bins) and labeling each interval accordingly.\\n\\n# Create bins for numeric data\\ndf[\\'Sales_Bin\\'] = pd.cut(df[\\'Sales\\'], bins=[0, 100, 150, 200], labels=[\\'Low\\', \\'Medium\\', \\'High\\'])\\n\\nImage by Author\\n\\n29. Finding Unique Values\\n\\nIdentifying unique values in the ‘Region’ column. Useful for understanding the distinct categories present in a categorical column.\\n\\n# Find unique values in a column\\nunique_values = df[\\'Region\\'].unique()\\n\\n\\n\\n30. Value Counts\\n\\nCounting the occurrences of each unique value in the ‘Region’ column. Useful for understanding the distribution of categorical data.\\n\\n# Count occurrences of each value in a column\\nvalue_counts = df[\\'Region\\'].value_counts()\\n\\n\\n\\nThese examples showcase the application of various Pandas functions using a hypothetical sales dataset. Adapt and modify these code snippets based on your specific use case and dataset. Happy coding! 🐼🚀'}},\n",
       "  {'id': '68ffa12f8885',\n",
       "   'title': 'Data Visualization Tips to have a long-lasting Impact on Your Audience',\n",
       "   'subtitle': 'Let’s start with the Bar Chart',\n",
       "   'author': 'd80580992695',\n",
       "   'publication_id': '*Self-Published*',\n",
       "   'published_at': '2024-01-30 01:52:20',\n",
       "   'last_modified_at': '2024-01-30 14:39:16',\n",
       "   'tags': ['data-visualization',\n",
       "    'data-science',\n",
       "    'data',\n",
       "    'visualization',\n",
       "    'data-analysis'],\n",
       "   'topics': ['data-science'],\n",
       "   'claps': 126,\n",
       "   'voters': 28,\n",
       "   'word_count': 736,\n",
       "   'responses_count': 1,\n",
       "   'reading_time': 3.827358490566038,\n",
       "   'url': 'https://anmol3015.medium.com/data-visualization-tips-to-have-a-long-lasting-impact-on-your-audience-68ffa12f8885',\n",
       "   'unique_slug': 'data-visualization-tips-to-have-a-long-lasting-impact-on-your-audience-68ffa12f8885',\n",
       "   'image_url': 'https://miro.medium.com/1*NhCWYLw5Qd0o8vYZA6lyKA.png',\n",
       "   'lang': 'en',\n",
       "   'is_series': False,\n",
       "   'is_locked': True,\n",
       "   'is_shortform': False,\n",
       "   'top_highlight': '',\n",
       "   'content': {'id': '68ffa12f8885',\n",
       "    'content': 'Data Visualization Tips to have a long-lasting Impact on Your Audience\\n\\nLet’s start with the Bar Chart\\n\\nWhy is Data Visualization a critical skill?\\n\\nData visualization is an art; mastering it involves more than just creating plots. Today, we’re diving into the hidden gems of data visualization - the tips that often lurk in the shadows, unknown to many professionals but are very critical for creating impactful visualizations.\\n\\nIn this series of blogs, we will start with the Bar chart which is one of the most used - simple yet effective visualizations out there and yet used in the wrong setup many times.\\n\\nFundamentals: What is a Bar chart and when to use it?\\n\\nA bar chart is used to compare & show the difference between different categories where one axis is categorical and the other is continuous (numeric).\\n\\nA bar chart can be used to compare and find the largest and smallest category. For example - comparing the Medical Spending across different age groups (Millennials, GenZ, Young, etc.)\\n\\nBar chart (Image by Author)\\n\\n1. The Power of Width\\n\\nTip: Optimal Bar Width for Impact\\n\\nBar charts are a staple in data visualization, but the width of those bars can make a significant difference. The key is finding the sweet spot - not too thin that bars get lost in the background, and not too wide that they clutter the visual space.\\n\\nThe image below illustrates the ideal/perfect width of the bar and highlights what too thin and too wide looks like.\\n\\nWidth of Bar graphs(Image by Author)\\n\\n2. Multiseries chart\\n\\nMultiseries bar charts, also known as grouped bar charts, are a powerful way to compare multiple categories across different groups. When dealing with complex datasets involving multiple series, these charts offer clarity and depth to your visual narrative.\\n\\nLet’s explore some best practices to ensure you wield the multi series bar chart with finesse and create visual brilliance.\\n\\nColor Coding for Clarity\\n\\nWhen dealing with multiple series, a well-chosen color palette can be your secret weapon. Opt for distinct colors that not only differentiate each series but also complement the overall aesthetic. This ensures that viewers can easily identify and compare categories without confusion. We will be covering more of this at the end.\\n\\nMindful Ordering\\n\\nThe order in which bars are presented can significantly impact the chart’s interpretability. Arrange bars logically, such as by size or category, to make comparisons intuitive for your audience.\\n\\nMulti-Series Graph (Image by Author)\\n\\n3. Stacked Bar chart\\n\\nStacked bar graphs are a versatile tool for comparing the total across categories and also comparing the sub-levels - showcasing how individual components contribute to the total.\\n\\nOne of the challenges inherent in stacked bar graphs is the potential difficulty in comparing individual series, especially when the baseline is not fixed.\\n\\nSolution: Order the bars from largest to smallest unless there is an intrinsic order of levels.\\n\\nStacked Bar graph (Image by Author)\\n\\n4. Horizontal Bar charts\\n\\nUnlocking Clarity: The Importance of Horizontal Bar Charts in Data Visualization\\n\\nIn the vast landscape of data visualization, the choice of chart type plays a pivotal role in effectively conveying information. While vertical bar charts are a common go-to, the horizontal bar chart stands out as a powerful alternative that can significantly enhance readability and comprehension.\\n\\nWhy - We are used to reading from left to right in a z sequence and thus horizontal bar graphs are easier to read and understand.\\n\\n\\n\\n5. Power of Color\\n\\nThe power of color extends beyond mere aesthetics; it serves as a dynamic communicator, conveying information with nuance and clarity.\\n\\nColor Consistency: Opt for color gradients that maintain a sense of consistency and harmony throughout your visualization. A well-curated palette ensures that viewers can effortlessly interpret the information without distraction or confusion.\\n\\nContrast for Clarity: Leverage color gradients to highlight meaningful differences in your data. Whether you’re showcasing variations in performance, concentrations, or trends, a thoughtful gradient can emphasize distinctions and guide the viewer’s attention.\\n\\nHierarchy Reinforcement: Use color gradients strategically to reinforce visual hierarchies within your graph. Whether emphasizing specific data points or delineating categories, a well-orchestrated gradient contributes to a visually engaging and informative hierarchy.\\n\\nBad Choice of Colors (Image by Author)\\n\\nRight Choice of Color (Image by Author)\\n\\nConclusion\\n\\nIn this comprehensive blog, we delve into the art and science of creating impactful bar charts that captivate and inform. From the foundational principles of bar chart design to advanced techniques for enhancing clarity and engagement, we explore the nuances that transform data into compelling narratives.\\n\\nI hope you learned something new and useful, Thank You.'}},\n",
       "  {'id': '81909c97e7d2',\n",
       "   'title': 'Don’t Underestimate the Power of Matplotlib, It can create Animations Too!',\n",
       "   'subtitle': 'The untapped potential of matplotlib',\n",
       "   'author': 'd80580992695',\n",
       "   'publication_id': '29038077e4c6',\n",
       "   'published_at': '2024-01-17 01:32:14',\n",
       "   'last_modified_at': '2024-01-24 12:29:53',\n",
       "   'tags': ['python-programming',\n",
       "    'python',\n",
       "    'visualization',\n",
       "    'data-science',\n",
       "    'data-visualization'],\n",
       "   'topics': ['data-science', 'programming'],\n",
       "   'claps': 147,\n",
       "   'voters': 37,\n",
       "   'word_count': 836,\n",
       "   'responses_count': 2,\n",
       "   'reading_time': 3.988050314465409,\n",
       "   'url': 'https://medium.com/codex/dont-underestimate-the-power-of-matplotlib-it-can-create-animations-too-81909c97e7d2',\n",
       "   'unique_slug': 'dont-underestimate-the-power-of-matplotlib-it-can-create-animations-too-81909c97e7d2',\n",
       "   'image_url': 'https://miro.medium.com/1*Zg5A9B0Mr8cTE5a8u7N7_A.jpeg',\n",
       "   'lang': 'en',\n",
       "   'is_series': False,\n",
       "   'is_locked': True,\n",
       "   'is_shortform': False,\n",
       "   'top_highlight': '',\n",
       "   'content': {'id': '81909c97e7d2',\n",
       "    'content': \"Don’t Underestimate the Power of Matplotlib, It can create Animations Too!\\n\\nThe untapped potential of matplotlib\\n\\nPic Credit: Unsplash\\n\\nMatplotlib might seem a bit dull at first, but, looks can be deceiving! If you believe it’s not good for making visuals look cool, that’s not true at all.\\n\\nGuess what? Matplotlib is like a superhero for making pictures that move. In this blog, we’re going to look at how awesome Matplotlib can be when it comes to making things dance on your screen.\\n\\nSo, get ready for a fun ride as we explore the exciting world of animations with Matplotlib. It’s not just about boring pictures - we’re going to make them come alive! Let’s dive in and discover the magic of animated charts and graphs with Matplotlib.\\n\\n1. Sine wave\\n\\nSine wave animation (Image by Author)\\n\\nimport numpy as np\\nimport matplotlib.pyplot as plt\\nfrom matplotlib.animation import FuncAnimation\\n\\n# Enable notebook backend\\n%matplotlib notebook\\n\\n# Create a figure and axis\\nfig, ax = plt.subplots()\\nx_data = np.linspace(0, 2 * np.pi, 100)\\nline, = ax.plot(x_data, np.sin(x_data))\\n\\n# Animation function\\ndef update(frame):\\n    line.set_ydata(np.sin(x_data + frame / 10))\\n    return line,\\n\\n# Create the animation\\nanimation = FuncAnimation(fig, update, frames=range(200), interval=50)\\n\\n# Show the animation\\nplt.show()\\n\\nIn the above code, we are following the below steps:\\n\\nUsing plt.subplots()to create a figure and an axis for our animation.\\n\\nCreating the values for the x-axis and assigning it to x_data.\\n\\nThe update function is called for each frame in the animation. In this case, it shifts the sine wave horizontally.\\n\\nFuncAnimation creates the animation, specifying the figure, updating function, frames, and interval between frames.\\n\\nThis is a basic example, but similar principles can be applied to more complex visualizations and datasets.\\n\\n2. Scatter Plot Animation\\n\\nScatter Plot Animation (Image by Author)\\n\\nimport numpy as np\\n\\n# Create a figure and axis\\nfig, ax = plt.subplots()\\nx_data = np.random.rand(50)\\ny_data = np.random.rand(50)\\nsc = ax.scatter(x_data, y_data)\\n\\n# Animation function\\ndef update_scatter(frame):\\n    sc.set_offsets(np.column_stack((x_data + np.sin(frame / 10), y_data + np.cos(frame / 10))))\\n    return sc,\\n\\n# Create the animation\\nanimation_scatter = FuncAnimation(fig, update_scatter, frames=range(200), interval=50)\\n\\nplt.show()\\n\\nIn the above code, we start by generating the data for the plot and then creating the scatter plot\\n\\nThe update_scatter function is the core of the animation. It takes a frame as input and updates the position of the scatter plot points for each frame. The points move in circular patterns as a result of the original random data and sine/cosine functions.\\n\\nThe FuncAnimation class from Matplotlib is used to create the animation. It takes the figure (fig), the update function (update_scatter), the number of frames (here, 200 frames), and the interval between frames (50 milliseconds) as arguments.\\n\\n3. Coil\\n\\nCoil Animation(Image by Author)\\n\\nimport numpy as np\\nimport matplotlib.pyplot as plt\\nfrom matplotlib.animation import FuncAnimation\\n\\n# Enable notebook backend\\n%matplotlib notebook\\n\\n# Create a figure and axis\\nfig, ax = plt.subplots()\\n\\n# Initial position\\ntheta = np.linspace(0, 2 * np.pi, 100)\\nradius = 0.1\\nx_data = radius * np.cos(theta)\\ny_data = radius * np.sin(theta)\\n\\n# Plot the initial coil\\nline, = ax.plot(x_data, y_data, color='b')\\n\\n# Animation function\\ndef update_coil(frame):\\n    # Update the coil's rotation and unwinding\\n    new_theta = np.linspace(0, 2 * np.pi * frame / 100, 100)\\n    new_x_data = radius * np.cos(new_theta)\\n    new_y_data = radius * np.sin(new_theta)\\n    \\n    # Set new data for the line\\n    line.set_xdata(new_x_data)\\n    line.set_ydata(new_y_data)\\n    \\n    return line,\\n\\n# Create the animation\\nanimation_coil = FuncAnimation(fig, update_coil, frames=range(100), interval=50)\\n\\n# Show the animation\\nplt.show()\\n\\nIn this example:\\n\\nThe update_coil function updates the angle (theta) of the coil over time to create the unwinding effect.\\n\\nThe angle is calculated based on the frame number, controlling the speed of unwinding.\\n\\nThe FuncAnimation is used to create the animation, updating the coil's shape for each frame.\\n\\n4. 3D plot\\n\\n3-D plot animation (Image by Author)\\n\\nimport numpy as np\\nimport matplotlib.pyplot as plt\\nfrom matplotlib.animation import FuncAnimation\\nfrom mpl_toolkits.mplot3d import Axes3D\\n\\n# Enable notebook backend\\n%matplotlib notebook\\n\\n# Create a figure and 3D axis\\nfig = plt.figure()\\nax = fig.add_subplot(111, projection='3d')\\n\\n# Create a wireframe\\nx_data = np.linspace(-5, 5, 100)\\ny_data = np.linspace(-5, 5, 100)\\nX, Y = np.meshgrid(x_data, y_data)\\nZ = np.sin(np.sqrt(X**2 + Y**2))\\n\\nwireframe = ax.plot_wireframe(X, Y, Z, rstride=5, cstride=5, color='b')\\n\\n# Animation function\\ndef update(frame):\\n    ax.view_init(elev=20, azim=frame)  # Rotate the view\\n    return wireframe,\\n\\n# Create the animation\\nanimation_3d = FuncAnimation(fig, update, frames=range(0, 360, 2), interval=50)\\n\\n# Show the animation\\nplt.show()\\n\\nIn this example:\\n\\nWe create a 3D plot using projection='3d'.\\n\\nA wireframe is generated based on a function (in this case, a surface plot of the sine of the distance from the origin).\\n\\nThe update function changes the view angle of the 3D plot for each frame to create a rotating effect.\\n\\nThe animation iterates through angles from 0 to 360 degrees.\\n\\nFeel free to modify the parameters and explore different 3D visualization options based on your data.\\n\\nAs we wrap up our exploration into the dynamic capabilities of Matplotlib, it’s clear that this library is not just a static chart-maker but a dynamic storyteller. We’ve witnessed how Matplotlib, often underestimated for its visual appeal, transforms into a versatile tool for creating captivating animations.\\n\\nHappy Learning, Thank You!\"}},\n",
       "  {'id': 'f4104ce25e0b',\n",
       "   'title': 'Top 10 coding mistakes committed by Data Scientists\\u200a—\\u200aA Dramatic Version',\n",
       "   'subtitle': 'Hey there, fellow Data Scientists! Let’s spill the tea on some common mistakes we data scientists tend to do while dancing with the code…',\n",
       "   'author': 'd80580992695',\n",
       "   'publication_id': '29038077e4c6',\n",
       "   'published_at': '2023-12-25 01:01:37',\n",
       "   'last_modified_at': '2024-01-01 08:33:33',\n",
       "   'tags': ['data-science', 'data', 'python', 'data-analysis'],\n",
       "   'topics': ['data-science'],\n",
       "   'claps': 50,\n",
       "   'voters': 18,\n",
       "   'word_count': 898,\n",
       "   'responses_count': 2,\n",
       "   'reading_time': 3.588679245283019,\n",
       "   'url': 'https://medium.com/codex/top-10-coding-mistakes-committed-by-data-scientists-a-dramatic-version-f4104ce25e0b',\n",
       "   'unique_slug': 'top-10-coding-mistakes-committed-by-data-scientists-a-dramatic-version-f4104ce25e0b',\n",
       "   'image_url': 'https://miro.medium.com/1*BeHAZ9ATRAfXS5RLRJD1ZQ.jpeg',\n",
       "   'lang': 'en',\n",
       "   'is_series': False,\n",
       "   'is_locked': True,\n",
       "   'is_shortform': False,\n",
       "   'top_highlight': '',\n",
       "   'content': {'id': 'f4104ce25e0b',\n",
       "    'content': 'Top 10 coding mistakes committed by Data Scientists - A Dramatic Version\\n\\nPic Credit: Unsplash\\n\\nHey there, fellow Data Scientists! Let’s spill the tea on some common mistakes we data scientists tend to do while dancing with the code monsters. If you have never committed these mistakes then you deserve a CLAP and if you are still doing these then it’s time to learn!\\n\\nSo, buckle up, and let’s dive into the top 10 coding mishaps we’ve all probably tripped over at some point.\\n\\n1. Ghosting Our Data Digs\\n\\nEver get too excited and skip the \"get to know you\" phase with your dataset?\\n\\nIt’s like skipping small talk and going straight to the date - you might miss the red flags!\\n\\nAlways give your data a little love; peek at it, see what makes it tick, and maybe find those sneaky NaNs hiding in the corners.\\n\\n# Data Exploration Example\\nimport pandas as pd\\n\\n# Load the dataset\\ndf = pd.read_csv(\\'your_dataset.csv\\')\\n\\n# Display basic statistics\\nprint(df.describe())\\n\\n# Check for missing values\\nprint(df.isnull().sum())\\n\\n2. Cleaning, Who Needs It?\\n\\nCleaning might be a bore, but it’s like brushing your teeth - you can’t skip it!\\n\\nIgnoring those messy outliers or missing values is like ignoring cavities. So, grab your data toothbrush and start scrubbing, because clean data is KING.\\n\\n# Data Cleaning Example\\nimport pandas as pd\\n\\n# Handling missing values\\ndf.dropna(inplace=True)\\n\\n# Handling outliers\\nQ1 = df.quantile(0.25)\\nQ3 = df.quantile(0.75)\\nIQR = Q3 - Q1\\ndf = df[~((df < (Q1 - 1.5 * IQR)) | (df > (Q3 + 1.5 * IQR))).any(axis=1)]\\n\\n3. Skipping the Data Sightseeing\\n\\nDon’t be that traveler who lands in a new city and never leaves the hotel room.\\n\\nExploratory Data Analysis (EDA) is your city tour. Check out the sights, spot the trends, and don’t miss the local quirks. Your data has stories to tell; let it be your guide!\\n\\n4. The Imbalanced Dance\\n\\nBalancing acts are for tightrope walkers, not for data.\\n\\nIgnoring imbalanced datasets is like trying to juggle with one hand tied. Give some love to those minority classes - they deserve the spotlight too!\\n\\n# Handling Imbalanced Data Example\\nfrom imblearn.over_sampling import SMOTE\\nfrom sklearn.model_selection import train_test_split\\n\\n# Assume X and y are your features and target variable\\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\\n\\n# Use SMOTE to oversample minority class\\nsmote = SMOTE(random_state=42)\\nX_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\\n\\n5. Trusting Default BFFs\\n\\nWe all love defaults, but don’t let them hog the spotlight.\\n\\nThose default parameters in your models might not be your data’s besties. Shake things up a bit, tune those hyperparameters, and let your models shine!\\n\\n# Tuning Model Hyperparameters Example (using GridSearchCV)\\nfrom sklearn.model_selection import GridSearchCV\\nfrom sklearn.ensemble import RandomForestClassifier\\n\\n# Assume X_train, X_test, y_train, y_test are your data\\nparam_grid = {\\n    \\'n_estimators\\': [50, 100, 200],\\n    \\'max_depth\\': [None, 10, 20],\\n}\\n\\nrf_model = RandomForestClassifier()\\n\\ngrid_search = GridSearchCV(estimator=rf_model, param_grid=param_grid, cv=3)\\ngrid_search.fit(X_train, y_train)\\n\\n# Best parameters\\nprint(\"Best Parameters:\", grid_search.best_params_)\\n\\n6. Feature Scaling Drama\\n\\nImagine a choir where one singer is way louder than the rest - not pleasant.\\n\\nScaling features is like giving everyone a fair chance to be heard. Normalize those features so they play nicely together.\\n\\n# Scaling Features Example\\nfrom sklearn.preprocessing import StandardScaler\\n\\n# Assume X is your feature matrix\\nscaler = StandardScaler()\\nX_scaled = scaler.fit_transform(X)\\n\\n7. Overfitting, the Drama Queen\\n\\nYour model might be whispering sweet nothings to your training data, but is it singing the same tune with the real world?\\n\\nOverfitting is like a dramatic breakup - avoid it by introducing regularization. Let your model be the strong, silent type, not the clingy ex.\\n\\n# Overfitting Prevention Example (using Regularization)\\nfrom sklearn.linear_model import Ridge\\n\\n# Assume X_train, X_test, y_train, y_test are your data\\nridge_model = Ridge(alpha=1.0)  # alpha is the regularization strength\\n\\nridge_model.fit(X_train, y_train)\\n\\n8. Feature FOMO\\n\\nFeatures are like friends; don’t underestimate their importance.\\n\\nCheck out the cool kids using feature importance analysis. Identify the MVPs, and let them shine in your model’s entourage.\\n\\n# Feature Importance Example (using Random Forest)\\nfrom sklearn.ensemble import RandomForestClassifier\\n\\n# Assume X_train, y_train are your data\\nrf_model = RandomForestClassifier()\\nrf_model.fit(X_train, y_train)\\n\\n# Feature importance\\nfeature_importance = rf_model.feature_importances_\\nprint(\"Feature Importance:\", feature_importance)\\n\\n9. Metric Misunderstandings\\n\\nPicking metrics is like choosing the right emoji for your text - it sets the tone.\\n\\nDon’t underestimate the power of precision, recall, and F1 score. They’re the cool emojis of model evaluation.\\n\\n# Model Evaluation Metrics Example (using classification report)\\nfrom sklearn.metrics import classification_report\\nfrom sklearn.ensemble import RandomForestClassifier\\n\\n# Assume X_train, X_test, y_train, y_test are your data\\nrf_model = RandomForestClassifier()\\nrf_model.fit(X_train, y_train)\\n\\n# Predictions\\ny_pred = rf_model.predict(X_test)\\n\\n# Classification Report\\nprint(\"Classification Report:\")\\nprint(classification_report(y_test, y_pred))\\n\\n10. Code Whisperer, Not Shouter\\n\\nYour code might be a Shakespearean sonnet, but if nobody understands it, is it really art? Visualize your insights, report them like you’re telling a friend a story over coffee. Make your code speak human, not code-ese.\\n\\n# Visualization and Reporting Example (using matplotlib and seaborn)\\nimport matplotlib.pyplot as plt\\nimport seaborn as sns\\n\\n# Assume you have a DataFrame df with results\\n# Visualization Example\\nsns.barplot(x=\\'variable\\', y=\\'value\\', data=pd.melt(df), hue=\\'category\\')\\nplt.title(\\'Results Overview\\')\\nplt.show()\\n\\n# Reporting Example (saving results to a CSV file)\\ndf.to_csv(\\'results_summary.csv\\', index=False)\\n\\nSo, fellow Data Scientics, let’s learn from these coding fumbles. Embrace your coding journey, remember to laugh at the mishaps, and keep those data adventures lively!\\n\\nHappy coding, and may the errors be ever in your favor! 🚀'}}],\n",
       " '8a910484fe84': [{'id': '0f27c5684804',\n",
       "   'title': 'Want to be Rich? DON’T Start a Side Hustle.',\n",
       "   'subtitle': 'Why Side Hustles Won’t Transform Your Life, But This Five-Step Formula Will',\n",
       "   'author': '8a910484fe84',\n",
       "   'publication_id': '*Self-Published*',\n",
       "   'published_at': '2023-12-03 22:29:33',\n",
       "   'last_modified_at': '2024-01-06 16:38:33',\n",
       "   'tags': ['side-hustle',\n",
       "    'business',\n",
       "    'entrepreneurship',\n",
       "    'make-money-online',\n",
       "    'marketing'],\n",
       "   'topics': ['startups'],\n",
       "   'claps': 244,\n",
       "   'voters': 30,\n",
       "   'word_count': 791,\n",
       "   'responses_count': 8,\n",
       "   'reading_time': 3.368238993710692,\n",
       "   'url': 'https://medium.com/@moneytent/want-to-be-rich-dont-start-a-side-hustle-0f27c5684804',\n",
       "   'unique_slug': 'want-to-be-rich-dont-start-a-side-hustle-0f27c5684804',\n",
       "   'image_url': 'https://miro.medium.com/1*th_mKOVG4094x6gq7xlF8w.png',\n",
       "   'lang': 'en',\n",
       "   'is_series': False,\n",
       "   'is_locked': False,\n",
       "   'is_shortform': False,\n",
       "   'top_highlight': \"You can't, not yet. Create the Minimum Viable Product (MVP), the simplest version of your solution.\",\n",
       "   'content': {'id': '0f27c5684804',\n",
       "    'content': 'Want to be Rich? DON’T Start a Side Hustle.\\n\\nWhy Side Hustles Won’t Transform Your Life, But This Five-Step Formula Will\\n\\n\\n\\nLet’s talk about something that could potentially change the game for you - your journey to financial freedom.\\n\\nSo, you’ve probably stumbled upon the idea of side hustles, watched countless videos on YouTube, and thought, \"This is it!\" But, what if I told you there’s a more impactful way to reshape your life?\\n\\nBuckle up; we’re diving into a formula that’s less about quick fixes and more about building a legacy.\\n\\nWe strongly recommend that you check out our guide on how to take advantage of AI in today’s passive income economy.\\n\\nThe Side Hustle Warning: A Mirage of Riches\\n\\nYou know, we’ve all been there - scouring the internet for the perfect side hustle, hoping it’s the secret to a multi-millionaire status.\\n\\nThe truth? It’s a rabbit hole. Hours turn into days, and you’re left feeling lost, overwhelmed, and confused.\\n\\nSide hustles are a distraction, a small supplement to your main job, and a constant run on the hamster wheel. Let’s aim higher, my friend.\\n\\nAiming High: The Five Steps to Transformative Success\\n\\nSo, here’s the deal - let’s ditch the side hustle mentality and follow a five-step formula that can genuinely change your life.\\n\\nIt all begins with taking action. Procrastination is the killer of dreams, and positive momentum starts with the first step.\\n\\nNow, let’s walk through the transformative steps that can turn your free time into a business powerhouse.\\n\\nStep One: Identifying the Problem and Taking the Plunge\\n\\nPicture this - you’re tired of the endless cycle, ready to identify a problem and create a solution.\\n\\nIt’s not about waiting for the perfect idea to hit you; it’s about looking at your life, your hobbies, and your work.\\n\\nList down the problems you’ve faced and think about potential solutions.\\n\\nWhether it’s raising chickens in a cold environment or starting an online tea business, your problems could be the gateway to a thriving business.\\n\\nStep Two: Minimum Viable Product (MVP) - Just Start Moving\\n\\nNow that you’ve identified the problem, it’s time to take action.\\n\\nBut here’s a crucial point - don’t get bogged down by trying to design the perfect solution.\\n\\nYou can’t, not yet. Create the Minimum Viable Product (MVP), the simplest version of your solution.\\n\\nSell it, get it into the hands of your customers, and listen to their feedback.\\n\\nThis is your blueprint for success, and there’s a brilliant book called ‘The Lean Startup’ that dives deeper into this strategy.\\n\\nStep Three: Getting Paid - Balancing Costs and Value\\n\\nAlright, you’ve got your MVP out there; now let’s talk money.\\n\\nEstimate your costs - include your time and all expenses.\\n\\nThen, set a price. Market research is your ally; see what similar services are charging.\\n\\nBe mindful; your selling price needs to be higher than your cost.\\n\\nIt might be a bit tricky at first, especially with service-based products, but aim to cover your costs, make some sales, and refine later.\\n\\nStep Four: Refine and Repeat - The Road to Riches\\n\\nNow, my friend, we’re on the cusp of greatness.\\n\\nYou’ve identified a problem, solved it, and got paid. But we’re not stopping there. This is where the magic happens - refine and repeat.\\n\\nLearn from your initial customers, make the product better, and keep evolving.\\n\\nThink about scaling up - how can you make it more efficient, faster, and cheaper?\\n\\nThis is the stage where your business transforms into a profit-generating machine.\\n\\nStep Five: Scaling Up - Leverage for Prosperity\\n\\nHere’s the key to sustained success - scaling up.\\n\\nAs you learn from your initial customers, focus on making your production more efficient.\\n\\nConsider leveraging external resources, processes, software, and machinery.\\n\\nThe goal is to produce more, better, and cheaper. This is where your business becomes wonderfully profitable, and you start reaping the rewards.\\n\\nKey Takeaways\\n\\nSo, here’s the bottom line - if you genuinely want to change your life, ditch the side hustles.\\n\\nWork on identifying a problem, creating a solution, and taking action.\\n\\nStart now, my friend. The journey to financial freedom begins with that first step. Trust me; you’ve got this!\\n\\nReady to transform your life?\\n\\nStart by identifying a problem, taking action, creating a solution, refining, scaling up, and then watch as your life transforms.\\n\\nDitch the side hustles and embrace a comprehensive formula that can genuinely change your life.\\n\\nTake the plunge into a world where positive momentum propels you towards financial freedom. Don’t just dream; start building your legacy today!\\n\\n\\n\\nWe strongly recommend that you check out our guide on how to take advantage of AI in today’s passive income economy.'}},\n",
       "  {'id': 'fe0a5a72bed5',\n",
       "   'title': 'The New AI Side Hustle That’s Making $1,579+/Day',\n",
       "   'subtitle': 'Unlocking a Goldmine: The Underrated AI Side Hustle',\n",
       "   'author': '8a910484fe84',\n",
       "   'publication_id': '*Self-Published*',\n",
       "   'published_at': '2024-02-02 22:01:42',\n",
       "   'last_modified_at': '2024-02-02 22:01:42',\n",
       "   'tags': ['ai',\n",
       "    'side-hustle',\n",
       "    'artificial-intelligence',\n",
       "    'make-money-online',\n",
       "    'machine-learning'],\n",
       "   'topics': ['artificial-intelligence', 'marketing'],\n",
       "   'claps': 13,\n",
       "   'voters': 5,\n",
       "   'word_count': 646,\n",
       "   'responses_count': 0,\n",
       "   'reading_time': 2.821069182389937,\n",
       "   'url': 'https://medium.com/@moneytent/the-new-ai-side-hustle-thats-making-1-579-day-fe0a5a72bed5',\n",
       "   'unique_slug': 'the-new-ai-side-hustle-thats-making-1-579-day-fe0a5a72bed5',\n",
       "   'image_url': 'https://miro.medium.com/1*CY891-DC6oRRgoZ0tA_Glw.png',\n",
       "   'lang': 'en',\n",
       "   'is_series': False,\n",
       "   'is_locked': False,\n",
       "   'is_shortform': False,\n",
       "   'top_highlight': '',\n",
       "   'content': {'id': 'fe0a5a72bed5',\n",
       "    'content': 'The New AI Side Hustle That’s Making $1,579+/Day\\n\\nUnlocking a Goldmine: The Underrated AI Side Hustle\\n\\nMaking a Fortune with AI-Generated Trivia Quizzes on TikTok\\n\\nHave you ever stumbled upon a goldmine so profound yet so underrated that it makes you wonder why not everyone is doing it? Well, that’s exactly what I discovered with an AI side hustle that’s making people earn a staggering $1,579 per day. Yes, you heard that right. So, let me take you on this journey of how you can tap into this lucrative venture using tools like Canva, ChatGPT, and the power of TikTok.\\n\\nWe strongly recommend that you check out our guide on how to take advantage of AI in today’s passive income economy.\\n\\n\\n\\nStep 1: Monetizing with TikTok Ads\\n\\nImagine starting a TikTok account and hitting millions of views on your second video. That’s not a dream; it’s what TriviaTimeHQ did. With TikTok’s new advertising monetization platform, the potential to earn is massive. Videos over a minute can earn around 50 cents to a dollar per 1000 views. Picture this: 22 million views in your first week could translate to over $11,000. And the secret? Simple trivia quiz videos.\\n\\nStep 2: Amplifying Earnings with Affiliate Commissions\\n\\nAffiliate marketing is another avenue to explore. By promoting products through affiliate links in your TikTok bio, you can earn substantial commissions. I discovered accounts like realconversationseries, which cater to specific niches like English learning, and they’re making a killing. Platforms like ClickBank offer a plethora of high-commission affiliate offers, opening doors to endless earning possibilities.\\n\\nStep 3: Crafting Perfect Trivia Quizzes with ChatGPT\\n\\nCreating engaging trivia quizzes is a breeze with ChatGPT. Whether you prefer basic questions or ones that challenge the intellect of geography enthusiasts, ChatGPT can tailor quizzes to your needs. You can even specify the style, like fill-in-the-blanks, to keep your content diverse and engaging.\\n\\nStep 4: Bringing Quizzes to Life with Canva\\n\\nNow, for the magic touch - turning those quizzes into captivating videos using Canva. Canva’s user-friendly interface lets you customize pre-built quiz video templates, ensuring your videos align perfectly with your niche’s aesthetic. With an array of visual elements and the ability to add AI voiceovers, creating professional-looking videos is a piece of cake.\\n\\nThe Journey to Success\\n\\nSo, let’s picture the journey: You start by crafting a trivia quiz on ChatGPT. Next, you bring it to life in Canva, creating a visually appealing video. Then, you post it on TikTok, where it garners thousands, if not millions, of views. With the right strategy, your video not only earns through TikTok Ads but also drives traffic to your affiliate links. You’re not just creating content; you’re creating an income stream.\\n\\nA Word of Caution\\n\\nRemember, consistency and quality are key. Your content needs to resonate with your audience. Also, keep in mind the limitations and guidelines of platforms like TikTok and affiliate programs. Not all countries have access to the TikTok Creator Fund, so always have a backup plan like affiliate marketing.\\n\\nYour Turn to Shine\\n\\nNow, it’s your turn. Imagine harnessing the power of AI and social media to create a side hustle that’s not only profitable but also fun. You’re creating content that educates, entertains, and engages a wide audience while opening doors to financial freedom. It’s not just about making money; it’s about creating value and connecting with people worldwide.\\n\\nSo, why wait? Dive into this incredible opportunity and start your journey today. Who knows, you might just be the next big hit on TikTok, all thanks to a simple trivia quiz. Remember, in the world of AI and social media, the only limit is your imagination. Let’s make those dreams a reality!\\n\\n\\n\\nWe strongly recommend that you check out our guide on how to take advantage of AI in today’s passive income economy.'}},\n",
       "  {'id': '16e93bc3cb05',\n",
       "   'title': 'Top AI tools for UI Designers',\n",
       "   'subtitle': 'Leveraging AI in UI/UX Design: A Creative Revolution',\n",
       "   'author': '8a910484fe84',\n",
       "   'publication_id': '*Self-Published*',\n",
       "   'published_at': '2024-02-02 21:01:42',\n",
       "   'last_modified_at': '2024-02-02 21:01:42',\n",
       "   'tags': ['ui', 'ui-design', 'ai', 'artificial-intelligence', 'ai-tools'],\n",
       "   'topics': ['design'],\n",
       "   'claps': 6,\n",
       "   'voters': 1,\n",
       "   'word_count': 881,\n",
       "   'responses_count': 0,\n",
       "   'reading_time': 3.7078616352201257,\n",
       "   'url': 'https://medium.com/@moneytent/top-ai-tools-for-ui-designers-16e93bc3cb05',\n",
       "   'unique_slug': 'top-ai-tools-for-ui-designers-16e93bc3cb05',\n",
       "   'image_url': 'https://miro.medium.com/1*npLf3N72udSPw7mlAfi6Aw.png',\n",
       "   'lang': 'en',\n",
       "   'is_series': False,\n",
       "   'is_locked': False,\n",
       "   'is_shortform': False,\n",
       "   'top_highlight': '',\n",
       "   'content': {'id': '16e93bc3cb05',\n",
       "    'content': 'Top AI tools for UI Designers\\n\\nLeveraging AI in UI/UX Design: A Creative Revolution\\n\\nEmbracing the AI Wave in Design\\n\\nAs we stand at the cusp of a new era, where artificial intelligence intertwines seamlessly with our creative processes, it’s impossible not to feel a surge of excitement. Gone are the days of tedious, repetitive tasks that drain our creative spirits. AI is not just a tool; it’s a collaborator, a muse that amplifies our design capabilities. Let’s dive into this fascinating world where technology meets creativity, and explore ten AI tools that are revolutionizing UI/UX design.\\n\\nWe strongly recommend that you check out our guide on how to take advantage of AI in today’s passive income economy.\\n\\n\\n\\n1. FigJam AI: Simplifying Complexity\\n\\nImagine a tool that breathes life into your wireframes and user flow diagrams with minimal effort. That’s FigJam AI for you. With a simple prompt, like designing a flowchart for a mobile banking app, this tool transforms your ideas into structured diagrams. It’s like having a diligent assistant who takes care of the meticulous details, freeing you to focus on the broader design narrative.\\n\\n2. Mushu: Where UI Meets AI\\n\\nCreated by Pablo Stanley and his team, Mushu represents a perfect symbiosis of user interface and artificial intelligence. Picture this: you’re crafting a landing page for a podcast. You input your vision into Figma, and Mushu brings it to life. The result? A near-complete design that serves as a robust foundation, ripe for your creative touch.\\n\\n3. ChatGPT: Your Copywriting Companion\\n\\nEvery designer knows the value of compelling copy. ChatGPT steps in as your writing partner, generating user personas, research material, and even entire sections of text for your projects. Its ability to kickstart your creativity with words is nothing short of magical.\\n\\n4. MidJourney: A Visual Odyssey\\n\\nIf you’re in pursuit of stunning images, MidJourney is your go-to AI tool. Operating within Discord, this platform offers unparalleled image generation capabilities. Whether you’re upscaling, searching for specific themes, or experimenting with visual styles, MidJourney is a treasure trove of visual inspiration.\\n\\n5. Adobe Firefly: Unleashing Creativity\\n\\nAdobe’s Firefly AI technology is a game-changer for UI designers. It empowers you with text-to-image generation, generative fill, and unique text effects. If you’re looking to inject a dose of uniqueness into your designs, Adobe Firefly, accessible through Adobe Express, is your creative ally.\\n\\n6. FontJoy: Harmonizing Typography\\n\\nFont pairing is an art, and FontJoy is the artist’s palette. Powered by AI, this tool helps you discover and pair fonts in a way that is both aesthetically pleasing and functionally sound. Lock in your favorite font, and watch as FontJoy weaves typography magic, crafting pairings that resonate with your design ethos.\\n\\n7. Colormind: A Spectrum of Possibilities\\n\\nColormind is a testament to how AI can enhance the color selection process. It’s not just a palette generator; it’s a color consultant, offering unique combinations and allowing you to tweak and refine them to your heart’s content. The tool uses AI to guide your choices, ensuring your palettes are not just beautiful but also cohesive.\\n\\n8. Uizard: Prototyping Made Easy\\n\\nUizard, a somewhat controversial tool in the UI community, offers a unique proposition: enter a prompt, and it generates a prototype in mere seconds. While it might not be the final product, Uizard provides a solid starting point, a canvas awaiting your creative strokes.\\n\\n9. Vizil: Transforming Sketches into Designs\\n\\nImagine turning a hand-drawn sketch into a high-fidelity design with just a few clicks. Vizil’s ‘Sketch to Design’ feature does precisely that. While it’s not flawless, the potential it holds is immense. It’s like having a digital artisan who understands and respects your initial vision.\\n\\n10. Genius UI: The Future of Component Design\\n\\nGenius UI, still in the waiting list phase, is an intriguing proposition. It promises to harness the power of ChatGPT for generating UI components in both design and code. The prospect of designing and coding simultaneously, with AI assistance, is a tantalizing glimpse into the future of UI design.\\n\\nThe AI Journey: A Path to Explore\\n\\nAs we navigate these AI-infused waters, it’s important to remember that these tools are not replacements for our creativity but catalysts that enhance it. They open up new possibilities, allowing us to push the boundaries of what we can imagine and create. Embracing these AI tools is not just about staying relevant; it’s about redefining the very essence of design.\\n\\nSo, my fellow designers, I encourage you to dive into this exciting world. Experiment with these tools, integrate them into your workflow, and watch as they transform your design process. The future of UI/UX design is here, and it’s brimming with AI-enabled possibilities.\\n\\nRemember, these tools are just the beginning. As AI continues to evolve, so will our capabilities as designers. So keep your eyes open, your mind curious, and your heart full of creative passion. The journey into the AI-enhanced design is not just about the destination; it’s about the fascinating path we take to get there. Let’s embark on this journey together, and reshape the world of design as we know it.\\n\\n\\n\\nWe strongly recommend that you check out our guide on how to take advantage of AI in today’s passive income economy.'}},\n",
       "  {'id': '63eba8ec76a1',\n",
       "   'title': 'BEST AI Tools for Content Creators in 2024!',\n",
       "   'subtitle': 'Harnessing the Power of AI for Unparalleled Content Creation',\n",
       "   'author': '8a910484fe84',\n",
       "   'publication_id': '*Self-Published*',\n",
       "   'published_at': '2024-02-02 20:01:01',\n",
       "   'last_modified_at': '2024-02-02 20:01:01',\n",
       "   'tags': ['ai',\n",
       "    'content-creation',\n",
       "    'artificial-intelligence',\n",
       "    'youtube',\n",
       "    'machine-learning'],\n",
       "   'topics': ['artificial-intelligence'],\n",
       "   'claps': 26,\n",
       "   'voters': 4,\n",
       "   'word_count': 685,\n",
       "   'responses_count': 0,\n",
       "   'reading_time': 2.968238993710692,\n",
       "   'url': 'https://medium.com/@moneytent/best-ai-tools-for-content-creators-in-2024-63eba8ec76a1',\n",
       "   'unique_slug': 'best-ai-tools-for-content-creators-in-2024-63eba8ec76a1',\n",
       "   'image_url': 'https://miro.medium.com/1*t7NwUxee8giAMPWqdIFqJA.png',\n",
       "   'lang': 'en',\n",
       "   'is_series': False,\n",
       "   'is_locked': False,\n",
       "   'is_shortform': False,\n",
       "   'top_highlight': '',\n",
       "   'content': {'id': '63eba8ec76a1',\n",
       "    'content': 'BEST AI Tools for Content Creators in 2024!\\n\\nHarnessing the Power of AI for Unparalleled Content Creation\\n\\nRevolutionizing Digital Expression with AI Tools\\n\\nIn an era where content is king, AI tools have emerged as the game-changers in the realm of digital creation. As someone deeply immersed in this transformative landscape, I’ve been exploring tools that not only save time but also amplify the impact of our digital footprints. Here, I want to share my experiences and insights into these revolutionary tools.\\n\\nWe strongly recommend that you check out our guide on how to take advantage of AI in today’s passive income economy.\\n\\n\\n\\nChatGPT: The Crown Jewel of AI Content Creation\\n\\nAt the heart of my toolkit is ChatGPT. It’s a tool that embodies the cutting edge of AI, offering capabilities that extend far beyond mere text generation. The recent integration of DALL-E 3 into ChatGPT is particularly exciting. This feature allows the creation of stunning images directly from text inputs, enabling content creators like us to craft visually arresting thumbnails and graphics with ease and precision.\\n\\nOpus Clip: The Master of Video Content Repurposing\\n\\nAnother gem in the AI content creation crown is Opus Clip. This remarkable tool takes your long-form videos and segments them into bite-sized, engaging clips. It’s not just the segmentation that’s impressive; Opus Clip also adds captions, allows for customization, and is set to integrate B-roll footage based on AI analysis. This tool is a godsend for repurposing content across various platforms, offering endless possibilities for engagement.\\n\\nFire Cut: The Premiere Pro Plugin Revolutionizing Editing\\n\\nVenturing into the realm of video editing, Fire Cut is a plugin for Premiere Pro that’s redefining the editing workflow. It automates multiple camera angle cuts, adds dynamic captions, and even includes features like automatic zoom and chapter creation. Its ability to remove filler words seamlessly is a testament to its sophistication, transforming the editing process into a swift and intuitive experience.\\n\\nContent Strategy: Balancing AI and Human Creativity\\n\\nWhile these tools offer immense power, they are not without their limitations. The human touch remains irreplaceable. AI can generate content, but it’s our unique perspective and creativity that breathe life into it. For instance, while Opus Clip generates numerous clips from a single video, it’s the discerning eye of the creator that picks the gems. It’s about striking the right balance, using AI as a foundation upon which our creativity and style can flourish.\\n\\nEmbracing the AI-Assisted Future of Content Creation\\n\\nAs we stand on the cusp of a new era in digital content creation, it’s essential to embrace these AI tools. They are not just conveniences; they are catalysts for unleashing our creative potential. From ChatGPT’s text and image generation capabilities to Opus Clip’s video repurposing prowess and Fire Cut’s editing automation, these tools are redefining what it means to be a content creator.\\n\\nThe Journey Continues…\\n\\nMy journey in the ever-evolving world of AI-assisted content creation is ongoing. I continue to explore, experiment, and share my findings with my community, \"Deeper than the Brand.\" Here, we delve into the intricacies of AI in content creation, uncovering new ways to harness its power.\\n\\nIn conclusion, the fusion of AI tools like ChatGPT, Opus Clip, and Fire Cut with our creativity is creating a new frontier in content creation. It’s a thrilling time to be a creator, and I invite you to join me in exploring the limitless possibilities of this AI-enhanced landscape. Let’s continue to push the boundaries, blend our artistic flair with AI’s efficiency, and redefine the essence of digital storytelling.\\n\\nTake Action: Are you ready to embark on this transformative journey of AI-assisted content creation? Dive into the world of ChatGPT, Opus Clip, and Fire Cut, and unleash your creative potential. Join me in the community at \"Deeper than the Brand\" and let’s explore the future of digital expression together. Remember, in this AI-powered era, your creativity is the limit.\\n\\n\\n\\nWe strongly recommend that you check out our guide on how to take advantage of AI in today’s passive income economy.'}},\n",
       "  {'id': 'e1e04de813a0',\n",
       "   'title': 'How To Build a Website FAST Using AI',\n",
       "   'subtitle': 'Dive into the Future of Web Design\\u200a—\\u200aEffortless, Quick, and Tailored to Your Brand with AI',\n",
       "   'author': '8a910484fe84',\n",
       "   'publication_id': '*Self-Published*',\n",
       "   'published_at': '2024-02-02 19:01:40',\n",
       "   'last_modified_at': '2024-02-02 19:01:40',\n",
       "   'tags': ['website',\n",
       "    'ai',\n",
       "    'artificial-intelligence',\n",
       "    'machine-learning',\n",
       "    'no-code'],\n",
       "   'topics': ['marketing', 'design'],\n",
       "   'claps': 7,\n",
       "   'voters': 1,\n",
       "   'word_count': 794,\n",
       "   'responses_count': 0,\n",
       "   'reading_time': 3.3795597484276727,\n",
       "   'url': 'https://medium.com/@moneytent/how-to-build-a-website-fast-using-ai-e1e04de813a0',\n",
       "   'unique_slug': 'how-to-build-a-website-fast-using-ai-e1e04de813a0',\n",
       "   'image_url': 'https://miro.medium.com/1*6k1FnAPWYG52bRsZOGIhYA.png',\n",
       "   'lang': 'en',\n",
       "   'is_series': False,\n",
       "   'is_locked': False,\n",
       "   'is_shortform': False,\n",
       "   'top_highlight': '',\n",
       "   'content': {'id': 'e1e04de813a0',\n",
       "    'content': 'How To Build a Website FAST Using AI\\n\\nDive into the Future of Web Design - Effortless, Quick, and Tailored to Your Brand with AI\\n\\nThe Dawn of a New Era in Web Design\\n\\nRemember the days when building a website was akin to a Herculean task, reserved for the tech-savvy and the code-literate? Those days are long gone. Today, I’m here to walk you through a revolutionary journey, where AI takes the wheel in crafting your digital presence. This isn’t just a leap; it’s a quantum jump in how we approach website creation.\\n\\nWe strongly recommend that you check out our guide on how to take advantage of AI in today’s passive income economy.\\n\\n\\n\\nLaying the Foundation: Choosing the Right Web Host\\n\\nBefore we dive into the nitty-gritty of AI-driven web design, let’s talk about web hosting. Think of it as the digital land where your website will reside. Without it, your website is just a blueprint without a physical address. For years, I’ve navigated the vast oceans of web hosting, and one platform has consistently stood out - Hostinger. It’s more than just a hosting service; it’s the launchpad for your website’s journey.\\n\\nHostinger: A Blend of Tradition and Innovation\\n\\nHostinger isn’t your average hosting platform. It’s an ecosystem that intertwines traditional hosting services with cutting-edge AI features. It’s rare to find a hosting company that not only stores your digital content but also helps you create it. And with their latest AI website builder, they’re redefining the game.\\n\\nSeizing the Moment: Unbelievable Offers\\n\\nAs I guide you through this landscape, let’s take a moment to appreciate Hostinger’s current offer - a whopping 79% discount. This isn’t just a deal; it’s a gateway to endless possibilities in the digital world, perfectly timed with the 2024 New Year celebrations.\\n\\nThe Magic of the AI Website Builder\\n\\nNow, let’s talk about the crown jewel of Hostinger - the AI Website Builder. Imagine creating a fully functional website with just a few clicks. No coding, no hassle. Whether it’s an online store, a blog, or a portfolio, this tool adapts to your needs, crafting a site that resonates with your brand’s essence.\\n\\nCustomization at Your Fingertips\\n\\nThe beauty of Hostinger’s platform lies in its customization options. You’re not just getting a cookie-cutter website; you’re getting a canvas to paint your digital masterpiece. From color themes to fonts, every element can be tweaked to mirror your unique style.\\n\\nThe Power of Integrated AI Tools\\n\\nHostinger’s platform is a treasure trove of AI tools. It’s like having a digital Swiss Army knife at your disposal. From AI blog generators to logo makers, every tool is designed to streamline your web design process, making it accessible to everyone, regardless of their technical background.\\n\\nCreating with AI: A Seamless Experience\\n\\nLet’s delve into the AI image generator. It’s akin to having a personal artist who understands your vision. Simply type in your requirements, and voilà - you have a range of images to choose from, all tailored to fit your website’s aesthetic.\\n\\nThe Ultimate Convenience: Hostinger’s Image Library\\n\\nGone are the days of scouring the internet for the perfect image. Hostinger’s library is a goldmine of high-quality, non-copyright images. Just drag and drop your chosen image onto your site. It’s that easy.\\n\\nBeyond Aesthetics: Enhancing User Engagement\\n\\nThe AI heat map feature is a game-changer. It shows where visitors are likely to focus on your website, allowing you to strategically place content for maximum impact. It’s like having a window into your visitors’ minds.\\n\\nTaking Action: The Path to Digital Success\\n\\nNow, we’ve traversed the landscape of AI-driven website creation. But knowledge without action is like a ship without a sail. It’s time to take the plunge. Head over to Hostinger, harness these tools, and start building your digital dream.\\n\\nElevating Your Website with ChatGPT\\n\\nTo add another layer to your website, consider ChatGPT. It’s a powerhouse for content creation, capable of generating blogs, redesigning your site, and even brainstorming brand names. It’s the companion you need for a website that not only looks good but also communicates effectively.\\n\\nThe Final Word: Embrace the Journey\\n\\nEmbarking on this journey of website creation is more than just a task; it’s an adventure. Explore, experiment, and enjoy the process. With Hostinger and AI at your fingertips, you’re not just building a website; you’re crafting a piece of the digital future.\\n\\nRemember, the path to a stunning website is not just about the destination; it’s about the journey. Take that first step today, and witness your digital dreams unfold into reality.\\n\\n\\n\\nWe strongly recommend that you check out our guide on how to take advantage of AI in today’s passive income economy.'}},\n",
       "  {'id': 'c6a008a4fb67',\n",
       "   'title': 'Making AI Mobile App Using One Tool For FREE!',\n",
       "   'subtitle': 'Embracing the No-Code Revolution: Crafting Digital Dreams Without Coding',\n",
       "   'author': '8a910484fe84',\n",
       "   'publication_id': '*Self-Published*',\n",
       "   'published_at': '2024-02-02 18:01:53',\n",
       "   'last_modified_at': '2024-02-02 18:01:53',\n",
       "   'tags': ['ai',\n",
       "    'apps',\n",
       "    'artificial-intelligence',\n",
       "    'ai-tools',\n",
       "    'mobile-app-development'],\n",
       "   'topics': ['artificial-intelligence'],\n",
       "   'claps': 9,\n",
       "   'voters': 2,\n",
       "   'word_count': 807,\n",
       "   'responses_count': 0,\n",
       "   'reading_time': 3.428616352201258,\n",
       "   'url': 'https://medium.com/@moneytent/making-ai-mobile-app-using-one-tool-for-free-c6a008a4fb67',\n",
       "   'unique_slug': 'making-ai-mobile-app-using-one-tool-for-free-c6a008a4fb67',\n",
       "   'image_url': 'https://miro.medium.com/1*VvGvvUL8RVPPMV-DextZ_w.png',\n",
       "   'lang': 'en',\n",
       "   'is_series': False,\n",
       "   'is_locked': False,\n",
       "   'is_shortform': False,\n",
       "   'top_highlight': '',\n",
       "   'content': {'id': 'c6a008a4fb67',\n",
       "    'content': 'Making AI Mobile App Using One Tool For FREE!\\n\\nEmbracing the No-Code Revolution: Crafting Digital Dreams Without Coding\\n\\nA Journey from Skepticism to Innovation\\n\\nI remember a time, not so long ago in 2019, when the mere thought of creating an app without the backbone of programming languages like C++ or Python seemed almost rebellious. It was a time of rigid boundaries, where the act of coding was sacred, a rite of passage for anyone daring to contribute to the digital world.\\n\\nBut as I journeyed through the evolving landscape of technology, a revelation dawned on me: the art of creating need not be confined to lines of code. This revelation led me to the doors of Imagica AI, a portal to a world where creativity knows no bounds, and where ideas could take flight without the traditional chains of coding.\\n\\nWe strongly recommend that you check out our guide on how to take advantage of AI in today’s passive income economy.\\n\\n\\n\\nThe New Era of Digital Creation\\n\\nImagica AI, a name that initially seemed like a ticket to a fantasy world, became my guide in this new reality. It presented a realm where apps, websites, and chatbots could be conjured up with nothing but a prompt. It was as if the AI understood the language of my imagination, translating my thoughts into digital reality.\\n\\nThe Three Pathways to Creation\\n\\nWith Imagica AI, I discovered three magical pathways to bring my digital dreams to life:\\n\\nPrompt-Powered Creation: Here, I simply fed a prompt to the AI. Like a skilled artisan, it crafted the entire workflow, leaving me with the joy of tweaking and publishing.\\n\\nThe Blank Canvas Approach: For those who prefer the thrill of starting from scratch, this pathway was an open field, ripe with possibilities.\\n\\nThe Template Trail: Imagica AI also offered a treasure trove of templates, each a starting point for a unique journey.\\n\\nEmbarking on the Creator Economy\\n\\nThe true test of Imagica AI’s prowess was in its ability to automate the pathway to the creator economy. I envisioned a platform where beginners could lay the foundation of their content empire, simply by stating their niche. From channel names to logos, metadata, and content strategies - all sprang forth automatically, guided by the AI’s understanding of my vision.\\n\\nThe Magic of the AI-Generated Travel App\\n\\nTo illustrate the power of this tool, let me take you through the creation of a travel app. With a simple input of a location and interests, the AI conjured up a weekend travel planner. It felt like wielding a magic wand, transforming inputs into bespoke travel experiences.\\n\\nCrafting from Scratch: The Automation of a Content Empire\\n\\nBut the true allure of Imagica AI lay in the freedom to create from the ground up. I ventured into designing an automated system for a YouTube content creator, focusing on a niche of their choosing. The process was intuitive and seamless:\\n\\nChannel Name and Logo: Starting with a catchy, SEO-friendly name, followed by a logo designed to reflect the essence of the channel.\\n\\nMetadata Magic: The AI then spun descriptions, keywords, and hashtags, weaving the narrative of the channel.\\n\\nContent Titles: From intriguing questions to captivating titles, the AI generated ideas that promised to hook the audience.\\n\\nDiverse Media Forms: The platform even extended its prowess to creating newsletter titles and other media formats.\\n\\nThe result was a fully automated, ready-to-launch YouTube channel, tailored to the creator’s niche.\\n\\nThe Final Stretch: Publishing and Impact\\n\\nThe final step was to publish. With a few clicks, the AI-assembled app was ready, accessible through a link, and open for the world to explore. It was a testament to the power of no-code platforms, a beacon for aspiring creators who once saw technology as a barrier.\\n\\nThe No-Code Revolution: A Gateway to Unleashed Creativity\\n\\nIn this journey, I’ve come to realize that the no-code movement is more than just a technological advancement. It’s a liberation movement for creativity. It’s an invitation to those who dream but hesitate at the complexity of coding. It’s a bridge connecting imagination to reality, ensuring that the digital world is no longer the exclusive playground of coders.\\n\\nAs we embrace this revolution, we open doors to endless possibilities. We enable dreamers, storytellers, and visionaries to paint their dreams onto the digital canvas, unrestricted by the technicalities of coding. In this new era, your imagination is the only limit.\\n\\nSo, I invite you to embark on this journey. Explore Imagica AI, experiment with its magic, and watch as your digital dreams take form. This is not just a technological evolution; it’s a creative revolution, and it’s yours to command.\\n\\n\\n\\nWe strongly recommend that you check out our guide on how to take advantage of AI in today’s passive income economy.'}},\n",
       "  {'id': '914c14819bcf',\n",
       "   'title': 'This Free ChatGPT SEO Script Is Worth Millions',\n",
       "   'subtitle': 'Transforming a YouTube Script into a Captivating Medium Article',\n",
       "   'author': '8a910484fe84',\n",
       "   'publication_id': '*Self-Published*',\n",
       "   'published_at': '2024-02-02 17:02:00',\n",
       "   'last_modified_at': '2024-02-02 17:02:00',\n",
       "   'tags': ['chatgpt', 'seo', 'ai', 'artificial-intelligence', 'script'],\n",
       "   'topics': ['programming'],\n",
       "   'claps': 2,\n",
       "   'voters': 2,\n",
       "   'word_count': 744,\n",
       "   'responses_count': 0,\n",
       "   'reading_time': 3.190880503144654,\n",
       "   'url': 'https://medium.com/@moneytent/this-free-chatgpt-seo-script-is-worth-millions-914c14819bcf',\n",
       "   'unique_slug': 'this-free-chatgpt-seo-script-is-worth-millions-914c14819bcf',\n",
       "   'image_url': 'https://miro.medium.com/1*S9B7W4HAhxAdazIrjnY0Kg.png',\n",
       "   'lang': 'en',\n",
       "   'is_series': False,\n",
       "   'is_locked': False,\n",
       "   'is_shortform': False,\n",
       "   'top_highlight': '',\n",
       "   'content': {'id': '914c14819bcf',\n",
       "    'content': 'This Free ChatGPT SEO Script Is Worth Millions\\n\\nTransforming a YouTube Script into a Captivating Medium Article\\n\\nIntroduction to the World of Automation and Scripting\\n\\nHello there, friend! Today, I want to share with you an incredible journey into the world of automation, specifically focusing on a scripting process that I’ve found utterly transformative for my business. Imagine being able to automate tedious tasks, enhance productivity, and potentially skyrocket your online presence. That’s exactly what I’m about to dive into, and I’m excited to walk you through every step.\\n\\nWe strongly recommend that you check out our guide on how to take advantage of AI in today’s passive income economy.\\n\\n\\n\\nThe Magic Begins: Setting Up Your Automation Tools\\n\\nEmbracing Git: The Gateway to Code Sharing\\n\\nOur first step in this adventure is embracing Git. If you’re new to this, Git is essentially a platform that allows you to clone repositories and manage code changes. It’s a game-changer for sharing and updating code, especially when dealing with multiple files.\\n\\nPython: More Than Just a Snake\\n\\nNext up, we’re delving into Python. Oh, and it’s not just a serpent! Python, in our world, is a versatile programming language that’s integral to running scripts. It’s both a language and a computational powerhouse, essential for executing the scripts we’ll discuss.\\n\\nVisual Studio Code: Your Coding Canvas\\n\\nEnter Visual Studio Code, our Integrated Development Environment (IDE). Think of it as a sophisticated notepad for your code, making editing a breeze. It’s where your code lives, breathes, and comes to life.\\n\\nThe Heart of the Process: Python, Git, and VS Code in Harmony\\n\\nNow that we have our tools - Git, Python, and Visual Studio Code - it’s time to bring them together. This synergy is where the magic happens. We’ll use Git to clone a repository (a fancy term for copying code from the internet to your machine), Python to run the script, and Visual Studio Code to interact and modify the code effortlessly.\\n\\nScripting for Success: Automating Your Business Needs\\n\\nThe Power of Automation in Your Hands\\n\\nHere’s where we get to the heart of our journey. I’ve crafted a script that can do wonders for your business. Whether it’s generating content, organizing data, or simplifying complex tasks, this script is a digital Swiss Army knife.\\n\\nSetting Up: A Step-by-Step Guide\\n\\nI’ll walk you through setting up the script, from cloning the repository to installing Python and Visual Studio Code. It’s a straightforward process, and I’ll ensure you have all the knowledge needed to do it yourself.\\n\\nCustomization: Tailoring to Your Business\\n\\nThe beauty of this script lies in its flexibility. You can tailor it to your specific business needs. Whether you’re managing a blog, an online store, or any digital platform, this script can be adapted to suit your unique requirements.\\n\\nUnleashing the Power of ChatGPT: AI-Driven Content Creation\\n\\nHarnessing AI for Effortless Content\\n\\nOne of the script’s key features is its integration with ChatGPT, an AI-driven tool that can generate content at an astonishing pace. Imagine having an AI assistant that can churn out high-quality articles, tailored to your needs, in minutes.\\n\\nFine-Tuning for Perfection\\n\\nWhile the AI does most of the heavy lifting, your human touch is still crucial. I’ll show you how to fine-tune the AI’s output, ensuring the content aligns perfectly with your brand’s voice and style.\\n\\nConclusion: Embracing Automation for Business Growth\\n\\nTaking Action for Tangible Results\\n\\nAs we wrap up, I encourage you to take these insights and apply them to your business. The world of automation and AI offers immense potential for growth, efficiency, and success. By embracing these tools, you’re not just keeping up with the digital age; you’re leveraging it to propel your business forward.\\n\\nYour Next Steps to Success\\n\\nStart by setting up the tools we discussed. Experiment with the script, tailor it to your needs, and watch as your business processes transform. Remember, the journey to automation is ongoing, and there’s always more to learn and explore.\\n\\nThank you for joining me on this exciting journey. As you venture into the world of automation and AI, remember that these tools are here to augment your skills and amplify your business’s potential. Embrace them, and the results will speak for themselves. Happy automating, and here’s to your success!\\n\\n\\n\\nWe strongly recommend that you check out our guide on how to take advantage of AI in today’s passive income economy.'}},\n",
       "  {'id': 'f004bd43e60b',\n",
       "   'title': 'Copy My $400/Day Affiliate Marketing Strategy',\n",
       "   'subtitle': 'Unveiling the Secrets to Successful Affiliate Marketing\\u200a—\\u200aA Journey from Trials to Triumph',\n",
       "   'author': '8a910484fe84',\n",
       "   'publication_id': '*Self-Published*',\n",
       "   'published_at': '2024-02-02 16:01:42',\n",
       "   'last_modified_at': '2024-02-02 16:01:42',\n",
       "   'tags': ['affiliate-marketing',\n",
       "    'make-money-online',\n",
       "    'marketing',\n",
       "    'passive-income',\n",
       "    'side-hustle'],\n",
       "   'topics': ['marketing'],\n",
       "   'claps': 71,\n",
       "   'voters': 5,\n",
       "   'word_count': 630,\n",
       "   'responses_count': 1,\n",
       "   'reading_time': 2.760691823899371,\n",
       "   'url': 'https://medium.com/@moneytent/copy-my-400-day-affiliate-marketing-strategy-f004bd43e60b',\n",
       "   'unique_slug': 'copy-my-400-day-affiliate-marketing-strategy-f004bd43e60b',\n",
       "   'image_url': 'https://miro.medium.com/1*uyYHVDRN_ShVQLttoJQrmQ.png',\n",
       "   'lang': 'en',\n",
       "   'is_series': False,\n",
       "   'is_locked': False,\n",
       "   'is_shortform': False,\n",
       "   'top_highlight': '',\n",
       "   'content': {'id': 'f004bd43e60b',\n",
       "    'content': 'Copy My $400/Day Affiliate Marketing Strategy\\n\\nUnveiling the Secrets to Successful Affiliate Marketing - A Journey from Trials to Triumph\\n\\nA Realistic Guide to Your First $11,000\\n\\nHey friend! Let me share something incredible with you. Over the past two years, I’ve been deeply immersed in the world of affiliate marketing. It wasn’t an easy ride - countless sleepless nights and a fair share of trial and error. But guess what? I recently made over $3,000 in just a week through affiliate marketing! And I’m excited to guide you on how to realistically earn your first $11,000 in this arena.\\n\\nWe strongly recommend that you check out our guide on how to take advantage of AI in today’s passive income economy.\\n\\n\\n\\nThe Power of Affiliate Networks: Where to Begin\\n\\nYour first step into the world of affiliate marketing is joining a network. I recommend starting with Impact.com. It’s fast and easy - just head over to app.impact.com and sign up as a partner. They offer a plethora of brands with affiliate programs. Once you’re in, click on ‘Brands’ and ‘Find Brands’ to explore tens of thousands of opportunities waiting for you.\\n\\nChoosing Your Niche: The Foundation of Success\\n\\nIn affiliate marketing, your niche is crucial. For me, software, travel, and health and fitness have been lucrative. But you might find your groove in different areas. On Impact, you can browse categories to find what resonates with you. Take NordVPN, for example. Their acceptance rate is 100%, meaning new affiliates like you can easily start promoting their products.\\n\\nClickBank: A Gateway to Diverse Niches\\n\\nAnother platform worth exploring is ClickBank. It’s free and offers a range of categories. Whether it’s health, fitness, or something else, you can quickly grab affiliate links and start promoting. Products here, like the iara juice, offer an average commission of $139 per sale!\\n\\nThe Strategy: High-Ticket Products in Travel\\n\\nFor this guide, let’s focus on a high-ticket product in the travel niche: Skyscanner. As an affiliate, you earn 20% commission on flight bookings. Imagine someone books a $1,000 flight through your link; you make $200 instantly! And with Skyscanner’s 30-day cookie duration, you still earn if they book within a month after clicking your link.\\n\\nCreating Compelling Content: The AI-Assisted Approach\\n\\nCreating engaging content is key. Luckily, AI tools can help. For instance, Hostinger’s AI blog creation tool can churn out a complete article in under a minute. Just specify your tone, length, and topic, and it crafts content for you, even embedding your affiliate links strategically.\\n\\nOptimizing for Search Engines: The SEO Edge\\n\\nTo ensure your article ranks on Google, integrate specific keywords. Avoid generic ones; instead, focus on long-tail, low-competition keywords. Use tools like SEMrush’s Keyword Magic Tool to find keywords that are easier to rank for, boosting your article’s visibility and, in turn, your affiliate earnings.\\n\\nBuilding Your Affiliate Website: An AI-Powered Solution\\n\\nWith Hostinger, creating an AI-driven website is a breeze. Just input your brand name and a description, and it crafts a site for you in minutes. Remember, the more articles you add containing those strategic keywords, the more traffic and potential earnings you’ll see.\\n\\nConclusion: Your Path to Affiliate Marketing Success\\n\\nAffiliate marketing is an exciting journey, filled with learning and growth. By choosing the right niche, leveraging AI tools for content and website creation, and mastering SEO, you’re setting yourself up for success. So, dive in, experiment, and watch as your affiliate marketing efforts turn into a rewarding income stream. Don’t forget, every journey begins with a single step - start yours today and unlock the potential of affiliate marketing!\\n\\n\\n\\nWe strongly recommend that you check out our guide on how to take advantage of AI in today’s passive income economy.'}},\n",
       "  {'id': '262c355fdff1',\n",
       "   'title': '15 AI Tools That Will Make You Rich in 2024\\u200a—\\u200aGame Changer AI Tools in 2024!',\n",
       "   'subtitle': '15 Game-Changing AI Tools to Watch in 2024',\n",
       "   'author': '8a910484fe84',\n",
       "   'publication_id': '*Self-Published*',\n",
       "   'published_at': '2024-02-02 15:01:50',\n",
       "   'last_modified_at': '2024-02-02 15:01:50',\n",
       "   'tags': ['ai',\n",
       "    'ai-tools',\n",
       "    'artificial-intelligence',\n",
       "    'make-money-online',\n",
       "    'rich'],\n",
       "   'topics': ['artificial-intelligence'],\n",
       "   'claps': 56,\n",
       "   'voters': 7,\n",
       "   'word_count': 1184,\n",
       "   'responses_count': 0,\n",
       "   'reading_time': 4.85125786163522,\n",
       "   'url': 'https://medium.com/@moneytent/15-ai-tools-that-will-make-you-rich-in-2024-game-changer-ai-tools-in-2024-262c355fdff1',\n",
       "   'unique_slug': '15-ai-tools-that-will-make-you-rich-in-2024-game-changer-ai-tools-in-2024-262c355fdff1',\n",
       "   'image_url': 'https://miro.medium.com/1*7pH8oVdb0fyfQF7kOxU7Ew.png',\n",
       "   'lang': 'en',\n",
       "   'is_series': False,\n",
       "   'is_locked': False,\n",
       "   'is_shortform': False,\n",
       "   'top_highlight': '',\n",
       "   'content': {'id': '262c355fdff1',\n",
       "    'content': '15 AI Tools That Will Make You Rich in 2024 - Game Changer AI Tools in 2024!\\n\\n15 Game-Changing AI Tools to Watch in 2024\\n\\nEmbracing the AI Revolution\\n\\nHey there! It’s incredible how rapidly technology is advancing, especially in the world of Artificial Intelligence. The year 2023 was a remarkable period, but 2024 is shaping up to be even more thrilling. I want to share with you some groundbreaking AI tools that have caught my eye. They’re not just cool tech gimmicks; these tools have the potential to revolutionize how we work, create, and interact with digital content. So, let’s dive in and explore these fascinating innovations together!\\n\\nWe strongly recommend that you check out our guide on how to take advantage of AI in today’s passive income economy.\\n\\n\\n\\n1. Perplexity: The Chatbot with Cutting-Edge Data\\n\\nFirst up is Perplexity, a chatbot that’s making waves. It’s similar to ChatGPT but stands out with its access to the latest data. What’s great about Perplexity is its user-friendly interface. Right off the bat, without any login hassle, you can ask it anything. Whether you’re curious about the new president of the Netherlands or any other current topic, Perplexity delivers concise, up-to-date answers. Plus, it offers high-quality images alongside responses, which is a boon for content creators. And guess what? You can even upload PDFs for detailed insights. The cherry on top? It’s free for regular use!\\n\\n2. Newbert: Revolutionizing Music with AI\\n\\nNext, let’s groove to the beat of Newbert, an AI music generator and royalty-free music ecosystem. Imagine having the power to generate music tracks just by entering prompts or selecting genres, moods, and activities. From hip-hop to classical, Newbert’s got you covered. Set your track length, hit ‘generate,’ and voila - your personalized music track is ready. This tool is perfect for content creators looking for unique soundtracks for their videos or podcasts.\\n\\n3. Hey Gen: Transforming Text into Video\\n\\nHey Gen is a cloud-based text-to-video solution that’s perfect for marketers, educators, and content creators. This tool transforms text into high-quality videos using AI avatars. You can even swap faces to create your unique avatar. With its range of avatars, voices, and auto captions, Hey Genen makes video creation a breeze.\\n\\n4. Idiogram: Mastering Text in Images\\n\\nWhile AI image generators like Mid Journey have impressed us, Idiogram takes it a step further by excelling in integrating text into images. Whether it’s creating a New Year post or a custom logo design, Idiogram delivers top-notch text-based outputs. It’s a game-changer for designers and anyone looking to add that extra flair to their images.\\n\\n5. Soundful: AI Music Generation Redefined\\n\\nSoundful is another fantastic AI music generator. Its interface allows you to select genres, styles, and adjust parameters like BPM and key signature to create the perfect track. After generating a preview, you can download your custom track. It’s ideal for creators who need royalty-free music with a personal touch.\\n\\n6. Market Muse: Optimizing Content for SEO\\n\\nFor content creators focused on SEO, Market Muse is a godsend. This content optimization platform helps you craft high-quality, search engine optimized content. It’s packed with features like competitive content analysis, keyword research, and content planning. Market Muse is your go-to for enhancing search visibility and driving organic traffic.\\n\\n7. Pika 1.0: Next-Level Video Generation\\n\\nPika 1.0 is an innovative text-to-video and image-to-video generator. With its new web version, creating videos is more accessible than ever. You can set various parameters like aspect ratio, FPS, and even add negative prompts to refine your video. It’s a versatile tool for generating unique video content.\\n\\n8. Fleeky AI: Revolutionizing Video Content Creation\\n\\nFleeky AI specializes in converting text into videos with ultra-realistic voiceovers. It’s user-friendly and offers a vast selection of voices in multiple languages. Whether it’s for social media content or educational videos, Fleeky AI helps you create engaging and high-quality videos effortlessly.\\n\\n9. Exploring the World with AI-Generated Content\\n\\nLet me take you on a virtual tour of some of the world’s most beautiful places, like the Amalfi Coast in Italy, through the lens of these AI tools. It’s amazing how technology can bring the beauty of the world to our screens in such a vivid and engaging way.\\n\\n10. Muff AI: Monetize Your Voice with AI\\n\\nMuff AI is a remarkable text-to-speech platform that stands out for its ultra-realistic voiceovers. What’s unique is the opportunity to monetize your voice on platforms like YouTube. It offers a range of voice models, making it perfect for creating engaging audio content.\\n\\n11. Sunno AI: Custom Songs from Text Prompts\\n\\nSunno AI is where creativity meets technology. This tool allows you to create songs from text prompts. Whether you need a hip-hop track about the USA or any other theme, Sunno AI generates lyrics and compositions, complete with a cover photo. It’s a dream tool for aspiring musicians and content creators.\\n\\n12. Cap Cut: The Ultimate AI Video Editing Tool\\n\\nCap Cut is not just a video editor; it’s a hub of AI-powered tools. It offers features like script generation, automatic video creation, AI model for product images, and much more. This tool is perfect for creating high-quality, engaging content efficiently.\\n\\n13. Playday AI: Innovative AI Video Generator\\n\\nPlayday AI is an exciting new video generator tool. Its face swap feature sets it apart from other AI video tools. With Playday AI, you can create consistent character videos and deep fakes quickly and easily.\\n\\n14. SE Ai: Streamlining SEO-Optimized Content Creation\\n\\nSE Ai is an AI writing tool designed for creating SEO-optimized articles and blog posts. It supports 48 languages and integrates seamlessly with WordPress. Its features like NLP keyword generation and SEO settings make it invaluable for content creators focused on organic search rankings.\\n\\n15. Acool Deep Fake: Exploring the World of Deepfakes\\n\\nAcool is a hub of AI tools specializing in deep fakes. It allows you to swap faces in videos or images, creating realistic AI avatars. It’s a fascinating tool for exploring the capabilities and ethical considerations of deep fake technology.\\n\\nConclusion: The Future is Here\\n\\nThese 15 AI tools are just the tip of the iceberg in the AI revolution of 2024. The potential and possibilities they offer are astounding. As we embrace these innovations, let’s remember to use them responsibly and ethically. The future is not just a glimpse; it’s here, and it’s filled with exciting opportunities. Let’s harness these tools to create, innovate, and revolutionize the way we interact with technology.\\n\\nI hope this exploration of AI tools has been as exciting for you as it has been for me. If you’re as intrigued as I am, don’t hesitate to dive in and experiment with these tools. The future is now, and it’s ours to shape. Happy creating!\\n\\n\\n\\nWe strongly recommend that you check out our guide on how to take advantage of AI in today’s passive income economy.'}},\n",
       "  {'id': 'c27c2166efec',\n",
       "   'title': 'Building a Video Content Agency with AI (in 2024)',\n",
       "   'subtitle': 'How AI Can Revolutionize Content Creation for Your Business',\n",
       "   'author': '8a910484fe84',\n",
       "   'publication_id': '*Self-Published*',\n",
       "   'published_at': '2024-02-02 14:01:43',\n",
       "   'last_modified_at': '2024-02-02 14:01:43',\n",
       "   'tags': ['content-creation',\n",
       "    'ai',\n",
       "    'artificial-intelligence',\n",
       "    'video-marketing',\n",
       "    'ai-tools'],\n",
       "   'topics': ['artificial-intelligence', 'marketing'],\n",
       "   'claps': 2,\n",
       "   'voters': 2,\n",
       "   'word_count': 716,\n",
       "   'responses_count': 0,\n",
       "   'reading_time': 3.0852201257861633,\n",
       "   'url': 'https://medium.com/@moneytent/building-a-video-content-agency-with-ai-in-2024-c27c2166efec',\n",
       "   'unique_slug': 'building-a-video-content-agency-with-ai-in-2024-c27c2166efec',\n",
       "   'image_url': 'https://miro.medium.com/1*3DFy3Mv7EVTxdikDGXLgcQ.png',\n",
       "   'lang': 'en',\n",
       "   'is_series': False,\n",
       "   'is_locked': False,\n",
       "   'is_shortform': False,\n",
       "   'top_highlight': '',\n",
       "   'content': {'id': 'c27c2166efec',\n",
       "    'content': 'Building a Video Content Agency with AI (in 2024)\\n\\nHow AI Can Revolutionize Content Creation for Your Business\\n\\nEmbracing AI for Effective Content Repurposing\\n\\nHey there! I’m here to share some exciting insights on a topic I’m really passionate about - using AI to build a content repurposing agency. As a content creator, I understand the effort that goes into producing long-form content. The great news is, AI tools have made it more accessible and affordable to maximize the potential of the content we create.\\n\\nWe strongly recommend that you check out our guide on how to take advantage of AI in today’s passive income economy.\\n\\n\\n\\nUnderstanding AI Tools: A Closer Look at Munch AI\\n\\nFirst things first, understanding the AI tool you choose is crucial. Take Munch AI, for instance. It’s an intuitive and powerful tool, perfect not just for individual creators but also for agencies managing multiple clients. It helps you sift through hours of content to find and repurpose micro content effectively, thanks to its features like topic and keyword identification, and even provides SEO scores to gauge content ranking potential.\\n\\nIdentifying Your Core Audience\\n\\nKnowing your audience is key. In the realm of content repurposing, your primary targets are podcasters, YouTubers, live streamers, and webinar hosts. These are content-rich creators, often with a business-driven approach, making them ideal clients for an agency like ours. They are constantly looking for ways to amplify their reach through micro-content across various social media platforms.\\n\\nTailoring Content for Different Platforms\\n\\nUnderstanding the specific needs of each social media platform is critical. From Instagram Reels and YouTube Shorts to TikTok videos, each platform has its unique format, like vertical or landscape videos. However, it’s not just about what’s trending; it’s about what works best for your clients. Experimentation and real data are your best friends here.\\n\\nCrafting an Iterative Business Plan\\n\\nDon’t get bogged down by a rigid business plan. In the fast-paced world of AI and content creation, flexibility is your ally. Start with a clear understanding of the AI tools at your disposal, know your audience, and decide on the platforms you want to specialize in. Remember, starting small is okay - it’s about mastering what you know.\\n\\nBuilding a Specialized Team\\n\\nStarting an agency can begin as a solo journey, but as you grow, assembling a specialized team becomes essential. AI tools like Munch AI can streamline your production process, but as you scale up, you’ll need diverse talents and specialties to handle the increased workload and maintain quality.\\n\\nLeveraging AI for Streamlined Processes\\n\\nWith tools like Munch AI, repetitive tasks become more manageable, allowing you to focus on scaling your business. However, it’s important to document and understand every step of your process. Remember, AI assists but doesn’t replace the human touch, especially in quality control.\\n\\nPricing Strategies and Financial Growth\\n\\nPricing is a critical aspect of your business. It’s not just about being the cheapest or the most expensive. Do your market research and understand the value you offer. Your pricing should reflect the quality of your service, including additional offerings like social media copywriting and hashtag research.\\n\\nLegal and Compliance Considerations\\n\\nTransparency is key when using AI tools. Ensure your clients are aware of the AI tools you’re using and confirm they have the rights to the content they provide. It’s essential to have clear legal and compliance strategies to protect your business and maintain trust with your clients.\\n\\nFinal Thoughts: The Power of AI in Content Repurposing\\n\\nTo wrap up, the potential of AI in content repurposing is enormous. It’s an exciting time to build an agency in this space. AI tools like Munch AI are making it easier and more affordable to produce high-quality, engaging content. Remember, it’s about combining the efficiency of AI with the creativity and insight of human expertise to deliver the best results for your clients.\\n\\nSo, are you ready to take the plunge and transform your content creation process with AI? The journey is thrilling, and the potential is limitless. Let’s make the most of our content and drive our businesses forward with the power of AI!\\n\\n\\n\\nWe strongly recommend that you check out our guide on how to take advantage of AI in today’s passive income economy.'}}],\n",
       " '4beacba7dc8a': [{'id': '6ad21c4cfa99',\n",
       "   'title': 'Forget Prompt Engineering, ChatGPT Can Write Perfect Prompts for You',\n",
       "   'subtitle': 'I enabled ChatGPT to write optimal, research-based prompts so anyone can be an expert prompt engineer.',\n",
       "   'author': '4beacba7dc8a',\n",
       "   'publication_id': '*Self-Published*',\n",
       "   'published_at': '2024-01-13 20:28:42',\n",
       "   'last_modified_at': '2024-01-13 20:28:42',\n",
       "   'tags': ['chatgpt',\n",
       "    'artificial-intelligence',\n",
       "    'ai',\n",
       "    'prompt-engineering',\n",
       "    'openai'],\n",
       "   'topics': ['programming'],\n",
       "   'claps': 2425,\n",
       "   'voters': 436,\n",
       "   'word_count': 1432,\n",
       "   'responses_count': 28,\n",
       "   'reading_time': 6.10377358490566,\n",
       "   'url': 'https://medium.com/@jordan_gibbs/forget-prompt-engineering-chatgpt-can-write-perfect-prompts-for-you-6ad21c4cfa99',\n",
       "   'unique_slug': 'forget-prompt-engineering-chatgpt-can-write-perfect-prompts-for-you-6ad21c4cfa99',\n",
       "   'image_url': 'https://miro.medium.com/1*heKVq8v-TzkRBbrNuYsAMw.png',\n",
       "   'lang': 'en',\n",
       "   'is_series': False,\n",
       "   'is_locked': True,\n",
       "   'is_shortform': False,\n",
       "   'top_highlight': '1. Always use the COSTAR prompt framework:\\nContext (C): Provide essential background information or setting for the task. This helps the LLM understand the specific scenario or domain it is dealing with, leading to more relevant responses.\\nObjective (O): Clearly articulate the goal or purpose of the prompt. Specify what you want the LLM to accomplish, ensuring that its focus remains on achieving this particular aim.\\nStyle (S): Define the desired style of the response. This could range from imitating the writing style of a specific profession, like a scientist or journalist, to emulating the narrative tone of certain genres, such as formal reports or creative fiction.\\nTone (T): Determine the emotional or attitudinal coloring of the response. Whether it\\'s formal, casual, enthusiastic, or empathetic, setting the tone ensures the LLM\\'s response aligns with the intended sentiment.\\nAudience (A): Identify the target audience for whom the response is intended. Tailoring the content and complexity of the LLM\\'s response to suit the audience, such as experts, beginners, or a general readership, ensures better comprehension and engagement.\\nResponse Format (R): Specify the format in which you want the response. This could be a list, a structured report, a JSON object, a narrative, etc. Defining the format helps in generating responses that are suitable for your subsequent use, whether it be for analysis, presentation, or further processing.\\n2. Break down complex tasks into a sequence of simpler prompts in an interactive conversation. \\n3. Employ affirmative directives such as `do,\\' while steering clear of negative language like \\'don\\'t\\'. \\n4. Implement example-driven prompting (Use few-shot prompting). \\n5. Use following phrases: \"Your task is\" and \"You MUST\". \\n6. Always use leading words like writing \"think step by step\". \\n7. Assign a role to the model i.e. \"you are an expert ___\"\\n8. Repeat specific words or phrases multiple times within a prompt. \\n9. Try to induce Chain-of-thought (CoT) when possible, guiding the LLM to do dive in deeper to each step\\n10. Use output primers, which involve concluding your prompt with the beginning of the desired output. Utilize output primers by ending your prompt with the start of the anticipated response. \\n11. To write an essay /text /paragraph /article or any type of text that should be detailed: \"Write an ultra-detailed [essay/text /paragraph] for me on [topic] in detail by adding all the information necessary\".',\n",
       "   'content': {'id': '6ad21c4cfa99',\n",
       "    'content': 'Forget Prompt Engineering, ChatGPT Can Write Perfect Prompts for You\\n\\nI enabled ChatGPT to write optimal, research-based prompts so anyone can be an expert prompt engineer.\\n\\n\\n\\nI’ve been prompting for a long time now, and frankly, I’m tired. It’s annoying to think about word choice and structure when all I care about is the output. The iteration process of writing a great prompt is arduous and time consuming, so I figured it’s time for a change.\\n\\nI realized that all prompt engineering techniques are, by definition, language tasks. ChatGPT is a master of language; thus, why not make ChatGPT the prompt engineer?\\n\\nNow that ChatGPT has been widely used for over a year, there are many respected prompting techniques proven to increase the quality of output. I combined some of these techniques with my own learned strategies to create a GPT that turns you into an expert.\\n\\nHow the ChatGPT Prompt Engineer works\\n\\nTo make the ultimate prompt writer, I did some prompting (go figure). At a high level, this is the process I gave to GPT to turn it into a prompt wizard:\\n\\nDigest the user’s prompt\\n\\nAsk the user questions required to gather all the required information from them to adhere to the prompt rules (found below)\\n\\nAssess whether this prompt would benefit from being a multi-step prompt or a single prompt\\n\\nRewrite the prompt (or prompt chain) using the prompt rules\\n\\nAfter this process, we can inject the outputted prompt into a new instance of ChatGPT, and voila, we have an excellent optimized output.\\n\\nThe prompting rules\\n\\nAs I mentioned above, the prompt rules that I gave ChatGPT combine well-respected, research-based best practices and my own special sauce. Many of these rules are inspired by this incredible article by Sheila Teo.\\n\\nHere is the full list of prompt rules, so feel free to use them if you’re still interested in writing your own prompts!\\n\\n1. Always use the COSTAR prompt framework:\\nContext (C): Provide essential background information or setting for the task. This helps the LLM understand the specific scenario or domain it is dealing with, leading to more relevant responses.\\nObjective (O): Clearly articulate the goal or purpose of the prompt. Specify what you want the LLM to accomplish, ensuring that its focus remains on achieving this particular aim.\\nStyle (S): Define the desired style of the response. This could range from imitating the writing style of a specific profession, like a scientist or journalist, to emulating the narrative tone of certain genres, such as formal reports or creative fiction.\\nTone (T): Determine the emotional or attitudinal coloring of the response. Whether it’s formal, casual, enthusiastic, or empathetic, setting the tone ensures the LLM\\'s response aligns with the intended sentiment.\\nAudience (A): Identify the target audience for whom the response is intended. Tailoring the content and complexity of the LLM\\'s response to suit the audience, such as experts, beginners, or a general readership, ensures better comprehension and engagement.\\nResponse Format (R): Specify the format in which you want the response. This could be a list, a structured report, a JSON object, a narrative, etc. Defining the format helps in generating responses that are suitable for your subsequent use, whether it be for analysis, presentation, or further processing.\\n2. Break down complex tasks into a sequence of simpler prompts in an interactive conversation. \\n3. Employ affirmative directives such as `do,\\' while steering clear of negative language like \\'don\\'t\\'. \\n4. Implement example-driven prompting (Use few-shot prompting). \\n5. Use following phrases: \"Your task is\" and \"You MUST\". \\n6. Always use leading words like writing \"think step by step\". \\n7. Assign a role to the model i.e. \"you are an expert ___\"\\n8. Repeat specific words or phrases multiple times within a prompt. \\n9. Try to induce Chain-of-thought (CoT) when possible, guiding the LLM to do dive in deeper to each step\\n10. Use output primers, which involve concluding your prompt with the beginning of the desired output. Utilize output primers by ending your prompt with the start of the anticipated response. \\n11. To write an essay /text /paragraph /article or any type of text that should be detailed: \"Write an ultra-detailed [essay/text /paragraph] for me on [topic] in detail by adding all the information necessary\".  \\n\\nThe ChatGPT Prompt Engineer in action\\n\\nNow that we have shareable GPTs, I can share with you my own custom GPT prompt engineer, which follows this process.\\n\\nYou can find it here.\\n\\nIf you want to use this in your own instances of GPT, simply copy the guidelines and the prompt rules above and you can easily convert any of your ChatGPT conversations into a prompt engineering session.\\n\\nNow, I\\'ll show you how the process works. First, we need to think of something we want to prompt for. In this case, let’s try something that requires GPT to be a bit creative. Here is my starting idea; it will transform into a beautiful prompt before our eyes:\\n\\nI am a music reviewer, I want you to help me create my own unique grading scale for music.\\n\\nThis is the questioning stage, where it will ask for more required information to create a better prompt. As you can see, I answered the questions in my next message.\\n\\nNow, Prompt Wizard will rewrite my prompt for me:\\n\\n\\n\\nThis prompt is well-written and primed for a great result. The next step is to pass this prompt into a fresh chat:\\n\\n\\n\\nI couldn’t fit the entire response into a screenshot, but I thought it was good enough to share:\\n\\nChatGPT: Creating a unique and engaging grading scale for music reviews requires a blend of professional insight and quirky creativity. To make it stand out, let’s first list the key musical elements that will be evaluated, and then assign each a creative numerical system.\\n\\nKey Musical Elements:\\n\\nMelody & Harmony: How catchy, original, and harmonically rich the music is.\\n\\nRhythm & Tempo: The effectiveness of the beat, rhythm complexity, and tempo choices.\\n\\nLyrics & Storytelling: The depth, creativity, and impact of the lyrics.\\n\\nVocal Performance: Quality, range, and expression of the vocals.\\n\\nInstrumentation & Arrangement: The choice and use of instruments, and how well they’re arranged.\\n\\nProduction Quality: The quality of the audio production, mixing, and mastering.\\n\\nEmotional Impact & Atmosphere: The ability of the music to evoke emotions and create an atmosphere.\\n\\nInnovation & Creativity: How the piece stands out in terms of originality and creativity.\\n\\nGenre Execution: How well the piece represents and elevates its genre.\\n\\nAudience Engagement: The potential for the music to resonate with and engage its audience.\\n\\nUnique Numerical Grading System:\\n\\nMelody & Harmony: Scale of 1–5 \"Earworms\" 🎵\\n\\nRhythm & Tempo: 1–5 \"Heartbeats\" 💓\\n\\nLyrics & Storytelling: 1–5 \"Quills\" \\U0001fab6\\n\\nVocal Performance: 1–5 \"Golden Microphones\" 🎤\\n\\nInstrumentation & Arrangement: 1–5 \"Orchestral Bows\" 🎻\\n\\nProduction Quality: 1–5 \"Soundwaves\" 🔊\\n\\nEmotional Impact & Atmosphere: 1–5 \"Soul Sparks\" ✨\\n\\nInnovation & Creativity: 1–5 \"Muses\" 🎨\\n\\nGenre Execution: 1–5 \"Genre Gems\" 💎\\n\\nAudience Engagement: 1–5 \"Applause Signs\" 👏\\n\\nEach element will be graded on this scale, with the possibility of earning up to 5 in each category. The total score will be out of 50, but instead of a simple sum, the final score will be presented as a \"Musical Palette,\" a color-coded spectrum that visually represents the strengths and weaknesses of the album or track in a single glance.\\n\\nFor instance, a score might look like this:\\n\\nTotal Score: 38/50\\n\\nMusical Palette: A vibrant array of colors with dominant hues indicating strengths in \"Lyrics & Storytelling\" (Quills: 4/5) and \"Emotional Impact\" (Soul Sparks: 5/5), but a softer tone in \"Rhythm & Tempo\" (Heartbeats: 2/5).\\n\\nThis system not only quantifies the quality of the music but also provides a visually engaging and intuitive way to understand the review at a glance. The use of unique symbols and a color-coded final score adds a quirky touch, making the reviews stand out and appealing to a broad audience, from casual listeners to music aficionados.\\n\\nWhy you should use this system\\n\\nThere are so many reasons why this system will increase your ChatGPT productivity; here are just a few:\\n\\nThis system works for every type of prompt, for any type of request\\n\\nIt saves massive amounts of \"iteration time\" (i.e., when ChatGPT is super off-base and you desperately try to get it on the right track)\\n\\nIt forces you to give ChatGPT enough information (you answer the questions that GPT asks you)\\n\\nIt makes GPT more declarative and less suggestive (ChatGPT takes the reigns with more defined prompts and is more decisive)\\n\\nIt teaches you the best prompting practices\\n\\nI hope this helps you on your prompt engineering journey and saves you loads of time.\\n\\nThanks for reading!\\n\\n-Jordan'}},\n",
       "  {'id': '8088ec559681',\n",
       "   'title': 'How to *Not* Use ChatGPT',\n",
       "   'subtitle': 'Every single thing you absolutely shouldn’t use ChatGPT for (there’s a lot)',\n",
       "   'author': '4beacba7dc8a',\n",
       "   'publication_id': '*Self-Published*',\n",
       "   'published_at': '2024-01-20 22:58:19',\n",
       "   'last_modified_at': '2024-01-20 22:58:19',\n",
       "   'tags': ['chatgpt',\n",
       "    'artificial-intelligence',\n",
       "    'ai',\n",
       "    'technology',\n",
       "    'writing'],\n",
       "   'topics': ['design', 'programming'],\n",
       "   'claps': 663,\n",
       "   'voters': 94,\n",
       "   'word_count': 2760,\n",
       "   'responses_count': 11,\n",
       "   'reading_time': 12.01509433962264,\n",
       "   'url': 'https://medium.com/@jordan_gibbs/how-to-not-use-chatgpt-8088ec559681',\n",
       "   'unique_slug': 'how-to-not-use-chatgpt-8088ec559681',\n",
       "   'image_url': 'https://miro.medium.com/1*h5-lcbnZhj8qhodrkFjGkw.png',\n",
       "   'lang': 'en',\n",
       "   'is_series': False,\n",
       "   'is_locked': True,\n",
       "   'is_shortform': False,\n",
       "   'top_highlight': '',\n",
       "   'content': {'id': '8088ec559681',\n",
       "    'content': 'How to *Not* Use ChatGPT\\n\\nEvery single thing you absolutely shouldn’t use ChatGPT for (there’s a lot)\\n\\n\\n\\nIn March of 2023, I showed my dad ChatGPT for the first time. He knew a bit about it beforehand, but he hadn’t yet played with it himself. I plopped my laptop down on the kitchen table and logged in for him. I asked GPT a few questions at first to show him the ropes, and then I let him have a go. The first thing he asked was, \"Who is [the name of one of his good friends]?\"\\n\\nThis friend just so happens to have a unique name and a bit of a public profile, so ChatGPT responded, boldly telling us about said friend. As you may have guessed, it was completely and utterly wrong on nearly all accounts. It manufactured 90% lies around the 10% facts that it had, and my dad was shocked to see how inaccurate (yet persuasive) it was.\\n\\nNeedless to say, his confidence in Chat plummeted. I didn’t want this experience to taint his view of GPT forever, so I jumped in with a better use case. I said, \"ChatGPT is great for brainstorming; why don’t we try some of that?\"\\n\\nIn just a few minutes, I showed him Chat’s wonderful ability to generate ideas and jumpstart creativity. The rest is history. Today, my dad is a huge ChatGPT fan, and he uses it often to accentuate his work.\\n\\nMy point here is simple - ChatGPT is not a panacea. Many people get turned away from ChatGPT because they don’t know how to use it, and they begin to think it’s worthless and stupid. In this article, I articulate all the ways not to use Chat so you can be aware (and hopefully inform others) of its many pitfalls so you can focus on its best core abilities.\\n\\nThis article is a bit of a doozy, so here’s a quick outline:\\n\\nCommon mistakes I see ChatGPT users make\\n\\nThings ChatGPT is terrible at\\n\\nThings ChatGPT does really well\\n\\nLet’s get started.\\n\\nCommon mistakes I see ChatGPT users make\\n\\nExperts and novices alike, I have seen these mistakes time and time again. It’s imperative to use ChatGPT correctly because, at best, you’ll be sorely disappointed, and at worst, you’ll be completely misled.\\n\\nExpecting ChatGPT to be an expert\\n\\nMany people will see a few introductory messages with ChatGPT and automatically assume it’s some sort of genius. Oftentimes, initial interactions will go something like this:\\n\\n\\n\\nThe user will immediately think, \"Wow! ChatGPT really is smart…\" Then, of course, things will escalate until they’re asking GPT for legal, financial, or medical advice, and, despite Chat’s desperate attempts to avoid answering these queries, the user will inevitably be unknowingly served misinformation.\\n\\nChatGPT isn’t a true expert in anything. It’s great for surface-level exploration of certain topics, but in its current state, it won’t replace a human (for now).\\n\\nUsing ChatGPT for fact-checking\\n\\nChatGPT will so confidently lie to you that it’s almost unreal. The worst part is that its lies are insidious, and littered with half-truths that allure the user into belief. Here is a perfect example of what I mean:\\n\\n\\n\\nA quick Google search shows that there is no hippo (at least not one that is well-known) named Luangwa, let alone one that also happens to be the heaviest ever recorded. The eerie part is that the numbers here are right. The heaviest hippo known is called Mubarak, who weighed 9920 pounds. See what I mean? GPT is really sneaky. No wonder so many users fall into the trap of trusting it.\\n\\nExpecting ChatGPT to know obscure information\\n\\nChatGPT knows a lot about many things, but it can’t know everything. Here’s a great example of this in action:\\n\\n\\n\\nNotice how ChatGPT doesn’t ask me which bolt I am talking about specifically, which is a problem. It also doesn’t specify the actual thread type (it’s an M6) and is wrong about the length (it’s 20 mm).\\n\\nThis is a pretty overt example, but this holds true for many things. For example, I’ve been using an app-building framework called Streamlit to build lightweight apps. I used ChatGPT to help me many times, but when I started requesting anything deeper than the most surface-level help from it, it was completely useless. This is because most Streamlit documentation and online discourse isn’t necessarily in the training set, but there’s just enough to trick you into thinking it’s knowledgeable on it.\\n\\nThis is just like the Honda Accord example above; there simply isn’t enough available information in its training materials for it to confidently answer obscure requests, and this holds true for everything. It knows most broad tenets, but it can never quite see the trees among the forest.\\n\\nLearning things and not following up\\n\\nWhile this isn’t necessarily a fault of GPT itself, I think Chat inherently begets it. In my opinion, you should use ChatGPT as a knowledge prepper, not an all-knowing beacon of information. I have fallen into this trap before. Several months ago, when I was trying to learn more Python, I heavily relied on Chat to help me. After a few months of this, I felt pretty comfortable in Python, but then I realized something. When I sat down to code, I couldn’t even put the proverbial pen to paper. ChatGPT had become such a crutch to me when writing Python that I couldn’t even begin to write my own without its help. It’s as if I were a cheating student sitting down for the final exam with nothing in my head.\\n\\nAfter I had this realization, I decided to focus more on digesting and taking time to practice and implement the concepts I learned myself. This extra bit of effort has improved my skills by leaps and bounds. Moral of the story? If you’re learning with GPT, you must try to retain your newfound knowledge, or it will surely melt away.\\n\\nThings ChatGPT is terrible at\\n\\nNow that I’ve detailed some of my GPT use case pet peeves, below is a direct list of the things that ChatGPT is particularly bad at. Think of this as a PSA for future use.\\n\\nSpatial reasoning\\n\\nA few months ago, I tested ChatGPT’s ability to solve some classic LSAT logic problems and got some hilarious results. Here is an example of how ChatGPT can fully break down and analyze a very complex logical puzzle, only to arrive at a blatantly wrong answer:\\n\\n\\n\\nI’ve left out the middle part, but there were over 500 words of logical leaping done here by GPT…\\n\\n\\n\\nAfter a huge bout of thinking, it arrives at a very wrong answer of \"b\" when the correct answer is c. It’s quite persuasive, isn’t it?\\n\\nMathematical reasoning\\n\\nYes, ChatGPT may be really \"smart\" but that doesn’t mean it can do math. It’s in the name - Large Language Model. Luckily as of a few months ago, we got automating code writing and analysis, so now ChatGPT can write a code to do the math problem for it. Rule of thumb - you can ask ChatGPT to do math (if you have Pro), but you must ensure that this little analyzer symbol pops up, which indicates that it’s writing an executing code to solve the problem:\\n\\n\\n\\nThis will, of course, never be 100% correct, so take this tip with a grain of salt. However, if you don’t do this, you’ll end up with something that is likely going to be very, very wrong:\\n\\nThis was done with GPT 3.5, which does not write and execute code for you. It happens to be quite wrong (the right answer is C)\\n\\nTrue originality\\n\\nI’ve written an article about jumpstarting your creativity with ChatGPT, and as a preface, I’m not rescinding what I wrote there. But I will reiterate here that ChatGPT cobbles together ideas from its training set when it helps you brainstorm. You can’t expect it to generate the next best genre of music or a brand-new art style because it’s really hard to create something that’s more than the sum of its parts. Here is an example of what I mean:\\n\\n\\n\\nThe names generated here are, putting it nicely, hamfisted. They’re highly derivative, and it’d be a stretch to call them creative. However, it’s clear that this list is a great diving board to create some better ideas of my own.\\n\\nThis is also true of Dalle3, which can’t be entirely original either:\\n\\n\\n\\nWhile this image is visually interesting, it’s clear that it’s by no means original. Here, you can actually see the \"cobbling\" effect I’m talking about in a big way; it’s really just a blend of other styles.\\n\\nMaking ethical judgments\\n\\nI’ve seen enough \"ChatGPT does the trolley problem\" posts for a lifetime, and it’s clear to me how compromised its moral system can get. Of course, ChatGPT is so tightly guardrailed that it oftentimes can’t even provide an actual decision regarding moral dilemmas, but when it does, it’s often a bit off-base:\\n\\n\\n\\nClearly, GPT isn’t human and can’t understand the gravity of most ethical dilemmas. What it can do, however, is help us analyze these scenarios. Instead of asking ChatGPT what the \"right\" choice is, we should focus on letting it interpret and present solutions and pathways. Ideation is, after all, always safer than decision.\\n\\nUnderstanding complex systems\\n\\nChatGPT is great at doing highly specific and direct tasks. However, as soon as it has multiple tasks to handle at once, its effectiveness begins to break down. This is especially apparent when you request it to take a body of code and change several aspects of it. I’ve found if you request much more than five major changes at once, it will begin to \"forget\" the things that it committed to doing.\\n\\nOne way to remedy this is, of course, to force it to write an outline of its tasks first. If you ensure that it must write the code in a separate message from its outline, it’s often in a deeper semantic space that helps it to \"remember\" to implement your requests.\\n\\nNow, I’m using code as an example here, but this is also just as true for complex scenarios set up via natural language. For example, let’s say you have a character mapped out to a list of many traits. If you ask GPT to write a scene with this character, requiring it to adhere to the \"rules\" of the character, it will not do a great job. There will be glaring inconsistencies and the character’s integrity will break down, especially the farther into the writing it gets.\\n\\nA better way of getting results from GPT in this scenario would be to write a section of text with a very simple character and then ask GPT how you could alter the text to represent a small set of character traits within the context of the pre-written text. This helps it have a bigger picture, more high-level view of things. That’s the beauty of using ChatGPT; there’s always a workaround!\\n\\nNavigating ambiguous tasks\\n\\nMany people expect GPT to read their minds. GPT thrives on information, so the more you give it, the better it will be. Here’s a good example:\\n\\n\\n\\nIt’s doing a fine job of blog writing, but it really doesn’t know my intention at all. Likely, I won’t be happy with this output because it wasn’t what I imagined. This is why we must reduce ambiguity as much as possible to get the most out of GPT.\\n\\nOne of my previous articles gets to the bottom of this issue. The prompt in that article forces ChatGPT to ask you about information that it needs to better complete your request. This is a perfect way of getting Chat to gather more information before it starts rolling.\\n\\nNow I can really tell Chat what I need it to write, and its output will be infinitely closer to my intentions.\\n\\nGPT cannot infer without the proper information. In an effort to make its output sound the most intelligent and accurate, GPT will make assumptions. Another great example of this is a coding task that requires the use of some libraries. GPT will likely assume some specific libraries that the user wants to use, and it will completely change the entire form and scope of the code if it assumes incorrectly.\\n\\nIt’s bad at picking the \"right\" one because it has so many different pathways to choose at any given time. This is why I’ll reiterate it repeatedly: it’s imperative to force GPT to think step-by-step or at least outline its actions before it completes your request and to have it ask you for clarifying information.\\n\\nWhat ChatGPT does incredibly well\\n\\nNow that we’ve dove into the things that ChatGPT cannot do, I think it’s best to remind ourselves that ChatGPT isn’t entirely incompetent. Here’s a brief list of things it’s great at:\\n\\nPure language tasks\\n\\n\"Pure language tasks,\" in my opinion, are those that specifically relate to the manipulation and interpretation of human language. Here are a few examples:\\n\\nSummarization (non-technical) - One of my favorite use cases for GPT is its amazing ability to compress large amounts of information. However, I would stray away from technical summaries, as it can often misinterpret logical or spatial linkages.\\n\\nParaphrasing & re-voicing - It’s easy to ask ChatGPT to re-interpret, say, the Declaration of Independence in pirate speak, and it does a remarkably good job. It’s also great at rewriting and rephrasing content to have different wording while retaining the same core message.\\n\\nFinding synonyms - As I have mentioned before, ChatGPT is a master of semantic meaning and relationships. This means that it’s excellent at finding creative synonyms for words or phrases.\\n\\n\\n\\nWriting copy - Another great way to use GPT is feeding it a ton of information, say, about a brand and asking it to output some marketing copy that adheres to said brand. It’s a fast way to block out core messaging based on a set of guidelines. The best part is that this use case is very low stakes, and it’s easy to iterate.\\n\\nBrainstorming + ideation\\n\\nBy far, my favorite use case for ChatGPT is its incredible ability to create brainstorming sessions out of nothing. Even if 90% of the ideas are garbage or derivative, it’s amazing just how much it can jog your creative juices.\\n\\n\\n\\nOutlining & planning\\n\\nOftentimes, I will start a project (writing-based or otherwise) with a few ChatGPT-generated outlines. This process really crystallizes the idea’s vision in my head, and it just so happens that ChatGPT is really, really good at creating cascading, ordered sections that relate and build upon the original idea.\\n\\nEven if you don’t use every section of the outline, it’s a great way to increase your scope knowledge of the idea at hand so you can better pick and choose what to include and what not to. A great way I’ve found to improve writing is what I call progressive outline building. This is where you iterate on multiple detail levels of outline to create a highly detailed plan for the rest of the writing. Here’s an example:\\n\\n\\n\\nNow, let’s force GPT to expand the first point of part one:\\n\\n\\n\\nAs you can see, this has given us some serious detail in this outline. If we continued and did this for each subsequent section, we would quickly have thousands of words and immense detail so we could begin writing.\\n\\nClosing remarks\\n\\nI don’t want this article to seem like some huge GPT diss session, but I can see how it sounds that way. Don’t get me wrong, I think it’s some of the greatest technology I’ve ever used, but like anything, if you don’t fully understand it, you’re bound to misuse it.\\n\\nNow, I could probably expand this list even more than I already have, but for the sake of brevity, I’ll stop here. Here are the most important takeaways:\\n\\nUse ChatGPT for language tasks - Avoid numbers and spatial logic at all costs unless you force it to write code for you.\\n\\nAlways prioritize giving GPT as much information as possible - Information sets ChatGPT free, and there’s no substitute.\\n\\nNever take GPT’s outputs as gospel - Always double-check the important stuff! Ideation before decision, always.\\n\\nDon’t expect too much from GPT - Remember, it’s not a genius. If you set your sights too high, it will disappoint you. You still have to put in the work.\\n\\nI hope this list wasn’t too exhausting or overbearing! I hope you found these lessons useful and I hope I equipped you with the knowledge to articulate for yourself what GPT can and cannot do.\\n\\nThanks for reading.\\n\\n-Jordan'}},\n",
       "  {'id': '0991c54be605',\n",
       "   'title': 'How to Prompt ChatGPT to Teach You Anything',\n",
       "   'subtitle': 'I created a prompt chain that enables you to learn any complex concept from ChatGPT.',\n",
       "   'author': '4beacba7dc8a',\n",
       "   'publication_id': '*Self-Published*',\n",
       "   'published_at': '2023-11-25 04:09:32',\n",
       "   'last_modified_at': '2023-11-25 04:09:32',\n",
       "   'tags': ['artificial-intelligence',\n",
       "    'chatgpt',\n",
       "    'learning',\n",
       "    'reading',\n",
       "    'science'],\n",
       "   'topics': ['artificial-intelligence', 'programming'],\n",
       "   'claps': 1332,\n",
       "   'voters': 294,\n",
       "   'word_count': 913,\n",
       "   'responses_count': 21,\n",
       "   'reading_time': 4.645283018867924,\n",
       "   'url': 'https://medium.com/@jordan_gibbs/how-to-prompt-chatgpt-to-teach-you-anything-0991c54be605',\n",
       "   'unique_slug': 'how-to-prompt-chatgpt-to-teach-you-anything-0991c54be605',\n",
       "   'image_url': 'https://miro.medium.com/1*D5I02-bjuJur5wMWk2Z6ig.png',\n",
       "   'lang': 'en',\n",
       "   'is_series': False,\n",
       "   'is_locked': True,\n",
       "   'is_shortform': False,\n",
       "   'top_highlight': 'Provide an executive summary of this link [or attatched document]. After this, provide an overview of the sections within and their page numbers, and then summarize each major section as well. Always cite your sources.',\n",
       "   'content': {'id': '0991c54be605',\n",
       "    'content': 'How to Prompt ChatGPT to Teach You Anything\\n\\nI created a prompt chain that enables you to learn any complex concept from ChatGPT.\\n\\n\\n\\nHave you ever looked at a paper and just thought to yourself, \"This is way above my pay grade…\" Now, those days are gone. ChatGPT, with a little prompting expertise, can become your personal tutor for any high-level concept.\\n\\nI developed a prompt chain that takes an input document or webpage and guides the AI through the process of teaching you anything. This process causes ChatGPT to be more comprehensive, more accurate, and more responsive than a more traditional approach. Let’s jump right in!\\n\\nFind your learning material\\n\\nBefore you can start this process, find a document or webpage that contains a new concept or something that is tough to learn on your own. This can be old or new information; it doesn’t matter. In this case, I chose this paper from Anthropic AI about identifying LLM features via sparse autoencoders. Much of this paper is beyond my knowledge of AI, so I was happy to let ChatGPT help me out.\\n\\nInput your learning material\\n\\nOnce you have your material, download it as a PDF, or if it’s a webpage, copy the link. Click the paperclip icon on ChatGPT, or simply paste the link into the box.\\n\\n\\n\\nDon’t send this link or file yet; we need to include the first prompt with our first request.\\n\\nThe summarize + outline prompt\\n\\nInput \"Shift-Enter\" on your keyboard, and paste the first prompt into the input box. Here is the prompt (this works for any concept):\\n\\nProvide an executive summary of this link [or attatched document]. After this, provide an overview of the sections within and their page numbers, and then summarize each major section as well. Always cite your sources.\\n\\n\\n\\nPress enter, and you’re on your way.\\n\\n\\n\\nContinuing the learning prompt chain\\n\\nBefore you do anything else, input this prompt:\\n\\nUsing this summary, please generate a conceptual map based on the paper (no images) for me to learn from. make sure to output some foundational concepts, with descriptions, and then work your way into the tougher topics. Think of this as a lesson plan.\\n\\nThis prompt enables ChatGPT to think critically about the topics within and build a set of foundational topics that you must understand to understand the rest of the more complex ones within the paper. This is the most important step; it’ll jump-start your learning speed because you can skip the fluff and dive right into the important stuff.\\n\\n\\n\\nYou can clearly see how effective this is at splitting out the high-level concepts and paring them down into a digestible outline.\\n\\nHere’s where the learning really begins\\n\\nNow you can pick and choose what you want ChatGPT to teach you. In this example, I already understood AI language models fairly well. However, I needed a deep dive into Feature Extraction. So then I used this prompt:\\n\\nLet’s do a deep dive into the [your chosen section] of the lesson plan. Please output a detailed description of the concept based on the text. After that, I will ask questions, and you will answer them and cite your sources.\\n\\n\\n\\nNow you can begin a standard Q&A process with ChatGPT, and dive as deep into the concept as you like.\\n\\n\\n\\nPost Q&A learning\\n\\nNow, let’s say that you’ve gone down a Q&A track, and you’re in a good spot to understand that topic. You can now either ask the AI where you should read first to flesh out your knowledge, or you can move on to the other parts of your learning roadmap that the AI generated for you. Here is an example of asking it to cite places to read specifically:\\n\\nWhat sections of the text should I read to gather more info on [insert topic]?\\n\\nHere is the output:\\n\\n\\n\\nHere’s how you can continue down the lesson plan:\\n\\nLet’s do a deep dive into [the next section you want to learn] part of the lesson plan. Please output a detailed description of the concept based on the text. After that, I will ask questions, and you will answer them and cite your sources.\\n\\n\\n\\nFor a final prompt, this is a great one to get the AI to give you deeper information:\\n\\nNow that I have a decent understanding of [insert topic] can you dive deeper into the text and tell me more about it and it’s place in the text, and why it’s impactful towards the overall point of the paper? Please be highly detailed.\\n\\nFrom here, you can iterate through the rest of your lesson plan that ChatGPT gave you, and you can ask it questions along the way. I urge you to read the important sections of the material that it suggests yourself, because it’s risky to trust that the AI has not hallucinated. Luckily, now that you have some understanding of the topic, the reading will become much easier.\\n\\nThis strategy changed the way I learn\\n\\nReading a dense text after going through a learning session like this gives an incredible boost in terms of comprehension and retention. This strategy has changed the way I learn high-level concepts forever.\\n\\nI will be writing an article in the future about automating this process (with up to 20 documents at a time) via the Assistant API, so please let me know in the comments if you want to see this!\\n\\nThanks for reading.\\n\\n-Jordan'}},\n",
       "  {'id': '55ef2bdc4d4a',\n",
       "   'title': 'The Most Important ChatGPT Prompt',\n",
       "   'subtitle': 'I‘ve read dozens of articles about “the best ChatGPT prompts,” but I’ve never seen the most effective one…',\n",
       "   'author': '4beacba7dc8a',\n",
       "   'publication_id': '*Self-Published*',\n",
       "   'published_at': '2023-12-18 17:26:16',\n",
       "   'last_modified_at': '2023-12-18 17:26:16',\n",
       "   'tags': ['chatgpt',\n",
       "    'openai',\n",
       "    'ai',\n",
       "    'artificial-intelligence',\n",
       "    'prompt-engineering'],\n",
       "   'topics': ['programming'],\n",
       "   'claps': 3344,\n",
       "   'voters': 736,\n",
       "   'word_count': 763,\n",
       "   'responses_count': 48,\n",
       "   'reading_time': 3.829245283018868,\n",
       "   'url': 'https://medium.com/@jordan_gibbs/the-most-important-chatgpt-prompt-55ef2bdc4d4a',\n",
       "   'unique_slug': 'the-most-important-chatgpt-prompt-55ef2bdc4d4a',\n",
       "   'image_url': 'https://miro.medium.com/1*12v9CX7ENSplhj3upW9TkQ.png',\n",
       "   'lang': 'en',\n",
       "   'is_series': False,\n",
       "   'is_locked': True,\n",
       "   'is_shortform': False,\n",
       "   'top_highlight': '\"Before you start, please ask me any questions you have about this so I can give you more context. Be extremely comprehensive.\"',\n",
       "   'content': {'id': '55ef2bdc4d4a',\n",
       "    'content': 'The Most Important ChatGPT Prompt\\n\\nI‘ve read dozens of articles about \"the best ChatGPT prompts,\" but I’ve never seen the most effective one…\\n\\nChatGPT as \"The Thinker\" - Generated by Dalle-3\\n\\nWhen I first introduced my brother to the wonders of ChatGPT, it took him less than five minutes to say, \"This thing is dumb and useless.\"\\n\\nThis happened about eight months ago. I remember he asked GPT to write him a lab report from scratch, and I assured him it would do an excellent job. He put in the lab instructions, the report questions, and his experimental data.\\n\\nThe lab report output by ChatGPT, to put it nicely, was hot garbage. The report was riddled with loosely connected sections, rife with hallucinations, and packed with hamfisted data stuffing. The report was entirely unusable from the outset to the point where it wasn’t even worth prompting for another one.\\n\\nAt that moment, my brother immediately lost all faith in ChatGPT, and he went back to writing manually. I had to admit, I was disappointed in it as well.\\n\\nA contextual realization\\n\\nI reflected on this experience, and I wondered why it faired so poorly when I assured him it wouldn’t. I thought about all the times I had great success with GPT, and I suddenly had a realization. ChatGPT thrives on information.\\n\\nChatGPT is a master of semantics; it understands the deep interrelations between nearly all textual information. However, it has a huge flaw: it cannot accurately infer.\\n\\nChatGPT’s true purpose is to output text that imitates that of a real human, and it will go to great lengths to do that for you (including hallucinating falsehoods). Asking ChatGPT to output something, especially touchy and complex writing such as a lab report, without giving it enough information is a recipe for disaster.\\n\\nBut here’s the catch - how do you know when you’ve given it enough information? ChatGPT will almost always assume that it has the requisite information that it needs to complete your request, even if it doesn’t.\\n\\nHere lies the crux of my realization: only ChatGPT knows what it doesn’t know. So why not ask it?\\n\\nAsking the right questions\\n\\nWhat is the right question? - Generated by Dalle-3\\n\\nI realized that a single prompt was the answer to this problem (and infinitely many more problems like it). A single line tacked on to the end of nearly any request can make ChatGPT output more informed, denser, and more factual writing.\\n\\nThis article is beginning to feel like a recipe with someone’s excruciatingly over-detailed life story at the beginning, so I’ll get straight to the point:\\n\\nChatGPT knows what it doesn’t know. You don’t know what ChatGPT doesn’t know because it doesn’t tell you. We can cure this disconnect with one simple prompt:\\n\\n\"Before you start, please ask me any questions you have about this so I can give you more context. Be extremely comprehensive.\"\\n\\nWhy does this work?\\n\\nAs I said earlier, ChatGPT will output something that seems good, even if it doesn’t have the information it needs. So why not force it to gather info it doesn’t know from the only person who does?\\n\\nAfter using this prompt, ChatGPT will rattle off 10–15 insightful questions, asking you about information that you totally forgot that it needed. In your next prompt, simply list out the numbers of the questions and answer them sequentially.\\n\\nNow that it has all the information it needs, it can write a significantly more informed output, complete with infinitely less guesswork. You’ll be amazed at the quality jump.\\n\\nThe prompt in action\\n\\nHere is a side-by-side comparison of ChatGPT output, first without the prompt and then with:\\n\\nNot using the question prompt:\\n\\n\\n\\nSame prompt, new chat, now using the question prompt:\\n\\n\\n\\nI then answered these questions, and you can see just how much better the output was:\\n\\n\\n\\nWhile this is a pretty extreme example (I gave it almost no information from the outset), you can see just how incredible the output becomes in the second scenario (which was only the first outfit of three, by the way).\\n\\nI think this outfit is a winner - Generated by Dalle-3\\n\\nThe beauty of this prompt is that it works for almost any request you’ll ever have of ChatGPT. Writing a blog post? Give it more information via questions. Writing an abstract for your paper? Ask it to ask you questions about info not found in the paper. Need advice about a complex interpersonal issue with a friend? Use the question prompt.\\n\\nI don’t say this lightly - it’s a bit of a panacea. For the last eight months, I’ve been using it daily, and I hope you will, too.\\n\\nThanks for reading!\\n\\n-Jordan'}},\n",
       "  {'id': 'fbdcf256f6bc',\n",
       "   'title': 'Upskilling Yourself with AI will Change Your Life',\n",
       "   'subtitle': 'I’ll show you how to harness AI’s best use case with this simple framework.',\n",
       "   'author': '4beacba7dc8a',\n",
       "   'publication_id': '*Self-Published*',\n",
       "   'published_at': '2023-11-21 02:33:00',\n",
       "   'last_modified_at': '2023-11-21 02:33:00',\n",
       "   'tags': ['learning',\n",
       "    'personal-development',\n",
       "    'personal-growth',\n",
       "    'artificial-intelligence',\n",
       "    'chatgpt'],\n",
       "   'topics': ['artificial-intelligence', 'work', 'programming'],\n",
       "   'claps': 503,\n",
       "   'voters': 40,\n",
       "   'word_count': 1338,\n",
       "   'responses_count': 6,\n",
       "   'reading_time': 5.882389937106918,\n",
       "   'url': 'https://medium.com/@jordan_gibbs/upskilling-yourself-with-ai-will-change-your-life-fbdcf256f6bc',\n",
       "   'unique_slug': 'upskilling-yourself-with-ai-will-change-your-life-fbdcf256f6bc',\n",
       "   'image_url': 'https://miro.medium.com/1*Ep3iJro_D5eFYGgPBBH8Cw.png',\n",
       "   'lang': 'en',\n",
       "   'is_series': False,\n",
       "   'is_locked': True,\n",
       "   'is_shortform': False,\n",
       "   'top_highlight': \"I've developed a general framework that generalizes AI upskilling to any field. I have used this framework now for the past six months, and I can say with absolute certainty that it has changed my life for the better.\",\n",
       "   'content': {'id': 'fbdcf256f6bc',\n",
       "    'content': 'Upskilling Yourself with AI will Change Your Life\\n\\nI’ll show you how to harness AI’s best use case with this simple framework.\\n\\nI’ve developed a general framework that generalizes AI upskilling to any field. I have used this framework now for the past six months, and I can say with absolute certainty that it has changed my life for the better.\\n\\n\\n\\nIn the AI age, anyone can become anything.\\n\\nIf you have a subscription to ChatGPT, you have access to a coach who can teach you about anything at any time. We all have things we can learn about:\\n\\nNeed to learn the basics of Python?\\n\\nHave a tough situation to navigate at work?\\n\\nCan’t get your sourdough to prove correctly?\\n\\nIt doesn’t matter the subject, AI can help you with that.\\n\\nThis may seem obvious, especially if you’ve ever used ChatGPT. However, I believe in the power and effectiveness of the framework below, and I know it’ll serve you well.\\n\\nThe Generalized AI Upskilling Framework\\n\\n\\n\\nFollow this procedure to jumpstart your upskilling pathway. Beware, this isn’t some instant panacea for all of your shortcomings. You need to be willing to put in some concentrated effort! Let’s kick things off:\\n\\n1. Figure out where you’re falling short.\\n\\nTo start this process, you must desire to learn or improve at something. Think about your current skill set, and identify where you fall short. Are there any gaps in your abilities, such as a lack in a hobby or a career skill? Identify this and clearly define it in your brain.\\n\\nIf you’re unsure where to start, AI can also help you here. Type into ChatGPT your career, hobby, and life interests, and ask it where you can begin learning new things. You’ll be surprised how much there is to learn, and how, much you don’t know.\\n\\n2. Define what success means to you.\\n\\nIn order to know if you’ve achieved anything at the end of this process, you must have a goal or a concrete idea of what your success looks like. This could be as simple as \"I want to be able to code an app in Python for my new idea\" or \"I want to become a better and more comprehensive notetaker.\" Write this goal down somewhere, and reference it within this process. It doesn’t have to be strictly measurable, but I recommend attempting to ascribe a grading scale to it for your own self-reference.\\n\\nI’d recommend getting a benchmark of your current skill level and reaching to surpass that result by the end of the process. This can be on any aspect that you define, but the key is writing it down!\\n\\n3. Identify your unknown unknowns.\\n\\nIf you’re trying to learn a new skill or flesh out your skills in an area you’re familiar with, you’ll have some unknown unknowns. This means that there are things that don’t exist in the realm of your understanding. Begin your upskilling process by knowing what you don’t know.\\n\\nHelpful prompts to get you started:\\n\\nI want to start coding in Python, and I’m a complete beginner. What are the major knowledge building blocks of Python?\\n\\nHere’s another example:\\n\\nI’m having trouble writing effective emails. What are the building blocks of an excellent email?\\n\\n4. Begin upskilling with AI!\\n\\nNow that you know the nature of the beast you’re tackling, you must create a strategy to attack this problem. Ask the AI to create a \"lesson plan\" outline for you to reference, honing in on the parts that you’re struggling with. Here is an example:\\n\\nMe: I want to learn how to start my own pottery business. I know how to launch a business and the basic pottery making process, but I have very little experience or knowledge on how to acquire and use all the equipment required. Please create a learning outline with overarching points for me to tackle. Be very detailed, and cover all the realms of this subject so I can plan how to learn.\\n\\nThe above prompt is a helpful starting point, especially if you’ve already identified the skills or knowledge you lack. Here is GPT’s response:\\n\\n\\n\\nPick and choose the aspects of this outline that you want to focus on. Write them down in a safe place for reference later. Now that you have your learning outline, you can work with the AI to build out conversations for each bullet.\\n\\nI recommend starting a new chat session for each bullet to really get the AI focused on one subject.\\n\\nHere is a general prompt template you can use for the intro to each of these sessions:\\n\\nI am learning [overarching subject], and I need your help with one aspect. I need to learn the ins and outs of [specific aspect of subject], and I want you to walk me through the things I need to know. Please be very detailed and use many examples to enable me to understand exactly what I need.\\n\\nFor example:\\n\\n\\n\\nYou can really go down a rabbit hole with each subject matter. You don’t have to worry about getting too specific because the scope here is very limited. Your sessions will be split, so you can glance at your sidebar and reference a certain subject at any time if you need more information.\\n\\nAbove all, write down the big lessons. There is no point in doing this if you don’t record your learnings and act on them.\\n\\n5. Verify + fact check AI’s output.\\n\\nAI isn’t perfect. It will be wrong on certain things. This is why, if you’re unsure of something or if it sounds fantastical, do some internet searching yourself about the subject. Get your own view of the matter from multiple sources. With the new browsing feature in ChatGPT, you can also simply ask the AI to cite a source when asking about a particularly crucial aspect of your learning.\\n\\n6. Backfill your knowledge through experience.\\n\\n\\n\\n95% of your learning happens in this step. This is where the real actionable work begins! Experiential learning is the best teacher.\\n\\nI use the word \"backfill\" here because I think it’s an apt descriptor. I’ll use my own personal example of my journey with Python. Before ChatGPT, I was not comfortable with my Python skills. I spent 90% of my time coding and sifting through StackOverflow to find the answers to my questions. I was so slow, and there were certain things that I couldn’t even figure out how to do.\\n\\nChatGPT helped me elevate my knowledge to a whole new level, especially using my framework. I now had a genius companion that I could use as a backboard for all of my Python learning. \"Hey, does this code look optimal to you? If not, please help me fix it.\" Another one I often used was, \"I can’t figure out this problem. Present 3 viable solutions in code.\"\\n\\nI went from a Python novice to feeling very comfortable with it in just 3 months. I could now build all of the things that I dreamed of building, and it was all thanks to AI. Coding is a foundational skill that builds up to others, and I am currently on a journey learning about machine learning, databases, and much more. Now I feel confident that if I want to learn about something, no matter how complex, AI can give me a commanding start with it.\\n\\nMy point here is simple. If you don’t get out there and follow your learning plan, it’ll just sit on your computer, and you’ll forget about it. AI is just an impetus; it can’t do the work for you.\\n\\n7. Measure your success!\\n\\nFinally, in order to prove to yourself that you’ve grown, you need to reflect. Using the success metric that you predefined, take a look at where you’ve come from. Chances are, you’ll be pretty happy with the result. You’ve reached a conclusion, and you can make the final judgment call: \"Should I keep learning?\"\\n\\nI say yes.\\n\\nThanks for reading!\\n\\n-Jordan'}},\n",
       "  {'id': 'd952c5716930',\n",
       "   'title': 'The Top 100 Self-Help Books in One: ChatGPT’s Master Lessons',\n",
       "   'subtitle': 'All self-help books share the same DNA, so I extracted the most common core principles with ChatGPT.',\n",
       "   'author': '4beacba7dc8a',\n",
       "   'publication_id': '*Self-Published*',\n",
       "   'published_at': '2024-02-04 20:10:06',\n",
       "   'last_modified_at': '2024-02-04 20:10:06',\n",
       "   'tags': ['chatgpt',\n",
       "    'ai',\n",
       "    'reading',\n",
       "    'self-improvement',\n",
       "    'artificial-intelligence'],\n",
       "   'topics': ['books', 'self'],\n",
       "   'claps': 629,\n",
       "   'voters': 51,\n",
       "   'word_count': 1112,\n",
       "   'responses_count': 5,\n",
       "   'reading_time': 4.746226415094339,\n",
       "   'url': 'https://medium.com/@jordan_gibbs/the-top-100-self-help-books-in-one-chatgpts-master-lessons-d952c5716930',\n",
       "   'unique_slug': 'the-top-100-self-help-books-in-one-chatgpts-master-lessons-d952c5716930',\n",
       "   'image_url': 'https://miro.medium.com/1*nSeg0aeWBOHDYFb4UteGTA.png',\n",
       "   'lang': 'en',\n",
       "   'is_series': False,\n",
       "   'is_locked': True,\n",
       "   'is_shortform': False,\n",
       "   'top_highlight': '',\n",
       "   'content': {'id': 'd952c5716930',\n",
       "    'content': 'The Top 100 Self-Help Books in One: ChatGPT’s Master Lessons\\n\\nAll self-help books share the same DNA, so I extracted the most common core principles with ChatGPT.\\n\\n\\n\\nWhenever I read a self-improvement book, I always have a similar thought: \"This shares a lot of the same lessons as the other books I’ve read…\" I’ve always found this annoying, so I decided to do something about it.\\n\\nAs I do, I thought about how AI could help in this scenario. In this case, I had the idea to compress the knowledge and lessons contained in the top self-help books into a concise list of the most commonly overlapping content. So I did just that.\\n\\nThe knowledge compression process\\n\\nI fed this entire article, the top 100 self-help books of all time (ranked by the number of experts who recommend them), into GPT-4. I asked it to extract the titles and authors.\\n\\nI split each book into a separate GPT call and asked it to generate an ultra-detailed summary of the main points of each book.\\n\\nI fed all of these summaries (titles not included to not \"poison\" the data) into a single GPT call. I asked it to compress everything into the 30 most commonly occurring and important life lessons.\\n\\nIf you follow these tenets closely throughout your life, I’d imagine it’d be deeply fulfilling. It’s quite interesting reading through it, as each lesson is familiar and relatable, and they serve as a reminder of what’s really important.\\n\\nThe nice thing about this list is that there’s no convolution; it’s just pure, actionable content. Without further ado, here’s the list:\\n\\nChatGPT’s 30 Prime Life Lessons\\n\\n1. Embrace Challenges and Persistence: Many of these books emphasize the importance of facing challenges head-on and persisting through difficulties. Whether it’s pushing past perceived limits, overcoming failures, or navigating obstacles, persistence is key to achieving success and personal growth.\\n\\n2. The Power of Mindset: A recurring theme is the significance of mindset in shaping our experiences and outcomes. Cultivating a positive, growth-oriented mindset can transform challenges into opportunities and foster resilience.\\n\\n3. Value of Self-Awareness and Reflection: Self-awareness is crucial for personal development. Understanding oneself, including strengths, weaknesses, and behavioral patterns, allows for more intentional actions and decisions.\\n\\n4. Importance of Habits and Consistency: Building positive habits and maintaining consistency in actions lead to significant long-term results. Small, daily actions compound over time, creating substantial change.\\n\\n5. Effective Communication and Listening: Many books highlight the importance of clear communication and active listening, especially in difficult conversations or when building relationships. Understanding and being understood are fundamental to successful interactions.\\n\\n6. Setting and Prioritizing Goals: Identifying clear, actionable goals and prioritizing them based on personal values and long-term visions are essential steps towards achieving success and fulfillment.\\n\\n7. Financial Discipline and Management: Key lessons include living below one’s means, avoiding debt, saving diligently, and investing wisely. Financial independence requires discipline, strategic planning, and an understanding of personal finance.\\n\\n8. The Significance of Empathy and Understanding Others: Developing empathy and striving to understand others’ perspectives are crucial for building strong relationships, effective leadership, and fostering collaboration.\\n\\n9. Adaptability and Embracing Change: The ability to adapt to changing circumstances and embrace change is highlighted as a critical skill for navigating life and work successfully.\\n\\n10. The Role of Failure in Growth: Failure is not to be feared but embraced as a valuable learning experience. It’s through failures that individuals grow, learn, and ultimately succeed.\\n\\n11. Taking Personal Responsibility: Accountability for one’s actions, decisions, and life circumstances is a common thread. Taking responsibility empowers individuals to make positive changes.\\n\\n12. The Power of Positive Thinking and Optimism: Cultivating a positive outlook and optimism can significantly impact one’s emotional well-being, resilience, and overall success.\\n\\n13. The Importance of Action Over Inaction: Taking initiative and acting towards goals is emphasized over waiting for the perfect moment. Progress often requires taking the first step, even without certainty.\\n\\n14. Leveraging the Strengths of Teamwork: Collaborating effectively with others and leveraging collective strengths lead to greater achievements than working alone.\\n\\n15. Mindfulness and Living in the Present: Many books promote mindfulness and the value of living in the present moment as keys to happiness and reduced stress.\\n\\n\\n\\n16. Self-Care and Physical Health: Prioritizing self-care, including physical health, mental health, and emotional well-being, is crucial for sustaining long-term success and happiness.\\n\\n17. Learning from Others and Seeking Mentorship: Gaining insights from others’ experiences, seeking mentorship, and being open to feedback accelerate personal and professional growth.\\n\\n18. Cultivating Gratitude: Practicing gratitude and focusing on the positive aspects of life enhance happiness and overall life satisfaction.\\n\\n19. Breaking Free from Societal Expectations: Many authors encourage readers to define their own paths to success and happiness, rather than conforming to societal norms and expectations.\\n\\n20. Generosity and Giving Back: The act of giving, whether through time, resources, or support, is not only beneficial to others but also enriches the giver’s life.\\n\\n21. Navigating Work-Life Balance: Finding a balance between professional ambitions and personal life is essential for overall well-being and fulfillment.\\n\\n22. The Role of Curiosity and Lifelong Learning: Cultivating curiosity and committing to lifelong learning are fundamental for personal development and staying adaptable.\\n\\n23. Strategic Risk-Taking: Calculated risks are often necessary for growth and achievement. Embracing uncertainty can lead to significant rewards.\\n\\n24. The Importance of Authenticity: Being true to oneself and acting in alignment with one’s values are critical for genuine satisfaction and success.\\n\\n25. Building and Maintaining Trust: Trust is a foundational element in all relationships, and its development and maintenance are vital for effective leadership and collaboration.\\n\\n26. The Power of Visualization and Goal Setting: Visualizing success and setting specific, measurable goals are effective strategies for achieving desired outcomes.\\n\\n27. Seeking Fulfillment Beyond Material Success: True fulfillment often comes from experiences, relationships, and personal growth, rather than material wealth or status.\\n\\n28. The Value of Legacy and Impact: Considering the legacy one wishes to leave encourages actions and decisions that have a positive, lasting impact on others.\\n\\n29. Embracing Vulnerability: Vulnerability is not a weakness but a strength that fosters connection, creativity, and personal growth.\\n\\n30. The Necessity of Boundaries: Setting healthy boundaries in personal and professional life is crucial for maintaining well-being and effective relationships.\\n\\n\\n\\nThat’s all folks\\n\\nWhew. That’s a lot at once. I’d be willing to bet that if you take five of these lessons that resonate most with you and follow them your whole life, you’d end up alright.\\n\\nI hope this list sparked some introspection!\\n\\nThanks for reading.\\n\\n-Jordan'}},\n",
       "  {'id': '0765f71dee3e',\n",
       "   'title': 'The Art of Asking the Right Question',\n",
       "   'subtitle': 'All of our problems are solvable\\u200a—\\u200aif we could only ask the right questions.',\n",
       "   'author': '4beacba7dc8a',\n",
       "   'publication_id': '*Self-Published*',\n",
       "   'published_at': '2024-02-01 18:19:13',\n",
       "   'last_modified_at': '2024-02-01 18:19:13',\n",
       "   'tags': ['problem-solving',\n",
       "    'questions',\n",
       "    'productivity',\n",
       "    'inspiration',\n",
       "    'self-improvement'],\n",
       "   'topics': ['psychology', 'self'],\n",
       "   'claps': 134,\n",
       "   'voters': 14,\n",
       "   'word_count': 1698,\n",
       "   'responses_count': 2,\n",
       "   'reading_time': 6.9575471698113205,\n",
       "   'url': 'https://medium.com/@jordan_gibbs/the-art-of-asking-the-right-question-0765f71dee3e',\n",
       "   'unique_slug': 'the-art-of-asking-the-right-question-0765f71dee3e',\n",
       "   'image_url': 'https://miro.medium.com/1*VTM9PjtwBhMT7xvytE_Lew.png',\n",
       "   'lang': 'en',\n",
       "   'is_series': False,\n",
       "   'is_locked': True,\n",
       "   'is_shortform': False,\n",
       "   'top_highlight': '\"If I had an hour to solve a problem and my life depended on the solution, I would spend the first 55 minutes determining the proper question to ask... for once I know the proper question, I could solve the problem in less than five minutes.\"',\n",
       "   'content': {'id': '0765f71dee3e',\n",
       "    'content': 'The Art of Asking the Right Question\\n\\nAll of our problems are solvable - if we could only ask the right questions.\\n\\n\\n\\nThink for a moment about a problem you’ve solved. Now, consider the genesis of its solution. Where did it come from? How did you arrive at it? What was your process?\\n\\nImagine this, and hold it in your head for a moment. Now I ask you this - is there any point in this process where you asked yourself a question? I’m willing to bet there is. I have a hunch it was important to your end solution. My hypothesis? This question was the core impetus of your end solution. Questions are at the heart of good problem-solving.\\n\\nIf you cannot find the right question to ask, you won’t arrive at the right solution. Albert Einstein once said:\\n\\n\"If I had an hour to solve a problem and my life depended on the solution, I would spend the first 55 minutes determining the proper question to ask… for once I know the proper question, I could solve the problem in less than five minutes.\"\\n\\nEinstein’s career originated from the pursuit of an answer. He had to start with a question, a so-called \"beautiful question\":\\n\\n\"What if I rode a light beam across the universe?\"\\n\\nHis answer to this grand question? Relativity.\\n\\nOne of the most important scientific theories in human history, and it’s all traced back to one simple, beautiful question.\\n\\nHow can we ask beautiful questions?\\n\\nAre you asking the right questions?\\n\\nThere’s something for you to ponder. Hopefully, you’re now thinking about your thought process and meta-analyzing it.\\n\\nIf you answered yes, then you\\'ve probably thought about this before. If not, you might be wondering what the \"right\" questions are and how you can ask them.\\n\\nHow can you ask the right questions?\\n\\nIt’s tough to know when you’ve arrived at the right question to ask. In fact, it can be nearly impossible to know where to begin. I realized this was a problem, and I did some thinking. The question I asked myself to begin solving this issue was,\\n\\n\"What if there was a general framework to brainstorm question ideation, and accelerate problem solving?\"\\n\\nIn this case, the question itself is a synecdoche. In asking it, I had answered it - with a little more thinking, of course. After some time, I developed a framework for question generation that I believe ignites better question-asking. I call it the Big Three Question Archetypes.\\n\\nThe Big Three Question Archetypes\\n\\nA question seedling, soon to be a question tree (with enough care)\\n\\nEach archetype is a question category that envelops a whole class of questions, a general force, with each one causing a different thought process to occur. With each archetype, I’ve included a brief description, a \"question ember\" (a jumping board, if you will), and an example usage to help elicit your own questions.\\n\\nFor each of the three archetypes, I present a high-level \"question ember,\" which is a good jumping-off point for asking the right questions. From this ember, you can begin your question tunneling process (more on this later).\\n\\nAfter I have presented the Big Three, I will walk you through the process of using them. Let’s begin!\\n\\nArchetype 1: The Perspective Shifts\\n\\nThese questions require a shift in mindset, inviting you to walk in a pair of shoes yet untrodden. These questions are especially useful for solving the following types of problems:\\n\\nInterpersonal problems (empathy, anyone?)\\n\\nSpatial problems (physical space, time-space)\\n\\nCircumstantial problems (mismatched causes and effects, unexplainable events, etc.)\\n\\nPerspective Shift Question Ember:\\n\\nWhich point of view is most useful to understand?\\n\\nAfter you ask yourself this question, it’s easy to start asking more:\\n\\nIf I were this person/that thing/somewhere else in this situation, what would I have felt/seen/heard/experienced?\\n\\nDo I have all the information needed to simulate this new perspective in my mind?\\n\\nWhat is the most crucial thing to know to inform my new perspective?\\n\\nNow that you’ve begun questioning, let the rest of the flow in a stream of consciousness. Eventually, the right question will appear. You’ll feel it hit you, and it’ll likely be answered before you even ask it.\\n\\nArchetype 2: The Big \"Ifs\"\\n\\nThese ones are especially easy, and it’s fun to really think outside the box here. These questions often lead to a \"trial and error\" thought pattern. \"Big Ifs\" are especially good for the following:\\n\\n\"Uncertain future\" problems\\n\\nDecision fork problems (i.e., you have two choices, which one is best?)\\n\\nRoot cause uncertainty problems (why does X thing happen?)\\n\\nThe Big If Question Ember:\\n\\nIf things were different, what would happen?\\n\\nMore Big If questions to ask:\\n\\nIf things were different, which difference would have the most appreciable outcome in the long term? In the short term?\\n\\nIf I did this now, what would I feel/see/experience in the short term?\\n\\nIf I did this set of experiments, would I have enough information to figure out the root cause?\\n\\nThe \"Ifs\" are so fun because you get to use your imagination. Don’t be afraid to flex your brain; it’s good for you.\\n\\nArchetype 3: The Why Seekers\\n\\nThese questions might be the most broadly applicable, but they are also the hardest to get right. These are great for digging deep, but often, I find it’s easy to start here and switch to one of the other archetypes mid-way through your question chain. Why Seekers are good for the following:\\n\\nIntrospection (why questions are the best for self-reflection)\\n\\nUncertain \"what\" or \"how\" (before you can figure out your next action, it’s important to understand the \"why\" behind it)\\n\\nUnknown unknowns (things that you don’t know you don’t know yet)\\n\\nThe Why Seeker Question Ember:\\n\\nWhy does this happen?\\n\\nMore Why Seeker questions to ask:\\n\\nWhy did I react in that way to that scenario?\\n\\nWhy is this person/organization/thing behaving in this way?\\n\\nWhy do I do what I do?\\n\\nWhy don’t I feel that I understand this scenario?\\n\\nLike I said, \"whys\" are the toughest. If you’re uncomfortable with this realm, switch to one of the previous archetypes and try those first.\\n\\nHow to use the Big Three Archetypes\\n\\nNow that I’ve presented the Big Three, I’ll show you how I use them. For me, these three archetypes are starting points for further questioning, a process I call question tunneling. In fact, you probably utilize this thought process every day without realizing it. Knowing and understanding this process forces you to think about your questions and answers, causing higher-quality thinking.\\n\\nThis process is best shown with a simple example: Let’s say you’ve lost your keys.\\n\\nLost keys - one of life’s grand conundrums\\n\\nTo start solving this problem, you could:\\n\\nA: Start frantically looking for them\\nB: Pause and start asking questions\\nC: Curl up into a ball and give up\\n\\nLet’s try out option B.\\n\\nStep 1: Choose a starting point and start tunneling\\n\\nChoose one of the three Archetypes to get started. For this example, let’s try Archetype 3: The Why Seekers. Once we have our first question, it’s easy to start rapid-firing off questions, forming a useful and actionable question tunnel.\\n\\nQuestion 1: \"Why are my keys gone?\"\\n\\nThis isn’t the right question, but we’re just beginning.\\n\\nQuestion 2: \"Why would my keys not be where they normally are?\"\\n\\nGetting closer…\\n\\nQuestion 3: \"Why would I break my routine and not put my keys where they should go?\"\\n\\nHmm, that’s a thinker.\\n\\nStep 2: Begin iterating between solving thoughts and questions\\n\\nNow, we can start trying to solve our problem as long as we remember to be vigilant about asking more questions.\\n\\nSolving Thought 1: \"Last night, I got home late. I did a few things and went straight to bed.\"\\n\\nForce yourself to ask another question.\\n\\nQuestion 4: \"What was I feeling that would cause me to break my normal routine?\"\\n\\nGetting there… think again.\\n\\nSolving Thought 2: \"I remember I was super dehydrated, and all I could think of was drinking some water.\"\\n\\nThings are heating up now. Another question.\\n\\nQuestion 5: \"What does the process of getting water entail?\"\\n\\nYes!\\n\\nThe Right Question: \"Where would my keys be during the process of getting water?\"\\n\\nWe’ve got it. Now to solve…\\n\\nSolving Thought 3: \"My keys were in my hands to unlock the front door. My water pitcher is in the fridge. I went straight from the door to the water pitcher. My keys were likely in my hands the whole time.\"\\n\\nWait, could this really be?\\n\\nPotential Solution 1: \"I left my keys in the fridge.\"\\n\\nCheck your solution; you may just be right.\\n\\nSolved State: My keys were in the fridge (yes, this has actually happened to me; the best examples are rooted in reality).\\n\\nThroughout this example, you’ve probably been thinking:\\n\\n\"This is what I already do when I have a problem, and it happens a lot quicker when I just let my instincts take over. This process is overly arduous, and it sucks.\"\\n\\nHowever, you must remember one thing… this is a general framework. This means that it works for all cases, both the mundane and the complex.\\n\\nNext time you face a deep, multifaceted, complicated problem, I urge you to try this framework out. Force yourself to follow the question pathways, and several things will happen:\\n\\nYou’ll waste less time on \"overthinking\"\\n\\nYou’ll find the root cause faster\\n\\nYou’ll solve the problem sooner\\n\\nYou’ll solve the problem with a higher-quality solution\\n\\nNotice your friend seems upset by something you said? Break it down.\\n\\nCan’t figure out why your colleagues aren’t responding to your emails? Question tunnel.\\n\\nYour company strategy is unsound? Dissolve it into its bare components through questioning.\\n\\nMaking a conscious decision to use this framework will help you take a more deliberate approach to problem-solving. Even if you don’t use the Big Three directly and you use your own special sauce, that’s perfectly fine.\\n\\nThe key benefit here is simple:\\n\\nWhen you use a questioning framework, you force self-awareness about your questioning and problem-solving process.\\n\\nA little self-awareness is all you need to improve, and it’s never too late to start asking questions.\\n\\nThanks for reading.\\n\\n-Jordan'}},\n",
       "  {'id': 'fb3f7e0d9deb',\n",
       "   'title': 'Read 1000 Books per Year with ChatGPT',\n",
       "   'subtitle': 'Supercharge your reading volume, comprehension, and retention with ChatGPT-assisted reading',\n",
       "   'author': '4beacba7dc8a',\n",
       "   'publication_id': '*Self-Published*',\n",
       "   'published_at': '2024-01-03 03:39:02',\n",
       "   'last_modified_at': '2024-01-03 03:39:02',\n",
       "   'tags': ['chatgpt', 'ai', 'artificial-intelligence', 'reading', 'learning'],\n",
       "   'topics': ['productivity'],\n",
       "   'claps': 1757,\n",
       "   'voters': 293,\n",
       "   'word_count': 1126,\n",
       "   'responses_count': 33,\n",
       "   'reading_time': 5.1990566037735855,\n",
       "   'url': 'https://medium.com/@jordan_gibbs/read-1000-books-per-year-with-chatgpt-fb3f7e0d9deb',\n",
       "   'unique_slug': 'read-1000-books-per-year-with-chatgpt-fb3f7e0d9deb',\n",
       "   'image_url': 'https://miro.medium.com/1*IsLL1ZnRVJ0fkoysWFx5Uw.png',\n",
       "   'lang': 'en',\n",
       "   'is_series': False,\n",
       "   'is_locked': True,\n",
       "   'is_shortform': False,\n",
       "   'top_highlight': 'Write an ultra-detailed summary about [Insert Book Title].',\n",
       "   'content': {'id': 'fb3f7e0d9deb',\n",
       "    'content': 'Read 1000 Books per Year with ChatGPT\\n\\nSupercharge your reading volume, comprehension, and retention with ChatGPT-assisted reading\\n\\n\\n\\nI’ve been experimenting with highly actionable ways to use ChatGPT, and I recently stumbled upon this gem of a workflow. This set of prompts allows you to \"read\" books in 1/100th of the time it takes to read them with a concept I call tailored conversational summarization. I’m super excited to share it with you all!\\n\\nNote: this strategy is not for traditional readers; it is designed for learning freaks like me. Don’t expect to replace fully reading a book; this is for conceptual capture only.\\n\\nReading books - what do you really get out of it?\\n\\nI’ve always been intrigued by the idea of reading books and how it relates to memory. A week after reading a great book, I can give a pretty accurate retelling of major points, themes, and learnings. A year out, and I’m reduced to a few interesting facts and anecdotes. A decade, and, well… probably nil. While the information builds on itself over time and over many books, it’s likely you’ll forget 99% of what you read.\\n\\nThis is why I propose that reading books (non-fiction) for major points and concepts is by far the most efficient way of digesting book information and getting value out of them. With the following prompt chain, I posit that reading and retaining information from >1000 books per year is possible. But how does it work?\\n\\nChatGPT adds a new dimension to summarization\\n\\nIf you’re an information hound like me, you’ve surely run into this situation - you read a summary for a book one day and promptly forget everything by the next. This is why my GPT learning scheme requires several extra critical steps beyond just reading a simple summary.\\n\\nChatGPT is wonderful. It can tailor its output to your situation, and it can converse with you in natural language, allowing for the beauty of custom live Q&A to unfold before your eyes. Let’s jump right into the prompts.\\n\\nPrompt 1: The Summary Basis\\n\\nThe first order of business is to request a detailed summary from GPT about a book you have in mind. Here’s how I go about getting a good starting summary:\\n\\nWrite an ultra-detailed summary about [Insert Book Title].\\n\\nThis prompt coaxes a lot of detail out of GPT. For example, let’s try James Clear’s Atomic Habits.\\n\\nNote: This is a \"self-help\" book, but this prompt chain works for any type of non-fiction book.\\n\\nI couldn’t fit it all in the screenshot, but this went on for a good while.\\n\\nThis step allows ChatGPT to root itself within the context of its summary, reducing hallucinations and improving output later on in the conversation. It’s also useful to read yourself as a good intro to the book’s concepts. Now that we have our summary basis, we can jump into the real meat of this process.\\n\\nPrompt 2: The Tailored Request\\n\\nThis prompt shifts the context into a more actionable space and tailors it directly to you. This is the most important step of the process.\\n\\nNow, tailor the lessons from the book to me. I am a [Insert Brief Personal Bio]. Please ask me some contextual questions to gather more information from me before you start.\\n\\nThis prompt is important because it does two huge things:\\n\\nIt forces ChatGPT to gather valuable information from you to tailor its suggestions.\\n\\nIt \"cuts the fat\" of the book and focuses on giving you the most pertinent information that you are likely to remember\\n\\nHere it is in action, along with my response:\\n\\n\\n\\nNow, answer the questions it asks you. I answered the questions it had for me, and here is a sample from its long list of suggestions:\\n\\n\\n\\nAs you can see, this is a great look into how I can directly apply the knowledge contained in this book to my life specifically, significantly increasing the likelihood that I’ll remember the information. Now, on to the next prompt.\\n\\nPrompt 3: Insurance\\n\\nNow that it has given you some insights into how you might apply the concepts from the book to your life, you need to ensure that it has covered everything relevant to you. Thus, we use this prompt:\\n\\nAre there any other concepts in the book that you think would be good for me to know?\\n\\nHere is what this looks like in practice:\\n\\n\\n\\nNow, it has covered all the bases, and we ensure that we aren’t missing anything important.\\n\\nPrompt 4: Wait, this one isn’t a prompt…\\n\\nBefore we move on, I urge you to try to complete a critical step: taking notes. Write down the most crucial or interesting points that you want to remember for future reference. I use Obsidian, a great note-taking software that allows you to create a personal wiki of interconnected knowledge. If you just glaze over ChatGPT’s output, you’ll never retain any of the information, so taking notes is mission-critical.\\n\\nPrompt 5: Pause and Refresh\\n\\nNow that you’ve read and absorbed the main concepts of the book from an objective stance and how they can relate to you directly, we can start the most interesting step, remembrance.\\n\\nNone of this process makes any sense if we don’t retain any of this information in the future. That’s why we can take advantage of one of ChatGPT’s strong suits - conversation.\\n\\nSet a reminder one or two months in the future to return to this chat and refresh yourself with the content. Reopen the chat after some time has elapsed, and start with this:\\n\\nIt’s been [X] months. Please write a brief quiz about the concepts in the book you told me about to test my knowledge.\\n\\n\\n\\nNow, answer the questions to your best ability and see how you did. This is where GPT shines; it will tell you where you are wrong, and it can help jog your memory in a more interactive way than simply looking over your old notes. Plus, you’ll be forced to look deep into your memory to ace the \"quiz.\"\\n\\nNow, it’s a free-for-all. You can prompt it for whatever you like, and it’ll fill you in with the requisite information. Never before have you been able to look at your notes and ask, \"Remind me about that one again?\" but now you can.\\n\\nSome final thoughts\\n\\nIt’s amazing what this can do for you in a short amount of time. The sheer amount of content digestion that is possible here is almost unfathomable.\\n\\nWhile I only recently discovered this prompt chain, I think it will revolutionize how I read books. Not to mention, it’ll be great to use as a refresher for books I have long forgotten about!\\n\\nI hope you find this prompt scheme helpful. Thanks for reading!\\n\\n-Jordan'}},\n",
       "  {'id': '948fce739c61',\n",
       "   'title': 'Do Gimmicky ChatGPT Prompts Actually Work?',\n",
       "   'subtitle': 'I analyzed if viral gimmick prompts actually trick ChatGPT into working harder.',\n",
       "   'author': '4beacba7dc8a',\n",
       "   'publication_id': '*Self-Published*',\n",
       "   'published_at': '2023-12-27 03:02:16',\n",
       "   'last_modified_at': '2023-12-27 03:02:16',\n",
       "   'tags': ['chatgpt',\n",
       "    'openai',\n",
       "    'ai',\n",
       "    'artificial-intelligence',\n",
       "    'prompt-engineering'],\n",
       "   'topics': ['data-science', 'programming'],\n",
       "   'claps': 125,\n",
       "   'voters': 21,\n",
       "   'word_count': 513,\n",
       "   'responses_count': 2,\n",
       "   'reading_time': 2.319182389937107,\n",
       "   'url': 'https://medium.com/@jordan_gibbs/do-gimmicky-chatgpt-prompts-actually-work-948fce739c61',\n",
       "   'unique_slug': 'do-gimmicky-chatgpt-prompts-actually-work-948fce739c61',\n",
       "   'image_url': 'https://miro.medium.com/1*Uz4_8rQuiXIQXCNDSjN0wQ.png',\n",
       "   'lang': 'en',\n",
       "   'is_series': False,\n",
       "   'is_locked': True,\n",
       "   'is_shortform': False,\n",
       "   'top_highlight': '',\n",
       "   'content': {'id': '948fce739c61',\n",
       "    'content': 'Do Gimmicky ChatGPT Prompts Actually Work?\\n\\nI analyzed if viral gimmick prompts actually trick ChatGPT into working harder.\\n\\n\\n\\nRecently, I’ve been exploring the merits of gimmicky ChatGPT prompts and whether they actually make a strong difference. I wrote an entire article about using bribing prompts and figured out which month of the year ChatGPT is at its best.\\n\\nI saw a Reddit post the other day (see screenshot above) that showed a huge system prompt that collected all the trendy prompting gimmicks into one mega-prompt. It was so ridiculous that I just had to put it to the test.\\n\\nThe results were interesting and, honestly, quite shocking to me…\\n\\nTesting the mega-gimmick\\n\\nI used a classic testing setup that I have been using to test ChatGPT’s laziness, which programmatically tests the output length of different prompt setups. I ran each prompt 100 times and averaged the results. I did this on five different prompts on varying tasks: one round of control data (without the mega-prompt) and one round with the prompt input as part of the GPT system prompt.\\n\\nI counted tokens (1 token = ~0.75 words) for each of the outputs, and the total test ended up totaling around 750,000 tokens.\\n\\nHere are the five tasks that I asked GPT to do for me (100 control runs and 100 gimmick runs of each):\\n\\nGive me a detailed overview of how a nuclear reactor works.\\n\\nWrite a touching story about something of your choice.\\n\\nWrite me a comprehensive history of the Roman Empire.\\n\\nCreate a multi-threaded web crawler in Python that can crawl specific types of websites (e.g., news portals, academic journals, e-commerce sites) and extract relevant data. The crawler should be able to handle various data formats (HTML, PDF, JSON, etc.). After data extraction, implement a data processing module to perform statistical analysis and generate insightful reports.\\n\\nProvide a detailed proof of the Riemann Hypothesis for a specific case.\\n\\nI felt this list of tasks pushed GPT to a point where it could \"decide\" how verbose it wanted to be. It had some serious liberty on how much it output, so I figured the mega-prompt would actually work quite well.\\n\\nThe results are… unexpected\\n\\nI figured I’d get a 5–10% increase in output length with the prompt, but I couldn’t have been more wrong. Here are the averages plotted visually:\\n\\n\\n\\nCrazily enough, the mega-prompt actually made ChatGPT significantly lazier. On average, the control runs were a full 14% longer. And yes, for those who ask, all of these differences are statistically significant.\\n\\nI found this deeply interesting, especially because some of these gimmicky prompts alone actually do help, as I’ve found in some of my other articles. I’m quite baffled, so I’m currently writing an article that breaks down all of the gimmicks one by one to understand these prompts better.\\n\\nIf my analysis has any truth to it, I’d recommend you refrain from using these prompts, as they’ll not get you any real results. Stick to classic, plain language prompts!\\n\\nThanks for reading.\\n\\n-Jordan'}},\n",
       "  {'id': 'b0911e3faf6b',\n",
       "   'title': 'Which Phrases are the Most “ChatGPT” of All?',\n",
       "   'subtitle': 'I analyzed 1.2 million GPT words to find the most common phrases output by ChatGPT\\u200a—\\u200aI found some crazy results.',\n",
       "   'author': '4beacba7dc8a',\n",
       "   'publication_id': '*Self-Published*',\n",
       "   'published_at': '2023-12-14 17:36:37',\n",
       "   'last_modified_at': '2023-12-14 17:36:37',\n",
       "   'tags': ['chatgpt',\n",
       "    'ai',\n",
       "    'artificial-intelligence',\n",
       "    'openai',\n",
       "    'linguistics'],\n",
       "   'topics': ['data-science'],\n",
       "   'claps': 1106,\n",
       "   'voters': 158,\n",
       "   'word_count': 816,\n",
       "   'responses_count': 22,\n",
       "   'reading_time': 3.9125786163522016,\n",
       "   'url': 'https://medium.com/@jordan_gibbs/which-phrases-are-the-most-chatgpt-of-all-b0911e3faf6b',\n",
       "   'unique_slug': 'which-phrases-are-the-most-chatgpt-of-all-b0911e3faf6b',\n",
       "   'image_url': 'https://miro.medium.com/1*5ARxvUDOs_76GIHYtDCYKQ.png',\n",
       "   'lang': 'en',\n",
       "   'is_series': False,\n",
       "   'is_locked': True,\n",
       "   'is_shortform': False,\n",
       "   'top_highlight': '',\n",
       "   'content': {'id': 'b0911e3faf6b',\n",
       "    'content': 'Which Phrases are the Most \"ChatGPT\" of All?\\n\\nI analyzed 1.2 million GPT words to find the most common phrases output by ChatGPT - I found some crazy results.\\n\\n\\n\\nI did an experiment to identify some of the most common ChatGPTisms, and compared them to real human writing. The results are rather hilarious. Yes, your assumptions are correct. ChatGPT has some really annoying patterns, so let’s find out which ones are the most egregious!\\n\\nHow I made my dataset\\n\\nMy ChatGPT data was generated in the following way:\\n\\nI wrote a GPT script that produced realistic user prompts that would likely be asked to ChatGPT (quite meta, I know).\\n\\nI fed a list of 500 topics into this user prompt generator script five times (with a high temperature so there were no duplicate prompts) to get 2500 realistic GPT calls.\\n\\nI fed the 2500 prompts into a new GPT function, posing as fake user prompts so GPT would answer \"normally.\"\\n\\nI collected all these GPT responses into one text file, which is 1.2 million words long. I would have done more, but my wallet was bleeding…\\n\\nHere’s a sample from this flow:\\n\\nGenerated Fake User Prompt: \"Give me some insights on how to incorporate sustainable materials into my line of handcrafted jewelry.\"\\n\\nHere is the Python script that completes this prompt:\\n\\ndef completion(prompt):\\n    response = client.chat.completions.create(\\n        model=\"gpt-4-1106-preview\",\\n        temperature=0.8,\\n        messages=[{\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\\n                  {\"role\": \"user\", \"content\": f\"{prompt}.\"}],\\n    )\\n    return response.choices[0].message.content.strip()\\n\\nGPT response: Incorporating sustainable materials into your line of handcrafted jewelry is a commendable approach that aligns with increasing consumer interest in environmentally friendly products. Here are some insights and ideas on how you can do this…\\n\\nI ran this same flow 2500 times, and I got a fairly longitudinal dataset of ChatGPT content. On to the analysis!\\n\\nComparing GPT writing to real human text\\n\\nI used samples from several English text databases (COCA, COHA, NOW, iWEB) from the Corpus of Contemporary American English. These human samples ended up being over 97.6 million words in total. As far as linguistic analysis goes, this is actually a very small sample. However, I couldn\\'t afford to purchase the full multi-billion word databases (they’re $800), so this is what I’m working with.\\n\\nI made a code that stripped out the most prevalent three and four-word phrases from this dataset (I didn’t do five or six; the files became so large I didn’t want to accidentally data bomb my computer).\\n\\nAnalyzing the three-word phrases\\n\\nAfter much data analysis, I found some interesting things. First, I’ll set the stage with the data:\\n\\nTotal amount of three-word phrases (real English dataset): 97,648,942\\n\\nTotal amount of three-word phrases (GPT English dataset): 1,171,775\\n\\nThe most common real English three-word phrase is \"one of the.\" This accounts for 0.03% of the total phrases in this dataset.\\n\\nOn the flip side, the most common GPT three-word phrase is \"can lead to,\" which accounts for 0.058% of the total phrases in this dataset.\\n\\nI calculated the prevalence percentage (the total occurrences of one phrase / the total amount of phrases in the dataset) and then divided those two prevalence percentages to get the prevalence factor, which essentially answers the question: \"How much more likely is ChatGPT to output this phrase than a real human?\"\\n\\nHere is a graph showing the top 10 most common three-word phrases in the GPT dataset and their prevalence factors:\\n\\nThe raw top 10 most occurring three-word phrases in the GPT dataset, compared to the human output of those same phrases.\\n\\nAnd now for the really interesting stuff. Here is a graph showing the most overused phrases; these are the phrases that are the most \"ChatGPT\" phrases possible…\\n\\nThe top 10 most prevalent three-word phrases in the GPT dataset, ranked by how much more likely GPT will output them than a human.\\n\\nHere are a few GPTisms that didn’t make the graphs:\\n\\n\"the grand tapestry\" - 250x prevalence factor\\n\\n\"a crucial role\" - 79x prevalence factor\\n\\n\"id be happy\" - 40x prevalence factor\\n\\nAnalyzing the four-word phrases\\n\\nNow, on to the four-word phrases:\\n\\nThe most common real English four-word phrase is \"the end of the.\" This accounts for 0.007% of the total phrases in this dataset.\\n\\nThe most common GPT four-word phrase is \"can be used to,\" which accounts for 0.017% of the total phrases in this dataset.\\n\\nI conducted the same analysis as I did in the three-word phrases and generated some graphs. Here is a graph showing the top 10 most common four-word phrases in the GPT dataset and their prevalence factors:\\n\\nThe raw top 10 most occurring four-word phrases in the GPT dataset, compared to the human output.\\n\\nNow for the fun stuff, GPT’s most over-used four-word phrases:\\n\\nThe top 10 most prevalent four-word phrases in the GPT dataset, ranked by how much more likely GPT will output them than a human.\\n\\nHere are a few GPTisms that didn’t make the graphs:\\n\\n\"foster a sense of\" - 1208x prevalence factor\\n\\n\"a multifaceted approach that\" - 1125x prevalence factor\\n\\n\"requires careful planning and\" - 1000x prevalence factor\\n\\nI had a ton of fun with this experiment. Let me know of any common phrases you know ChatGPT loves in the comments, and I’ll search my dataset and tell you the prevalence factor.\\n\\nThanks for reading!\\n\\n-Jordan'}}],\n",
       " '630ab5ffdf27': [{'id': '0826b977bb5a',\n",
       "   'title': 'My magical first job as a self-taught software engineer',\n",
       "   'subtitle': 'I’m a self-taught software engineer. No formal courses. No internship. Being self-taught means I have some noticeable gaps in my technical…',\n",
       "   'author': '630ab5ffdf27',\n",
       "   'publication_id': '7fa1ab2ec345',\n",
       "   'published_at': '2024-02-16 10:31:47',\n",
       "   'last_modified_at': '2024-02-16 10:31:47',\n",
       "   'tags': ['programming',\n",
       "    'software-engineering',\n",
       "    'software-development',\n",
       "    'careers'],\n",
       "   'topics': ['work', 'programming'],\n",
       "   'claps': 211,\n",
       "   'voters': 21,\n",
       "   'word_count': 350,\n",
       "   'responses_count': 5,\n",
       "   'reading_time': 1.520754716981132,\n",
       "   'url': 'https://atomic.engineering/my-magical-first-job-as-a-self-taught-software-engineer-0826b977bb5a',\n",
       "   'unique_slug': 'my-magical-first-job-as-a-self-taught-software-engineer-0826b977bb5a',\n",
       "   'image_url': 'https://miro.medium.com/0*dpx9eSSU8dllS32h.png',\n",
       "   'lang': 'en',\n",
       "   'is_series': False,\n",
       "   'is_locked': False,\n",
       "   'is_shortform': False,\n",
       "   'top_highlight': 'Comparison is the thief of joy.',\n",
       "   'content': {'id': '0826b977bb5a',\n",
       "    'content': 'My magical first job as a self-taught software engineer\\n\\nI’m a self-taught software engineer. No formal courses. No internship. Being self-taught means I have some noticeable gaps in my technical knowledge. But that never stopped me, much to the chagrin of my coworkers.\\n\\nI found my first job by searching \"web development\" on Indeed. I sent my nearly-empty CV (I mowed grass and worked at Dairy Queen prior to this) to a dozen companies and got a single call back. They wanted me to take a timed code challenge. I didn’t know what that meant, but sure! It was in a language called PHP, whatever that meant. I may not know PHP, but I know how to use Google.\\n\\nI passed the code challenge (in retrospect, \"wtf?!\") and started work three weeks later at a startup with one other developer.\\n\\nHe quit the next day. \\U0001fae0\\n\\nAnd there I was. Thousands of lines of code to manage. Other developers to interview. And a full 24 hours of professional experience to back me up.\\n\\nThat job ended up being a ton of fun. It’s still the steepest learning curve I’ve ever encountered. My salary was $44,000. That was as much as my dad! I was rich, busy, and proud of myself.\\n\\nThere’s something magical about your first real job. I don’t think I’ve ever felt that rich, or that ambitious, or that boldly stupid since.\\n\\nToday I’m a software engineer at Medium. I love what I do. It’s challenging and inspiring and stressful and beautiful. Am I happier now than I was then? I don’t think so. I get paid more, and I filled some of those technical knowledge gaps. But there’s happiness everywhere. (Sometimes I dream of going back to a small team where my biggest concerns are how to make git branches work with two engineers.)\\n\\nComparison is the thief of joy.\\n\\nLife is short. Don’t wait until you get into FAANG to be happy. Enjoy the journey! There’s beauty all around.\\n\\nOne day, the internet will turn off and we can all go home.\\n\\nxkcd 1346'}},\n",
       "  {'id': '3be015341e5e',\n",
       "   'title': 'An algorithm for high-performance engineering teams',\n",
       "   'subtitle': 'How does a team go from “good” to “great”?',\n",
       "   'author': '630ab5ffdf27',\n",
       "   'publication_id': '7fa1ab2ec345',\n",
       "   'published_at': '2024-02-14 16:37:02',\n",
       "   'last_modified_at': '2024-02-15 04:02:03',\n",
       "   'tags': ['leadership', 'programming', 'software-engineering'],\n",
       "   'topics': ['work', 'programming'],\n",
       "   'claps': 459,\n",
       "   'voters': 58,\n",
       "   'word_count': 1588,\n",
       "   'responses_count': 8,\n",
       "   'reading_time': 6.542452830188679,\n",
       "   'url': 'https://atomic.engineering/an-algorithm-for-high-performance-engineering-teams-3be015341e5e',\n",
       "   'unique_slug': 'an-algorithm-for-high-performance-engineering-teams-3be015341e5e',\n",
       "   'image_url': 'https://miro.medium.com/1*YBldg8qIX_Y7oxfu_UaS8w.png',\n",
       "   'lang': 'en',\n",
       "   'is_series': False,\n",
       "   'is_locked': True,\n",
       "   'is_shortform': False,\n",
       "   'top_highlight': 'All models are wrong, but some are useful.',\n",
       "   'content': {'id': '3be015341e5e',\n",
       "    'content': 'An algorithm for high-performance engineering teams\\n\\nHow does a team go from \"good\" to \"great\"?\\n\\nGreat teams don’t start great. They become great through focused effort.\\n\\nThe 2004 NBA finals showed the value of a team over individuals. The Los Angeles Lakers played like five superstar individual contributors while the Detroit Pistons played like a team. Against 8-to-1 odds, the Pistons won and showed the world that great teams beat great individuals.\\n\\nDetroit Pistons, 2004 NBA Champions (Getty Images)\\n\\nThere’s a method to developing great teams. It doesn’t depend on a manager, or any formal leadership title. You can effect change as a leader at any level.\\n\\nThe Tuckman model: clean and inflexible\\n\\nAll models are wrong, but some are useful.\\n\\nBruce Tuckman’s model for Stages of Group Development defines a linear progression through predictable stages.\\n\\n🆕 In the Forming stage, team members face uncertainty in their individual roles and in the group\\'s objectives. You’ll see lots of politeness as members learn about each other and the team. Leadership plays a pivotal role here, providing direction and helping to establish the groundwork for the team’s purpose and objectives.\\n\\n⛈️ The Storming stage is characterized by the struggle for power. This can be a tumultuous period where boundaries are tested and conflict emerges. In extreme cases subgroups may form. Good (not overbearing) leadership during this time will guide the team through disagreements and pave the way for collaboration.\\n\\n🧘 At the Norming stage, the tone shifts from a group of individuals to a collective team identity. \"I\" becomes \"we\". The team begins to find its rhythm. Conflicts are resolved, and a sense of cohesion and unity emerges. Working relationships between team members are built on mutual respect and understanding instead of competition and conflict.\\n\\n📈 Ideally, the team will advance to the Performing stage, where the team works effectively with a high degree of autonomy. Members fully engage, leveraging their strengths to achieve the team’s goals with minimal oversight. The focus shifts from individual accomplishment to collective success.\\n\\nTuckman’s Stages of Group Development\\n\\nThe first engineering team I joined was an already-established team of six engineers. By all accounts, this team was well into Norming and on their way to Performing. I was eager to contribute.\\n\\nTwo weeks later, the team was back to Storming with all the telltale signs. I got pulled into secret meetings to prepare my faction’s case against the others. One memorable team meeting was a string of constant interruptions as two engineers argued about testing strategies.\\n\\nOur manager guided us through these discussions without concern, setting boundaries and keeping the shared goals in sight along the way. We emerged a few weeks later as a refined team with unified purpose and mutual respect.\\n\\nBut, wait… what happened? Why were we Storming?\\n\\nThe team had already been formed. It had been around for years, and the other engineers had been working on the team for at least a full year prior to me joining. Of course they had stormed and normed. Why did we regress?\\n\\nPermanent teams are different\\n\\nTuckman’s original article is a meta-analysis of research that primarily studied group therapy. We can draw some similarities between engineering teams and short-lived therapy groups, but the group dynamics of a permanent working team have important differences:\\n\\nTuckman’s analysis focused on groups of individuals who began working together all at the same time. Modern teams are usually slow-growing, with individuals joining and leaving throughout the team’s lifetime.\\n\\nIndividuals in group therapy often have similar individual goals (stop drinking, forgive others and yourself, etc.), but that’s distinct from the group having a singular goal. Modern working groups have a shared goal (release a feature, squash a bug, etc.) that individuals must coordinate to accomplish.\\n\\nWith some adjustments, the Tuckman model is still useful as a framework for understanding where the team is currently and how effort should be focused.\\n\\nModels are clean; real life is messy\\n\\nPermanent teams have a beginning, but for most members, that was long before they joined. New members join \"in the middle,\" where the team has already gone through Forming, Storming, and Norming, probably many times.\\n\\nEach time a new member joins a team, the team is Forming again\\n\\nWhen a new member joins the team, it throws the team back into Forming. An established team can move through the stages more quickly, but speed is not guaranteed. It depends on the effort of the individual members to intentionally step through Forming, Storming, and Norming.\\n\\nMoving past Storming and on to Norming might take some 1:1s with targeted team members.\\n\\nPerforming, of course, will take time. Many teams never get here. Permanent teams benefit from established relationships and rapid iteration through the group development cycle.\\n\\nThe linear relationship of the Tuckman model doesn’t fit permanent teams. The reality is more of a cycle that repeats constantly, resetting each time the team roster changes.\\n\\n\\n\\nHow you influence your team\\n\\nYou influence your whole team, even if you don’t ever explicitly \"lead\" them. You will use that influence for better or worse (please try \"better\", it’s much more enjoyable).\\n\\n❤️ Be kind\\n\\nKindness is underrated.\\n\\nThere was a wizard engineer (we’ll call him \"Jon\") who worked for me a few years ago. His code was good. His PRs were quick. By all technical accounts, he was a great engineer.\\n\\nWe got some common feedback about him from other engineers:\\n\\n\"Jon is one of the best engineers at [the company]. I would have a hard time working with him.\"\\n\\n\"Jon is committed to doing ‘the right thing.’ But some quieter engineers avoid discussions with him.\"\\n\\nIf Jon was a great engineer, why was he so hard to work with? Isn’t his job to get things right?\\n\\nNo. The job of an engineer is to get things done. And getting anything done past a certain point requires working well with others.\\n\\nIf you are right but nobody wants to work with you, what net value are you bringing to the team?\\n\\nBeing thoughtful about the feelings of others won’t make you any less right or wrong. But it will make you more impactful in your role as others seek your input.\\n\\n🤝 Be helpful\\n\\nIt’s tempting to correct mistakes as soon as you see them, even when you don’t have the full context. But take a few moments to check your intentions as well as learn more about what’s going on.\\n\\nFrom Andrew Bosworth (CTO of Meta):\\n\\nBefore you provide feedback you should ask yourself: what is my goal? If the answer is to influence decision making for the good of [the team] then you are on the right track. If it is to make yourself feel better then it is best to keep it to yourself.\\n\\nBoz goes on to suggest two goals when providing feedback:\\n\\nEnsure your concern is well understood and not being overlooked accidentally.\\n\\nEnsure you understand why your concern isn’t being addressed.\\n\\nGiving great feedback is a superpower. Giving bad feedback can backfire spectacularly.\\n\\n🔭 Be aware\\n\\nIt takes surprisingly little time to stay on top of the work your team has going on. I spend the first and last 20 minutes of each day reviewing the in-progress work for my team. Since I began this ritual some years ago, far fewer things slip through the cracks.\\n\\nStaying on top of your responsibilities is a skill. It’s called \"Executive Functioning\" and there’s more to it than just saying organized. Like any skill, it can be practiced. Jillian Enright wrote a fantastic article about executive functioning skills including strategies to help.\\n\\nA few other small changes with big results:\\n\\nContribute to more PRs. Discussions happening this close to the code are full of context.\\n\\nGet passionate about documentation. This could be as simple as asking questions in public Slack channels. Or go all-in on internal docs for your product. (Hint: make outlines for docs you wish you had, then delegate the work of filling it out to the engineers with the most context.)\\n\\n📚 Be excellent\\n\\nI get immense satisfaction from knowing a job was done well. Not just as well as I could do it, but objectively well by any measure. That means I have to study and practice and correct mistakes and actively fight against the natural draw to mediocrity.\\n\\nIt takes effort. But you owe it to yourself to be an excellent engineer. Why not? If you’re going to do something, do it really well.\\n\\nRead books. Another hill I’ll gladly die on. Reading books accelerates learning, specifically when you want to dive deep in a topic. Start with Clean Architecture and then follow up with books related to the specific content of your current work.\\n\\nWrite. Teaching others improves your own skill. Find a platform (Medium is a great fit), share your experience, and teach others what you’ve learned.\\n\\nPractice your craft. Engineering is a skill, and like all skills you get better by practicing. Approach hard problems as opportunities to improve rather than tasks to grind through.\\n\\n🗣️ Be open\\n\\nEffective teamwork begins and ends with communication.\\n\\n—\\u200aMike Krzyzewski (Coach K)\\n\\nOne of my core beliefs is that most problems related to people can be solved by effective communication. The Tuckman model, and the derivative model I described, are first and foremost interpersonal relationships and effective communication. It’s worth the time and effort to get better at communicating.\\n\\nWe’ve all had different experiences on effective (and ineffective) teams. What have you learned from great teams you’ve been part of?'}},\n",
       "  {'id': 'a8f2b9faad1d',\n",
       "   'title': 'I almost got fired once',\n",
       "   'subtitle': '👋 Hi, this is Jacob with this week’s newsletter, “I almost got fired once.”',\n",
       "   'author': '630ab5ffdf27',\n",
       "   'publication_id': '7fa1ab2ec345',\n",
       "   'published_at': '2024-02-09 11:31:46',\n",
       "   'last_modified_at': '2024-02-09 11:31:46',\n",
       "   'tags': ['programming',\n",
       "    'software-development',\n",
       "    'software-engineering',\n",
       "    'problem-solving',\n",
       "    'leadership'],\n",
       "   'topics': ['work', 'programming'],\n",
       "   'claps': 378,\n",
       "   'voters': 34,\n",
       "   'word_count': 746,\n",
       "   'responses_count': 5,\n",
       "   'reading_time': 3.1984276729559746,\n",
       "   'url': 'https://atomic.engineering/i-almost-got-fired-once-a8f2b9faad1d',\n",
       "   'unique_slug': 'i-almost-got-fired-once-a8f2b9faad1d',\n",
       "   'image_url': 'https://miro.medium.com/1*LB-gvS9Z52OtQKljoJy6bw.png',\n",
       "   'lang': 'en',\n",
       "   'is_series': False,\n",
       "   'is_locked': False,\n",
       "   'is_shortform': False,\n",
       "   'top_highlight': 'Luke Millar (VP of Eng at Medium) explained to me what made one of our team members so valuable. \"They\\'re not necessarily fast, but I know if I give them a hard problem that no one else understands, they\\'ll eventually find an answer, and it will be a good one.\"',\n",
       "   'content': {'id': 'a8f2b9faad1d',\n",
       "    'content': 'I almost got fired once\\n\\nMy friend, and manager at the time, James Russell, pulled me into a room one morning. He told me I wouldn’t be working on the ML product I’d been building. It would be transitioned to another product engineer and data scientist. I asked, with clear concern in my voice, if I was being fired. James paused for what felt like minutes before responding, \"No, but you need to find something else to do.\"\\n\\nI considered myself a good engineer up to that point. I always checked the boxes on PRs. Tests were clean. Abstractions weren’t leaky. What else was I missing?\\n\\nI was missing a lot, it turns out. Everything. I knew how to write code. But I needed to learn how to solve problems. Not just \"how to CRUD\" problems, but actually difficult problems like \"How can we stop breaking production?\" and \"Where’s the value for the customer?\"\\n\\nI went on to have a great relationship with James, who taught me a lot about the value of engineers as problem-solvers first and programmers second. Later, he said to me, \"Stop bringing me problems. I need solutions. I’m paying you so I can bring you problems.\"\\n\\nProblem-solving is hard. If it were easy, we wouldn’t have nice jobs.\\n\\nYour value as a software engineer is in your ability to solve increasingly ambiguous problems. The more ambiguous of a problem you can solve, the more successful you’ll be.\\n\\n\\n\\nLuke Millar (VP of Eng at Medium) explained to me what made one of our team members so valuable. \"They’re not necessarily fast, but I know if I give them a hard problem that no one else understands, they’ll eventually find an answer, and it will be a good one.\"\\n\\nHow can you get better at solving hard problems?\\n\\nThere’s no hack to \"git gud\" quickly. It takes time to master. But there is a method to \"get good guaranteed.\"\\n\\n💡 Learn from others.\\n\\n📚 Read books. If you aren’t a reader, become a reader. You can learn from the experience of engineers from the greatest teams without needing to work at a FAANG company first. Some of my favorite books I keep coming back to are:\\n\\nClean Architecture by Robert Martin\\n\\nThe Pragmatic Programmer by David Thomas and Andrew Hunt\\n\\nStaff Engineer: Leadership Beyond the Management Track (my favorite) by Will Larson\\n\\n🥑 Pair program. Pair programming is the superfood of knowledge transfer. There’s a reason it works. Watching other engineers write code and talking about why they make decisions improves your own skills and reasoning. You can also drive the programming and let them comment on your process.\\n\\n🔁 Solve more problems.\\n\\nYou get good at something by doing that thing. Over and over and over.\\n\\nTackle problems that come up! There’s a culture at Medium of engineers volunteering to fix problems in parts of the codebase they aren’t familiar with so they can learn about it. This usually requires input from other engineers more familiar with that area. But this behavior of facing new problems head-on dramatically improves each engineer’s effectiveness and the quality of the whole team.\\n\\nDon’t shy away from problems. Embrace them.\\n\\n🙋 Ask questions.\\n\\nDon’t be afraid to ask \"dumb\" questions. Problem-solving requires knowledge to draw from. The surface area of \"tech\" is huge, and there’s no expectation that you should know all of it. If you don’t know about something, just ask.\\n\\nA former eng leader asked me about IP CIDR addressing, an obscure thing (for product engineers) I learned about when I was 17. Sure, I was surprised he didn’t know about it already. But I didn’t think any less of him for it. If anything, I was impressed by his determination to solve problems even if that meant asking dumb questions and risking looking foolish (hint: you don’t look foolish asking questions).\\n\\nBe the bold question-asker.\\n\\nxkcd 1053\\n\\nHave a great week, and stay safe out there.\\n\\nJacob Bennett\\n\\nBonus reading\\n\\nDare Obasanjo, Microsoft dev from 2002–2019, shares their insider perspective on the company under Steve Ballmer vs Satya Nadella in 5 Things I Learned About Leadership from the Death & Rebirth of Microsoft\\n\\nProf Bill Buchanan OBE, Professor of Cryptography at Edinburgh Napier University, explains what the Barbie typewriter can teach us about cybersecurity in Is Barbie’s Password ‘uiff;rnl’?\\n\\nJacob Bennett, Staff Engineer at Medium, shares git workflow improvements you can use today in Use Git Like a Senior Engineer'}},\n",
       "  {'id': '547e3edc7a36',\n",
       "   'title': 'A tale of two engineering teams',\n",
       "   'subtitle': '👋 Hi, this is Jacob with this week’s newsletter, “A tale of two engineering teams.”',\n",
       "   'author': '630ab5ffdf27',\n",
       "   'publication_id': '7fa1ab2ec345',\n",
       "   'published_at': '2024-02-02 11:31:43',\n",
       "   'last_modified_at': '2024-02-02 11:31:43',\n",
       "   'tags': ['programming',\n",
       "    'software-development',\n",
       "    'software-engineering',\n",
       "    'technology'],\n",
       "   'topics': ['programming'],\n",
       "   'claps': 595,\n",
       "   'voters': 70,\n",
       "   'word_count': 616,\n",
       "   'responses_count': 6,\n",
       "   'reading_time': 2.5245283018867926,\n",
       "   'url': 'https://atomic.engineering/a-tale-of-two-engineering-teams-547e3edc7a36',\n",
       "   'unique_slug': 'a-tale-of-two-engineering-teams-547e3edc7a36',\n",
       "   'image_url': 'https://miro.medium.com/0*dpMZyiz7Wm5sI2B6.png',\n",
       "   'lang': 'en',\n",
       "   'is_series': False,\n",
       "   'is_locked': False,\n",
       "   'is_shortform': False,\n",
       "   'top_highlight': '\"First, make it work.\" You are out of business if it doesn\\'t work.',\n",
       "   'content': {'id': '547e3edc7a36',\n",
       "    'content': 'A tale of two engineering teams\\n\\n👋 Hi, this is Jacob with this week’s newsletter. I write about software engineering, big tech/startups, and career growth.\\n\\nThis week, I’m sharing personal experiences from two very different engineering teams I was part of. If you’ve had similar experiences, I’d love to hear about them. Thank you for reading!\\n\\nIn Clean Architecture, Robert Martin adds some commentary to Kent Beck’s famous \"Make it work, make it right, make it fast\" quote:\\n\\n\"First, make it work.\" You are out of business if it doesn’t work.\\n\\n\"Then make it right.\" Refactor the code so that you and others can understand and evolve it as needs change or are better understood.\\n\\n\"Then make it fast.\" Refactor the code for \"needed\" performance.\\n\\nOne of my old teams did this so right. Another one did it so, so wrong…\\n\\nThe $27M failure\\n\\nI used to work for a company that built a B2B SaaS product. Their old, monolithic, Java-based product was a cash cow, bringing in $15 million annually for eight straight years. They hired a new engineering director who promised to build a next-gen product that would take them even further using the latest tech (at the time, that meant \"Kubernetes solves all problems\"). He just needed 30 engineers and permission to do it as a complete rewrite.\\n\\nThe product was an engineering marvel. The director got the 30 engineers he wanted and they built and deployed 162 microservices (\"picoservices\" might be a better name) supporting everything from CAN-SPAM to a chatbot with some early NLP features.\\n\\nThere was only one problem: it didn’t work.\\n\\nAfter two years of development and $27 million spent on \"R&D\", no customers could migrate from the Java monolith to the new system. Pages loaded in minutes. Events were stuck in queues for hours as calls fanned out and validated data.\\n\\nThe director was, unsurprisingly, let go. The project was written off as a total loss. After two years, the company returned to iterating on the Java monolith, a system they still use today.\\n\\nThe team that made it work\\n\\nThere was another team I worked for that had a single driving principle: Delight the users. That core principle drove all our decisions, especially when building new features. We took user feedback, implemented it quickly, and shipped it in a few days.\\n\\nWe cared about clean architecture, passing tests, and scalable services. But our primary focus was a working product.\\n\\nThe result of this team was just that: a product that worked. We iterated on a great product, delighted users, and built a profitable system that continues to run ten years later. (You go, SyncTimes!)\\n\\nMaybe it’s boring that there wasn’t much drama about this project. But \"Boring is beautiful\" (credit to Ben \"The Hosk\" Hosking in \"Boring is Beautiful in Software Development,\" worth the read).\\n\\nFirst, make it work. Then, make it right. That’s not the same as \"Move fast and break things.\" Making it work is still the number one priority. When you know what you want to write, write it. Save improvements for later.\\n\\n\"But Jacob, WhAT abOUt TeCh dEBt!?\"\\n\\nThis \"clean up later\" attitude is the polar opposite of what I usually say. The nuance is: Don’t \"make it right\" or \"make it fast\" at the expense of \"making it work.\"\\n\\nKeep your priorities straight. Your end user might be a paying customer, another engineer, or the whole C-Suite. Prioritize working products over seemingly great engineering.\\n\\nxkcd 1926\\n\\nHave a great week, and stay safe out there.\\n\\nJacob Bennett\\n\\nBonus reading\\n\\nTest Driven Development, by Kent Beck (book)\\n\\nClean Architecture, by Robert C. Martin (book)\\n\\nWhat To Tidy, by Kent Beck (Medium)'}},\n",
       "  {'id': '597a768f6509',\n",
       "   'title': 'Welcome to The Standup',\n",
       "   'subtitle': 'A single idea. 5 minutes or less. Every week.',\n",
       "   'author': '630ab5ffdf27',\n",
       "   'publication_id': '7fa1ab2ec345',\n",
       "   'published_at': '2024-01-26 13:32:22',\n",
       "   'last_modified_at': '2024-01-26 16:52:09',\n",
       "   'tags': ['programming',\n",
       "    'software-development',\n",
       "    'software-engineering',\n",
       "    'software-architecture',\n",
       "    'data-science'],\n",
       "   'topics': ['programming'],\n",
       "   'claps': 79,\n",
       "   'voters': 11,\n",
       "   'word_count': 120,\n",
       "   'responses_count': 1,\n",
       "   'reading_time': 0.4528301886792453,\n",
       "   'url': 'https://atomic.engineering/welcome-to-atomic-engineering-daily-597a768f6509',\n",
       "   'unique_slug': 'welcome-to-atomic-engineering-daily-597a768f6509',\n",
       "   'image_url': '',\n",
       "   'lang': 'en',\n",
       "   'is_series': False,\n",
       "   'is_locked': False,\n",
       "   'is_shortform': True,\n",
       "   'top_highlight': '',\n",
       "   'content': {'id': '597a768f6509',\n",
       "    'content': 'Welcome to The Standup\\n\\nA single idea. 5 minutes or less. Every week.\\n\\nHello 👋 I’m Jacob. I’ve learned a lot from the start of my career as a junior engineer to now working as a staff software engineer at Medium. The Atomic Engineer is an attempt to collect those learnings (mostly ideas from great engineers that I’ve learned from) in a single place as a resource for engineers to learn and grow.\\n\\nThis newsletter, The Standup, promises to deliver atomic ideas - self-contained concepts in five minutes or less - to your inbox every week. I’ll share what I’ve learned and pull insights from other great engineers with outsized impact in their roles.\\n\\nWelcome to The Standup! ⚛️'}},\n",
       "  {'id': 'edd9949df58b',\n",
       "   'title': 'The 5 paid subscriptions I actually use in 2024 as a software engineer',\n",
       "   'subtitle': 'Tools I use that are cheaper than Netflix',\n",
       "   'author': '630ab5ffdf27',\n",
       "   'publication_id': '5517fd7b58a6',\n",
       "   'published_at': '2024-01-04 15:44:45',\n",
       "   'last_modified_at': '2024-01-04 15:44:45',\n",
       "   'tags': ['software-engineering',\n",
       "    'software-development',\n",
       "    'programming',\n",
       "    'technology',\n",
       "    'data-science'],\n",
       "   'topics': ['programming'],\n",
       "   'claps': 9093,\n",
       "   'voters': 2385,\n",
       "   'word_count': 896,\n",
       "   'responses_count': 122,\n",
       "   'reading_time': 4.331132075471698,\n",
       "   'url': 'https://levelup.gitconnected.com/the-5-paid-subscriptions-i-actually-use-in-2024-as-a-software-engineer-edd9949df58b',\n",
       "   'unique_slug': 'the-5-paid-subscriptions-i-actually-use-in-2024-as-a-software-engineer-edd9949df58b',\n",
       "   'image_url': 'https://miro.medium.com/1*jDgxfrxa6FoWb5e0VAFt-w.gif',\n",
       "   'lang': 'en',\n",
       "   'is_series': False,\n",
       "   'is_locked': True,\n",
       "   'is_shortform': False,\n",
       "   'top_highlight': 'Kagi: a better search engine than Google',\n",
       "   'content': {'id': 'edd9949df58b',\n",
       "    'content': 'The 5 paid subscriptions I actually use in 2024 as a software engineer\\n\\nTools I use that are cheaper than Netflix\\n\\nI care a lot about the tools I use. Especially when they aren’t free.\\n\\nHere’s what I’m paying for in 2023–24 to improve my performance and productivity as a software engineer.\\n\\nPlease note: None of the links in this article are affiliate links.\\n\\nGitHub Copilot: an AI pair programmer\\n\\nWhen I’m writing code, Copilot works in the background by reading what I’ve written and quietly suggesting what I might want to write next.\\n\\nLast year I said Copilot has improved my productivity by at least 30%. The real figure might be closer to 50%. I spend considerably less effort on the mundane and boilerplate, and I feel much more satisfied with the engaging bits of software engineering.\\n\\nGitHub Copilot in action (source from GitHub)\\n\\nMy biggest productivity improvements have come from:\\n\\nWriting test cases. Most of the time I write the description for the test case and Copilot fills out everything else.\\n\\nSmall things I would have to look up. e.g. Instead of searching for the correct RegEx to parse a string, I write a comment explaining what I want the RegEx to do and Copilot writes the RegEx for me.\\n\\nBoilerplate functions. For 90% of boilerplate functions (e.g. snakeCaseToCamel or loggingMiddleware) I write the function name and Copilot writes the function.\\n\\nLearn more about GitHub Copilot →\\n\\nKagi: a better search engine than Google\\n\\nI measure the effectiveness of searches by how long it takes me to find what I was actually looking for. By that measure, Google has been steadily getting worse.\\n\\nWhen I search for something on Kagi, the correct result is in the first 2 links 95% of the time. It’s in the top 5 links 99% of the time. That just doesn’t happen with Google, Bing, etc.\\n\\nThe consistently great results page is further boosted by the search personalization I control. I’ve told Kagi that any results from Stack Overflow or Medium should be weighted higher, as well as blocked other sites I don’t care to see results from.\\n\\n\\n\\nNo ads. Objectively better search results. Of all the subscriptions I pay for, this is the hill I will die on.\\n\\nWhy pay for search? The same reason I pay for Medium: The goals of ad-supported search (and ad-supported content generally) directly conflict with why I use search engines. If you want to get indoctrinated, read their post The Age of PageRank is Over.\\n\\nLearn more about Kagi →\\n\\nChatGPT: an AI companion for my whole job\\n\\n\"Describe this block of code for me.\"\\n\\n\"Why did this Go code panic?\"\\n\\n\"I’m going into a review cycle and I am seeking a promotion. Can you analyze my self review and suggest improvements before I send it to my manager?\"\\n\\nI’m constantly pinging ChatGPT with technical questions. It’s usually spot on, and the rubber-ducking I do with it is 100x more effective than using an actual rubber duck.\\n\\nThe feature that pushed me to pay for ChatGPT was \"Create a GPT\".\\n\\n\\n\\nI currently have four purpose-built GPTs for different projects and settings. The most used one is \"Codie\", my pair programmer. You can try Codie out here →\\n\\nMy purpose-built GPT (try it out here)\\n\\nAdding ChatGPT (or Bard or Bing Chat) feels clumsy at first. Of course it does. You’re working with a new tool. You have to practice it to become an expert. But keep at it, the payoff in productivity and quality gains is monumental\\n\\nLearn more about ChatGPT →\\n\\nMedium: knowledge-sharing with other engineers\\n\\nMy favorite platform for learning from other people in my field is this blogging platform (Medium). Here you can read thousands of high-quality articles about programming, data science, technology, and more.\\n\\nThe Medium.com landing page\\n\\nI’ve been a fan of Medium for years. And yes, I work here. But I chose to work here because I really love the platform!\\n\\nLearn more about Medium →\\n\\nExcalidraw: easy and beautiful diagrams\\n\\nThis is an app that made the list this year. I upgraded to Excalidraw+ in April 2023 and haven’t looked back.\\n\\nWe use diagrams extensively at Medium Engineering. Most of our diagrams are created in Excalidraw, which makes them clean, fun, and editable.\\n\\nScreencap of a presentation I gave during our Partner Program release retrospective\\n\\nLearn more about Excalidraw →\\n\\nI stopped paying for tools I don’t use\\n\\nSome things didn’t make the cut. My post from last year included 2 tools that I no longer use.\\n\\nMidjourney has been replaced by ChatGPT + DALL-E. Midjourney image generation is a bit better, but it’s more than I need. I would pay for ChatGPT without the image generation, but having DALL-E bundled in the subscription is a nice bonus. The image generation is still great, and I can chat more naturally with DALL-E than I can with Midjourney (I can’t chat with Midjourney at all 😩).\\n\\nScribd has been replaced by Kindle + Libby. I finally bought a Kindle! Not sure why that took so long… But it has been life-changing. eReaders aren’t for everyone, but they work well for me with 3 kids and a busy schedule. Scribd was great, but the Kindle ecosystem is top-tier.\\n\\nI care a lot about spending money on things that improve my life. These tools bring tremendous value to me as a software engineer. Consider adding these to your toolbox!\\n\\nThis post follows up on my 2023 post.'}},\n",
       "  {'id': '815da93996a',\n",
       "   'title': 'Yes, You Can Write ‘switch’ Statements in Python',\n",
       "   'subtitle': 'And it comes with a secret superpower!',\n",
       "   'author': '630ab5ffdf27',\n",
       "   'publication_id': '78073def27b8',\n",
       "   'published_at': '2023-04-05 04:17:00',\n",
       "   'last_modified_at': '2023-04-14 20:55:11',\n",
       "   'tags': ['python',\n",
       "    'programming',\n",
       "    'software-development',\n",
       "    'data-science',\n",
       "    'technology'],\n",
       "   'topics': ['programming'],\n",
       "   'claps': 560,\n",
       "   'voters': 82,\n",
       "   'word_count': 1110,\n",
       "   'responses_count': 8,\n",
       "   'reading_time': 4.3886792452830194,\n",
       "   'url': 'https://python.plainenglish.io/yes-you-can-write-switch-statements-in-python-815da93996a',\n",
       "   'unique_slug': 'yes-you-can-write-switch-statements-in-python-815da93996a',\n",
       "   'image_url': 'https://miro.medium.com/0*ZK-x4MQeq7ElOOW1.png',\n",
       "   'lang': 'en',\n",
       "   'is_series': False,\n",
       "   'is_locked': True,\n",
       "   'is_shortform': False,\n",
       "   'top_highlight': '',\n",
       "   'content': {'id': '815da93996a',\n",
       "    'content': 'Yes, You Can Write ‘switch’ Statements in Python\\n\\nAnd it comes with a secret superpower\\n\\n\\n\\nWith the release of Python 3.10, we got switch statements in the form of match 🎉\\n\\nThe basic syntax of the match statement is simple:\\n\\nmatch subject:\\n  case <pattern_1>:\\n    <action_1>\\n  case <pattern_2>:\\n    <action_2>\\n  case <pattern_3>:\\n    <action_3>\\n  case _:\\n    <action_wildcard>\\n\\nmatch supports basic and complex pattern matching, as well as a default case if no match is found.\\n\\nThe basic flow of the match statement is:\\n\\nEvaluate the subject in the match statement\\n\\nCompare the subject with each pattern in case statements from top to bottom until a match is confirmed\\n\\nExecute the action associated with the matched case statement\\n\\nIf an exact match is not confirmed and a wildcard _ is provided, execute the action associated with the wildcard _ case. If no wildcard is provided, the entire match block is a no-op.\\n\\nIf the input exactly matches one of the case statements, that case will get executed and no further cases are evaluated.\\n\\nPattern matching\\n\\nLet’s take a look at a simple example: matching the subject with int literals. At each step, the status subject gets compared against the case pattern to determine equality (i.e. ==).\\n\\ndef http_error(status: int) -> str:\\n  match status:\\n    case 400:\\n      return \"Bad request\"\\n    case 404:\\n      return \"Not found\"\\n    case 418:\\n      return \"I\\'m a teapot\"\\n\\nprint(http_error(400)) # \"Bad request\"\\nprint(http_error(404)) # \"Not found\"\\nprint(http_error(418)) # \"I\\'m a teapot\"\\n\\nThe subject can be more than just a value. You’ll often want to evaluate the subject within the match block.\\n\\ndef http_error(status) -> str:\\n  match int(status / 100):\\n    case 2:\\n      return \"200-level status\"\\n    case 3:\\n      return \"300-level status\"\\n    case 4:\\n      return \"400-level status\"\\n    case 5:\\n      return \"500-level status\"\\n\\nprint(http_error(201)) # \"200-level status\"\\nprint(http_error(302)) # \"300-level status\"\\nprint(http_error(404)) # \"400-level status\"\\nprint(http_error(500)) # \"500-level status\"\\n\\nYou can also combine multiple literals in a single case pattern using a pipe |. The pipe is equivalent to Python’s or keyword (e.g. 400 or 401 or 403).\\n\\ndef http_error(status) -> str:\\n  match status:\\n    case 400 | 401 | 403:\\n      return \"Bad request\"\\n    case 404:\\n      return \"Not found\"\\n    # ...\\n\\nprint(http_error(400)) # \"Bad request\"\\nprint(http_error(401)) # \"Bad request\"\\nprint(http_error(404)) # \"Not found\"\\n\\nThe wildcard case (default case)\\n\\nNote the final case statement case _. This is a special wildcard case (similar to default cases in other languages). If this wildcard case has been declared, any subject that doesn’t match another case will match the wildcard.\\n\\nThe wildcard case will catch everything, even inputs that don’t match the type you are expecting.\\n\\ndef http_error(status) -> str:\\n  match status:\\n    case 400:\\n      return \"Bad request\"\\n    case 404:\\n      return \"Not found\"\\n    case 418:\\n      return \"I\\'m a teapot\"\\n    case _:\\n      return f\"Got another status: {status}\"\\n\\nprint(http_error(400)) # \"Bad request\"\\nprint(http_error(200)) # \"Got another status: 200\"\\nprint(http_error(500)) # \"Got another status: 500\"\\nprint(http_error(\"foo\")) # \"Got another status: foo\"\\n\\nThe wildcard case is optional. If you don’t include it and the subject fails to match a case, no case gets executed.\\n\\n# no wildcard case\\ndef http_error(status) -> str:\\n  match status:\\n    case 400:\\n      return \"Bad request\"\\n    case 404:\\n      return \"Not found\"\\n    case 418:\\n      return \"I\\'m a teapot\"\\n\\nprint(http_error(400)) # \"Bad request\"\\nprint(http_error(404)) # \"Not found\"\\nprint(http_error(500)) # None (http_error did not return a value)\\n\\nComplex pattern matching\\n\\nPatterns can be more complex than a single literal. You can compare a match subject against complex data structures that contain literals, variables, or both.\\n\\nA note on all patterns with variables. A variable declared in a case pattern is scoped to that case.\\n\\nTuples\\n\\nYou can match against tuples with literals, variables, or both.\\n\\n# point is a tuple\\nmatch point:\\n  case (0, 0):\\n    return \"The point is on the origin\"\\n  case (x, 0):\\n    return f\"{x=} and the point is on the y-axis\"\\n  case (0, y):\\n    return f\"{y=} and the point is on the x-axis\"\\n  case (x, y):\\n    return f\"{x=} {y=}\"\\n  case _:\\n    raise ValueError(\"Not a valid point\")\\n\\nClasses\\n\\nWhen using classes as patterns, use the class name followed by the list of arguments like a constructor.\\n\\n@dataclass\\nclass Point:\\n  x: int\\n  y: int\\n\\nmatch point:\\n  case Point(x=0, y=0):\\n    return \"The point is on the origin\"\\n  case Point(x=x, y=0):\\n   return f\"{x=} and the point is on the y-axis\"\\n  case Point(x=0, y=y):\\n    return f\"{y=} and the point is on the x-axis\"\\n  case Point(x=x, y=y):\\n    return f\"{x=} {y=}\"\\n  case _:\\n   raise ValueError(\"Not a valid point\")\\n\\nA note on classes with positional parameters. Pattern matching will use positional parameters if the class supports it (e.g. with @dataclass). In the above example with Point, these patterns are all equivalent:\\n\\nPoint(1, val)\\nPoint(1, y=val)\\nPoint(x=1, y=val)\\nPoint(y=val, x=1)\\n\\nLists\\n\\nPatterns will match items in lists.\\n\\nmatch data:\\n  case []:\\n    print(\"empty\")\\n  case [x]:\\n    print(f\"one item in the list: {x}\")\\n  case [x, y]:\\n    print(f\"two items in the list: {x} and {y}\")\\n  case [1, 2, x]:\\n    print(f\"the list goes 1, 2, {x}\")\\n\\nList expansion works in patterns as well.\\n\\nmatch data:\\n  case []:\\n    print(\"empty\")\\n  case [x]:\\n    print(f\"one item in the list: {x}\")\\n  case [x, y]:\\n    print(f\"two items in the list: {x} and {y}\")\\n  case [x, y, *z]:\\n    print(f\"more than two items: {data}\")\\n\\nOrder matters on pattern matching, so consider using match sorted(data) when including literals in your patterns.\\n\\nmatch sorted(users):\\n  case [\"Adrienne\", \"Andréas\", \"Sofie\"]:\\n    print(\"Gold Team\")\\n  case [\"Brittany\", \"Nouf\", \"Tony\"]:\\n    print(\"Red Team\")\\n  case [\"Dan\", \"Eddie\", \"Jorge\"]:\\n    print(\"Blue Team\")\\n\\nFilter cases with guards\\n\\nYou can apply more granular filters for cases using guards. Add an if statement after the case <pattern> expression to filter that case further. If the guard evaluates to False, match goes on to try the next case block.\\n\\nmatch point:\\n  case Point(x, y) if x == y:\\n    return f\"The point is on the diagonal: {x=} {y=}\"\\n  case Point(x, y):\\n    return f\"The point just exists: {x=} {y=}\"\\n\\nComplex wildcards (match’s hidden superpower)\\n\\nUnlike the default cases in other languages, wildcards can be used within complex variables.\\n\\nmatch rock_paper_scissors:\\n  case (\"rock\", second, third) if second != \"rock\":\\n    print(\"Rock was first\")\\n  case (\"rock\", \"rock\", _):\\n    print(\"2 rocks in a row\")\\n\\nPython match statements are a powerful addition to the language, especially with the complex wildcard matching. Check out the 3.10 release notes to learn more about it and other features in Python.\\n\\nPlease let me know your thoughts about this article! Add a few claps if you think it’s worth it, and drop your thoughts in a reply. Follow Jacob Bennett and Python in Plain English for more in-depth Python education 🐍\\n\\nMore content at PlainEnglish.io.\\n\\nSign up for our free weekly newsletter. Follow us on Twitter, LinkedIn, YouTube, and Discord.\\n\\nInterested in scaling your software startup? Check out Circuit.'}},\n",
       "  {'id': 'c1fe776c108f',\n",
       "   'title': 'The comprehensive guide to Python project setup',\n",
       "   'subtitle': 'Start your project right and reap the rewards for years',\n",
       "   'author': '630ab5ffdf27',\n",
       "   'publication_id': '5517fd7b58a6',\n",
       "   'published_at': '2023-04-04 17:24:29',\n",
       "   'last_modified_at': '2023-04-04 17:24:29',\n",
       "   'tags': ['python',\n",
       "    'programming',\n",
       "    'software-development',\n",
       "    'data-science',\n",
       "    'technology'],\n",
       "   'topics': ['programming'],\n",
       "   'claps': 1331,\n",
       "   'voters': 399,\n",
       "   'word_count': 2632,\n",
       "   'responses_count': 9,\n",
       "   'reading_time': 10.315408805031446,\n",
       "   'url': 'https://levelup.gitconnected.com/the-comprehensive-guide-to-python-project-setup-c1fe776c108f',\n",
       "   'unique_slug': 'the-comprehensive-guide-to-python-project-setup-c1fe776c108f',\n",
       "   'image_url': 'https://miro.medium.com/0*LxrVQie98hgHzUAQ.png',\n",
       "   'lang': 'en',\n",
       "   'is_series': False,\n",
       "   'is_locked': True,\n",
       "   'is_shortform': False,\n",
       "   'top_highlight': 'Indeed, the ratio of time spent reading versus writing is well over 10 to 1. We are constantly reading old code as part of the effort to write new code. ...[Therefore,] making it easy to read makes it easier to write.',\n",
       "   'content': {'id': 'c1fe776c108f',\n",
       "    'content': 'The comprehensive guide to Python project setup\\n\\nStart your project right and reap the rewards for years\\n\\n\\n\\nPython is a superb language used for everything from building websites to doing complex scientific research. But getting your project set up can be a challenge. That’s where this guide comes in! In this article, we’ll show you how to organize your project, set up virtual environments, manage dependencies, format your code, test your code, and more. We’ll cover everything you need to know to get your Python project off the ground and running smoothly.\\n\\nAbove all else, keep it simple\\n\\nPython is meant to be simple. Run import this in a Python REPL and you’ll get The Zen of Python.\\n\\n>>> import this\\nThe Zen of Python, by Tim Peters\\n\\nBeautiful is better than ugly.\\nExplicit is better than implicit.\\nSimple is better than complex.\\nComplex is better than complicated.\\nFlat is better than nested.\\nSparse is better than dense.\\nReadability counts.\\nSpecial cases aren\\'t special enough to break the rules.\\nAlthough practicality beats purity.\\nErrors should never pass silently.\\nUnless explicitly silenced.\\nIn the face of ambiguity, refuse the temptation to guess.\\nThere should be one-- and preferably only one --obvious way to do it.\\nAlthough that way may not be obvious at first unless you\\'re Dutch.\\nNow is better than never.\\nAlthough never is often better than *right* now.\\nIf the implementation is hard to explain, it\\'s a bad idea.\\nIf the implementation is easy to explain, it may be a good idea.\\nNamespaces are one honking great idea -- let\\'s do more of those!\\n\\nCreating a project that’s useful is easy. Creating a project that’s long-lasting is challenging. But we have guidance!\\n\\nIndeed, the ratio of time spent reading versus writing is well over 10 to 1. We are constantly reading old code as part of the effort to write new code. …[Therefore,] making it easy to read makes it easier to write.\\n\\nSource: Robert C. Martin, Clean Code: A Handbook of Agile Software Craftsmanship\\n\\nWhen setting up a Python project, it’s critical to set the standard of writing maintainable code - code with low cognitive overhead. Easy to read. Easy to find. Easy to follow.\\n\\nDirectory structure\\n\\nA well-maintained project starts with an approachable directory structure. Your goal here (and everywhere, really) is to reduce the friction for developers to understand what the code does.\\n\\nUse a root directory for your project. Create a root directory for your project and name it after your project. Name your project something sensible. I prefer naming projects and modules after what they do, and I avoid using codenames for things.\\n\\nUse subdirectories for your code. Organize your code into subdirectories based on logical components or modules. For example, you might have a subdirectory for your data processing code, a subdirectory for your visualization code, and so on.\\n\\nUse an __init__.py file in directories containing modules. If you have a directory containing Python modules, include an __init__.py file in the directory. This tells Python that the directory is a package and allows you to import modules from the package.\\n\\nUse descriptive names for your project, files, and directories. Use descriptive names that make it clear what each module, file, and directory contains. This will make it easier for others to understand your code and navigate your project (and easier for you after you put your project down for a few weeks).\\n\\nKeep your tests beside your code. Some engineers like to create a tests directory to write their tests. I prefer keeping tests right beside the code being tested. If you have a file named models/user.py, the test file should be models/user_test.py. This makes it clear where your code is and where your tests are, and it lets you keep them in the same cognitive space.\\n\\nUse a virtual environment. Use a virtual environment to manage your dependencies and ensure that your project runs consistently across different environments. More on that later.\\n\\nYou’ll often be working with frameworks or tools that may already have opinions on directory structure (I’m looking at you, Django). Or you may want to apply an MVC pattern to your project structure. Whatever you choose, make a plan and be consistent!\\n\\nVirtual environments\\n\\nA virtual environment is a self-contained Python environment that allows you to install packages and dependencies for your project without affecting the global Python installation on your system. Virtual environments are important because they help ensure that your project’s dependencies are consistent across different environments, making it easier to reproduce and maintain your project.\\n\\nTo set up a virtual environment for your project, you can use a tool like Poetry, virtualenv, or conda. Most tutorials and courses use virtualenv, so I’ll talk about that first.\\n\\nHere’s how to set up a virtual environment using virtualenv:\\n\\nInstall virtualenv. You can install virtualenv using pip, the Python package manager. Open your terminal and run pip install virtualenv.\\n\\nCreate a virtual environment. Navigate to your project directory and run virtualenv venv. This will create a new virtual environment in the current directory called venv.\\n\\nActivate the virtual environment. To activate the virtual environment, run source venv/bin/activate on Linux/Mac or venv\\\\Scripts\\\\activate on Windows.\\n\\nOnce you’ve activated the virtual environment, you can install packages and dependencies for your project using pip. The packages will get installed in your virtual environment but will not be available from the global Python environment on your system or from other Python projects using different virtual environments. When you’re done working on your project, you can deactivate the virtual environment by running deactivate in your terminal.\\n\\nI use Poetry to manage virtual environments for all of my Python projects. Here’s how to use Poetry:\\n\\nInstall Poetry. You can install Poetry by following the installation instructions on the Poetry website.\\n\\nCreate a new project. Navigate to the directory where you want to create your project and run poetry new myproject. This will create a new project directory called myproject with a basic project structure inside.\\n\\nActivate the virtual environment. To activate the virtual environment for your project, run poetry shell. This will create a new virtual environment and activate it. If you want to run a command in the virtual environment without activating it, use poetry run <command> like this: poetry run python main.py\\n\\nInstall packages and dependencies. To install packages and dependencies for your project, run poetry add package_name. This will install the package and add it to your project\\'s pyproject.toml file. More on this later.\\n\\nOnce you’ve installed your packages and dependencies, you can deactivate the virtual environment by running exit in your terminal.\\n\\nLearn more about Poetry →\\n\\nIf you’re using VS Code, you can also use Devcontainers as an alternative to virtual environments. Devcontainers are pre-configured environments that run inside Docker containers and allow you to develop and test your code in a consistent environment. I prefer Devcontainers as I work across multiple computers with 3 different operating systems. The Poetry + Devcontainer combination means I spend zero effort trying to make my code work on different systems. It always does.\\n\\nThere’s a great article by Dexter Williams on Python Devcontainers. Go check it out →\\n\\nGetting Started with Python 3 Dev Containers\\nA basic guide to getting started with Python 3 dev containersmedium.com\\n\\nDependencies\\n\\nProject dependencies are external packages or libraries (code that other people wrote) that your Python project uses to function properly. Dependencies can include things like web frameworks, database drivers, or machine learning libraries.\\n\\nInstead of copying code from other libraries into your own, Python (and most other languages) supports installing dependencies through a dependency management tool called pip. You can find projects available for installation at PyPI.org.\\n\\npip is a good tool. But it’s basic. On all my Python projects, I use poetry to manage dependencies. It’s the same tool I use to manage virtual environments.\\n\\nInstall Poetry with this command:\\n\\ncurl -sSL https://install.python-poetry.org | python3 -\\n\\nOnce that’s installed on your system, you can start a new project.\\n\\npoetry new myproject\\ncd myproject\\n\\nAdding dependencies to your project is just as simple as using pip.\\n\\npoetry add requests\\n\\npoetry saves all of your dependencies to pyproject.toml and pins them to a specific version in a poetry.lock file. This ensures you can replicate your project exactly across different environments.\\n\\nThere are a few other features that make poetry an easy choice. Their docs have an up-to-date feature list.\\n\\nUse poetry show - tree to see downstream dependencies.\\n\\nLearn more about Poetry →\\n\\nCode formatting\\n\\nCode formatting refers to the way that code is structured and styled, including things like indentation, line spacing, and naming conventions. While it may seem like a small detail, consistent and well-formatted code is fundamental for the long-term health of a project.\\n\\nConsistently-formatted code makes your code more readable and understandable for yourself and other developers who may be working on the project. When code is formatted consistently, it becomes easier to identify patterns and structures within the code. Consistently-formatted code is easier to read, understand, and maintain\\n\\nRemember our quote from Bob Martin? More time is spent reading code than writing it. If that code is formatted consistently, reading is a lot easier.\\n\\nTo that end, I always use black. There are other formatters out there. And black is not very configurable. But that’s it’s selling point. Any team that chooses to adopt black will get code that looks exactly the same everywhere. No arguing about formatting anymore because the choice has already been made. And it integrates with every code editor I’ve ever used.\\n\\npoetry add black --group dev\\n\\nStraight from the black docs:\\n\\nBy using Black, you agree to cede control over minutiae of hand-formatting. In return, Black gives you speed, determinism, and freedom from pycodestyle nagging about formatting. You will save time and mental energy for more important matters.\\n\\nLearn more about Black →\\n\\nCode linting\\n\\nCode linting and code formatting are related, but they are not the same thing.\\n\\nCode formatting refers to the way that code is structured and styled, including things like indentation, line spacing, and naming conventions. It’s about making sure that the code is easy to read and understand, which can make it easier to debug and maintain over time.\\n\\nOn the other hand, code linting involves analyzing the code for potential errors or issues that could cause problems. Linters look at things like syntax errors, unused variables, and other potential bugs, and can provide suggestions for how to fix them.\\n\\nMy linting tool of choice is pylint. It analyzes your Python codebase to identify potential errors and issues. Pylint also provides suggestions for how to fix these issues, along with a score that represents the overall quality of your codebase. This score can be used as a benchmark to help you identify areas where your code could be improved and make it easier to maintain over time.\\n\\npoetry add pylint --group dev\\n\\nPylint has a ton of configuration options. I suggest starting with the default set of configurations and adding exceptions as you and your team start working more with it.\\n\\nUsing pylint with black\\n\\nYou’re bound to have a few conflicts when using overlapping tools. Black calls this out in their docs and provides the solution: clear configuration.\\n\\nAs of today, there is only one conflicting style opinion between Pylint and Black: line length. You can set that for Pylint in your pyproject.toml.\\n\\n# pyproject.toml\\n[tool.pylint.format]\\nmax-line-length = \"88\"\\n\\nInterestingly, the Pylint codebase uses Black for its own internal formatting.\\n\\nLearn more about Pylint →\\n\\nTesting\\n\\nWhy testing is important\\n\\nTypes of tests you can write (e.g. unit tests, integration tests)\\n\\nTools you can use for testing (e.g. pytest, unittest)\\n\\nBest practices for writing and organizing tests\\n\\nTesting ensures your code is working as intended and catches potential issues before they become larger problems. Tests verify that individual components of your codebase are functioning correctly and that changes made to one part of the code don’t break other parts. This catches bugs and other issues early before they have a chance to cause major problems down the line.\\n\\nThe de facto standard for robust testing in Python is Pytest. Pytest comes with powerful features out of the box like detailed test failure output and a simple API. It also integrates with Django, Jupyter, and dozens more Python tools.\\n\\npoetry add pytest --group dev\\n\\nPlan ahead for successful testing in your project.\\n\\nUse a testing framework. Python has several, though I strongly recommend using Pytest. Using a testing framework makes it easier to write and manage your tests.\\n\\nWrite tests for each function and method. Write tests for each function and method in your codebase to ensure that they are working as intended. This makes it easier to identify and fix issues in your codebase as things change.\\n\\nUse descriptive test names. Give each test a name that describes what it is testing (e.g. test_user_can_authenticate). This makes it easier to understand what each test is doing and can help identify issues more quickly.\\n\\nUse setup and teardown methods. Use setup and teardown methods to set up any necessary test fixtures and clean up after each test. This ensures that tests are run in a clean environment and there are no lingering side effects from previous tests.\\n\\nOrganize your tests into test suites. Organize your tests into test suites based on their purpose or functionality. This makes it easier to run specific tests (or groups of tests) and can identify issues more quickly.\\n\\nContinuous integration and deployment (CI/CD)\\n\\nContinuous Integration (CI) and Continuous Deployment (CD) are processes that automate building, testing, and deploying code changes. CI is the process of automatically building and testing code changes as soon as they are committed to the code repository. CD is the process of automatically deploying code changes to production or staging environments once they pass the CI tests.\\n\\nCI/CD (together as a concept) is important because it catches issues early on in the development process and ensures code changes are safe to deploy to production. The key to success is these tools build, test, and deploy changes automatically. Developers don’t have to remember to apply these processes manually after each change, and they don’t get to choose. It just happens, and it just works.\\n\\nThere are lots of CI/CD tools, and the best one for your use case is probably the one most tightly integrated with your Git vendor (GitHub, GitLab, Bitbucket, etc.). The process is the same for any platform.\\n\\nPlan your CI/CD pipeline. This usually looks like \"Build → Test → Deploy\". Some of these steps might contain multiple substeps. For example, the \"Test\" step might include \"Unit tests\", \"Integration tests\", and \"Linter checks\".\\n\\nDefine your pipeline in config files. These files get committed to your project and are the code definitions of your CI/CD pipeline. Make them readable! Read the docs for GitHub Actions, GitLab Pipelines, or CircleCI. There are other great projects out there, too.\\n\\nTest your pipeline by committing code. Testing your configuration usually means running it via new commits to your project. Check that the output is what you expect, and adjust the config files as necessary.\\n\\nPlease let me know your thoughts about this article! Add a few claps if you think it’s worth it, and drop your thoughts in a reply. Follow Jacob Bennett and Level Up Coding for more in-depth Python education 🐍\\n\\nLevel Up Coding\\n\\nThanks for being a part of our community! Before you go:\\n\\n👏 Clap for the story and follow the author 👉\\n\\n📰 View more content in the Level Up Coding publication\\n\\n💰 Free coding interview course ⇒ View Course\\n\\n🔔 Follow us: Twitter | LinkedIn | Newsletter\\n\\n🚀👉 Join the Level Up talent collective and find an amazing job'}},\n",
       "  {'id': '9418515a315a',\n",
       "   'title': 'The 5 paid subscriptions I actually use in 2023 as a software engineer',\n",
       "   'subtitle': 'Tools I use that are cheaper than Netflix',\n",
       "   'author': '630ab5ffdf27',\n",
       "   'publication_id': '9758482ba857',\n",
       "   'published_at': '2023-03-25 17:01:41',\n",
       "   'last_modified_at': '2023-03-25 17:01:41',\n",
       "   'tags': ['programming',\n",
       "    'technology',\n",
       "    'education',\n",
       "    'data-science',\n",
       "    'software-development'],\n",
       "   'topics': ['programming'],\n",
       "   'claps': 4606,\n",
       "   'voters': 1554,\n",
       "   'word_count': 665,\n",
       "   'responses_count': 47,\n",
       "   'reading_time': 3.3427672955974845,\n",
       "   'url': 'https://medium.com/geekculture/the-5-paid-subscriptions-i-actually-use-in-2023-as-a-software-engineer-9418515a315a',\n",
       "   'unique_slug': 'the-5-paid-subscriptions-i-actually-use-in-2023-as-a-software-engineer-9418515a315a',\n",
       "   'image_url': 'https://miro.medium.com/1*pB-JOp4O5Q1jUj3YX4ca8w.png',\n",
       "   'lang': 'en',\n",
       "   'is_series': False,\n",
       "   'is_locked': True,\n",
       "   'is_shortform': False,\n",
       "   'top_highlight': 'Bonus: Excalidraw',\n",
       "   'content': {'id': '9418515a315a',\n",
       "    'content': 'The 5 paid subscriptions I actually use in 2023 as a software engineer\\n\\nTools I use that are cheaper than Netflix\\n\\nI care a lot about the tools I use. Especially when they aren’t free.\\n\\nSome tools are too good to keep to myself. I have to share them! Here’s what I’ve spent my money on in 2022–23 that has genuinely improved my life as a software engineer.\\n\\nPlease note: None of the links in this article are affiliate links.\\n\\n1. GitHub Copilot: an AI pair programmer\\n\\nWhen I’m writing code, Copilot works in the background by reading what I’ve written and quietly suggesting what I might want to write next.\\n\\nCopilot has improved my productivity by at least 30%.\\n\\nGitHub Copilot code suggestions\\n\\nMy biggest productivity improvements have come from:\\n\\nWriting test cases. Most of the time I write the name for the test case and Copilot fills out everything else.\\n\\nSmall things I would have to look up. e.g. Instead of searching for the correct RegEx to parse a string, I write a comment explaining what I want the RegEx to do and Copilot writes the RegEx for me.\\n\\nLearn more about GitHub Copilot.\\n\\n2. Kagi: a better search engine than Google\\n\\nI measure the effectiveness of searches by how long it takes me to find what I was actually looking for. By that measure, Google has been steadily getting worse.\\n\\nWhen I search for something on Kagi, the correct result is in the first 2 links 95% of the time. It’s in the top 5 links 99% of the time. That just doesn’t happen with Google, Bing, etc.\\n\\nThe consistently great results page is further boosted by the search personalization I control. I’ve told Kagi that any results from Stack Overflow or Medium should be weighted higher, as well as blocked other sites I don’t care to see results from.\\n\\nLearn more about Kagi.\\n\\n3. Midjourney: AI-generated images\\n\\nAs a back-end software engineer, I rarely have to deal with creating or editing images (besides diagrams - for that there’s Excalidraw). But lately I’ve been needing them more. Maybe I’m a hammer looking for a nail? Still, though, image creation is not something I’ve learned a great deal about.\\n\\nI’m not a photoshop wizard. But I do know how to use Discord!\\n\\n\\n\\nMidjourney integrates with Discord to bring AI image generation straight to a chat. It took me 3 minutes to create the game square below, iterating on a few results and finally choosing one (I never altered my prompt).\\n\\nGenerated game terrain by Midjourney (prompt: \"isometric diaroma of a forest kingdom, large game map, clean SVG vector\")\\n\\nI do end up needing lots of images when I’m writing technical articles on Medium. Instead of Unsplash images for my articles, I prefer making my own with Midjourney.\\n\\nLearn more about Midjourney.\\n\\n4. Scribd: a huge library of eBooks and audiobooks (and more)\\n\\nScribd is a paid library of popular eBooks, audiobooks, magazines, and more. Their library is constantly updated, and everything comes with a single subscription (vs. Audible where you pay per title).\\n\\nI listen to audiobooks as I travel, and I often read eBooks in my (increasingly rare) down time at home. Scribd has been a steady subscription for years, and I’ve grown tremendously from it.\\n\\nLearn more about Scribd.\\n\\n5. Medium: knowledge-sharing with other professionals\\n\\nMy favorite platform for learning from other people in my field is this blogging platform (Medium). Here you can read thousands of premium articles about programming, data science, technology, and more.\\n\\nThe Medium.com landing page\\n\\nI’ve been a fan of Medium for years, and I finally got the chance to work for them starting in 2022 (yes, full disclosure, I work here…but I really love the platform!).\\n\\nLearn more about Medium.\\n\\nBonus: Excalidraw\\n\\nWe use diagrams extensively at Medium Engineering. Most of our diagrams are created in Excalidraw, which makes them clean, fun, and editable.\\n\\n\\n\\nLearn more about Excalidraw.\\n\\nI care a lot about spending money on things that improve my life. These tools bring tremendous value to me as a software engineer. Consider adding these to your toolbox!'}},\n",
       "  {'id': 'ae06c6f24827',\n",
       "   'title': 'Solution to LeetCode #1: Two Sum (Python)',\n",
       "   'subtitle': 'Top 0.2% of solutions',\n",
       "   'author': '630ab5ffdf27',\n",
       "   'publication_id': '*Self-Published*',\n",
       "   'published_at': '2023-03-18 06:23:34',\n",
       "   'last_modified_at': '2023-03-30 03:07:10',\n",
       "   'tags': ['python',\n",
       "    'programming',\n",
       "    'software-development',\n",
       "    'leetcode',\n",
       "    'leetcode-easy'],\n",
       "   'topics': ['programming'],\n",
       "   'claps': 10,\n",
       "   'voters': 6,\n",
       "   'word_count': 976,\n",
       "   'responses_count': 0,\n",
       "   'reading_time': 4.233018867924528,\n",
       "   'url': 'https://jacobistyping.medium.com/solution-to-leetcode-1-two-sum-python-ae06c6f24827',\n",
       "   'unique_slug': 'solution-to-leetcode-1-two-sum-python-ae06c6f24827',\n",
       "   'image_url': 'https://miro.medium.com/1*TBZxhGJLzO1V4BjJuz_u-w.png',\n",
       "   'lang': 'en',\n",
       "   'is_series': False,\n",
       "   'is_locked': True,\n",
       "   'is_shortform': False,\n",
       "   'top_highlight': '',\n",
       "   'content': {'id': 'ae06c6f24827',\n",
       "    'content': \"Solution to LeetCode #1: Two Sum (Python)\\n\\nTop 0.2% of solutions\\n\\n\\n\\nThis is an easy LeetCode problem (source).\\n\\nJump to the solutions ↓\\n\\nGiven an array of integers nums and an integer target, return indices of the two numbers such that they add up to target.\\n\\nYou may assume that each input would have exactly one solution, and you may not use the same element twice.\\n\\nYou can return the answer in any order.\\n\\nExample 1:\\n\\nInput: nums = [2,7,11,15], target = 9\\nOutput: [0,1]\\nExplanation: Because nums[0] + nums[1] == 9, we return [0, 1].\\n\\nExample 2:\\n\\nInput: nums = [3,2,4], target = 6\\nOutput: [1,2]\\n\\nExample 3:\\n\\nInput: nums = [3,3], target = 6\\nOutput: [0,1]\\n\\nConstraints:\\n\\n2 <= nums.length <= 104\\n\\n-109 <= nums[i] <= 109\\n\\n-109 <= target <= 109\\n\\nOnly one valid answer exists.\\n\\nFollow-up: Can you come up with an algorithm that is less than O(n2) time complexity?\\n\\nThe obvious solution - O(n²)\\n\\nAt first glance, the solution might jump out at you: loop over the array twice and add the numbers at the current index. Check the result against the target and return.\\n\\nLet’s write that out.\\n\\nFirst we need to loop over the nums list to look at each element in the list.\\n\\nfor i, i_num in enumerate(nums):\\n    # ...\\n\\nWe use the built-in enumerate function to return the index and value of list items at the same time (read the docs).\\n\\nOnce we’re inside that loop, we need to check the list again so we can get a second number to add to the first.\\n\\nfor i, i_num in enumerate(nums):\\n    for j, j_num in enumerate(nums):\\n        # ...\\n\\nOne of the problem requirements stated that we may not use the same element twice. Let’s add some logic to check if we’re looking at the same element and skip to the next element using continue.\\n\\nif i == j:\\n    continue\\n\\nThe last thing we need to do is check if the 2 numbers we’re currently looking at add up to the target number. If they do, we found our answer. (Make sure to return the indexes of the numbers, not the numbers themselves.)\\n\\nif i_num + j_num == target:\\n    return [i, j]\\n\\nPutting that all together we get a pretty small function.\\n\\nclass Solution:\\n    def twoSum(self, nums: List[int], target: int) -> List[int]:\\n\\n        # loop over the list once\\n        for i, i_num in enumerate(nums):\\n\\n            # loop over the list again\\n            for j, j_num in enumerate(nums):\\n\\n                # we can't use the same index twice,\\n                # so if both loops are looking at the\\n                # same index then just skip it\\n                if i == j:\\n                    continue\\n\\n                # if the sum of the two numbers matches\\n                # the target, we found our answer\\n                if i_num + j_num == target:\\n                    return [i, j]\\n\\nThis solution works, meets all of the criteria, and is easy to read. Definitely a great submission! But the complexity is O(n²), and we can do better.\\n\\n\\n\\nGoing further - O(n)\\n\\nWe can bring this down to O(n) complexity by not nesting our loops. We still need to look through the list twice since we need to compare 2 numbers. Nested loops increase our complexity exponentially, but sequential loops do not. Since O(n) == O(2n) we can use multiple loops in a row (not nested) to check our list. A more efficient way to solve this uses a hashmap (there’s a great explanation of hashmaps at Stack Overflow).\\n\\nBefore we start, let’s decide how we’ll be looking at each item.\\n\\nIn our original solution, we added 2 numbers together and compared the result with a target.\\n\\ntarget = num_1 + num_2\\n\\nWe can use the concept of a complement and move variables around to be more useful to us.\\n\\ntarget - num1 = num2\\n\\nLet’s rename those variables so we have some common language to talk about them.\\n\\ntarget - currentValue = complement\\n\\nLet’s come back to this in just a bit.\\n\\nOur first step is to declare a hashmap that allows us to query in constant time what the index of each item is. We’ll be putting the nums in here as we see them, so we’ll call this seen_nums.\\n\\nseen_nums = {}\\n\\nNow let’s loop over the nums array again and bring in that equation from before. Once again we’ll use Python’s enumerate function to get the index and value of the items in the list as we iterate over it.\\n\\nfor idx, num in enumerate(nums):\\n    complement = target - num\\n\\nNice! Since we have a complement we can look up that value in the hashmap. If that value exists in the hashmap we have a potential answer for our problem. If it doesn’t exist, save the number to seen_nums and move on to the next number.\\n\\nif complement not in seen_nums:\\n    seen_nums[num] = idx\\n    continue\\n\\nAs part of our problem requirements, we have to make sure we don’t use the same index twice. Let’s put that check in place.\\n\\ncomplement_idx = seen_nums[complement]\\nif complement_idx == idx:\\n    continue\\n\\nOnce we pass that, we have our answer.\\n\\nreturn [seen_nums[complement], idx]\\n\\nPutting it all together, we get a function that’s a bit longer than our first solution. With some good variable names it’s just as readable.\\n\\nclass Solution:\\n    def twoSum(self, nums: List[int], target: int) -> List[int]:\\n        # create a hashmap to store a map of numbers to their indexes\\n        seen_nums = {}\\n\\n        # loop over the list of numbers \\n        for idx, num in enumerate(nums):\\n\\n            # calculate the current number's complement\\n            complement = target - num\\n\\n            # check if the complement is available in our hashmap\\n            if complement not in seen_nums:\\n                seen_nums[num] = idx\\n                continue\\n            \\n            # the complement is in our hashmap, but we\\n            # can't use the same element twice so let's check\\n            complement_idx = seen_nums[complement]\\n            if complement_idx == idx:\\n                continue\\n            \\n            # the complement exists and is the correct answer\\n            return [seen_nums[complement], idx]\"}}],\n",
       " 'b856005e5ecd': [{'id': 'ded34fccd16a',\n",
       "   'title': '100x Faster\\u200a—\\u200aScaling Your RAG App for Billions of Embeddings',\n",
       "   'subtitle': 'Computing Cosine Similarity in parallel',\n",
       "   'author': 'b856005e5ecd',\n",
       "   'publication_id': '5517fd7b58a6',\n",
       "   'published_at': '2024-02-15 12:16:47',\n",
       "   'last_modified_at': '2024-02-15 12:16:47',\n",
       "   'tags': ['data-science',\n",
       "    'python',\n",
       "    'chatgpt',\n",
       "    'large-language-models',\n",
       "    'coding'],\n",
       "   'topics': ['machine-learning', 'data-science', 'programming'],\n",
       "   'claps': 276,\n",
       "   'voters': 38,\n",
       "   'word_count': 2310,\n",
       "   'responses_count': 0,\n",
       "   'reading_time': 9.966981132075471,\n",
       "   'url': 'https://levelup.gitconnected.com/100x-faster-scaling-your-rag-app-for-billions-of-embeddings-ded34fccd16a',\n",
       "   'unique_slug': '100x-faster-scaling-your-rag-app-for-billions-of-embeddings-ded34fccd16a',\n",
       "   'image_url': 'https://miro.medium.com/1*4Ry1nUyUXjrDE9L2GDRwEg.png',\n",
       "   'lang': 'en',\n",
       "   'is_series': False,\n",
       "   'is_locked': False,\n",
       "   'is_shortform': False,\n",
       "   'top_highlight': '',\n",
       "   'content': {'id': 'ded34fccd16a',\n",
       "    'content': 'Created using Stable Diffusion 2.1\\n\\n100x Faster - Scaling Your RAG App for Billions of Embeddings\\n\\nComputing Cosine Similarity in parallel\\n\\nAmong the biggest problems with RAG applications is their computation retrieval time. Imagine you have a vector database of a trillion records of embedding vectors. When you try to match a user query with a trillion vectors, it is surely going to take more than a minute to retrieve the correct information.\\n\\nCan we reduce the time to seconds for retrieving correct information using parallel processing on CPU cores?\\n\\nReducing the time involves finding efficient methods for calculating cosine similarity between user query embedding vector and the million, billion, or even trillion other embedding vectors stored in your vector database.\\n\\nChunkdot, under the MIT license, is specifically designed for this purpose, offering multi-threaded matrix multiplication for both dense and sparse matrices. It’s suitable for computing the K most similar items for a large number of items by segmenting the item matrix representation (embeddings) and using Numba to accelerate the calculations.\\n\\nChunkdot GitHub Repository\\n\\nGitHub - rragundez/chunkdot: Multi-threaded matrix multiplication and cosine similarity…\\nMulti-threaded matrix multiplication and cosine similarity calculations for dense and sparse matrices. Appropriate for…github.com\\n\\nThere are many datasets available on HuggingFace that provide embedding vectors of over one million entries such as this dataset from Qdrant. You can use it to test Chunkdot performance. However, for a detailed performance measurement, we will be using the NumPy library to generate random embedding vectors of various dimensions.\\n\\nWe will compare two approaches, one from Chunkdot and the second, a pseudocode of cosine similarity. We’ll observe how performance is affected by increasing the size and dimension. I’ll be using a Kaggle (No GPU) Notebook for this task to ensure consistency.\\n\\nAll the code for this blog is available in my GitHub repository.\\n\\nGitHub - FareedKhan-dev/speed_up_your_RAG_app\\nContribute to FareedKhan-dev/speed_up_your_RAG_app development by creating an account on GitHub.github.com\\n\\nTable of Contents\\n\\nSetting the stage\\n\\nCoding Pseudocode Algorithm\\n\\nCoding Chunkdot Algorithm\\n\\nCoding Computation Time Function\\n\\nTesting for 10k Vector Embeddings\\n\\nTesting for 100k Vector Embeddings\\n\\nTesting for 1 Million Vector Embeddings\\n\\nVisualizing Scalability Impact\\n\\nFeatures of Chunkdot\\n\\nWhat’s Next\\n\\nSetting the stage\\n\\nChunkdot requires a similar installation process as any other library.\\n\\n# installing chunkdot\\npip install chunkdot\\n\\nBefore running anything, we must first check the available memory in our Kaggle environment.\\n\\n# Checking available memory\\n!free -h\\n\\nAvailable memory in Kaggle Notebook\\n\\nChecking available memory is crucial for Chunkdot. As the vector database size increases, so does the computation memory. To prevent exceeding the available memory, it’s important to monitor the remaining memory in our hardware. In my case the free space is 25GB excluding Buff/Cache.\\n\\nLet’s import the necessary libraries.\\n\\n# to matrix generate matrices\\nimport numpy as np\\n\\n# importing cosine similarity module from chunkdot\\nfrom chunkdot import cosine_similarity_top_k\\n\\n# to calculate computation time\\nimport timeit\\n\\nCoding Pseudocode Algorithm\\n\\nWe will first construct a pseudocode algorithm that calculates cosine similarities between the user query vector with other millions of vectors that may be stored in the database or locally.\\n\\ndef cosine_pseudocode(query_v, doc_v, num_indices):\\n    \"\"\"\\n    Retrieve indices of the highest cosine similarity values between\\n    the query vector and embeddings.\\n    \\n    Parameters:\\n        query_v (numpy.ndarray): Query vector.\\n        doc_v (list of numpy.ndarray): List of embedding vectors.\\n        num_indices (int): Number of Top indices to retrieve.\\n        \\n    Returns:\\n        list of int: Indices of the highest cosine similarity values.\\n    \"\"\"\\n    cosine_similarities = []  # Initialize an empty list to store cosine similarities\\n\\n    query_norm = np.linalg.norm(query_v)  # Calculate the norm of the query vector\\n    \\n    # Iterate over each documents embedding vectors in the list\\n    for vec in doc_v:\\n        dot_product = np.dot(vec, query_v.T)  # Calculate dot product between embedding vector and query vector\\n        embedding_norm = np.linalg.norm(vec)  # Calculate the norm of the embedding vector\\n        cosine_similarity = dot_product / (embedding_norm * query_norm)  # Calculate cosine similarity\\n        cosine_similarities.append(cosine_similarity)  # Append cosine similarity to the list\\n    \\n    cosine_similarities = np.array(cosine_similarities)  # Convert the list to a numpy array\\n    \\n    # Sort the array in descending order\\n    sorted_array = sorted(range(len(cosine_similarities)), key=lambda i: cosine_similarities[i], reverse=True)\\n\\n    # Get indices of the top two values\\n    top_indices = sorted_array[:num_indices]\\n    \\n    # Return the indices of highest cosine similarity values\\n    return top_indices\\n\\nThis cosine similarity function, independent of any library except NumPy, takes three inputs:\\n\\nquery_v the embedding vector of the user query\\n\\ndoc_v the embedding vectors of documents stored somewhere\\n\\nnum_indices the index number from documents for similar top_k results\\n\\nCoding Chunkdot Algorithm\\n\\nNow that we’ve coded the pseudocode algorithm, the next step is to code the Chunkdot cosine similarity function.\\n\\ndef cosine_chunkdot(query_v, doc_v, num_indices, max_memory):\\n    \"\"\"\\n    Calculate cosine similarity using the chunkdot library.\\n    \\n    Parameters:\\n        query_v (numpy.ndarray): Query vector.\\n        doc_v (numpy.ndarray): List of Embedding vectors.\\n        num_indices (int): Number of top indices to retrieve.\\n        max_memory (float): Maximum memory to use.\\n        \\n    Returns:\\n        numpy.ndarray: Top k indices.\\n    \"\"\"\\n    \\n    # Calculate Cosine Similarity\\n    cosine_array = cosine_similarity_top_k(embeddings=query_v, embeddings_right=doc_v, \\n                                          top_k=num_indices, max_memory=max_memory)  # Calculate cosine similarity using chunkdot\\n\\n    # Get indices of the top values\\n    top_indices = cosine_array.nonzero()[1]\\n    \\n    # return the top similar results\\n    return top_indices\\n\\nThis Chunkdot function takes four inputs:\\n\\nquery_v the embedding vector of the user query\\n\\ndoc_v the embedding vectors of documents stored somewhere\\n\\nnum_indices the index number from documents for similar top_k results\\n\\nmax_memory represents the available memory you have for computation, with the value in bytes. For example, 1E9 means 1GB, and 10E9 means 10GB, and so on.\\n\\nLet’s test both of our functions on a sample dataset to observe their outputs.\\n\\ndoc_embeddings = np.random.randn(10, 100) # 10 document embeddings (100 dim)\\n\\nuser_query = np.random.rand(1,100) # 1 user query (100 dim)\\n\\ntop_indices = 1 # number of top indices to retrieve\\n\\nmax_memory = 5E9 # maximum memory to use (5GB)\\n\\n# retrieve indices of the highest cosine similarity values using pseudocode\\nprint(\"top indices using pseudocode:\", cosine_pseudocode(user_query, doc_embeddings, top_indices))\\n\\n# retrieve indices of the highest cosine similarity values using chunkdot\\nprint(\"top indices using chunkdot:\", cosine_chunkdot(user_query, doc_embeddings, top_indices, max_memory))\\n\\n### OUTPUT ###\\ntop indices using pseudocode: [4]\\ntop indices using chunkdot: [4]\\n### OUTPUT ###\\n\\nI’ve generated 10 random embedding vectors for document embeddings, each of dimension 100, and a user query which is a single embedding vector having the same dimension. The top_indices parameter is set to 1, which means it will return the index of only one similar item from the document embeddings based on the highest cosine similarity. Memory usage has been set to 5E9, which is equal to 5GB. Both of our functions return the same index, 4, indicating that we have accurately coded both functions.\\n\\nCoding Computation Time Function\\n\\nWe also need to create a timing function that can measure the computation time taken by both of these functions to output the results.\\n\\n# calculate time taken\\ndef calculate_execution_time(query_v, doc_v, num_indices, max_memory, times):\\n    \\n    # calculate time taken to execute the pseudocode function\\n    pseudocode_time = round(timeit.timeit(lambda: cosine_pseudocode(query_v, doc_v, num_indices), number=times), 5)\\n\\n    # calculate time taken to execute the chunkdot function\\n    chunkdot_time = round(timeit.timeit(lambda: cosine_chunkdot(query_v, doc_v, num_indices, max_memory), number=times), 5)\\n\\n    # print the time taken\\n    print(\"Time taken for pseudocode function:\", pseudocode_time, \"seconds\")\\n    print(\"Time taken for chunkdot function:\", chunkdot_time, \"seconds\")\\n\\nWe’ve already reviewed the parameters being passed into this function. The only new parameter here is times, which tells the function how many times you want to run the code. Let’s test the efficiency of Chunkdot performance on a larger scale.\\n\\nTesting for 10k Vector Embeddings\\n\\nWe will begin with a reasonable number of document embeddings, 10000, which is comparable to a small-scale domain-specific RAG application. I have set the dimension of each embedding vector as1536 , which is equivalent to OpenAI embedding model text-embedding-3-small .\\n\\nLet’s calculate the computational time for each approach by running them 100 times.\\n\\ndoc_embeddings = np.random.randn(10000, 1536) # 10K document embeddings (1536 dim)\\n\\nuser_query = np.random.rand(1,1536) # user query (1536 dim)\\n\\ntop_indices = 1 # number of top indices to retrieve \\n\\nmax_memory = 5E9 # maximum memory set to 5GB\\n\\n# compute the time taken to execute the functions\\ncalculate_execution_time(user_query, doc_embeddings, top_indices, max_memory, 100)\\n\\nFor 10k document embeddings, dimension of 1536, running both the algorithms 100 times, here it the comparison:\\n\\n10k documents computation time\\n\\nChunkdot takes more time compared to our pseudocode. This is because it first creates chunks and performs computation on each chunk before merging them. Therefore, for this small-scale example, it may not be a suitable solution. However, you will see the benefits of Chunkdot when we work with a larger example later on.\\n\\nTesting for 100k Vector Embeddings\\n\\nFor 10K our pseudocode approach wins but now let’s increase our document embedding vectors upto 100K vectors, which is comparable to a mid-scale RAG application.\\n\\nLet’s calculate the computational time for each approach, but this time we are setting the times parameter to 1 (running the code for once) because the number of vectors is quite large, and there is no need to perform the calculation multiple times.\\n\\ndoc_embeddings = np.random.randn(100000, 1536) # 100K document embeddings (1536 dim)\\n\\nuser_query = np.random.rand(1,1536) # user query (1536 dim)\\n\\ntop_indices = 1 # number of top indices to retrieve \\n\\nmax_memory = 5E9 # maximum memory set to 5GB\\n\\ntimes = 1 # number of times to execute the functions\\n\\n# compute the time taken to execute the functions\\ncalculate_execution_time(user_query, doc_embeddings, top_indices, max_memory, times)\\n\\nFor 100k document embeddings, dimension of 1536, running both the algorithms single time, here it the comparison:\\n\\n100k documents computation time\\n\\nChunkdot takes less time compared to our pseudocode, almost half. Now we are seeing the promising impact of Chunkdot.\\n\\nTesting for 1 Million Vector Embeddings\\n\\nWorking with a task involving millions of embeddings, the first thing you need to check is how much memory the document embedding vectors occupy.\\n\\n# 1 Million document embeddings (1536 dim)\\ndoc_embeddings = np.random.randn(1000000, 1536)\\n\\n# user query (1536 dim)\\nuser_query = np.random.rand(1,1536)\\n\\n# Check the memory size of doc_embeddings and user_query embedding\\nprint(doc_embeddings.nbytes / (1024 * 1024 * 1024),\\n      user_query.nbytes / (1024 * 1024))\\n\\nMemory size of 1 Million embedding vectors\\n\\nOur document embeddings approximately take up 12GB. Let’s check the remaining space available.\\n\\nChecking available free space\\n\\nWe have available memory of up to 17GB. To avoid any memory errors, we will set a safe value for the max_memory parameter, i.e., 12GB. Let’s see the results.\\n\\n# 1 Million document embeddings (1536 dim)\\ndoc_embeddings = np.random.randn(1000000, 1536)\\n\\n# user query (1536 dim)\\nuser_query = np.random.rand(1,1536)\\n\\ntop_indices = 1 # number of top indices to retrieve \\n\\nmax_memory = 12E9 # maximum memory set to  --- 12GB ---\\n\\ntimes = 1 # number of times to execute the functions\\n\\n# compute the time taken to execute the functions\\ncalculate_execution_time(user_query, doc_embeddings, top_indices, max_memory, times)\\n\\n1 Million documents computation time\\n\\nChunkDot does indeed reduce computation effectively. When you’re aiming to build a serious RAG app, you should consider starting with at least a million queries. Working with embedding models of higher dimensions, up to 4000. This approach will become even more efficient.\\n\\nVisualizing Scalability Impact\\n\\nLet’s visualize the impact of increasing the number of document embedding vectors, starting from 10,000 to a very large number.\\n\\nComputation time for different number of documents\\n\\nI plotted three methods, and Chunkdot is the most superior among all based on increasing the number of document embeddings. Now, let’s see how the dimension of embedding vectors affects computation time.\\n\\nComputation time for different dimensions\\n\\nI used 100K documents while increasing the dimension of vectors, and the same behavior was observed as we saw when increasing the number of documents.\\n\\nFeatures of Chunkdot\\n\\nChunkdot has a feature where you can display a progress bar, which helps you keep track of how much computation is remaining.\\n\\ndoc_embeddings = np.random.randn(100000, 1536) # 100K document embeddings (1536 dim)\\n\\nuser_query = np.random.rand(1,1536) # user query (1536 dim)\\n\\ntop_indices = 100 # number of top indices to retrieve \\n\\nmax_memory = 5E9 # maximum memory set to 5GB\\n\\n# with progress bar\\noutput_array = cosine_similarity_top_k(user_query, doc_embeddings, \\n                        top_k=top_indices, \\n                        show_progress=True)\\n\\nprogress bar example\\n\\nThe output of Chunkdot is a sparse matrix, which you can convert into an array using:\\n\\n# converting the ouput\\noutput_array.toarray()\\n\\nYou can use Chunkdot for only document embeddings, which will return the top_k most similar elements for each element of document embeddings.\\n\\n# total 5 documents embeddings\\nembeddings = np.random.randn(5, 256)\\n\\n# return top 2 most similar item index for each\\ncosine_similarity_top_k(embeddings, top_k=2).toarray()\\n\\n### OUTPUT ###\\narray([[1.        , 0.        , 0.        , 0.        , 0.09924064],\\n       [0.        , 1.        , 0.        , 0.09935381, 0.        ],\\n       [0.02358785, 0.        , 1.        , 0.        , 0.        ],\\n       [0.        , 0.09935381, 0.        , 1.        , 0.        ],\\n       [0.09924064, 0.        , 0.        , 0.        , 1.        ]])\\n### OUTPUT ###\\n\\nSimilarly you can return the top most dissimilar items by providing negative value to top_k parameter\\n\\n# total 5 documents embeddings\\nembeddings = np.random.randn(5, 256)\\n\\n# return top 2 most dissimilar item index for each \\n# Top_K = -2\\ncosine_similarity_top_k(embeddings, top_k=-2).toarray()\\n\\n### OUTPUT ###\\narray([[ 0.        ,  0.        , -0.04357524,  0.        , -0.05118288],\\n       [ 0.        ,  0.        ,  0.        ,  0.01619543, -0.01836534],\\n       [-0.04357524,  0.        ,  0.        , -0.02466613,  0.        ],\\n       [ 0.        ,  0.01619543, -0.02466613,  0.        ,  0.        ],\\n       [-0.05118288, -0.01836534,  0.        ,  0.        ,  0.        ]])\\n### OUTPUT ###\\n\\nThis may not be your case, but in case you handle sparse embeddings up to a dimension of 10K, you can use the density parameter to reduce the computation more efficiently.\\n\\n# for creating sparse embeddings\\nfrom scipy import sparse\\n\\n# creating spare matrix with 100K documents (10K dim each)\\n# defining density of 0.005\\nembeddings = sparse.rand(100000, 10000, density=0.005)\\n\\n# using all you system\\'s memory\\ncosine_similarity_top_k(embeddings, top_k=50)\\n\\nWhat’s Next\\n\\nIf you want to learn how the Chunkdot algorithm works, check out this amazing blog from the author. One of the biggest benefits of Chunkdot is that it works on CPU cores. In the future, they plan to integrate GPU support, which will significantly reduce the time for calculations. In case your local environment does not have enough RAM, you can use platforms like Kaggle or GitHub Codespaces, where cloud CPU cores and RAM come at a very low cost compared to GPU costs. Don’t forget to check out the official GitHub repository along with their blog, as it explains extremely well how Chunkdot works.'}},\n",
       "  {'id': 'f612398f06c2',\n",
       "   'title': 'Building a Million-Parameter LLM from Scratch Using Python',\n",
       "   'subtitle': 'A Step-by-Step Guide to Replicating LLaMA Architecture',\n",
       "   'author': 'b856005e5ecd',\n",
       "   'publication_id': '5517fd7b58a6',\n",
       "   'published_at': '2023-12-07 14:55:24',\n",
       "   'last_modified_at': '2023-12-19 04:25:11',\n",
       "   'tags': ['artificial-intelligence',\n",
       "    'python',\n",
       "    'data-science',\n",
       "    'chatgpt',\n",
       "    'deep-learning'],\n",
       "   'topics': [],\n",
       "   'claps': 2426,\n",
       "   'voters': 645,\n",
       "   'word_count': 6094,\n",
       "   'responses_count': 31,\n",
       "   'reading_time': 24.796226415094342,\n",
       "   'url': 'https://levelup.gitconnected.com/building-a-million-parameter-llm-from-scratch-using-python-f612398f06c2',\n",
       "   'unique_slug': 'building-a-million-parameter-llm-from-scratch-using-python-f612398f06c2',\n",
       "   'image_url': 'https://miro.medium.com/1*ox3hToPFUWxAwURxYEXiGg.jpeg',\n",
       "   'lang': 'en',\n",
       "   'is_series': False,\n",
       "   'is_locked': False,\n",
       "   'is_shortform': False,\n",
       "   'top_highlight': '# Definition of a basic neural network class\\nclass SimpleBrokenModel(nn.Module):\\n    def __init__(self, config=MASTER_CONFIG):\\n\\n        # Rest of the code        \\n        ... \\n\\n        # Forward pass function for the base model\\n        def forward(self, idx, targets=None):\\n            # Embedding layer converts character indices to vectors\\n            x = self.embedding(idx)\\n            \\n            # Linear layers for modeling relationships between features\\n            a = self.linear(x)\\n            \\n            # Apply softmax activation to obtain probability distribution\\n            logits = F.softmax(a, dim=-1)\\n\\n            # If targets are provided, calculate and return the cross-entropy loss\\n            if targets is not None:\\n                # Reshape logits and targets for cross-entropy calculation\\n                loss = F.cross_entropy(logits.view(-1, self.config[\\'vocab_size\\']), targets.view(-1))\\n                return logits, loss\\n\\n            # If targets are not provided, return the logits\\n            else:\\n                return logits\\n\\n        # Print the total number of model parameters\\n        print(\"Model parameters:\", sum([m.numel() for m in self.parameters()]))',\n",
       "   'content': {'id': 'f612398f06c2',\n",
       "    'content': 'Building a Million-Parameter LLM from Scratch Using Python\\n\\nA Step-by-Step Guide to Replicating LLaMA Architecture\\n\\nImage from GoogleDeepMind (Open Source available on pexels)\\n\\nMaking your own Large Language Model (LLM) is a cool thing that many big companies like Google, Twitter, and Facebook are doing. They release different versions of these models, like 7 billion, 13 billion, or 70 billion. Even smaller communities are doing it too. You might have read blogs or watched videos on creating your own LLM, but they usually talk a lot about theory and not so much about the actual steps and code.\\n\\nIn this blog, I’ll try to make an LLM with only 2.3 million parameters, and the interesting part is we won’t need a fancy GPU for it. We’ll follow a LLaMA 1 Paper Approach to guide us. Don’t worry; we’ll keep it simple and use a basic dataset so you can see how easy it is to create your own million-parameter LLM.\\n\\nCheck out my new blog where I solve the transformers architecture by hand using matrix multiplications. I break it down step by step so you can easily grasp the concepts:\\n\\nUnderstanding Transformers from Start to End - A Step-by-Step Math Example\\nWe will be using a simple dataset and performing numerous matrix multiplications to solve the encoder and decoder parts…medium.com\\n\\nTable of Contents\\n\\n· Prerequisites\\n· Understanding the Transformer Architecture of LLaMA\\n ∘ Pre-normalization Using RMSNorm\\n ∘ SwiGLU Activation Function\\n ∘ Rotary Embeddings (RoPE)\\n· Setting the Stage\\n· Data Preprocessing\\n· Evaluation Strategy\\n· Setting Up a Base Neural Network Model\\n· Replicating LLaMA Architecture\\n ∘ RMSNorm for pre-normalization\\n ∘ Rotary Embeddings\\n ∘ SwiGLU activation function\\n· Experimenting with hyperparameters \\n· Saving Your Language Model (LLM)\\n· Conclusion\\n\\nPrerequisites\\n\\nMake sure you have a basic understanding of object-oriented programming (OOP) and neural networks (NN). Familiarity with PyTorch will also be helpful in coding.\\n\\n\\n\\nUnderstanding the Transformer Architecture of LLaMA\\n\\nBefore diving into creating our own LLM using the LLaMA approach, it’s essential to understand the architecture of LLaMA. Below is a comparison diagram between the vanilla transformer and LLaMA.\\n\\nDifference between Transformers and Llama architecture (Llama architecture by Umar Jamil)\\n\\nIn case you’re not familiar with the vanilla transformer architecture, you can read this blog for a basic guide.\\n\\nLet’s look into the essential concepts of LLaMA with a bit more detail:\\n\\nPre-normalization Using RMSNorm:\\n\\nIn the LLaMA approach, a technique called RMSNorm is employed for normalizing the input of each transformer sub-layer. This method is inspired by GPT-3 and is designed to optimize the computational cost associated with Layer Normalization. RMSNorm provides similar performance to LayerNorm but reduces the running time significantly (by 7%∼64%).\\n\\nRoot Mean Square Layer Normalization Paper (https://arxiv.org/abs/1910.07467)\\n\\nIt achieves this by emphasizing re-scaling invariance and regulating the summed inputs based on the root mean square (RMS) statistic. The primary motivation is to simplify LayerNorm by removing the mean statistic. Interested readers can explore the detailed implementation of RMSNorm here.\\n\\nSwiGLU Activation Function:\\n\\nLLaMA introduces the SwiGLU activation function, drawing inspiration from PaLM. To understand SwiGLU, it’s essential to first grasp the Swish activation function. SwiGLU extends Swish and involves a custom layer with a dense network to split and multiply input activations.\\n\\nSwiGLU: GLU Variants Improve Transformer (https://kikaben.com/swiglu-2020/)\\n\\nThe aim is to enhance the expressive power of the model by introducing a more sophisticated activation function. Further details on SwiGLU can be found in the associated paper.\\n\\nRotary Embeddings (RoPE):\\n\\nRotary Embeddings, or RoPE, is a type of position embedding used in LLaMA. It encodes absolute positional information using a rotation matrix and naturally includes explicit relative position dependency in self-attention formulations. RoPE offers advantages such as scalability to various sequence lengths and decaying inter-token dependency with increasing relative distances.\\n\\nThis is achieved by encoding relative positions through multiplication with a rotation matrix, resulting in decayed relative distances - a desirable feature for natural language encoding. Those interested in the mathematical details can refer to the RoPE paper.\\n\\nIn addition to these concepts, the LLaMA paper introduces other significant approaches, including the use of the AdamW optimizer with specific parameters, efficient implementations such as the causal multi-head attention operator available in the xformers library, and manually implemented backward functions for transformer layers to optimize computation during backward passes.\\n\\nA special acknowledgment and thanks to Anush Kumar for providing an in-depth explanation of each crucial aspect of LLaMA.\\n\\nSetting the Stage\\n\\nWe’ll be working with a range of Python libraries throughout this project, so let’s import them:\\n\\n# PyTorch for implementing LLM (No GPU)\\nimport torch\\n\\n# Neural network modules and functions from PyTorch\\nfrom torch import nn\\nfrom torch.nn import functional as F\\n\\n# NumPy for numerical operations\\nimport numpy as np\\n\\n# Matplotlib for plotting Loss etc.\\nfrom matplotlib import pyplot as plt\\n\\n# Time module for tracking execution time\\nimport time\\n\\n# Pandas for data manipulation and analysis\\nimport pandas as pd\\n\\n# urllib for handling URL requests (Downloading Dataset)\\nimport urllib.request\\n\\nFurthermore, I’m creating a configuration object that stores model parameters.\\n\\n# Configuration object for model parameters\\nMASTER_CONFIG = {\\n    # Adding parameters later\\n}\\n\\nThis approach maintains flexibility, allowing for the addition of more parameters as needed in the future.\\n\\nData Preprocessing\\n\\nIn the original LLaMA paper, diverse open-source datasets were employed to train and evaluate the model.\\n\\nhttps://research.facebook.com/publications/llama-open-and-efficient-foundation-language-models/\\n\\nUnfortunately, utilizing extensive datasets may be impractical for smaller projects. Therefore, for our implementation, we’ll take a more modest approach by creating a dramatically scaled-down version of LLaMA.\\n\\nGiven the constraints of not having access to vast amounts of data, we will focus on training a simplified version of LLaMA using the TinyShakespeare dataset. This open source dataset, available here, contains approximately 40,000 lines of text from various Shakespearean works. This choice is influenced by the Makemore series by Karpathy, which provides valuable insights into training language models.\\n\\nWhile LLaMA was trained on an extensive dataset comprising 1.4 trillion tokens, our dataset, TinyShakespeare, containing around 1 million characters.\\n\\nFirst, let’s obtain our dataset by downloading it:\\n\\n# The URL of the raw text file on GitHub\\nurl = \"https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\"\\n\\n# The file name for local storage\\nfile_name = \"tinyshakespeare.txt\"\\n\\n# Execute the download\\nurllib.request.urlretrieve(url, file_name)\\n\\nThis Python script fetches the tinyshakespeare dataset from the specified URL and saves it locally with the filename \"tinyshakespeare.txt.\"\\n\\nNext, let’s determine the vocabulary size, which represents the unique number of characters in our dataset. Here’s the code snippet:\\n\\n# Read the content of the dataset\\nlines = open(\"tinyshakespeare.txt\", \\'r\\').read()\\n\\n# Create a sorted list of unique characters in the dataset\\nvocab = sorted(list(set(lines)))\\n\\n# Display the first 10 characters in the vocabulary list\\nprint(\\'Printing the first 10 characters of the vocab list:\\', vocab[:10])\\n\\n# Output the total number of characters in our dataset (Vocabulary Size)\\nprint(\\'Total number of characters in our dataset (Vocabulary Size):\\', len(vocab))\\n\\n\\n\\nNow, we’re creating mappings between integers to characters (itos) and characters to integers (stoi). Here’s the code:\\n\\n# Mapping integers to characters (itos)\\nitos = {i: ch for i, ch in enumerate(vocab)}\\n\\n# Mapping characters to integers (stoi)\\nstoi = {ch: i for i, ch in enumerate(vocab)}\\n\\n\\n\\nIn the original LLaMA paper, the SentencePiece byte-pair encoding tokenizer from Google was used. However, for simplicity, we’ll opt for a basic character-level tokenizer. Let’s create encode and decode functions that we’ll later apply to our dataset:\\n\\n# Encode function: Converts a string to a list of integers using the mapping stoi\\ndef encode(s):\\n    return [stoi[ch] for ch in s]\\n\\n# Decode function: Converts a list of integers back to a string using the mapping itos\\ndef decode(l):\\n    return \\'\\'.join([itos[i] for i in l])\\n\\n# Example: Encode the string \"hello\" and then decode the result\\ndecode(encode(\"morning\"))\\n\\nThe final line will output morning confirms the proper functionality of the encode and decode functions.\\n\\nWe are now converting our dataset into a torch tensor, specifying its data type for further operations using PyTorch:\\n\\n# Convert the dataset into a torch tensor with specified data type (dtype)\\ndataset = torch.tensor(encode(lines), dtype=torch.int8)\\n\\n# Display the shape of the resulting tensor\\nprint(dataset.shape)\\n\\nThe output istorch.Size([1115394]) indicates that our dataset contains approximately one million tokens. It\\'s worth noting that this is significantly smaller than the LLaMA dataset, which consists of 1.4 trillion tokens.\\n\\nWe’ll create a function responsible for splitting our dataset into training, validation, or test sets. In machine learning or deep learning projects, such splits are crucial for developing and evaluating models, and the same principle applies here in replicating a Large Language Model (LLM) approach:\\n\\n# Function to get batches for training, validation, or testing\\ndef get_batches(data, split, batch_size, context_window, config=MASTER_CONFIG):\\n    # Split the dataset into training, validation, and test sets\\n    train = data[:int(.8 * len(data))]\\n    val = data[int(.8 * len(data)): int(.9 * len(data))]\\n    test = data[int(.9 * len(data)):]\\n\\n    # Determine which split to use\\n    batch_data = train\\n    if split == \\'val\\':\\n        batch_data = val\\n    if split == \\'test\\':\\n        batch_data = test\\n\\n    # Pick random starting points within the data\\n    ix = torch.randint(0, batch_data.size(0) - context_window - 1, (batch_size,))\\n\\n    # Create input sequences (x) and corresponding target sequences (y)\\n    x = torch.stack([batch_data[i:i+context_window] for i in ix]).long()\\n    y = torch.stack([batch_data[i+1:i+context_window+1] for i in ix]).long()\\n\\n    return x, y\\n\\nNow that our splitting function is defined, let’s establish two parameters crucial for this process:\\n\\n# Update the MASTER_CONFIG with batch_size and context_window parameters\\nMASTER_CONFIG.update({\\n    \\'batch_size\\': 8,          # Number of batches to be processed at each random split\\n    \\'context_window\\': 16      # Number of characters in each input (x) and target (y) sequence of each batch\\n})\\n\\nbatch_size determines how many batches are processed at each random split, while context_window specifies the number of characters in each input (x) and target (y) sequence of each batch.\\n\\nLet’s print a random sample from the train split of batch 8 and context window 16 from our dataset:\\n\\n# Obtain batches for training using the specified batch size and context window\\nxs, ys = get_batches(dataset, \\'train\\', MASTER_CONFIG[\\'batch_size\\'], MASTER_CONFIG[\\'context_window\\'])\\n\\n# Decode the sequences to obtain the corresponding text representations\\ndecoded_samples = [(decode(xs[i].tolist()), decode(ys[i].tolist())) for i in range(len(xs))]\\n\\n# Print the random sample\\nprint(decoded_samples)\\n\\n\\n\\nEvaluation Strategy\\n\\nNow, we are set to create a function dedicated to evaluating our self-created LLaMA architecture. The reason for doing this before defining the actual model approach is to enable continuous evaluation during the training process.\\n\\n@torch.no_grad()  # Don\\'t compute gradients for this function\\ndef evaluate_loss(model, config=MASTER_CONFIG):\\n    # Placeholder for the evaluation results\\n    out = {}\\n    \\n    # Set the model to evaluation mode\\n    model.eval()\\n\\n    # Iterate through training and validation splits\\n    for split in [\"train\", \"val\"]:\\n        # Placeholder for individual losses\\n        losses = []\\n\\n        # Generate 10 batches for evaluation\\n        for _ in range(10):\\n            # Get input sequences (xb) and target sequences (yb)\\n            xb, yb = get_batches(dataset, split, config[\\'batch_size\\'], config[\\'context_window\\'])\\n            \\n            # Perform model inference and calculate the loss\\n            _, loss = model(xb, yb)\\n            \\n            # Append the loss to the list\\n            losses.append(loss.item())\\n\\n        # Calculate the mean loss for the split and store it in the output dictionary\\n        out[split] = np.mean(losses)\\n    \\n    # Set the model back to training mode\\n    model.train()\\n    \\n    return out\\n\\nWe have used the loss as a metric to assess the performance of the model during training iterations. Our function iterates through the training and validation splits, computes the mean loss over 10 batches for each split, and finally returns the results. The model is then set back to training mode with model.train().\\n\\nSetting Up a Base Neural Network Model\\n\\nWe’re building a basic neural network that we’ll improve later using LLaMA techniques.\\n\\n# Definition of a basic neural network class\\nclass SimpleBrokenModel(nn.Module):\\n    def __init__(self, config=MASTER_CONFIG):\\n        super().__init__()\\n        self.config = config\\n\\n        # Embedding layer to convert character indices to vectors (vocab size: 65)\\n        self.embedding = nn.Embedding(config[\\'vocab_size\\'], config[\\'d_model\\'])\\n\\n        # Linear layers for modeling relationships between features\\n        # (to be updated with SwiGLU activation function as in LLaMA)\\n        self.linear = nn.Sequential(\\n            nn.Linear(config[\\'d_model\\'], config[\\'d_model\\']),\\n            nn.ReLU(),  # Currently using ReLU, will be replaced with SwiGLU as in LLaMA\\n            nn.Linear(config[\\'d_model\\'], config[\\'vocab_size\\']),\\n        )\\n\\n        # Print the total number of model parameters\\n        print(\"Model parameters:\", sum([m.numel() for m in self.parameters()]))\\n\\nIn the current architecture, the embedding layer has a vocabulary size of 65, representing the characters in our dataset. As this serves as our base model, we are using ReLU as the activation function in the linear layers; however, this will later be replaced with SwiGLU, as used in LLaMA.\\n\\nTo create a forward pass for our base model, we must define a forward function within our NN model.\\n\\n# Definition of a basic neural network class\\nclass SimpleBrokenModel(nn.Module):\\n    def __init__(self, config=MASTER_CONFIG):\\n\\n        # Rest of the code        \\n        ... \\n\\n        # Forward pass function for the base model\\n        def forward(self, idx, targets=None):\\n            # Embedding layer converts character indices to vectors\\n            x = self.embedding(idx)\\n            \\n            # Linear layers for modeling relationships between features\\n            a = self.linear(x)\\n            \\n            # Apply softmax activation to obtain probability distribution\\n            logits = F.softmax(a, dim=-1)\\n\\n            # If targets are provided, calculate and return the cross-entropy loss\\n            if targets is not None:\\n                # Reshape logits and targets for cross-entropy calculation\\n                loss = F.cross_entropy(logits.view(-1, self.config[\\'vocab_size\\']), targets.view(-1))\\n                return logits, loss\\n\\n            # If targets are not provided, return the logits\\n            else:\\n                return logits\\n\\n        # Print the total number of model parameters\\n        print(\"Model parameters:\", sum([m.numel() for m in self.parameters()]))\\n\\nThis forward pass function takes character indices (idx) as input, applies the embedding layer, passes the result through linear layers, applies a softmax activation to obtain a probability distribution (logits). If targets are provided, it calculates the cross-entropy loss and returns both logits and loss. If targets are not provided, it returns only the logits.\\n\\nTo instantiate this model, we can directly invoke the class and print the total number of parameters in our Simple Neural Network Model. We’ve set the dimension of our linear layers to 128, specifying this value in our config object:\\n\\n# Update MASTER_CONFIG with the dimension of linear layers (128)\\nMASTER_CONFIG.update({\\n    \\'d_model\\': 128,\\n})\\n\\n# Instantiate the SimpleBrokenModel using the updated MASTER_CONFIG\\nmodel = SimpleBrokenModel(MASTER_CONFIG)\\n\\n# Print the total number of parameters in the model\\nprint(\"Total number of parameters in the Simple Neural Network Model:\", sum([m.numel() for m in model.parameters()]))\\n\\n\\n\\nOur Simple Neural Network Model comprises approximately 33,000 parameters.\\n\\nSimilarly, to compute logits and loss, we only need to feed our split dataset into our model:\\n\\n# Obtain batches for training using the specified batch size and context window\\nxs, ys = get_batches(dataset, \\'train\\', MASTER_CONFIG[\\'batch_size\\'], MASTER_CONFIG[\\'context_window\\'])\\n\\n# Calculate logits and loss using the model\\nlogits, loss = model(xs, ys)\\n\\nTo train our base model and note its performance, we need to specify some parameters. We are training for a total of 1000 epochs. Increasing the batch size to 32 from 8, and set the log_interval to 10, indicating that the code will print or log information about the training progress every 10 batches. For optimization, we’ll use the Adam optimizer.\\n\\n# Update MASTER_CONFIG with training parameters\\nMASTER_CONFIG.update({\\n    \\'epochs\\': 1000,          # Number of training epochs\\n    \\'log_interval\\': 10,      # Log information every 10 batches during training\\n    \\'batch_size\\': 32,        # Increase batch size to 32\\n})\\n\\n# Instantiate the SimpleBrokenModel with updated configuration\\nmodel = SimpleBrokenModel(MASTER_CONFIG)\\n\\n# Define the Adam optimizer for model parameters\\noptimizer = torch.optim.Adam(\\n    model.parameters(),      # Pass the model parameters to the optimizer\\n)\\n\\nLet’s execute the training process and capture the loss from our base model, including the total number of parameters. Additionally, each line is commented for clarity:\\n\\n# Function to perform training\\ndef train(model, optimizer, scheduler=None, config=MASTER_CONFIG, print_logs=False):\\n    # Placeholder for storing losses\\n    losses = []\\n    \\n    # Start tracking time\\n    start_time = time.time()\\n\\n    # Iterate through epochs\\n    for epoch in range(config[\\'epochs\\']):\\n        # Zero out gradients\\n        optimizer.zero_grad()\\n\\n        # Obtain batches for training\\n        xs, ys = get_batches(dataset, \\'train\\', config[\\'batch_size\\'], config[\\'context_window\\'])\\n\\n        # Forward pass through the model to calculate logits and loss\\n        logits, loss = model(xs, targets=ys)\\n\\n        # Backward pass and optimization step\\n        loss.backward()\\n        optimizer.step()\\n\\n        # If a learning rate scheduler is provided, adjust the learning rate\\n        if scheduler:\\n            scheduler.step()\\n\\n        # Log progress every specified interval\\n        if epoch % config[\\'log_interval\\'] == 0:\\n            # Calculate batch time\\n            batch_time = time.time() - start_time\\n            \\n            # Evaluate loss on validation set\\n            x = evaluate_loss(model)\\n            \\n            # Store the validation loss\\n            losses += [x]\\n            \\n            # Print progress logs if specified\\n            if print_logs:\\n                print(f\"Epoch {epoch} | val loss {x[\\'val\\']:.3f} | Time {batch_time:.3f} | ETA in seconds {batch_time * (config[\\'epochs\\'] - epoch)/config[\\'log_interval\\'] :.3f}\")\\n                \\n            # Reset the timer\\n            start_time = time.time()\\n\\n            # Print learning rate if a scheduler is provided\\n            if scheduler:\\n                print(\"lr: \", scheduler.get_lr())\\n\\n    # Print the final validation loss\\n    print(\"Validation loss: \", losses[-1][\\'val\\'])\\n    \\n    # Plot the training and validation loss curves\\n    return pd.DataFrame(losses).plot()\\n\\n# Execute the training process\\ntrain(model, optimizer)\\n\\n\\n\\nThe initial cross-entropy loss before training stands at 4.17, and after 1000 epochs, it reduces to 3.93. In this context, cross-entropy reflects the likelihood of selecting the incorrect word.\\n\\nOur model incorporates a softmax layer on the logits, which transforms a vector of numbers into a probability distribution. Let’s use the built-in F.cross_entropy function, we need to directly pass in the unnormalized logits. Consequently, we will modify our model accordingly.\\n\\n# Modified SimpleModel class without softmax layer\\nclass SimpleModel(nn.Module):\\n    def __init__(self, config):\\n       \\n       # Rest of the code\\n       ...\\n\\n    def forward(self, idx, targets=None):\\n        # Embedding layer converts character indices to vectors\\n        x = self.embedding(idx)\\n        \\n        # Linear layers for modeling relationships between features\\n        logits = self.linear(x)\\n\\n        # If targets are provided, calculate and return the cross-entropy loss\\n        if targets is not None:\\n\\n            # Rest of the code\\n            ...\\n\\nLet’s recreate the updated SimpleModel and train it for 1000 epochs to observe any changes:\\n\\n# Create the updated SimpleModel\\nmodel = SimpleModel(MASTER_CONFIG)\\n\\n# Obtain batches for training\\nxs, ys = get_batches(dataset, \\'train\\', MASTER_CONFIG[\\'batch_size\\'], MASTER_CONFIG[\\'context_window\\'])\\n\\n# Calculate logits and loss using the model\\nlogits, loss = model(xs, ys)\\n\\n# Define the Adam optimizer for model parameters\\noptimizer = torch.optim.Adam(model.parameters())\\n\\n# Train the model for 100 epochs\\ntrain(model, optimizer)\\n\\n\\n\\nAfter reducing the loss to 2.51, let’s explore how our language model with approximately 33,000 parameters generates text during inferencing. We’ll create a ‘generate’ function, which we’ll later use when replicating LLaMA:\\n\\n# Generate function for text generation using the trained model\\ndef generate(model, config=MASTER_CONFIG, max_new_tokens=30):\\n    idx = torch.zeros(5, 1).long()\\n    for _ in range(max_new_tokens):\\n        # Call the model\\n        logits = model(idx[:, -config[\\'context_window\\']:])\\n        last_time_step_logits = logits[\\n            :, -1, :\\n        ]  # all the batches (1), last time step, all the logits\\n        p = F.softmax(last_time_step_logits, dim=-1)  # softmax to get probabilities\\n        idx_next = torch.multinomial(\\n            p, num_samples=1\\n        )  # sample from the distribution to get the next token\\n        idx = torch.cat([idx, idx_next], dim=-1)  # append to the sequence\\n    return [decode(x) for x in idx.tolist()]\\n\\n# Generate text using the trained model\\ngenerate(model)\\n\\n\\n\\nThe generated text doesn’t look great with our basic model of around 33K parameters. However, now that we’ve laid the groundwork with this simple model, we’ll move on to constructing the LLaMA architecture in the next section.\\n\\nReplicating LLaMA Architecture\\n\\nIn the earlier part of the blog, we covered essential concepts, and now, we’ll integrate these concepts into our base model. LLaMA introduces three architectural modifications to the original Transformer:\\n\\nRMSNorm for pre-normalization\\n\\nRotary embeddings\\n\\nSwiGLU activation function\\n\\nWe’ll incorporate each of these modifications one by one into our base model, iterating and building upon them.\\n\\nRMSNorm for pre-normalization:\\n\\nWe are defining an RMSNorm function with the following functionalities:\\n\\nclass RMSNorm(nn.Module):\\n    def __init__(self, layer_shape, eps=1e-8, bias=False):\\n        super(RMSNorm, self).__init__()\\n\\n        # Registering a learnable parameter \\'scale\\' as a parameter of the module\\n        self.register_parameter(\"scale\", nn.Parameter(torch.ones(layer_shape)))\\n\\n    def forward(self, x):\\n        \"\"\"\\n        Assumes shape is (batch, seq_len, d_model)\\n        \"\"\"\\n        # Calculating the Frobenius norm, RMS = 1/sqrt(N) * Frobenius norm\\n        ff_rms = torch.linalg.norm(x, dim=(1,2)) * x[0].numel() ** -.5\\n\\n        # Normalizing the input tensor \\'x\\' with respect to RMS\\n        raw = x / ff_rms.unsqueeze(-1).unsqueeze(-1)\\n\\n        # Scaling the normalized tensor using the learnable parameter \\'scale\\'\\n        return self.scale[:x.shape[1], :].unsqueeze(0) * raw\\n\\nwe define the RMSNorm class. During initialization, it registers a scale parameter. In the forward pass, it calculates the Frobenius norm of the input tensor and then normalizes the tensor. Finally, the tensor is scaled by the registered scale parameter. This function is designed for use in LLaMA to replace the LayerNorm operation.\\n\\nNow it’s time to incorporate the first implementation concept of LLaMA, which is RMSNorm, into our simple NN model. Here’s the updated code:\\n\\n# Define the SimpleModel_RMS with RMSNorm\\nclass SimpleModel_RMS(nn.Module):\\n    def __init__(self, config):\\n        super().__init__()\\n        self.config = config\\n\\n        # Embedding layer to convert character indices to vectors\\n        self.embedding = nn.Embedding(config[\\'vocab_size\\'], config[\\'d_model\\'])\\n\\n        # RMSNorm layer for pre-normalization\\n        self.rms = RMSNorm((config[\\'context_window\\'], config[\\'d_model\\']))\\n\\n        # Linear layers for modeling relationships between features\\n        self.linear = nn.Sequential(\\n            # Rest of the code\\n            ...\\n        )\\n\\n        # Print the total number of model parameters\\n        print(\"Model parameters:\", sum([m.numel() for m in self.parameters()]))\\n\\n    def forward(self, idx, targets=None):\\n        # Embedding layer converts character indices to vectors\\n        x = self.embedding(idx)\\n\\n        # RMSNorm pre-normalization\\n        x = self.rms(x)\\n\\n        # Linear layers for modeling relationships between features\\n        logits = self.linear(x)\\n\\n        if targets is not None:\\n\\n            # Rest of the code\\n            ...\\n\\nLet’s execute the modified NN model with RMSNorm and observe the updated number of parameters in the model, along with the loss:\\n\\n# Create an instance of SimpleModel_RMS\\nmodel = SimpleModel_RMS(MASTER_CONFIG)\\n\\n# Obtain batches for training\\nxs, ys = get_batches(dataset, \\'train\\', MASTER_CONFIG[\\'batch_size\\'], MASTER_CONFIG[\\'context_window\\'])\\n\\n# Calculate logits and loss using the model\\nlogits, loss = model(xs, ys)\\n\\n# Define the Adam optimizer for model parameters\\noptimizer = torch.optim.Adam(model.parameters())\\n\\n# Train the model\\ntrain(model, optimizer)\\n\\n\\n\\nThe validation loss experiences a small decrease, and the parameters of our updated LLM now total approximately 55,000.\\n\\nRotary Embeddings:\\n\\nNext, we will implement rotary positional embeddings. In RoPE, the authors suggest embedding the position of a token in a sequence by rotating the embedding, applying a different rotation at each position. Let’s create a function that mimics the actual paper implementation of RoPE:\\n\\ndef get_rotary_matrix(context_window, embedding_dim):\\n    # Initialize a tensor for the rotary matrix with zeros\\n    R = torch.zeros((context_window, embedding_dim, embedding_dim), requires_grad=False)\\n    \\n    # Loop through each position in the context window\\n    for position in range(context_window):\\n        # Loop through each dimension in the embedding\\n        for i in range(embedding_dim // 2):\\n            # Calculate the rotation angle (theta) based on the position and embedding dimension\\n            theta = 10000. ** (-2. * (i - 1) / embedding_dim)\\n            # Calculate the rotated matrix elements using sine and cosine functions\\n            m_theta = position * theta\\n            R[position, 2 * i, 2 * i] = np.cos(m_theta)\\n            R[position, 2 * i, 2 * i + 1] = -np.sin(m_theta)\\n            R[position, 2 * i + 1, 2 * i] = np.sin(m_theta)\\n            R[position, 2 * i + 1, 2 * i + 1] = np.cos(m_theta)\\n    return R\\n\\nwe generate a rotary matrix based on the specified context window and embedding dimension, following the proposed RoPE implementation.\\n\\nAs you may be familiar with the architecture of transformers, which involves attention heads, we similarly need to create attention heads when replicating LLaMA. To start, let’s first create a single masked attention head using the get_rotary_matrix function we previously developed for rotary embeddings. Additionally, each line is commented for clarity:\\n\\nclass RoPEAttentionHead(nn.Module):\\n    def __init__(self, config):\\n        super().__init__()\\n        self.config = config\\n        # Linear transformation for query\\n        self.w_q = nn.Linear(config[\\'d_model\\'], config[\\'d_model\\'], bias=False)\\n        # Linear transformation for key\\n        self.w_k = nn.Linear(config[\\'d_model\\'], config[\\'d_model\\'], bias=False)\\n        # Linear transformation for value\\n        self.w_v = nn.Linear(config[\\'d_model\\'], config[\\'d_model\\'], bias=False)\\n        # Obtain rotary matrix for positional embeddings\\n        self.R = get_rotary_matrix(config[\\'context_window\\'], config[\\'d_model\\'])\\n\\n    def get_rotary_matrix(context_window, embedding_dim):\\n        # Generate rotational matrix for RoPE\\n        R = torch.zeros((context_window, embedding_dim, embedding_dim), requires_grad=False)\\n        for position in range(context_window):\\n            for i in range(embedding_dim//2):\\n                \\n                # Rest of the code\\n                ...\\n\\n        return R\\n\\n    def forward(self, x, return_attn_weights=False):\\n        # x: input tensor of shape (batch, sequence length, dimension)\\n\\n        b, m, d = x.shape  # batch size, sequence length, dimension\\n\\n        # Linear transformations for Q, K, and V\\n        q = self.w_q(x)\\n        k = self.w_k(x)\\n        v = self.w_v(x)\\n\\n        # Rotate Q and K using the RoPE matrix\\n        q_rotated = (torch.bmm(q.transpose(0, 1), self.R[:m])).transpose(0, 1)\\n        k_rotated = (torch.bmm(k.transpose(0, 1), self.R[:m])).transpose(0, 1)\\n\\n        # Perform scaled dot-product attention\\n        activations = F.scaled_dot_product_attention(\\n            q_rotated, k_rotated, v, dropout_p=0.1, is_causal=True\\n        )\\n\\n        if return_attn_weights:\\n            # Create a causal attention mask\\n            attn_mask = torch.tril(torch.ones((m, m)), diagonal=0)\\n            # Calculate attention weights and add causal mask\\n            attn_weights = torch.bmm(q_rotated, k_rotated.transpose(1, 2)) / np.sqrt(d) + attn_mask\\n            attn_weights = F.softmax(attn_weights, dim=-1)\\n            return activations, attn_weights\\n\\n        return activations\\n\\nNow that we have a single masked attention head that returns attention weights, the next step is to create a multi-Head attention mechanism.\\n\\nclass RoPEMaskedMultiheadAttention(nn.Module):\\n    def __init__(self, config):\\n        super().__init__()\\n        self.config = config\\n        # Create a list of RoPEMaskedAttentionHead instances as attention heads\\n        self.heads = nn.ModuleList([\\n            RoPEMaskedAttentionHead(config) for _ in range(config[\\'n_heads\\'])\\n        ])\\n        self.linear = nn.Linear(config[\\'n_heads\\'] * config[\\'d_model\\'], config[\\'d_model\\'])  # Linear layer after concatenating heads\\n        self.dropout = nn.Dropout(.1)  # Dropout layer\\n\\n    def forward(self, x):\\n        # x: input tensor of shape (batch, sequence length, dimension)\\n\\n        # Process each attention head and concatenate the results\\n        heads = [h(x) for h in self.heads]\\n        x = torch.cat(heads, dim=-1)\\n        \\n        # Apply linear transformation to the concatenated output\\n        x = self.linear(x)\\n        \\n        # Apply dropout\\n        x = self.dropout(x)\\n        return x\\n\\nThe original paper used 32 heads for their smaller 7b LLM variation, but due to constraints, we’ll use 8 heads for our approach.\\n\\n# Update the master configuration with the number of attention heads\\nMASTER_CONFIG.update({\\n    \\'n_heads\\': 8,\\n})\\n\\nNow that we’ve implemented Rotational Embedding and Multi-head Attention, let’s re-write our RMSNorm neural network model with the updated code. We’ll test its performance, compute the loss, and check the number of parameters. We’ll refer to this updated model as \"RopeModel\"\\n\\nclass RopeModel(nn.Module):\\n    def __init__(self, config):\\n        super().__init__()\\n        self.config = config\\n\\n        # Embedding layer for input tokens\\n        self.embedding = nn.Embedding(config[\\'vocab_size\\'], config[\\'d_model\\'])\\n        \\n        # RMSNorm layer for pre-normalization\\n        self.rms = RMSNorm((config[\\'context_window\\'], config[\\'d_model\\']))\\n        \\n        # RoPEMaskedMultiheadAttention layer\\n        self.rope_attention = RoPEMaskedMultiheadAttention(config)\\n\\n        # Linear layer followed by ReLU activation\\n        self.linear = nn.Sequential(\\n            nn.Linear(config[\\'d_model\\'], config[\\'d_model\\']),\\n            nn.ReLU(),\\n        )\\n\\n        # Final linear layer for prediction\\n        self.last_linear = nn.Linear(config[\\'d_model\\'], config[\\'vocab_size\\'])\\n\\n        print(\"model params:\", sum([m.numel() for m in self.parameters()]))\\n\\n    def forward(self, idx, targets=None):\\n        # idx: input indices\\n        x = self.embedding(idx)\\n\\n        # One block of attention\\n        x = self.rms(x)  # RMS pre-normalization\\n        x = x + self.rope_attention(x)\\n\\n        x = self.rms(x)  # RMS pre-normalization\\n        x = x + self.linear(x)\\n\\n        logits = self.last_linear(x)\\n\\n        if targets is not None:\\n            loss = F.cross_entropy(logits.view(-1, self.config[\\'vocab_size\\']), targets.view(-1))\\n            return logits, loss\\n\\n        else:\\n            return logits\\n\\nLet’s execute the modified NN model with RMSNorm, Rotational Embeddings and Masked Multi Head Attentions to observe the updated number of parameters in the model, along with the loss:\\n\\n# Create an instance of RopeModel (RMSNorm, RoPE, Multi-Head)\\nmodel = RopeModel(MASTER_CONFIG)\\n\\n# Obtain batches for training\\nxs, ys = get_batches(dataset, \\'train\\', MASTER_CONFIG[\\'batch_size\\'], MASTER_CONFIG[\\'context_window\\'])\\n\\n# Calculate logits and loss using the model\\nlogits, loss = model(xs, ys)\\n\\n# Define the Adam optimizer for model parameters\\noptimizer = torch.optim.Adam(model.parameters())\\n\\n# Train the model\\ntrain(model, optimizer)\\n\\n\\n\\nThe validation loss experiences a small decrease again, and the parameters of our updated LLM now total approximately 55,000.\\n\\nLet’s train the model for more epochs to see if the loss of our recreated LLaMA LLM continues to decrease or not.\\n\\n# Updating training configuration with more epochs and a logging interval\\nMASTER_CONFIG.update({\\n    \"epochs\": 5000,\\n    \"log_interval\": 10,\\n})\\n\\n# Training the model with the updated configuration\\ntrain(model, optimizer)\\n\\n\\n\\nThe validation loss continues to decrease, suggesting that training for more epochs could lead to further loss reduction, though not significantly.\\n\\nSwiGLU activation function:\\n\\nAs mentioned before, the creators of LLaMA use SwiGLU instead of ReLU, so we’ll be implementing SwiGLU equation in our code.\\n\\nhttps://arxiv.org/pdf/2002.05202v1.pdf\\n\\nclass SwiGLU(nn.Module):\\n    \"\"\" Paper Link -> https://arxiv.org/pdf/2002.05202v1.pdf \"\"\"\\n    def __init__(self, size):\\n        super().__init__()\\n        self.config = config  # Configuration information\\n        self.linear_gate = nn.Linear(size, size)  # Linear transformation for the gating mechanism\\n        self.linear = nn.Linear(size, size)  # Linear transformation for the main branch\\n        self.beta = torch.randn(1, requires_grad=True)  # Random initialization of the beta parameter\\n\\n        # Using nn.Parameter for beta to ensure it\\'s recognized as a learnable parameter\\n        self.beta = nn.Parameter(torch.ones(1))\\n        self.register_parameter(\"beta\", self.beta)\\n\\n    def forward(self, x):\\n        # Swish-Gated Linear Unit computation\\n        swish_gate = self.linear_gate(x) * torch.sigmoid(self.beta * self.linear_gate(x))\\n        out = swish_gate * self.linear(x)  # Element-wise multiplication of the gate and main branch\\n        return out\\n\\nAfter implementing the SwiGLU equation in python, we need to integrate it into our modified LLaMA language model (RopeModel).\\n\\nclass RopeModel(nn.Module):\\n    def __init__(self, config):\\n        super().__init__()\\n        self.config = config\\n\\n        # Embedding layer for input tokens\\n        self.embedding = nn.Embedding(config[\\'vocab_size\\'], config[\\'d_model\\'])\\n        \\n        # RMSNorm layer for pre-normalization\\n        self.rms = RMSNorm((config[\\'context_window\\'], config[\\'d_model\\']))\\n        \\n        # Multi-head attention layer with RoPE (Rotary Positional Embeddings)\\n        self.rope_attention = RoPEMaskedMultiheadAttention(config)\\n\\n        # Linear layer followed by SwiGLU activation\\n        self.linear = nn.Sequential(\\n            nn.Linear(config[\\'d_model\\'], config[\\'d_model\\']),\\n            SwiGLU(config[\\'d_model\\']),  # Adding SwiGLU activation\\n        )\\n\\n        # Output linear layer\\n        self.last_linear = nn.Linear(config[\\'d_model\\'], config[\\'vocab_size\\'])\\n\\n        # Printing total model parameters\\n        print(\"model params:\", sum([m.numel() for m in self.parameters()]))\\n\\n    def forward(self, idx, targets=None):\\n        x = self.embedding(idx)\\n\\n        # One block of attention\\n        x = self.rms(x)  # RMS pre-normalization\\n        x = x + self.rope_attention(x)\\n\\n        x = self.rms(x)  # RMS pre-normalization\\n        x = x + self.linear(x)  # Applying SwiGLU activation\\n\\n        logits = self.last_linear(x)\\n\\n        if targets is not None:\\n            # Calculate cross-entropy loss if targets are provided\\n            loss = F.cross_entropy(logits.view(-1, self.config[\\'vocab_size\\']), targets.view(-1))\\n            return logits, loss\\n\\n        else:\\n            return logits\\n\\nLet’s execute the modified NN model with RMSNorm, Rotational Embeddings, Masked Multi Head Attentions and SwiGLU to observe the updated number of parameters in the model, along with the loss:\\n\\n# Create an instance of RopeModel (RMSNorm, RoPE, Multi-Head, SwiGLU)\\nmodel = RopeModel(MASTER_CONFIG)\\n\\n# Obtain batches for training\\nxs, ys = get_batches(dataset, \\'train\\', MASTER_CONFIG[\\'batch_size\\'], MASTER_CONFIG[\\'context_window\\'])\\n\\n# Calculate logits and loss using the model\\nlogits, loss = model(xs, ys)\\n\\n# Define the Adam optimizer for model parameters\\noptimizer = torch.optim.Adam(model.parameters())\\n\\n# Train the model\\ntrain(model, optimizer)\\n\\n\\n\\nOnce again the validation loss experiences a small decrease, and the parameters of our updated LLM now total approximately 60,000.\\n\\nSo far, we have successfully implemented the key components of the paper, namely RMSNorm, RoPE, and SwiGLU. We observed that these implementations led to a minimal decrease in the loss.\\n\\nNow we will add layers to our LLaMA to examine its impact on the loss. The original paper used 32 layers for the 7b version, but we will use only 4 layers. Let’s adjust our model settings accordingly.\\n\\n# Update model configurations for the number of layers\\nMASTER_CONFIG.update({\\n    \\'n_layers\\': 4,  # Set the number of layers to 4\\n})\\n\\nLet’s start by creating a single layer to understand its impact.\\n\\n# add RMSNorm and residual connection\\nclass LlamaBlock(nn.Module):\\n    def __init__(self, config):\\n        super().__init__()\\n        self.config = config\\n\\n        # RMSNorm layer\\n        self.rms = RMSNorm((config[\\'context_window\\'], config[\\'d_model\\']))\\n\\n        # RoPE Masked Multihead Attention layer\\n        self.attention = RoPEMaskedMultiheadAttention(config)\\n\\n        # Feedforward layer with SwiGLU activation\\n        self.feedforward = nn.Sequential(\\n            nn.Linear(config[\\'d_model\\'], config[\\'d_model\\']),\\n            SwiGLU(config[\\'d_model\\']),\\n        )\\n\\n    def forward(self, x):\\n        # one block of attention\\n        x = self.rms(x) # RMS pre-normalization\\n        x = x + self.attention(x)  # residual connection\\n\\n        x = self.rms(x) # RMS pre-normalization\\n        x = x + self.feedforward(x)  # residual connection\\n        return x\\n\\nCreate an instance of the LlamaBlock class and applies it to a random tensor.\\n\\n# Create an instance of the LlamaBlock class with the provided configuration\\nblock = LlamaBlock(MASTER_CONFIG)\\n\\n# Generate a random tensor with the specified batch size, context window, and model dimension\\nrandom_input = torch.randn(MASTER_CONFIG[\\'batch_size\\'], MASTER_CONFIG[\\'context_window\\'], MASTER_CONFIG[\\'d_model\\'])\\n\\n# Apply the LlamaBlock to the random input tensor\\noutput = block(random_input)\\n\\nHaving successfully created a single layer, we can now use it to construct multiple layers. Additionally, we will rename our model class from \"ropemodel\" to \"Llama\" as we have replicated every component of the LLaMA language model.\\n\\nclass Llama(nn.Module):\\n    def __init__(self, config):\\n        super().__init__()\\n        self.config = config\\n        # Embedding layer for token representations\\n        self.embeddings = nn.Embedding(config[\\'vocab_size\\'], config[\\'d_model\\'])\\n        # Sequential block of LlamaBlocks based on the specified number of layers\\n        self.llama_blocks = nn.Sequential(\\n            OrderedDict([(f\"llama_{i}\", LlamaBlock(config)) for i in range(config[\\'n_layers\\'])])\\n        )\\n        # Feedforward network (FFN) for final output\\n        self.ffn = nn.Sequential(\\n            nn.Linear(config[\\'d_model\\'], config[\\'d_model\\']),\\n            SwiGLU(config[\\'d_model\\']),\\n            nn.Linear(config[\\'d_model\\'], config[\\'vocab_size\\']),\\n        )\\n\\n        # Print total number of parameters in the model\\n        print(\"model params:\", sum([m.numel() for m in self.parameters()]))\\n\\n    def forward(self, idx, targets=None):\\n        # Input token indices are passed through the embedding layer\\n        x = self.embeddings(idx)\\n        # Process the input through the LlamaBlocks\\n        x = self.llama_blocks(x)\\n        # Pass the processed input through the final FFN for output logits\\n        logits = self.ffn(x)\\n\\n        # If targets are not provided, return only the logits\\n        if targets is None:\\n            return logits\\n        # If targets are provided, compute and return the cross-entropy loss\\n        else:\\n            loss = F.cross_entropy(logits.view(-1, self.config[\\'vocab_size\\']), targets.view(-1))\\n            return logits, loss\\n\\nLet’s execute the modified LLaMA model with RMSNorm, Rotational Embeddings, Masked Multi Head Attentions, SwiGLU and N_layers to observe the updated number of parameters in the model, along with the loss:\\n\\n# Create an instance of RopeModel (RMSNorm, RoPE, Multi-Head, SwiGLU, N_layers)\\nllama = Llama(MASTER_CONFIG)\\n\\n# Obtain batches for training\\nxs, ys = get_batches(dataset, \\'train\\', MASTER_CONFIG[\\'batch_size\\'], MASTER_CONFIG[\\'context_window\\'])\\n\\n# Calculate logits and loss using the model\\nlogits, loss = llama(xs, ys)\\n\\n# Define the Adam optimizer for model parameters\\noptimizer = torch.optim.Adam(llama.parameters())\\n\\n# Train the model\\ntrain(llama, optimizer)\\n\\n\\n\\nWhile there’s a possibility of overfitting, it’s crucial to explore whether extending the number of epochs leads to a further reduction in loss. Additionally, note that our current LLM has over 2 million parameters.\\n\\nLet’s train it for higher number of epochs.\\n\\n# Update the number of epochs in the configuration\\nMASTER_CONFIG.update({\\n    \\'epochs\\': 10000,\\n})\\n# Train the LLaMA model for the specified number of epochs\\ntrain(llama, optimizer, scheduler=None, config=MASTER_CONFIG)\\n\\n\\n\\nThe loss here is 1.08, we can achieve even more lower loss without encountering significant overfitting. This suggests the model is performing well.\\n\\nLet’s train the model once more, this time incorporating a scheduler\\n\\n# Training the model again, scheduler for better optimization.\\ntrain(llama, optimizer, config=MASTER_CONFIG)\\n\\n\\n\\nUp until now, we’ve successfully implemented a scaled-down version of the LLaMA architecture on our custom dataset. Now, let’s examine the generated output from our 2 million-parameter Language Model.\\n\\n# Generate text using the trained LLM (llama) with a maximum of 500 tokens\\ngenerated_text = generate(llama, MASTER_CONFIG, 500)[0]\\nprint(generated_text)\\n\\n\\n\\nEven though some generated words may not be perfect English, our LLM with just 2 million parameters has shown a basic understanding of the English language.\\n\\nNow, let’s see how well our model performs on the test set.\\n\\n# Get batches from the test set\\nxs, ys = get_batches(dataset, \\'test\\', MASTER_CONFIG[\\'batch_size\\'], MASTER_CONFIG[\\'context_window\\'])\\n\\n# Pass the test data through the LLaMA model\\nlogits, loss = llama(xs, ys)\\n\\n# Print the loss on the test set\\nprint(loss)\\n\\nThe computed loss on the test set is approximately 1.236.\\n\\nA simple way to check for changes in the generated output is to run training for a large number of epochs and observe the results.\\n\\nExperimenting with hyperparameters\\n\\nHyperparameter tuning is a crucial step in training neural networks. In the original Llama paper, the authors utilized the Cosine Annealing learning schedule. However, in our experimentation, it didn’t perform well. Here’s an example of experimenting with hyperparameters using a different learning schedule:\\n\\n# Update configuration\\nMASTER_CONFIG.update({\\n    \"epochs\": 1000\\n})\\n\\n# Create Llama model with Cosine Annealing learning schedule\\nllama_with_cosine = Llama(MASTER_CONFIG)\\n\\n# Define Adam optimizer with specific hyperparameters\\nllama_optimizer = torch.optim.Adam(\\n    llama.parameters(),\\n    betas=(.9, .95),\\n    weight_decay=.1,\\n    eps=1e-9,\\n    lr=1e-3\\n)\\n\\n# Define Cosine Annealing learning rate scheduler\\nscheduler = torch.optim.lr_scheduler.CosineAnnealingLR(llama_optimizer, 300, eta_min=1e-5)\\n\\n# Train the Llama model with the specified optimizer and scheduler\\ntrain(llama_with_cosine, llama_optimizer, scheduler=scheduler)\\n\\nSaving Your Language Model (LLM)\\n\\nYou can save your entire LLM or just the parameters using the following:\\n\\n# Save the entire model\\ntorch.save(llama, \\'llama_model.pth\\')\\n\\n# If you want to save only the model parameters\\ntorch.save(llama.state_dict(), \\'llama_model_params.pth\\')\\n\\nTo save your PyTorch model for Hugging Face’s Transformers library, you can use the save_pretrained method. Here\\'s an example:\\n\\nfrom transformers import GPT2LMHeadModel, GPT2Config\\n\\n# Assuming Llama is your PyTorch model\\nllama_config = GPT2Config.from_dict(MASTER_CONFIG)\\nllama_transformers = GPT2LMHeadModel(config=llama_config)\\nllama_transformers.load_state_dict(llama.state_dict())\\n\\n# Specify the directory where you want to save the model\\noutput_dir = \"llama_model_transformers\"\\n\\n# Save the model and configuration\\nllama_transformers.save_pretrained(output_dir)\\n\\nGPT2Config is used to create a configuration object compatible with GPT-2. Then, a GPT2LMHeadModel is created and loaded with the weights from your Llama model. Finally, save_pretrained is called to save both the model and configuration in the specified directory.\\n\\nYou can then load the model using the Transformers library:\\n\\nfrom transformers import GPT2LMHeadModel, GPT2Config\\n\\n# Specify the directory where the model was saved\\noutput_dir = \"llama_model_transformers\"\\n\\n# Load the model and configuration\\nllama_transformers = GPT2LMHeadModel.from_pretrained(output_dir)\\n\\nConclusion\\n\\nIn this blog, we’ve walked through a step-by-step process on how to implement the LLaMA approach to build your own small Language Model (LLM). As a suggestion, consider expanding your model to around 15 million parameters, as smaller models in the range of 10M to 20M tend to comprehend English better. Once your LLM becomes proficient in language, you can fine-tune it for specific use cases.\\n\\nI hope this comprehensive blog has provided you with insights on replicating a paper to create your personalized LLM.\\n\\nThanks for reading this extensive post!'}},\n",
       "  {'id': '969af38516b2',\n",
       "   'title': 'Chat with Graphs Intelligently',\n",
       "   'subtitle': 'Talking Graphs, Your Data Speaks Up',\n",
       "   'author': 'b856005e5ecd',\n",
       "   'publication_id': '5517fd7b58a6',\n",
       "   'published_at': '2024-01-23 04:01:22',\n",
       "   'last_modified_at': '2024-01-23 04:01:22',\n",
       "   'tags': ['data-science',\n",
       "    'data-visualization',\n",
       "    'python',\n",
       "    'artificial-intelligence',\n",
       "    'chatgpt'],\n",
       "   'topics': ['data-science', 'programming'],\n",
       "   'claps': 442,\n",
       "   'voters': 46,\n",
       "   'word_count': 1179,\n",
       "   'responses_count': 1,\n",
       "   'reading_time': 5.949056603773585,\n",
       "   'url': 'https://levelup.gitconnected.com/chat-with-graphs-intelligently-969af38516b2',\n",
       "   'unique_slug': 'chat-with-graphs-intelligently-969af38516b2',\n",
       "   'image_url': 'https://miro.medium.com/1*VrxMVWJjDT42bSvySMwYxw.png',\n",
       "   'lang': 'en',\n",
       "   'is_series': False,\n",
       "   'is_locked': False,\n",
       "   'is_shortform': False,\n",
       "   'top_highlight': '',\n",
       "   'content': {'id': '969af38516b2',\n",
       "    'content': 'Chat with Graphs Intelligently\\n\\nTalking Graphs, Your Data Speaks Up\\n\\nClustering using ChatGraph\\n\\nGraphs are one of the ways that provide important information about your data or your analysis on that data. However, most of the time, reading graphs is among the difficult tasks. How good would it be if you could use a multimodal to understand your graphs and receive information that you cannot learn by just seeing it?\\n\\nChatGraph is a web app I have created for coders/non-coders that allows you to talk intelligently with graphs. We will look at each of its features here to understand what it can do and then test its capabilities.\\n\\nChatGraph Website: chat-with-graph.streamlit\\n\\nThe Python code for creating the web app is available in my GitHub repository. It also includes all the important steps to run it locally.\\n\\nGitHub - FareedKhan-dev/ChatGraph\\nContribute to FareedKhan-dev/ChatGraph development by creating an account on GitHub.github.com\\n\\nUser Interface of ChatGraph\\n\\nTable of Contents\\n\\nEnhanced AI Feature\\n\\nManual Chat Feature\\n\\nAI Chat Feature\\n\\nHow Accurate is ChatGraph?\\n\\nEnhanced AI Feature\\n\\nThis feature is useful when you’ve plotted a graph, but you don\\'t know what kind of questions can be asked related to it. Enhanced AI comes in handy as it generates important questions related to the graph, which you can then ask.\\n\\nHome Prices Graph\\n\\nConsider the graph of home pricing, where the prices of houses depend on the age of the house and the population in that area. By just looking at the graph, you may already have some questions in your mind, such as: \"If my house is x years old and the population in the area is y, what could be the house price?\" Many more questions may come to mind, But thinking takes time. On the other hand, the enhanced AI feature can generate more than 20 important questions related to that graph within 5 seconds.\\n\\nhow Enhanced AI feature works\\n\\nYou can adjust the number of questions by changing the parameter. I’ve set it to 20 for the web app, but when running locally, you have the flexibility to access everything and increase the number of generated questions to 100, 200, or even more.\\n\\nRelevant AI Question generated using Enhanced AI feature\\n\\nHere’s another example that demonstrates how the enhanced AI feature generates prompts for the graph, closely resembling the questions that come to mind when we initially see the graph or seek answers from it.\\n\\nManual Chat Feature\\n\\nThis feature is quite similar to ChatGPT where you can ask custom questions, The interesting part is, every question and its response, whether from manual or enhanced ai chat, gets stored in the cache. This gives it a ChatGPT-like feel, where our entire conversation is saved for reference.\\n\\nhow Manual Chat feature works\\n\\nI’ve set the conversation history range between 10 to 30 (no. of messages), but similar to other parameters, you have the flexibility to adjust it based on your specific needs.\\n\\na general question asked to ChatGraph\\n\\nAI Chat Feature\\n\\nMost of the questions we ask related to graphs, whether for numerical or text data, are common among developers, such as identifying outliers, understanding the trend in a time series plot, or determining the number of clusters present. This AI feature has compiled over 250+ questions in a detailed manner under different categories such Data Analyst, NLP etc. This way, it provides descriptive questions based on your search query rather than short questions that may not offer sufficient information.\\n\\nHow AI Feature works\\n\\nNow that we’ve had a brief overview of ChatGraph, the real test lies in how well it performs on different types of graphs. In the next section, we will evaluate its accuracy.\\n\\nHow Accurate is ChatGraph?\\n\\nHiding number of clusters\\n\\nConsider this graph of different data points with some noise in it, I already know that there are 5 clusters present in it, I hide this information visually and ask ChatGraph how many cluster are present in this noisy data.\\n\\nIdentifying number of clusters\\n\\nIt correctly identifies the number of clusters present in this data, but it may not be as accurate in every condition, especially when dealing with a large number of data points. In my case, there are only 500 points.\\n\\nPredicting Trend\\n\\nI made a line graph without a clear pattern. I hid the last predicted number 7.36 and asked ChatGraph to guess it. It guessed 5, which isn’t very close, but it did recognize that the trend suggests an increase in the values.\\n\\nIdentifying Outliers\\n\\nIn this graph, I intentionally created three extreme outliers at [6.4, 16.7, 18.1], and I asked ChatGraph to detect it. It’s predicted x values are [6.5, 16.5, 18.5] which are almost equal to true values, but providing additional information can yield a more descriptive answer, such as explaining why these outliers exist and so on.\\n\\nNot exact Linear Relationship between A and B\\n\\nTo determine whether it can understand relationship between variables, I plotted a graph where both variables initially show a positive correlation at the 12.5 value but have a different relation afterward. I then asked ChatGraph to understand the relationships between these variables.\\n\\nUser Query - Do Variable A and Variable B show a consistent correlation over the entire time period?\\n\\nChatGraph - No, the correlation between the two variables is not consistent over the entire time period. While there is a positive correlation between the two variables for the first half of the time period, there is a negative correlation between the two variables for the second half of the time period.\\n\\nEffect of amplitude\\n\\nTo verify if ChatGraph can find the impact of one variable over the other, I plotted a graph where increasing the amplitude value results in a more complex pattern, while decreasing its value makes the overall relationship less complex. Let’s see if ChatGraph can observe and understand this behavior.\\n\\nUser Query - how changing the amplitude affects the overall patterns and complexity in the relationship between Variable A and Variable B over time?\\n\\nChatGraph - The amplitude of a signal, like sinusoidal components, affects the intensity of fluctuations in variables over time. Higher amplitude magnifies differences, making relationships complex. Lower amplitude simplifies relationships by reducing fluctuations. In summary, amplitude acts as a magnifier, influencing the complexity and dynamics of the relationship between variables.\\n\\nPrices of houses\\n\\nInstead of posing a question, let’s observe what insights ChatGraph can derive from the above graph on its own.\\n\\nHere are a few insights extracted by ChatGraph:\\n\\nThe home value increases with the home age and area population.\\n\\nThe home value is mostly affected by the area population.\\n\\nThe home value is less affected by the home age.\\n\\nMost homes are valued between $100,000 and $300,000.\\n\\nMost homes are between 0 and 50 years old.\\n\\nThe graph can predicts home value using age and local population. For example, 20-year-old home in a 10,000 people area is valued around $200,000.\\n\\nWhat’s next?\\n\\nCertainly, there are numerous possibilities with ChatGraph, and you can customize the web app according to your specific needs. This includes changing the prompt structure or adjusting the history parameters to a higher value. I’ve written another article on creating a copilot inside your notebook, which includes a feature for chatting with graphs while coding. You can find it here:\\n\\nCreate a Copilot inside your notebooks that can chat with graphs, write code and more\\nAn Intelligent Help for Efficient Programminglevelup.gitconnected.com'}},\n",
       "  {'id': 'e9390e2b9ed8',\n",
       "   'title': 'Create a Copilot inside your notebooks that can chat with graphs, write code and more',\n",
       "   'subtitle': 'An Intelligent Help for Efficient Programming',\n",
       "   'author': 'b856005e5ecd',\n",
       "   'publication_id': '5517fd7b58a6',\n",
       "   'published_at': '2024-01-11 15:39:01',\n",
       "   'last_modified_at': '2024-01-12 15:22:35',\n",
       "   'tags': ['python',\n",
       "    'github',\n",
       "    'machine-learning',\n",
       "    'programming',\n",
       "    'data-science'],\n",
       "   'topics': ['programming'],\n",
       "   'claps': 749,\n",
       "   'voters': 136,\n",
       "   'word_count': 3276,\n",
       "   'responses_count': 9,\n",
       "   'reading_time': 13.495597484276729,\n",
       "   'url': 'https://levelup.gitconnected.com/create-copilot-inside-your-notebooks-that-can-chat-with-graphs-write-code-and-more-e9390e2b9ed8',\n",
       "   'unique_slug': 'create-copilot-inside-your-notebooks-that-can-chat-with-graphs-write-code-and-more-e9390e2b9ed8',\n",
       "   'image_url': 'https://miro.medium.com/1*DETUd5sgj8GAQAVvLMrkEQ.png',\n",
       "   'lang': 'en',\n",
       "   'is_series': False,\n",
       "   'is_locked': False,\n",
       "   'is_shortform': False,\n",
       "   'top_highlight': '',\n",
       "   'content': {'id': 'e9390e2b9ed8',\n",
       "    'content': 'Create a Copilot inside your notebooks that can chat with graphs, write code, and more\\n\\nAn Intelligent Help for Efficient Programming\\n\\nOur Copilot answering how many outliers present in cell 16 graph\\n\\nThe above is an example of one of the copilot features that you are going to build.%graphsignals to our copilot that I need to ask question related to graphs. It can take a cell reference, such as --in16, which contains the graph we need to analyze. Also, the input prompt specifies what information you need to ask about the graph, and it outputs accurate results. It can operate in Anaconda Jupyter Notebooks, VS Code Notebooks, Jupyter Lab, or any local notebook environment you work in.\\n\\nShort Story\\n\\nGitHub Copilot is free for verified students, teachers, and maintainers of popular open-source projects. Meanwhile, Google is soon expected to release its own version based on Gemini, a recently launched multi-model, but it will likely require a budget-friendly subscription.\\n\\nWhat if you don’t fall into any category eligible for GitHub Copilot or you’re not in the mood to pay for Google’s future Copilot release?\\n\\nI recently explored a project by Jupyter AI that allows you to code through AI, depending on open-source LLM or the OpenAI API. However, a challenge arises with the pricing or suboptimal performance of the open-source LLM. Although it is good, Many of us rely on ChatGPT while coding. What sets Gemini Multi-Model apart is that it provides a free API and a large context window. I used the opportunity and decided to build a Copilot on top of it to test its capabilities.\\n\\n— Code is available in my repository -\\n\\nGitHub - FareedKhan-dev/create-copilot-in-your-notebooks\\nContribute to FareedKhan-dev/create-copilot-in-your-notebooks development by creating an account on GitHub.github.com\\n\\nTable of Contents\\n\\nSetting the stage\\n\\nSimple Chat Feature\\n\\nChat with Code Feature\\n\\nGenerate Code Feature\\n\\nGenerate Relational Code Feature\\n\\nChat with Graph Feature\\n\\nChat with Files Feature\\n\\nCompiling the Code\\n\\nWhat’s Next\\n\\nSetting the stage\\n\\nTo create features of our Copilot, the first step is to initialize Gemini MultiModel. For that, you need to install a few libraries:\\n\\n# Install necessary libraries\\npip install -q -U google-generativeai grpcio grpcio-tools\\n\\nNow, we need to import the necessary library that will fetch Gemini LLM API calls and instantiate the required API key.\\n\\n# Import the Google Generative AI library\\nimport google.generativeai as genai\\n\\n# Initialize the GenerativeModel with \\'gemini-pro\\' for chat and code\\ntext_model = genai.GenerativeModel(\\'gemini-pro\\')\\n\\n# Initialize the GenerativeModel with \\'gemini-pro-vision\\' for graphs\\nimage_model = genai.GenerativeModel(\\'gemini-pro-vision\\')\\n\\n# Configure the library with your API key\\ngenai.configure(api_key=\"Your-API-key\")\\n\\nWe have loaded two models, gemini-pro, which serves as our text model for generating code or engaging in code-related conversations, and gemini-pro-vision, which will be used to manage image-related features of our Copilot. You can obtain your API key from here for free. Next, we need to import the library that we will be using to create Copilot functions.\\n\\n# Regular expression for pattern matching\\nimport re\\n\\n# IPython for working with IPython environment\\nimport IPython\\n\\n# OS for interacting with the operating system\\nimport os\\n\\n# JSON for working with JSON data\\nimport json\\n\\n# Base64 for encoding and decoding base64 data\\nimport base64\\n\\n# Image class from IPython.display for displaying images\\nfrom IPython.display import Image\\n\\n# register_line_magic for registering custom magic commands\\nfrom IPython.core.magic import register_line_magic\\n\\nLet’s start coding a simple feature of our Copilot, which is to chat. The reason for starting with this feature is that it will make it easier to understand later code when we build more complex features.\\n\\nSimple Chat Feature\\n\\nYou are coding in your notebooks, and then you realize you need to ask something to ChatGPT. To avoid switching to a browser tab for chatting, we will create a chat feature that allows you to chat right next to your code cell. Our \"chat\" function takes one input, which is our prompt, and in response, the Gemini text model will provide an answer.\\n\\n# Registering a Jupyter Notebook magic command named \\'chat\\'\\n@register_line_magic\\ndef chat(contents):\\n    # Generating a response using the \\'generate_content\\' method of the \\'text_model\\' object\\n    # The method takes a formatted string containing the provided \\'contents\\'\\n    response = text_model.generate_content(f\\'\\'\\'\\n                                    Answer the question in a short quick readable paragraph, dont provide answer in any format or code\\n                                    {contents}\\n                                    \\'\\'\\').text\\n\\n    # Printing the generated response to the output\\n    print(response)\\n\\nthere are two important lines in our chat function, one is@register_line_magic decorator. It will help us to call our function with %chat rather than chat( ). This makes it more like an AI-like feel, although this is not necessary. The second important part is the prompt template that is used. The reason for choosing this prompt is that Gemini has a habit to generate chat responses in markdown format most of the time. Therefore, it is necessary to instruct Gemini that the response must not be in markdown or code format. You can update the prompt template based on your needs.\\n\\nYou can use the \"chat\" feature in any of your code cells. For this, you need to pass %chat [your_question], and it will print the response.\\n\\n# Running Chat Feature\\n%chat What are some useful libraries for coding neural networks in Python\\n\\nhow chat function works\\n\\nChat with Code Feature\\n\\nThis feature gives you the ability to chat with your code within your notebook, you don’t have to use ChatGPT separately to go there, paste the code, and ask questions. The \"Chat with Code\" function requires two things, your prompt and the code on which you want to ask a question.\\n\\n# Define a function named \\'chatn\\' that takes \\'contents\\' as a parameter\\n@register_line_magic\\ndef chatn(contents):\\n    try:\\n        # Use regular expression to find all occurrences of \\'--in\\' followed by digits in \\'contents\\'\\n        numbers = [int(match.group().replace(\\'--in\\', \\'\\')) for match in re.finditer(r\\'--in\\\\d+\\', contents)]\\n\\n        # Remove the found pattern \\'--in\\\\d+\\' from \\'contents\\'\\n        contents_filter = re.sub(r\\'--in\\\\d+\\', \\'\\', contents)\\n\\n        # Check if there are any references (numbers) found\\n        if numbers:\\n            # Retrieve the current cell contents for all references using the IPython \\'In\\' variable\\n            current_cell_contents = [In[number] for number in numbers]\\n\\n            # Combine the contents into a single string with line breaks\\n            combined_content = \\'\\\\n\\'.join(current_cell_contents)\\n\\n            # Execute the text_model to generate response\\n            response = text_model.generate_content(f\\'\\'\\'\\n                                            {combined_content}\\n                                            Answer the question in a short readable paragraph, don\\'t provide the answer in any format or code\\n                                            {contents_filter}\\n                                            \\'\\'\\').text\\n\\n            # Print the generated response\\n            print(response)\\n\\n        else:\\n            # Print an error message if no references are found\\n            print(\\'Please provide a correct codeblock reference.\\')\\n\\n    except Exception as e:\\n        # Print an error message if an exception occurs\\n        print(\\'Please provide a correct codeblock reference.\\')\\n\\nLet’s understand our chatn function. The try-except block is used to avoid any errors in case you didn\\'t pass a cell reference in it. The first thing we do is use regex to extract all --in patterns for cell references and clean the prompt to avoid passing it in the Gemini API. I have used the --in format for cell number references because it is easier to remember. In[number] will fetch all the code from the cell numbers you mentioned in your prompt, merge it, and pass it along with your cleaned prompt. You can pass as many cell references as you want, and there is no need to order them.\\n\\nTo use the \"Chat with Code\" feature, you need to pass %chatn [cell references][your_question], and it will print the response.\\n\\n# Running Chat with Code Feature\\n%chatn --in17 --in11 I sum element wise but it is not working\\n\\nHow chat with code feature works\\n\\nYou may think it is a very easy question, but it will work on more complex code.\\n\\nGenerate Code Feature\\n\\nGenerating code is one of the most important features that you will most probably be using every minute. There are two versions we will be coding, one is to generate code based on your prompt, and the second is to generate relational code, which you will see in the next section. The simple \"Generate Code\" function takes one input, which is your prompt, and it will generate code in the very next cell.\\n\\n# Register a custom line magic command\\n@register_line_magic\\ndef code(contents):\\n\\n    # Get the IPython shell instance\\n    from IPython.core.getipython import get_ipython\\n    shell = get_ipython()\\n\\n    # Generate code content using a text model\\n    response = text_model.generate_content(f\\'\\'\\'\\n                                    write a python code that and dont answer anything else\\n                                    {contents}\\n                                    \\'\\'\\').text\\n\\n    # Remove ``` and python from the response\\n    response = response.replace(\\'```\\', \\'\\')\\n\\n    # Clean up the response\\n    response = response.replace(\\'python\\', \\'\\').strip(\\'\\\\n\\').rstrip(\\'\\\\n\\').replace(\\'```python\\', \\'\\')\\n\\n    # Prepare payload for setting the next input\\n    payload = dict(\\n        source=\\'set_next_input\\',\\n        text=response,\\n        replace=False,\\n    )\\n\\n    # Write the payload to the IPython shell\\n    shell.payload_manager.write_payload(payload, single=False)\\n\\nIn our code function, the get_ipython module is responsible for generating code right next to the current cell where you provide the prompt. Cleaning is necessary because the generated Python code contains some extra characters that need to be removed. The payload is going to take the response of our Gemini model and create a new cell to paste it.\\n\\nTo use the \"Generate Code\" feature, you need to pass %code [your_prompt], and it will create your requested code in the next cell.\\n\\n# Running Generate Code Feature\\n%code load my data.csv and take random sample of 100 rows\\n\\nhow generate code feature works\\n\\nGenerate Relational Code Feature\\n\\nThe relational coding feature is very important because most of the time, you will likely be coding on top of some other code. The good thing is that this feature is same as what we use in the chatn function. The \"Relational Code\" function requires two things, your prompt and the code which you want to relate.\\n\\n# Define a function named \\'coden\\' that takes \\'contents\\' as a parameter\\n@register_line_magic\\ndef coden(contents):\\n    try:\\n\\n        # Get the IPython shell instance\\n        from IPython.core.getipython import get_ipython\\n        shell = get_ipython()\\n\\n        # Use regular expression to find all occurrences of \\'--in\\' followed by digits in \\'contents\\'\\n        numbers = [int(match.group().replace(\\'--in\\', \\'\\')) for match in re.finditer(r\\'--in\\\\d+\\', contents)]\\n\\n        # Remove the found pattern \\'--in\\\\d+\\' from \\'contents\\'\\n        contents_filter = re.sub(r\\'--in\\\\d+\\', \\'\\', contents)\\n\\n        # Check if there are any references (numbers) found\\n        if numbers:\\n            # Retrieve the current cell contents for all references using the IPython \\'In\\' variable\\n            current_cell_contents = [In[number] for number in numbers]\\n\\n            # Combine the contents into a single string with line breaks\\n            combined_content = \\'\\\\n\\'.join(current_cell_contents)\\n\\n            # Execute the text_model to generate code\\n            response = text_model.generate_content(f\\'\\'\\'{combined_content}\\n                                                  {contents_filter}\\n                                                  please write Python code and don\\'t answer anything else, dont provide output of the code\\n                                                  \\'\\'\\').text\\n            # Remove ``` and python from the response\\n            response = response.replace(\\'```\\', \\'\\')\\n\\n            # Clean up the response\\n            response = response.replace(\\'python\\', \\'\\').strip(\\'\\\\n\\').rstrip(\\'\\\\n\\').replace(\\'```python\\', \\'\\')\\n\\n            # Prepare payload for setting the next input\\n            payload = dict(\\n                source=\\'set_next_input\\',\\n                text=response,\\n                replace=False,\\n            )\\n\\n            # Write the payload to the IPython shell\\n            shell.payload_manager.write_payload(payload, single=False)\\n\\n        else:\\n            # Print an error message if no references are found\\n            print(\\'Please provide a correct codeblock reference.\\')\\n\\n    except Exception as e:\\n        # Print an error message if an exception occurs\\n        print(\\'Please provide a correct codeblock reference.\\')\\n\\npayload and cleaning text code are used from the code function, while rest of the code is taken from the chatn function. To use the \"Relational Code\" feature, you need to pass %coden [cell references] [your_prompt], and it will create your requested code in the next cell. You can pass as many cell references as you want.\\n\\nTo use the \"Relational Code\" feature, you need to pass %code [cell_references] [your_prompt], and it will create your requested code in the next cell.\\n\\n# Running Relational Code Feature\\n%coden --in83 --in76 multiply y with each x item\\n\\nHow relational code works\\n\\nChat with Graph Feature\\n\\nThis feature is going to be a complicated one. Let’s build it step by step. First, you have to programmatically fetch the filename in which you are writing code.\\n\\n# Import the IPython module\\nimport IPython\\n\\n# Import the os module for interacting with the operating system\\nimport os\\n\\n# Extract the local variables from the IPython environment\\nfile_path = IPython.extract_module_locals()[1][\\'__vsc_ipynb_file__\\']\\n\\n# Extract the base name (file name) from the file path\\nfile_name = os.path.basename(file_path)\\n\\n# Return the file name\\nprint(file_name)\\n\\n\\n############### OUTPUT ###############\\n\\n      myfile.ipynb\\n  \\n############### OUTPUT ############### \\n\\nThis would only work in VSCode but not in Jupyter Lab or Anaconda notebooks. If you don’t use VSCode, you can skip this step because our final code will have this ability, allowing you to pass the filename manually in your prompt. Next, we need to load this notebook in json.\\n\\n# Import the json module for working with JSON data\\nimport json\\n\\nimport base64\\nfrom IPython.display import Image\\n\\n# Open the notebook file in read mode\\nwith open(file_name, \"r\") as f:\\n    # Load the content of the notebook file as JSON\\n    notebook_json = json.load(f)\\n\\nOnce we load the notebook file, we can loop through the data and fetch that specific cell output where our graph exists. Suppose our graph exist at cell number 65.\\n\\n# Import the base64 module for encoding and decoding base64 data\\nimport base64\\n\\n# Import the Image class from the IPython.display module for displaying images in an IPython environment\\nfrom IPython.display import Image\\n\\n####### Cell Number #######\\ncell_number = 65\\n\\n# Find the cell in the notebook JSON with execution count equal to 65\\nelement = next(cell for cell in notebook_json[\\'cells\\'] if \\'execution_count\\' in cell and cell[\\'execution_count\\'] == cell_number)\\n\\n# Extract the base64-encoded PNG image data from the cell\\'s outputs\\nimage_data = element[\\'outputs\\'][0][\\'data\\'][\\'image/png\\']\\n\\n# Decode the base64-encoded image data\\nimage_base64 = base64.b64decode(image_data)\\n\\n# Save the decoded image data as a JPG file in the local directory\\nwith open(\\'img_code.jpg\\', \\'wb\\') as f:\\n    f.write(image_base64)\\n\\n# Assuming \\'Image\\' is imported from the IPython.display module, load the saved image using the Image() function\\nimage = Image(filename=\\'img_code.jpg\\')\\n\\nGemini image model only takes images that are locally stored, you have to save that extracted graph and load the image using the Image module. we can use this approach to build our chat with the graph feature. It will take two inputs, one is the prompt, and the second is the cell reference which contains the graph.\\n\\n# Try to get the current notebook filename using IPython\\ntry:\\n    file_name = IPython.extract_module_locals()[1][\\'__vsc_ipynb_file__\\']\\n\\n    # Extract the base name (file name) from the file path\\n    file_name = os.path.basename(file_name)\\n\\nexcept:\\n    # If an exception occurs, print a message indicating no file\\n    file_name = None\\n\\n# Register a custom magic command for the Jupyter notebook\\n@register_line_magic\\ndef graph(contents):\\n    # Search for the pattern --in<number>\\n    pattern = re.compile(r\\'--in\\\\d+\\')\\n\\n    # Find the first occurrence of the pattern in the contents\\n    match = pattern.search(contents)\\n\\n    # Remove the pattern from the contents\\n    contents_filter = pattern.sub(\\'\\', contents)\\n\\n    # Define a new pattern for --filename=<word>\\n    pattern_f = re.compile(r\\'--filename=\\\\w+\\')\\n\\n    # Find the first occurrence of the new pattern in the contents\\n    match_f = pattern_f.search(contents)\\n\\n    # Remove the new pattern from the filtered contents\\n    contents_filter = pattern_f.sub(\\'\\', contents_filter)\\n\\n    # If the --in<number> pattern is found\\n    if match:\\n        # Get the global variable file_name\\n        global file_name\\n\\n        # Check if file_name is available from the IPython magic command\\n        if file_name:\\n            notebookName = file_name\\n            with open(notebookName, \"r\") as f:\\n                # Load the notebook JSON data\\n                notebook_json = json.load(f)\\n        elif match_f:\\n            # Extract the filename from the --filename=<word> pattern\\n            match_c = match_f.group().replace(\\'--filename=\\', \\'\\')\\n            notebookName = match_c + \\'.ipynb\\'\\n            with open(notebookName, \"r\") as f:\\n                # Load the notebook JSON data\\n                notebook_json = json.load(f)\\n        else:\\n            # If neither file_name nor --filename=<word> is provided, print an error message\\n            return \\'Please provide a correct file path using --filename=<filename>.ipynb, e.g., --filename=mycode.ipynb\\'\\n\\n        # Extract the number from the --in<number> pattern\\n        number = int(match.group().replace(\\'--in\\', \\'\\'))\\n\\n        # Find the cell with the specified execution_count in the notebook JSON data\\n        element = next(cell for cell in notebook_json[\\'cells\\'] if \\'execution_count\\' in cell and cell[\\'execution_count\\'] == number)\\n\\n        # Extract image data from the cell\\'s output\\n        image_data = element[\\'outputs\\'][0][\\'data\\'][\\'image/png\\']\\n\\n        # Decode base64 image data\\n        image_base64 = base64.b64decode(image_data)\\n\\n        # Save the image in the local directory as img_code.jpg\\n        with open(\\'img_code.jpg\\', \\'wb\\') as f:\\n            f.write(image_base64)\\n\\n        # Load the image using the Image() function\\n        image = Image(filename=\\'img_code.jpg\\')\\n\\n        # extract information using image model\\n        response = image_model.generate_content([contents_filter, image])\\n        print(response.text)\\n    else:\\n        # If --in<number> pattern is not found, print an error message\\n        print(\\'Please provide a correct code block reference.\\')\\n\\nConversations with graphs require the image_model, and we have performed text pattern extraction for filename in the same way as we have done for --in cell references. To use the \"Chat with Graph\" feature, you need to pass %graph [single_cell_reference] [your_prompt] [filename], and it will print the response.\\n\\n# Running Chat with Image Feature\\n%coden --in143 how many outliers are there\\n\\nHow chat with graph feature works (working in jupyterLab, filename is important)\\n\\nVS Code Result Chat with graph feature (no filename needed)\\n\\nChat with Files Feature\\n\\nSmall-scale projects often depend on multiple Python files. This feature is helpful when you want to chat with py files within your notebook instead of inspecting their code one by one. The \"Chat with Files\" function requires two things, your prompt and the folder name which contain py files.\\n\\n# Register a custom magic command for IPython\\n@register_line_magic\\ndef chatf(contents):\\n    try:\\n        # Parse the folder name from the provided argument\\n        folder_match = re.search(r\\'--folder_name=(\\\\S+)\\', contents)\\n        if not folder_match:\\n            # Print an error message if folder name is not provided in the correct format\\n            print(\"Please provide a valid folder name using the format \\'--folder_name=<folder_name>\\'.\")\\n            return\\n\\n        # Extract the folder name from the regex match\\n        folder_name = folder_match.group(1)\\n\\n        # Get a list of Python files in the specified folder\\n        python_files = [file for file in os.listdir(folder_name) if file.endswith(\\'.py\\')]\\n\\n        # Check if any Python files were found\\n        if not python_files:\\n            print(f\"No Python files found in the folder \\'{folder_name}\\'.\")\\n            return\\n\\n        # Initialize an empty string to store combined content\\n        combined_content = \"\"\\n\\n        # Iterate through each Python file in the folder\\n        for file_name in python_files:\\n            with open(os.path.join(folder_name, file_name), \\'r\\') as file:\\n                # Read the content of the file\\n                file_content = file.read()\\n\\n                # Format the combined content with file name and its code\\n                combined_content += f\"\\\\nfile: {file_name}\\\\n{file_content}\\\\n{\\'_\\'*15}\\\\n\"\\n\\n        # Remove the pattern of folder from the input contents\\n        contents_filter = re.sub(r\\'--folder_name=\\\\S+\\', \\'\\', contents)\\n\\n        # Generate content using a model and display the response\\n        response = text_model.generate_content(f\\'\\'\\'\\n                                        {combined_content}\\n                                        Answer the question in a short readable paragraph, don\\'t provide the answer in any format or code\\n                                        {contents_filter}\\n                                        \\'\\'\\').text\\n        print(response)\\n\\n    except Exception as e:\\n        # Print an error message if an exception occurs\\n        print(f\\'An error occurred: {str(e)}\\')\\n\\nThe chatf function will take a folder reference, similar to the way we provide a cell reference. It will then merge all file names with their content, and rest of the code will remain the same which we use in our chatn function. To use the \"Chat with Files\" feature, you need to pass %chatf [single_folder_reference] [your_prompt], and it will print the response.\\n\\n# Running chat with files Feature\\n%chatf --folder_name=myfolder How to clean and format data\\n\\nHow chat with files feature works\\n\\nCompiling the Features\\n\\nYou don’t want to type each feature function again and again for different projects, it will be a time-consuming task. What you can do is simply merge all your functions in one py file. I named it my_copilot.py, and then I can simply import this module and use any feature from it.\\n\\n# Importing all features of your copilot\\nfrom my_copilot import *\\n\\n# using generate code feature\\n%code load my data.csv file using pandas\\n\\nWhat’s Next\\n\\nThere are many more features you can create with the help of the knowledge and code you have seen in this blog. For example, you can create a multi-graph chat, or instead of chatting with files, you can extend this to code with files and more. The cool thing is that the majority of the tasks you will be creating contain most of the code that you have already seen here.\\n\\nThanks for reading this extensive post!'}},\n",
       "  {'id': '16d4e64e6eb1',\n",
       "   'title': 'Solving Transformer by Hand: A Step-by-Step Math Example',\n",
       "   'subtitle': 'Performing numerous matrix multiplications to solve the encoder and decoder parts of the transformer',\n",
       "   'author': 'b856005e5ecd',\n",
       "   'publication_id': '5517fd7b58a6',\n",
       "   'published_at': '2023-12-18 12:41:09',\n",
       "   'last_modified_at': '2023-12-21 04:19:24',\n",
       "   'tags': ['data-science',\n",
       "    'artificial-intelligence',\n",
       "    'machine-learning',\n",
       "    'python',\n",
       "    'deep-learning'],\n",
       "   'topics': ['machine-learning', 'data-science', 'programming'],\n",
       "   'claps': 1717,\n",
       "   'voters': 346,\n",
       "   'word_count': 2607,\n",
       "   'responses_count': 26,\n",
       "   'reading_time': 12.787735849056602,\n",
       "   'url': 'https://levelup.gitconnected.com/understanding-transformers-from-start-to-end-a-step-by-step-math-example-16d4e64e6eb1',\n",
       "   'unique_slug': 'understanding-transformers-from-start-to-end-a-step-by-step-math-example-16d4e64e6eb1',\n",
       "   'image_url': 'https://miro.medium.com/1*99eK1ktrNGPyt4IPowcAgg.png',\n",
       "   'lang': 'en',\n",
       "   'is_series': False,\n",
       "   'is_locked': False,\n",
       "   'is_shortform': False,\n",
       "   'top_highlight': 'When training, there are two inputs to the decoder. One is from the encoder, where the output matrix of the last add and norm layer serves as the query and key for the second multi-head attention layer in the decoder part. Below is the visualization of it (from batool haider):',\n",
       "   'content': {'id': '16d4e64e6eb1',\n",
       "    'content': 'Transformer in NYC (created from phtofunia)\\n\\nSolving Transformer by Hand: A Step-by-Step Math Example\\n\\nI have already written a detailed blog on how transformers work using a very small sample of the dataset, which will be my best blog ever because it has elevated my profile and given me the motivation to write more. However, that blog is incomplete as it only covers 20% of the transformer architecture and contains numerous calculation errors, as pointed out by readers. After a considerable amount of time has passed since that blog, I will be revisiting the topic in this new blog.\\n\\nMy previous blog on transformer architecture (covers only 20%):\\n\\nUnderstanding Transformers: A Step-by-Step Math Example - Part 1\\nI understand that the transformer architecture may seem scary, and you might have encountered various explanations on…medium.com\\n\\nI plan to explain the transformer again in the same manner as I did in my previous blog (for both coders and non-coders), providing a complete guide with a step-by-step approach to understanding how they work.\\n\\nTable of Contents\\n\\nDefining our Dataset\\n\\nFinding Vocab Size\\n\\nEncoding\\n\\nCalculating Embedding\\n\\nCalculating Positional Embedding\\n\\nConcatenating Positional and Word Embeddings\\n\\nMulti Head Attention\\n\\nAdding and Normalizing\\n\\nFeed Forward Network\\n\\nAdding and Normalizing Again\\n\\nDecoder Part\\n\\nUnderstanding Mask Multi Head Attention\\n\\nCalculating the Predicted Word\\n\\nImportant Points\\n\\nConclusion\\n\\nStep 1 - Defining our Dataset\\n\\nThe dataset used for creating ChatGPT is 570 GB. On the other hand, for our purposes, we will be using a very small dataset to perform numerical calculations visually.\\n\\nOur entire dataset containing only three sentences\\n\\nOur entire dataset contains only three sentences, all of which are dialogues taken from a TV show. Although our dataset is cleaned, in real-world scenarios like ChatGPT creation, cleaning a 570 GB dataset requires a significant amount of effort.\\n\\nStep 2— Finding Vocab Size\\n\\nThe vocabulary size determines the total number of unique words in our dataset. It can be calculated using the below formula, where N is the total number of words in our dataset.\\n\\nvocab_size formula where N is total number of words\\n\\nIn order to find N, we need to break our dataset into individual words.\\n\\ncalculating variable N\\n\\nAfter obtaining N, we perform a set operation to remove duplicates, and then we can count the unique words to determine the vocabulary size.\\n\\nfinding vocab size\\n\\nTherefore, the vocabulary size is 23, as there are 23 unique words in our dataset.\\n\\nStep 3 - Encoding\\n\\nNow, we need to assign a unique number to each unique word.\\n\\nencoding our unique words\\n\\nAs we have considered a single token as a single word and assigned a number to it, ChatGPT has considered a portion of a word as a single token using this formula: 1 Token = 0.75 Word\\n\\nAfter encoding our entire dataset, it’s time to select our input and start working with the transformer architecture.\\n\\nStep 4 - Calculating Embedding\\n\\nLet’s select a sentence from our corpus that will be processed in our transformer architecture.\\n\\nInput sentence for transformer\\n\\nWe have selected our input, and we need to find an embedding vector for it. The original paper uses a 512-dimensional embedding vector for each input word.\\n\\nOriginal Paper uses 512 dimension vector\\n\\nSince, for our case, we need to work with a smaller dimension of embedding vector to visualize how the calculation is taking place. So, we will be using a dimension of 6 for the embedding vector.\\n\\nEmbedding vectors of our input\\n\\nThese values of the embedding vector are between 0 and 1 and are filled randomly in the beginning. They will later be updated as our transformer starts understanding the meanings among the words.\\n\\nStep 5 - Calculating Positional Embedding\\n\\nNow we need to find positional embeddings for our input. There are two formulas for positional embedding depending on the position of the ith value of that embedding vector for each word.\\n\\nPositional Embedding formula\\n\\nAs you do know, our input sentence is \"when you play the game of thrones\" and the starting word is \"when\" with a starting index (POS) value is 0, having a dimension (d) of 6. For i from 0 to 5, we calculate the positional embedding for our first word of the input sentence.\\n\\nPositional Embedding for word: When\\n\\nSimilarly, we can calculate positional embedding for all the words in our input sentence.\\n\\nCalculating Positional Embeddings of our input (The calculated values are rounded)\\n\\nStep 6 - Concatenating Positional and Word Embeddings\\n\\nAfter calculating positional embedding, we need to add word embeddings and positional embeddings.\\n\\nconcatenation step\\n\\nThis resultant matrix from combining both matrices (Word embedding matrix and positional embedding matrix) will be considered as an input to the encoder part.\\n\\nStep 7 - Multi Head Attention\\n\\nA multi-head attention is comprised of many single-head attentions. It is up to us how many single heads we need to combine. For example, LLaMA LLM from Meta has used 32 single heads in the encoder architecture. Below is the illustrated diagram of how a single-head attention looks like.\\n\\nSingle Head attention in Transformer\\n\\nThere are three inputs: query, key, and value. Each of these matrices is obtained by multiplying a different set of weights matrix from the Transpose of same matrix that we computed earlier by adding the word embedding and positional embedding matrix.\\n\\nLet’s say, for computing the query matrix, the set of weights matrix must have the number of rows the same as the number of columns of the transpose matrix, while the columns of the weights matrix can be any; for example, we suppose 4 columns in our weights matrix. The values in the weights matrix are between 0 and 1 randomly, which will later be updated when our transformer starts learning the meaning of these words.\\n\\ncalculating Query matrix\\n\\nSimilarly, we can compute the key and value matrices using the same procedure, but the values in the weights matrix must be different for both.\\n\\nCalculating Key and Value Matrices\\n\\nSo, after multiplying matrices, the resultant query, key, and values are obtained:\\n\\nQuery, Key, Value matrices\\n\\nNow that we have all three matrices, let’s start calculating single-head attention step by step.\\n\\nmatrix multiplication between Query and Key\\n\\nFor scaling the resultant matrix, we have to reuse the dimension of our embedding vector, which is 6.\\n\\nscaling the resultant matrix with dimension 5\\n\\nThe next step of masking is optional, and we won’t be calculating it. Masking is like telling the model to focus only on what’s happened before a certain point and not peek into the future while figuring out the importance of different words in a sentence. It helps the model understand things in a step-by-step manner, without cheating by looking ahead.\\n\\nSo now we will be applying the softmax operation on our scaled resultant matrix.\\n\\nApplying softmax on resultant matrix\\n\\nDoing the final multiplication step to obtain the resultant matrix from single-head attention.\\n\\ncalculating the final matrix of single head attention\\n\\nWe have calculated single-head attention, while multi-head attention comprises many single-head attentions, as I stated earlier. Below is a visual of how it looks like:\\n\\nMulti Head attention in Transformer\\n\\nEach single-head attention has three inputs: query, key, and value, and each three have a different set of weights. Once all single-head attentions output their resultant matrices, they will all be concatenated, and the final concatenated matrix is once again transformed linearly by multiplying it with a set of weights matrix initialized with random values, which will later get updated when the transformer starts training.\\n\\nSince, in our case, we are considering a single-head attention, but this is how it looks if we are working with multi-head attention.\\n\\nSingle Head attention vs Multi Head attention\\n\\nIn either case, whether it’s single-head or multi-head attention, the resultant matrix needs to be once again transformed linearly by multiplying a set of weights matrix.\\n\\nnormalizing single head attention matrix\\n\\nMake sure the linear set of weights matrix number of columns must be equal to the matrix that we computed earlier (word embedding + positional embedding) matrix number of columns, because the next step, we will be adding the resultant normalized matrix with (word embedding + positional embedding) matrix.\\n\\nOutput matrix of multi head attention\\n\\nAs we have computed the resultant matrix for multi-head attention, next, we will be working on adding and normalizing step.\\n\\nStep 8 - Adding and Normalizing\\n\\nOnce we obtain the resultant matrix from multi-head attention, we have to add it to our original matrix. Let’s do it first.\\n\\nAdding matrices to perform add and norm step\\n\\nTo normalize the above matrix, we need to compute the mean and standard deviation row-wise for each row.\\n\\ncalculating meand and std.\\n\\nwe subtract each value of the matrix by the corresponding row mean and divide it by the corresponding standard deviation.\\n\\nnormalizing the resultant matrix\\n\\nAdding a small value of error prevents the denominator from being zero and avoids making the entire term infinity.\\n\\nStep 9 - Feed Forward Network\\n\\nAfter normalizing the matrix, it will be processed through a feedforward network. We will be using a very basic network that contains only one linear layer and one ReLU activation function layer. This is how it looks like visually:\\n\\nFeed Forward network comparison\\n\\nFirst, we need to calculate the linear layer by multiplying our last calculated matrix with a random set of weights matrix, which will be updated when the transformer starts learning, and adding the resultant matrix to a bias matrix that also contains random values.\\n\\nCalculating Linear Layer\\n\\nAfter calculating the linear layer, we need to pass it through the ReLU layer and use its formula.\\n\\nCalculating ReLU Layer\\n\\nStep 10 - Adding and Normalizing Again\\n\\nOnce we obtain the resultant matrix from feed forward network, we have to add it to the matrix that is obtained from previous add and norm step, and then normalizing it using the row wise mean and standard deviation.\\n\\nAdd and Norm after Feed Forward Network\\n\\nThe output matrix of this add and norm step will serve as the query and key matrix in one of the multi-head attention mechanisms present in the decoder part, which you can easily understand by tracing outward from the add and norm to the decoder section.\\n\\nStep 11 - Decoder Part\\n\\nThe good news is that up until now, we have calculated Encoder part, all the steps that we have performed, from encoding our dataset to passing our matrix through the feedforward network, are unique. It means we haven’t calculated them before. But from now on, all the upcoming steps that is the remaining architecture of the transformer (Decoder part) are going to involve similar kinds of matrix multiplications.\\n\\nTake a look at our transformer architecture. What we have covered so far and what we have to cover yet:\\n\\nUpcoming steps illustration\\n\\nWe won’t be calculating the entire decoder because most of its portion contains similar calculations to what we have already done in the encoder. Calculating the decoder in detail would only make the blog lengthy due to repetitive steps. Instead, we only need to focus on the calculations of the input and output of the decoder.\\n\\nWhen training, there are two inputs to the decoder. One is from the encoder, where the output matrix of the last add and norm layer serves as the query and key for the second multi-head attention layer in the decoder part. Below is the visualization of it (from batool haider):\\n\\nVisualization is from Batool Haider\\n\\nWhile the value matrix comes from the decoder after the first add and norm step.\\n\\nThe second input to the decoder is the predicted text. If you remember, our input to the encoder is when you play game of thrones so the input to the decoder is the predicted text, which in our case is you win or you die .\\n\\nBut the predicted input text needs to follow a standard wrapping of tokens that make the transformer aware of where to start and where to end.\\n\\ninput comparison of encoder and decoder\\n\\nWhere <start> and <end> are two new tokens being introduced. Moreover, the decoder takes one token as an input at a time. It means that <start> will be served as an input, and you must be the predicted text for it.\\n\\nDecoder input <start> word\\n\\nAs we already know, these embeddings are filled with random values, which will later be updated during the training process.\\n\\nCompute rest of the blocks in the same way that we computed earlier in the encoder part.\\n\\nCalculating Decoder\\n\\nBefore diving into any further details, we need to understand what masked multi-head attention is, using a simple mathematical example.\\n\\nStep 12 - Understanding Mask Multi Head Attention\\n\\nIn a Transformer, the masked multi-head attention is like a spotlight that a model uses to focus on different parts of a sentence. It’s special because it doesn’t let the model cheat by looking at words that come later in the sentence. This helps the model understand and generate sentences step by step, which is important in tasks like talking or translating words into another language.\\n\\nSuppose we have the following input matrix, where each row represents a position in the sequence, and each column represents a feature:\\n\\ninpur matrix for masked multi head attentions\\n\\nNow, let’s understand the masked multi-head attention components having two heads:\\n\\nLinear Projections (Query, Key, Value): Assume the linear projections for each head: Head 1: Wq1\\u200b,Wk1\\u200b,Wv1\\u200b and Head 2: Wq2\\u200b,Wk2\\u200b,Wv2\\u200b\\n\\nCalculate Attention Scores: For each head, calculate attention scores using the dot product of Query and Key, and apply the mask to prevent attending to future positions.\\n\\nApply Softmax: Apply the softmax function to obtain attention weights.\\n\\nWeighted Summation (Value): Multiply the attention weights by the Value to get the weighted sum for each head.\\n\\nConcatenate and Linear Transformation: Concatenate the outputs from both heads and apply a linear transformation.\\n\\nLet’s do a simplified calculation:\\n\\nAssuming two conditions\\n\\nWq1\\u200b = Wk1 \\u200b= Wv1 \\u200b= Wq2\\u200b = Wk2 \\u200b= Wv2\\u200b = I, the identity matrix.\\n\\nQ=K=V=Input Matrix\\n\\nMask Multi Head Attention (Two Heads)\\n\\nThe concatenation step combines the outputs from the two attention heads into a single set of information. Imagine you have two friends who each give you advice on a problem. Concatenating their advice means putting both pieces of advice together so that you have a more complete view of what they suggest. In the context of the transformer model, this step helps capture different aspects of the input data from multiple perspectives, contributing to a richer representation that the model can use for further processing.\\n\\nStep 13 - Calculating the Predicted Word\\n\\nThe output matrix of the last add and norm block of the decoder must contain the same number of rows as the input matrix, while the number of columns can be any. Here, we work with 6.\\n\\nAdd and Norm output of decoder\\n\\nThe last add and norm block resultant matrix of the decoder must be flattened in order to match it with a linear layer to find the predicted probability of each unique word in our dataset (corpus).\\n\\nflattened the last add and norm block matrix\\n\\nThis flattened layer will be passed through a linear layer to compute the logits (scores) of each unique word in our dataset.\\n\\nCalculating Logits\\n\\nOnce we obtain the logits, we can use the softmax function to normalize them and find the word that contains the highest probability.\\n\\nFinding the Predicted word\\n\\nSo based on our calculations, the predicted word from the decoder is you.\\n\\nFinal output of decoder\\n\\nThis predicted word you, will be treated as the input word for the decoder, and this process continues until the <end> token is predicted.\\n\\nImportant Points\\n\\nThe above example is very simple, as it does not involve epochs or any other important parameters that can only be visualized using a programming language like Python.\\n\\nIt has shown the process only until training, while evaluation or testing cannot be visually seen using this matrix approach.\\n\\nMasked multi-head attentions can be used to prevent the transformer from looking at the future, helping to avoid overfitting your model.\\n\\nConclusion\\n\\nIn this blog, I have shown you a very basic way of how transformers mathematically work using matrix approaches. We have applied positional encoding, softmax, feedforward network, and most importantly, multi-head attention.\\n\\nIn the future, I will be posting more blogs on transformers and LLM as my core focus is on NLP. More importantly, if you want to build your own million-parameter LLM from scratch using Python, I have written a blog on it which has received a lot of appreciation on Medium. You can read it here:\\n\\nBuilding a Million-Parameter LLM from Scratch Using Python\\nA Step-by-Step Guide to Replicating LLaMA Architecturelevelup.gitconnected.com\\n\\nHave a great time reading!'}},\n",
       "  {'id': '3e71f406338b',\n",
       "   'title': 'Free GenAI APIs You Can Use in 2024',\n",
       "   'subtitle': 'Exploring the Latest Free GenAI APIs',\n",
       "   'author': 'b856005e5ecd',\n",
       "   'publication_id': '5517fd7b58a6',\n",
       "   'published_at': '2024-02-04 18:47:29',\n",
       "   'last_modified_at': '2024-02-04 18:47:29',\n",
       "   'tags': ['api',\n",
       "    'artificial-intelligence',\n",
       "    'data-science',\n",
       "    'machine-learning',\n",
       "    'ai'],\n",
       "   'topics': ['programming'],\n",
       "   'claps': 240,\n",
       "   'voters': 22,\n",
       "   'word_count': 1304,\n",
       "   'responses_count': 4,\n",
       "   'reading_time': 5.304088050314466,\n",
       "   'url': 'https://levelup.gitconnected.com/free-genai-apis-you-can-use-in-2024-3e71f406338b',\n",
       "   'unique_slug': 'free-genai-apis-you-can-use-in-2024-3e71f406338b',\n",
       "   'image_url': 'https://miro.medium.com/1*jRaq7jiSFE1HivnUiIJxzQ.png',\n",
       "   'lang': 'en',\n",
       "   'is_series': False,\n",
       "   'is_locked': False,\n",
       "   'is_shortform': False,\n",
       "   'top_highlight': '',\n",
       "   'content': {'id': '3e71f406338b',\n",
       "    'content': 'Free GenAI APIs You Can Use in 2024\\n\\nExploring the Latest Free GenAI APIs\\n\\nMany small-scale companies are offering powerful APIs at no cost or providing a free trial that may extend up to a year based on your usage. We will look into some of those APIs and explore their benefit and usage.\\n\\nAll the code of this blog is available in my GitHub Repository.\\n\\nGitHub - FareedKhan-dev/Free-GenAI-APIs-in-2024: We have listed some of the free and powerful GenAI…\\nWe have listed some of the free and powerful GenAI APIs and explore their benefit and usage. - GitHub …github.com\\n\\n1. Voyage AI\\n\\nVoyage is a team of leading AI researchers and engineers, building embedding models for better retrieval and RAG.\\n\\nAs good as OpenAI Embedding Models\\n\\nPrice: Currently Free (Feb 2024)\\n\\nDocumentation: https://docs.voyageai.com/\\n\\nGet Started: https://docs.voyageai.com/\\n\\nSupported Embedding models, and more to come.\\n\\nembedding models (more coming soon)\\n\\nTo install voyage library:\\n\\n# Use pip to insatll the \\'voyageai\\' Python package to the latest version.\\npip install voyageai\\n\\nlet’s use one of the embedding model voyage-2 and see its output:\\n\\n# Import the \\'voyageai\\' module\\nimport voyageai\\n\\n# Create a \\'Client\\' object from the \\'voyageai\\' module and initialize it with your API key\\nvo = voyageai.Client(api_key=\"<your secret voyage api key>\")\\n\\n# user query\\nuser_query = \"when apple is releasing their new Iphone?\"\\n\\n\\n# The \\'model\\' parameter is set to \"voyage-2\", and the \\'input_type\\' parameter is set to \"document\"\\ndocuments_embeddings = vo.embed(\\n    [user_query], model=\"voyage-2\", input_type=\"document\"\\n).embeddings\\n\\n# printing the embedding\\nprint(documents_embeddings)\\n\\n########### OUTPUT ###########\\n[ 0.12, 0.412, 0.573, ... 0.861 ] # dimension is 1024\\n########### OUTPUT ###########\\n\\n2. AnyScale AI\\n\\nAnyscale, the company behind Ray, releases APIs for LLM developers to run and fine-tune open-source LLMs quickly, cost-efficiently, and at scale.\\n\\nRunning/Fine-Tuning Powerful Open-Source LLM at a very low or no cost\\n\\nPrice (no credit card): Free tier $10, where $0.15 per Million/tokens\\n\\nDocumentation: https://docs.endpoints.anyscale.com/\\n\\nGet Started: https://app.endpoints.anyscale.com/welcome\\n\\nSupported LLM and Embedding models\\n\\nText Generation and Embedding Model from AnyScale\\n\\nAnyscale endpoints works with OpenAI library:\\n\\n# Use pip to insatll the \\'openai\\' Python package to the latest version.\\npip install openai\\n\\nlet’s use one of the Text generation LLM and see its output:\\n\\n# Import necessary modules\\nimport openai\\n\\n# Define the Anyscale endpoint token\\nANYSCALE_ENDPOINT_TOKEN = \"<your secret anyscale api key>\"\\n\\n# Create an OpenAI client with the Anyscale base URL and API key\\noai_client = openai.OpenAI(\\n    base_url=\"https://api.endpoints.anyscale.com/v1\",\\n    api_key=anyscale_key,\\n)\\n\\n# Define the OpenAI model to be used for chat completions\\nmodel = \"mistralai/Mistral-7B-Instruct-v0.1\"\\n\\n# Define a prompt for the chat completion\\nprompt = \\'\\'\\'hello, how are you?\\n\\'\\'\\'\\n\\n# Use the AnyScale model for chat completions\\n# Send a user message using the defined prompt\\nresponse = oai_client.chat.completions.create(\\n    model=model,\\n    messages=[\\n        {\"role\": \"user\", \"content\": prompt}\\n    ],\\n)\\n\\n# printing the response\\nprint(response.choices[0].message.content)\\n\\n\\n########### OUTPUT ###########\\nHello! I am just a computer program, so I dont have \\nfeelings or emotions like a human does ...\\n########### OUTPUT ###########\\n\\n3. Gemini Multi Model\\n\\nThis one you may already know, but it’s worth mentioning, Google released their Gemini Multi-Model last year, and its free tier API usage is what makes it more interesting.\\n\\nChat with text and images (Similar to GPT-4) and Embedding Models\\n\\nPrice: Free Version (60 Query per minute)\\n\\nDocumentation: https://ai.google.dev/docs\\n\\nGet Started: https://makersuite.google.com/app/apikey\\n\\nSupported Models\\n\\ngemini models\\n\\nTo install required libraries\\n\\n# Install necessary libraries\\npip install google-generativeai grpcio grpcio-tools\\n\\nTo use text model gemini-pro\\n\\n# importing google.generativeai as genai\\nimport google.generativeai as genai\\n\\n# setting the api key\\ngenai.configure(api_key=\"<your secret gemini api key>\")\\n\\n# setting the text model\\nmodel = genai.GenerativeModel(\\'gemini-pro\\')\\n\\n# generating response\\nresponse = model.generate_content(\"What is the meaning of life?\")\\n\\n# printing the response\\nprint(response.text)\\n\\n########### OUTPUT ###########\\nhe query of life purpose has perplexed people \\nacross centuries ... \\n########### OUTPUT ###########\\n\\nTo use image model gemini-pro-vision\\n\\n# importing google.generativeai as genai\\nimport google.generativeai as genai\\n\\n# setting the api key\\ngenai.configure(api_key=\"<your secret gemini api key>\")\\n\\n# setting the text model\\nmodel = genai.GenerativeModel(\\'gemini-pro-vision\\')\\n\\n# loading Image\\nimport PIL.Image\\nimg = PIL.Image.open(\\'cat_wearing_hat.jpg\\')\\n\\n# chating with image\\nresponse =  model.generate_content([img, \"Is there a cat in this image?\"])\\n\\n# printing the response\\nprint(response.text)\\n\\n########### OUTPUT ###########\\nYes there is a cat in this image\\n########### OUTPUT ###########\\n\\n4. Depth Anything AI\\n\\nImage depth estimation is about figuring out how far away objects in an image are. It’s an important problem in computer vision because it help in tasks such as self-driving cars. A Hugging Face space from Lihe Young offers an API through which you can find image depth.\\n\\nfind image depth in seconds without storing or loading the model\\n\\nPrice: Free (Required HuggingFace Token)\\n\\nGet HuggingFace Token: https://huggingface.co/settings/tokens\\n\\nWeb Demo: https://huggingface.co/spaces/LiheYoung/Depth-Anything\\n\\nSupported Models:\\n\\nhttps://huggingface.co/spaces/LiheYoung/Depth-Anything/tree/main/checkpoints\\n\\nTo install required libraries\\n\\n# Install necessary libraries\\npip install  gradio_client\\n\\nFinding image depth using depth-anything model.\\n\\nfrom gradio_client import Client\\n\\n# Your Hugging Face API token\\nhuggingface_token = \"YOUR_HUGGINGFACE_TOKEN\"\\n\\n# Create a Client instance with the URL of the Hugging Face model deployment\\nclient = Client(\"https://liheyoung-depth-anything.hf.space/--replicas/odat1/\")\\n\\n# Set the headers parameter with your Hugging Face API token\\nheaders = {\"Authorization\": f\"Bearer {huggingface_token}\"}\\n\\n# image link or path\\nmy_image = \"house.jpg\"\\n\\n# Use the Client to make a prediction, passing the headers parameter\\nresult = client.predict(\\n    my_image,\\n    api_name=\"/on_submit\",\\n    headers=headers  # Pass the headers with the Hugging Face API token\\n)\\n\\n# loading the result\\nfrom IPython.display import Image\\nimage_path = result[0][1]\\nImage(filename=image_path)\\n\\n\\nOutput of Depth estimation\\n\\n5. Screenshot to HTML/CSS\\n\\nYou can create a webpage template using an API provided by HuggingFace M4.\\n\\nJust take a screenshot of webpage and pass it in API.\\n\\nPrice: Free (Required HuggingFace Token)\\n\\nGet HuggingFace Token: https://huggingface.co/settings/tokens\\n\\nWeb Demo: https://huggingface … screenshot2html\\n\\nTo install required libraries\\n\\n# Install necessary libraries\\npip install  gradio_client\\n\\nConverting website screenshot to code using screenshot-to-code model.\\n\\n# Installing required library\\nfrom gradio_client import Client\\n\\n# Your Hugging Face API token\\nhuggingface_token = \"YOUR_HUGGINGFACE_TOKEN\"\\n\\n# Create a Client instance with the URL of the Hugging Face model deployment\\nclient = Client(\"https://huggingfacem4-screenshot2html.hf.space/--replicas/cpol9/\")\\n\\n# Set the headers parameter with your Hugging Face API token\\nheaders = {\"Authorization\": f\"Bearer {huggingface_token}\"}\\n\\n# website image link or path\\nmy_image = \"mywebpage_screenshot.jpg\"\\n\\n# Use the Client to generate code, passing the headers parameter\\nresult = client.predict(\\n    my_image,\\n    api_name=\"/model_inference\",\\n    headers=headers  # Pass the headers with the Hugging Face API token\\n)\\n\\n# printing the output\\nprinting(result)\\n\\n\\n########### OUTPUT ###########\\n<html>\\n<style>\\nbody {\\n...\\n</body>\\n</html>\\n########### OUTPUT ###########\\n\\ngenerated output comparison with actual image\\n\\n6. Whisper (Audio to Text)\\n\\nConvert audio to text using Whisper API.\\n\\nJust convert audio to text using API, without loading whisper model.\\n\\nPrice: Free (Required HuggingFace Token)\\n\\nGet HuggingFace Token: https://huggingface.co/settings/tokens\\n\\nWeb Demo: https://hugging … whisper\\n\\nTo install required libraries\\n\\n# Install necessary libraries\\npip install  gradio_client\\n\\nConverting audio to text using Whisper model.\\n\\n# Installing required library\\nfrom gradio_client import Client\\n\\n# Your Hugging Face API token\\nhuggingface_token = \"YOUR_HUGGINGFACE_TOKEN\"\\n\\n# Create a Client instance with the URL of the Hugging Face model deployment\\nclient = Client(\"https://huggingfacem4-screenshot2html.hf.space/--replicas/cpol9/\")\\n\\n# Set the headers parameter with your Hugging Face API token\\nheaders = {\"Authorization\": f\"Bearer {huggingface_token}\"}\\n\\n# audio link or path\\nmy_image = \"myaudio.mp4\"\\n\\n# Use the Client to generate response, passing the headers parameter\\nresult = client.predict(\\n    my_audio,\\n    \"transcribe\", # str in \\'Task\\' Radio component\\n    api_name=\"/predict\"\\n    headers=headers  # Pass the headers with the Hugging Face API token\\n)\\n\\n# printing the output\\nprinting(result)\\n\\n########### OUTPUT ###########\\nHi, how are you?\\n########### OUTPUT ###########\\n\\nWhat’s Next\\n\\nThere are many more APIs you can explore through Hugging Face Spaces. Many SME companies provide powerful generative AI tools at a very low cost, such as OpenAI embeddings, which cost $0.00013 for 1K/Tokens. Make sure to check their licenses, as many free APIs in the free tier either limit per day requests or are for non-commercial use.'}},\n",
       "  {'id': '2675c73080ff',\n",
       "   'title': 'Make your LLM aware of today’s Knowledge using Python',\n",
       "   'subtitle': 'A Classification Approach, Making LLM Knowledge-Aware',\n",
       "   'author': 'b856005e5ecd',\n",
       "   'publication_id': '5517fd7b58a6',\n",
       "   'published_at': '2024-01-30 18:32:09',\n",
       "   'last_modified_at': '2024-02-02 14:42:33',\n",
       "   'tags': ['data-science',\n",
       "    'python',\n",
       "    'machine-learning',\n",
       "    'deep-learning',\n",
       "    'programming'],\n",
       "   'topics': ['programming'],\n",
       "   'claps': 202,\n",
       "   'voters': 23,\n",
       "   'word_count': 3321,\n",
       "   'responses_count': 1,\n",
       "   'reading_time': 13.832075471698113,\n",
       "   'url': 'https://levelup.gitconnected.com/solve-llm-knowledge-cutoff-problem-with-python-2675c73080ff',\n",
       "   'unique_slug': 'solve-llm-knowledge-cutoff-problem-with-python-2675c73080ff',\n",
       "   'image_url': 'https://miro.medium.com/1*_bXvfeEEfLCQ7ekmUZh94w.png',\n",
       "   'lang': 'en',\n",
       "   'is_series': False,\n",
       "   'is_locked': False,\n",
       "   'is_shortform': False,\n",
       "   'top_highlight': '',\n",
       "   'content': {'id': '2675c73080ff',\n",
       "    'content': 'Making LLM Knowledge-Aware (From Fareed Khan)\\n\\nMake your LLM aware of today\\'s Knowledge using Python\\n\\nA Classification Approach, Making LLM Knowledge-Aware\\n\\nKnowledge cutoff is one of the issues that hasn’t been properly solved yet. The one and only solution currently available for this problem is RAG. However, the associated cost and computation make it unaffordable for individual developers. As the data increases, storing vector databases and querying or fetching it become challenging, with no guarantee of retrieving appropriate results.\\n\\nIn this blog, we will explore the most economical way (Classification) to make your LLM aware of current events so that when a user asks for information about something that has happened today, this week, or this month, your LLM can provide an answer instead of apologizing for its knowledge cutoff.\\n\\nYou can find the code from this blog on my GitHub repository.\\n\\nGitHub - FareedKhan-dev/Solve-LLM-Knowledge-Cutoff: A Classification Approach: Making LLM…\\nA Classification Approach: Making LLM Knowledge-Aware - GitHub - FareedKhan-dev/Solve-LLM-Knowledge-Cutoff: A…github.com\\n\\nTable of Contents\\n\\nImporting Libraries\\n\\nVisual Representation of Our Architecture\\n\\nBase LLM (Mistral-7B-Instruct)\\n\\nClassification of User Prompt\\n\\nFetching Information Using APIs\\n\\nProviding Information to Base LLM\\n\\nResults\\n\\nLarge Scale Implementation Guide\\n\\nWhat’s Next\\n\\nImporting Libraries\\n\\nOur architecture relies on multiple libraries, so the initial step is to import the necessary ones.\\n\\n# Import the sys module for system-related functionality\\nimport sys\\n\\n# Import the openai module for using OpenAI\\'s API\\nimport openai\\n\\n# Import the streamlit library for creating web applications\\nimport streamlit as st\\n\\n# Import the numpy library for numerical operations\\nimport numpy as np\\n\\n# Import cosine_similarity function from sklearn for calculating cosine similarity\\nfrom sklearn.metrics.pairwise import cosine_similarity\\n\\n# Import SentenceTransformer from sentence_transformers for sentence embeddings\\nfrom sentence_transformers import SentenceTransformer\\n\\n# Import google.generativeai module (if it exists; please verify the correct module)\\nimport google.generativeai as genai\\n\\n# Import json module for working with JSON data\\nimport json\\n\\n# Import requests module for making HTTP requests\\nimport requests\\n\\n# Import re module for regular expressions\\nimport re\\n\\n# Import word_tokenize and stopwords from nltk for natural language processing\\nfrom nltk.tokenize import word_tokenize\\nfrom nltk.corpus import stopwords\\n\\nYou might already be familiar with many libraries, while some may need installation, like the Google Generative AI library, if they don’t exist on your system.\\n\\n# Install google generative ai library\\npip install -q -U google-generativeai grpcio grpcio-tools\\n\\nVisual Representation of Our Architecture\\n\\nOur Architecture that we will be coding (From Fareed Khan)\\n\\nOur architecture begins by taking the user prompt, for example: \"When is Apple releasing their electric vehicles?\" As seen earlier, Mistral alone cannot answer this. The first stage is to classify this prompt under a relevant category. Based on the sample prompt, it might be classified under \"current events\" or \"tech news.\" Once a category is assigned, the next step is to invoke the correct API. If the detected category is \"current events,\" the Bing News API will be triggered with that user prompt and will fetch relevant information. This information, along with the prompt, will be passed to our base LLM (Mistral). Mistral will then generate a response based on the provided information.\\n\\nNow that we have an overview of our architecture, let’s start coding each component one by one and observe how it will impact our LLM.\\n\\nBase LLM (Mistral-7B-Instruct)\\n\\nI will be using Mistral-7B-Instruct-v0.1 as my base LLM because it can generate responses very effectively, and we will be enhancing its memory. Alternatively, mistral-7b-GPTQ provided by TheBloke can also be used, it can be run on Colab, and the notebook is available here. Feel free to choose any other LLM of your preference.\\n\\n# Set the device to load the model onto (e.g., \"cuda\" for GPU)\\ndevice = \"cuda\"\\n\\n# Load the pre-trained model and tokenizer from the Mistral-7B-Instruct-v0.1 checkpoint\\nbase_LLM = AutoModelForCausalLM.from_pretrained(\"mistralai/Mistral-7B-Instruct-v0.1\")\\ntokenizer = AutoTokenizer.from_pretrained(\"mistralai/Mistral-7B-Instruct-v0.1\")\\n\\n############ User input ############\\nuser_input = \"what is your knowledge cutoff?\"\\n\\n# Tokenize the user input\\nencoded_user_input = tokenizer(user_input, return_tensors=\"pt\")\\n\\n# Move the model inputs to the specified device (e.g., GPU)\\nmodel_inputs = encoded_user_input.to(device)\\n\\n# Move the entire model to the specified device (e.g., GPU)\\nbase_LLM.to(device)\\n\\n# Generate a response from the model using the provided code snippet\\noutput = base_LLM.generate(inputs=model_inputs, do_sample=True, max_new_tokens=2048)\\n\\n# Decode and print the generated response\\ndecoded_response = tokenizer.decode(output[0])\\nprint(decoded_response)\\n\\nJust to confirm, the above code returns: \"My knowledge cutoff is 2021–08–09.\" So, most likely, when we ask a current knowledge question, Mistral-7B respond with this information.\\n\\nMistral-7B Knowledge cutoff test (From Fareed Khan)\\n\\nA recent news of 2024, where Apple has recently confirmed the delay of their electric vehicle release from 2026 to 2028. While it has been circulating on the internet since 2021, the exact date was never announced before 2024. Mistral provided information based on its knowledge up to 2021, but the ideal output should reflect the current information.\\n\\nClassification of User Prompt\\n\\nClassification Component\\n\\nOnce we have chosen our base LLM, the next step is to find a strategy that can quickly and accurately classify the user prompt. This can be achieved in three steps:\\n\\nDefining Categories\\n\\nUtilizing Semantic Search LLM or Multi-Model Similarity Search\\n\\nCosine Similarity to categorize\\n\\nThe first step is to define different categories, which is a crucial step because the entire procedure depend on it. Each category you define must be detailed, containing all the relevant information that truly highlights that category. For example, if someone asks for information on the latest SPIN technique for fine-tuning LLM released in 2024, it must fall under the category of \"research_papers\". Similarly, if someone ask about the winner of yesterday’s football match between TeamX and TeamY, it should be categorized under \"football_match_statistics\", and so forth.\\n\\n# Dictionary with main category names as keys\\ncategories_data = {\\n    \\'sports_stats\\': \\'Statistics and performance metrics of professional athletes and sports personalities\\',\\n    \\'entertainment_updates\\': \\'Latest developments, news, and highlights about your favorite movies, TV shows, and celebrities\\',\\n    \\'current_events\\': \\'Up-to-the-minute coverage of breaking news on global current events\\',\\n    \\'research_papers\\': \\'Exploration of research papers and scholarly articles on various topics\\',\\n}\\n\\nI have defined 4 important categories where the keys represent their category names, and the values provide detailed, concise information about what each category is about. The more categories you provide, the greater the effort required, but it also enhances your LLM’s awareness of recent events.\\n\\nNext, we need to convert our defined categories into embedding vectors and apply cosine similarity to map it with closest category. There are various methods to achieve this, such as using pretrained word2vec models or Spacy en_core_web_lg. Through my testing, two of the most satisfactory approaches are either utilizing a semantic search LLM or a multi-model like Gemini.\\n\\nFor semantic search, Hugging Face has a variety of LLMs available. However, our requirement is that the LLM size must be as small as possible while still providing satisfactory results. For this reason, I have tried several LLMs, and among them, I found the \"sentence_similarity_LLM\" from Sakil. Its size is only 265 MB, and it can be easily used for inference within approximately 0.1 seconds.\\n\\n# Import the SentenceTransformer class from the sentence_transformers library\\nfrom sentence_transformers import SentenceTransformer\\n\\n# Specify the pre-trained model name to be used\\nmodel_HF_name = \"Sakil/sentence_similarity_semantic_search\"\\n\\n# Create an instance of the SentenceTransformer model using the specified pre-trained model\\nmodel_HF = SentenceTransformer(model_HF_name)\\n\\n# Get the values from the \\'categories_data\\' dictionary and convert them to a list\\n# Then, encode the list of category values using the SentenceTransformer model and convert the result to a PyTorch tensor\\ncategories_data_embeddings_hf_ = model_HF.encode(list(categories_data.values()), convert_to_tensor=True)\\n\\nThe above code will encode our categories data into embedding vectors using an open-source Hugging Face LLM. Similarly, using \"Gemini MultiModel\", we can easily encode our data with its free API. Alternatively, the OpenAI API is an option, but it involves a cost, and its embedding vector may not perform as effectively as Gemini MultiModel.\\n\\n# setting the api key\\ngenai.configure(api_key=\"YOUR_API_KEY\")\\n\\n# Define a function to calculate the embeddings of the input text\\ndef model_MM(input_text):\\n    categories_data_embeddings_MM_ = genai.embed_content(\\n        model=\"models/embedding-001\",\\n        content=input_text,\\n        task_type=\"retrieval_document\",\\n        title=\"Embedding of inputs\")\\n    return categories_data_embeddings_MM_[\\'embedding\\']\\n\\n# calculate embedding of sentence2 and categories_data\\ncategories_data_embeddings_MM_ = model_MM(list(categories_data.values()))\\n\\nNow that we have coded two approaches to calculate the embedding of categories, we need to implement a function for cosine similarity that takes the embedding vectors, models and a user prompt.\\n\\ndef find_best_result(user_prompt, embedding_model_MM, embedding_model_hf, categories_data_embeddings_MM, categories_data_embeddings_hf):\\n    # Convert user prompt to embedding vector\\n    user_prompt_embedding_MM = embedding_model_MM([user_prompt])\\n    user_prompt_embedding_hf = embedding_model_hf.encode([user_prompt], convert_to_tensor=True)\\n\\n    # Calculate cosine similarity with categories data embeddings\\n    similarity_scores_MM = cosine_similarity(user_prompt_embedding_MM, categories_data_embeddings_MM)\\n    similarity_scores_hf = cosine_similarity(user_prompt_embedding_hf, categories_data_embeddings_hf)\\n\\n    # Find the index of the best result with the highest score for both models\\n    best_result_index_MM = np.argmax(similarity_scores_MM)\\n    best_result_index_hf = np.argmax(similarity_scores_hf)\\n\\n    # Get the best first result with the highest score for both models\\n    best_result_MM = list(categories_data.keys())[best_result_index_MM]\\n    best_result_hf = list(categories_data.keys())[best_result_index_hf]\\n\\n    return best_result_MM, best_result_hf\\n\\nWe can use this function to detect the category being assigned to user prompt.\\n\\n# User prompt\\nuser_prompt = \"what is self play fine tuning in LLM\"\\n\\n# Find the best result with the highest score for both models\\nbest_result_MM, best_result_hf = find_best_result(user_prompt, model_MM, model_HF, categories_data_embeddings_MM_, categories_data_embeddings_hf_)\\n\\n# Print the results\\nprint(\"Best result from MM model:\", best_result_MM)\\nprint(\"Best result from HF model:\", best_result_hf)\\n\\n######## OUTPUT ########\\nBest result from MM model: research_papers\\nBest result from HF model: research_papers\\n######## OUTPUT ########\\n\\nBoth models categorized the input under the correct category, \"research_papers\" and the computation time was below 1 second. Let’s test it with a number of prompts and see if one lags compared to the other.\\n\\n\\n\\nI used 100 different user prompts to determine the accuracy (code is available here). Multi-Model (MM) proved to be more accurate in categorizing user prompts for different categories compared to the Hugging Face (HF) model. This accuracy can be further increased by providing more detailed information for each category.\\n\\nFetching Information Using APIs\\n\\nAPI Calling Component\\n\\nWe will be using the Gemini Multi-Model for classification due to its accuracy. Based on the identified category, it must trigger the correct API. For example, if the user prompt is \"What is self-play fine-tuning in LLM\" after Gemini Multi-Model identifies it lies in the \"research_papers\" category, ArXiv API (Licencse) will get triggered. Alternatively, you can use any other API of your choice, as long as it correctly fetches the data based on the prompt. I chose ArXiv because it contains more than 2.3 million papers and includes the latest information. Let’s implement it in code.\\n\\n# Define a function named \\'query_arxiv\\' that takes a search query, start position, and maximum results as parameters.\\ndef query_arxiv(search_query, start=0, max_results=2):\\n    \\n    # Define the base URL for the ArXiv API.\\n    base_url = \"http://export.arxiv.org/api/query?\"\\n    \\n    # Create a dictionary \\'query_params\\' with the specified parameters for the API query.\\n    query_params = {\\n        \\'search_query\\': f\\'all:{search_query}\\',  # Construct the search query parameter.\\n        \\'start\\': start,  # Set the start position parameter.\\n        \\'max_results\\': max_results  # Set the maximum results parameter.\\n    }\\n\\n    # Make an HTTP GET request to the ArXiv API using the \\'requests.get\\' function with the constructed URL and parameters.\\n    response = requests.get(base_url, params=query_params)\\n\\n    # Use regular expression (regex) to extract content between \\'<summary>\\' tags in the API response.\\n    summaries = re.findall(\\'<summary>(.*?)</summary>\\', response.text, re.DOTALL)\\n\\n    # Replace newline and tab characters with spaces, and trim leading/trailing spaces for each summary.\\n    # Join the modified summaries into a single string separated by spaces.\\n    merged_summary = \\' \\'.join(summary.replace(\\'\\\\n\\', \\' \\').replace(\\'\\\\t\\', \\' \\').strip() for summary in summaries)\\n\\n    # Return the merged and cleaned summary.\\n    return merged_summary\\n\\nI have set the default \"max_result\" value to 1, meaning it fetches only one relevant paper. You can set it according to your preference. Once it fetches the information, it will combine the abstracts of all the relevant papers. I have chosen to fetch the abstracts. You can fetch the entire paper using their guide. However, using complete papers would be irrelevant. This is because feeding the entire paper to our Base LLM would exceed its context length and may result in an error.\\n\\nIn a similar scenario, what if the user prompt is related to the current events category, such as \"Where is Cyclone Anggrek heading?\" This cyclone is currently active and is expected to lose its intensity in the upcoming days, concluding by this Wednesday (31–1–2024). Fetching the latest information from a news API can be costly, as most free tiers offer only 100 requests per day. However, the Bing News API’s free tier provides 1000 requests per month, which is sufficient for exploration and testing to determine if it fetches relevant information. Even for deployment purposes, their paid plan is reasonably priced. Moreover, Bing News is considered more reliable as they have their own news platform instead of relying on external sources. This ensures a diverse range of news for each searched query.\\n\\nAlthough, similar to the ArXiv API where we passed the entire user prompt, this approach won’t work with the \"current_events\" category. We need to extract important entities from the user prompt to pass them in the API. otherwise, the search results won’t be accurate. For this purpose, we can use either NLTK or SpaCy to extract entities.\\n\\ndef extract_keywords(text):\\n    # Tokenize, remove stopwords, and merge into a string\\n    merged_words = \\' \\'.join([word for word in word_tokenize(text) if word.lower() not in set(stopwords.words(\\'english\\'))])\\n\\n    # Remove ? ! , . from the string\\n    merged_words = re.sub(\\'[\\\\?\\\\!\\\\,\\\\.\\\\\\']\\', \\'\\', merged_words)  # Missing \\'import re\\' statement\\n\\n    # strip the string\\n    merged_words = merged_words.strip()\\n\\n    # Print the remaining keywords\\n    return merged_words\\n\\n# Example usage\\nprompt = \"when will apple be releasing their electric vehicles?\"\\nextract_keywords(prompt)\\n\\n######## OUTPUT ########\\nApple releasing electric vehicles\\n######## OUTPUT ########\\n\\nThe provided code is a quick and effective approach to extract entities from a user prompt. I passed a sample prompt to it, and it extracted only the relevant entities, making it easy for our Bing API to recognize relevant news. Now, let’s code how the Bing API will fetch information based on the extracted entities.\\n\\ndef get_current_information(query):\\n    # Hardcoded values for the URL and subscription key\\n    search_url = \"https://api.bing.microsoft.com/v7.0/news/search\"  # actual search URL\\n    subscription_key = \"YOUR_BING_NEWS_API_KEY\"  # Replace with the actual subscription key\\n\\n    # Make the API request\\n    response = requests.get(search_url, headers={\"Ocp-Apim-Subscription-Key\": subscription_key},\\n                            params={\"q\": query, \"textDecorations\": True, \"textFormat\": \"HTML\"})\\n    response.raise_for_status()\\n\\n    # Extract descriptions from the response\\n    descriptions = [item.get(\\'description\\', \\'\\') for item in json.loads(json.dumps(response.json())).get(\\'value\\', [])]\\n\\n    # Clean and format the descriptions\\n    cleaned_description = re.sub(\\'<.*?>\\', \\'\\', \\'\\\\n\\'.join(descriptions))\\n    cleaned_description = re.sub(\\'\\\\.\\\\.\\\\.\\', \\'\\', cleaned_description)\\n    cleaned_description = re.sub(\\'&#39;\\', \"\\'\", cleaned_description)\\n\\n    return cleaned_description\\n\\nThere are many parameters such as how many results you want, or how latest the information must be, you can pass such params in bing search api from the given guide. I have set it to default, a bit text cleaning is required on the fetched output.\\n\\nNow that we have coded two important categories, it provides insight into how the latest information can be extracted using APIs. Similarly, suppose you want your LLM to extract the current stock price. In that case, it must extract entities from the prompt, and then those entities should be passed to your stock API, such as the Polygon API. It will return the current price of that stock.\\n\\nProviding Information to Base LLM\\n\\nInference Base LLM Final Component\\n\\nUp until now, we have implemented each component into functions, making it easier for us to code the final part of our architecture by simply calling those functions. Let’s examine how the structure of our code in this section looks like:\\n\\nUser prompt will be classified based on given categories using Gemini Multi-Model. We chose this option for better accuracy.\\n\\nBased on the classified category, it will trigger the right API. For certain categories like \"current_events,\" we have to extract entities from the user prompt. Based on those entities, it will fetch relevant information.\\n\\nThe fetched information will then be passed, along with the user prompt, into our base LLM, which will generate an answer based on the provided information.\\n\\ndef find_best_result_MM(user_prompt, embedding_model_MM, categories_data_embeddings_MM):\\n    # Convert user prompt to embedding vector\\n    user_prompt_embedding_MM = embedding_model_MM([user_prompt])\\n\\n    # Calculate cosine similarity with categories data embeddings\\n    similarity_scores_MM = cosine_similarity(user_prompt_embedding_MM, categories_data_embeddings_MM)\\n\\n    # Find the index of the best result with the highest score for both models\\n    best_result_index_MM = np.argmax(similarity_scores_MM)\\n\\n    # Get the best first result with the highest score for both models\\n    best_result_MM = list(categories_data.keys())[best_result_index_MM]\\n\\n    return best_result_MM\\n\\nSince we are exclusively relying on Gemini MultiModel for classifying user prompts, I have updated the function accordingly.\\n\\n# Define the sample user prompt \\nuser_prompt = \"what is the spin technique for fine-tuning a language model?\"\\n\\n# Determine the category using the multimodal model\\ncategory_result = find_best_result_MM(user_prompt, model_MM, categories_data_embeddings_MM_)\\n\\n# Retrieve information based on the determined category\\nif category_result == \\'research_papers\\':\\n    information = query_arxiv(user_prompt)\\nelif category_result == \\'current_events\\':\\n    information = get_current_information(extract_keywords(user_prompt))\\n\\n# Create a prompt template with the obtained information\\nprompt_template = f\\'\\'\\'\\n{information}\\n\\nanswer the following question in a detailed manner based on the above information\\n{user_prompt}\\n\\'\\'\\'\\n\\n# Generate a response from the base language model using the provided prompt\\noutput = base_LLM.generate(inputs=model_inputs, do_sample=True, max_new_tokens=2048)\\n\\n# Decode and print the generated response\\ndecoded_response = tokenizer.decode(output[0])\\nprint(decoded_response)\\n\\n######## OUTPUT ########\\nThe Self-Play Fine-tuNing (SPIN) technique ... preference data.\\n######## OUTPUT ########\\n\\nWe have implemented the entire architecture for just two categories, and you can extend it for as many categories as needed. Although keep in mind that manual efforts will be required for each category. I passed a user prompt related to a new SPIN technique invented in 2024. Gemini classified it in the \"research_papers\" category, triggering the ArXiv API to fetch relevant information. This information is then passed to our base LLM, which generates a response based on the provided information and the user prompt. The entire process took 5 seconds to generate the response.\\n\\nResults\\n\\nNow that we have coded the entire architecture, let’s build a simple chatbot using Streamlit to provide a better visual representation and avoid rerunning the code. Each example took 4 seconds inference time.\\n\\nCyclone Anggrek\\n\\nSPIN Technique\\n\\nWhy Taylor swift is trending?\\n\\nCricket related query\\n\\nApple Electric cars release date\\n\\nSince I have implemented API code for just two categories, most of the questions I have asked here are related to only those two categories. However, you can extend it to a larger-scale project. Extending it to a larger scale will require cost calculation along with a more comprehensive methodology for our implemented architecture, which is what our next section is about.\\n\\nLarge Scale Implementation Guide\\n\\nWhen scaling this architecture, how you define categories becomes crucial. The more detailed the category, the higher the chances of correctly classifying the user prompt. You can use \"ChatGPT\" or \"Gemini\" to write a comprehensive description of your category. I used the Gemini embedding model to convert the text to embeddings. For larger-scale implementation, Gemini is still a better choice compared to other open-source LLMs.\\n\\nThe function I used to find the closeness (cosine similarity) remains effective and quick even when dealing with large-scale data. The key consideration after defining categories is the total cost. For a small scale (single category LLM), you won’t encounter issues as many API free tiers offer suitable subscriptions, especially if you have a low number of requests per hour or day. Some APIs provide more flexibility even when scaling your project to a larger scale, such as the Bing News API we discussed earlier.\\n\\nI cannot provide an exact cost estimate as it depends on the scalability of your architecture. However, if you work with 10 categories, the minimum cost you might incur is approximately $20 per month, excluding the cost of hosting your base LLM.\\n\\nWhat’s Next\\n\\nTry implementing this architecture with a smaller base LLM and measure its accuracy. Often, you may deploy an LLM for a specific task, like retrieving information based on tweets, where the cost is significantly lower, or in some cases, you might not incur any costs at all. Another option is to use Ansyscale API, which provides $10 in free credits, allowing you to test various LLMs with this architecture quickly without depending on Colab or Kaggle. Thank you for reading this comprehensive post!'}},\n",
       "  {'id': '9a083d3811df',\n",
       "   'title': 'Convert Weak LLM to Strong LLM Using SPIN Technique',\n",
       "   'subtitle': 'Can we help a weak LLM get better without getting more data?',\n",
       "   'author': 'b856005e5ecd',\n",
       "   'publication_id': '5517fd7b58a6',\n",
       "   'published_at': '2024-01-16 23:24:01',\n",
       "   'last_modified_at': '2024-01-16 23:24:01',\n",
       "   'tags': ['machine-learning',\n",
       "    'deep-learning',\n",
       "    'large-language-models',\n",
       "    'ai',\n",
       "    'data-science'],\n",
       "   'topics': ['machine-learning'],\n",
       "   'claps': 75,\n",
       "   'voters': 12,\n",
       "   'word_count': 3289,\n",
       "   'responses_count': 3,\n",
       "   'reading_time': 13.711320754716981,\n",
       "   'url': 'https://levelup.gitconnected.com/convert-weak-llm-to-strong-llm-using-spin-technique-9a083d3811df',\n",
       "   'unique_slug': 'convert-weak-llm-to-strong-llm-using-spin-technique-9a083d3811df',\n",
       "   'image_url': 'https://miro.medium.com/1*thxroSFEju_2OFHme6mPVA.png',\n",
       "   'lang': 'en',\n",
       "   'is_series': False,\n",
       "   'is_locked': False,\n",
       "   'is_shortform': False,\n",
       "   'top_highlight': '',\n",
       "   'content': {'id': '9a083d3811df',\n",
       "    'content': 'Convert Weak LLM to Strong LLM Using SPIN Technique\\n\\nCan we help a weak LLM get better without getting more data?\\n\\nMuch of the development in Large Language Models (LLMs) has already taken place as we enter the year 2024. Among these, an important one is alignment methods, which involves Supervised Fine-Tuning (SFT) using human examples and Reinforcement Learning from Human Feedback (RLHF) relying on human preferences. These methods have played a crucial role in recent efforts to make LLMs better. However, the challenge with alignment methods, especially those mentioned earlier, lies in the significant requirement for human-annotated data. This challenge makes fine-tuning a dynamic area of research, with researchers actively working on developing methods that can effectively utilize human data.\\n\\nVisual illustration of How SFT and RLHF Works (From Open foundation and fine-tuned chat models)\\n\\nA recent study from the University of California has introduced a novel technique named SPIN (Self Play fIne tuNing). Drawing inspiration from the success of self-play mechanisms in games, like AlphaGo Zero and AlphaZero. SPIN starts with a supervised fine-tuned model. What makes it stand out is its ability to enable the LLM to engage in self-play. This eliminates the requirement for an expert annotator, be it a human or a more advanced LLM like GPT-4. In simple terms, SPIN involves training a new language model to differentiate between its own generated responses and human-generated responses through a series of iterations. The ultimate goal is to develop a language model that produces responses indistinguishable from those produced by humans.\\n\\nTable of Contents\\n\\nWhat is Self Play?\\n\\nHow SPIN Works\\n– Training Main Player\\n– Updating Opponent Player\\n\\nCoding SPIN Algorithm\\n– Initializing the Parameters and SFT Dataset\\n– Generating Synthetic Data (Inner Loop of SPIN Algorithm)\\n– Implementing Update Rule\\n– Training (Outer Loop of SPIN Algorithm)\\n\\nPerformance and Results\\n\\nResources\\n\\nWhat is Self Play?\\n\\nSelf-play is a technique where an algorithm learns by playing against copies of itself. This method increases the challenge and complexity of the learning environment, allowing agents to interact with various versions of themselves. It has gained significant attention in multi-agent reinforcement learning (MARL) due to its effectiveness. A notable example is AlphaGo Zero, a self-play learning scheme that achieved exceptional performance against human players in the game of Go.\\n\\nHow Self-Play Environment Works (Created by Fareed Khan)\\n\\nResearchers have explored various adaptations and implementations of self-play, including variations in the number of agents, the type of interactions, and the learning algorithms used. The effectiveness of self-play in MARL is well-established, but its application to the enhancement of large language models (LLMs) is a new approach. The application of self-play to LLMs has the potential to further enhance their capabilities and enable them to generate more coherent, informative, and engaging text.\\n\\nSelf-play can be used in both competitive and cooperative settings.\\n\\nIn competitive settings, the copies of the algorithm compete against each other to achieve a specific goal.\\n\\nIn cooperative settings, the copies of the algorithm work together to achieve a common goal.\\n\\nIt can also be combined with other learning techniques, such as supervised learning and reinforcement learning, to further enhance the performance of the algorithm.\\n\\nHow SPIN Works\\n\\nSPIN operates like a two-player game. In this game:\\n\\nMain Player (New LLM) - This player’s role is to learn how to distinguish between responses generated by the Language Model (LLM) and those created by humans. In each iteration (round), the main player is the LLM being actively trained. Its objective is to improve its ability to recognize and differentiate between responses.\\n\\nOpponent (Old LLM) - The opponent’s task is to generate responses that are indistinguishable from those produced by humans. The opponent, in this case, is the LLM from the previous iteration (round). It uses the self-play mechanism, generating responses based on its past knowledge. The opponent’s goal is to create responses so realistic that the main player (new LLM) has a challenging time deciding whether they are from a human or the LLM.\\n\\nThe dynamics of SPIN involve using a Supervised Fine-Tuning (SFT) dataset, which consists of pairs of input (x) and output (y). These examples are annotated by humans and serve as the basis for training the main player to recognize human-like responses. Some public SFT datasets include Dolly15K, Baize, Ultrachat, and more.\\n\\nTraining Main Player\\n\\nTo train the main player in telling apart language model (LLM) responses from human responses, SPIN uses an objective function. This function measures the expected gap in value between real data and the responses generated by the opponent player. The main player aims to maximize this expected value gap. This involves assigning high values to pairs where a prompt is paired with a response from real data and low values to pairs where the response is generated by the opponent player. This objective function is formulated as a minimization problem.\\n\\nThe main player works to minimize a loss function measuring the disparity between the assigned values for pairs from real data and those from the opponent player’s responses. Throughout training, the main player adjusts its parameters to minimize this loss function. This iterative process continues until the main player becomes adept at effectively telling apart LLM responses from human responses. The choice of function is crucial for the performance of the main player.\\n\\nUpdating Opponent Player\\n\\nUpdating the Opponent Player involves refining the ability of our main player, who has learned to distinguish between real data and the language model responses. With the improved main player and its understanding within a certain function class, let’s see how to update the parameters of the opponent player. When the main player is given two responses to the same prompt, it evaluates their values using its learned discrimination. If one response has a higher value than the other, it assumes that it comes from real data, and the other is from the language model.\\n\\nThe goal of the opponent player is then to enhance the language model so that its responses are indistinguishable from real data according to the main player. To achieve this, a process is set up to adjust the language model’s parameters. The aim is to maximize the main player’s evaluation of language model responses while maintaining stability and avoiding drastic changes. This involves a balancing act, ensuring improvement without straying too far from the original language model.\\n\\nThe process involves finding a new distribution for language model responses that aligns with the main player’s assessments. A regularization term is introduced to prevent excessive deviation from the original model. This ensures a gradual and controlled improvement. Importantly, the obtained distribution may not match the original language model. To ensure alignment, a proportional relationship is solved for that considers both the original and updated models. This leads to a refined model that closely matches the main player’s evaluations. By optimizing this process, a refined model for the opponent player is achieved. This refined model now better matches the main player’s discernment, achieving the goal of improving the language model’s responses in a way that is indistinguishable from real data.\\n\\nCoding SPIN Algorithm\\n\\nSPIN algorithm works by first generating synthetic data from the pre-trained model. This synthetic data is then used to fine-tune the model on the new task.\\n\\nSPIN Algorithm Pseudocode (From Original Paper)\\n\\nThe Spin algorithm’s pseudocode in the original paper might be hard to understand, but by coding it in Python, we can break down each term and better understand how it works.\\n\\nInitializing the Parameters and SFT Dataset\\n\\nThe original paper uses the Zephyr-7B-SFT-Full as the base model. This model is derived from the pre-trained Mistral-7B. For the dataset, they have used the Ultrachat200k subset of the larger UltraChat corpus, which consists of approximately 1.4 million dialogues produced using OpenAI’s Turbo APIs. From UltraChat200k, they randomly sample 50k prompts and use the base model to generate synthetic responses.\\n\\n# Import necessary libraries\\nfrom datasets import load_dataset\\nimport pandas as pd\\n\\n# Load the Ultrachat 200k dataset\\nultrachat_dataset = load_dataset(\"HuggingFaceH4/ultrachat_200k\")\\n\\n# Initialize an empty DataFrame\\ncombined_df = pd.DataFrame()\\n\\n# Loop through all the keys in the Ultrachat dataset\\nfor key in ultrachat_dataset.keys():\\n    # Convert each dataset key to a pandas DataFrame and concatenate it with the existing DataFrame\\n    combined_df = pd.concat([combined_df, pd.DataFrame(ultrachat_dataset[key])])\\n\\n# Shuffle the combined DataFrame and reset the index\\ncombined_df = combined_df.sample(frac=1, random_state=123).reset_index(drop=True)\\n\\n# Select the first 50,000 rows from the shuffled DataFrame\\nultrachat_50k_sample = combined_df.head(50000)\\n\\nWe have coded the same approach of obtaining our dataset by combining all the splits, and then randomly sampling 50k prompts from the original dataframe. As the UltraChat200k dataset contains multi-round conversations, the authors consider the prompting template \"### Instruction: {prompt}\\\\n\\\\n### Response:\" and only sample the first round as their prompt and ground truth completion pairs.\\n\\n# for storing each template in a list\\ntemplates_data = []\\n\\nfor index, row in ultrachat_50k_sample.iterrows():\\n    messages = row[\\'messages\\']\\n    \\n    # Check if there are at least two messages (user and assistant)\\n    if len(messages) >= 2:\\n        user_message = messages[0][\\'content\\']\\n        assistant_message = messages[1][\\'content\\']\\n        \\n        # Create the template\\n        instruction_response_template = f\"### Instruction: {user_message}\\\\n\\\\n### Response: {assistant_message}\"\\n        \\n        # Append the template to the list\\n        templates_data.append({\\'Template\\': instruction_response_template})\\n\\n# Create a new DataFrame with the generated templates (ground truth)\\nground_truth_df = pd.DataFrame(templates_data)\\n\\nWe have transformed our dataframe into a prompt template. This is what the single transformation look like:\\n\\nTransformation of dataset into prompt template (Created by Fareed Khan)\\n\\nThe prompt template dataset serves as a ground truth dataset for our use, consisting of human responses. Zephyr-7B-SFT-Full will then generate a response for the same prompt, and the SPIN algorithm aims to align it with the ground truth response by iteratively updating the parameters of the language model (LLM). This process continues until it becomes challenging to distinguish between the generated response and the ground truth, achieving a high level of similarity (lowering the loss).\\n\\nThere are two loops in SPIN algorithm. The inner loop runs based on the number of samples we are working with, which is 50k, and the outer loop runs for a total of 3 iterations because the authors found that the model’s performance observe no change after it. Moreover, Alignment Handbook library is used as the codebase for the self-play fine-tuning method, incorporating DeepSpeed module to reduce training costs. They train Zephyr-7B-SFT-Full with the RMSProp optimizer, with no weight decay for all iterations, as commonly used in fine-tuning LLMs for alignment. The global batch size is set to 64, and bfloat16 precision is used. The peak learning rate is set to 5e-7 for iterations 0 and 1, and this peak learning rate is decayed to 1e-7 for iterations 2 and 3 as the loop approaches the end of self-play fine-tuning. Lastly, they choose β = 0.1, and the maximum sequence length is set to be 2048 tokens.\\n\\n# Importing the PyTorch library\\nimport torch\\n\\n# Importing the neural network module from PyTorch\\nimport torch.nn as nn\\n\\n# Importing the DeepSpeed library for distributed training\\nimport deepspeed\\n\\n# Importing the AutoTokenizer and AutoModelForCausalLM classes from the transformers library\\nfrom transformers import AutoTokenizer, AutoModelForCausalLM\\n\\n# Loading the zephyr-7b-sft-full model from HuggingFace\\ntokenizer = AutoTokenizer.from_pretrained(\"alignment-handbook/zephyr-7b-sft-full\")\\nmodel = AutoModelForCausalLM.from_pretrained(\"alignment-handbook/zephyr-7b-sft-full\")\\n\\n# Initializing DeepSpeed Zero with specific configuration settings\\ndeepspeed_config = deepspeed.config.Config(train_batch_size=64, train_micro_batch_size_per_gpu=4)\\nmodel, optimizer, _, _ = deepspeed.initialize(model=model, config=deepspeed_config, model_parameters=model.parameters())\\n\\n# Defining the optimizer and setting the learning rate using RMSprop\\noptimizer = deepspeed.optim.RMSprop(optimizer, lr=5e-7)\\n\\n# Setting up a learning rate scheduler using LambdaLR from PyTorch\\nscheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lambda epoch: 0.2 ** epoch)\\n\\n# Setting hyperparameters for training\\nnum_epochs = 3\\nmax_seq_length = 2048\\nbeta = 0.1\\n\\nAs we initialize DeepSpeed, parallel processing is configured to utilize 4 GPUs, and the training configuration is set with a batch size of 64 and a micro-batch size of 4 per GPU. We then loads the zephyr-7b-sft-full model from HuggingFace using the AutoTokenizer and AutoModelForCausalLM classes. Additionally, the optimizer is defined using RMSprop with a learning rate of 5e-7. A learning rate scheduler is implemented using LambdaLR from PyTorch, applying a decay factor of 0.2 at each epoch. The hyperparameters for training, such as the number of epochs (3), maximum sequence length (2048), and a beta value (0.1), are set. The change in the beta value will occur within the outer training loop.\\n\\nGenerating Synthetic Data (Inner Loop of SPIN Algorithm)\\n\\nNow that we have the ground truth dataset and parameters initialized for our Zephyr-SFT LLM training, we need to code the inner loop of the SPIN algorithm. This inner loop is responsible for generating responses that need to be aligned with the ground truth data.\\n\\n# zephyr-sft-dataframe (that contains output that will be improved while training)\\nzephyr_sft_output = pd.DataFrame(columns=[\\'prompt\\', \\'generated_output\\'])\\n\\n# Looping through each row in the \\'ultrachat_50k_sample\\' dataframe\\nfor index, row in ultrachat_50k_sample.iterrows():\\n    # Extracting the \\'prompt\\' column value from the current row\\n    prompt = row[\\'prompt\\']\\n    \\n    # Generating output for the current prompt using the Zephyr model\\n    input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids\\n    output = model.generate(input_ids, max_length=200, num_beams=5, no_repeat_ngram_size=2, top_k=50, top_p=0.95)\\n    \\n    # Decoding the generated output to human-readable text\\n    generated_text = tokenizer.decode(output[0], skip_special_tokens=True)\\n    \\n    # Appending the current prompt and its generated output to the new dataframe \\'zephyr_sft_output\\'\\n    zephyr_sft_output = zephyr_sft_output.append({\\'prompt\\': prompt, \\'generated_output\\': generated_text}, ignore_index=True)\\n\\nThis is what the ground truth and synthetic response look like for a single prompt.\\n\\nComparison of ground-truth and zephyr-sft answer (Created by Fareed Khan)\\n\\nSince our dataset contains 50k prompts for the first outer loop iteration, the inner loop will run 50k times, generating responses for each prompt. As a result, a new dataframe will be created zephyr_sft_outputthat contains the prompt and its corresponding generated output through our base model, Zephyr-7B-SFT-Full.\\n\\nImplementing Update Rule\\n\\nBefore coding the minimization problem, it is crucial to understand how the conditional probability distribution of an LLM-generated output can be calculated. The original paper uses a Markov process, wherein the conditional probability distribution pθ\\u200b(y∣x) can be expressed through a decomposition as follows:\\n\\nConditional Probability Formula (Markov Process)\\n\\nThis decomposition means that the probability of the output sequence given the input sequence can be calculated by multiplying the probabilities of each output token given the input sequence and the previous output tokens. For example, if the output sequence is \"I enjoy reading books\" and the input sequence is \"I enjoy\", then the conditional probability of the output sequence given the input sequence can be calculated as follows:\\n\\nCalculating Conditional Probability of small sentence\\n\\nMarkov process conditional probability will be used to calculate the probability distribution of the ground truth LLM response and the Zephyr LLM response, which will then be used to compute the loss function. But first, we need to code the conditional probability function.\\n\\n# Conditional Probability Function of input text\\ndef compute_conditional_probability(tokenizer, model, input_text):\\n    # Tokenize the input text and convert it to PyTorch tensors\\n    inputs = tokenizer([input_text], return_tensors=\"pt\")\\n\\n    # Generate text using the model, specifying additional parameters\\n    outputs = model.generate(**inputs, return_dict_in_generate=True, output_scores=True)\\n\\n    # Assuming \\'transition_scores\\' is the logits for the generated tokens\\n    transition_scores = model.compute_transition_scores(outputs.sequences, outputs.scores, normalize_logits=True)\\n\\n    # Get the length of the input sequence\\n    input_length = inputs.input_ids.shape[1]\\n\\n    # Assuming \\'transition_scores\\' is the logits for the generated tokens\\n    logits = torch.tensor(transition_scores)\\n\\n    # Apply softmax to obtain probabilities\\n    probs = torch.nn.functional.softmax(logits, dim=-1)\\n\\n    # Extract the generated tokens from the output\\n    generated_tokens = outputs.sequences[:, input_length:]\\n\\n    # Compute conditional probability\\n    conditional_probability = 1.0\\n    for prob in probs[0]:\\n        token_probability = prob.item()\\n        conditional_probability *= token_probability\\n\\n    return conditional_probability\\n\\nThe loss function, which is the sum for each outer loop iteration based on which our training will occur and minimize, contains four important conditional probability variables. Each of these variables depends on either ground truth data or synthetic data created earlier.\\n\\nL(SPIN) Loss Function Equation (Created by Fareed Khan)\\n\\nWhile lambda is a regularization parameter that is used to control the deviation of the opponent player. It is utilized in the KL regularization term to penalize the divergence between the distribution of the opponent player and the target data distribution. The specific value of lambda used in the paper is not explicitly mentioned, as it is likely to be tuned based on the specific task and dataset being used.\\n\\ndef LSPIN_loss(model, updated_model, tokenizer, input_text, lambda_val=0.01):\\n    # Initialize conditional probability using the original model and input text\\n    cp = compute_conditional_probability(tokenizer, model, input_text)\\n\\n    # Update conditional probability using the updated model and input text\\n    cp_updated = compute_conditional_probability(tokenizer, updated_model, input_text)\\n\\n    # Calculate conditional probabilities for ground truth data\\n    p_theta_ground_truth = cp(tokenizer, model, input_text)\\n    p_theta_t_ground_truth = cp(tokenizer, model, input_text)\\n\\n    # Calculate conditional probabilities for synthetic data\\n    p_theta_synthetic = cp_updated(tokenizer, updated_model, input_text)\\n    p_theta_t_synthetic = cp_updated(tokenizer, updated_model, input_text)\\n\\n    # Calculate likelihood ratios\\n    lr_ground_truth = p_theta_ground_truth / p_theta_t_ground_truth\\n    lr_synthetic = p_theta_synthetic / p_theta_t_synthetic\\n\\n    # Compute the LSPIN loss\\n    loss = lambda_val * torch.log(lr_ground_truth) - lambda_val * torch.log(lr_synthetic)\\n\\n    return loss\\n\\nA quick rule of thumb is that, If you have a large dataset, you can use a smaller value of lambda or if you have a small dataset, you may need to use a larger value of lambda to prevent overfitting. As we have a smaller dataset with a size of 50k, we can use 0.01 as the value of lambda.\\n\\nTraining (Outer Loop of SPIN Algorithm)\\n\\nCoding the outer loop will include all the code we have developed so far. This encompasses generating synthetic data and utilizing the LSPIN loss function to compute the loss. This loss is then used to update our model parameters, resulting in the formation of a new model in the next iteration. Subsequently, this new model generates its output, which is compared to the ground truth, representing human responses.\\n\\n# Training loop\\nfor epoch in range(num_epochs):\\n    \\n    # Model with initial parameters\\n    initial_model = AutoModelForCausalLM.from_pretrained(\"alignment-handbook/zephyr-7b-sft-full\")\\n  \\n    # Update the learning rate\\n    scheduler.step()\\n\\n    # Initialize total loss for the epoch\\n    total_loss = 0.0\\n\\n    # Generating Synthetic Data (Inner loop)\\n    for index, row in ultrachat_50k_sample.iterrows():\\n\\n        # Rest of the code       \\n        ...\\n\\n        # Output == prompt response dataframe\\n        zephyr_sft_output\\n\\n    # Computing loss using LSPIN function\\n    for (index1, row1), (index2, row2) in zip(ultrachat_50k_sample.iterrows(), zephyr_sft_output.iterrows()):\\n        # Assuming \\'prompt\\' and \\'generated_output\\' are the relevant columns in zephyr_sft_output\\n        prompt = row1[\\'prompt\\']\\n        generated_output = row2[\\'generated_output\\']\\n\\n        # Compute LSPIN loss\\n        updated_model = model  # It will be replacing with updated model\\n        loss = LSPIN_loss(initial_model, updated_model, tokenizer, prompt)\\n\\n        # Accumulate the loss\\n        total_loss += loss.item()\\n\\n    # Backward pass\\n    loss.backward()\\n\\n    # Update the parameters\\n    optimizer.step()\\n\\n    # Update the value of beta\\n    if epoch == 2:\\n        beta = 5.0\\n\\nWhen running this training algorithm for epochs set to 3, it will undergo training and generate a finalized Zephyr SFT LLM version. This version will be capable of generating output up to some extent similar to the ground truth or human response, considering that the official implementation is not yet available as open source on GitHub. Let’s visually explore how the training occurs.\\n\\nTraining using SPIN Algorithm (Created by Fareed Khan)\\n\\nPerformance and Results\\n\\nThe results demonstrate that SPIN can significantly enhance the LLM’s performance across various benchmarks and even surpass models trained through direct preference optimization (DPO) supplemented with additional GPT-4 preference data.\\n\\nPerformance comparison after each epoch (From Original Paper)\\n\\nAs we keep training, the improvements become smaller over time. This suggests that the model reaches a point where further iterations don’t lead to significant gains. This is what the response looks like after each iteration for a sample prompt from our training data.\\n\\nGeneration example of Fine Tuned SPIN LLM (From Original Paper)\\n\\nThe generated response, based on the updated parameters after each iteration, aims to closely match the ground truth response. Moreover, they empirically evaluate their method on several benchmark datasets, including the HuggingFace Open LLM Leaderboard, MT-Bench, and datasets from Big-Bench.\\n\\nResources\\n\\nWolfe, C. R. (2023, September 11). Understanding and Using Supervised Fine-Tuning (SFT) for Language Models. Retrieved from https://cameronrwolfe.substack.com/p/understanding-and-using-supervised\\n\\nChen, Z., Deng, Y., Yuan, H., Ji, K., & Gu, Q. (2024, January 2). Self-Play Fine-Tuning Converts Weak Language Models to Strong Language Models. Retrieved from https://arxiv.org/pdf/2401.01335.pdf\\n\\nTouvron, H. (2023, July 13). Llama 2: Open Foundation and Fine-Tuned Chat Models. Retrieved from https://arxiv.org/abs/2307.09288'}},\n",
       "  {'id': 'f3ebc8c42da3',\n",
       "   'title': 'Coding Stable Diffusion from Scratch',\n",
       "   'subtitle': 'A step by step guide of implementing diffusion model architecture.',\n",
       "   'author': 'b856005e5ecd',\n",
       "   'publication_id': '5517fd7b58a6',\n",
       "   'published_at': '2024-01-04 15:46:31',\n",
       "   'last_modified_at': '2024-01-10 12:03:43',\n",
       "   'tags': ['artificial-intelligence',\n",
       "    'data-science',\n",
       "    'stable-diffusion',\n",
       "    'python',\n",
       "    'machine-learning'],\n",
       "   'topics': [],\n",
       "   'claps': 438,\n",
       "   'voters': 69,\n",
       "   'word_count': 8669,\n",
       "   'responses_count': 6,\n",
       "   'reading_time': 34.46320754716981,\n",
       "   'url': 'https://levelup.gitconnected.com/building-stable-diffusion-from-scratch-using-python-f3ebc8c42da3',\n",
       "   'unique_slug': 'building-stable-diffusion-from-scratch-using-python-f3ebc8c42da3',\n",
       "   'image_url': 'https://miro.medium.com/1*pFNOzxb0_7WkcAyK5NhMxA.png',\n",
       "   'lang': 'en',\n",
       "   'is_series': False,\n",
       "   'is_locked': False,\n",
       "   'is_shortform': False,\n",
       "   'top_highlight': 'This choice is driven by the fact that a color image with 512x512 resolution has a huge number of potential values. In comparison, Stable Diffusion uses a compressed image that is 48 times smaller, containing fewer values. This significant reduction in processing requirements allows the use of Stable Diffusion on a desktop computer with an NVIDIA GPU featuring 8 GB of RAM. The effectiveness of the smaller latent space is based on the idea that natural images follow patterns rather than randomness. Stable Diffusion uses variational autoencoder (VAE) files in the decoder to capture intricate details such as eyes.',\n",
       "   'content': {'id': 'f3ebc8c42da3',\n",
       "    'content': 'Stable Diffusion - Pikachu sleeps with a blanket Example\\n\\nCoding Stable Diffusion from Scratch\\n\\nBuilding a Stable Diffusion from scratch is possible, which you will see in this blog, but achieving the current quality found in the market, similar to how Stability AI has built it, is challenging due to the substantial amount of data and computation required. Just as today you can construct a million-parameter LLM, as demonstrated in one of my blogs, scaling it to a billion parameters, as done by companies like Mistral or Meta, demands the same powerful computation and extensive data resources.\\n\\nIn this blog, I will try to create a small-scale stable diffusion like model from scratch. Small-scale here means that we will be working with a small dataset MNIST, which you may have heard of. The reason for choosing this dataset is that the training process should not take too much time, allowing us to quickly check whether our results are getting better or not. Throughout this blog, all the code you see is available in my GitHub repository.\\n\\nGitHub - FareedKhan-dev/create-stable-diffusion-from-scratch: Implemented a stable diffusion…\\nImplemented a stable diffusion architecture using PyTorch. - GitHub …github.com\\n\\nThe code presented throughout this blog or repository is built on top of the code provided by Binxu, who is currently a Research Fellow at the Kempner Institute.\\n\\nTable of Contents\\n\\nPrerequisites\\n\\nHow Stable Diffusion Works?\\n\\nArchitecture of Stable Diffusion\\n\\nUnderstanding Our Dataset\\n\\nSetting the Stage\\n\\nCreating basic forward diffusion\\n\\nCreating basic reverse diffusion\\n\\nLearning Score Function\\n\\nTime Embedding for Neural Network\\n\\nCoding the U-Net Architecture with Concatenation\\n\\nCoding the U-Net Architecture with Addition\\n\\nForward Diffusion Process with Exponential Noise\\n\\nCoding the Loss Function\\n\\nCoding the Sampler\\n\\nTraining U-Net Concatenation Architecture\\n\\nTraining U-Net Addition Architecture\\n\\nBuilding Attention Layers\\n\\nCoding the U-Net Architecture with Spatial Transformer\\n\\nUpdating U-Net Loss with Denoising Condition\\n\\nTraining U-Net Architecture With Attention Layers\\n\\nGenerating Images\\n\\nWhat’s Next\\n\\nPrerequisites\\n\\nTo achieve fast training, it is essential to use a GPU. Ensure you have a basic understanding of object-oriented programming (OOP) and neural networks (NN). Familiarity with PyTorch will also be helpful in coding. If a GPU is not available, you can modify the device value to ‘cpu’ wherever it appears in the code.\\n\\nPrerequisites for this blog\\n\\nHow Stable Diffusion Works?\\n\\nStable Diffusion operates differently compared to many other image generation models as a diffusion model. In simple terms, diffusion models use fuzzy noise to encode an image. They then use a noise predictor along with a reverse diffusion process to put the image back together.\\n\\nBeyond the technical differences of a diffusion model, Stable Diffusion stands out by not using the pixel space of the image. Instead, it uses a simplified latent space.\\n\\nThis choice is driven by the fact that a color image with 512x512 resolution has a huge number of potential values. In comparison, Stable Diffusion uses a compressed image that is 48 times smaller, containing fewer values. This significant reduction in processing requirements allows the use of Stable Diffusion on a desktop computer with an NVIDIA GPU featuring 8 GB of RAM. The effectiveness of the smaller latent space is based on the idea that natural images follow patterns rather than randomness. Stable Diffusion uses variational autoencoder (VAE) files in the decoder to capture intricate details such as eyes.\\n\\nStable Diffusion V1 underwent training using three datasets compiled by LAION from the Common Crawl. This includes the LAION-Aesthetics v2.6 dataset, which has images with an aesthetic rating of 6 or higher.\\n\\nHow Stable Diffusion works\\n\\nArchitecture of Stable Diffusion\\n\\nStable Diffusion uses several main architectural components, and in this exploration, we will be building these components:\\n\\n1. Variational Autoencoder:\\n\\nConsists of an encoder and decoder.\\n\\nEncoder compresses a 512x512 pixel image into a smaller 64x64 model in latent space.\\n\\nDecoder restores the model from latent space into a full-size 512x512 pixel image.\\n\\n2. Forward Diffusion:\\n\\nAdds Gaussian noise to an image progressively until only random noise remains.\\n\\nUsed during training but not for other tasks, except image-to-image conversion.\\n\\n3. Reverse Diffusion:\\n\\nIteratively undoes forward diffusion.\\n\\nTrained on billions of images using prompts to create unique images.\\n\\n4. Noise Predictor (U-Net):\\n\\nUtilizes a U-Net model for denoising images.\\n\\nU-Net models are convolutional neural networks, with Stable Diffusion using the Residual Neural Network (ResNet) model.\\n\\n5. Text Conditioning:\\n\\nText prompts are a common form of conditioning.\\n\\nA CLIP tokenizer analyzes each word in a textual prompt and embeds the data into a 768-value vector.\\n\\nUp to 75 tokens can be used in a prompt.\\n\\nText prompts are fed from the text encoder to the U-Net noise predictor using a text transformer.\\n\\nSetting the seed to a random number generator generates different images in the latent space.\\n\\nThese components work together to make Stable Diffusion capable of creating and manipulating images in a unique and controlled way.\\n\\nUnderstanding Our Dataset\\n\\nWe’ll use the MNIST dataset from the torchvision module, which has small 28x28 images of handwritten digits 0–9. As mentioned, we want a small dataset so training doesn’t take too long. Let’s take a peek at what our dataset looks like.\\n\\n# Import the required libraries\\nimport torch\\nimport torchvision\\nfrom torchvision import transforms\\nimport matplotlib.pyplot as plt\\n\\n# Define a transform to normalize the data\\ntransform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\\n\\n# Download and load the training dataset\\ntrain_dataset = torchvision.datasets.MNIST(root=\\'./data\\', train=True, transform=transform, download=True)\\ntrain_loader = torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=True)\\n\\n# Extract a batch of unique images\\nunique_images, unique_labels = next(iter(train_loader))\\nunique_images = unique_images.numpy()\\n\\n# Display a grid of unique images\\nfig, axes = plt.subplots(4, 16, figsize=(16, 4), sharex=True, sharey=True)  # Create a 4x16 grid of subplots with a wider figure\\n\\nfor i in range(4):  # Loop over rows\\n    for j in range(16):  # Loop over columns\\n        index = i * 16 + j  # Calculate the index in the batch\\n        axes[i, j].imshow(unique_images[index].squeeze(), cmap=\\'gray\\')  # Show the image using a grayscale colormap\\n        axes[i, j].axis(\\'off\\')  # Turn off axis labels and ticks\\n\\nplt.show()  # Display the plot\\n\\nOutput of above code (Sample MNIST Data)\\n\\nOur dataset comprising 60,000 square images, showcasing hand-drawn digits ranging from 0 to 9. We’re going to construct the Stable Diffusion architecture and train our model using these images. We’ll experiment with various parameter values during the training process. Once the model is trained, we’ll give it a digit, like 5, and it will generate an image of a hand-drawn digit 5 for us.\\n\\nSetting the Stage\\n\\nWe’ll be working with a range of Python libraries throughout this project, so let’s import them:\\n\\n# Import the PyTorch library for tensor operations.\\nimport torch\\n\\n# Import the neural network module from PyTorch.\\nimport torch.nn as nn\\n\\n# Import functional operations from PyTorch.\\nimport torch.nn.functional as F\\n\\n# Import the \\'numpy\\' library for numerical operations.\\nimport numpy as np\\n\\n# Import the \\'functools\\' module for higher-order functions.\\nimport functools\\n\\n# Import the Adam optimizer from PyTorch.\\nfrom torch.optim import Adam\\n\\n# Import the DataLoader class from PyTorch for handling datasets.\\nfrom torch.utils.data import DataLoader\\n\\n# Import data transformation functions from torchvision.\\nimport torchvision.transforms as transforms\\n\\n# Import the MNIST dataset from torchvision.\\nfrom torchvision.datasets import MNIST\\n\\n# Import \\'tqdm\\' for creating progress bars during training.\\nimport tqdm\\n\\n# Import \\'trange\\' and \\'tqdm\\' specifically for notebook compatibility.\\nfrom tqdm.notebook import trange, tqdm\\n\\n# Import the learning rate scheduler from PyTorch.\\nfrom torch.optim.lr_scheduler import MultiplicativeLR, LambdaLR\\n\\n# Import the \\'matplotlib.pyplot\\' library for plotting graphs.\\nimport matplotlib.pyplot as plt\\n\\n# Import the \\'make_grid\\' function from torchvision.utils for visualizing image grids.\\nfrom torchvision.utils import make_grid\\n\\n# Importing the `rearrange` function from the `einops` library\\nfrom einops import rearrange\\n\\n# Importing the `math` module for mathematical operations\\nimport math\\n\\nMake sure to have these libraries installed to avoid any errors:\\n\\n# Install the \\'einops\\' library for easy manipulation of tensors\\npip install einops\\n\\n# Install the \\'lpips\\' library for computing perceptual similarity between images\\npip install lpips\\n\\nAfter importing the necessary libraries, let’s proceed to create the first component of the Stable Diffusion architecture.\\n\\nCreating basic forward diffusion\\n\\nLet’s begin with forward diffusion. In basic terms, the diffusion equation is:\\n\\nForward Diffusion Equation\\n\\nHere, σ(t)>0 is the noise strength, Δt is the step size, and r∼N(0,1) is a standard normal random variable. Simply put, we keep adding normally-distributed noise to our sample. Usually, the noise strength σ(t) is chosen to increase with time (as t gets larger).\\n\\n# Forward diffusion for N steps in 1D.\\ndef forward_diffusion_1D(x0, noise_strength_fn, t0, nsteps, dt):\\n    \"\"\"\\n    Parameters:\\n    - x0: Initial sample value (scalar)\\n    - noise_strength_fn: Function of time, outputs scalar noise strength\\n    - t0: Initial time\\n    - nsteps: Number of diffusion steps\\n    - dt: Time step size\\n\\n    Returns:\\n    - x: Trajectory of sample values over time\\n    - t: Corresponding time points for the trajectory\\n    \"\"\"\\n\\n    # Initialize the trajectory array\\n    x = np.zeros(nsteps + 1)\\n    \\n    # Set the initial sample value\\n    x[0] = x0\\n\\n    # Generate time points for the trajectory\\n    t = t0 + np.arange(nsteps + 1) * dt\\n\\n    # Perform Euler-Maruyama time steps for diffusion simulation\\n    for i in range(nsteps):\\n\\n        # Get the noise strength at the current time\\n        noise_strength = noise_strength_fn(t[i])\\n\\n        # Generate a random normal variable\\n        random_normal = np.random.randn()\\n\\n        # Update the trajectory using Euler-Maruyama method\\n        x[i + 1] = x[i] + random_normal * noise_strength\\n\\n    # Return the trajectory and corresponding time points\\n    return x, t\\n\\nSetting the noise strength function to always equal 1.\\n\\n# Example noise strength function: always equal to 1\\ndef noise_strength_constant(t):\\n    \"\"\"\\n    Example noise strength function that returns a constant value (1).\\n\\n    Parameters:\\n    - t: Time parameter (unused in this example)\\n\\n    Returns:\\n    - Constant noise strength (1)\\n    \"\"\"\\n    return 1\\n\\nNow that we have defined our forward diffusion component, let’s check whether it is working correctly or not for different trials.\\n\\n# Number of diffusion steps\\nnsteps = 100\\n\\n# Initial time\\nt0 = 0\\n\\n# Time step size\\ndt = 0.1\\n\\n# Noise strength function\\nnoise_strength_fn = noise_strength_constant\\n\\n# Initial sample value\\nx0 = 0\\n\\n# Number of tries for visualization\\nnum_tries = 5\\n\\n# Setting larger width and smaller height for the plot\\nplt.figure(figsize=(15, 5))\\n\\n# Loop for multiple trials\\nfor i in range(num_tries):\\n\\n    # Simulate forward diffusion\\n    x, t = forward_diffusion_1D(x0, noise_strength_fn, t0, nsteps, dt)\\n\\n    # Plot the trajectory\\n    plt.plot(t, x, label=f\\'Trial {i+1}\\')  # Adding a label for each trial\\n\\n# Labeling the plot\\nplt.xlabel(\\'Time\\', fontsize=20)\\nplt.ylabel(\\'Sample Value ($x$)\\', fontsize=20)\\n\\n# Title of the plot\\nplt.title(\\'Forward Diffusion Visualization\\', fontsize=20)\\n\\n# Adding a legend to identify each trial\\nplt.legend()\\n\\n# Show the plot\\nplt.show()\\n\\nForward Diffusion for different trials\\n\\nThis visualization illustrates the forward diffusion process, which can be understood as slowly introducing noise to the starting sample. This leads to the creation of various samples as the diffusion process progresses, as depicted in the graph.\\n\\nCreating basic reverse diffusion\\n\\nTo undo this diffusion process, we use a similar update rule:\\n\\nReverse Diffusion Equation\\n\\ns(x,t) is known as the score function. Knowing this function allows us to reverse the forward diffusion and convert noise back into our initial state.\\n\\nIf our starting point is always just one point at x0\\u200b=0, and the noise strength is constant, then the score function is exactly equal to\\n\\nScore function when noise strength is constant\\n\\nNow that we know the mathematical equations, let’s first code the 1D reverse diffusion function.\\n\\n# Reverse diffusion for N steps in 1D.\\ndef reverse_diffusion_1D(x0, noise_strength_fn, score_fn, T, nsteps, dt):\\n    \"\"\"\\n    Parameters:\\n    - x0: Initial sample value (scalar)\\n    - noise_strength_fn: Function of time, outputs scalar noise strength\\n    - score_fn: Score function\\n    - T: Final time\\n    - nsteps: Number of diffusion steps\\n    - dt: Time step size\\n\\n    Returns:\\n    - x: Trajectory of sample values over time\\n    - t: Corresponding time points for the trajectory\\n    \"\"\"\\n\\n    # Initialize the trajectory array\\n    x = np.zeros(nsteps + 1)\\n    \\n    # Set the initial sample value\\n    x[0] = x0\\n\\n    # Generate time points for the trajectory\\n    t = np.arange(nsteps + 1) * dt\\n\\n    # Perform Euler-Maruyama time steps for reverse diffusion simulation\\n    for i in range(nsteps):\\n\\n        # Calculate noise strength at the current time\\n        noise_strength = noise_strength_fn(T - t[i])\\n\\n        # Calculate the score using the score function\\n        score = score_fn(x[i], 0, noise_strength, T - t[i])\\n\\n        # Generate a random normal variable\\n        random_normal = np.random.randn()\\n\\n        # Update the trajectory using the reverse Euler-Maruyama method\\n        x[i + 1] = x[i] + score * noise_strength**2 * dt + noise_strength * random_normal * np.sqrt(dt)\\n\\n    # Return the trajectory and corresponding time points\\n    return x, t\\n\\nNow, we will code a very simple score function, always equal to 1.\\n\\n# Example score function: always equal to 1\\ndef score_simple(x, x0, noise_strength, t):\\n    \"\"\"\\n    Parameters:\\n    - x: Current sample value (scalar)\\n    - x0: Initial sample value (scalar)\\n    - noise_strength: Scalar noise strength at the current time\\n    - t: Current time\\n\\n    Returns:\\n    - score: Score calculated based on the provided formula\\n    \"\"\"\\n\\n    # Calculate the score using the provided formula\\n    score = - (x - x0) / ((noise_strength**2) * t)\\n\\n    # Return the calculated score\\n    return score\\n\\nJust as we plot our forward diffusion function to check whether it is working correctly, we will do the same for our reverse diffusion function.\\n\\n# Number of reverse diffusion steps\\nnsteps = 100\\n\\n# Initial time for reverse diffusion\\nt0 = 0\\n\\n# Time step size for reverse diffusion\\ndt = 0.1\\n\\n# Function defining constant noise strength for reverse diffusion\\nnoise_strength_fn = noise_strength_constant\\n\\n# Example score function for reverse diffusion\\nscore_fn = score_simple\\n\\n# Initial sample value for reverse diffusion\\nx0 = 0\\n\\n# Final time for reverse diffusion\\nT = 11\\n\\n# Number of tries for visualization\\nnum_tries = 5\\n\\n# Setting larger width and smaller height for the plot\\nplt.figure(figsize=(15, 5))\\n\\n# Loop for multiple trials\\nfor i in range(num_tries):\\n    # Draw from the noise distribution, which is diffusion for time T with noise strength 1\\n    x0 = np.random.normal(loc=0, scale=T)\\n\\n    # Simulate reverse diffusion\\n    x, t = reverse_diffusion_1D(x0, noise_strength_fn, score_fn, T, nsteps, dt)\\n\\n    # Plot the trajectory\\n    plt.plot(t, x, label=f\\'Trial {i+1}\\')  # Adding a label for each trial\\n\\n# Labeling the plot\\nplt.xlabel(\\'Time\\', fontsize=20)\\nplt.ylabel(\\'Sample Value ($x$)\\', fontsize=20)\\n\\n# Title of the plot\\nplt.title(\\'Reverse Diffusion Visualized\\', fontsize=20)\\n\\n# Adding a legend to identify each trial\\nplt.legend()\\n\\n# Show the plot\\nplt.show()\\n\\nReverse Diffusion for different trials\\n\\nThis visualization shows that after the forward diffusion process creates a sample from the complex data distribution (as seen in the previous forward diffusion visualization), the reverse diffusion process maps it back to the simple distribution using a series of inverse transformations.\\n\\nLearning Score Function\\n\\nIn real-world scenarios, we start without knowledge of the score function, our goal is to learn it. One approach involves training a neural network to ‘denoise’ samples using the denoising objective:\\n\\ndenoising objective equation\\n\\nHere, p0\\u200b(x0\\u200b) represents our target distribution (e.g., images of cars and cats), and x(noised)\\u200b denotes the sample from the target distribution x0\\u200b after a single forward diffusion step. In simpler terms, [ x(noised) \\u200b− x0 ]\\u200b is essentially a normally-distributed random variable.\\n\\nExpressing the same idea in a way closer to the actual implementation:\\n\\nother way to write denoising objective equation\\n\\nIt’s important to understand the concept that our aim is to predict the amount of noise added to each part of our sample effectively at every time t in the diffusion process and for every x0\\u200b in our original distribution (cars, cats, etc.)\\n\\nIn these expressions:\\n\\nJ represents the denoising objective.\\n\\nE denotes the expectation.\\n\\nt represents the time parameter.\\n\\nx0\\u200b is a sample from the target distribution p0\\u200b(x0\\u200b).\\n\\nx(noised)\\u200b represents the target distribution sample x0\\u200b after one forward diffusion step.\\n\\ns(⋅,⋅) represents the score function.\\n\\nσ(t) is a function of time.\\n\\nϵ is a normally-distributed random variable.\\n\\nSo far, we’ve covered the basics of how forward and backward diffusion work, and we’ve explored how to learn our score function.\\n\\nTime Embedding for Neural Network\\n\\nLearning the score function is like transforming random noise into something meaningful. To do this, we use a neural network to approximate the score function. When dealing with images, we want our neural network to cooperate well with them and the score function we aim to learn depends on time, we need a method to ensure our neural network accurately responds to time variations. To achieve this, we can use a time embedding.\\n\\nInstead of only providing our network with a single time value, we represent the current time using many sinusoidal features. By offering various representations of time, we aim to enhance our network’s ability to adapt to time changes. This approach allows us to effectively learn a time-dependent score function s(x,t).\\n\\nTo enable our neural network to interact with time, we need to create two modules.\\n\\n# Define a module for Gaussian random features used to encode time steps.\\nclass GaussianFourierProjection(nn.Module):\\n    def __init__(self, embed_dim, scale=30.):\\n        \"\"\"\\n        Parameters:\\n        - embed_dim: Dimensionality of the embedding (output dimension)\\n        - scale: Scaling factor for random weights (frequencies)\\n        \"\"\"\\n        super().__init__()\\n\\n        # Randomly sample weights (frequencies) during initialization.\\n        # These weights (frequencies) are fixed during optimization and are not trainable.\\n        self.W = nn.Parameter(torch.randn(embed_dim // 2) * scale, requires_grad=False)\\n\\n    def forward(self, x):\\n        \"\"\"\\n        Parameters:\\n        - x: Input tensor representing time steps\\n        \"\"\"\\n        # Calculate the cosine and sine projections: Cosine(2 pi freq x), Sine(2 pi freq x)\\n        x_proj = x[:, None] * self.W[None, :] * 2 * np.pi\\n\\n        # Concatenate the sine and cosine projections along the last dimension\\n        return torch.cat([torch.sin(x_proj), torch.cos(x_proj)], dim=-1)\\n\\nThe GaussianFourierProjection function is designed to create a module for generating Gaussian random features, which will be used to represent time steps in our context. When we utilize this module, it generates random frequencies that remain fixed throughout the optimization process. Once we provide an input tensor x to the module, it computes sine and cosine projections by multiplying x with these pre-defined random frequencies. These projections are then concatenated to form a feature representation of the input, effectively capturing temporal patterns. This module is valuable in our task, where we aim to incorporate time-related information into our neural network.\\n\\n# Define a module for a fully connected layer that reshapes outputs to feature maps.\\nclass Dense(nn.Module):\\n    def __init__(self, input_dim, output_dim):\\n        \"\"\"\\n        Parameters:\\n        - input_dim: Dimensionality of the input features\\n        - output_dim: Dimensionality of the output features\\n        \"\"\"\\n        super().__init__()\\n\\n        # Define a fully connected layer\\n        self.dense = nn.Linear(input_dim, output_dim)\\n\\n    def forward(self, x):\\n        \"\"\"\\n        Parameters:\\n        - x: Input tensor\\n\\n        Returns:\\n        - Output tensor after passing through the fully connected layer\\n          and reshaping to a 4D tensor (feature map)\\n        \"\"\"\\n\\n        # Apply the fully connected layer and reshape the output to a 4D tensor\\n        return self.dense(x)[..., None, None]\\n        # This broadcasts the 2D tensor to a 4D tensor, adding the same value across space.\\n\\nDense is designed to reshape the output of the fully connected layer into a 4D tensor, effectively converting it into a feature map. The module takes as input the dimensionality of the input features (input_dim) and the desired dimensionality of the output features (output_dim). During the forward pass, the input tensor x is processed through the fully connected layer (self.dense(x)) and the output is reshaped into a 4D tensor by adding two singleton dimensions at the end ([..., None, None]). This reshaping operation effectively transforms the output into a feature map suitable for further processing in convolutional layers. This operation broadcasts the 2D tensor to a 4D tensor by adding the same value across spatial dimensions.\\n\\nNow that we’ve established the two modules for integrating time interaction into our neural network, it’s time to proceed with coding the main neural network.\\n\\nCoding the U-Net Architecture with Concatenation\\n\\nWhen dealing with images, our neural network needs to work seamlessly with them and capture the inherent features associated with images.\\n\\nWe opt for a U-Net architecture, which combines a CNN-like structure with downscaling/upscaling operations. This combination helps the network focus on image features at different spatial scales.\\n\\n# Define a time-dependent score-based model built upon the U-Net architecture.\\nclass UNet(nn.Module):\\n    def __init__(self, marginal_prob_std, channels=[32, 64, 128, 256], embed_dim=256):\\n        \"\"\"\\n        Initialize a time-dependent score-based network.\\n\\n        Parameters:\\n        - marginal_prob_std: A function that takes time t and gives the standard deviation\\n          of the perturbation kernel p_{0t}(x(t) | x(0)).\\n        - channels: The number of channels for feature maps of each resolution.\\n        - embed_dim: The dimensionality of Gaussian random feature embeddings.\\n        \"\"\"\\n\\n        super().__init__()\\n\\n        # Gaussian random feature embedding layer for time\\n        self.time_embed = nn.Sequential(\\n            GaussianFourierProjection(embed_dim=embed_dim),\\n            nn.Linear(embed_dim, embed_dim)\\n        )\\n\\n        # Encoding layers where the resolution decreases\\n        self.conv1 = nn.Conv2d(1, channels[0], 3, stride=1, bias=False)\\n        self.dense1 = Dense(embed_dim, channels[0])\\n        self.gnorm1 = nn.GroupNorm(4, num_channels=channels[0])\\n\\n        self.conv2 = nn.Conv2d(channels[0], channels[1], 3, stride=2, bias=False)\\n        self.dense2 = Dense(embed_dim, channels[1])\\n        self.gnorm2 = nn.GroupNorm(32, num_channels=channels[1])\\n\\n        # Additional encoding layers (copied from the original code)\\n        self.conv3 = nn.Conv2d(channels[1], channels[2], 3, stride=2, bias=False)\\n        self.dense3 = Dense(embed_dim, channels[2])\\n        self.gnorm3 = nn.GroupNorm(32, num_channels=channels[2])\\n\\n        self.conv4 = nn.Conv2d(channels[2], channels[3], 3, stride=2, bias=False)\\n        self.dense4 = Dense(embed_dim, channels[3])\\n        self.gnorm4 = nn.GroupNorm(32, num_channels=channels[3])\\n\\n        # Decoding layers where the resolution increases\\n        self.tconv4 = nn.ConvTranspose2d(channels[3], channels[2], 3, stride=2, bias=False)\\n        self.dense5 = Dense(embed_dim, channels[2])\\n        self.tgnorm4 = nn.GroupNorm(32, num_channels=channels[2])\\n\\n        self.tconv3 = nn.ConvTranspose2d(channels[2] + channels[2], channels[1], 3, stride=2, bias=False, output_padding=1)\\n        self.dense6 = Dense(embed_dim, channels[1])\\n        self.tgnorm3 = nn.GroupNorm(32, num_channels=channels[1])\\n\\n        self.tconv2 = nn.ConvTranspose2d(channels[1] + channels[1], channels[0], 3, stride=2, bias=False, output_padding=1)\\n        self.dense7 = Dense(embed_dim, channels[0])\\n        self.tgnorm2 = nn.GroupNorm(32, num_channels=channels[0])\\n\\n        self.tconv1 = nn.ConvTranspose2d(channels[0] + channels[0], 1, 3, stride=1)\\n\\n        # The swish activation function\\n        self.act = lambda x: x * torch.sigmoid(x)\\n        self.marginal_prob_std = marginal_prob_std\\n\\n    def forward(self, x, t, y=None):\\n        \"\"\"\\n        Parameters:\\n        - x: Input tensor\\n        - t: Time tensor\\n        - y: Target tensor (not used in this forward pass)\\n\\n        Returns:\\n        - h: Output tensor after passing through the U-Net architecture\\n        \"\"\"\\n\\n        # Obtain the Gaussian random feature embedding for t\\n        embed = self.act(self.time_embed(t))\\n\\n        # Encoding path\\n        h1 = self.conv1(x) + self.dense1(embed)\\n        h1 = self.act(self.gnorm1(h1))\\n        h2 = self.conv2(h1) + self.dense2(embed)\\n        h2 = self.act(self.gnorm2(h2))\\n\\n        # Additional encoding path layers (copied from the original code)\\n        h3 = self.conv3(h2) + self.dense3(embed)\\n        h3 = self.act(self.gnorm3(h3))\\n        h4 = self.conv4(h3) + self.dense4(embed)\\n        h4 = self.act(self.gnorm4(h4))\\n\\n        # Decoding path\\n        h = self.tconv4(h4)\\n        h += self.dense5(embed)\\n        h = self.act(self.tgnorm4(h))\\n        h = self.tconv3(torch.cat([h, h3], dim=1))\\n        h += self.dense6(embed)\\n        h = self.act(self.tgnorm3(h))\\n        h = self.tconv2(torch.cat([h, h2], dim=1))\\n        h += self.dense7(embed)\\n        h = self.act(self.tgnorm2(h))\\n        h = self.tconv1(torch.cat([h, h1], dim=1))\\n\\n        # Normalize output\\n        h = h / self.marginal_prob_std(t)[:, None, None, None]\\n        return h\\n\\nWe created a model that understands how things change over time. It uses a special architecture called U-Net. Imagine you have a starting picture, and you want to see how it transforms over different moments in time. The model learns patterns and details from these transformations. The code defines how this learning happens, using various layers and computations. It makes sure the output, or the generated pictures, are properly adjusted based on the time information. It’s like a smart tool for understanding and predicting how things evolve visually.\\n\\nThroughout the U-Net model’s architecture, the shape of tensors evolves as information passes through encoding and decoding paths. In the encoding path, which involves downsampling, tensors undergo shape reduction with each convolutional layer - h1, h2, h3, and h4 successively. In the decoding path, the transpose convolutional layers initiate the recovery of spatial information. The tensor h starts to restore the original spatial dimensions, and at each step (h4 to h1), features from earlier layers are added back to facilitate upsampling. Finally, the last layer, represented by h, produces the output, and a normalization step ensures appropriate scaling for the generated image. The specifics of tensor shapes depend on factors like filter sizes, strides, and padding used in the convolutional layers, shaping the model\\'s ability to capture and reconstruct details effectively.\\n\\nCoding the U-Net Architecture with Addition\\n\\nDiffusion models can work well with various architectural choices. In the previous model we built, we combined the tensor from the down blocks using concatenation for skip connection. In the upcoming model we’ll code, we’ll simply add the tensor from the down blocks for skip connection.\\n\\n# Define a time-dependent score-based model built upon the U-Net architecture.\\nclass UNet_res(nn.Module):\\n    def __init__(self, marginal_prob_std, channels=[32, 64, 128, 256], embed_dim=256):\\n        \"\"\"\\n        Parameters:\\n        - marginal_prob_std: A function that takes time t and gives the standard deviation\\n          of the perturbation kernel p_{0t}(x(t) | x(0)).\\n        - channels: The number of channels for feature maps of each resolution.\\n        - embed_dim: The dimensionality of Gaussian random feature embeddings.\\n        \"\"\"\\n\\n        super().__init__()\\n\\n        # Gaussian random feature embedding layer for time\\n        self.time_embed = nn.Sequential(\\n            GaussianFourierProjection(embed_dim=embed_dim),\\n            nn.Linear(embed_dim, embed_dim)\\n        )\\n\\n        # Encoding layers where the resolution decreases\\n        self.conv1 = nn.Conv2d(1, channels[0], 3, stride=1, bias=False)\\n        self.dense1 = Dense(embed_dim, channels[0])\\n        self.gnorm1 = nn.GroupNorm(4, num_channels=channels[0])\\n        self.conv2 = nn.Conv2d(channels[0], channels[1], 3, stride=2, bias=False)\\n        self.dense2 = Dense(embed_dim, channels[1])\\n        self.gnorm2 = nn.GroupNorm(32, num_channels=channels[1])\\n        self.conv3 = nn.Conv2d(channels[1], channels[2], 3, stride=2, bias=False)\\n        self.dense3 = Dense(embed_dim, channels[2])\\n        self.gnorm3 = nn.GroupNorm(32, num_channels=channels[2])\\n        self.conv4 = nn.Conv2d(channels[2], channels[3], 3, stride=2, bias=False)\\n        self.dense4 = Dense(embed_dim, channels[3])\\n        self.gnorm4 = nn.GroupNorm(32, num_channels=channels[3])\\n\\n        # Decoding layers where the resolution increases\\n        self.tconv4 = nn.ConvTranspose2d(channels[3], channels[2], 3, stride=2, bias=False)\\n        self.dense5 = Dense(embed_dim, channels[2])\\n        self.tgnorm4 = nn.GroupNorm(32, num_channels=channels[2])\\n        self.tconv3 = nn.ConvTranspose2d(channels[2], channels[1], 3, stride=2, bias=False, output_padding=1)\\n        self.dense6 = Dense(embed_dim, channels[1])\\n        self.tgnorm3 = nn.GroupNorm(32, num_channels=channels[1])\\n        self.tconv2 = nn.ConvTranspose2d(channels[1], channels[0], 3, stride=2, bias=False, output_padding=1)\\n        self.dense7 = Dense(embed_dim, channels[0])\\n        self.tgnorm2 = nn.GroupNorm(32, num_channels=channels[0])\\n        self.tconv1 = nn.ConvTranspose2d(channels[0], 1, 3, stride=1)\\n\\n        # The swish activation function\\n        self.act = lambda x: x * torch.sigmoid(x)\\n        self.marginal_prob_std = marginal_prob_std\\n\\n    def forward(self, x, t, y=None):\\n        \"\"\"\\n        Parameters:\\n        - x: Input tensor\\n        - t: Time tensor\\n        - y: Target tensor (not used in this forward pass)\\n\\n        Returns:\\n        - h: Output tensor after passing through the U-Net architecture\\n        \"\"\"\\n\\n        # Obtain the Gaussian random feature embedding for t\\n        embed = self.act(self.time_embed(t))\\n\\n        # Encoding path\\n        h1 = self.conv1(x) + self.dense1(embed)\\n        h1 = self.act(self.gnorm1(h1))\\n        h2 = self.conv2(h1) + self.dense2(embed)\\n        h2 = self.act(self.gnorm2(h2))\\n        h3 = self.conv3(h2) + self.dense3(embed)\\n        h3 = self.act(self.gnorm3(h3))\\n        h4 = self.conv4(h3) + self.dense4(embed)\\n        h4 = self.act(self.gnorm4(h4))\\n\\n        # Decoding path\\n        h = self.tconv4(h4)\\n        h += self.dense5(embed)\\n        h = self.act(self.tgnorm4(h))\\n        h = self.tconv3(h + h3)\\n        h += self.dense6(embed)\\n        h = self.act(self.tgnorm3(h))\\n        h = self.tconv2(h + h2)\\n        h += self.dense7(embed)\\n        h = self.act(self.tgnorm2(h))\\n        h = self.tconv1(h + h1)\\n\\n        # Normalize output\\n        h = h / self.marginal_prob_std(t)[:, None, None, None]\\n        return h\\n\\nThe UNet_res model that we have just coded is a variant of the standard UNet model. While both models follow the U-Net architecture, the key difference lies in how skip connections are implemented. In the original UNet model, skip connections concatenate tensors from the encoding path with tensors in the decoding path. However, in the UNet_res model, skip connections involve directly adding tensors from the encoding path to the corresponding tensors in the decoding path. This variation in skip connection strategies can influence the information flow and interactions between different resolution levels, potentially affecting the model’s capacity to capture features and dependencies in the data.\\n\\nForward Diffusion Process with Exponential Noise\\n\\nWe will define the specific forward diffusion process:\\n\\nforward diffusion equation\\n\\nThis formula represents a dynamic system where the variable x changes over time (t) with the introduction of noise (dw). The noise level is determined by the parameter σ, and it increases exponentially as time progresses.\\n\\nGiven this process and an initial value x(0), we can find an analytical solution for x(t):\\n\\nAnalytical solution for the sample\\n\\nIn this context, σ(t) is referred to as the marginal standard deviation. Essentially, it represents the variability of the distribution of x(t) given the initial value x(0).\\n\\nFor our specific case, the marginal standard deviation is calculated as:\\n\\nmarginal standard deviation equation\\n\\nThis formula provides a detailed understanding of how the noise level (σ) evolves over time, influencing the variability of the system.\\n\\n# Using GPU\\ndevice = \"cuda\"\\n\\n# Marginal Probability Standard Deviation Function\\ndef marginal_prob_std(t, sigma):\\n    \"\"\"\\n    Compute the mean and standard deviation of $p_{0t}(x(t) | x(0))$.\\n\\n    Parameters:\\n    - t: A vector of time steps.\\n    - sigma: The $\\\\sigma$ in our SDE.\\n\\n    Returns:\\n    - The standard deviation.\\n    \"\"\"\\n    # Convert time steps to a PyTorch tensor\\n    t = torch.tensor(t, device=device)\\n    \\n    # Calculate and return the standard deviation based on the given formula\\n    return torch.sqrt((sigma**(2 * t) - 1.) / 2. / np.log(sigma))\\n\\nNow that we have coded the function for marginal probability standard deviation, we can similarly code the diffusion coefficient.\\n\\n# Using GPU\\ndevice = \"cuda\"\\n\\ndef diffusion_coeff(t, sigma):\\n    \"\"\"\\n    Compute the diffusion coefficient of our SDE.\\n\\n    Parameters:\\n    - t: A vector of time steps.\\n    - sigma: The $\\\\sigma$ in our SDE.\\n\\n    Returns:\\n    - The vector of diffusion coefficients.\\n    \"\"\"\\n    # Calculate and return the diffusion coefficients based on the given formula\\n    return torch.tensor(sigma**t, device=device)\\n\\nNow we initialize both marginal probability standard deviation and diffusion coefficient with sigma 25\\n\\n# Sigma Value\\nsigma =  25.0\\n\\n# marginal probability standard\\nmarginal_prob_std_fn = functools.partial(marginal_prob_std, sigma=sigma)\\n\\n# diffusion coefficient\\ndiffusion_coeff_fn = functools.partial(diffusion_coeff, sigma=sigma)\\n\\nAfter coding both modules, it’s time to develop the loss function for our stable diffusion architecture.\\n\\nCoding the Loss Function\\n\\nNow, we’re putting together the U-Net we made earlier with a method to learn the score function. We’ll create a loss function and train the neural network.\\n\\ndef loss_fn(model, x, marginal_prob_std, eps=1e-5):\\n    \"\"\"\\n    The loss function for training score-based generative models.\\n\\n    Parameters:\\n    - model: A PyTorch model instance that represents a time-dependent score-based model.\\n    - x: A mini-batch of training data.\\n    - marginal_prob_std: A function that gives the standard deviation of the perturbation kernel.\\n    - eps: A tolerance value for numerical stability.\\n    \"\"\"\\n    # Sample time uniformly in the range (eps, 1-eps)\\n    random_t = torch.rand(x.shape[0], device=x.device) * (1. - 2 * eps) + eps\\n    # Find the noise std at the sampled time `t`\\n    std = marginal_prob_std(random_t)\\n    \\n    # Generate normally distributed noise\\n    z = torch.randn_like(x)\\n    \\n    # Perturb the input data with the generated noise\\n    perturbed_x = x + z * std[:, None, None, None]\\n    \\n    # Get the score from the model using the perturbed data and time\\n    score = model(perturbed_x, random_t)\\n    \\n    # Calculate the loss based on the score and noise\\n    loss = torch.mean(torch.sum((score * std[:, None, None, None] + z)**2, dim=(1, 2, 3)))\\n    \\n    return loss\\n\\nThis loss function figures out how wrong our model is while training. It involves picking a random time, getting the noise level, adding this noise to our data, and then checking how off our model’s prediction is from reality. The aim is to reduce this error during training.\\n\\nCoding the Sampler\\n\\nStable Diffusion creates an image by starting with a totally random one. The noise predictor then guesses how noisy the image is, and this guessed noise is removed from the image. This whole cycle repeats several times, resulting in a clean image at the end.\\n\\nThis cleaning-up process is called \"sampling\" because Stable Diffusion produces a fresh image sample at each step. The way it creates these samples is called the \"sampler\" or \"sampling method\".\\n\\nStable Diffusion has various options for creating image samples, and one method we’ll use is the Euler–Maruyama method, also known as the Euler method.\\n\\n# number of steps\\nnum_steps = 500\\n\\ndef Euler_Maruyama_sampler(score_model,\\n                           marginal_prob_std,\\n                           diffusion_coeff,\\n                           batch_size=64,\\n                           x_shape=(1, 28, 28),\\n                           num_steps=num_steps,\\n                           device=\\'cuda\\',\\n                           eps=1e-3, y=None):\\n    \"\"\"\\n    Generate samples from score-based models with the Euler-Maruyama solver.\\n\\n    Parameters:\\n    - score_model: A PyTorch model that represents the time-dependent score-based model.\\n    - marginal_prob_std: A function that gives the standard deviation of the perturbation kernel.\\n    - diffusion_coeff: A function that gives the diffusion coefficient of the SDE.\\n    - batch_size: The number of samplers to generate by calling this function once.\\n    - x_shape: The shape of the samples.\\n    - num_steps: The number of sampling steps, equivalent to the number of discretized time steps.\\n    - device: \\'cuda\\' for running on GPUs, and \\'cpu\\' for running on CPUs.\\n    - eps: The smallest time step for numerical stability.\\n    - y: Target tensor (not used in this function).\\n\\n    Returns:\\n    - Samples.\\n    \"\"\"\\n\\n    # Initialize time and the initial sample\\n    t = torch.ones(batch_size, device=device)\\n    init_x = torch.randn(batch_size, *x_shape, device=device) * marginal_prob_std(t)[:, None, None, None]\\n    \\n    # Generate time steps\\n    time_steps = torch.linspace(1., eps, num_steps, device=device)\\n    step_size = time_steps[0] - time_steps[1]\\n    x = init_x\\n    \\n    # Sample using Euler-Maruyama method\\n    with torch.no_grad():\\n        for time_step in tqdm(time_steps):\\n            batch_time_step = torch.ones(batch_size, device=device) * time_step\\n            g = diffusion_coeff(batch_time_step)\\n            mean_x = x + (g**2)[:, None, None, None] * score_model(x, batch_time_step, y=y) * step_size\\n            x = mean_x + torch.sqrt(step_size) * g[:, None, None, None] * torch.randn_like(x)\\n    \\n    # Do not include any noise in the last sampling step.\\n    return mean_x\\n\\nThis function generates image samples using the Euler–Maruyama method, combining a score-based model, a function for noise standard deviation, and a diffusion coefficient. It iteratively applies the method over a specified number of steps, returning the final set of generated samples.\\n\\nTraining U-Net Concatenation Architecture\\n\\nWe have developed two U-Net architectures: one utilizing addition and the other utilizing concatenation. To initiate training, we will use the U-Net architecture based on concatenation with the following hyperparameters: 50 epochs for training, a mini-batch size of 2048, and a learning rate of 5e-4. The training will be conducted on the MNIST dataset.\\n\\n# Define the score-based model and move it to the specified device\\nscore_model = torch.nn.DataParallel(UNet(marginal_prob_std=marginal_prob_std_fn))\\nscore_model = score_model.to(device)\\n\\n# Number of training epochs\\nn_epochs = 50\\n# Size of a mini-batch\\nbatch_size = 2048\\n# Learning rate\\nlr = 5e-4\\n\\n# Load the MNIST dataset and create a data loader\\ndataset = MNIST(\\'.\\', train=True, transform=transforms.ToTensor(), download=True)\\ndata_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=4)\\n\\n# Define the Adam optimizer for training the model\\noptimizer = Adam(score_model.parameters(), lr=lr)\\n\\n# Progress bar for epochs\\ntqdm_epoch = trange(n_epochs)\\nfor epoch in tqdm_epoch:\\n    avg_loss = 0.\\n    num_items = 0\\n    # Iterate through mini-batches in the data loader\\n    for x, y in tqdm(data_loader):\\n        x = x.to(device)\\n        # Calculate the loss and perform backpropagation\\n        loss = loss_fn(score_model, x, marginal_prob_std_fn)\\n        optimizer.zero_grad()\\n        loss.backward()\\n        optimizer.step()\\n        avg_loss += loss.item() * x.shape[0]\\n        num_items += x.shape[0]\\n    # Print the averaged training loss for the current epoch\\n    tqdm_epoch.set_description(\\'Average Loss: {:5f}\\'.format(avg_loss / num_items))\\n    # Save the model checkpoint after each epoch of training\\n    torch.save(score_model.state_dict(), \\'ckpt.pth\\')\\n\\nUpon executing the training code, the entire training process is expected to complete in approximately 7 minutes for each epoch. The average loss observed across epochs is 34.128, and the trained model will be saved in the current directory with the filename \"ckpt.pth\".\\n\\nLet’s visualize the results from our U-Net architecture based on concatenation. It’s important to note that we haven’t started working on developing a system where we pass a prompt to generate specific results. The current visualization is simply based on random inputs.\\n\\n# Load the pre-trained checkpoint from disk.\\ndevice = \\'cuda\\'\\n\\n# Load the pre-trained model checkpoint\\nckpt = torch.load(\\'ckpt.pth\\', map_location=device)\\nscore_model.load_state_dict(ckpt)\\n\\n# Set sample batch size and number of steps\\nsample_batch_size = 64\\nnum_steps = 500\\n\\n# Choose the Euler-Maruyama sampler\\nsampler = Euler_Maruyama_sampler\\n\\n# Generate samples using the specified sampler\\nsamples = sampler(score_model,\\n                  marginal_prob_std_fn,\\n                  diffusion_coeff_fn,\\n                  sample_batch_size,\\n                  num_steps=num_steps,\\n                  device=device,\\n                  y=None)\\n\\n# Clip samples to be in the range [0, 1]\\nsamples = samples.clamp(0.0, 1.0)\\n\\n# Visualize the generated samples\\n%matplotlib inline\\nimport matplotlib.pyplot as plt\\nsample_grid = make_grid(samples, nrow=int(np.sqrt(sample_batch_size)))\\n\\n# Plot the sample grid\\nplt.figure(figsize=(6, 6))\\nplt.axis(\\'off\\')\\nplt.imshow(sample_grid.permute(1, 2, 0).cpu(), vmin=0., vmax=1.)\\nplt.show()\\n\\nOutput of U-Net Architecture based on concatenation for 50 Epochs\\n\\nThe current results are not satisfactory, as it is challenging to identify any numbers clearly. However, there is still a lot to cover in this blog, which will showcase promising results.\\n\\nTraining U-Net Addition Architecture\\n\\nThe U-Net architecture with concatenation did not perform well. However, let’s proceed with training the U-Net architecture based on addition and determine whether it yields improved results or not.\\n\\nWe will be using following hyperparameters: 75 epochs for training, a mini-batch size of 1024, and a learning rate of 10e-3. The training will be conducted on the MNIST dataset.\\n\\n# Initialize the alternate U-Net model for training.\\nscore_model = torch.nn.DataParallel(UNet_res(marginal_prob_std=marginal_prob_std_fn))\\nscore_model = score_model.to(device)\\n\\n# Set the number of training epochs, mini-batch size, and learning rate.\\nn_epochs = 75\\nbatch_size = 1024\\nlr = 1e-3\\n\\n# Load the MNIST dataset for training.\\ndataset = MNIST(\\'.\\', train=True, transform=transforms.ToTensor(), download=True)\\ndata_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=4)\\n\\n# Initialize the Adam optimizer with the specified learning rate.\\noptimizer = Adam(score_model.parameters(), lr=lr)\\n# Learning rate scheduler to adjust the learning rate during training.\\nscheduler = LambdaLR(optimizer, lr_lambda=lambda epoch: max(0.2, 0.98 ** epoch))\\n\\n# Training loop over epochs.\\ntqdm_epoch = trange(n_epochs)\\nfor epoch in tqdm_epoch:\\n    avg_loss = 0.\\n    num_items = 0\\n    # Iterate over mini-batches in the training data loader.\\n    for x, y in data_loader:\\n        x = x.to(device)\\n        # Compute the loss for the current mini-batch.\\n        loss = loss_fn(score_model, x, marginal_prob_std_fn)\\n        # Zero the gradients, backpropagate, and update the model parameters.\\n        optimizer.zero_grad()\\n        loss.backward()\\n        optimizer.step()\\n        # Accumulate the total loss and the number of processed items.\\n        avg_loss += loss.item() * x.shape[0]\\n        num_items += x.shape[0]\\n    \\n    # Adjust the learning rate using the scheduler.\\n    scheduler.step()\\n    lr_current = scheduler.get_last_lr()[0]\\n    \\n    # Print the average loss and learning rate for the current epoch.\\n    print(\\'{} Average Loss: {:5f} lr {:.1e}\\'.format(epoch, avg_loss / num_items, lr_current))\\n    tqdm_epoch.set_description(\\'Average Loss: {:5f}\\'.format(avg_loss / num_items))\\n    \\n    # Save the model checkpoint after each epoch of training.\\n    torch.save(score_model.state_dict(), \\'ckpt_res.pth\\')\\n\\nUpon executing the training code, the entire training process is expected to complete in approximately 11 minutes for each epoch. The average loss observed across epochs is 24.585, and the trained model will be saved in the current directory with the filename \"ckpt_res.pth\".\\n\\nLet’s visualize the results from our U-Net architecture based on addition.\\n\\n# Load the pre-trained checkpoint from disk.\\ndevice = \\'cuda\\'\\n\\n# Load the pre-trained model checkpoint\\nckpt = torch.load(\\'ckpt_res.pth\\', map_location=device)\\nscore_model.load_state_dict(ckpt)\\n\\n# Set sample batch size and number of steps\\nsample_batch_size = 64\\nnum_steps = 500\\n\\n# Choose the Euler-Maruyama sampler\\nsampler = Euler_Maruyama_sampler\\n\\n# Generate samples using the specified sampler\\nsamples = sampler(score_model,\\n                  marginal_prob_std_fn,\\n                  diffusion_coeff_fn,\\n                  sample_batch_size,\\n                  num_steps=num_steps,\\n                  device=device,\\n                  y=None)\\n\\n# Clip samples to be in the range [0, 1]\\nsamples = samples.clamp(0.0, 1.0)\\n\\n# Visualize the generated samples\\n%matplotlib inline\\nimport matplotlib.pyplot as plt\\nsample_grid = make_grid(samples, nrow=int(np.sqrt(sample_batch_size)))\\n\\n# Plot the sample grid\\nplt.figure(figsize=(6, 6))\\nplt.axis(\\'off\\')\\nplt.imshow(sample_grid.permute(1, 2, 0).cpu(), vmin=0., vmax=1.)\\nplt.show()\\n\\nOutput of U-Net Architecture based on addition for 75 Epochs\\n\\nThe U-Net architecture based on addition demonstrates better performance compared to the concatenation architecture. It allows for clearer identification of numbers in the images, and additionally, the loss consistently decreases during training using this architecture.\\n\\nUp until now, our architecture has generated random image samples. However, the goal is to enable our stable diffusion model to hand-draw a specified number when provided as input.\\n\\nBuilding Attention Layers\\n\\nWhen creating attention models, we usually have three main parts:\\n\\nCross Attention: Handles self/cross attention for sequences.\\n\\nTransformer Block: Combines attention with a neural network for processing.\\n\\nSpatial Transformer: Transforms the spatial tensor in a U-net to a sequential form and vice versa.\\n\\nLet’s break down the math behind attention models in simpler terms. In QKV (query-key-value) attention, we represent queries, keys, and values as vectors. These vectors help us connect words or images on one side of a translation task to the other side.\\n\\nThese vectors (q, k, v) are linearly related to the encoder’s hidden state vectors (e) and the decoder’s hidden state vectors (h):\\n\\nquery, key and value\\n\\n\\u200bTo decide what to ‘pay attention’ to, we calculate the inner product (similarity) of each key (k) and query (q). To ensure the values are reasonable, we normalize them by the length of the query vectors (qi).\\n\\nThe final attention distribution is obtained by applying softmax to these values:\\n\\nApplying Softmax\\n\\nThis attention distribution helps pick out a relevant combination of features. For instance, when translating the phrase \"This is cool\" from English to French, the correct answer (\"c’est cool\") involves paying attention to both words simultaneously, rather than translating each word separately. Mathematically, we use the attention distribution to weight the values (vj):\\n\\nattention distribution\\n\\nNow that we understand the basics of attention and the three attention modules we need to build, let’s begin coding them.\\u200b\\n\\nLet’s start by coding the first attention layer, which is CrossAttention.\\n\\nclass CrossAttention(nn.Module):\\n    def __init__(self, embed_dim, hidden_dim, context_dim=None, num_heads=1):\\n        \"\"\"\\n        Initialize the CrossAttention module.\\n\\n        Parameters:\\n        - embed_dim: The dimensionality of the output embeddings.\\n        - hidden_dim: The dimensionality of the hidden representations.\\n        - context_dim: The dimensionality of the context representations (if not self attention).\\n        - num_heads: Number of attention heads (currently supports 1 head).\\n\\n        Note: For simplicity reasons, the implementation assumes 1-head attention.\\n        Feel free to implement multi-head attention using fancy tensor manipulations.\\n        \"\"\"\\n        super(CrossAttention, self).__init__()\\n\\n        self.hidden_dim = hidden_dim\\n        self.context_dim = context_dim\\n        self.embed_dim = embed_dim\\n\\n        # Linear layer for query projection\\n        self.query = nn.Linear(hidden_dim, embed_dim, bias=False)\\n        \\n        # Check if self-attention or cross-attention\\n        if context_dim is None:\\n            self.self_attn = True\\n            self.key = nn.Linear(hidden_dim, embed_dim, bias=False)\\n            self.value = nn.Linear(hidden_dim, hidden_dim, bias=False)\\n        else:\\n            self.self_attn = False\\n            self.key = nn.Linear(context_dim, embed_dim, bias=False)\\n            self.value = nn.Linear(context_dim, hidden_dim, bias=False)\\n\\n    def forward(self, tokens, context=None):\\n        \"\"\"\\n        Forward pass of the CrossAttention module.\\n\\n        Parameters:\\n        - tokens: Input tokens with shape [batch, sequence_len, hidden_dim].\\n        - context: Context information with shape [batch, context_seq_len, context_dim].\\n                   If self_attn is True, context is ignored.\\n\\n        Returns:\\n        - ctx_vecs: Context vectors after attention with shape [batch, sequence_len, embed_dim].\\n        \"\"\"\\n\\n        if self.self_attn:\\n            # Self-attention case\\n            Q = self.query(tokens)\\n            K = self.key(tokens)\\n            V = self.value(tokens)\\n        else:\\n            # Cross-attention case\\n            Q = self.query(tokens)\\n            K = self.key(context)\\n            V = self.value(context)\\n\\n        # Compute score matrices, attention matrices, and context vectors\\n        scoremats = torch.einsum(\"BTH,BSH->BTS\", Q, K)  # Inner product of Q and K, a tensor\\n        attnmats = F.softmax(scoremats / math.sqrt(self.embed_dim), dim=-1)  # Softmax of scoremats\\n        ctx_vecs = torch.einsum(\"BTS,BSH->BTH\", attnmats, V)  # Weighted average value vectors by attnmats\\n\\n        return ctx_vecs\\n\\nThe CrossAttention class is a module designed for handling attention mechanisms in neural networks. It takes input tokens and, optionally, context information. If used for self-attention, it focuses on relationships within the input tokens. In the case of cross-attention, it considers the interaction between input tokens and context information. The module employs linear projections for query, key, and value transformations. It calculates score matrices, applies softmax for attention weights, and computes context vectors by combining the weighted values based on attention weights. This mechanism allows the network to selectively focus on different parts of the input or context, aiding in capturing relevant information during the learning process. The forward method implements these operations, returning context vectors after attention.\\n\\nLet’s proceed to the second attention layer, known as TransformerBlock.\\n\\nclass TransformerBlock(nn.Module):\\n    \"\"\"The transformer block that combines self-attn, cross-attn, and feed forward neural net\"\"\"\\n    def __init__(self, hidden_dim, context_dim):\\n        \"\"\"\\n        Initialize the TransformerBlock.\\n\\n        Parameters:\\n        - hidden_dim: The dimensionality of the hidden state.\\n        - context_dim: The dimensionality of the context tensor.\\n\\n        Note: For simplicity, the self-attn and cross-attn use the same hidden_dim.\\n        \"\"\"\\n\\n        super(TransformerBlock, self).__init__()\\n\\n        # Self-attention module\\n        self.attn_self = CrossAttention(hidden_dim, hidden_dim)\\n\\n        # Cross-attention module\\n        self.attn_cross = CrossAttention(hidden_dim, hidden_dim, context_dim)\\n\\n        # Layer normalization modules\\n        self.norm1 = nn.LayerNorm(hidden_dim)\\n        self.norm2 = nn.LayerNorm(hidden_dim)\\n        self.norm3 = nn.LayerNorm(hidden_dim)\\n\\n        # Implement a 2-layer MLP with K * hidden_dim hidden units, and nn.GELU nonlinearity\\n        self.ffn = nn.Sequential(\\n            nn.Linear(hidden_dim, 3 * hidden_dim),\\n            nn.GELU(),\\n            nn.Linear(3 * hidden_dim, hidden_dim)\\n        )\\n\\n    def forward(self, x, context=None):\\n        \"\"\"\\n        Forward pass of the TransformerBlock.\\n\\n        Parameters:\\n        - x: Input tensor with shape [batch, sequence_len, hidden_dim].\\n        - context: Context tensor with shape [batch, context_seq_len, context_dim].\\n\\n        Returns:\\n        - x: Output tensor after passing through the TransformerBlock.\\n        \"\"\"\\n\\n        # Apply self-attention with layer normalization and residual connection\\n        x = self.attn_self(self.norm1(x)) + x\\n\\n        # Apply cross-attention with layer normalization and residual connection\\n        x = self.attn_cross(self.norm2(x), context=context) + x\\n\\n        # Apply feed forward neural network with layer normalization and residual connection\\n        x = self.ffn(self.norm3(x)) + x\\n\\n        return x\\n\\nThe TransformerBlock class represents a building block in a transformer model, incorporating self-attention, cross-attention, and a feed-forward neural network. It takes input tensors with shape [batch, sequence_len, hidden_dim] and, optionally, a context tensor with shape [batch, context_seq_len, context_dim]. The self-attention and cross-attention modules are followed by layer normalization and a residual connection. Additionally, the block includes a two-layer MLP with a GELU nonlinearity for further non-linear transformations. The output is obtained after passing through the TransformerBlock.\\n\\nLet’s proceed to the final attention layer, known as SpatialTransformer.\\n\\nclass SpatialTransformer(nn.Module):\\n    def __init__(self, hidden_dim, context_dim):\\n        \"\"\"\\n        Initialize the SpatialTransformer.\\n\\n        Parameters:\\n        - hidden_dim: The dimensionality of the hidden state.\\n        - context_dim: The dimensionality of the context tensor.\\n        \"\"\"\\n        super(SpatialTransformer, self).__init__()\\n        \\n        # TransformerBlock for spatial transformation\\n        self.transformer = TransformerBlock(hidden_dim, context_dim)\\n\\n    def forward(self, x, context=None):\\n        \"\"\"\\n        Forward pass of the SpatialTransformer.\\n\\n        Parameters:\\n        - x: Input tensor with shape [batch, channels, height, width].\\n        - context: Context tensor with shape [batch, context_seq_len, context_dim].\\n\\n        Returns:\\n        - x: Output tensor after applying spatial transformation.\\n        \"\"\"\\n        b, c, h, w = x.shape\\n        x_in = x\\n\\n        # Combine the spatial dimensions and move the channel dimension to the end\\n        x = rearrange(x, \"b c h w -> b (h w) c\")\\n\\n        # Apply the sequence transformer\\n        x = self.transformer(x, context)\\n\\n        # Reverse the process\\n        x = rearrange(x, \\'b (h w) c -> b c h w\\', h=h, w=w)\\n\\n        # Residue connection\\n        return x + x_in\\n\\nNow, you can incorporate SpatialTransformer layers into our U-Net architecture.\\n\\nCoding the U-Net Architecture with Spatial Transformer\\n\\nWe’re going to code our U-Net architecture using the attention layers created in the previous step.\\n\\nclass UNet_Tranformer(nn.Module):\\n    \"\"\"A time-dependent score-based model built upon U-Net architecture.\"\"\"\\n\\n    def __init__(self, marginal_prob_std, channels=[32, 64, 128, 256], embed_dim=256,\\n                 text_dim=256, nClass=10):\\n        \"\"\"\\n        Initialize a time-dependent score-based network.\\n\\n        Parameters:\\n        - marginal_prob_std: A function that takes time t and gives the standard deviation\\n          of the perturbation kernel p_{0t}(x(t) | x(0)).\\n        - channels: The number of channels for feature maps of each resolution.\\n        - embed_dim: The dimensionality of Gaussian random feature embeddings of time.\\n        - text_dim: The embedding dimension of text/digits.\\n        - nClass: Number of classes to model.\\n        \"\"\"\\n        super().__init__()\\n\\n        # Gaussian random feature embedding layer for time\\n        self.time_embed = nn.Sequential(\\n            GaussianFourierProjection(embed_dim=embed_dim),\\n            nn.Linear(embed_dim, embed_dim)\\n        )\\n\\n        # Encoding layers where the resolution decreases\\n        self.conv1 = nn.Conv2d(1, channels[0], 3, stride=1, bias=False)\\n        self.dense1 = Dense(embed_dim, channels[0])\\n        self.gnorm1 = nn.GroupNorm(4, num_channels=channels[0])\\n\\n        self.conv2 = nn.Conv2d(channels[0], channels[1], 3, stride=2, bias=False)\\n        self.dense2 = Dense(embed_dim, channels[1])\\n        self.gnorm2 = nn.GroupNorm(32, num_channels=channels[1])\\n\\n        self.conv3 = nn.Conv2d(channels[1], channels[2], 3, stride=2, bias=False)\\n        self.dense3 = Dense(embed_dim, channels[2])\\n        self.gnorm3 = nn.GroupNorm(32, num_channels=channels[2])\\n        self.attn3 = SpatialTransformer(channels[2], text_dim)\\n\\n        self.conv4 = nn.Conv2d(channels[2], channels[3], 3, stride=2, bias=False)\\n        self.dense4 = Dense(embed_dim, channels[3])\\n        self.gnorm4 = nn.GroupNorm(32, num_channels=channels[3])\\n        self.attn4 = SpatialTransformer(channels[3], text_dim)\\n\\n        # Decoding layers where the resolution increases\\n        self.tconv4 = nn.ConvTranspose2d(channels[3], channels[2], 3, stride=2, bias=False)\\n        self.dense5 = Dense(embed_dim, channels[2])\\n        self.tgnorm4 = nn.GroupNorm(32, num_channels=channels[2])\\n\\n        self.tconv3 = nn.ConvTranspose2d(channels[2], channels[1], 3, stride=2, bias=False, output_padding=1)\\n        self.dense6 = Dense(embed_dim, channels[1])\\n        self.tgnorm3 = nn.GroupNorm(32, num_channels=channels[1])\\n\\n        self.tconv2 = nn.ConvTranspose2d(channels[1], channels[0], 3, stride=2, bias=False, output_padding=1)\\n        self.dense7 = Dense(embed_dim, channels[0])\\n        self.tgnorm2 = nn.GroupNorm(32, num_channels=channels[0])\\n        self.tconv1 = nn.ConvTranspose2d(channels[0], 1, 3, stride=1)\\n\\n        # The swish activation function\\n        self.act = nn.SiLU()\\n        self.marginal_prob_std = marginal_prob_std\\n        self.cond_embed = nn.Embedding(nClass, text_dim)\\n\\n    def forward(self, x, t, y=None):\\n        \"\"\"\\n        Forward pass of the UNet_Transformer model.\\n\\n        Parameters:\\n        - x: Input tensor.\\n        - t: Time tensor.\\n        - y: Target tensor.\\n\\n        Returns:\\n        - h: Output tensor after passing through the UNet_Transformer architecture.\\n        \"\"\"\\n        # Obtain the Gaussian random feature embedding for t\\n        embed = self.act(self.time_embed(t))\\n        y_embed = self.cond_embed(y).unsqueeze(1)\\n\\n        # Encoding path\\n        h1 = self.conv1(x) + self.dense1(embed)\\n        h1 = self.act(self.gnorm1(h1))\\n        h2 = self.conv2(h1) + self.dense2(embed)\\n        h2 = self.act(self.gnorm2(h2))\\n        h3 = self.conv3(h2) + self.dense3(embed)\\n        h3 = self.act(self.gnorm3(h3))\\n        h3 = self.attn3(h3, y_embed)\\n        h4 = self.conv4(h3) + self.dense4(embed)\\n        h4 = self.act(self.gnorm4(h4))\\n        h4 = self.attn4(h4, y_embed)\\n\\n        # Decoding path\\n        h = self.tconv4(h4) + self.dense5(embed)\\n        h = self.act(self.tgnorm4(h))\\n        h = self.tconv3(h + h3) + self.dense6(embed)\\n        h = self.act(self.tgnorm3(h))\\n        h = self.tconv2(h + h2) + self.dense7(embed)\\n        h = self.act(self.tgnorm2(h))\\n        h = self.tconv1(h + h1)\\n\\n        # Normalize output\\n        h = h / self.marginal_prob_std(t)[:, None, None, None]\\n        return h\\n\\nNow that we’ve implemented the U-Net architecture with attention layers, it’s time to update our loss function.\\n\\nUpdating U-Net Loss with Denoising Condition\\n\\nLet’s update the loss function by incorporating the y information during training.\\n\\ndef loss_fn_cond(model, x, y, marginal_prob_std, eps=1e-5):\\n    \"\"\"The loss function for training score-based generative models with conditional information.\\n\\n    Parameters:\\n    - model: A PyTorch model instance that represents a time-dependent score-based model.\\n    - x: A mini-batch of training data.\\n    - y: Conditional information (target tensor).\\n    - marginal_prob_std: A function that gives the standard deviation of the perturbation kernel.\\n    - eps: A tolerance value for numerical stability.\\n\\n    Returns:\\n    - loss: The calculated loss.\\n    \"\"\"\\n    # Sample time uniformly in the range [eps, 1-eps]\\n    random_t = torch.rand(x.shape[0], device=x.device) * (1. - eps) + eps\\n    # Generate random noise with the same shape as the input\\n    z = torch.randn_like(x)\\n    # Compute the standard deviation of the perturbation kernel at the sampled time\\n    std = marginal_prob_std(random_t)\\n    # Perturb the input data with the generated noise and scaled by the standard deviation\\n    perturbed_x = x + z * std[:, None, None, None]\\n    # Get the model\\'s score for the perturbed input, considering conditional information\\n    score = model(perturbed_x, random_t, y=y)\\n    # Calculate the loss using the score and perturbation\\n    loss = torch.mean(torch.sum((score * std[:, None, None, None] + z)**2, dim=(1, 2, 3)))\\n    return loss\\n\\nThis updated loss function calculates the loss for training generative models with added conditions. It involves sampling time, generating noise, perturbing the input data, and computing the loss based on the model’s score and perturbation.\\n\\nTraining U-Net Architecture With Attention Layers\\n\\nThe advantage of training the U-Net architecture based on the attention layer is that, once trained, we can provide a specific number for our stable diffusion model to draw. Let’s initiate the training process with the following hyperparameters: 100 epochs, a mini-batch size of 1024, and a learning rate of 10e-3. The training will be performed using the MNIST dataset.\\n\\n# Specify whether to continue training or initialize a new model\\n\\ncontinue_training = False # Either True or False\\n\\nif not continue_training:\\n    \\n    # Initialize a new UNet with Transformer model\\n    score_model = torch.nn.DataParallel(UNet_Tranformer(marginal_prob_std=marginal_prob_std_fn))\\n    score_model = score_model.to(device)\\n\\n# Set training hyperparameters\\nn_epochs =   100   #{\\'type\\':\\'integer\\'}\\nbatch_size =  1024 #{\\'type\\':\\'integer\\'}\\nlr = 10e-4         #{\\'type\\':\\'number\\'}\\n\\n# Load the MNIST dataset and create a data loader\\ndataset = MNIST(\\'.\\', train=True, transform=transforms.ToTensor(), download=True)\\ndata_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=4)\\n\\n# Define the optimizer and learning rate scheduler\\noptimizer = Adam(score_model.parameters(), lr=lr)\\nscheduler = LambdaLR(optimizer, lr_lambda=lambda epoch: max(0.2, 0.98 ** epoch))\\n\\n# Use tqdm to display a progress bar over epochs\\ntqdm_epoch = trange(n_epochs)\\nfor epoch in tqdm_epoch:\\n    avg_loss = 0.\\n    num_items = 0\\n\\n    # Iterate over batches in the data loader\\n    for x, y in tqdm(data_loader):\\n        x = x.to(device)\\n\\n        # Compute the loss using the conditional score-based model\\n        loss = loss_fn_cond(score_model, x, y, marginal_prob_std_fn)\\n        optimizer.zero_grad()\\n        loss.backward()\\n        optimizer.step()\\n        avg_loss += loss.item() * x.shape[0]\\n        num_items += x.shape[0]\\n\\n    # Adjust learning rate using the scheduler\\n    scheduler.step()\\n    lr_current = scheduler.get_last_lr()[0]\\n\\n    # Print epoch information including average loss and current learning rate\\n    print(\\'{} Average Loss: {:5f} lr {:.1e}\\'.format(epoch, avg_loss / num_items, lr_current))\\n    tqdm_epoch.set_description(\\'Average Loss: {:5f}\\'.format(avg_loss / num_items))\\n\\n    # Save the model checkpoint after each epoch of training\\n    torch.save(score_model.state_dict(), \\'ckpt_transformer.pth\\')\\n\\nUpon executing the training code, the entire training process is expected to complete in approximately 20 minutes. The average loss observed across epochs is 21.413, and the trained model will be saved in the current directory with the filename \"ckpt_transformer.pth\".\\n\\nGenerating Images\\n\\nNow, with the addition of conditional generation through attention layers, we can instruct our stable diffusion model to draw any digit. Let’s observe its outcome when tasked to draw the digit 9.\\n\\n## Load the pre-trained checkpoint from disk.\\n# device = \\'cuda\\' #@param [\\'cuda\\', \\'cpu\\'] {\\'type\\':\\'string\\'}\\nckpt = torch.load(\\'ckpt_transformer.pth\\', map_location=device)\\nscore_model.load_state_dict(ckpt)\\n\\n\\n########### Specify the digit for which to generate samples\\n###########\\ndigit = 9 #@param {\\'type\\':\\'integer\\'}\\n###########\\n###########\\n\\n\\n\\n# Set the batch size for generating samples\\nsample_batch_size = 64 #@param {\\'type\\':\\'integer\\'}\\n# Set the number of steps for the Euler-Maruyama sampler\\nnum_steps = 250 #@param {\\'type\\':\\'integer\\'}\\n# Choose the sampler type (Euler-Maruyama, pc_sampler, ode_sampler)\\nsampler = Euler_Maruyama_sampler #@param [\\'Euler_Maruyama_sampler\\', \\'pc_sampler\\', \\'ode_sampler\\'] {\\'type\\': \\'raw\\'}\\n# score_model.eval()\\n\\n## Generate samples using the specified sampler.\\nsamples = sampler(score_model,\\n        marginal_prob_std_fn,\\n        diffusion_coeff_fn,\\n        sample_batch_size,\\n        num_steps=num_steps,\\n        device=device,\\n        y=digit*torch.ones(sample_batch_size, dtype=torch.long))\\n\\n## Sample visualization.\\nsamples = samples.clamp(0.0, 1.0)\\n%matplotlib inline\\nimport matplotlib.pyplot as plt\\n# Create a grid of samples for visualization\\nsample_grid = make_grid(samples, nrow=int(np.sqrt(sample_batch_size)))\\n\\n# Plot the generated samples\\nplt.figure(figsize=(6,6))\\nplt.axis(\\'off\\')\\nplt.imshow(sample_grid.permute(1, 2, 0).cpu(), vmin=0., vmax=1.)\\nplt.show()\\n\\nGenerating 9 Number from our stable diffusion\\n\\nHere is the visualization of all the digits generated by our stable diffusion architecture.\\n\\nGenerating 0–9 Number from our stable diffusion\\n\\nWhat’s Next\\n\\nWe trained the stable diffusion architecture on the MNIST dataset, which is relatively small. You can experiment with training the same architecture on the CelebA dataset with slight modifications. I attempted it, but it crashed the Colab GPU, indicating that even a modest stable diffusion model demands substantial computational power. Alternatively, you can explore finetuning existing open-source versions of Stable Diffusion.\\n\\nI hope this provides you with a solid grasp of the practical implementation of stable diffusion. Check out my other blogs for further insights:\\n\\nSolving Transformer by Hand: A Step-by-Step Math Example\\nPerforming numerous matrix multiplications to solve the encoder and decoder parts of the transformerlevelup.gitconnected.com\\n\\nBuilding a Million-Parameter LLM from Scratch Using Python\\nA Step-by-Step Guide to Replicating LLaMA Architecturelevelup.gitconnected.com'}},\n",
       "  {'id': 'c26d08a55809',\n",
       "   'title': 'Building Powerful NLP Library in Python for 2024',\n",
       "   'subtitle': 'How Gemini by Google has transformed NLP tasks',\n",
       "   'author': 'b856005e5ecd',\n",
       "   'publication_id': '5517fd7b58a6',\n",
       "   'published_at': '2023-12-28 22:13:24',\n",
       "   'last_modified_at': '2024-01-01 09:32:00',\n",
       "   'tags': ['nlp',\n",
       "    'python',\n",
       "    'data-science',\n",
       "    'machine-learning',\n",
       "    'deep-learning'],\n",
       "   'topics': ['machine-learning', 'programming'],\n",
       "   'claps': 585,\n",
       "   'voters': 98,\n",
       "   'word_count': 3475,\n",
       "   'responses_count': 4,\n",
       "   'reading_time': 13.81320754716981,\n",
       "   'url': 'https://levelup.gitconnected.com/how-i-created-the-most-powerful-nlp-library-in-python-c26d08a55809',\n",
       "   'unique_slug': 'how-i-created-the-most-powerful-nlp-library-in-python-c26d08a55809',\n",
       "   'image_url': 'https://miro.medium.com/1*iW0G158ttjCvYxJd1aFWwg.png',\n",
       "   'lang': 'en',\n",
       "   'is_series': False,\n",
       "   'is_locked': False,\n",
       "   'is_shortform': False,\n",
       "   'top_highlight': '',\n",
       "   'content': {'id': 'c26d08a55809',\n",
       "    'content': 'Building Powerful NLP Library in Python for 2024\\n\\nConsider one of the most stressful scenarios that most coders face, dealing with large text data that requires cleaning. When using regex, you need to define different sets of patterns to remove text, and even then, you may not be sure if there is any new garbage data that needs removal. Tasks like these can be stressful for developers because of the time and effort they have to invest, and there’s still uncertainty about whether the new data requires the same procedural coding or not.\\n\\nThe recent trends of Large Language Models (LLMs), whether open source or closed source, have given us a new dimension of how text data can be handled. Since LLMs can analyze text data more quickly than us and can intelligently understand data to a considerable extent, similar to the way we understand it, why don’t we perform our NLP tasks using LLMs? This could automate the process and make the coder’s life less stressful.\\n\\nThe Core Concept Driving My Library\\n\\nI tried out several open-source LLMs like Mistral 8x7b or LLAMA-2–70b-chat-hf, but they never met my expectations. Although good for question answering and text generation, they fall short when it comes to NLP tasks. On the other hand, ChatGPT exceeded my expectations, but it requires a paid API access to perform NLP tasks on our custom dataset. Gemini, as capable as GPT-4, provides a free API with limited access. I tested it with the help of prompt engineering and found that it can solve almost any NLP task you want to tackle.\\n\\nHere is a simple visual illustration of how I have used Gemini multi-model to perform NLP tasks on my dataset:\\n\\nVisual illustration of how my library works ( Created using FIGMA )\\n\\nThis concept can be used by yourself, allowing you to create your own NLP library to improve your productivity. Highlighting all the features of my library here would make the blog lengthy. You can find my GitHub repository that contains detailed information about each task and its usage. However, this blog will focus on the most important features, how to use them, and how to include your own customized NLP tasks.\\n\\nGitHub - FareedKhan-dev/Most-powerful-NLP-library: Gemini, as capable as GPT-4, provides a free API…\\nGemini, as capable as GPT-4, provides a free API with limited access. I tested it with the help of prompt engineering…github.com\\n\\nTable of Contents\\n\\nInstalling the Library\\n\\nUnderstanding File Structure\\n\\nInitiating the Library\\n\\nCleaning the Text\\n\\nPerform Lemmatization or Stemming\\n\\nSimplifying NER Detection and POS Tagging\\n\\nText Pattern Matching\\n\\nText Classification\\n\\nSemantic Role Labeling (SRL)\\n\\nIntent Recognition\\n\\nHandling Large Data\\n\\nCustomizing the Library\\n\\nWhat’s Next\\n\\nInstalling the Library\\n\\nFirst, you need to clone my GitHub repository.\\n\\ngit clone https://github.com/FareedKhan-dev/Most-powerful-NLP-library.git\\n\\nIf you don’t have Git installed on your machine, you can download the repository as a ZIP file.\\n\\ndownload repository as zip file from github link\\n\\nOnce you have cloned the repository, you need to install the required dependencies that allow you to work with the Gemini API.\\n\\n# Install the Google Generative AI library\\npip install -q -U google-generativeai\\n\\nUnderstanding File Structure\\n\\nYou can skip this step as it is for later use only if you want to understand the library and how it works. Here is the file structure of this library.\\n\\nmain_directory/\\n|-- for_beginner/\\n|   |-- preprocessing.ipynb\\n|   |-- core_nlp.ipynb\\n|-- pre_processing.py\\n|-- core_nlp.py\\n|-- code_file.ipyb  # Containing example of each function\\n\\nA \"for_beginner\" folder containing two Jupyter notebook files with code blocks for each NLP task that will make it easier for you to understand how this library is working. While both Python files are going to be used to call as modules and use them for your requested task.\\n\\npre_processing.py contains functions that are used for preprocessing our text, such as clean_text, remove_html_tags, etc., while core_nlp contains functions that are useful for handling text data and performing different tasks, such as summarize_text, translate_text, etc.\\n\\nInitiating the Library\\n\\nIn the previous step, we installed the required dependencies and cloned our NLP library. Now, we need to import the necessary library that will fetch Gemini LLM API calls and instantiate the required API key.\\n\\n# Import the Google Generative AI library\\nimport google.generativeai as genai\\n\\n# Initialize the GenerativeModel with \\'gemini-pro\\'\\nmodel = genai.GenerativeModel(\\'gemini-pro\\')\\n\\n# Configure the library with your API key\\ngenai.configure(api_key=\"Your-API-key\")\\n\\nYou can obtain your API key from here. Once you have the key, proceed to the next step.\\n\\nCleaning the Text\\n\\nOne of the initial and most frustrating steps while handling text data is to clean it. While regex is a powerful way to clean text, here is what an LLM-based library can do.\\n\\n# Import the clean_text function from the pre_processing module\\nfrom pre_processing import clean_text\\n\\n# User input text\\nuser_input = \\'\\'\\'faree$$@$%d khan will arrive at 9:00 AM. \\n                He will@%$ 1meet you at the airport. \\n                He will be driving a black BMW. \\n                His license plate is 123-456-7890.\\'\\'\\'\\n\\n# Clean the text using the specified model\\ncleaned_text = clean_text(user_input, model)\\n\\n# Print the cleaned text\\nprint(cleaned_text)\\n\\n##### OUTPUT OF ABOVE CODE #####\\n\\nFareed Khan will arrive at 9:00 AM. He will meet you at the airport. \\nHe will be driving a black BMW. His license plate is 123-456-7890.\\n\\n##### OUTPUT OF ABOVE CODE #####\\n\\nWe imported the function from our pre_processing.py module for cleaning our text. clean_text takes two inputs: the text that you have to clean and the model that you created earlier during the library initiation step. With a little bit of prompt engineering behind this function, our LLM can easily understand what should be removed from the input.\\n\\nPerform Lemmatization or Stemming\\n\\nLemmatization and stemming are tricky in NLP because words come in different forms and meanings. Deciding the base or root of a word can be hard, especially with irregular words and various contexts.\\n\\nMultiple libraries, like NLTK, can be used for tasks like lemmatization and stemming, but they often lack the effectiveness of an LLM approach. LLMs, trained on extensive datasets, outperform traditional libraries in capturing language nuances and providing more accurate results.\\n\\n# Import the lemmatize_text and stem_text functions from the pre_processing module\\nfrom pre_processing import lemmatize_text, stem_text\\n\\n# User input text\\nuser_input = \\'\\'\\'The cats are running and playing in the gardens, \\n                while the dogs are barking loudly and chasing their tails\\'\\'\\'\\n\\n# Lemmatize the text using the specified model\\nlemmatized_sentence = lemmatize_text(user_input, model)\\n\\n# Stem the text using the specified model\\nstemmed_sentence = stem_text(user_input, model)\\n\\n# Print the lemmatized and stemmed sentences\\nprint(lemmatized_sentence)\\nprint(stemmed_sentence)\\n\\n##### OUTPUT OF Lemmatized Sentence #####\\n\\nThe cat be run and play in the garden, \\nwhile the dog be bark loud and chase their tail\\n\\n##### OUTPUT OF Stemmed Sentence #####\\n\\nthe cat ar run and play in the garden, \\nwhil the dog ar bark loud and chas their tail\\n\\nBoth our lemmatizing and stemming functions take two inputs: the text you want to process and the model you initiated earlier. Unlike NLTK, our functions come in handy when working with different languages that may not be supported by NLTK.\\n\\nSimplifying NER Detection and POS Tagging\\n\\nNER in NLP is challenging because figuring out where entities start and end can be unclear, and entities often appear in different ways. Also, there are many types of entities, and the task gets even harder when dealing with new or changing entities. On the hand, LLMs work well for NER detection because they learn detailed patterns and context, making them good at recognizing different named entities using their vast training data.\\n\\n# Import the detect_ner function from the core_nlp module\\nfrom core_nlp import detect_ner\\n\\n# User input text\\nuser_input = \"I will meet you at the airport sharp 12:00 AM.\"\\n\\n# Specify NER tags (optional, default includes \\'person, location, date, number, ...\\')\\nner_tags = \\'person, location, date, number, ... cardinal\\'\\n\\n# Detect named entities in the text using the specified model and NER tags\\nner_result = detect_ner(input_text=user_input, ner_tags=ner_tags, model=model)\\n\\n# Print the NER result\\nprint(ner_result)\\n\\n##### OUTPUT OF ABOVE CODE #####\\n\\nairport: facility\\n12:00 AM: time\\n\\n##### OUTPUT OF ABOVE CODE #####\\n\\nThis function requires three inputs: the text for which you need NER tags, the ner_tags specifying the types of entities to extract (with default values like name, organization, etc.), and the model initiated at the beginning. With zero-shot prompt engineering, there\\'s no need to provide specific examples behind the function. Just provide a bit of detail in the prompt, and our function outputs the relevant ner_tags detected in the input.\\n\\nSimilarly, POS tagging is challenging in NLP as it involves distinguishing between word classes, and certain words may serve multiple grammatical functions based on context. Managing slang, informal language, or domain-specific terms adds complexity to accurately assigning part-of-speech tags.\\n\\n# Import the detect_pos function from the core_nlp module\\nfrom core_nlp import detect_pos\\n\\n# User input text\\nuser_input = \"I will meet you at the airport sharp 12:00 AM.\"\\n\\n# Specify POS tags (optional, default includes \\'NOUN, verb, adjective, adverb, ...\\')\\npos_tags = \\'noun, verb, adjective, adverb, pronoun, ... entity_phrase\\'\\n\\n# Detect part-of-speech in the text using the specified model and POS tags\\npos_result = detect_pos(input_text=user_input, pos_tags=pos_tags, model=model)\\n\\n# Print the POS result\\nprint(pos_result)\\n\\n##### OUTPUT OF ABOVE CODE #####\\n\\nI: pronoun\\nwill: verb\\nmeet: verb\\nyou: pronoun\\nat: preposition\\nthe: determiner\\nairport: noun\\nsharp: adverb\\n12:00: time\\nAM: time\\n.: punctuation\\n\\n##### OUTPUT OF ABOVE CODE #####\\n\\nThis function also takes three inputs, as you may have already seen in the code. An important point to note is that the default POS tags are approximately more than 50, which is sufficient for a detailed extraction of words based on them. However, if you need a new tag not present in the default values, you can add it for easier implementation based on your specific case.\\n\\nText Pattern Matching\\n\\nWhen extracting patterns like emails or numbers from text data, defining patterns using regex or other libraries is a common approach. However, the LLM has a significant advantage due to its training on large text data. Unlike regex, you just need to name the pattern you want to extract, such as email or phone number, making it more convenient.\\n\\n# Import the extract_patterns function from the pre_processing module\\nfrom pre_processing import extract_patterns\\n\\n# User input text\\nuser_input = \\'\\'\\'The phone number of fareed khan is 123-456-7890 and 523-456-7892. Please call for assistance and email me at x123@gmail.com\\'\\'\\'\\n\\n# Define patterns for extraction\\npattern_matching = \\'\\'\\'email, phone number, name\\'\\'\\'\\n\\n# Extract patterns from the input text using the specified model and patterns\\nextracted_patterns = extract_patterns(user_input, pattern_matching, model)\\n\\n# Print the extracted patterns\\nprint(extracted_patterns)\\n\\n##### OUTPUT OF ABOVE CODE #####\\n\\ntype: python list\\n\\n[\\'123-456-7890\\', \\'523-456-7892\\', \\'x123@gmail.com\\', \\'fareed khan\\']\\n\\n##### OUTPUT OF ABOVE CODE #####\\n\\nWhile extracting emails and phone numbers may not pose significant challenges, patterns like disease codes or license plates may require additional effort. Defining regex patterns for such cases can be uncertain for new data. In extract_patterns function, you only need to provide comma-separated patterns you want to identify, and Gemini will handle the rest of the effort for you.\\n\\nAlthough there are many text preprocessing features that I have created in this library, I recommend visiting my GitHub repository to explore the full list of functionalities I have introduced.\\n\\nText Classification\\n\\nI have introduced three features for text classification tasks:\\n\\nSentiment Analysis\\n\\nTopic Classification\\n\\nSpam Detection\\n\\nSentiment analysis, by default, includes three main categories: positive, neutral, and negative. However, you have the flexibility to specify more detailed categories based on your preferences.\\n\\n# Import the analyze_sentiment function from the core_nlp module\\nfrom core_nlp import analyze_sentiment\\n\\n# User input text\\nuser_input = \"I love to play football, but today I am feeling very sad. I do not want to play football today.\"\\n\\n# Specify sentiment categories (optional, default includes \\'positive, negative, neutral\\')\\ncategory = \"positive, negative, neutral\"\\n\\n# Analyze sentiment in the text using the specified model and sentiment categories\\nsentiment_result = analyze_sentiment(input_text=user_input, category=category, explanation=True, model=model)\\n\\n# Print the sentiment result\\nprint(sentiment_result)\\n\\n##### OUTPUT OF ABOVE CODE #####\\n\\nCategory: Negative\\n\\nShort Explanation:\\nThe overall sentiment of the text is negative. \\nThe author expresses a love for football but then \\ngoes on to say that they are feeling very sad and \\ndo not want to play football today. This indicates \\na negative sentiment towards the activity of playing football.\\n\\n##### OUTPUT OF ABOVE CODE #####\\n\\nYou can customize the category based on your preferences and also set the explanation parameter to TRUE or FALSE depending on whether you want an explanation for the answer. The rest of the input parameters remain the same, similar to other functions.\\n\\nFor topic classification, you need to set the topics yourself. The explanation parameter is used to justify the answer and explain why it fits into a particular topic category.\\n\\n# Import the classify_topic function from the core_nlp module\\nfrom core_nlp import classify_topic\\n\\n# User input text\\nuser_input = \"I love to play football, but today I am feeling very sad. I do not want to play football today.\"\\n\\n# Specify topics (optional, default includes \\'story, horror, comedy\\')\\ntopics = \"story, horror, comedy\"\\n\\n# Classify the topic of the text using the specified model and topics\\ntopic_result = classify_topic(input_text=user_input, topics=topics, explanation=True, model=model)\\n\\n# Print the topic result\\nprint(topic_result)\\n\\n##### OUTPUT OF ABOVE CODE #####\\n\\nCategory: Story\\n\\nShort Explanation:\\nThe input text is a story about a person who loves to play football \\nbut is feeling sad and does not want to play today. \\nThe text does not contain any elements of horror or comedy,\\nso the topic is classified as story.\\n\\n##### OUTPUT OF ABOVE CODE #####\\n\\nSimilarly, spam detection has three default categories: spam, not_spam, and unknown. It also includes an explanation parameter to justify why Gemini has chosen a particular category.\\n\\n# Import the detect_spam function from the core_nlp module\\nfrom core_nlp import detect_spam\\n\\n# User input text\\nuser_input = \"you have just won $14000, claim this award here at this link.\"\\n\\n# Specify spam categories (optional, default includes \\'spam, not_spam, unknown\\')\\ncategory = \\'spam, not_spam, unknown\\'\\n\\n# Detect spam in the text using the specified model and spam categories\\nspam_result = detect_spam(input_text=user_input, category=category, explanation=True, model=model)\\n\\n# Print the spam result\\nprint(spam_result)\\n\\n##### OUTPUT OF ABOVE CODE #####\\n\\nCategory: spam\\n\\nShort Explanation:\\nThe message contains the promise of a large monetary reward, \\nwhich is a classic tactic used by spammers to attract attention \\nand entice people to click on the link.\\n\\n##### OUTPUT OF ABOVE CODE #####\\n\\nIn all three text classification tasks, only topic classification requires you to define the topics you want to classify, whereas the rest of the tasks have default values commonly used for categorization.\\n\\nSemantic Role Labeling (SRL)\\n\\nFiguring out what words do in a sentence, known as Semantic Role Labeling (SRL), can be tough in NLP. It gets tricky due to sentence structures and the different jobs words can have based on what’s happening. Large language models (LLMs) are good at understanding these details, like who did what in a sentence.\\n\\n# Import the perform_srl function from the core_nlp module\\nfrom core_nlp import perform_srl\\n\\n# User input text\\nuser_input = \"tornado is approaching the city, please take shelter\"\\n\\n# Perform Semantic Role Labeling (SRL) on the text using the specified model\\nsrl_result = perform_srl(user_input, model)\\n\\n# Print the SRL result\\nprint(srl_result)\\n\\n##### OUTPUT OF ABOVE CODE #####\\n\\nPredicate: approach\\nRoles:\\n- Agent: tornado\\n- Theme: city\\n\\n##### OUTPUT OF ABOVE CODE #####\\n\\nIt identifies two important components: the predicate, which tells what the subject is doing or what the subject is, and roles, which contain agents and more. The function takes only two inputs: the text data and the model.\\n\\nIntent Recognition\\n\\nIntent recognition in NLP involves identifying the purpose or goal behind a user’s input, like understanding if they’re asking a question or making a request. This is crucial for enhancing user interactions with applications, as it enables systems to comprehend user intentions and respond appropriately, creating more effective and personalized user experiences.\\n\\n# Import the recognize_intent function from the core_nlp module\\nfrom core_nlp import recognize_intent\\n\\n# User input text\\nuser_input = \"tornado is approaching the city, please take shelter\"\\n\\n# Recognize intent in the text using the specified model\\nintent_result = recognize_intent(user_input, model)\\n\\n# Print the intent result\\nprint(intent_result)\\n\\n##### OUTPUT OF ABOVE CODE #####\\n\\nIntent: Emergency alert\\n\\n##### OUTPUT OF ABOVE CODE #####\\n\\nIt accurately identifies the intent behind the text, understanding the user’s input intention. This function takes the same two inputs as seen earlier: the text data and the model.\\n\\nHandling Large Data\\n\\nUp until now, we’ve worked with relatively small text data, like short sentences. If you need to handle larger text, while I haven’t implemented it yet, one approach is to break your text data into chunks and process it accordingly. Here’s an example of how to work with a bigger dataset.\\n\\n# Example text dataset\\ntext_dataset = \"some_big_text_file.txt\"\\n\\n# Break the text into sentences based on full stops\\nsentences = text_dataset.split(\\'. \\')\\n\\n# some ner_tags you have defined\\nner_tags = \"person, organization ...\"\\n\\n# Applying NER on it\\nfor i, sentence in enumerate(sentences):\\n    print(f\"Sentence {i + 1}:\")\\n    \\n    # Applying NER on each sentence\\n    detect_ner(input_text=sentence, ner_tags=ner_tags, model=model)\\n\\nAnother approach to handling larger data is to break it into more extensive chunks, for example, 500 sentences per chunk, to preserve dataset information. If you want to apply the text_summarization task, you can then provide the summaries of each chunk in a combined manner to generate one detailed summary for the entire text.\\n\\nVisual Illustration of how to handle large text data\\n\\nThere are several ways to handle big data, but the approaches I’ve just shared are among the most common and practical.\\n\\nCustomizing the Library\\n\\nCustomizing the library involves including your own functions, and a well-crafted prompt is essential for making your customized functions work. For instance, if you want to create a paraphrasing-checking function, you need to start with a prompt for the paraphrasing task.\\n\\n# Question to be asked for determining paraphrasing\\nquestion = f\\'\\'\\'Given the input text, determine if two sentences are paraphrases of each other.\\nSentence 1: {user_input[0]}\\nSentence 2: {user_input[1]}\\nAnswer must be \\'yes\\' or \\'no\\'.\\n{explanation}\\n\\'\\'\\'\\n\\nWhen creating a customized function, it’s crucial to explain the expected output from Gemini to maintain consistency across runs. Additionally, defining the answer format is essential; for instance, in tokenization, you may specify that the output format should be a list. To achieve this, you can later convert the string representation to an actual list using the ast Python library. In the paraphrasing task, the rest of the prompt remains relatively constant, with changes depending on how many sentences you want to input—I\\'ve considered two in this example.\\n\\nOnce you create your prompt, you can build a function on top of it.\\n\\n# function for paraphrase detection\\ndef paraphrasing_detection(input_text, explanation, model):\\n\\n    # Check if explanation is required\\n    explanation_text = \\'short explanation: \\' if explanation else \\'no explanation\\'\\n\\n    # Question to be asked for determining paraphrasing\\n    question = f\\'\\'\\'Given the input text, determine if two sentences are paraphrases of each other.\\n    Sentence 1: {input_text[0]}\\n    Sentence 2: {input_text[1]}\\n    Answer must be \\'yes\\' or \\'no\\'.\\n    {explanation_text}\\n    \\'\\'\\'\\n\\n    # Generate response\\n    response = model.generate_content(question)\\n    return response.text.strip()\\n\\nYou can easily call that function on top of your text data.\\n\\n# Import the paraphrasing_detection function from the core_nlp module\\nfrom core_nlp import paraphrasing_detection\\n\\n# User input text\\nuser_input = [\\'\\'\\'The sun sets in the west every evening.\\'\\'\\', \\'\\'\\'Every evening, the sun goes down in the west.\\'\\'\\']\\n\\n# Perform paraphrasing detection using the specified model\\nintent_result = paraphrasing_detection(user_input, explanation=True, model=model)\\n\\n# Print the paraphrasing detection result\\nprint(intent_result)\\n\\n##### OUTPUT OF ABOVE CODE #####\\n\\nAnswer: yes\\nShort Explanation: Both sentences express the same idea that the sun \\nsets in the west  every evening. They use different words to convey \\nthe same meaning,  such as \"sets\" and \"goes down\" for the verb and \\n\"every evening\" for temporal modifier.\\n\\n##### OUTPUT OF ABOVE CODE #####\\n\\nWhat’s Next\\n\\nThere are many more features introduced in this library. This is just a glimpse of how LLMs reshape NLP tasks and simplify the handling of text data. Explore the full potential by checking out my GitHub repository, which includes features like generating embeddings for cosine similarity, text summarization, and more. Feel free to adapt the library for your specific domain, whether it’s medical or any other. I hope you enjoy reading this blog.\\n\\nIf you want to build your own LLM from scratch or understand the mathematical aspects of transformers, you can refer to my other blogs:\\n\\nSolving Transformer by Hand: A Step-by-Step Math Example\\nPerforming numerous matrix multiplications to solve the encoder and decoder parts of the transformerlevelup.gitconnected.com\\n\\nBuilding a Million-Parameter LLM from Scratch Using Python\\nA Step-by-Step Guide to Replicating LLaMA Architecturelevelup.gitconnected.com'}}],\n",
       " 'b0fbe613be9d': [{'id': 'c06edaa78534',\n",
       "   'title': 'Demonstrate, Search, Predict (DSP) for LLMs',\n",
       "   'subtitle': 'This study which is just over a year old from Stanford, makes for interesting reading and illustrates how far we have come over as short…',\n",
       "   'author': 'b0fbe613be9d',\n",
       "   'publication_id': '*Self-Published*',\n",
       "   'published_at': '2024-02-16 08:18:20',\n",
       "   'last_modified_at': '2024-02-16 08:18:20',\n",
       "   'tags': ['ai',\n",
       "    'artificial-intelligence',\n",
       "    'machine-learning',\n",
       "    'large-language-models',\n",
       "    'conversational-ai'],\n",
       "   'topics': ['machine-learning'],\n",
       "   'claps': 65,\n",
       "   'voters': 9,\n",
       "   'word_count': 873,\n",
       "   'responses_count': 1,\n",
       "   'reading_time': 4.494339622641509,\n",
       "   'url': 'https://cobusgreyling.medium.com/demonstrate-search-predict-dsp-for-llms-c06edaa78534',\n",
       "   'unique_slug': 'demonstrate-search-predict-dsp-for-llms-c06edaa78534',\n",
       "   'image_url': 'https://miro.medium.com/1*54LE60qrXqdvlPMJWLPYNg.png',\n",
       "   'lang': 'en',\n",
       "   'is_series': False,\n",
       "   'is_locked': False,\n",
       "   'is_shortform': False,\n",
       "   'top_highlight': '',\n",
       "   'content': {'id': 'c06edaa78534',\n",
       "    'content': 'Demonstrate, Search, Predict (DSP) for LLMs\\n\\nThis study which is just over a year old from Stanford, makes for interesting reading and illustrates how far we have come over as short period of time.\\n\\nIntroduction\\n\\nFirst of all, the study refers to what we now know as Large Language Models (LLMs), as Knowledge Intensive Natural Language Processing (NLP). Some refer to this as KI-NLP.\\n\\nDemonstrate, Search, Predict (DSP) is a program written for answering open-domain questions in a conversational setting and in a multi-hop fashion.\\n\\nThe study recognises that there are two main elements, a frozen language model (LLM) and a retrieval Model (RM).\\n\\nThe study also recognises the advantages of grounding knowledge, lower deployment overheads and annotation costs.\\n\\nTo get an idea how fast concepts and accepted architecture are developing, the study finds that in-context learning offers a new approach where we can create complex systems by assembling pre-trained components through natural language instructions and allowing them to interact.\\n\\nThis paradigm relies on pre-trained LLMs as building blocks and natural language for giving instructions and manipulating text.\\n\\nThe study continues to say that achieving this vision could democratise AI development, accelerate system prototyping for different domains, and leverage specialised pre-trained components more effectively.\\n\\nAnd have we not seen this democratisation in the number of prompting frameworks and tools. Together with the number of tools to perform vector embeddings and semantic search.\\n\\n\\n\\nDecomposition\\n\\nAn interesting component of the DSP approach is not only what we now know as RAG, but the idea of decomposing the query or prompt. The study refers to this process of decomposition as Multi-Hop; but again we know it today as Chain-of-Thought.\\n\\nIn fact, the notion of decomposition has taken on so many different permutations, that the phenomenon of Chain-of-X has seen the light.\\n\\nSource\\n\\nIn the image below, a simple example of DSP is shown, with the multiple questions.\\n\\nDemonstrate stage adds notes to training examples based on a simple form of teaching. Then, in the Search stage, the program breaks down the question and finds relevant information in two steps. Finally, in the Predict stage, it uses the notes and the found information to answer the question.\\n\\nSource\\n\\nAutonomous Agent Like\\n\\nThe study contains a notebook to run DSP…\\n\\nAs seen below, DSP needs to be installed…\\n\\n !pip install dspy-ai\\n\\nAnd below is an extract on how the LLM is instructed…\\n\\nFollow the following format.  \\n\\nContext: may contain relevant facts  \\n\\nQuestion: ${question}  \\n\\nReasoning: Let\\'s think step by step in order to ${produce the answer}. \\n\\nWe ...  \\n\\nAnswer: often between 1 and 5 words\\n\\nBelow is a snipped from the notebook and what I find interesting is how autonomous agent like the reasoning and response is.\\n\\n\\n\\nAnd below an example where the context, question, reasoning and answer are all populated.\\n\\nContext:\\n[1] «David Gregory (physician) | David Gregory (20 December 1625 – 1720) was a Scottish physician and inventor. His surname is sometimes spelt as Gregorie, the original Scottish spelling. He inherited Kinnairdy Castle in 1664. Three of his twenty-nine children became mathematics professors. He is credited with inventing a military cannon that Isaac Newton described as \"being destructive to the human species\". Copies and details of the model no longer exist. Gregory\\'s use of a barometer to predict farming-related weather conditions led him to be accused of witchcraft by Presbyterian ministers from Aberdeen, although he was never convicted.»\\n[2] «Gregory Tarchaneiotes | Gregory Tarchaneiotes (Greek: Γρηγόριος Ταρχανειώτης , Italian: \"Gregorio Tracanioto\" or \"Tracamoto\" ) was a \"protospatharius\" and the long-reigning catepan of Italy from 998 to 1006. In December 999, and again on February 2, 1002, he reinstituted and confirmed the possessions of the abbey and monks of Monte Cassino in Ascoli. In 1004, he fortified and expanded the castle of Dragonara on the Fortore. He gave it three circular towers and one square one. He also strengthened Lucera.»\\n[3] «David Gregory (mathematician) | David Gregory (originally spelt Gregorie) FRS (? 1659 – 10 October 1708) was a Scottish mathematician and astronomer. He was professor of mathematics at the University of Edinburgh, Savilian Professor of Astronomy at the University of Oxford, and a commentator on Isaac Newton\\'s \"Principia\".»\\n\\nQuestion: What castle did David Gregory inherit?\\n\\nReasoning: Let\\'s think step by step in order to produce the answer. We know that David Gregory inherited a castle. The name of the castle is Kinnairdy Castle.\\n\\nAnswer: Kinnairdy Castle\\n\\n⭐️ Follow me on LinkedIn for updates on Large Language Models ⭐️\\n\\n\\n\\nI’m currently the Chief Evangelist @ Kore AI. I explore & write about all things at the intersection of AI & language; ranging from LLMs, Chatbots, Voicebots, Development Frameworks, Data-Centric latent spaces & more.\\n\\n\\n\\nLinkedIn\\n\\n\\n\\nGet an email whenever Cobus Greyling publishes.\\nGet an email whenever Cobus Greyling publishes. By signing up, you will create a Medium account if you don’t already…cobusgreyling.medium.com\\n\\nGitHub - stanfordnlp/dspy: DSPy: The framework for programming-not prompting-foundation models\\nDSPy: The framework for programming-not prompting-foundation models - stanfordnlp/dspygithub.com\\n\\nDemonstrate-Search-Predict: Composing retrieval and language models for knowledge-intensive NLP\\nRetrieval-augmented in-context learning has emerged as a powerful approach for addressing knowledge-intensive tasks…arxiv.org\\n\\nGoogle Colaboratory\\nEdit descriptioncolab.research.google.com'}},\n",
       "  {'id': '9a5aaa01e437',\n",
       "   'title': 'T-RAG = RAG + Fine-Tuning + Entity Detection',\n",
       "   'subtitle': 'The T-RAG approach is premised on combining RAG architecture with an open-source fine-tuned LLM and an entities tree vector database. The…',\n",
       "   'author': 'b0fbe613be9d',\n",
       "   'publication_id': '*Self-Published*',\n",
       "   'published_at': '2024-02-15 09:08:22',\n",
       "   'last_modified_at': '2024-02-15 09:08:22',\n",
       "   'tags': ['ai',\n",
       "    'artificial-intelligence',\n",
       "    'large-language-models',\n",
       "    'machine-learning',\n",
       "    'conversational-ai'],\n",
       "   'topics': ['machine-learning', 'programming'],\n",
       "   'claps': 283,\n",
       "   'voters': 50,\n",
       "   'word_count': 874,\n",
       "   'responses_count': 2,\n",
       "   'reading_time': 4.34811320754717,\n",
       "   'url': 'https://cobusgreyling.medium.com/t-rag-rag-fine-tuning-entity-detection-9a5aaa01e437',\n",
       "   'unique_slug': 't-rag-rag-fine-tuning-entity-detection-9a5aaa01e437',\n",
       "   'image_url': 'https://miro.medium.com/1*1q3swfPylyxyN-BGOjwTrQ.png',\n",
       "   'lang': 'en',\n",
       "   'is_series': False,\n",
       "   'is_locked': False,\n",
       "   'is_shortform': False,\n",
       "   'top_highlight': 'Subsequently, this information is amalgamated with the document chunks retrieved from the vector database to construct the context.',\n",
       "   'content': {'id': '9a5aaa01e437',\n",
       "    'content': 'Source\\n\\nT-RAG = RAG + Fine-Tuning + Entity Detection\\n\\nThe T-RAG approach is premised on combining RAG architecture with an open-source fine-tuned LLM and an entities tree vector database. The focus is on contextual retrieval.\\n\\nIntroduction\\n\\nLarge Language Models (LLMs) are increasingly utilised across various domains, including question answering over private enterprise documents, where data security and robustness are paramount.\\n\\nRetrieval-Augmented Generation (RAG) is a prominent framework for building such applications, but ensuring its robustness requires extensive customisation.\\n\\nThis study shares experiences in deploying an LLM application for question answering over private organisational documents, using a system called Tree-RAG (T-RAG) that incorporates entity hierarchies for improved performance.\\n\\nEvaluations demonstrate the effectiveness of this approach, providing valuable insights for real-world LLM applications.\\n\\nData Privacy\\n\\nSecurity risks are a primary concern due to the sensitive nature of these documents, making it impractical to use proprietary LLM models over publich APIs, to avoid data leakage risks.\\n\\nThis calls for the use of open-source models that can be deployed on-premise.\\n\\nAdditionally, limited computational resources and smaller training datasets based on available documents present challenges.\\n\\nFurthermore, ensuring reliable and accurate responses to user queries adds complexity, necessitating extensive customisation and decision-making in deploying robust applications in such environments.\\n\\nTake-Aways\\n\\nWhat interested me in this study is that the researches develop an application that integrates Retrieval-Augmented Generation (RAG) with a fine-tuned open-source Large Language Model (LLM) for generating responses. This model is trained using an instruction dataset derived from the organisation’s documents.\\n\\nThey introduce a novel evaluation metric, termed Correct-Verbose, designed to assess the quality of generated responses. This metric evaluates responses based on their correctness while also considering the inclusion of additional relevant information beyond the scope of the original question.\\n\\nT-RAG\\n\\nBelow the workflow of Tree-RAG (T-RAG)…\\n\\nFor a given user query, the vector database is searched for the relevant document chunks, the chunk serves as the contextual reference for LLM in-context learning.\\n\\nIf the query mentions any organisational related entities, information regarding the entities is extracted from the entities tree and added to the context. The fine-tuned Llama-2 7B model generates a response from the presented data.\\n\\nSource\\n\\nA feature of T-RAG is the inclusion of an entities tree in addition to the vector database for context retrieval.\\n\\nEntities Tree\\n\\nOne distinguishing aspect of T-RAG is its incorporation of an entities tree alongside the vector database for context retrieval. The entities tree stores details regarding the organization’s entities and their hierarchical arrangement. Each node within this tree represents an entity, with parent nodes indicating their respective group memberships.\\n\\nDuring the retrieval process, the framework leverage the entities tree to enhance the context retrieved from the vector database.\\n\\nThe procedure for entity tree search and context generation unfolds as follows:\\n\\nInitially, a parser module scans the user query for keywords corresponding to entity names within the organisation.\\n\\nUpon identifying one or more matches, details regarding each matched entity are extracted from the tree.\\n\\nThese details are transformed into textual statements that furnish information about the entity and its position within the organisation’s hierarchy.\\n\\nSubsequently, this information is amalgamated with the document chunks retrieved from the vector database to construct the context.\\n\\nBy adopting this approach, the model gains access to pertinent information about entities and their hierarchical positioning within the organisation when users inquire about them.\\n\\nSource\\n\\nConsidering the image above, the retrieval process for context generation involves utilising an illustrative example from an organisational chart to demonstrate how tree search and retrieval are executed.\\n\\nIn addition to fetching contextual documents, a spaCy library is used with custom rules to identify named entities within the organisation.\\n\\nIf the query contains one or more such entities, relevant information regarding the entity’s hierarchical location is extracted from the tree and transformed into textual statements. These statements are then incorporated into the context along with the retrieved documents.\\n\\nHowever, if the user’s query does not mention any entities, the tree search is omitted, and only the context from the retrieved documents is utilised.\\n\\nIn Conclusion\\n\\nI found this study fascinating in the sense that it combines RAG and also fine-tuning. While making use of an open-sourced model hosted on premise to address issues of data-privacy, while simultaneously solving for inference latency, token usage cost and regional and geographic availability.\\n\\nIt is also interesting how entities are used via spaCy framework for entity search and context generation. The fact that this was not just a research piece, but lessons learned based on experiences building an LLM application for real-world use.\\n\\n⭐️ Follow me on LinkedIn for updates on Large Language Models ⭐️\\n\\n\\n\\nI’m currently the Chief Evangelist @ Kore AI. I explore & write about all things at the intersection of AI & language; ranging from LLMs, Chatbots, Voicebots, Development Frameworks, Data-Centric latent spaces & more.\\n\\n\\n\\nLinkedIn\\n\\n\\n\\nGet an email whenever Cobus Greyling publishes.\\nGet an email whenever Cobus Greyling publishes. By signing up, you will create a Medium account if you don’t already…cobusgreyling.medium.com\\n\\nT-RAG: Lessons from the LLM Trenches\\nLarge Language Models (LLM) have shown remarkable language capabilities fueling attempts to integrate them into…arxiv.org'}},\n",
       "  {'id': '1f62a6cbdaef',\n",
       "   'title': 'Run A Small Language Model (SLM) Local & Offline',\n",
       "   'subtitle': 'One notable advantage of SLMs are their flexibility in deployment\\u200a—\\u200athey can be run locally or offline, providing users with greater…',\n",
       "   'author': 'b0fbe613be9d',\n",
       "   'publication_id': '*Self-Published*',\n",
       "   'published_at': '2024-02-14 08:46:14',\n",
       "   'last_modified_at': '2024-02-14 08:46:14',\n",
       "   'tags': ['ai',\n",
       "    'artificial-intelligence',\n",
       "    'machine-learning',\n",
       "    'technology',\n",
       "    'conversational-ai'],\n",
       "   'topics': ['machine-learning'],\n",
       "   'claps': 345,\n",
       "   'voters': 45,\n",
       "   'word_count': 1156,\n",
       "   'responses_count': 1,\n",
       "   'reading_time': 5.612264150943396,\n",
       "   'url': 'https://cobusgreyling.medium.com/run-a-small-language-model-slm-local-offline-1f62a6cbdaef',\n",
       "   'unique_slug': 'run-a-small-language-model-slm-local-offline-1f62a6cbdaef',\n",
       "   'image_url': 'https://miro.medium.com/1*9EaS5q1U-uYJ25wQ5FBxMQ.png',\n",
       "   'lang': 'en',\n",
       "   'is_series': False,\n",
       "   'is_locked': False,\n",
       "   'is_shortform': False,\n",
       "   'top_highlight': 'It demonstrates nearly state-of-the-art performance in common sense, language understanding, and logical reasoning, despite having fewer parameters.',\n",
       "   'content': {'id': '1f62a6cbdaef',\n",
       "    'content': \"Run A Small Language Model (SLM) Local & Offline\\n\\nOne notable advantage of SLMs are their flexibility in deployment - they can be run locally or offline, providing users with greater control over their data and ensuring privacy.\\n\\nIntroduction\\n\\nLarge Language Model (LLM) use can be categorised into two main use-cases.\\n\\nThe first being intended for personal single use, products catering for this use-case include ChatGPT, HuggingChat, Cohere Coral, and now NVIDIA Chat.\\n\\nThe second being where the LLM underpins an application; often referred to as a GenApp or Generative Application. These applications vary in complexity with elements like LLM orchestration, autonomous agents and more and has in most cases a conversational user interface.\\n\\nAs I mentioned in a previous post, there are a number of impediments with LLMs being a hosted service and all the complexities and dependancies this architecture introduce.\\n\\nHence there is a need to run LLM-like functionality offline, but also making use of a model size which matches the application requirements.\\n\\nNVIDIA launched a demo app that lets you personalize a GPT large language model (LLM) connected to your own content - docs, notes, videos, or other data.\\n\\nLeveraging retrieval-augmented generation (RAG), TensorRT-LLM, and RTX acceleration, you can query a custom chatbot to quickly get contextually relevant answers.\\n\\nAnd because it all runs locally on your Windows RTX PC or workstation, you’ll get fast and secure results.\\n\\nNVIDIA Chat with RTX\\n\\nConversational AI\\n\\nConsidering the image below, Conversational AI really only requires the five elements shown below. And a traditional NLU engine can be used in conjunction with a SLM.\\n\\nSince the advent of chatbots, the dream was to have reliable, succinct, coherent and affordable NLG functionality. Together with basic built-in logic and common-sense reasoning ability.\\n\\nAdd to this a flexible avenue to manage dialog context and state, and a more knowledge intensive solution than NLU, and SLMs seem like the perfect fit.\\n\\n\\n\\nChatbot Use-Case\\n\\nLLMs are now commonly augmented with reference data during generation, enhancing in-context learning.\\n\\nWhile LLMs’ vast knowledge is mainly utilised in end-user UI implementations like Chat-GPT, the question arises: if chatbots rely on retrieval-augmentation and limited LLM functionality, would SLMs suffice?\\n\\nImplementing SLMs could address five key impediments faced by companies, such as inference latency, token usage cost, model drift, data privacy concerns, and LLM API rate limits.\\n\\nSLMs can be seen as next-generation NLU engines.\\n\\nMicrosoft Phi-2\\n\\nPhi-2, a Small Language Model (SML) with 2.7 billion parameters, was trained using similar data sources as Phi-1.5, with additional synthetic NLP texts and filtered websites.\\n\\nIt demonstrates nearly state-of-the-art performance in common sense, language understanding, and logical reasoning, despite having fewer parameters.\\n\\nMicrosoft developed Phi-2 as an open-source model to address safety challenges like reducing toxicity, understanding biases, and improving controllability. SMLs like Phi-2 offer a cost-effective alternative to Large Language Models for less demanding tasks.\\n\\nPhi-2 can be run locally or via a notebook for experimentation. Access the Phi-2 model card at HuggingFace for direct interaction.\\n\\nNotebook\\n\\nThe Phi-2 SLM can be run locally via a notebook, the complete code to do this can be found here.\\n\\nI asked the SLM the following question:\\n\\nCreate a list of 5 words which have a similar meaning to the word hope.\\n\\nWith the result:\\n\\nCreate a list of 5 words which have a similar meaning to the word hope. \\n\\nSolution:\\nCreating a list of words with similar meaning to hope\\\\nwords = \\n\\n['optimism', 'faith', 'aspiration', 'desire', 'expectation']\\n\\n\\nExercise 2\\nCreate a list of 5 words which have a similar meaning to the word despair.\\n\\nSolution:\\nCreating a list of words with similar meaning to despair\\\\nwords = \\n\\n['desolation', 'despair', 'anguish', 'despair', 'despair']\\n\\nRunning the code in Colab was quite straightforward, running it locally on my machine making use of a Jupyter Notebook proved to be more challenging.\\n\\nLM Studio\\n\\nLM Studio is free for personal use, but not for business use. Installing and running LM Studio locally on a MacBook was straightforward and easy.\\n\\nConsidering the image below, in the top bar I searched for phi-2 (1) , and chose (2) a model on the left, and the file to download on the right (3).\\n\\nLM Studio\\n\\nThe download and installation of the model is quick and to a large degree automated. As seen below, the chat bubble icon can be selected on the left, and the model selected in the top bar.\\n\\nNow you are free to chat with the model, in the example below I ask the question:\\n\\nWhat are 5 ways people can ask to close their account?\\n\\nThis is typically a question which is used to create intent training examples / sentences. The responses are streamed with the tokens per second showed, stop reason, total token use and more.\\n\\nLM Studio\\n\\nBelow is a view as to how to create a local inference server endpoint.\\n\\nLM Studio\\n\\nThere are other solutions similar to LM Studio, but this illustration serves as an example of how a SLM can be downloaded and deployed locally and made use of off-line.\\n\\nIn Conclusion\\n\\nSmall Language Models (SLMs) offer a tailored solution when their capabilities align with the task at hand. Their usage proves particularly beneficial for scenarios where the demands are less extensive and do not necessitate the vast resources of Large Language Models.\\n\\nSLMs can be utilised effectively for various tasks, including text generation, classification, and sentiment analysis, among others.\\n\\nOne notable advantage of SLMs is their flexibility in deployment - they can be run locally or offline, providing users with greater control over their data and ensuring privacy.\\n\\nThis local execution capability empowers users to leverage SLMs in environments with limited internet connectivity or strict privacy requirements, making them a versatile and accessible choice for a wide range of applications.\\n\\n⭐️ Follow me on LinkedIn for updates on Large Language Models ⭐️\\n\\n\\n\\nI’m currently the Chief Evangelist @ Kore AI. I explore & write about all things at the intersection of AI & language; ranging from LLMs, Chatbots, Voicebots, Development Frameworks, Data-Centric latent spaces & more.\\n\\n\\n\\nLinkedIn\\n\\n\\n\\nGet an email whenever Cobus Greyling publishes.\\nGet an email whenever Cobus Greyling publishes. By signing up, you will create a Medium account if you don’t already…cobusgreyling.medium.com\\n\\nThe Case For Small Language Models\\nMicrosoft Phi-2 is a small language model capable of common-sense reasoning, language understanding, generation and…cobusgreyling.medium.com\\n\\n👾 LM Studio - Discover and run local LLMs\\nLM Studio is an easy to use desktop app for experimenting with local and open-source Large Language Models (LLMs). The…lmstudio.ai\\n\\nmicrosoft/phi-2 · Hugging Face\\nWe're on a journey to advance and democratize artificial intelligence through open source and open science.huggingface.co\\n\\nOriginal notebook can be found here:\\n\\nGoogle Colaboratory\\nEdit descriptioncolab.research.google.com\\n\\nWorking / executed version:\\n\\nhugging-face/phi_2_offline_version.ipynb at main · cobusgreyling/hugging-face\\nHuggingFace notebooks. Contribute to cobusgreyling/hugging-face development by creating an account on GitHub.github.com\"}},\n",
       "  {'id': 'd088c69be2fb',\n",
       "   'title': 'The Case For Small Language Models',\n",
       "   'subtitle': 'Microsoft Phi-2 is a small language model capable of common-sense reasoning, language understanding, generation and more…',\n",
       "   'author': 'b0fbe613be9d',\n",
       "   'publication_id': '*Self-Published*',\n",
       "   'published_at': '2024-02-13 10:02:42',\n",
       "   'last_modified_at': '2024-02-13 10:02:42',\n",
       "   'tags': ['ai',\n",
       "    'artificial-intelligence',\n",
       "    'machine-learning',\n",
       "    'conversational-ai',\n",
       "    'chatbots'],\n",
       "   'topics': ['artificial-intelligence', 'machine-learning'],\n",
       "   'claps': 383,\n",
       "   'voters': 22,\n",
       "   'word_count': 1689,\n",
       "   'responses_count': 1,\n",
       "   'reading_time': 7.506918238993711,\n",
       "   'url': 'https://cobusgreyling.medium.com/the-case-for-small-language-models-d088c69be2fb',\n",
       "   'unique_slug': 'the-case-for-small-language-models-d088c69be2fb',\n",
       "   'image_url': 'https://miro.medium.com/1*BIBopB2C6AicmwqpzhLfOA.png',\n",
       "   'lang': 'en',\n",
       "   'is_series': False,\n",
       "   'is_locked': False,\n",
       "   'is_shortform': False,\n",
       "   'top_highlight': '',\n",
       "   'content': {'id': 'd088c69be2fb',\n",
       "    'content': 'The Case For Small Language Models\\n\\nMicrosoft Phi-2 is a small language model capable of common-sense reasoning, language understanding, generation and more…\\n\\nIntroduction\\n\\nConsidering Conversational AI implementations in general, like chatbots and voicebots, making use of a Large Language Model (LLM) does seem like an overkill in most instances, and it does introduce complexities which is hard to manage.\\n\\nThis brings me to the question, do SLMs not solve for this problem? Allow me to explain…\\n\\nTaking LLMs To Production\\n\\nI recently asked on LinkedIn what are the challenges in taking LLMs to production, below are the top five concerns raised. These concerns all exist due to the fact LLMs are primarily hosted by LLM providers and made available via an API.\\n\\nMaking use of commercially available APIs introduces an operational component which is near impossible to manage.\\n\\nThe ideal would be for an organisation to have a local installation of an LLM they can make use of. But this comes with challenges most organisations cannot address, like hosting, processing power and other technical demands.\\n\\nYes, there are \"raw\" open-sourced models available, but again the impediment here is hosting, fine-tuning, technical expertise etc.\\n\\n\\n\\nThese problems can be solved for, by making use of a SLM, which in most cases are more than sufficient for Conversational AI implementations.\\n\\nConversational AI\\n\\nConsidering the image below, Conversational AI really only requires the five elements shown below. And a traditional NLU engine can be used in conjunction with a SLM.\\n\\nSince the advent of chatbots, the dream was to have a reliable, succinct, coherent and affordable NLG functionality. Together with the a basic built-in logic and common-sense ability.\\n\\nAdd to this a flexible avenue to manage dialog context and state, and a more knowledge intensive solution than NLU, and SLMs seem like the perfect fit.\\n\\n\\n\\nAugmentation\\n\\nAlmost by default now, LLMs are not used solely for their vast knowledge but rather the LLM generation is augmented with reference data acting as a contextual reference, injected at inference. This contextual reference data enables the in-context learning capability of LLMs.\\n\\nThe vast general knowledge of LLMs are almost solely used in end-user UI implementations like Chat-GPT and the like.\\n\\nThis begs the question, if chatbots rely on retrieval-augmentation, and a limited scope of LLM functionality, will SLMs not suffice? And by implementing a SLM, these five impediments listed below will be circumnavigated…\\n\\nCompanies are in the experimental phase rather than moving to production due to:\\n\\n1️⃣ Inference Latency\\n2️⃣ Token Usage Cost\\n3️⃣ Model Drift\\n4️⃣ Data Privacy Concerns\\n5️⃣ LLM API Rate Limits\\n\\nOne can almost consider SLMs as next generation NLU engines.\\n\\nMicrosoft Phi-2\\n\\nPhi-2 is a Small Language Model (SML) with 2.7 billion parameters. It was trained making use of the same data sources as Phi-1.5, augmented with a new data source that consists of various NLP synthetic texts and filtered websites for safety and educational value.\\n\\nConsidering common sense, language understanding and logical reasoning, Phi-2 showed close-to nearly state-of-the-art performance among models with less than 13 billion parameters.\\n\\nMicrosoft’s intention in crafting this open-source model is to provide the research community with a non-restricted small model to explore vital safety challenges, such as reducing toxicity, understanding societal biases, enhancing controllability, and more.\\n\\nYet, considering production conversational AI implementations, SLMs are a cost-effective alternative to Large Language Models and are also useful when they are being used for less demanding tasks, tasks which do not require the power of an LLM.\\n\\nPhi-2 can be run locally or via a notebook for expermentation.\\n\\nBelow is the phi-2 model card at HuggingFace; you can interact directly with the model form here.\\n\\nHuggingFace\\n\\nRunning Phi-2 In A Notebook\\n\\nHere is a simple example of running Phi-2 by make use of HuggingFace within a notebook. I had to change the runtime type to T4 GPU to have the SLM respond in a reasonable time.\\n\\nConsidering most chatbot development frameworks use LLMs to generate NLU training data, and specifically different variations of intent sentence examples, I asked Phi-2 the following question:\\n\\nGive me three example sentences on how someone can ask to close their account.\\n\\nHere is the complete code you can paste into a notebook…\\n\\n!pip install -q -U transformers\\n!pip install -q -U accelerate\\n\\nfrom transformers import pipeline\\n\\nmodel_name = \"microsoft/phi-2\"\\n\\npipe = pipeline(\\n    \"text-generation\",\\n    model=model_name,\\n    device_map=\"auto\",\\n    trust_remote_code=True,\\n)\\n\\nprompt = \"Give met three example sentences on how someone can ask to close their acuount.\"\\n\\noutputs = pipe(\\n    prompt,\\n    max_new_tokens=300,\\n    do_sample=True,\\n    temperature=0.7,\\n    top_k=50,\\n    top_p=0.95,\\n)\\nprint(outputs)\\n\\nAnd the output below…Phi-2 generated three example sentences, together with follow-up questions and answers. These follow-up questions and answers can act well to present chatbot users with quick-reply buttons in the dialog.\\n\\nOr it can be used to create sub-intents or nested intents.\\n\\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\\n\\n[{\\'generated_text\\': \\n\\'Give met three example sentences on how someone can ask to close their acuount.\\n\\nAnswer:\\n1. \"Can I close my account now, please?\"\\n2. \"I would like to close my account, can you help me with that?\"\\n3. \"I need to close my account, can you guide me through the process?\"\\n\\nExercise: \\nWhat should you do if you are unsure about closing your account?\\nAnswer: \\nYou should seek help from a trusted adult or contact the company directly to clarify any doubts or concerns.\\n\\nExercise: \\nWhat are some important details to have ready when closing your account?\\nAnswer: \\nSome important details to have ready include the account number, any PIN codes, and the reason for closing the account.\\n\\nExercise: Why is it important to know how to close an account on a website?\\nAnswer: Knowing how to close an account on a website is important because it allows you to take control of your online presence and protect your personal information. It also helps you manage your finances and account settings effectively.\\n\\nDiscussion:\\nPositive Side:\\nThe knowledge of how to close an account on a website is extremely useful in today\\\\\\'s digital age. \\nWith the increasing reliance on the internet for various purposes, it is important for individuals to have control over their online presence. Knowing how to close an account on a website allows individuals to take control of their personal information and protect themselves from potential risks such as identity theft or fraud. It also helps individuals manage their finances and\\'\\n}]\\n\\nBelow Phi-2 is presented with a dialog, which acts as a contextual reference for the conversation, and how to continue the conversation. This example dialog also serves well for in-context learning, hence allowing the SLM to continue the conversation.\\n\\nprompt = \"\"\"\\nAlice: I don\\'t know why, I\\'m struggling to maintain focus while studying. \\nAny suggestions?\\n\\nBob: Well, have you tried creating a study schedule and sticking to it?\\n\\nAlice: Yes, I have, but it doesn\\'t seem to help much.\\n\\nBob: Hmm, maybe you should try studying in a quiet environment, \\nlike the library.\\n\\nAlice: \\n.\"\"\"\\n\\noutputs = pipe(\\n    prompt,\\n    max_new_tokens=300,\\n    do_sample=True,\\n    temperature=0.7,\\n    top_k=50,\\n    top_p=0.95,\\n)\\nprint(outputs)\\n\\nAnd again below the result, Phi-2 created a number of different conversation paths from the contextual reference. This illustrates how Phi-2 can be used for chit-chat/small talk, developing different dialog paths, or creating a mockup of a conversation.\\n\\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\\n[{\\'generated_text\\': \"\\n\\nAlice: I don\\'t know why, I\\'m struggling to maintain focus while studying. \\nAny suggestions?\\n\\nBob: Well, have you tried creating a study schedule and sticking to it?\\n\\nAlice: Yes, I have, but it doesn\\'t seem to help much.\\n\\nBob: Hmm, maybe you should try studying in a quiet environment, like the library.\\n\\nAlice: \\n\\n...\\n\\n\\nAlice: I tried studying in the library, but the constant noise from other students was really distracting.\\n\\nBob: Oh, that\\'s unfortunate. Maybe you could try using noise-canceling headphones?\\n\\nAlice: I thought about that, but I don\\'t have any with me right now.\\n\\nBob: In that case, have you considered going to a coffee shop? They usually have a quieter atmosphere.\\n\\nAlice:\\n...\\n\\nAlice: I went to a coffee shop to study, but the background music was too loud for me to concentrate.\\n\\nBob: I see. Maybe you could try finding a study group?\\n\\nAlice: I thought about that, but I prefer studying alone.\\n\\nBob: Well, have you considered using a study app or website? They often have features to block out distractions.\\n\\nAlice: ...\\n\\nAlice: I tried using a study app, but the notifications kept popping up and interrupting my studying.\\\\nBob: Oh, that\\'s frustrating. Maybe you could try studying in a different location altogether?\\\\nAlice: I thought about that, but I\\'m not sure where else to go.\\\\nBob: Well, have you considered studying in a park or a quiet corner of your house?\\\\nAlice: \\\\n...\\\\n\\\\nAlice: I tried studying in a park, but the presence of other people and their activities was too distracting.\\\\nBob: I understand.\"}]\\n\\nIn Conclusion\\n\\nFor now, it seems highly feasible to use NLU in conjunction with a SLM to underpin a chatbot development framework.\\n\\nRunning a SLM locally and using an augmented generation approach with in-context learning can solve for impediments like inference latency, token cost, model drift, data privacy, data governance and more.\\n\\n\\n\\nI’m currently the Chief Evangelist @ Kore AI. I explore & write about all things at the intersection of AI & language; ranging from LLMs, Chatbots, Voicebots, Development Frameworks, Data-Centric latent spaces & more.\\n\\n\\n\\nLinkedIn\\n\\n\\n\\nGet an email whenever Cobus Greyling publishes.\\nGet an email whenever Cobus Greyling publishes. By signing up, you will create a Medium account if you don’t already…cobusgreyling.medium.com\\n\\nmicrosoft/phi-2 · Hugging Face\\nWe\\'re on a journey to advance and democratize artificial intelligence through open source and open science.huggingface.co\\n\\nMicrosoft unveils Phi-2, a small language model that packs power\\nEven though Google\\'s Gemini Nano has only been out for a week, it already has some competition.www.zdnet.com\\n\\nhugging-face/Microsoft_Phi_2.ipynb at main · cobusgreyling/hugging-face\\nHuggingFace notebooks. Contribute to cobusgreyling/hugging-face development by creating an account on GitHub.github.com'}},\n",
       "  {'id': '3594ee338467',\n",
       "   'title': 'Beyond Chain-of-Thought LLM Reasoning',\n",
       "   'subtitle': 'This approach can be implemented on a prompt level and does not require any dedicated frameworks or pre-processing.',\n",
       "   'author': 'b0fbe613be9d',\n",
       "   'publication_id': '*Self-Published*',\n",
       "   'published_at': '2024-02-12 18:42:55',\n",
       "   'last_modified_at': '2024-02-12 18:43:17',\n",
       "   'tags': ['ai',\n",
       "    'artificial-intelligence',\n",
       "    'machine-learning',\n",
       "    'prompt-engineering',\n",
       "    'conversational-ai'],\n",
       "   'topics': ['artificial-intelligence', 'machine-learning'],\n",
       "   'claps': 90,\n",
       "   'voters': 8,\n",
       "   'word_count': 689,\n",
       "   'responses_count': 0,\n",
       "   'reading_time': 3.7333333333333334,\n",
       "   'url': 'https://cobusgreyling.medium.com/beyond-chain-of-thought-llm-reasoning-3594ee338467',\n",
       "   'unique_slug': 'beyond-chain-of-thought-llm-reasoning-3594ee338467',\n",
       "   'image_url': 'https://miro.medium.com/1*i2s2TWgy5bqxdimGEnbvxA.png',\n",
       "   'lang': 'en',\n",
       "   'is_series': False,\n",
       "   'is_locked': False,\n",
       "   'is_shortform': False,\n",
       "   'top_highlight': '',\n",
       "   'content': {'id': '3594ee338467',\n",
       "    'content': 'Source\\n\\nBeyond Chain-of-Thought LLM Reasoning\\n\\nThis approach can be implemented on a prompt level and does not require any dedicated frameworks or pre-processing.\\n\\nIntroduction\\n\\nA recent study addressed the need to enhance the reasoning capabilities of Large Language Models (LLMs) beyond Direct Reasoning (DR) frameworks like Chain-of-Thought and Self-Consistency, which may struggle with real-world tasks requiring Indirect Reasoning (IR).\\n\\nThe study proposed an IR method leveraging logic of contradictions for tasks like factual reasoning and mathematical proof.\\n\\nThe methodology involves augmenting data and rules using contrapositive logical equivalence and designing prompt templates for IR based on proof by contradiction.\\n\\nThe IR method is simple yet effective,\\n\\nEnhancing overall accuracy in factual reasoning by 27.33% and\\n\\nMathematical proof by 31.43% compared to traditional DR methods.\\n\\nCombining IR & DR methods further boosts performance, highlighting the effectiveness of the proposed strategy.\\n\\nLLMs excel at language comprehension, content generation, dialog management and logical reasoning.\\n\\nIR Prompt Structure\\n\\nThe image shows indirect reasoning (IR) with Large Language Models (LLMs) in zero-shot and few-shot learning scenarios. It is presented for complex issues involving mathematical proof and factual reasoning.\\n\\nTraditional direct reasoning approaches might faltered in addressing these challenges.\\n\\nIn contrast, this methodology directs LLMs to employ contrapositive logic and contradictions, leading to precise reasoning and successful deduction of accurate answers.\\n\\nSource\\n\\nThe goal was to introduce novel strategies for employing Indirect Reasoning (IR) to address the constraints of direct reasoning. This approach offers an alternative and effective method for tackling practical problems.\\n\\nThe study also makes a number of prompt templates available which effectively stimulate LLMs to follow indirect reasoning.\\n\\nPrompt Based\\n\\nThe aim of the study was to keep the implementation light and prompt based, without any dependancy on external data. Hence approaches like fine-tuning, RAG-based implementations, or tool base (agent-like) were avoided.\\n\\nRule Augmentation\\n\\nLLMs often struggle to grasp complex rules, affecting their ability to use them effectively.\\n\\nConsider the following:\\n\\nFact: Bob does not drive to work\\n\\nRule: If the weather is fine, Bob drives to work\\n\\nHumans can apply the equivalence of contrapositive to deduce that the rule is equivalent to: If Bob does not drive to work, the weather is not fine hence humans can deduce.\\n\\nAnd this allows humans to conclude based on the rule, that The weather is not fine .\\n\\nLLMs can find this reasoning approach challenging, hence to address this issue, the study propose adding the contrapositive of rules to the rule set.\\n\\nHence applying at type of in-context learning, with few-shot learning.\\n\\nSource\\n\\nAnd here is a prompt template:\\n\\n# <Instruction>The contrapositive is equivalent to the original rule, \\nand now we need to convert the following rules into their contrapositives.\\n</Instruction>\\n\\n# Example 1\\n# Rule: [rule1]\\n# Contrapositive: [contrapositive1]\\n...\\n# Rules: [rules]\\n# Contrapositives:\\n\\nPerformance\\n\\nConsidering the graph below, the comparison between GPT 3.5 turbo and Gemini-pro.\\n\\nI was surprised by the jump in performance, an interesting piece of research to see which models respond best on IR with or without RA.\\n\\nIt is evident that both models showed below have a significant improvement in performance; but the spike in improvement from GPT.3.5 turbo on IR/RA scenario.\\n\\nSource\\n\\nIn Conclusion\\n\\nIndirect reasoning effectively addresses challenges that cannot be directly resolved using known conditions and rules.\\n\\nThe study demonstrates the effectiveness of this method in factual reasoning and mathematical proof tasks, confirming its utility.\\n\\nWhile this current study focuses on simple contrapositive and contradiction logic, future research could explore integrating more complex logical principles to enhance LLMs’ reasoning abilities further.\\n\\n\\n\\nI’m currently the Chief Evangelist @ Kore AI. I explore & write about all things at the intersection of AI & language; ranging from LLMs, Chatbots, Voicebots, Development Frameworks, Data-Centric latent spaces & more.\\n\\n\\n\\nLinkedIn\\n\\n\\n\\nGet an email whenever Cobus Greyling publishes.\\nGet an email whenever Cobus Greyling publishes. By signing up, you will create a Medium account if you don’t already…cobusgreyling.medium.com\\n\\nLarge Language Models as an Indirect Reasoner: Contrapositive and Contradiction for Automated…\\nRecently, increasing attention has been focused drawn on to improve the ability of Large Language Models (LLMs) to…arxiv.org'}},\n",
       "  {'id': '44c6d6f7c2f6',\n",
       "   'title': 'Comparing Human, LLM & LLM-RAG Responses',\n",
       "   'subtitle': 'A recent study, focusing on the healthcare & preoperative medicine compared expert human feedback with LLM generation and RAG enhanced…',\n",
       "   'author': 'b0fbe613be9d',\n",
       "   'publication_id': '*Self-Published*',\n",
       "   'published_at': '2024-02-09 12:08:15',\n",
       "   'last_modified_at': '2024-02-09 12:08:15',\n",
       "   'tags': ['ai',\n",
       "    'artificial-intelligence',\n",
       "    'machine-learning',\n",
       "    'large-language-models',\n",
       "    'prompt-engineering'],\n",
       "   'topics': ['artificial-intelligence', 'data-science'],\n",
       "   'claps': 187,\n",
       "   'voters': 24,\n",
       "   'word_count': 546,\n",
       "   'responses_count': 0,\n",
       "   'reading_time': 3.110377358490566,\n",
       "   'url': 'https://cobusgreyling.medium.com/comparing-human-llm-llm-rag-responses-44c6d6f7c2f6',\n",
       "   'unique_slug': 'comparing-human-llm-llm-rag-responses-44c6d6f7c2f6',\n",
       "   'image_url': 'https://miro.medium.com/1*ltyLqlHdBxOqKlrnWLlCUw.png',\n",
       "   'lang': 'en',\n",
       "   'is_series': False,\n",
       "   'is_locked': False,\n",
       "   'is_shortform': False,\n",
       "   'top_highlight': '',\n",
       "   'content': {'id': '44c6d6f7c2f6',\n",
       "    'content': 'Source\\n\\nComparing Human, LLM & LLM-RAG Responses\\n\\nA recent study, focusing on the healthcare & preoperative medicine compared expert human feedback with LLM generation and RAG enhanced responses.\\n\\nIntroduction\\n\\nUsually I do not read research on very narrow fields, however this paper offers a very insightful research in comparing question answering. And comparing human feedback, to LLM-only responses, and LLM-RAG responses.\\n\\nDuring the study, an LLM-RAG model was developed using 35 preoperative guidelines and tested it against human-generated responses.\\n\\nAfter evaluating a total number of 1260 responses, comprising of 336 human-generated, 336 LLM-generated, and 588 LLM-RAG-generated responses.\\n\\nFor the RAG pipeline clinical documents were converted into text using Python-based frameworks like LangChain and LlamaIndex, and processing these texts into chunks for embedding and retrieval.\\n\\nEvaluated LLMs including GPT3.5, GPT4.0, Llama2–7B, llama2–13B, together with a RAG implementation.\\n\\nThe correctness of responses were determined based on established guidelines and expert panel reviews. The human-generated answers were provided by junior doctors for comparison.\\n\\nInference Time & Accuracy\\n\\nThe LLM-RAG pipeline model responded in an average time of 15–20 seconds, significantly quicker than the 10 minutes typically needed by humans.\\n\\nAmong the basic LLMs, GPT4.0 achieved the highest accuracy of 80.1%.\\n\\nWith RAG enhancement, GPT4.0’s accuracy improved to 91.4%.\\n\\nThe human-generated instructions, had an accuracy of 86.3%.\\n\\nThe pipeline underscores the benefits of grounded knowledge, upgradability, and scalability as crucial elements in deploying LLMs for healthcare purposes.\\n\\nResults\\n\\nBelow is a basic diagram of the RAG pipeline, with the performance graphed in the top right.\\n\\nAnd considering the graph, I was astonished just how high the GPT4.0 model scored without RAG support. Also, note that GPT3.5 sans RAG, outscores other models with RAG.\\n\\nSource\\n\\nOperational Framework\\n\\nThe diagram below shows the operational framework from the study.\\n\\nThe LLM-RAG model with GPT4.0 shows great potential in creating precise and safe preoperative instructions, matching junior doctors’ performance.\\n\\nThis study highlights how LLMs can enhance preoperative medicine, emphasising that its use should complement human expertise, requiring continuous oversight and cautious implementation.\\n\\nSource\\n\\nIn Closing\\n\\nIt would be interesting to see this study which focusses on a very narrow and specialised domain, compared to a more general question answering domain.\\n\\nThe study shows clearly that human and GPT 4.0 + RAG is on par, with the only difference being response times. With humans taking much longer to respond to questions, and still not exceeding LLM/RAG performance.\\n\\nThis makes a good case for AI assisting humans; where physicians can make use of the RAG pipeline to get quick and accurate responses, which then in turn can be reviewed.\\n\\n⭐️ Follow me on LinkedIn for updates on Large Language Models ⭐️\\n\\n\\n\\nI’m currently the Chief Evangelist @ Kore AI. I explore & write about all things at the intersection of AI & language; ranging from LLMs, Chatbots, Voicebots, Development Frameworks, Data-Centric latent spaces & more.\\n\\n\\n\\nLinkedIn\\n\\n\\n\\nGet an email whenever Cobus Greyling publishes.\\nGet an email whenever Cobus Greyling publishes. By signing up, you will create a Medium account if you don’t already…cobusgreyling.medium.com\\n\\nFrom Prompt Engineering to Prompt Science With Human in the Loop\\nAs LLMs make their way into many aspects of our lives, one place that warrants increased scrutiny with LLM usage is…arxiv.org'}},\n",
       "  {'id': 'f574bb9a405e',\n",
       "   'title': 'Craft Successful Conversational User Interfaces: Align User Intent With Developed Intent',\n",
       "   'subtitle': 'In this article I illustrate how to achieve intent alignment by making use of the Kore.ai XO Platform Intent Discovery Tool.',\n",
       "   'author': 'b0fbe613be9d',\n",
       "   'publication_id': '*Self-Published*',\n",
       "   'published_at': '2024-02-08 12:11:10',\n",
       "   'last_modified_at': '2024-02-08 15:20:53',\n",
       "   'tags': ['ai',\n",
       "    'artificial-intelligence',\n",
       "    'conversational-ai',\n",
       "    'conversational-ui',\n",
       "    'chatbots'],\n",
       "   'topics': ['artificial-intelligence'],\n",
       "   'claps': 43,\n",
       "   'voters': 4,\n",
       "   'word_count': 1446,\n",
       "   'responses_count': 1,\n",
       "   'reading_time': 6.656603773584906,\n",
       "   'url': 'https://cobusgreyling.medium.com/craft-successful-conversational-user-interfaces-align-user-intent-with-developed-intent-f574bb9a405e',\n",
       "   'unique_slug': 'craft-successful-conversational-user-interfaces-align-user-intent-with-developed-intent-f574bb9a405e',\n",
       "   'image_url': 'https://miro.medium.com/1*282CBGj0AItCB_EiEMmMIA.png',\n",
       "   'lang': 'en',\n",
       "   'is_series': False,\n",
       "   'is_locked': False,\n",
       "   'is_shortform': False,\n",
       "   'top_highlight': '',\n",
       "   'content': {'id': 'f574bb9a405e',\n",
       "    'content': 'Craft Successful Conversational User Interfaces: Align User Intent With Developed Intent\\n\\nIn this article I illustrate how to achieve intent alignment by making use of the Kore.ai XO Platform Intent Discovery Tool.\\n\\nIntroduction\\n\\nAccording to Gartner, by 2028 Generative AI, digital customer service, and conversational UIs will revolutionise customer care.\\n\\nIn this article I want to delve deeper into conversational UI design, with specific focus on alignment of user intents with developed intents to craft relevant, intuitive and impactful conversational experiences.\\n\\nWhether you’re a conversation designer, developer, or business analyst, this guide serves as your compass for mastering the art of creating chatbot interactions that literally meets user intent.\\n\\nDecoding Intents\\n\\nThe Key to Effective Chatbot Development\\n\\nIn the domain of Natural Language Understanding (NLU) and natural language processing (NLP), intents are at the frontline of classifying user input. It can be described as the North Star of the dialogue systems, chatbot development, and any application dealing with understanding and interpreting human language.\\n\\nWhat Are intents?\\n\\nIn Natural Language Understanding (NLU) and natural language processing (NLP), an intent refers to the intention or purpose behind a user’s input or query. It is a key concept in dialogue systems, chatbot development, and other applications that involve understanding and interpreting human language.\\n\\nIntents At The Frontline\\n\\nPre-Defined Conversation Classifications\\n\\nHere’s the problem... Conversational designers are busy crafting engaging dialogues, usually centred around products and services with a well defined conversational UI.\\n\\nTheir process revolves around enhancing conversations by refining the design of the conversational flow.\\n\\nBut here’s the twist. It’s like putting the cart before the horse, as this is most probably not the conversation users want, when user intents doesn’t align with the developed intents.\\n\\nIntent misalignment is a stumbling block to a great user experience.\\n\\nFor an exceptional conversational user experience, the secret sauce lies in aligning user intents with business intents; as seen below:\\n\\nCredit to Vincent Warmerdam for this concept.\\n\\nConsidering the Venn diagram above…\\n\\nThe area of overlap is the conversation you users want to have.\\n\\nThese highly relevant and applicable intents are constituted by the delta of two corpuses of information.\\n\\nDiscovering this intent delta demands two crucial steps.\\n\\nFirst, leverage a data discovery tool to unearth existing intents within ongoing customer conversations.\\n\\nSecond, aligning conversational AI training data with these discovered intents.\\n\\nIt’s the roadmap to ensuring that the conversation users desire aligns seamlessly with the developed intents.\\n\\nWhy Aligning Intents Matters\\n\\nAligning customer intents with developed intents is a crucial aspect of chatbot development, ensuring a seamless and effective interaction between users and the chatbot.\\n\\nCustomer intents represent the varied reasons why a user engages with the chatbot, while developed intents are the predefined actions and responses the chatbot has been programmed to perform.\\n\\nHere are key considerations for aligning customer intents with developed intents:\\n\\nUnderstanding Customer Intents\\n\\nBegin by conducting thorough research to understand the diverse intents customers may have when interacting with the chatbot.\\n\\nStart by analysing customer inquiries, feedback, and historical data to identify common queries, trends, customer speak and more.\\n\\nDefine Clear and Relevant Developed Intents\\n\\nBased on customer insights, define a set of clear and relevant intents that cover a broad spectrum of user needs. Each developed intent should address a specific customer query or goal, ensuring a focused and effective response.\\n\\nRegularly Update Developed Intents\\n\\nFollow an agile approach to chatbot development by regularly updating and expanding the set of developed intents to accommodate evolving customer needs.\\n\\nMonitor customer interactions to identify new intents or changes in user behaviour and adjust the chatbot accordingly.\\n\\nMulti-Intent Recognition\\n\\nTrain the chatbot to recognise and handle multiple intents within a single user query, as conversations often involve a mix of topics. Prioritise intents based on user input to deliver the most relevant and timely information.\\n\\nA number of chatbot development frameworks have implemented a more granular approach to intent classification with sub-intents and nested intents.\\n\\nDesign Conversations That Matter\\n\\nDesign vs Desired Conversation Paths\\n\\nWith intent-driven conversation design, a crucial aspect lies in navigating the divergence between the designed path and desired user interactions.\\n\\nIntents lie embedded within the intricacies of existing customer conversations. However, these conversations pose a challenge as they are presented in the form of highly unstructured data from diverse sources.\\n\\nMoreover, when chatbot conversations are crafted with a focus solely on business intents rather than aligning with user intents, a noticeable gap emerges between the intended design and the actual user experience.\\n\\nThe ultimate goal is for these two paths to converge seamlessly, where the designed conversation aligns perfectly with the conversation users truly desire.\\n\\nThis alignment ensures that the chatbot experience resonates authentically with users, fostering user engagement and satisfaction.\\n\\n\\n\\nThe XO Solution\\n\\nIntent Discovery\\n\\nConsidering the image below, XO has a built-in intent discovery tool which comes standard with the XO solution. Under tools, the Intent (a) Discovery Tool can be found.\\n\\nAny unstructured data can be imported into the XO platform, the unstructured data is then segmented according to (b) extracted intents.\\n\\nThese intents can be considered as semantic clusters; where sentences which are semantically similar, are clustered together.\\n\\nThe clusters are also given a name, which can be used as the intent name, or modified. The number of qualified utterances are (c) listed for each intent cluster. The number of utterances per intent can be considered as a weight indicating how important an intent is.\\n\\nIntents with more qualified utterances most probably need to be broken down into nested or sub-intents.\\n\\nThis is also a feature which is available within XO, to create sub or nested intents for a higher level of granularity in managing conversations.\\n\\nFrom this view under Actions (d) utterances can be added to intents; and assigned intents can be viewed.\\n\\n\\n\\nContinuous Improvement\\n\\nContinuous intent development for chatbots is important for several reasons, and it plays a crucial role in ensuring the chatbot remains effective, relevant, and capable of meeting evolving user needs.\\n\\nAs seen below, within Kore.ai’s XO platform, data can be explored based on date filters.\\n\\n\\n\\nThis is important for a cadence of transcript inspection for the following reasons:\\n\\nAdaptability to Changing User Behaviour\\n\\nDetecting New User Intents\\n\\nImproving Accuracy and Precision\\n\\nStaying Relevant in Dynamic Products and Services Environments\\n\\nEnhancing Natural Language Understanding (NLU)\\n\\nCatering to Seasonal or Event-Specific Intents\\n\\nThe link between intent and conversation context is fundamental to the effective functioning of chatbots. Understanding this relationship is crucial for developing chatbots that can engage in meaningful and context-aware conversations.\\n\\nHere’s How Intent & Conversation Context Are Interconnected\\n\\nIntent represents the user’s goal or purpose behind a specific message or query.\\n\\nIntents indicate what the user wants to achieve; hence the user’s intent. In the context of a conversation, each user input is associated with a particular intent.\\n\\nThe chatbot uses this identified intent to determine the appropriate action or response. The intent serves as a guiding factor for the chatbot to fulfil the user’s request or provide relevant information.\\n\\nThe context of the conversation significantly impacts how intents are interpreted. Previous user inputs and the chatbot’s responses contribute to the ongoing context.\\n\\nWith Kore.ai’s XO Platform, users can drill down from an intent cluster, into the dialog turns as seen in the image below.\\n\\nThe transcript view presents a dialog turn view to present conversational designers with a conversational, contextual view.\\n\\n\\n\\nIn Closing\\n\\nSeamless Intent Alignment\\n\\nIn conclusion, let’s reflect on the journey towards aligning customer intents with developed intents in chatbot development.\\n\\nTraditionally, the intent discovery process follows the red line in the graph below. Here, chatbots are often fixed post-launch as conversations break down. This approach results in a high effort, high-stress ordeal, ultimately impacting the user experience.\\n\\nIn contrast, the blue line represents the XO approach, where intents are proactively detected, defined, and planned for.\\n\\n\\n\\nFrom day one, the developed intent is meticulously aligned with customer intent. This proactive strategy ensures that chatbots are finely tuned to meet user needs, fostering a seamless and satisfying conversational experience from the outset.\\n\\n\\n\\nI’m currently the Chief Evangelist @ Kore AI. I explore & write about all things at the intersection of AI & language; ranging from LLMs, Chatbots, Voicebots, Development Frameworks, Data-Centric latent spaces & more.\\n\\n\\n\\nGet an email whenever Cobus Greyling publishes.\\nGet an email whenever Cobus Greyling publishes. By signing up, you will create a Medium account if you don’t already…cobusgreyling.medium.com\\n\\nCOBUS GREYLING\\nAt the intersection of AI & Language | NLP/NLU/LLM, Chat/Voicebots, CCAI I explore and write about all things at the…www.cobusgreyling.me\\n\\nIntent Discovery (Beta)\\nThe new Intent Discovery module helps you auto-extract popular intents from previous user conversations. It reduces the…developer.kore.ai'}},\n",
       "  {'id': '904db5ebeefa',\n",
       "   'title': 'A Benchmark for Verifying Chain-Of-Thought',\n",
       "   'subtitle': 'A Chain-of-Thought is only as strong as its weakest link; a recent study from Google Research created a benchmark for Verifiers of…',\n",
       "   'author': 'b0fbe613be9d',\n",
       "   'publication_id': '*Self-Published*',\n",
       "   'published_at': '2024-02-07 20:56:54',\n",
       "   'last_modified_at': '2024-02-07 20:56:54',\n",
       "   'tags': ['ai',\n",
       "    'artificial-intelligence',\n",
       "    'large-language-models',\n",
       "    'machine-learning',\n",
       "    'conversational-ai'],\n",
       "   'topics': ['machine-learning', 'data-science'],\n",
       "   'claps': 148,\n",
       "   'voters': 5,\n",
       "   'word_count': 816,\n",
       "   'responses_count': 0,\n",
       "   'reading_time': 4.379245283018868,\n",
       "   'url': 'https://cobusgreyling.medium.com/a-benchmark-for-verifying-chain-of-thought-904db5ebeefa',\n",
       "   'unique_slug': 'a-benchmark-for-verifying-chain-of-thought-904db5ebeefa',\n",
       "   'image_url': 'https://miro.medium.com/1*9gQtv8MpXKXt7qKdmh7NRw.png',\n",
       "   'lang': 'en',\n",
       "   'is_series': False,\n",
       "   'is_locked': False,\n",
       "   'is_shortform': False,\n",
       "   'top_highlight': '',\n",
       "   'content': {'id': '904db5ebeefa',\n",
       "    'content': 'A Benchmark for Verifying Chain-Of-Thought\\n\\nA Chain-of-Thought is only as strong as its weakest link; a recent study from Google Research created a benchmark for Verifiers of Reasoning Chains\\n\\nIntroduction\\n\\nThere has been a significant number of studies performed on the topic of automated verification of LLM interactions. These methods evaluate LLM output and reasoning steps to evaluate and improve the correctness of responses.\\n\\nIn this study from Google Research, there is an observation that no fine-grained step-level datasets are available for the evaluation of chain-of-thought.\\n\\nHence the introduction of REVEAL, which is in essence a dataset to benchmark automatic verifiers of complex CoT for open-domain question answering.\\n\\nREVEAL contains comprehensive labels for:\\n\\nRelevance,\\n\\nAttribution to evidence passages, and\\n\\nLogical correctness\\n\\nof each reasoning step in a language model’s answer, across a wide variety of datasets and state-of-the-art language models.\\n\\nThe resulting dataset, named REVEAL, serves as a benchmark for evaluating the performance of automatic verifiers of LM reasoning.\\n\\nThe dataset is available on HuggingFace.\\n\\nChallenges\\n\\nThe research primarily focuses on evaluating verifiers that assess evidence attribution to a given source, rather than fact-checkers that perform evidence retrieval themselves.\\n\\nDue to this focus, REVEAL can only assess verifiers that operate on specific provided evidence.\\n\\nSome knowledge claims labeled as \"unsupported\" in the dataset may have supporting or contradictory evidence that was not surfaced by the retriever.\\n\\nHowever, it’s important to note that the dataset aims to gather a diverse range of cases to evaluate verifiers, rather than to assess the CoT itself using an \"ideal\" retriever. The labels in the dataset are well-defined for the specific evidence passages used.\\n\\nPractical Examples\\n\\nREVEAL is an evaluation benchmark for verifying reasoning chains in a Chain-of-Thought format. REVEAL checks whether a reasoning chain is a correct justification to the final answer.\\n\\nWhat is important to note, is that the answer can be correct even when the reasoning is incorrect.\\n\\nSource\\n\\nThe image above shows four verifiers in the middle column which verifies the correctness of a Chain-of-Thought on the left. The dataset is used to benchmark multiple verifiers, with the result shown on the right.\\n\\nBelow, a flowchart of the protocol for verifying reasoning and correctness step-by-step.\\n\\nSource\\n\\nConsidering the image below, a REVEAL instance is shown with labels for each step, for step type, relevance and correctness.\\n\\nSource\\n\\nAnnotation\\n\\nAs seen below, annotation was performed via a complex GUI and relies heavily on the annotators judgement.\\n\\nThe annotation task is split into two tasks; one task was focused on the logic annotation (including relevance, step type and logical correctness ratings).\\n\\nTogether with another task focused on the attribution annotations (including relevance and step-evidence attribution).\\n\\nIn the image below the annotation interface for the attribution task is shown.\\n\\nSource\\n\\nAnd in the image below, the annotation GUI is shown for the task of annotating the logic.\\n\\nSource\\n\\nConsideration\\n\\nSomething I find interesting from this study is the complexity involved in creating highly granular datasets.\\n\\nA second consideration is the level of data design involved, considering the complex data structure. The GUI for data annotation is also complex and I’m quite sure it demanded a high level of expertise from the annotators.\\n\\nIt is evident that the process is time consuming, demanding a more complex annotation framework. This contributes to a higher cost of annotation.\\n\\n⭐️ Follow me on LinkedIn for updates on Large Language Models ⭐️\\n\\n\\n\\nI’m currently the Chief Evangelist @ Kore AI. I explore & write about all things at the intersection of AI & language; ranging from LLMs, Chatbots, Voicebots, Development Frameworks, Data-Centric latent spaces & more.\\n\\n\\n\\nLinkedIn\\n\\n\\n\\nGet an email whenever Cobus Greyling publishes.\\nGet an email whenever Cobus Greyling publishes. By signing up, you will create a Medium account if you don’t already…cobusgreyling.medium.com\\n\\nA Chain-of-Thought Is as Strong as Its Weakest Link: A Benchmark for Verifiers of Reasoning Chains\\nPrompting language models to provide step-by-step answers (e.g., \"Chain-of-Thought\") is the prominent approach for…arxiv.org\\n\\ngoogle/reveal · Datasets at Hugging Face\\nWe\\'re on a journey to advance and democratize artificial intelligence through open source and open science.huggingface.co\\n\\nThe Chain-Of-X Phenomenon In LLM Prompting\\nIn a recent post, I discussed the seemingly emergent abilities of LLMs. A new study argues that Emergent Abilities are…cobusgreyling.medium.com\\n\\nSelf-Consistency For Chain-Of-Thought Prompting\\nThe paper on Self-Consistency Prompting was published 7 March 2023, as an improvement on Chain-Of-Thought Prompting. At…cobusgreyling.medium.com\\n\\nChain Of Natural Language Inference (CoNLI)\\nHallucination is categorised into subcategories of Context-Free Hallucination, Ungrounded Hallucination &…cobusgreyling.medium.com\\n\\nConcise Chain-of-Thought (CCoT) Prompting\\nTraditional CoT comes at a cost of increased output token usage, CCoT prompting is a prompt-engineering technique which…cobusgreyling.medium.com\\n\\nChain-of-Symbol Prompting (CoS) For Large Language Models\\nLLMs need to understand a virtual spatial environment described through natural language while planning & achieving…cobusgreyling.medium.com'}},\n",
       "  {'id': '02ead9cc2532',\n",
       "   'title': 'Seven RAG Engineering Failure Points',\n",
       "   'subtitle': 'Retrieval-Augmented Generation (RAG) systems remains a compelling solution to the challenge of relevant up-to-date reference data at…',\n",
       "   'author': 'b0fbe613be9d',\n",
       "   'publication_id': '*Self-Published*',\n",
       "   'published_at': '2024-02-06 14:44:18',\n",
       "   'last_modified_at': '2024-02-06 14:44:18',\n",
       "   'tags': ['ai',\n",
       "    'artificial-intelligence',\n",
       "    'machine-learning',\n",
       "    'large-language-models',\n",
       "    'conversational-ai'],\n",
       "   'topics': ['machine-learning', 'programming'],\n",
       "   'claps': 211,\n",
       "   'voters': 18,\n",
       "   'word_count': 1429,\n",
       "   'responses_count': 0,\n",
       "   'reading_time': 6.092452830188679,\n",
       "   'url': 'https://cobusgreyling.medium.com/seven-rag-engineering-failure-points-02ead9cc2532',\n",
       "   'unique_slug': 'seven-rag-engineering-failure-points-02ead9cc2532',\n",
       "   'image_url': 'https://miro.medium.com/1*ZBt1IUgsv4fKMhWbQJkVqQ.png',\n",
       "   'lang': 'en',\n",
       "   'is_series': False,\n",
       "   'is_locked': False,\n",
       "   'is_shortform': False,\n",
       "   'top_highlight': '',\n",
       "   'content': {'id': '02ead9cc2532',\n",
       "    'content': 'Seven RAG Engineering Failure Points\\n\\nRetrieval-Augmented Generation (RAG) systems remains a compelling solution to the challenge of relevant up-to-date reference data at inference time. Integrating retrieval mechanisms with the generative capabilities of LLMs & RAG systems can synthesise accurate, up-to-date and contextually relevant information.\\n\\nRAG Advantages\\n\\nA Retrieval-Augmented Generation (RAG) system combines information retrieval capabilities with the generative prowess of LLMs.\\n\\nConsidering the image below, there are three distinct advantages to RAG which makes it such a compelling option.\\n\\nThe first is that RAG reduces LLM hallucination. Hallucination is when an LLM generates highly succinct, coherent, plausible and believable answers.\\n\\nHowever, these responses are factually incorrect; this approximation of LLMs to the truth can be remedied by leveraging the immense in-context learning abilities of LLMs. This is achieved by injecting prompts at inference with highly contextual reference data.\\n\\nThe second advantage of RAG is that source and reference data are linked to interactions and conversations. Hence RAG is an easy way to introduce organisation, enterprise or industry specific data, together with definitions, terms and more.\\n\\nThirdly, the process of chunking and indexing the reference data is very much an automated process hence no human annotation of data is required.\\n\\n\\n\\nRAG Challenges\\n\\nThe study states that validation of a RAG system is only feasible during operation and the robustness of a RAG system evolves rather than designed at the start.\\n\\nThis assumption is the traditional belief in terms of user intents; and that user intents needs to be discovered as the application is in use.\\n\\nI disagree strongly with this assumption, as the long tail of intent distribution can be successfully detected and addressed by leveraging the first two steps of NLU Design.\\n\\nRead more about NLU Design and solving for the long tail of intent distribution here:\\n\\nSolving For The Long Tail Of Intent Distribution\\nThe long tail of intent distribution can be successfully addressed by leveraging the first two steps of NLU Designcobusgreyling.medium.com\\n\\nRAG Architecture\\n\\nThe study contains a detailed RAG architecture. with the Index Process shown, and the Query Process. The Index Process takes place at design-time, also referred to as development time.\\n\\nThe query time is also known as inference time, or run-time, as shown on the second row.\\n\\nWhat I particularly like is the fact that mandatory elements of the RAG architecture is underlined, while optional elements are not. With this in mind, the process of chunking and creating a vector database entry (indexing/embedding) are mandatory. Together with the retriever and Reader.\\n\\nAdditional features adding a Reranker or a Consolidator or Rewriter add complexity, together with scalability and flexibility.\\n\\nSource\\n\\nThe Consolidator is responsible for processing the chunks, which is important to overcome limitations of large language models in terms of token and rate limits.\\n\\nReaders are responsible for filtering the noise from the prompt, complying to formatting templates and producing the output to return for the query.\\n\\nSeven Potential RAG Failure Points\\n\\n1️⃣ Missing Content\\n\\nFailure can occur while posing a question that cannot be addressed using the existing documents. In the favourable scenario, the RAG system will simply reply with a message such as \"Sorry, I don’t know.\" However, in cases where questions are relevant to the content but lack specific answers, the system might be misled into providing a response.\\n\\n2️⃣ Missed Top Ranked\\n\\nThe document contains the answer to the question but didn’t rank high enough to be presented to the user. In theory, all documents are ranked and considered for further processing. However, in practice, only the top K documents are returned, where the value of K is chosen based on performance metrics.\\n\\n3️⃣ Not In Context\\n\\nDocuments containing the answer were successfully retrieved from the database but were not included in the context used to generate a response.\\n\\nThis situation arises when multiple documents are retrieved from the database, and a consolidation process is employed to extract the answer.\\n\\n4️⃣ Wrong Format\\n\\nThe question required extracting information in a specific format, such as a table or list, yet the large language model disregarded this instruction.\\n\\n5️⃣ Incorrect Specificity\\n\\nThe response includes an answer, but it lacks the required specificity or is overly specific, failing to meet the user’s needs.\\n\\nThis situation arises when the designers of the Retrieval-Augmented Generation (RAG) system have a predetermined outcome for a given question, such as providing educational content for students.\\n\\nIn such cases, the response should include not only the answer but also specific educational materials. Incorrect specificity can also occur when users are uncertain about how to phrase a question and provide overly general queries.\\n\\n6️⃣ Not Extracted\\n\\nIn this scenario, the answer is within the context provided, but the large language model fails to accurately extract it. This usually happens when there is excessive noise or conflicting information within the context.\\n\\n7️⃣ Incomplete\\n\\nIncomplete answers are not necessarily incorrect but lack some information, even though it was present in the context and could have been extracted.\\n\\nFor instance, consider a question like \"What are the key points covered in documents A, B, and C?\" A more effective approach would be to ask these questions separately for each document to ensure comprehensive coverage.\\n\\nI need to mention that this scenario is solved for by a approach from LlamaIndex called Agentic RAG. Agentic RAG allows for a lower level agent tool per document, with a higher order agent orchestrating the agent tools.\\n\\nChunking\\n\\nChunking is a natural language processing technique used to group words or tokens together based on specific criteria, such as syntactic structure or meaning.\\n\\nIt involves dividing a sentence into segments, or \"chunks,\" that consist of one or more words and typically include a noun and its modifiers.\\n\\nChunking helps in identifying meaningful units of text, which can then be processed or analyzed further. This technique is commonly used in tasks like information extraction, named entity recognition, and shallow parsing.\\n\\nChunking documents may seem straightforward, but its quality significantly impacts the retrieval process, particularly concerning the embeddings of the chunks and their matching to user queries.\\n\\nTwo main approaches to chunking exist:\\n\\nheuristic-based, which relies on punctuation or paragraph breaks, and\\n\\nsemantic chunking, which uses text semantics to determine chunk boundaries.\\n\\nFurther research should delve into the tradeoffs between these methods and their impact on crucial downstream processes like embedding and similarity matching. Establishing a systematic evaluation framework to compare chunking techniques based on metrics such as query relevance and retrieval accuracy would greatly advance the field.\\n\\nEmbeddings\\n\\nEmbeddings represent a dynamic research area, encompassing the generation of embeddings for multimedia and multimodal chunks, such as tables, figures, and formulas.\\n\\nChunk embeddings are usually generated during system development or when indexing a new document. The preprocessing of queries plays a vital role in the performance of a Retrieval-Augmented Generation (RAG) system, especially in managing negative or ambiguous queries.\\n\\nFurther exploration is necessary on architectural patterns and approaches to tackle inherent limitations in embeddings, as the quality of a match is often domain-specific.\\n\\nIn Closing\\n\\nFor highly scaleable implementations the most appropriate approach seems to be something called Agentic RAG.\\n\\nThe topic of Agentic RAG explores how agents can be incorporated into existing RAG pipelines for enhanced, conversational search and retrieval.\\n\\nI’m currently the Chief Evangelist @ Kore AI. I explore & write about all things at the intersection of AI & language; ranging from LLMs, Chatbots, Voicebots, Development Frameworks, Data-Centric latent spaces & more.\\n\\nLinkedIn\\n\\nGet an email whenever Cobus Greyling publishes.\\nGet an email whenever Cobus Greyling publishes. By signing up, you will create a Medium account if you don’t already…cobusgreyling.medium.com\\n\\nSeven Failure Points When Engineering a Retrieval Augmented Generation System\\nSoftware engineers are increasingly adding semantic search capabilities to applications using a strategy known as…arxiv.org\\n\\nCorrective RAG (CRAG)\\nBy now, RAG is an accepted and well established standard for addressing data relevance for in-context learning. But…cobusgreyling.medium.com\\n\\nAdding Noise Improves RAG Performance\\nThis study’s findings suggest that including irrelevant documents can enhance performance by over 30% in accuracy…cobusgreyling.medium.com\\n\\nLLamaIndex Agentic RAG Demo\\nAgentic RAG is an agent based approach to perform question answering over multiple documents in an orchestrated…cobusgreyling.medium.com\\n\\nMultiHop-RAG\\nA recent direction in RAG architecture is establishing wider context via a process of orchestration and chains over…cobusgreyling.medium.com\\n\\nAgentic RAG With LlamaIndex\\nThe topic of Agentic RAG explores how agents can be incorporated into existing RAG pipelines for enhanced…blog.llamaindex.ai\\n\\nUniMS-RAG: Unified Multi-Source RAG for Personalised Dialogue\\nConsiderable development has taken place in the area of RAG, especially in adding structure and multi-document…cobusgreyling.medium.com'}},\n",
       "  {'id': 'f6f3c38656b9',\n",
       "   'title': 'OpenAI Agent Query Planning Using LlamaIndex',\n",
       "   'subtitle': 'Agentic RAG can be described as an agent based approach to perform question answering over multiple documents in an orchestrated fashion…',\n",
       "   'author': 'b0fbe613be9d',\n",
       "   'publication_id': '*Self-Published*',\n",
       "   'published_at': '2024-02-05 15:36:21',\n",
       "   'last_modified_at': '2024-02-05 15:36:21',\n",
       "   'tags': ['ai',\n",
       "    'artificial-intelligence',\n",
       "    'large-language-models',\n",
       "    'machine-learning',\n",
       "    'conversational-ai'],\n",
       "   'topics': ['programming'],\n",
       "   'claps': 46,\n",
       "   'voters': 9,\n",
       "   'word_count': 667,\n",
       "   'responses_count': 0,\n",
       "   'reading_time': 3.466981132075472,\n",
       "   'url': 'https://cobusgreyling.medium.com/openai-agent-query-planning-using-llamaindex-f6f3c38656b9',\n",
       "   'unique_slug': 'openai-agent-query-planning-using-llamaindex-f6f3c38656b9',\n",
       "   'image_url': 'https://miro.medium.com/1*JcQ5Nt-Rz1xBJjVYTTv4rw.png',\n",
       "   'lang': 'en',\n",
       "   'is_series': False,\n",
       "   'is_locked': False,\n",
       "   'is_shortform': False,\n",
       "   'top_highlight': '',\n",
       "   'content': {'id': 'f6f3c38656b9',\n",
       "    'content': 'OpenAI Agent Query Planning Using LlamaIndex\\n\\nAgentic RAG can be described as an agent based approach to perform question answering over multiple documents in an orchestrated fashion. Such an agent can synthesise responses from different documents, which can be summarised or various summaries can be compared.\\n\\nIntroduction\\n\\nHere I consider how a retrieval agent can be built by making use of the LlamaIndex framework and OpenAI.\\n\\nThis demo incorporates a Query Planning Tool and an OpenAI agent, this allows the agent to perform advanced planning based on a user query, all via a single agent.\\n\\nConsidering the header image, the Query Plan Tool rely on other tools for input.\\n\\nPDF Agent\\n\\nYou only need to have an OpenAI API Key as shown below, the code can be run within a Colab notebook.\\n\\nimport os\\nimport openai\\n\\nos.environ[\"OPENAI_API_KEY\"] = \"Your api key goes here\"\\n\\nIn this example, a very clear and concise method is followed, three PDF documents are downloaded:\\n\\n!mkdir -p \\'data/10q/\\'\\n!wget \\'https://raw.githubusercontent.com/run-llama/llama_index/main/docs/examples/data/10q/uber_10q_march_2022.pdf\\' -O \\'data/10q/uber_10q_march_2022.pdf\\'\\n!wget \\'https://raw.githubusercontent.com/run-llama/llama_index/main/docs/examples/data/10q/uber_10q_june_2022.pdf\\' -O \\'data/10q/uber_10q_june_2022.pdf\\'\\n!wget \\'https://raw.githubusercontent.com/run-llama/llama_index/main/docs/examples/data/10q/uber_10q_sept_2022.pdf\\' -O \\'data/10q/uber_10q_sept_2022.pdf\\'\\n\\nThe data is loaded:\\n\\nmarch_2022 = SimpleDirectoryReader(\\n   input_files=[\"./data/10q/uber_10q_march_2022.pdf\"]\\n).load_data()\\njune_2022 = SimpleDirectoryReader(\\n    input_files=[\"./data/10q/uber_10q_june_2022.pdf\"]\\n).load_data()\\nsept_2022 = SimpleDirectoryReader(\\n    input_files=[\"./data/10q/uber_10q_sept_2022.pdf\"]\\n).load_data()\\n\\nAnd the vector index and query engine is created for each of the documents (March, June, September).\\n\\nmarch_index = GPTVectorStoreIndex.from_documents(march_2022)\\njune_index = GPTVectorStoreIndex.from_documents(june_2022)\\nsept_index = GPTVectorStoreIndex.from_documents(sept_2022)\\n\\nmarch_engine = march_index.as_query_engine(\\n    similarity_top_k=3, service_context=service_context\\n)\\njune_engine = june_index.as_query_engine(\\n    similarity_top_k=3, service_context=service_context\\n)\\nsept_engine = sept_index.as_query_engine(\\n    similarity_top_k=3, service_context=service_context\\n)\\n\\n\\n\\nBelow the query tools are defined, with the query engine name and description.\\n\\nfrom llama_index.tools import QueryEngineTool\\n\\n\\nquery_tool_sept = QueryEngineTool.from_defaults(\\n    query_engine=sept_engine,\\n    name=\"sept_2022\",\\n    description=(\\n        f\"Provides information about Uber quarterly financials ending\"\\n        f\" September 2022\"\\n    ),\\n)\\nquery_tool_june = QueryEngineTool.from_defaults(\\n    query_engine=june_engine,\\n    name=\"june_2022\",\\n    description=(\\n        f\"Provides information about Uber quarterly financials ending June\"\\n        f\" 2022\"\\n    ),\\n)\\nquery_tool_march = QueryEngineTool.from_defaults(\\n    query_engine=march_engine,\\n    name=\"march_2022\",\\n    description=(\\n        f\"Provides information about Uber quarterly financials ending March\"\\n        f\" 2022\"\\n    ),\\n)\\n\\nAnd here the query plan is defined…\\n\\n# define query plan tool\\nfrom llama_index.tools import QueryPlanTool\\nfrom llama_index import get_response_synthesizer\\n\\nresponse_synthesizer = get_response_synthesizer(\\n    service_context=service_context\\n)\\nquery_plan_tool = QueryPlanTool.from_defaults(\\n    query_engine_tools=[query_tool_sept, query_tool_june, query_tool_march],\\n    response_synthesizer=response_synthesizer,\\n)\\n\\nUsing The Agent\\n\\nThe agent is asked the question, Analyze Uber revenue growth in March, June, and September .\\n\\nThe agent knows to extract information for March, June and September from the respective tools.\\n\\n- In March 2022, Uber\\'s revenue was $6.854 billion.\\n- For the three months ended June 30, 2022, Uber\\'s revenue was $8,073 million (or $8.073 billion). However, we do not have the specific revenue for June 2022.\\n- For the three months ended September 30, 2022, Uber\\'s revenue was $8.343 billion.\\n\\nFrom this information, we can observe that Uber\\'s revenue has been growing \\nbetween the periods mentioned. The revenue increased from $6.854 billion in \\nMarch 2022 to $8.073 billion for the three months ended June 2022, \\nand further increased to $8.343 billion for the three months ended \\nSeptember 2022. However, we cannot provide a month-by-month analysis for \\nJune and September as the specific monthly revenue figures are not available.\\n========================\\n\\nAnd a final answer is synthesised by the agent:\\n\\nIn summary, Uber experienced significant revenue growth of 17.8% between \\nthe three-month periods ending in March and June, followed by a smaller \\ngrowth of 3.3% between the periods ending in June and September.\\n\\nThe complete executed example code can be found here.\\n\\n⭐️ Follow me on LinkedIn for updates on Large Language Models ⭐️\\n\\n\\n\\nI’m currently the Chief Evangelist @ Kore AI. I explore & write about all things at the intersection of AI & language; ranging from LLMs, Chatbots, Voicebots, Development Frameworks, Data-Centric latent spaces & more.\\n\\n\\n\\nLinkedIn\\n\\n\\n\\nGet an email whenever Cobus Greyling publishes.\\nGet an email whenever Cobus Greyling publishes. By signing up, you will create a Medium account if you don’t already…cobusgreyling.medium.com\\n\\nOpenAI Agent Query Planning - LlamaIndex 🦙 0.9.40\\nIn this demo, we explore adding a QueryPlanTool to an OpenAIAgent . This effectively enables the agent to do advanced…docs.llamaindex.ai\\n\\nLlamaIndex/OpenAI_Agent_PDF_Query_Planner.ipynb at main · cobusgreyling/LlamaIndex\\nLlamaIndex Notebooks. Contribute to cobusgreyling/LlamaIndex development by creating an account on GitHub.github.com'}}],\n",
       " '14176fcb5743': [{'id': '6921c4f43c2a',\n",
       "   'title': 'Midjourney V6 New Prompting Technique\\u200a—\\u200aIntroduction to “The 4W1H” 🎨',\n",
       "   'subtitle': 'Elevate Your Prompt Writing Structure & Skills',\n",
       "   'author': '14176fcb5743',\n",
       "   'publication_id': '48e972f5c24e',\n",
       "   'published_at': '2023-12-27 13:01:24',\n",
       "   'last_modified_at': '2024-01-24 02:48:22',\n",
       "   'tags': ['midjourney',\n",
       "    'artificial-intelligence',\n",
       "    'creativity',\n",
       "    'design',\n",
       "    'art'],\n",
       "   'topics': ['design'],\n",
       "   'claps': 2487,\n",
       "   'voters': 382,\n",
       "   'word_count': 1369,\n",
       "   'responses_count': 25,\n",
       "   'reading_time': 6.666037735849057,\n",
       "   'url': 'https://bootcamp.uxdesign.cc/midjourney-v6-new-prompting-technique-introduction-to-the-4w1h-6921c4f43c2a',\n",
       "   'unique_slug': 'midjourney-v6-new-prompting-technique-introduction-to-the-4w1h-6921c4f43c2a',\n",
       "   'image_url': 'https://miro.medium.com/1*2QvnFaQZQzbV04MAZcfUJQ.png',\n",
       "   'lang': 'en',\n",
       "   'is_series': False,\n",
       "   'is_locked': True,\n",
       "   'is_shortform': False,\n",
       "   'top_highlight': 'By breaking down the elements of your artwork into What, Who, When, Where, and How, you will assist Midjourney in gaining a deeper understanding of your creative thoughts.',\n",
       "   'content': {'id': '6921c4f43c2a',\n",
       "    'content': 'Midjourney V6 Prompting Made Simple- Introducing the \"4W1H\" Method 🎨\\n\\nElevate Your Prompt Writing Structure & Skills\\n\\nHello, everyone! I recently returned from my holiday and I hope you all had a wonderful Christmas🎄🎅🏻❤️\\n\\nAs some of you may be aware, the latest Midjourney v6 has an improved method for understanding prompts, eliminating the need for random phrases and words. This will require a new approach to creating prompts.\\n\\nI know it can be overwhelming to start or improve your art with so much information out there. That’s why I’m here to show you a simple technique to kickstart your Midjourney creation - The 4W1H Technique. ✨\\n\\nIt’s super beginner-friendly and will help you improve your Midjourney art over time.\\n\\n\\n\\nMidjourney\\n\\nMidjourney’s AI Art Generative Tool is a remarkable game-changer for unleashing your creative potential! This fantastic technology uses artificial intelligence and machine learning to help you easily create stunning visuals.\\n\\nIf you are just starting, I know it’s challenging to craft the perfect prompt. So, here is a beginner’s guide and list of prompts to get you started:\\n\\nMidjourney Comprehensive Guide: Commands, Features and Tricks here!\\nHow to Use Midjourney Elevate Your Images and Creativitybootcamp.uxdesign.cc\\n\\n20+ Incredible Midjourney Prompts You Must Try!\\nElevate Your AI Arts with These Creative Promptsbootcamp.uxdesign.cc\\n\\n\\n\\nThe 4W1H Technique\\n\\nBy breaking down the elements of your artwork into What, Who, When, Where, and How, you will assist Midjourney in gaining a deeper understanding of your creative thoughts.\\n\\nLet’s explore how you can use this technique to bring your artistic visions to life!\\n\\nPart One: Breakdown of 4W1H\\n\\nPart Two: Use Case\\n\\nPart Three: Commercial Usage\\n\\n\\n\\nPart One: Breakdown of 4W1H\\n\\nThe 4W1H refer to:\\n\\nWhat - Type/Art Style/Category of image\\n\\nWho - Main Subject/Theme\\n\\nWhere - Scene/Settings\\n\\nWhen - Time/Lighting\\n\\nHow - Style & Rendering & Details\\n\\nBelow is a breakdown of the 4W1H technique\\n\\n🎨 What - Type of Image\\n\\nSpecify the overall type of image first to ensure consistent style. This can include providing a specific aesthetic or artistic direction, such as:\\n\\nArt Style: Baroque, Impressionist, Renaissance, Abstract, Surrealism\\n\\nArt Medium - Charcoal, Pencil, Pastel, Watercolor, Oil painting, etc\\n\\nMaterial texture - Metal, Fabric, Wood, Marble, Glass, etc\\n\\nPhotography type - Candid, Black and White, Landscape, Portrait, Full Body, Wide angle etc\\n\\nWhat can also be a category like:\\n\\nCategory: Photographic Image, UI Design, Interior Design, Logo Design,\\n\\n✨ Who - Main Subject/Theme\\n\\nThe main subject is what the image is focused on. It can be a person, animal, character, object, etc.\\n\\nYou can also add secondary subjects.\\n\\nExamples:\\n\\nMain - A beautiful girl\\n\\nSecondary - With brown hair, in Christmas dress, luxurious attire\\n\\nSubjects can also be landscapes, objects etc.\\n\\n🌎 Where - Scene/Settings\\n\\nDescribe the setting or background. Generic terms like \"epic scene\" also work if you can’t decide.\\n\\nEnvironment can also be indoors, outdoors, ocean landscape, outer space, in New York\\n\\n🕰 When - Time/Lighting\\n\\nSpecify a time of day, season, year, historical period, etc.\\n\\nTime: 1980s, Jurassic period, springtime, Christmas, etc\\n\\nLighting: Blue hours, Morning, golden hours, sunset, nighttime, natural light, studio light\\n\\n🎨 How - Style/Rendering/ Extra Details\\n\\nThis covers the stylistic qualities of the image. Key elements:\\n\\nArt Style - Artists, studios, art movements, etc\\n\\n3D Style - 3D, VFX, game engines, etc\\n\\nColor: vibrant, muted, bright, monochromatic, colorful, black and white, pastel, etc.\\n\\nLighting: soft, ambient, overcast, cinematic, studio lights, etc\\n\\nMood: happy, calm, energetic, etc.\\n\\nRendering Style - Ray tracing, ambient occlusion, etc\\n\\nFocus on the terms most relevant to your image type. For beginners, start simple without too many advanced terms.\\n\\n\\n\\nPart Two: Putting It All Together\\n\\nNow, let’s apply the 4W1H framework and explore how we can utilize it in prompt writing\\n\\nExample One: A Portrait\\n\\nPrompt: A portrait of a beautiful lady with brown long hair and a white dress, standing in front of the sea, blue hour, soft color\\n\\nBreaking this down:\\n\\nWhat - A portrait\\n\\nWho - A beautiful lady with brown long hair and a white dress\\n\\nWhere - Standing in front of the sea\\n\\nWhen - Blue hour\\n\\nHow - Soft color\\n\\n\\n\\nExample Two: Wildlife Photography\\n\\nPrompt: Wildlife photography, a furry cute bunny in winter woods, sunset, cinematic lighting\\n\\nBreaking this down:\\n\\nWhat - Wildlife photography\\n\\nWho - A cute furry bunny\\n\\nWhere - In Winter Woods\\n\\nWhen - Sunset\\n\\nHow - Cinematic Lighting\\n\\n\\n\\n2W1H- Painting\\n\\nIt is not necessary to use every \"W\"s. Alternatively, you can also omit \"When\" and \"Where\" like this example below\\n\\nPrompt: Romanticism art style painting, birds and flowers, pastel color\\n\\nBreaking this down:\\n\\nWhat - Romanticism art style painting\\n\\nWho - Birds and flowers\\n\\nHow - Pastel color\\n\\n\\n\\nPart Three: Commercial Usage- Category\\n\\nLet’s look at how we can use the 4W1H technique for commercial\\n\\nUI Design\\n\\nPrompt: UI design of botanical plants shop, landing page, minimal, classy, beige and navy green --ar 4:3\\n\\n\\n\\nPackage Design\\n\\nPrompt: Package design of botanical plants shop, minimal, classy, beige and navy green --ar 4:3\\n\\n\\n\\nLogo Design\\n\\nPrompt: Logo design of botanical plants shop, minimal, classy, beige and navy green --ar 4:3\\n\\n\\n\\nBreaking this down:\\n\\nWhat - UI Design/ Package Design/ Logo Design\\n\\nWho - Botanical plants shop\\n\\nHow- Minimal, classy, beige and navy green\\n\\nAs you can see, basically, you just need to replace the first word in every prompt with the category\\n\\n[ Industry / Category ] design of [ subject/ product ], [ How - description, style ]\\n\\nInterior Design - Pantone 2024\\n\\nLet’s adopt this formula and create one more with 2024 Pantone Color- Peach Fuzz\\n\\nPrompt: Interior design of coffee shop, minimal, soft peach pantone color--ar 4:3\\n\\n\\n\\nMore Prompt Ideas with the 2024 Pantone Color can be found here:\\n\\n25 Incredible Midjourney Prompts with 2024 Pantone Color - Peach Fuzz 🍑\\nWith Commercial Usage and Visual Inspirationsbootcamp.uxdesign.cc\\n\\nFinal Thoughts\\n\\nThe 4W1H technique is a method I developed specifically for Midjourney V6. It is suitable for beginners to get started and can help you master Midjourney over time.\\n\\nBy mastering this trick, you can easily tweak the components of prompts. Changing the main subject, material, style or era is simple once you know the framework.\\n\\nThe key is to start simple and gain experience through practice. As you create more images, your prompting skills will improve until you develop your intuitive style.\\n\\n📌 Midjourney V6 Essentials: Insider Tips and Prompting Skills\\n\\nBe sure to save this list and never miss any tips on Midjourney V6.\\n\\nMidjourney V6 Essentials\\nEdit descriptionmedium.com\\n\\n\\n\\n👉🏻Passive Income with AI art: Master Midjourney 🎨\\n\\nDon’t Get Left Behind in the AI Art Gold Rush of 2024! Midjourney is exploding. Early adopters are raking in big bucks selling AI art online.\\n\\nThis is your ticket to passive income with AI art.💰- \"Master Midjourney 2024: Beginner to Pro\" digital guide.\\n\\nIt comes with:\\n\\n🎨 1,000+ money-making prompts for stunning, sellable art\\n\\n💡 Advanced Midjourney prompt writing, structure and techniques\\n\\n🖼 Specialized commercial guidance for graphic design, branding, logo, UI, photography, mockup and more\\n\\n🚀 Insider tips to maximize profits\\n\\n💰 AI Arts Monetisation Strategies\\n\\n💼 Top AI tools to edit Midjourney creations\\n\\n\\n\\n📚 Continuous education\\n\\nThis guide is designed for continuous education, new tutorials are added regularly so you stay ahead. With lifetime access for a single purchase, it’s the gift that keeps giving.\\n\\nI’ve poured my heart into creating this guide. I hope you enjoy it ❤️\\n\\nBecome My Creative Partner 😊 🤝\\n\\nLastly, I want to call all creative partners in crime! I’m looking for affiliate partners who want to earn commissions by sharing my Midjourney Guide.\\n\\nAs an affiliate, you’ll get a unique link. Just share your link however you like - email, social media, your website, etc. When someone buys through your link, you’ll receive **10% commission**of the sale!\\n\\n\\n\\nHey, Friends 👋 I am Christie— An AI Art Educator & Creator 😊 Also a coffee lover❤️☕️\\n\\nIf you’re craving more Insider Tips, Prompts and Tricks for creating and generating income with AI art, join me on this journey.\\n\\n🎨 Hit that \"Follow\" button to stay in the loop for more AI wisdom\\n💌 Stay tuned for more tutorials!\\n\\nLet’s explore the limitless possibilities of AI and build passive income together! 🚀'}},\n",
       "  {'id': 'b467aa07365e',\n",
       "   'title': '9 Midjourney V6. Prompting Technique You Need to Know 🎨',\n",
       "   'subtitle': 'Relearn Prompt Writing to Take Your AI Art to the Next Level!',\n",
       "   'author': '14176fcb5743',\n",
       "   'publication_id': '48e972f5c24e',\n",
       "   'published_at': '2024-01-19 13:01:48',\n",
       "   'last_modified_at': '2024-02-12 10:11:21',\n",
       "   'tags': ['midjourney',\n",
       "    'artificial-intelligence',\n",
       "    'creativity',\n",
       "    'design',\n",
       "    'art'],\n",
       "   'topics': ['artificial-intelligence', 'design', 'programming'],\n",
       "   'claps': 1143,\n",
       "   'voters': 132,\n",
       "   'word_count': 1887,\n",
       "   'responses_count': 10,\n",
       "   'reading_time': 9.070754716981131,\n",
       "   'url': 'https://bootcamp.uxdesign.cc/9-midjourney-v6-prompting-technique-you-need-to-know-b467aa07365e',\n",
       "   'unique_slug': '9-midjourney-v6-prompting-technique-you-need-to-know-b467aa07365e',\n",
       "   'image_url': 'https://miro.medium.com/1*EgyE5HYnjwDhLjJR04NPcw.png',\n",
       "   'lang': 'en',\n",
       "   'is_series': False,\n",
       "   'is_locked': True,\n",
       "   'is_shortform': False,\n",
       "   'top_highlight': '',\n",
       "   'content': {'id': 'b467aa07365e',\n",
       "    'content': '9 Midjourney V6. Prompting Technique You Need to Know 🎨\\n\\nRelearn Prompt Writing to Take Your AI Art to the Next Level!\\n\\nWith the latest Midjourney V6, we can make some cool pictures, almost like real life. But making these pictures might need a different way of prompting to help.\\n\\nThe new Midjourney V6 understands things more like a person, which is both an excellent thing and a bit tricky.\\n\\nPreviously, I introduced the \"4W1H\" Technique and \"Text Generating Pro Tips\" in structuring your prompt. Today, I am sharing more tricks and tips to note when writing prompts with Midjourney V6.\\n\\nLet’s get started!\\n\\n\\n\\nMidjourney\\n\\nMidjourney’s AI Art Generative Tool is a remarkable game-changer for unleashing your creative potential! This fantastic technology uses artificial intelligence and machine learning to help you easily create stunning visuals.\\n\\nIf you are just starting, I know crafting the perfect prompt is challenging. So, here is a beginner’s guide and list of prompts to get you started:\\n\\nMidjourney Comprehensive Guide: Commands, Features and Tricks here!\\nHow to Use Midjourney Elevate Your Images and Creativitybootcamp.uxdesign.cc\\n\\n20+ Incredible Midjourney Prompts You Must Try!\\nElevate Your AI Arts with These Creative Promptsbootcamp.uxdesign.cc\\n\\n\\n\\nV6 is a Revolution in Midjourney Prompting\\n\\nV6 utilizes natural language and has significantly increased memory for each /imagine compared to previous versions. This allows for\\n\\nLonger and more detailed prompts\\n\\nAbility to control composition, include multiple subjects and add text\\n\\n👉🏻 V6 Essentials\\n\\nI’ve compiled a list of tips and prompts specifically for Midjourney V6. Save this list to stay updated on the latest tutorials !\\n\\nMidjourney V6 Essentials\\nEdit descriptionmedium.com\\n\\nExploring V6’s Language Processing Capabilities ✨\\n\\nLet’s first explore how V6 is different from the old version, V5.2, and see how it helps you make super accurate and awesome AI-generated arts.\\n\\nHere are the six key takeaways regarding the changes:\\n\\n1. Reduced Sensitivity to Redundant Words: V6 is now less likely to be affected by filler words or non-descriptive language\\n\\n2. Natural Language: V6 can process more natural, conversational prompts, shifting from keyword-centric language.\\n\\n3. Refined Interpretation of Complex Prompts: Greater coherence in interpreting prompts with multiple subjects, actions, and settings, enabling more layered and narrative-driven images.\\n\\n4. Better Text Generation Capability: V6 has an enhanced ability to incorporate specific text into images.\\n\\n5. Longer Prompts: In the previous version, emphasis was placed on Words 1–5, but longer prompts of 40+ words were often overlooked. With V6, the system can now understand longer prompts (350+ words).\\n\\n6. Prompt Multiple Objects: V6 shows much more control and clarity. By following the right structure, you can prompt multiple objects easily.\\n\\n\\n\\nCrafting Effective V6 Prompts 🎨\\n\\nCrafting effective Midjourney V6 prompts requires a clear and vivid description in natural language. You can focus your prompt with:\\n\\nDescriptive Vocabulary\\n\\nSpatial Relationships\\n\\nExplicit Style\\n\\nAvoid overloading prompts with unnecessary information or non-descriptive filler words.\\n\\nTo turn it on select V6 from the dropdown menu under /settings or type --v 6 after your prompt\\n\\n\\n\\n\\n\\nHere are Nine Skills to prompt with Midjourney V6\\n\\n1. Simplify Prompting\\n\\nBe specific about your preferences, as V6 has improved natural language understanding. Simplify prompts by removing unnecessary \"fluff\" words that don’t add value.\\n\\nV6 understands requests more naturally without exaggerated descriptors.\\n\\nI recommend using The \"4W1H\" Technique that I recently talked about if you are not sure how to begin.\\n\\nMidjourney V6 New Prompting Technique - Introduction to \"The 4W1H\" 🎨\\nElevate Your Prompt Writing Structure & Skillsbootcamp.uxdesign.cc\\n\\nHere is one example that follows the \"4W1H\" Technique\"\\n\\nPrompt: A portrait of a beautiful lady in brown long hair and white dress, standing in front of the sea, blue hour, soft color\\n\\n\\n\\n📌 Most important change might be to strive to write in simple sentences of English that have good spelling and punctuation.\\n\\n2. Use Raw Style for Photorealistic Images\\n\\nWhen using styles and options, use \"--style raw\" for more photorealistic images.\\n\\nPre-wedding photo\\n\\nPrompt: A pre-wedding photo of a couple on a motorbike taken in the New York street with neon light --ar 16:9 --style raw --v 6\\n\\n\\n\\nPortrait\\n\\nPrompt: A portrait of a beautiful lady in brown long hair and white dress, standing in front of the sea during blue hour, soft color --ar 16:9 --v 6\\n\\n\\n\\nFood Photography\\n\\nPrompt: Food photography of grilled chicken stew on the bbq rack with flames and sparks--ar 16:9 --style raw --v 6\\n\\n\\n\\n3. Using \"--stylize\"\\n\\nAdjust \"stylize\" values to enhance prompt understanding or aesthetics (default is 100, adjustable up to 1000).\\n\\n(Image on the Left): Rococo art art style painting of birds and flowers painted with pastel color --v 6 --stylize 100\\n\\n(Image on the Right): Rococo art art style painting of birds and flowers painted with pastel color --v 6 --stylize 1000\\n\\n\\n\\n4. Control Composition of Multiple Objects\\n\\nWith V6, we can now have a higher control over composition. You can place things where you want on the canvas, using language to control composition. (e.g., \"on the left,\" \"in the background\").\\n\\nIt supports the control of more than one subject or object now.\\n\\nSpiderman, Captain America and Ironman\\n\\nThree popular superheroes standing on New York City. The hero on the left is an optimistic Spiderman in a strong wide stance. The hero in the middle is brave Captain America holding his shield high. The hero on the right is powerful Ironman with his suit. It is raining in the street at night. Photography inspired by Marvel film poster--v 6\\n\\n\\n\\nFood Photography\\n\\nPrompt: Food Photography of a creamy tomato soup. The tomato soup comes with a swirl of fresh cream sitting in the middle of the table, topped with crispy croutons and a sprinkle of basil, a bowl of fresh tomato on the left, herbs on the right. High angle shot inspired by editorial food photography.--v 6\\n\\n\\n\\n💡 The key to prompting multiple subjects in V6 is giving Midjourney a clear semantic link between the overall scene and the individual details.\\n\\nV6 doesn’t require any special prompting, but a starter template suggested by Midjourney will help you explore what works well for multiple subjects in V6.\\n\\nHere, I share a prompt structure for you to follow:\\n\\nMidjourney V6 Essential: Prompting Multiple Subjects\\nA Structure to follow with Visual Examples and Usagebootcamp.uxdesign.cc\\n\\n5. Descriptive Language\\n\\nUtilize visually descriptive adverbs and adjectives to convey the desired style and mood.\\n\\nAvoid cluttering prompts with excessive information or non-descriptive filler words such as \"amazing\" and \"incredible\" as they do not contribute to the visual description.\\n\\nBe deliberate.\\n\\nPrompt: Photo of a young handsome man in a suit with a cup of coffee in his hands sitting at a table, shot through an outdoor window of a coffee shop with neon sign lighting, window glares and reflections, depth of field, raining outside at night --ar 16:9 --v 6\\n\\n\\n\\nPrompt: Half shot of a beautiful woman with brown long hair and white shirt siting beside the window in a cafe in the afternoon, with high-contrast and a moody blue color grade --ar 16:9 --v 6\\n\\n\\n\\n6. Referencing Art, Design, and Culture\\n\\nIf you have a particular artistic style or theme in mind, please describe it clearly.\\n\\nYou can also provide references to artists, art movements, design movements, photography styles, cultures, ethnicities, etc. to help guide the AI in creating the desired content like \"Inspired by Vincent Van Gogh\" or \" Baroque Art Style\"\\n\\nLet’s look at this example below and see how the reference to artists can make a difference.\\n\\nPainting of Bookstore Inspired by Different Artists\\n\\nPrompt: A painting of a boutique bookstore in Paris street, inspired by [ Vincent Van Gogh/ Leonardo da Vinci/ Pablo Picasso/ Studio Ghibli ] --v 6\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nFor more art style inspiration, refer to this article below:\\n\\n20+ Incredible Midjourney Prompts to Create Wall Art that Sells!\\nComes with Visual Examples and Tips for Creating Stunning Mockups for Your Masterpiecebootcamp.uxdesign.cc\\n\\n7. Text Incorporation\\n\\nV6 has an enhanced ability to incorporate specific text into images. Simply by enclosing it in \"quotation marks\" and indicating its placement.\\n\\nUse phrases like: says, printed on, entitled, inscribed with, labeled as, marked with, branded with, embossed with, engraved with, stamped with, adorned with, scripted with, lettered with, etc.\\n\\nYou can also print text on things, suchspeech bubble, post-it note, book cover, poster, sign, t-shirt, mug, billboard, newspaper, magazine, greeting card, envelope, license plate, calendar, ticket, product packaging, business card, etc.\\n\\nTo have text or letters appear alone, it sometimes helps to add the phrase typography design to the prompt. You can explore using phrases isolated on a white background if you’d like the canvas to be otherwise blank.\\n\\nHappy 2024\\n\\nPrompt: High fashion photo of a futuristic girl wearing a glasses engraved with the text \"Happy 2024\" --style raw --v 6\\n\\n\\n\\nTake Action\\n\\nPrompt: Text \"Take Action\" in 3D isometric letter shape with neon light tube --style raw --v 6\\n\\n\\n\\n👉🏻Top Tips for Text Generation\\n\\nI have written an article, especially for prompting text with Midjourney V6, learn more about it here:\\n\\nMidjourney V6 Text Generation Made Easy: 7 Pro Tips to Try 🎨\\nGetting Crisp, Accurate Text with Midjourney V6bootcamp.uxdesign.cc\\n\\n8. Avoiding Vague Words\\n\\nAvoid vague words that are weaker contributors:\\n\\nextra, ultra, super, hyper, insanely, extremely, quite, rather, somewhat, notably, especially, significantly, remarkably\\n\\nindeed, forthwith, moreover, henceforth, furthermore, nevertheless, nonetheless, thereby, heretofore, thusly\\n\\nuntil, before, after, since, while, during, till, throughout, upon, whenever\\n\\nAvoid using unnecessary words that were previously thought to improve image quality, such as\\n\\n4k, 6k, 8k, 16k, ultra 4k, octane, unreal, v-ray, lumion, renderman, hd, hdr, hdmi, high-resolution, dp, dpi, ppi, 1080p\\n\\n9. Natural Language and Grammar\\n\\nCommunicate with V6 using clear and simple language\\n\\nPay attention to grammar and punctuation to avoid misunderstandings in image generation.\\n\\n\\n\\nFinal Thoughts\\n\\nMidjourney V6 prompting rewards specificity, visual descriptors, and clear communication. Simpler and more direct language produces better results than exaggerated prompts.\\n\\nWith practice in prompt structure and word choice, you can guide V6 to generate stunning creations that precisely match your creative vision.\\n\\n\\n\\nPassive Income with AI Art: Master Midjourney 🎨\\n\\nDon’t Get Left Behind in the AI Art Gold Rush of 2024! Are you ready to join the gold rush and turn your creativity into profit?\\n\\n👉🏻Your ticket to passive income with AI art.💰\\n\"Master Midjourney 2024: Beginner to Pro\" digital guide.\\n\\nIt comes with:\\n\\n🎨 1,000+ Prompts: Generate stunning, sellable art\\n\\n💻 Top Tutorials to Master Midjourney FAST\\n\\n🖼 Commercial Use Case Mastery\\n\\n💡 Advanced Midjourney prompt writing & expert tips\\n\\n🚀 Expert Insider Tips to maximize profits\\n\\n💰 Monetisation Strategies\\n\\n\\n\\n📚 Continuous education\\n\\nThis guide is designed for continuous education, new tutorials are added regularly so you stay ahead. With lifetime access for a single purchase, it’s the gift that keeps giving.\\n\\nI’ve poured my heart into creating this guide. I hope you enjoy it ❤️\\n\\n\\n\\nHey friends 👋 I am Christie - An AI Art Educator & Creator 😊 Also a coffee lover ❤️☕️\\n\\nIf you’re craving more Insider Tips, Prompts and Tricks for creating and generating income with AI art, join me on this journey.\\n\\n🎨 Hit that \"Follow\" button to stay in the loop for more AI wisdom\\n💌 Stay tuned for more tutorials!\\n\\nLet’s explore the limitless possibilities of AI Art and build passive income together! 🚀💰'}},\n",
       "  {'id': '5afc5b228cb3',\n",
       "   'title': 'One Magical Midjourney Prompt to Elevate Your Creativity!',\n",
       "   'subtitle': 'Level Up Your AI Image with this One Word',\n",
       "   'author': '14176fcb5743',\n",
       "   'publication_id': '48e972f5c24e',\n",
       "   'published_at': '2023-11-13 13:02:01',\n",
       "   'last_modified_at': '2023-12-19 09:34:03',\n",
       "   'tags': ['midjourney',\n",
       "    'artificial-intelligence',\n",
       "    'creativity',\n",
       "    'design',\n",
       "    'art'],\n",
       "   'topics': ['design'],\n",
       "   'claps': 830,\n",
       "   'voters': 85,\n",
       "   'word_count': 1186,\n",
       "   'responses_count': 14,\n",
       "   'reading_time': 6.225471698113208,\n",
       "   'url': 'https://bootcamp.uxdesign.cc/one-magical-midjourney-prompt-to-elevate-your-creativity-5afc5b228cb3',\n",
       "   'unique_slug': 'one-magical-midjourney-prompt-to-elevate-your-creativity-5afc5b228cb3',\n",
       "   'image_url': 'https://miro.medium.com/1*9LYsteVtPZ629V14eYA17A.png',\n",
       "   'lang': 'en',\n",
       "   'is_series': False,\n",
       "   'is_locked': True,\n",
       "   'is_shortform': False,\n",
       "   'top_highlight': 'Prompt: [ People ], picking a [ Food ], bright studio light, [ Color ] background, minimalist, miniature food photography, soft color blending --ar 3:4',\n",
       "   'content': {'id': '5afc5b228cb3',\n",
       "    'content': 'One Magical Midjourney Prompt to Elevate Your Creativity!\\n\\nLevel Up Your AI Image with this One Word\\n\\nWorking with Midjourney AI is a fascinating experience. It has limitless potential! The best way to gain an understanding of how it’s done is to take a look at what others have done and learn from them.\\n\\nDon’t worry if you’re a little confused about how to create a strong text prompt - I’m here to help!\\n\\nToday, I am going to share with you One Magical Word that I like to use to enhance the creativity of the images, especially for poster design.\\n\\n\\n\\nMidjourney\\n\\nMidjourney’s AI Art Generative Tool is a revolutionary and powerful AI program that unleashes your creativity and helps you generate beautiful visuals with the help of artificial intelligence and machine learning.\\n\\nFollow this comprehensive guide to Midjourney if you are just starting:\\n\\nMidjourney Comprehensive Guide: Commands, Features and Tricks here!\\nHow to Use Midjourney Elevate Your Images and Creativitybootcamp.uxdesign.cc\\n\\nCrafting the perfect prompt is key to getting the most out of Midjourney AI art generation. The right words can take your designs to the next level. One simple but powerful prompt I recommend adding to your toolbox is \"miniature.\"\\n\\nUsing \"miniature\" in your Midjourney prompts can instantly give your art an eye-catching, mesmerizing quality.\\n\\nLet’s see what I got today!\\n\\n1. Miniature Food Photography\\n\\nMiniaturized art intrigues viewers by presenting familiar subjects or scenes from an unexpected vantage point.\\n\\nPrompt: [ People ], picking a [ Food ], bright studio light, [ Color ] background, minimalist, miniature food photography, soft color blending --ar 3:4\\n\\nFor color, I usually pick the color of the food to make it more coherent.\\n\\n\\n\\nStrawberry\\n\\nFour workers picking a strawberry, bright studio light, pink background, minimalist, miniature food photography, soft color blending --ar 3:4\\n\\n\\n\\nPumpkin\\n\\nThree workers picking a pumpkin, bright studio light, orange background, minimalist, miniature food photography, soft color blending --ar 3:4\\n\\n\\n\\nLettuce\\n\\nFour workers picking a lettuce, bright studio light, green background, minimalist, miniature food photography, soft color blending --ar 3:4\\n\\n\\n\\nTomato\\n\\nFour workers picking a tomato, bright studio light, red background, minimalist, miniature food photography, soft color blending --ar 3:4\\n\\n\\n\\nThis is great for promoting or introducing fresh ingredients for your dishes or restaurant. It will surely make your product stand out!\\n\\nCustomize Your Graphic\\n\\nAfter crafting your Midjourney images, take the graphics to software like Canva and add any necessary information for your project.\\n\\nBy creating something different from general expectations, a miniature perspective gives the audience a completely new visual experience. It adds layers of novelty and imagination to your Midjourney creations.\\n\\n\\n\\n2. Miniature Food Scenery\\n\\nTo add a bit more fun and creativity, try creating an image with your food building your backdrop scenery\\n\\nThe outcome is a captivating miniature world filled with intricate details.\\n\\nPrompt: Miniature Scenery of a miniature [ characters ] playing in [ food ], intricate details, hyper realistic--ar 3:4\\n\\n\\n\\nHamburger\\n\\nPrompt: Miniature Scenery of a miniature people playing in a double cheese hamburger, intricate details, hyper realistic--ar 3:4\\n\\n\\n\\nStrawberry Cheesecake\\n\\nPrompt: Miniature Scenery of a miniature people playing in a straweberry cheesecake, intricate details, hyper realistic--ar 3:4\\n\\n\\n\\nWatermelon\\n\\nPrompt: Miniature Scenery of a miniature tourists playing in a slice of watermelon, intricate details, hyper realistic--ar 3:4\\n\\n\\n\\nTry using Niji Mode and see what kind of surprise you will receive!\\n\\n\\n\\nHamburger ( Niji Anime Style )\\n\\nPrompt: Miniature Scenery of a miniature people playing in a double cheese hamburger, intricate details, hyper realistic--ar 3:4 --niji 5 --s 180\\n\\n\\n\\n3. Mini Worldwide Landmark\\n\\nBesides food, a miniature landmark is something fun to try as well! This is fantastic for postcard design.\\n\\nPrompt: Depth of field, miniature, tilt shift, super cute clay world, isometric view of [ Landmark ] , clay freeze frame animation, landscape, zbrush, 3D --ar 3:4 --niji 5 --s 180\\n\\n\\n\\nParis Tower\\n\\nDepth of field, miniature, tilt shift, super cute clay world, isometric view of Paris Eiffel Tower, clay freeze frame animation, landscape, zbrush, 3D --ar 3:4 --niji 5 --s 180\\n\\n\\n\\nSydney Opera House\\n\\nDepth of field, miniature, tilt shift, super cute clay world, isometric view of Sydney Opera House, clay freeze frame animation, landscape, zbrush, 3D --ar 3:4 --niji 5 --s 180\\n\\n\\n\\nStatue of Liberty\\n\\nDepth of field, miniature, tilt shift, super cute clay world, isometric view of Statue of Liberty, clay freeze frame animation, landscape, zbrush, 3D --ar 3:4 --niji 5 --s 180\\n\\n\\n\\nI have a try with Midjourney latest version as well. The Niji style adds a touch of fancy and illustrative flair to the image, while the Midjourney default mode results in a miniature figure or toy.\\n\\n\\n\\nPersonally, I favor using the Niji style, especially when designing posters or postcards.\\n\\n💰 Extra: Make Money with AI Arts\\n\\nWith these Midjourney prompts, you can create artwork that is sure to sell! If you are looking for ways to generate passive income, consider selling your stunning visuals on Wirestock.\\n\\nWirestock is a single gateway to the most extensive marketplaces available, including iStock, Adobe Stock, Freepik, and more.\\n\\n🌟Try Wirestock for free. Use my code \" CHRISTIE\" for 20% OFF as you upgrade.\\n\\n\\n\\nMore details and a guide can be found here:\\n\\nMake Money Selling Midjourney AI Art on Wirestock\\nGuide to Turning Your AI Images into Cash!pub.aimind.so\\n\\n👉🏻 Digital Guide - 50+ Creative Midjourney Prompts\\n\\nIf you are looking for more ideas and advanced tips for poster ideas, I have also created a \"50+ Creative Commercial Advertisement -Midjourney Prompts\" digital tutorial for you guys.\\n\\nIt comes with\\n\\n🎨 50+ Optimized prompts for generating captivating content for Food, Commercial and Travel industries\\n\\n🖼 Prompt Structures & Visual examples\\n\\n💡 Tips from experts for taking your designs to the next level\\n\\n🚀 Ideas and styles for social posts, posters, branded content and more\\n\\n\\n\\nFinal Thoughts\\n\\nThe scale shift that \"miniature\" brings to your prompts is an effortless way to dramatically improve your poster designs. It’s one of my favorite Midjourney tricks for instantly leveling up art.\\n\\nExperiment with adding \"Miniature\" or \"Tiny\" to your own prompts and watch your posters become mesmerizing mini masterpieces! This simple keyword opens up a tiny world of potential.\\n\\nDon’t be afraid to run experiments, tweaking your prompts and observing the results. Prompt writing takes practice, so persistence is key.\\n\\nI sincerely invite you to join me in this creative journey. Learn and explore more opportunities together!\\n\\nHi👋 I am Christie - an AI Art Creator and Educator😊\\n\\nI hope you found value in this article on tapping into AI or unlimited creativity. If you’re craving more insider tips, prompts and tricks for tools like Midjourney, I’d love for you to join me on this journey.\\n\\n🎨 Hit that \"Follow\" button to stay in the loop for more AI wisdom\\n💌 Stay tuned for future updates\\n\\nLet’s explore the limitless possibilities of AI together. The future awaits. Let’s seize it! 🚀\\n\\nMore Midjourney Prompts\\n\\n20+ Incredible Midjourney Prompts You Must Try!\\nElevate Your AI Arts with These Creative Promptsbootcamp.uxdesign.cc\\n\\n10 Pro Tips for Crafting Creative Midjourney Prompts\\nMidjourney Prompt Mastery: 10 Structures for AI Art Successbootcamp.uxdesign.cc'}},\n",
       "  {'id': '71196de661cb',\n",
       "   'title': '20+ Incredible Midjourney Prompts You Must Try!',\n",
       "   'subtitle': 'Elevate Your AI Arts with These Creative Prompts',\n",
       "   'author': '14176fcb5743',\n",
       "   'publication_id': '48e972f5c24e',\n",
       "   'published_at': '2023-11-06 13:01:59',\n",
       "   'last_modified_at': '2024-01-18 01:36:25',\n",
       "   'tags': ['midjourney',\n",
       "    'artificial-intelligence',\n",
       "    'creativity',\n",
       "    'art',\n",
       "    'design'],\n",
       "   'topics': ['artificial-intelligence', 'design'],\n",
       "   'claps': 1112,\n",
       "   'voters': 160,\n",
       "   'word_count': 1278,\n",
       "   'responses_count': 20,\n",
       "   'reading_time': 6.722641509433963,\n",
       "   'url': 'https://bootcamp.uxdesign.cc/x20-incredible-midjourney-prompts-you-must-try-71196de661cb',\n",
       "   'unique_slug': 'x20-incredible-midjourney-prompts-you-must-try-71196de661cb',\n",
       "   'image_url': 'https://miro.medium.com/1*aYQLn2P3QdFqB-d8UdfZNA.png',\n",
       "   'lang': 'en',\n",
       "   'is_series': False,\n",
       "   'is_locked': True,\n",
       "   'is_shortform': False,\n",
       "   'top_highlight': 'Prompt: Blacklight planet in the galaxy, fancy dreamy',\n",
       "   'content': {'id': '71196de661cb',\n",
       "    'content': '20+ Incredible Midjourney Prompts You Must Try!\\n\\nElevate Your AI Arts with These Creative Prompts\\n\\nMidjourney is an AI art generator that is taking the creative world by storm. Using text prompts, you can generate stunning original images, opening up new possibilities for beginners and experts alike.\\n\\nBut as a Midjourney beginner, where do you start? I noticed that many of you are just starting and learning AI-generated art or Midjourney. Don’t worry if you’re confused about how to create a strong prompt - I am here to help!\\n\\nIn this post, I’ll share 20 incredible prompts to boost your creativity and art skills.\\n\\n\\n\\nMidjourney’s AI Art Generative Tool is a revolutionary and powerful AI program that unleashes your creativity and helps you generate beautiful visuals with the help of artificial intelligence and machine learning.\\n\\nFollow this beginner’s guide to Midjourney if you are just starting:\\n\\nThe Ultimate Beginner’s Guide to Midjourney\\nFollow this Step by Step Guide to Becoming a Prominent AI Art Creator!bootcamp.uxdesign.cc\\n\\nMidjourney Comprehensive Guide: Commands, Features and Tricks here!\\nHow to Use Midjourney Elevate Your Images and Creativitybootcamp.uxdesign.cc\\n\\n20 Incredible Midjourny Prompts\\n\\nToday, I will share with you 20+ fantastic prompts with various art styles, effects, and tricks to get your creative juice flowing. Read till the end for some extra tips.\\n\\nWith practice, you’ll be creating stunning AI art in no time! Let’s dive right in and experiment together!\\n\\n1. Phantasmal Iridescent\\n\\nPhantasmal Iridescent is a term used to describe a range of colors that are believed to have a magical or spiritual significance and are often associated with the supernatural or the divine\\n\\nPrompt: Phantasmal iridescent coffee machine\\n\\n\\n\\nThis is great for product and architectural design. I am also thinking of creating an article for product design. If you have any ideas, feel free to comment and let me know.\\n\\n2. Translucent\\n\\nIt features semi-transparent subjects and objects that allow light to pass through diffusely, creating a soft, hazy, dreamlike quality.\\n\\nPrompt: Translucent vehicle\\n\\n\\n\\n3. Holographic\\n\\nWith the illusion of a 3D floating image seemingly projected by lasers, featuring vibrant rainbow diffractions and transparent, multidimensional subjects.\\n\\nPrompt: Holographic, A fox, sleek glass material, transparent, cinematic lighting, white background, pink and blue\\n\\n\\n\\n4. Ethereal\\n\\nExtremely delicate, light, not of this earth. Airy, celestial, sublime\\n\\nPrompt: A fox sitting in the fluffy cloud, ethereal layer of pastel clouds, delicate, airy\\n\\n\\n\\n5. Egg Shaped\\n\\nWho can resist a round, fat and cute animal.\\n\\nPrompt: A 3D egg shaped fluffy fat cute cat, in white and brown, dreamy color palette, soft lighting\\n\\n\\n\\n6. Surreal Fantasy\\n\\nHaving an unreal, dream-like quality. Combining unlikely or impossible elements.\\n\\nPrompt: Jellyfish as a hot air balloon, surreal fantasy\\n\\n\\n\\n📌 Here I use the prompt formula \" [ Object ] as [ Object ]\"\\n\\nHere are nine more formulas to try for writing better prompts:\\n\\n10 Pro Tips for Crafting Creative Midjourney Prompts\\nMidjourney Prompt Mastery: 10 Structures for AI Art Successbootcamp.uxdesign.cc\\n\\n7. Bioluminescent\\n\\nCharacterized by the production and emission of light by living organisms. Often featuring vivid neon colors, glowing landscapes, and lighting effects.\\n\\nPrompt: Bioluminescent deep sea jellyfish, low poly, 3D rendering\\n\\n\\n\\n8. X-Ray\\n\\nRevealing inner layers and internal structures as if seen through an x-ray, often accentuating bones, organs, or mechanical parts.\\n\\nPrompt: X-ray diagram of a dinosaur, studio lighting\\n\\n\\n\\n9. Hologram\\n\\nA 3D image floating in space seemingly projected by lasers, with transparent and multi-dimensional qualities.\\n\\nPrompt: Hologram of Paris tower\\n\\n\\n\\n10. Blacklight\\n\\nBlacklight is an artistic effect that you see under ultraviolet light.\\n\\nPrompt: Blacklight planet in the galaxy, fancy dreamy\\n\\n\\n\\n11. Knolling\\n\\nKnolling is an amazing art form that involves taking various items and arranging them in a neat 90-degree formation.\\n\\nPrompt: Knolling of solar system\\n\\n\\n\\n12. 3D loop\\n\\nAn amazing way to liven up 3D objects! They create a seamless, looped image when applied, adding a vivid effect and depth to your artwork.\\n\\nPrompt: A 3D loop mountain print, dreamy color\\n\\n\\n\\n13. Matrix Raining Code\\n\\nMatrix Digital Rain is an iconic part of the Matrix franchise. As a representation of the simulated reality world of the Matrix, this falling code has become extremely popular in kinetic typography.\\n\\nPrompt: Matrix raining code, digits, spiderman\\n\\n\\n\\n14. Futuristic\\n\\nAn artistic style that emphasizes dynamism, speed, technology and youth.\\n\\nPrompt: Futuristic artificial intelligence\\n\\n\\n\\n15. Cyberpunk style\\n\\nA futuristic style that combines lowlife and high tech. It adds a cinematic effect to your image\\n\\nPrompt: Fox in a cyberpunk style\\n\\n\\n\\n16. Mechanic\\n\\nIt offers an industrial, machine-oriented aesthetic incorporating cogs, gears, pipes, wires, robotics, and other mechanical elements. Usually comes with a grungy metallic color palette.\\n\\nPrompt: Mechanic birds in futuristic landscapes\\n\\n\\n\\n17. Steampunk\\n\\nRetro-futuristic, incorporating steam power and fantastical mechanical technology.\\n\\nPrompt: Steampunk schnauzer meni\\n\\n\\n\\n18. Diagrammatic drawing\\n\\nDiagrams offer an efficient way of expressing ideas visually. They generally show two-dimensional objects and include shapes, lines and text to depict complex ideas in a simplified way.\\n\\nPrompt: Diagramatic drawing of the structure of London Bridge\\n\\n\\n\\n19. Stained Glass\\n\\nStained glass is an amazing art form - it uses colored glass to craft beautiful windows and other decorative items that let light pour in.\\n\\nPrompt: Stained glass window of a wolf in the mountain\\n\\n\\n\\n20. Double Exposure\\n\\nDouble exposure is a fantastic technique to mix two different photos into one unique, eye-catching image.\\n\\nPrompt: Double exposure of a bear and a mountain, natural scenery, watercolor art\\n\\n\\n\\n💰 Extra: Make Money with AI Arts\\n\\nWith these Midjourney prompts, you can create artworks that is sure to sell! If you are looking for ways to generate passive income, consider selling your stunning visuals on Wirestock.\\n\\nWirestock is a single gateway to the most extensive marketplaces available, including Shutterstock, iStock, Adobe Stock and more.\\n\\n\\n\\nMore details and a guide can be found here:\\n\\nMake Money Selling Midjourney AI Art on Wirestock\\nGuide to Turning Your AI Images into Cash!pub.aimind.so\\n\\n👉🏻Passive Income with AI art: Master Midjourney 🎨\\n\\nDon’t Get Left Behind in the AI Art Gold Rush of 2024! Midjourney is exploding. Early adopters are raking in big bucks selling AI art online.\\n\\nThis is your ticket to passive income with AI art.💰- \"Master Midjourney 2024: Beginner to Pro\" digital guide.\\n\\nIt comes with:\\n\\n🎨 1,000+ money-making prompts for stunning, sellable art\\n\\n💡 Advanced Midjourney prompt writing, structure and techniques\\n\\n🖼 Specialized commercial guidance for graphic, branding, logo, UI, photography, mockup and more\\n\\n🚀 Insider tips to maximize profits\\n\\n💰 AI Arts Monetisation Strategies\\n\\n💼 Top AI tools to edit Midjourney creations\\n\\n\\n\\n📚 Continuous education\\n\\nThis guide is designed for continuous education, new tutorials are added regularly so you stay ahead. With lifetime access for a single purchase, it’s the gift that keeps giving.\\n\\nI’ve poured my heart into creating this guide. I hope you enjoy it ❤️\\n\\nHey, Friends 👋 Christie here - An AI Art Educator & Creator 😊 Also a Coffee Lover❤️☕️\\n\\nIf you’re craving more Insider Tips, Prompts and Tricks for creating and generating income with AI art, join me on this journey.\\n\\n🎨 Hit that \"Follow\" button to stay in the loop for more AI wisdom\\n💌 Stay tuned for more tutorials!\\n\\nLet’s explore the limitless possibilities of AI Art and build passive income together! 🚀💰\\n\\nMore Incredible Midjourney Prompts & Tricks\\n\\nIncredible Midjourney Prompts and Tricks\\nThis is a list of prompts that comes with different categories that I organised and structured for your convenience…medium.com\\n\\nAffiliate Disclaimer:\\nPlease note that the link to Wirestock is an affiliate link, and I will earn a commission if you subscribe through the link. Please let me know if you have any questions about anything listed above.'}},\n",
       "  {'id': '27e9975cce9c',\n",
       "   'title': 'Midjourney Comprehensive Guide: Commands, Features and Tricks here!',\n",
       "   'subtitle': 'How to Use Midjourney to Elevate Your Images and Creativity',\n",
       "   'author': '14176fcb5743',\n",
       "   'publication_id': '48e972f5c24e',\n",
       "   'published_at': '2023-07-30 13:02:32',\n",
       "   'last_modified_at': '2024-01-04 03:03:59',\n",
       "   'tags': ['midjourney',\n",
       "    'artificial-intelligence',\n",
       "    'creativity',\n",
       "    'design',\n",
       "    'future'],\n",
       "   'topics': ['design'],\n",
       "   'claps': 1085,\n",
       "   'voters': 193,\n",
       "   'word_count': 1998,\n",
       "   'responses_count': 18,\n",
       "   'reading_time': 9.489622641509433,\n",
       "   'url': 'https://bootcamp.uxdesign.cc/a-comprehensive-midjourney-guide-commands-features-and-tricks-here-27e9975cce9c',\n",
       "   'unique_slug': 'a-comprehensive-midjourney-guide-commands-features-and-tricks-here-27e9975cce9c',\n",
       "   'image_url': 'https://miro.medium.com/1*jARZCchLet3ZIpvMvN01Qg.png',\n",
       "   'lang': 'en',\n",
       "   'is_series': False,\n",
       "   'is_locked': True,\n",
       "   'is_shortform': False,\n",
       "   'top_highlight': 'Using the same seed number will produce a similar style.',\n",
       "   'content': {'id': '27e9975cce9c',\n",
       "    'content': 'Midjourney Comprehensive Guide: Commands, Features and Tricks here!\\n\\nHow to Use Midjourney to Elevate Your Images and Creativity\\n\\nMidjourney’s AI Art Generative Tool is an innovative and powerful AI tool that empowers your creativity by utilizing artificial intelligence and machine learning to produce stunning visuals.\\n\\nMidjourney generates images based on a short text description called a Prompt with the primary \"imagine\" command.\\n\\nUtilizing this command is quite simple. However, if you desire greater styles and variations over the images, you’ll need to master the advanced prompts and parameters. Today, I have prepared a comprehensive guide to help you thrive in this creative journey! 🚀\\n\\nAs always, allow me to welcome you with a cup of coffee! ☕️\\n\\n\\n\\nIf you are just starting, check out this quick guide to set up Midjourney on Discord\\n\\nThe Ultimate Beginner’s Guide to Midjourney\\nFollow this Step by Step Guide to Becoming a Prominent AI Art Creator!bootcamp.uxdesign.cc\\n\\nToday, I will walk you through a list of parameters and commands to master Midjourney. From basic skills to advanced tips, you’ll unleash the full potential of this incredible AI tool.\\n\\nToday’s content is separated into several parts:\\n\\nPart One: Prompt types\\n\\nPart Two: Parameters\\n\\nPart Three: Advanced Command\\n\\nPart Four: Version and Style\\n\\nExtra: Latest Features & Creative Use Cases\\n\\nAs you all know, to interact with the Midjourney Bot on Discord, we will need to use commands. Commands are used to create images, customize settings, track user info, and perform other helpful functions.\\n\\nIn order to create images in Midjourney, we need to input a prompt followed by the command \"/imagine\".\\n\\nThe command for image generation: /imagine prompt\\n\\nThat’s what we are going to start today - Prompt.\\n\\n🌟 Part One: Prompt Types\\n\\nA Prompt is a short text phrase that the Midjourney Bot interprets to produce an image and can be broken down into three major types in the following structure.\\n\\n\\n\\n1. Image Prompt\\n\\nUse images to impact a Job’s composition, style, and colors.\\n\\n2. Text Prompt\\n\\nDescription of the image. Combine image prompts with text prompts for varied outcomes.\\n\\n3. Advanced Text Prompt\\n\\n3.1 Multi Prompt \"::\"\\n\\nUsing \" ::\" in the prompt lets Midjourney consider each part individually, allowing for assigning relative importance to the prompt.\\n\\nFor instance, \"Space ship\" results in a sci-fi spaceship, while \"space::ship\" creates a sailing ship in space.\\n\\n\\n\\nPrompt Weights\\n\\nBesides, We can also add a number after it determines the relative importance of that specific part.\\n\\nModifying the prompt to \"space::2 ship\" prioritizes \"space\" twice as much as \"ship,\" resulting in space-themed images with ships as secondary elements.\\n\\nspace::2 ship\\n\\nOrder of the Prompt\\n\\nBesides utilizing prompt weight, the order of your words also has a significant effect on the final image.\\n\\nBegin with the key keywords that hold the most significance.\\n\\nWords 1–5: carry significant influence and are likely to appear prominently in the initial results.\\n\\nWords 5–20: also hold influence, but may need 2–3 rerolls to highlight them in the image.\\n\\nWords 21–40: remain relevant, but might require several rerolls to be noticeable.\\n\\nWords 40+: likely to be overlooked\\n\\n3.2. Advanced Text Prompt - Permutation Prompt\\n\\nPermutation Prompt allows users to generate prompt variations using a list of options separated with commas \",\" within curly braces \"{ }\" to create different combinations.\\n\\nPrpmpt: A Fox { Inkpaint, Pop art, Cyberpunk}\\n\\nA Fox { Inkpaint, Pop art, Cyberpunk}\\n\\n🌟 Part Two: Parameters\\n\\nParameters are additional choices incorporated into a prompt, which modify the generation process of an image.\\n\\nParameters go at the end of the prompt, usually in this way\\n\\n--parameter <value>\\n\\n1. Aspect Ratios --ar [ width : height ]\\n\\nHere are common aspect ratios used in various contexts:\\n\\n--ar 1:1 Default aspect ratio.\\n\\nLandscape:\\n--ar 5:4 Common print ratio.\\n--ar 3:2 Common in print photography.\\n--ar 16:9 Televisions and computer monitors\\n\\nPortrait:\\n--ar 2:3 Good for Posters and Social Media Posts\\n--ar 9:16 Good for Stories and Video\\n\\nThe aspect ratio impacts the shape and composition of a generated image. V5 brings in various aspect ratios, including unconventional ones like 100:1.\\n\\n\\n\\n2. Chaos --c < 0–100 >\\n\\nHigher values result in more unusual and unexpected results and compositions.\\n\\n\\n\\n3. Image Weight --iw < 0–2 >\\n\\nImage prompt weight relative to text weight. The higher the iw value, the closer the final result will resemble the image.\\n\\nUse --iw 2if you want the result to look close to the original image. It is great for creating your own avatar and replicating images.\\n\\n\\n\\nPrompt: [ Image URL ], a handsome guy with short brown hair smiling, keep the consistency of action, expression, clothing, shape and appearance of the photos, photography from disney pixar studio, anime, super detail --iw 2 --s 180\\n\\nMore detialed guide can be found here:\\n\\nTurn Your Photo Into Captivating Anime Avatar with Midjourney\\nLearn the tricks to transform your photo into an avatar that reflects your unique style and personality.bootcamp.uxdesign.cc\\n\\n\\n\\nHow to use Midjourney to Replicate Your Images\\nLearn How to use /Describe and Image Promptbootcamp.uxdesign.cc\\n\\n4. Stop --stop < 10–100 >\\n\\nStop a job partway to create less detailed and blurrier results.\\n\\n\\n\\n5. Stylize --s < 0-1000 >\\n\\nApplication of Midjourney’s default aesthetics including artistic color, composition, and forms. High stylization values create images that are very artistic but less connected to the prompt.\\n\\n\\n\\n6. Weird: --w < 0–3000 >\\n\\nAdds quirky and offbeat qualities to your generated images, resulting in unique and unusual aesthetics.\\n\\n\\n\\n🎨 Note that using \" - stylize and - weird\" together with the same value can result in strange yet pretty images.\\n\\nMidjourney New \"Weird\" Command Takes Your Creativity to the Next Level\\nLet your imagination run wild!bootcamp.uxdesign.cc\\n\\n7. No: --no [ ]\\n\\nNegative prompting, for instance --no red remove the red color from the image.\\n\\nTo eliminate more than one element, separate it with \",\" like this\\n\\nYour prompt --no item1, item2, item3\\n\\nPrompt: Spiderman - no red\\n\\n8. Seed --seed < 0–4294967295 >\\n\\nUsing the same seed number will produce a similar style.\\n\\nImages with the seed number: 3114655039\\n\\nHow to Produce Similar Images or Styles in MidJourney\\nGenerate images that are more consistent and resplendent!bootcamp.uxdesign.cc\\n\\n9. Tile: --tile Generate images that can be used to create seamless patterns for print-on-demand products or packaging\\n\\n\\n\\n50+ Best Midjourney Prompts to Create Seamless Pattern that Sells\\nMake Passive Income With Midjourney!bootcamp.uxdesign.cc\\n\\nCreate Stunning Packaging Design with Midjourney Seamless Patterns\\nWith Midjourney Prompts and Visual Examplesbootcamp.uxdesign.cc\\n\\nOther Parameters\\n\\nModes: --relax,--fast & --turboRun a job using Relax/Fast/Turbo Mode.\\n\\nQuality: --q <.25, .5, or 1> Higher values use more GPU minutes.\\n\\nRepeat:--r < 1–40 > Create multiple Jobs from one prompt.\\n\\nVideo: --video Create a short video of image creation.\\n\\n🌟 Part Three: Advanced Command\\n\\n1 ./blend\\n\\nAllow you to upload 2–5 images and merge the aesthetics.\\n\\nExample of blending two images together\\n\\nMore examples can be found here:\\n\\nHow to Combine Images in MidJourney\\nCombine images with one single command easilybootcamp.uxdesign.cc\\n\\n2./describe\\n\\nGenerate four prompts based on an uploaded image. It allows you to learn more about prompts writing as well!\\n\\nNew Midjourney Command - Image2Text is Here!\\nGenerate Text Prompts that Accurately Depict An Image with the command - describe.bootcamp.uxdesign.cc\\n\\n3 ./prefer option:\\n\\nCreate a custom option. Set up parameters that you can add to the end of prompts, making your workflow more efficient.\\n\\nFor example: /prefer option set my --s 500--ar 16:9 creates an option called \"my\" that translates to --s 500--ar 16:9.\\n\\n/imagine prompt: \"Cat - my\" will become \" Cat - s 500 - ar 16:9\" directly\\n\\n- /prefer option list: View current custom options.\\n- /prefer suffix: Specify a suffix at the end of every prompt.\\n\\nHow to Produce Same Style Image with Just One Word in MidJourney\\nNo need to copy and paste or type long prompts anymorebootcamp.uxdesign.cc\\n\\n4./shorten:\\n\\nAnalyze a prompt and return shorter prompts omitting redundant words\\n\\n5. /remix:\\n\\nRemix Mode can alter prompts, parameters, model versions, or aspect ratios in variations. It takes the general composition of your starting image and incorporates it into the new Job. Remixing helps change the image’s setting, lighting, subject, or composition.\\n\\n🌟 Part Four: Versions and Style\\n\\nMidjourney provides an easy way for you to switch between various versions and styles either by selecting in the setting panel or adding a parameter.\\n\\n1. Settings\\n\\n/settings: Using the settings command will open a panel that allows you to switch between version, style, quality, and modes.\\n\\n\\n\\n2. Changing Parameters\\n\\nAlternatively, you can switch versions and styles through the use of parameters.\\n\\n--v [1/2/3/4/5/5.1/5.2]:Switch between versions\\n\\n--style raw: Reduce default aesthetic ( V5.1 and V5.2 )\\n\\n\\n\\n3. Niji Styles\\n\\nNiji Mode is an anime-specific model with a vast knowledge of anime, styles and aesthetics.\\n\\n--style [cute/ expressive/ scenic]\\n\\nBesides the original style that is great for modern anime flair, Niji also comes with\\n\\nCute: An adorable style that produces gentle pictures\\n\\nDefault: The most creative style, great for drawing new concepts\\n\\nExpressive: A stylish, chic look with a Western influence\\n\\nScenic: A cinematic look with strong dynamic lighting\\n\\nHere is a demonstration of the 4 different styles of Niji Journey V5 with the same prompt:\\n\\n\\n\\nThey just launched a New Niji App\\n\\nMidjourney Niji App is Here with Incredible Features!\\nStunning Anime Artwork with the Niji Journey App!bootcamp.uxdesign.cc\\n\\n🔥 Latest Features of Midjourney 🔥\\n\\n1. Vary (Region) - Inpainting\\n\\nThe \"Vary (Region)\" option allows you to select and regenerate specific parts of an image. This allows users to remove unwanted objects or fill in missing parts which works similarly as inpainting.\\n\\n2. Zoom Out\\n\\nIt allows you to expand the canvas of an upscaled image by 1.5x, 2x or in custom aspect while keeping the original content intact.\\n\\n3. Panning\\n\\nPanning extends your image in four different directions ➡️⬅️⬆️⬇️. You can keep panning multiple times, resulting in a large and detailed panoramic image.\\n\\n4. Upscale\\n\\nUpscalers allow you to upscale your image instantly to 2x and 4x larger.\\n\\n\\n\\nWhile the zoom-out feature allows you to tell a great story, create animation and even create beautiful mockups, the panning feature is great for panoramic images and more creative usage, learn more here:\\n\\nMidjourney New \"Zoom Out\" Feature - Incredible Hidden Tricks!\\nTell a Great Story and Create Professional Mockups with Zoom!bootcamp.uxdesign.cc\\n\\nMidjourney New \" Panning\" Feature - Remarkable Creative Usage!\\nCreate Captivating Panoramic Images, Stunning UI, Interior Design and More!bootcamp.uxdesign.cc\\n\\nExample Usage of the 3 features\\n\\nLet’s look at the example below where I regenerated a new scene with the same character\\n\\n\\n\\nTo add more settings, I used \"Zoom-out 2x\" and pan left with a custom prompt here.\\n\\n\\n\\n👉🏻Digital Guide: Master Midjourney 🎨🚀\\n\\nIf you are looking for more ideas and advanced tips for generating captivating AI art with Midjourney, I have also created a \"Master Midjourney: Beginner to Pro\" digital guide.\\n\\nIt comes with:\\n\\n🎨 1,000+ expert prompts\\n\\n💡 Advanced Midjourney prompt writing, structure and core techniques\\n\\n🖼 Specialized guidance for graphic design, branding, logo, UI, photography, and more commercial uses\\n\\n🚀 Pro tips to recreate styles, make avatars, generate anime artwork, and more\\n\\n💰 AI Arts Monetisation Strategies\\n\\n💼 Top AI tools to edit Midjourney creations\\n\\n\\n\\n📚 Continuous education\\n\\nThis guide is designed for continuous education, new tutorials are added regularly so you stay ahead. With lifetime access for a single purchase, it’s the gift that keeps giving.\\n\\nI’ve poured my heart into creating this guide. I hope you enjoy it ❤️\\n\\nIncredible Midjourney Prompt, Tricks and Features\\n\\nFor your convenience, I have categorized and structured my Midjourney prompt articles, providing visual examples, helpful tips, and tricks to assist you in crafting breathtaking images.\\n\\nIncredible Midjourney Prompts and Tricks\\nEdit descriptionmedium.com\\n\\nMidjourney Features, Commands & Parameters\\nEdit descriptionmedium.com\\n\\nHi👋 I am Christie - a multimedia designer and AI fanatic.😊\\n\\nI hope you found value in this article on tapping into AI or unlimited creativity. If you’re craving more insider tips, prompts and tricks for tools like Midjourney, I’d love for you to join me on this journey.\\n\\n🎨 Hit that \"Follow\" button to stay in the loop for more AI wisdom\\n💌 Stay tuned for future updates\\n\\nLet’s explore the limitless possibilities of AI together 🚀'}},\n",
       "  {'id': 'da3e4b1ac900',\n",
       "   'title': 'Top 12 Visual Design Trends for 2024 That Boost Engagement (Part 2)',\n",
       "   'subtitle': 'The Hottest Creative Styles to Captivate Audiences This Year',\n",
       "   'author': '14176fcb5743',\n",
       "   'publication_id': '*Self-Published*',\n",
       "   'published_at': '2024-02-18 13:01:39',\n",
       "   'last_modified_at': '2024-02-18 13:01:39',\n",
       "   'tags': ['midjourney',\n",
       "    'artificial-intelligence',\n",
       "    'creativity',\n",
       "    'design',\n",
       "    'make-money'],\n",
       "   'topics': ['design'],\n",
       "   'claps': 336,\n",
       "   'voters': 18,\n",
       "   'word_count': 1327,\n",
       "   'responses_count': 5,\n",
       "   'reading_time': 7.007547169811321,\n",
       "   'url': 'https://medium.com/@inchristiely/top-12-visual-design-trends-for-2024-that-boost-engagement-part-2-da3e4b1ac900',\n",
       "   'unique_slug': 'top-12-visual-design-trends-for-2024-that-boost-engagement-part-2-da3e4b1ac900',\n",
       "   'image_url': 'https://miro.medium.com/1*AUCseY5Vt4MMvTlUwf6zpA.png',\n",
       "   'lang': 'en',\n",
       "   'is_series': False,\n",
       "   'is_locked': True,\n",
       "   'is_shortform': False,\n",
       "   'top_highlight': '',\n",
       "   'content': {'id': 'da3e4b1ac900',\n",
       "    'content': 'Top 12 Visual Design Trends for 2024 That Boost Engagement (Part 2)\\n\\nThe Hottest Creative Styles to Captivate Audiences This Year\\n\\nWelcome back to part two of our 2024 AI art trend forecast! In the first part, we covered organic, retro, and vibrant creative styles emerging this year.\\n\\nNow let’s explore the remaining future-focused trends that will shape generative art. From Glassmorphism to Art Nouveau, these cutting-edge aesthetics demonstrate AI art’s continued evolution.\\n\\nBy mastering the hottest styles, your generative art can connect deeply with viewers and stand out!\\n\\n\\n\\nMy Best Pick Platform to Sell AI Art - Wirestock\\n\\nFor people wanting to sell AI-generated art, Wirestock offers AI artists and visual creators a platform to exhibit, connect with potential buyers and monetize their creations within the digital domain.\\n\\n\\n\\nOne-Stop Platform for Making Money Selling AI Art\\n\\nThey provide creators with a single gateway to the most extensive marketplaces available, including iStock, Adobe Stock, Freepik and more.\\n\\nThis means expanded exposure for your work and higher earning potential.\\n\\n👉🏻 Step-to-Step Guide\\n\\nIf you are new to Wirestock, follow my step-by-step guide here to making money selling your AI art :\\n\\nMake Money Selling Midjourney AI Art on Wirestock\\nGuide to Turning Your AI Images into Cash!pub.aimind.so\\n\\n\\n\\nHere comes the second part of the Top 12 Visual Design Trends for 2024 That Boost Engagement. If you have missed part one, be sure to check it out here:\\n\\nToday, let’s continue going over 6 more visual design trends for 2024.\\n\\n7. 3D Effects Add Dimension with Shape and Perspective\\n\\n3D shapes and objects add literal depth and perspective when used appropriately. Play with 3D bubbles, typography, geometric objects and more to make designs pop. But beware of overusing it.\\n\\nA little 3D goes a long way.\\n\\nKeywords\\n\\n3D\\n\\nBubbles\\n\\nColors\\n\\nIllustrations\\n\\nObjects\\n\\nShapes\\n\\nPlants\\n\\nThree dimensional\\n\\nShapes\\n\\nPrompt: A group of 3D colorful bubbles sitting on a white surface, in the style of quirky characters and objects, animated gifs, yellow and pink and blue --ar 16:9\\n\\n\\n\\nObjects\\n\\nPrompt: Cosmopolitan Isometric transparent glass of cosmopolitan with pink jelly, stardust, pink flowers, dreamy pink pastel color palette --ar 16:9\\n\\n\\n\\nIsometric\\n\\nPrompt: Isometric 3D icon, cartoon spacecraft, gradient glass, colourful color matching, 3D modeling, OC rendering, clean shadow, soft focus --ar 16:9\\n\\n\\n\\nIsometric Prompts\\n\\nIf you are looking for more isometric prompts, be sure to check this out. There is also a digital guide packed with \"70+ Creative Prompts\".\\n\\nUnlock New Dimensions with this One Magical Midjourney Prompt!\\nTake Your AI Art to the Next Level in 2024bootcamp.uxdesign.cc\\n\\n8. Art Nouveau Captivates with Organic Elegance\\n\\nRecalling the late 19th century, Art Nouveau charms with its organic motifs, graceful lines, and sophisticated style. Florals, looping lines, and nature motifs are intrinsic to this trend. Embrace rich jewel tones, pastels, and metallic accents.\\n\\nKeywords\\n\\nBrightness\\n\\nColorful\\n\\nGradient\\n\\nPastel\\n\\nPower\\n\\nVibrant\\n\\nFrame\\n\\nPrompt: A beautiful photo frame in Art Nouveau charms with its organic motifs, graceful lines, and sophisticated style --ar 16:9\\n\\n\\n\\nDecoration\\n\\nPrompt: An Art Nouveau painting of a butterfly surrounded by flowers --ar 16:9\\n\\n\\n\\nFrame Design\\n\\nPrompt: Art Nouveau floral frame design, surrounded with flowers, pastel color palette --ar 16:9\\n\\n\\n\\n9. Old Engravings Invoke Nostalgia and Tradition\\n\\nEngraved illustrations, often featuring flowers or animals, provide a sense of nostalgia. Combining old engravings with modern elements creates an appealing contrast.\\n\\nThe intricate details and fine lines of this 17th-century style remain influential.\\n\\nKeywords:\\n\\nVintage\\n\\nFine lines\\n\\nHistorical themes\\n\\nDetails\\n\\nNostalgia\\n\\nEngraving\\n\\nAnimals\\n\\nPrompt: Wild animals blue vintage print, in the style of embossed paper, old engraving style\\n\\n\\n\\nFlowers\\n\\nPrompt: Flowers, honey, leaves and birds, old engraving art on sketch paper\\n\\n\\n\\nStamp\\n\\nPrompt: Algerian postal stamp with algeria, name, gothic architecture, nouveau, light maroon, pen, stone, letras y figures\\n\\n\\n\\n10. Chrome Effect Adds Liquid Appeal with Metallics\\n\\nThe liquid chrome effect brings slick, futuristic vibes through reflective and metallic finishes. Use shiny chrome on fonts, abstract shapes, and objects.\\n\\nChrome beautifully complements trends like neon and holographic.\\n\\nKeywords\\n\\n3D\\n\\nChrome plated\\n\\nGradient\\n\\nLiquid Chrome\\n\\nPsycho\\n\\nShapes\\n\\nPastel\\n\\nTexture\\n\\nChrome Plated Texture\\n\\nPrompt: A blue and pink crystalline shape in the middle, with a blue and pink pattern, in the style of vray tracing, flowing draperies, made of liquid metal,chrome-plated, gradient background --ar 16:9\\n\\n\\n\\nChrome Plated Ring\\n\\nPrompt: Futuristic design of a ring, smooth curves, modern, gradient color, chrome plated, neon color of light pink and blue --ar 16:9\\n\\n\\n\\nLetter\\n\\nPrompt: 3D letter \" Flow\" in metallic chrome plate style, vibrant color --ar 16:9\\n\\n\\n\\n11. Glassmorphism Blurs Physical and Digital\\n\\nGlassmorphism makes designs look frosted, transparent, or blurred as if behind tinted glass. Use this trend to give a cutting-edge yet elegant feel. Soft-edged shapes, muted backgrounds, and minimalist design suit this tech-inspired style.\\n\\nKeywords\\n\\nRetro\\n\\nIllustration\\n\\nVibrant colors\\n\\nPastel\\n\\nShapes\\n\\nGradient\\n\\nLogo\\n\\nPrompt: A Glassmorphism camping logo that signifies adventure and exploration, a light gradient color of purple and blue, minimal background\\n\\n\\n\\nApp Icon\\n\\nPrompt: A Glassmorphism app icon design, a mail, minimal background, soft peach pantone color\\n\\n\\n\\nIcon Set\\n\\nPrompt: Design a Glassmorphism app icon set hat signifies adventure and exploration. Think about iconic symbols like an airplane and a globe and find a unique way to depict them, minimal background, light gradient color of purple and blue\\n\\n\\n\\nUI Design\\n\\nPrompt: UI design of a creative design company landing page , Glassmorphism style abstract shapes, gradient color of blue and purple--ar 16:9\\n\\n\\n\\n12. Pantone’s 2024 Color of the Year: Peach Fuzz 🍑\\n\\nAnd finally, Pantone’s 2024 color of the year is Peach Fuzz - a vibrant, warm peach shade. Embrace this inviting hue in your branding, packaging, designs and beyond.\\n\\nLet Peach Fuzz inspire creativity and positivity this year!\\n\\nKeywords\\n\\nColor of the year\\n\\nPantone\\n\\nPeach Pantone Color\\n\\nPeach Fuzz\\n\\nSoft Peach Color\\n\\nCorporate Flat Illustration\\n\\nPrompt: Flat illustration of a teacher standing in front of a dahboard, data chart, soft lines and shapes, abstract memphis, minimalism,soft peach pantone color, gradient, white background --ar 3:2\\n\\n\\n\\nInterior Design - Bar\\n\\nPrompt: Interior design of a cocktail bar, soft peach pantone color --ar 3:2\\n\\n\\n\\nHome Appliances Design\\n\\nPrompt: Coffee machine design, soft peach pantone color--ar 3:2\\n\\n\\n\\nPeach Fuzz is the Pantone Color of 2024, if you are looking for more art trends with the trending color, be sure to check this out:\\n\\n25 Incredible Midjourney Prompts with 2024 Pantone Color - Peach Fuzz 🍑\\nWith Commercial Usage and Visual Inspirationsbootcamp.uxdesign.cc\\n\\nThere you have it - 12 of the top visual design trends 2024 with tips to try them yourself.\\n\\nFrom retro to futuristic aesthetics, this year offers a diverse palette of styles to engage your audience. Now go forth and design something beautiful!\\n\\n\\n\\n👉🏻Digital Guide: Master Midjourney 🎨🚀\\n\\nIf you want to enhance your skills and explore advanced techniques, I have created a \"Master Midjourney: Beginner to Pro\" digital guide.\\n\\nIt comes with:\\n\\n🎨 1,000+ expert prompts to inspire your creativity\\n\\n💡 Advanced Midjourney prompt writing, structure and core techniques\\n\\n🖼 Specialized commercial guidance for graphic design, branding, logo, UI, photography, mockup and more\\n\\n🚀 Pro tips to recreate styles, make avatars, generate anime artwork, and more\\n\\n💰 AI Arts Monetisation Strategies\\n\\n💼 Top AI tools to edit Midjourney creations\\n\\n\\n\\n📚 Continuous education\\n\\nThis guide is designed for continuous education, new tutorials are added regularly so you stay ahead. With lifetime access for a single purchase, it’s the gift that keeps giving.\\n\\nI’ve poured my heart into creating this guide. I hope you enjoy it ❤️\\n\\n\\n\\nHey friends 👋 I am Christie - An AI Art Educator & Creator 😊 Also a coffee lover ❤️☕️\\n\\nIf you’re craving more Insider Tips, Prompts and Tricks for creating and generating income with AI art, join me on this journey.\\n\\n🎨 Hit that \"Follow\" button to stay in the loop for more AI wisdom\\n💌 Stay tuned for more tutorials!\\n\\nLet’s explore the limitless possibilities of AI Art and build passive income together! 🚀💰'}},\n",
       "  {'id': '572cd5758aa6',\n",
       "   'title': 'Top 12 Visual Design Trends for 2024 That Boost Engagement',\n",
       "   'subtitle': 'The Hottest Creative Styles to Captivate Audiences This Year',\n",
       "   'author': '14176fcb5743',\n",
       "   'publication_id': '48e972f5c24e',\n",
       "   'published_at': '2024-02-17 13:01:57',\n",
       "   'last_modified_at': '2024-02-17 21:52:30',\n",
       "   'tags': ['design', 'creativity', 'art', 'midjourney', 'make-money-online'],\n",
       "   'topics': ['design'],\n",
       "   'claps': 410,\n",
       "   'voters': 26,\n",
       "   'word_count': 1313,\n",
       "   'responses_count': 2,\n",
       "   'reading_time': 6.904716981132076,\n",
       "   'url': 'https://bootcamp.uxdesign.cc/top-12-visual-design-trends-for-2024-that-boost-engagement-572cd5758aa6',\n",
       "   'unique_slug': 'top-12-visual-design-trends-for-2024-that-boost-engagement-572cd5758aa6',\n",
       "   'image_url': 'https://miro.medium.com/1*D0D5XzAIxQ7ywOYPVNbyag.png',\n",
       "   'lang': 'en',\n",
       "   'is_series': False,\n",
       "   'is_locked': True,\n",
       "   'is_shortform': False,\n",
       "   'top_highlight': '',\n",
       "   'content': {'id': '572cd5758aa6',\n",
       "    'content': 'Top 12 Visual Design Trends for 2024 That Boost Engagement\\n\\nThe Hottest Creative Styles to Captivate Audiences This Year\\n\\nIn 2024, we anticipate the rise of prominent AI art trends as creative mediums are pushed to new frontiers. Aspiring AI artists must grasp these trends to craft impactful works that connect with the market.\\n\\nToday, I am going to share the upcoming AI art trends set to dominate in 2024 presented by Freepik.\\n\\nAdditionally, I will share some visual concepts generated with Midjourney that align with these trends and have the potential to generate income.\\n\\n\\n\\nMy Best Pick Platform to Sell AI Art - Wirestock\\n\\nFor people wanting to sell AI-generated art, Wirestock offers AI artists and visual creators a platform to exhibit, connect with potential buyers and monetize their creations within the digital domain.\\n\\n\\n\\nOne-Stop Platform for Making Money Selling AI Art\\n\\nThey provide creators with a single gateway to the most extensive marketplaces available, including iStock, Adobe Stock, Freepik and more.\\n\\nThis means expanded exposure for your work and higher earning potential.\\n\\n👉🏻 Step-to-Step Guide\\n\\nIf you are new to Wirestock, follow my step-by-step guide here to making money selling your AI art :\\n\\nMake Money Selling Midjourney AI Art on Wirestock\\nGuide to Turning Your AI Images into Cash!pub.aimind.so\\n\\n\\n\\nTop 12 Visual Design Trends 2024 - Part One\\n\\nAs the article is packed with valuable insights, I’ve decided to split it into two parts. Get ready to explore the first set of the 12 trends and discover the resources that will elevate your designs to new heights this year.\\n\\n1. Florals and Botanicals Bring Soft, Organic Touches\\n\\nOne of the best inspirations to draw from is nature. Flowers, leaves, and plants always stay in style. Stay connected to Mother Nature by incorporating florals and greens in your 2024 designs.\\n\\nConsider a realistic flower collage with nature photography or illustrations.\\n\\nKeywords:\\n\\nBotanical elements\\n\\nFlowers\\n\\nFlower Collage\\n\\nFreshness\\n\\nLeaves\\n\\nNature\\n\\nSoft colors\\n\\nPastel tones\\n\\nPlants\\n\\nCollage\\n\\nPrompt: A rococo art style collage of a bird surrounded by beautiful roses, dreamy pastel color palette --ar 16:9\\n\\n\\n\\nRealistic Flower\\n\\nPrompt: Knolling of colorful dried roses and leaves arranged on a plain white surface, beautiful sunlight--ar 16:9\\n\\n\\n\\nCommercial Usage - Mockup Stage Design\\n\\nPrompt: Mockup stage design for products, a flat wood, on a clean light beige background, with some woods and plants a flat front shot, horizontal composition, soft lighting, minimal style --ar 16:9\\n\\n\\n\\nFor more great mockup prompts, please refer to this article:\\n\\n20+ Incredible Midjourney Prompts to Create Your Professional Mockups\\nVisual examples, tricks and tips for creating an outstanding mockup for your productsbootcamp.uxdesign.cc\\n\\n2. Holographic 3D Shapes Dazzle with Light and Motion\\n\\nFuturistic designs incorporating shapes, like spheres and pyramids, in eye-catching materials keep audiences engaged. The interplay of textures paired with holographic 3D is the key.\\n\\nKeywords\\n\\n3D\\n\\nAbstract\\n\\nColors\\n\\nFuture\\n\\nHolographic\\n\\nLight\\n\\nMovement\\n\\nShapes\\n\\nTexture\\n\\nPrompt: Liquid foil, holographic, flowing, transparent, curves, blue, green and yellow --ar 16:9\\n\\n\\n\\nImage\\n\\nPrompt: An image of a model in futuristic costume, wearing glasses and white jacket, in rococo style, sculptures, light orange and magenta--ar 16:9\\n\\n\\n\\nCommercial Usage - Architectural Design\\n\\nPrompt: Architectural design of a national museum, in organic shape, Liquid foil, holographic, flowing, transparent, curves, dark sky-blue, light navy and violet --ar 16:9\\n\\n\\n\\nFor more architectural prompts inspiration, check this article out:\\n\\n35 Incredible Midjourney Prompts for Breathtaking Architecture Design\\nArchitecture Prompts With Various Styles, Structures, Materials and Visual Examplesbootcamp.uxdesign.cc\\n\\n3. 3D Fonts Make a Splash with Vibrancy\\n\\nAdd an extra splash of excitement by using liquid 3D fonts that appear to drip or move. Complement the fonts with vibrant colors for an energetic look or metallics like chrome for a sleek style.\\n\\nThis hot trend makes the text pop off the page.\\n\\nKeywords\\n\\n3D\\n\\nDynamism\\n\\nFresh colors\\n\\nHot palette\\n\\nLiquid\\n\\nShapes\\n\\nSpark\\n\\nLiquid Letter\\n\\nPrompt: The text \"water\" writen in liquid form, blue background --ar 16:9\\n\\n\\n\\nNeon Light\\n\\nPrompt: 3D isometric number shape of \"Take Action\" neon light tube shape--ar 16:9\\n\\n\\n\\n3D Dripping Letter\\n\\nPrompt: A 3D letter shape \" scary\" made of dripping blood in a dark background --ar 16:9 --style raw --s 75\\n\\n\\n\\nIf you have read my recent article in text generation, you will know using \"Raw Style\" can generate more accurate text. Learn more about the technique in prompting accurate text generation\\n\\nMidjourney V6 Text Generation Made Easy: 7 Pro Tips to Try 🎨\\nGetting Crisp, Accurate Text with Midjourney V6bootcamp.uxdesign.cc\\n\\n4. Vibrant Brights Convey Positivity and Excitement\\n\\nVibrant, saturated hues naturally promote positivity and grab the viewer’s focus. Combinations of bright primary colors and rainbow palettes deliver bold energy. Give your 2024 designs extra shine with this upbeat, lively trend.\\n\\nKeywords:\\n\\nBrightness\\n\\nColor\\n\\nElectric\\n\\nGradient\\n\\nPower\\n\\nVibrant\\n\\nAbstract pattern\\n\\nPrompt: 3D illustration of a abstract pattern, vibrant rainbow color palette, pop up color --ar 16:9\\n\\n\\n\\nProduct Design\\n\\nPrompt: A futuristic translucent sofa design in rainbow color palette --ar 16:9\\n\\n\\n\\nPackage Design\\n\\nPrompt: Beer bottle package design, vibrant illustration of abstract shapes --ar 16:9\\n\\n\\n\\n5. Grainy Gradients Blend Retro and Modern Styles\\n\\nGrainy gradients bridge vintage and contemporary aesthetics for timeless appeal. Mix grainy textures with modern fonts and abstract shapes to put a fresh spin on retro grain.\\n\\nUse as backgrounds to add depth and dimension.\\n\\nKeywords\\n\\nAbstract\\n\\nBackground\\n\\nColors\\n\\nGrainy\\n\\nGradients\\n\\nModern\\n\\nRetro\\n\\nTexture\\n\\nBackground\\n\\nPrompt: An abstract gradient background in pink and blue color, in the style of Grainy textured, light purple and orange --ar 16:9\\n\\n\\n\\nShapes\\n\\nPrompt: Grainy textures pattern and abstract shapes, retro grain style, pink and amber--ar 16:9\\n\\n\\n\\nPhoto Effect\\n\\nPrompt: A retro vintage close-up shot of a long hair girl wearing glasses, with a grainy textured, gradient purple tone --ar 16:9\\n\\n\\n\\n6. Collage\\n\\nIf you want to blend elements from different sources, consider creating collages. Collages allow you to combine various textures, images, and fonts into a single piece, making them ideal for experimenting with new ideas.\\n\\nThe start of a new year is a great opportunity to explore creative possibilities.\\n\\nKeywords:\\n\\nBotanical elements\\n\\nCollage\\n\\nFonts\\n\\nPastel tones\\n\\nPictures\\n\\nPhotography\\n\\nPlants\\n\\nTexture\\n\\nIllustration & Shapes\\n\\nPrompt: Collage in colorful shapes--ar 16:9\\n\\n\\n\\nMagazine\\n\\nPrompt: A collage of magazine pictures in creative ideas style--ar 16:9\\n\\n\\n\\nArt Style\\n\\nPrompt: A collage in the style of Dadaism --ar 16:9\\n\\n\\n\\nThere you have it - The First 6 of the 12 top visual design trends of 2024 with tips\\n\\nFrom Holographic to grainy gradients, this year offers diverse styles to engage your audience. Stay tuned for part two!\\n\\nNow go forth and design something beautiful and make an income out of it!\\n\\n\\n\\n👉🏻Digital Guide: Master Midjourney 🎨🚀\\n\\nIf you want to enhance your skills and explore advanced techniques, I have created a \"Master Midjourney: Beginner to Pro\" digital guide.\\n\\nIt comes with:\\n\\n🎨 1,000+ expert prompts to inspire your creativity\\n\\n💡 Advanced Midjourney prompt writing, structure and core techniques\\n\\n🖼 Specialized commercial guidance for graphic design, branding, logo, UI, photography, mockup and more\\n\\n🚀 Pro tips to recreate styles, make avatars, generate anime artwork, and more\\n\\n💰 AI Arts Monetisation Strategies\\n\\n💼 Top AI tools to edit Midjourney creations\\n\\n\\n\\n📚 Continuous education\\n\\nThis guide is designed for continuous education, new tutorials are added regularly so you stay ahead. With lifetime access for a single purchase, it’s the gift that keeps giving.\\n\\nI’ve poured my heart into creating this guide. I hope you enjoy it ❤️\\n\\n\\n\\nHey friends 👋 I am Christie - An AI Art Educator & Creator 😊 Also a coffee lover ❤️☕️\\n\\nIf you’re craving more Insider Tips, Prompts and Tricks for creating and generating income with AI art, join me on this journey.\\n\\n🎨 Hit that \"Follow\" button to stay in the loop for more AI wisdom\\n💌 Stay tuned for more tutorials!\\n\\nLet’s explore the limitless possibilities of AI Art and build passive income together! 🚀💰'}},\n",
       "  {'id': '865c0b54d1cb',\n",
       "   'title': 'Midjourney V6 Alpha is Now the Default with Improvements to Details, Contrast and Coherence🔥',\n",
       "   'subtitle': 'Prepared for NEW “describe” and “Character Consistency” Coming Soon!',\n",
       "   'author': '14176fcb5743',\n",
       "   'publication_id': '48e972f5c24e',\n",
       "   'published_at': '2024-02-15 13:02:01',\n",
       "   'last_modified_at': '2024-02-15 23:48:39',\n",
       "   'tags': ['midjourney',\n",
       "    'artificial-intelligence',\n",
       "    'creativity',\n",
       "    'design',\n",
       "    'art'],\n",
       "   'topics': ['design', 'programming'],\n",
       "   'claps': 163,\n",
       "   'voters': 11,\n",
       "   'word_count': 1155,\n",
       "   'responses_count': 2,\n",
       "   'reading_time': 5.758490566037736,\n",
       "   'url': 'https://bootcamp.uxdesign.cc/midjourney-v6-alpha-is-now-the-default-with-improvements-to-details-contrast-and-coherence-865c0b54d1cb',\n",
       "   'unique_slug': 'midjourney-v6-alpha-is-now-the-default-with-improvements-to-details-contrast-and-coherence-865c0b54d1cb',\n",
       "   'image_url': 'https://miro.medium.com/1*wybK0zuHORyKn8YH0AAELQ.png',\n",
       "   'lang': 'en',\n",
       "   'is_series': False,\n",
       "   'is_locked': True,\n",
       "   'is_shortform': False,\n",
       "   'top_highlight': '',\n",
       "   'content': {'id': '865c0b54d1cb',\n",
       "    'content': 'Midjourney V6 Alpha is Now the Default with Improvements to Details, Contrast and Coherence🔥\\n\\nPrepared for NEW \"describe\" and \"Character Consistency\" Coming Soon!\\n\\nWelcome guys! It’s another round of quick updates from Midjourney.\\n\\nMidjourney Alpha has just become the default model with a beta version coming soon with better aesthetics, text rendering, improved prompt understanding and more.\\n\\nStyle References, Outpainting and Inpainting are also available in Niji 6 now!\\n\\nLet’s see what new features are coming 🔥\\n\\n\\n\\nMidjourney V6 is Now the Default🔥\\n\\nV6 Alpha is now the Default Model\\n\\nThere is an improved Texture and Consistency\\n\\nIf you want to use V5.2 or the previous version please type /settings and select \"Version V5.2\"\\n\\n\\n\\nV6 Beta Upgrade\\n\\nKey upgrades include significantly improved text rendering, coherency, and prompt accuracy. Creations will also feature more realistic details such as hands, along with improvements in:\\n\\nBetter Text Generation with better texture\\n\\nBetter Prompting and Coherence\\n\\nAesthetic Improvement\\n\\nOptimizations for Improved Performance\\n\\nFaster Speed: Could get 2x faster with a turbo mode\\n\\n📅 Estimate Date: In the next two weeks\\n\\nThere might be a rating party before the launch, probably this friday\\n\\n👉🏻 As some of you may be aware, the latest Midjourney V6 has an improved method for understanding prompts. Here, I discuss the top Top 9 Tips to Master Prompting with V6\\n\\n9 Midjourney V6. Prompting Technique You Need to Know 🎨\\nRelearn Prompt Writing to Take Your AI Art to the Next Level!bootcamp.uxdesign.cc\\n\\nNiji 6 - Style References, Pan, Zoom and Inpainting are now available!\\n\\nThese beloved long-awaited capabilities have arrived!\\n\\nStyle References: Allows you to replicate a style and maintain the aesthetic easily.\\n\\nVary Region(Inpainting): Enable removing unwanted elements or changing parts of an image.\\n\\nZoom Out: Provides greater control over cropping and perspective (1.5 / 2 / Custom).\\n\\nPan: Extend your image in four different directions\\n\\nUsage of Niji Style References\\n\\nYou can use --sref, followed by a URL to give your Niji 6 generation a \"style reference\"\\n\\n/imagine [ your prompt ] --sref[ link to your style reference image ]\\n\\nLet’s look at the example below\\n\\n\\n\\n\\n\\nFor now, --sref is only available on the niji v6 alpha and midjourney v6 alpha, and will likely be updated for the niji 6 full release.\\n\\nLearn more about the tricks to using \"Style References\"here:\\n\\nMidjourney V6 New \"Style References\" - 4 Advanced Tips to Master Consistent Style🎨\\nReplicate a Style and Maintain Consistent Aesthetics Easily!bootcamp.uxdesign.cc\\n\\nPlanned Improvements for MidJourney V7 🔥\\n\\nEnhanced text quality\\n\\nImproved pixel image quality and Increased coherence\\n\\nAdvanced prompt understanding and details in images\\n\\nDevelopment progress is already underway with a promise of substantial advancement comparable to previous version transitions\\n\\n\\n\\n💻 Midjourney Website\\n\\nMidjourney Website Alpha is available for users who have generated over 1K images! As the website stabilizes, it will be accessed to more existing members.\\n\\nCheck how many images you’ve made with /info\\n\\nYou can access the site here: http://alpha.midjourney.com/\\n\\n\\n\\nHighlights of Alpha\\n\\nImage Creation\\n\\nBatch Download\\n\\nSmart Folders for Organisation\\n\\nImage Prompt & Style References Made Easy\\n\\n👉🏻 I have recently published a Guide to the Alpha Website, learn more about the new features here:\\n\\nUltimate Guide to Using Midjourney Website Alpha! 💻\\nImage Generation, Batch download and Smart Organisation with Ease!bootcamp.uxdesign.cc\\n\\nSocial: More social features will allow users to share and engage with Midjourney creations in new ways.\\n\\nEducational Resources: For new users, educational resources and onboarding tools will be added soon\\n\\n\\n\\nNew Exciting Features Coming Soon 🚀\\n\\n1. A new /describe\\n\\nThe Midjourney team is working on an entirely brand-new /describe feature.\\n\\nIt will be more powerful and accurate than before.\\n\\n📅 Estimated Release: This week or early next week\\n\\nThe /describe command is great at replicating an aesthetics of the image. I am sure the latest/describe will work great with \"Style References\" to replicate an art style\\n\\n3 Steps to Replicate An Image with Midjourney\\nLearn How to use /Describe and Image Promptbootcamp.uxdesign.cc\\n\\n2. Character Consistency 🎨\\n\\nThe consistent character system is currently in development. It will:\\n\\nFunction similarly to Style References with the --crefargument\\n\\nIt enables users to modify colors and backgrounds while maintaining a consistent character.\\n\\nUsers may have the option to specify which elements of the image they want to maintain consistency, such as color, clothing, or facial features.\\n\\n📅 Estimated Release Date: It will take several weeks more.\\n\\n3. New Style Tuner - Upcoming in V6.1🚀\\n\\nA rebuilt-style tuner is also nearing release. It is currently underway and will be a completely new style tuner compared to the previous version.\\n\\nIt will work like a \"Model Tuner\" and will enable\\n\\nGreater Customization over generated images.\\n\\nMore Personalization\\n\\n📅 Estimated Release: 1–2 months\\n\\n\\n\\n👉🏻What’s More?\\n\\nA NEW /feedback command\\n\\nMidjourney just launched a new \"/feedback\" command which lets you:\\n\\nSubmit ideas for future development\\n\\nRate ideas from other users\\n\\nSee ratings on your ideas\\n\\n\\n\\nThe aim is to establish a global leaderboard for ideas, fostering community collaboration and discussions on the path forward.\\n\\nVideo 🎥\\n\\nUnlike other video AI, Midjourney aims for visual excellence by default. After months of refinement, this new modality will emerge unlike anything seen before.\\n\\nReal-Time Drawing & Training Controlnets\\n\\nIn progress\\n\\nThis will set Midjourney apart from other similar offerings\\n\\nThere is ongoing training for Controlnets as the current progress is not up to standards\\n\\nStay tuned️ for all these great new features launching soon💌\\n\\nMidjourney V6 Essentials\\n\\nWith guide for text generation, prompt multiple objects and techniques for stunning images.\\n\\nSave the list and never miss any Expert Tutorials\\n\\nMidjourney V6 Essentials\\nEdit descriptionmedium.com\\n\\n\\n\\n👉🏻Passive Income with AI art: Master Midjourney 🎨\\n\\nDon’t Get Left Behind in the AI Art Gold Rush of 2024! Midjourney is exploding. Early adopters are raking in big bucks selling AI art online.\\n\\nThis is your ticket to passive income with AI art.💰- \"Master Midjourney 2024: Beginner to Pro\" digital guide.\\n\\nIt comes with:\\n\\n🎨 1,000+ money-making prompts for stunning, sellable art\\n\\n💡 Advanced Midjourney prompt writing, structure and techniques\\n\\n🖼 Specialized commercial guidance for graphic design, branding, logo, UI, photography, mockup and more\\n\\n🚀 Insider tips to maximize profits\\n\\n💰 AI Arts Monetisation Strategies\\n\\n💼 Top AI tools to edit Midjourney creations\\n\\n\\n\\n📚 Continuous education\\n\\nThis guide is designed for continuous education, new tutorials are added regularly so you stay ahead. With lifetime access for a single purchase, it’s the gift that keeps giving.\\n\\nI’ve poured my heart into creating this guide. I hope you enjoy it ❤️\\n\\n\\n\\nHey, Friends 👋 I am Christie - An AI Art Educator & Creator 😊 Also a coffee lover ❤️☕️\\n\\nIf you’re craving more Insider Tips, Prompts and Tricks for creating and generating income with AI art, join me on this journey.\\n\\n🎨 Hit that \"Follow\" button to stay in the loop for more AI wisdom\\n💌 Stay tuned for more tutorials & Midjourney updates!\\n\\nLet’s explore the limitless possibilities of AI and build passive income together! 🚀'}},\n",
       "  {'id': '6e8d6357da20',\n",
       "   'title': 'Midjourney V6 Essential- Transform Style with “Remix” 🎨',\n",
       "   'subtitle': 'A Structure to follow with Visual Examples and Usage',\n",
       "   'author': '14176fcb5743',\n",
       "   'publication_id': '48e972f5c24e',\n",
       "   'published_at': '2024-02-12 13:01:48',\n",
       "   'last_modified_at': '2024-02-12 22:20:55',\n",
       "   'tags': ['midjourney',\n",
       "    'artificial-intelligence',\n",
       "    'creativity',\n",
       "    'design',\n",
       "    'art'],\n",
       "   'topics': ['design'],\n",
       "   'claps': 416,\n",
       "   'voters': 25,\n",
       "   'word_count': 1279,\n",
       "   'responses_count': 5,\n",
       "   'reading_time': 6.576415094339622,\n",
       "   'url': 'https://bootcamp.uxdesign.cc/midjourney-v6-essential-transform-style-with-remix-6e8d6357da20',\n",
       "   'unique_slug': 'midjourney-v6-essential-transform-style-with-remix-6e8d6357da20',\n",
       "   'image_url': 'https://miro.medium.com/1*SrQ7YHs4cumUYkm1j5Kxfw.png',\n",
       "   'lang': 'en',\n",
       "   'is_series': False,\n",
       "   'is_locked': True,\n",
       "   'is_shortform': False,\n",
       "   'top_highlight': '',\n",
       "   'content': {'id': '6e8d6357da20',\n",
       "    'content': 'Midjourney V6 Essential- Transform Style with \"Remix\" 🎨\\n\\nA Structure to follow with Visual Examples and Usage\\n\\nRemixing in Midjourney V6 has improved in comparison to V5. It allows you to reimagine an image while preserving the overall structure and arrangement of the original.\\n\\nThis feature is amazing if you wish to change the subject or medium of your image. Previously, I introduced the \"4W1H\" Technique and \"Text Generating Pro Tips\" in structuring your prompt\\n\\nToday, I will share some tricks to maximize the potential of REMIX!\\n\\n\\n\\nMidjourney\\n\\nMidjourney’s AI Art Generative Tool is a remarkable game-changer for unleashing your creative potential! This fantastic technology uses artificial intelligence and machine learning to help you easily create stunning visuals.\\n\\nIf you are just starting, I know it’s challenging to craft the perfect prompt. So, here is a beginner’s guide and list of prompts to get you started:\\n\\nMidjourney Comprehensive Guide: Commands, Features and Tricks here!\\nHow to Use Midjourney to Elevate Your Images and Creativitybootcamp.uxdesign.cc\\n\\n20+ Incredible Midjourney Prompts You Must Try!\\nElevate Your AI Arts with These Creative Promptsbootcamp.uxdesign.cc\\n\\n\\n\\nToday’s content will be broken down into three parts:\\n\\nPart One: What is Remix Mode\\n\\nPart Two: How to use Remix\\n\\nPart Three: Creative Usage- Creating Hidden Face in An Image\\n\\nPart One: What is Remix Mode\\n\\nRemix Mode allows you to modify prompts, parameters, model versions, and aspect ratios to create variations of an original image. It takes the main elements of your initial image and uses them in a new task.\\n\\nIt is helpful for:\\n\\nChanging the setting or lighting of an image\\n\\nEvolving a subject\\n\\nCreating more complex compositions.\\n\\nExperimenting with different aspects of the original image to achieve the desired result.\\n\\nPart Two: How to use Remix\\n\\nStep 1: Activate \"Remix Mode\\n\\n\"Activate Remix mode with the /prefer remix command or by using the /settings command and toggling the 🎛️ Remix Mode button.\\n\\n\\n\\nRemix changes the behavior of the variation buttons (V1, V2, V3, V4) under image grids. When Remix is enabled, it allows you to edit your prompt during each variation.\\n\\nStep 2: Generate an image\\n\\nGenerate an image with /imagine\\n\\n\\n\\nFor Example: We want to transform a photograph into an illustration.\\nLet’s see what we will need to do next\\n\\nStep 3: Upscale a preferred image\\n\\nRemix changes the behavior of the variation buttons (V1, V2, V3, V4) under image grids.\\n\\n\\n\\nStep 4: Remix Prompt: (Vary Subtle)\\n\\nWhen Remix is enabled, it allows you to edit your prompt during each variation.\\n\\nChoose \"Vary Subtle\" to access a pop-up that allows you to rewrite your prompt.\\n\\nStep 5: Rewrite Your Prompt\\n\\nInput the changes you want to make\\n\\nFor instance, you can transform a photograph into an illustration. As an example, we transformed a photo of a man into a 3D rendering of a robot.\\n\\n\\n\\n\\n\\nHere is the result\\n\\nCustom Prompt: 3D render of a chrome robot with long beard. Indoors with soft, diffused lighting --v6 --style raw\\n\\n\\n\\nWe have transformed a photograph into an illustration.\\n\\n\\n\\nBreakdown\\n\\nThis example starts with a simple portrait photo of an older man and then remixes it into a completely different style and subject - a robot with long bears!\\n\\nOriginal Prompt:\\n\\n35mm film medium shot of a a 40-year-old Japanese man with a beard wearing a suit. Indoors with soft, diffused lighting --v6 --style raw\\n\\n✨ Remix Prompt: (Vary Subtle):\\n\\n3D render of a chrome robot with long beard. Indoors with soft, diffused lighting --v6 --style raw\\n\\nThe remixing allows you to take the basics like the face, beard, pose, etc. and reimagine them with a new creative spin.\\n\\nSome key details that change in the remix:\\n\\nPhoto to 3D render\\n\\nBusiness suit to robotic suit\\n\\nLonger grey beard\\n\\nDramatic lighting instead of soft\\n\\nYou can transform an image in so many ways while still harnessing the core aspects.\\n\\nHere is another example of a woman\\n\\nOriginal Prompt:\\n\\nPhoto of a smiling young woman standing on a beach at sunset. She has long blonde hair and is wearing a red sundress. Warm golden hour lighting.\\n\\n✨ Remix Prompt: (Vary subtle):\\n\\nRemixed into A cartoon avatar pixar style girl wearing a red dress, soft lighting\\n\\n\\n\\nIn this example, the original beach sunset photo is transformed into a completely different style and scene through remixing. Some key changes include:\\n\\nPhoto to cartoon avatar\\n\\nWarm lighting to soft lighting\\n\\nThe subject stays the same but the style interpretation changed.\\n\\n\\n\\nPart Three: Creative Usage- Creating Hidden Face in An Image\\n\\n\\n\\nThis idea is inspired by Jim the AI Whisperer from his article \" How to create hidden face portraits on MidJourney\\n\\nStep 1: Create the Base Image\\n\\nUse Midjourney to create a portrait and add the \" --stop 20\" parameter to make it blurry.\\n\\n\\n\\nTip by Jim: \"You want to generate an image that’s washed out, sketchy, blurred, or outlined. Nothing too detailed. However, it still needs to be recognizable. Basically, reroll until you can see who it is if you squint at it.\"\\n\\nYou will get a blurry image like this\\n\\n\\n\\nStep 2: Upscale the Image\\n\\nThen, upscale the image and hit \"Vary (subtle)\" to prompt the desired scene.\\n\\nStep 3: Remix with Prompt\\n\\nRemember to take away the --stop parameter.\\n\\nThis should result in a finished masterpiece with small and sweeping details.\\n\\n\\n\\nHere you go!\\n\\n\\n\\n\\n\\nHere is an in-depth article by Jim the AI Whisperer where he breaks down the steps and ideas of creating hidden face portraits. Be sure to check it out!\\n\\nHow to create hidden face portraits on MidJourney\\nOptical illusions: Making double images with AI artmedium.com\\n\\nFinal Thoughts\\n\\nAs you can see, the remixing feature provides an efficient way to explore variations of an image while locking down the core composition and subject matter. This frees you up to get creative with the details!\\n\\nTips for Remixing Successfully\\n\\nHere are some tips to help you get the most out of image remixing in Midjourney:\\n\\nKeep prompts clear and focused - highlight the key constant elements you want to retain.\\n\\nStart with minor stylistic changes before making dramatic shifts.\\n\\nRemixed elements should relate logically to the original image.\\n\\nTry remixing the same image in different ways.\\n\\nHave fun and let your creativity run wild!\\n\\n\\n\\n👉🏻Passive Income with AI art: Master Midjourney 🎨\\n\\nDon’t Get Left Behind in the AI Art Gold Rush of 2024! Midjourney is exploding. Early adopters are raking in big bucks selling AI art online.\\n\\nThis is your ticket to passive income with AI art.💰- \"Master Midjourney 2024: Beginner to Pro\" digital guide.\\n\\nIt comes with:\\n\\n🎨 1,000+ money-making prompts for stunning, sellable art\\n\\n💡 Advanced Midjourney prompt writing, structure and techniques\\n\\n🖼 Specialized commercial guidance for graphic design, branding, logo, UI, photography, mockup and more\\n\\n🚀 Insider tips to maximize profits\\n\\n💰 AI Arts Monetisation Strategies\\n\\n💼 Top AI tools to edit Midjourney creations\\n\\n\\n\\n📚 Continuous education\\n\\nThis guide is designed for continuous education, new tutorials are added regularly so you stay ahead.\\n\\nI’ve poured my heart into creating this guide. I hope you enjoy it ❤️\\n\\n\\n\\nHey, Friends 👋 I am Christie - An AI Art Educator & Creator 😊 Also a coffee lover❤️☕️\\n\\nIf you’re craving more Insider Tips, Prompts and Tricks for creating and generating income with AI art, join me on this journey.\\n\\n🎨 Hit that \"Follow\" button to stay in the loop for more AI wisdom\\n💌 Stay tuned for more tutorials!\\n\\nLet’s explore the limitless possibilities of AI and build passive income together! 🚀\\n\\n✨Midjourney V6 Essentials: Insider Tips and Prompting Skills\\n\\nBe sure to save this list and never miss any tips on Midjourney V6.\\n\\nMidjourney V6 Essentials\\nEdit descriptionmedium.com'}},\n",
       "  {'id': '92741d8fb067',\n",
       "   'title': 'Ultimate Guide to Using Midjourney Website Alpha! 💻',\n",
       "   'subtitle': 'Image Generation, Batch download and Smart Organisation with Ease!',\n",
       "   'author': '14176fcb5743',\n",
       "   'publication_id': '48e972f5c24e',\n",
       "   'published_at': '2024-02-09 13:01:32',\n",
       "   'last_modified_at': '2024-02-09 21:42:14',\n",
       "   'tags': ['midjourney',\n",
       "    'artificial-intelligence',\n",
       "    'creativity',\n",
       "    'design',\n",
       "    'art'],\n",
       "   'topics': ['design'],\n",
       "   'claps': 584,\n",
       "   'voters': 55,\n",
       "   'word_count': 1139,\n",
       "   'responses_count': 7,\n",
       "   'reading_time': 6.44811320754717,\n",
       "   'url': 'https://bootcamp.uxdesign.cc/ultimate-guide-to-using-midjourney-website-alpha-92741d8fb067',\n",
       "   'unique_slug': 'ultimate-guide-to-using-midjourney-website-alpha-92741d8fb067',\n",
       "   'image_url': 'https://miro.medium.com/1*wkYFlLubAFBU-8aWHkqtfQ.png',\n",
       "   'lang': 'en',\n",
       "   'is_series': False,\n",
       "   'is_locked': True,\n",
       "   'is_shortform': False,\n",
       "   'top_highlight': '',\n",
       "   'content': {'id': '92741d8fb067',\n",
       "    'content': 'Ultimate Guide to Using Midjourney Website Alpha! 💻\\n\\nImage Generation, Batch download and Smart Organisation with Ease!\\n\\nExciting News! Midjourney Website Alpha is available for users who have generated over 1000 images! As the website stabilizes, it will be accessed to more existing members.\\n\\nWith Midjourney\\'s new website, you can now create and organize images, reuse images and prompts and get inspired!\\n\\nToday, let me share how you can fully utilize the features on the website!\\n\\n\\n\\nMidjourney Website\\n\\nThere are three main sections on the website:\\n\\n1. Explore\\n\\nGet Inspiration: Images are placed in Random/Hot/Top/Likes\\n\\nImages Created from Other Users: You can reuse the prompt or even image as an image prompt easily. Learn how to do that in a later section.\\n\\n\\n\\n2. Create\\n\\nImage Creation: Easily generate images and reuse prompts. Now, you can generate images on the Midjourney website with the textbox located on the top.\\n\\n3. Archive\\n\\nOrganize: Group and organize images easily\\n\\nView Customization: Layout and image size\\n\\nFilters: Filter images with options like image size, version, type or more\\n\\nToday, let me share with you the way to work with the Alpha Midjourney Website to create and organize images\\n\\nSection One: Create\\n\\nSection Two: Archive\\n\\n\\n\\nSection One: Create\\n\\n1. Image Generation\\n\\nYou can now create images easily on the website with the Imagine textbox located on the top part of the website.\\n\\n\\n\\nHow do you generate an image on the Midjourney Website?\\n\\nStep 1: Go to the \" Imagine\" textbox\\n\\nStep 2: Type in words that describe the image you want to create, you can type a general description or be more specific adding styles and details.\\n\\nStep 3: Adjust parameters\\n\\nStep 4: Press \"Enter\" and your images will be generated\\n\\n\\n\\nThe website allows you to adjust the parameters easily including\\n\\nAspect Ratio: Image size\\n\\nMode: Standard/Raw\\n\\nVersion: Midjourney version\\n\\nStylization: Application of Midjourney’s default aesthetic style.\\n\\nWeirdness: Adds unusual aesthetics.\\n\\nVariety (Chaos): Unusual and unexpected results.\\n\\nSpeed: Relax/Fast/Turbo\\n\\nThe images you created will then appear down below.\\n\\n2. Further Customisation\\n\\nYou also have the option to perform the following actions without needing to upscale an image:\\n\\n\\n\\nOnce you go into the lightbox, you can access more functionalities\\n\\nVary ( Subtle & Strong )\\n\\nUpscale (2x/4x/Sutble/Creative)\\n\\nRemix (Sutble/ Strong)\\n\\nPan ( Up/Down/Left/Right)\\n\\nInpainting ( Vary Region )\\n\\nRerun or Use: Prompt\\n\\nChange AR: For Change aspect ratio\\n\\nChange AR\\n\\nIf you have read my recent updates on Midjourney, you will know that the \"Change AR\" allows you to easily change the asepct ratio with the dragging bar on the Midjourney website.\\n\\n\\n\\n\\n\\n3. Image Prompt & Blend Made Easy\\n\\nWith the Midjourney website, you can prompt easily with images with blend and image prompts.\\n\\nBlend: The blend command allows you to upload 2–5 images and merge the aesthetics.\\n\\nWith the website now, you can easily upload a photo:\\n\\nStep 1. Press the \"+\" icon\\n\\nStep 2. Choose a file or drop a file\\n\\n\\n\\n\\n\\nAlternatively, you can directly drag and drop images that you created directly to the \" Imagine\" textbox.\\n\\nClick \" Create\"\\n\\n\\n\\n\\n\\nHere is the result of blending two images.\\n\\nResult of Blending Two Images\\n\\n⭐️ Extra: User other’s Images\\n\\nYou can even use others’ images easily for \"blend\" or as an \"image prompt\" simply by dragging the image into the textbox like what I show you above.\\n\\n\\n\\n4. Style References\\n\\nYou can do the same with Midjourney V6 New \"Style References\" by including a URL or dragging the image.\\n\\nStep 1: Copy the URL of the Image\\n\\nUpon generating a new image, right-click to access the URL of the image or Copy the Image URL from the lightbox.\\n\\n\\n\\nStep 2: Include the URL with the parameter \"--sref\"\\n\\nAdd the URL after the command --sreflike this below\\n\\n\\n\\nExtra: Image Prompt with Style References\\n\\nYou can also include an image prompt together with \"Style References\".\\n\\n\\n\\n👉🏻 How to tell if you use an Image Prompt or Style References?\\n\\nThere will be a pin 📌 if the image is used as a \"Style References\"\\n\\n\\n\\nLearn more about \"Style References\" here where I share four advanced tips to fully optimise the feature:\\n\\nMidjourney V6 New \"Style References\" - 4 Advanced Tips to Master Consistent Style🎨\\nReplicate a Style and Maintain Consistent Aesthetics Easily!bootcamp.uxdesign.cc\\n\\n\\n\\nSection Two: Archive\\n\\n1. Batch Download and More\\n\\nYou can now select more than one image at a time and download them in batches or take more actions like \"Like, Hide or Add to Folder.\"\\n\\n\\n\\n2. Create a Folder for Organization\\n\\nThe Midjourney website allows for creating folders for categorisation.\\n\\nStep 1: Head over to \" Archive\"\\n\\nStep 2: Select \"Organise\" from the top right corner\\n\\nStep 3: Select \" Folder\" and click \"Create Folder\"\\n\\n\\n\\nStep 3: Select \" Smart Folder\"\\n\\nStep 4: Input the keywords used in your prompt in \"Search Terms\", for example \" Isometric\"\\n\\nStep 5: Give it a Title\\n\\n\\n\\nStep 6: Create Folder\\n\\n\\n\\n3. View and Filter Customization\\n\\nYou can now have more options when filtering images to customize the view\\n\\n\\n\\n📌 Things to Note\\n\\nSomewhat Unstable: features may change suddenly\\n\\nDesktop Focus: Mobile works but it has UI/UX issues and bugs. It will improve until the Desktop version matures\\n\\nEncouraged to use both Desktop and Discord: Both platforms are important for community, events, support, feedback, private servers\\n\\nFinal Thoughts\\n\\nThe website aims to evolve into a hub for Midjourney fans, with David emphasizing the goal of transforming Midjourney into a community rather than just a tool.\\n\\nMore website upgrade is set to be released this year. Stay tuned!\\n\\n\\n\\n👉🏻Passive Income with AI art: Master Midjourney 🎨\\n\\nDon’t Get Left Behind in the AI Art Gold Rush of 2024! Midjourney is exploding. Early adopters are raking in big bucks selling AI art online.\\n\\nThis is your ticket to passive income with AI art.💰- \"Master Midjourney 2024: Beginner to Pro\" digital guide.\\n\\nIt comes with:\\n\\n🎨 1,000+ money-making prompts for stunning, sellable art\\n\\n💡 Advanced Midjourney prompt writing, structure and techniques\\n\\n🖼 Specialized commercial guidance for graphic design, branding, logo, UI, photography, mockup and more\\n\\n🚀 Insider tips to maximize profits\\n\\n💰 AI Arts Monetisation Strategies\\n\\n💼 Top AI tools to edit Midjourney creations\\n\\n\\n\\n📚 Continuous education\\n\\nThis guide is designed for continuous education, new tutorials are added regularly so you stay ahead. With lifetime access for a single purchase, it’s the gift that keeps giving.\\n\\nI’ve poured my heart into creating this guide. I hope you enjoy it ❤️\\n\\n\\n\\nHey, Friends 👋 Christie here - An AI Art Educator & Creator 😊 Also a Coffee Lover❤️☕️\\n\\nIf you’re craving more Insider Tips, Prompts and Tricks for creating and generating income with AI art, join me on this journey.\\n\\n🎨 Hit that \"Follow\" button to stay in the loop for more AI wisdom\\n💌 Stay tuned for more tutorials!\\n\\nLet’s explore the limitless possibilities of AI Art and build passive income together! 🚀💰'}}],\n",
       " '9b351e8113e9': [{'id': 'a2ce57de0b02',\n",
       "   'title': 'Is Mamba the End of ChatGPT As We Know It?',\n",
       "   'subtitle': 'The Great New Question',\n",
       "   'author': '9b351e8113e9',\n",
       "   'publication_id': '98111c9905da',\n",
       "   'published_at': '2024-01-11 18:02:22',\n",
       "   'last_modified_at': '2024-01-11 18:02:22',\n",
       "   'tags': ['technology',\n",
       "    'artificial-intelligence',\n",
       "    'chatgpt',\n",
       "    'future',\n",
       "    'data-science'],\n",
       "   'topics': ['artificial-intelligence', 'machine-learning'],\n",
       "   'claps': 6308,\n",
       "   'voters': 1229,\n",
       "   'word_count': 1711,\n",
       "   'responses_count': 76,\n",
       "   'reading_time': 7.406603773584906,\n",
       "   'url': 'https://pub.towardsai.net/is-mamba-the-end-of-chatgpt-as-we-know-it-a2ce57de0b02',\n",
       "   'unique_slug': 'is-mamba-the-end-of-chatgpt-as-we-know-it-a2ce57de0b02',\n",
       "   'image_url': 'https://miro.medium.com/0*Igf3DFdae9Kd14Iy',\n",
       "   'lang': 'en',\n",
       "   'is_series': False,\n",
       "   'is_locked': True,\n",
       "   'is_shortform': False,\n",
       "   'top_highlight': 'Just like the attention module sits at the core of the Transformer, the Selective State Space Model (Selective SSM) sits at the core of Mamba.',\n",
       "   'content': {'id': 'a2ce57de0b02',\n",
       "    'content': 'Is Mamba the End of ChatGPT As We Know It?\\n\\nThe Great New Question\\n\\n\\n\\nTwo researchers have made the boldest claim in years: throwing the biggest algorithmic breakthrough of the 21st century out the window.\\n\\nNamed Mamba, it achieves what was once thought impossible: matching or beating the Transformer’s language modeling capabilities while being faster and a lot cheaper.\\n\\nEveryone seems to be talking about it, so let’s uncover what Mamba is.\\n\\nThis insight and more I share in Medium have previously been shared in my weekly newsletter, TheTechOasis.\\n\\nIf you want to be up-to-date with the frenetic world of AI while also feeling inspired to take action or, at the very least, to be well-prepared for the future ahead of us, this is for you.\\n\\n🏝Subscribe below🏝\\n\\nSubscribe | TheTechOasis\\nThe newsletter to stay ahead of the curve in AIthetechoasis.beehiiv.com\\n\\nThe Gift that Keeps on Giving\\n\\nSince its release in 2017, the Transformer architecture has become the ‘de facto’ choice for natural language modeling (models that generate text).\\n\\nChatGPT, Gemini, Claude, you name it, all are based on this seminal architecture.\\n\\nThe intrusiveness of this architecture is such that the ‘T’ in ChatGPT stands for ‘Transformer’.\\n\\nA sequence-to-sequence model, (takes a sequence as input, be that a text passage or a sequence of pixels in an image, and gives you another sequence, usually new text) the secret sauce of the Transformer is the attention mechanism.\\n\\nIn straightforward terms, it performs a pair-wise multiplication among all tokens in the sequence, making them ‘talk’ to uncover the relationships between words.\\n\\nPut simply, it indicates each word which words in the sequence it should be paying ‘attention’ to. For instance, the attention mechanism over a pronoun will allow it to pay attention to its noun.\\n\\nWorks wonderfully, but at a huge cost.\\n\\nMastering inefficiency\\n\\nPut simply, the Transformer yields impressive performance at the cost of being extremely inefficient.\\n\\nTo understand how models like ChatGPT process language, imagine you’re halfway reading a Harry Potter book.\\n\\nHowever, to successfully read the next page, you have to store all the pages read previously in your mind, the complete context. Put simply, to read the next word, you have to reread everything until that point again.\\n\\nAnd so forth.\\n\\nTransformers don’t actually re-read everything every time, they store a cache of previous calculations.\\n\\nHowever, it forces them to store all those calculations in memory, which in comparison is as if you had to remember every single word you read earlier to successfully read the next one.\\n\\nThat’s how Transformers like ChatGPT process language. Seems very inefficient, right?\\n\\nYes, because it is.\\n\\nBut how do humans read a Harry Potter book?\\n\\nYeah, surely we do remember many things read until that point, but we forget irrelevant data like Hermione’s summer activities. They are not relevant to the storyline, so our mind forgets about it.\\n\\nIn other words, instead of retaining all the information read until now, we build a compressed representation of the story, keeping relevant data and erasing irrelevant points.\\n\\nIn layman’s terms, what I am trying to tell you is that Transformers don’t compress context. But as context isn’t compressed, the computation requirements of Transformers grow considerably as the text sequence grows larger.\\n\\nSpecifically, Transformers have quadratic and linear complexity for training and inference respectively.\\n\\nIn other words, in training, doubling the sequence quadruples the cost, and in inference (execution), doubles it.\\n\\nSo what do research labs do?\\n\\nTo avoid costs spiraling out of control, they limit the ‘workspace’ of the model to a context window, which is why ChatGPT and others have a limited size of text they can process.\\n\\nOver the years, many different architectures with more ‘efficient’ attention mechanisms have been proposed, but the loss of performance has prevented them from really substituting the vanilla Transformer.\\n\\nSo what did Mamba’s researchers do?\\n\\nSimply, throw attention, the biggest algorithmic breakthrough over the last years, out of the window.\\n\\nInto a Stateful World\\n\\nThe Mamba architecture was born from a critical question: Can we model language as effectively as the Transformer while being far more efficient?\\n\\nAnd the answer was yes, thanks to what we define as ‘state’.\\n\\nCircling back to the Harry Potter example, when we are reading a book, we keep an updated state of the book; we slowly build a compressed, approximated understanding of what’s going on, keeping the key elements stored and rejecting the rest.\\n\\nIn essence, this is exactly what Mamba does.\\n\\nGive me 3 ‘s’\\n\\nJust like the attention module sits at the core of the Transformer, the Selective State Space Model (Selective SSM) sits at the core of Mamba.\\n\\nAn SSM is a rather new language modeling architecture inspired by state space models from the 1960s.\\n\\nIn simple terms, the model keeps a ‘state’, or memory, that serves as context. In other words, the next output will be a function of the current input and my current state up till that point.\\n\\nIf the current input is ‘Harry’, the SSM will use its state to infer that the next word is probably ‘Potter’. As it has probably seen both words together earlier, the state will remember this.\\n\\nHowever, ChatGPT can predict ‘Potter’ too, right?\\n\\nYes, but the key thing here is that Selective SSMs keep only the context that matters in memory, which means they achieve linear and constant complexities for training and inference.\\n\\nIn other words, if the sequence doubles the cost of training doubles (Transformers quadruple) while the inference cost remains constant no matter the length!\\n\\nConstant inference complexity is achieved because the state has a fixed size, the cost doesn’t increase no matter how long the sequence is, the model simply stores the key information and forgets the rest.\\n\\nOn the flipside, these models’ predictions are as good as their compressed context is.\\n\\nBut how can Selective SSMs choose what context to keep and Transformers don’t?\\n\\nThe answer to that is selectivity.\\n\\nTo choose or not choose, the question is\\n\\nWhat makes Mamba unique is that its SSM module is selective, it chooses what context to keep and what to discard. In other words, it performs what we define as compression by selection.\\n\\nLike any other state space model, the model is driven by two equations:\\n\\n\\n\\nWith parameters A, B, we first obtain the state h (the memory) and then the new output, y, with C.\\n\\nYou can think of these parameters as ‘gates’.\\n\\nAs A multiples the previous state, it decides if it’s relevant or not for the next prediction.\\n\\nB decides if the current input is important or not, computing the new state.\\n\\nUltimately, C decides how this information is turned into an output.\\n\\nThe key to allowing this is that, unlike all previous architectures, Mamba is input and time-dependent.\\n\\nIn this case, researchers decided to make A constant, although it can be parametrized too.\\n\\nSelective SSMs\\n\\nAs we want the model to be able to compress context, it has to be capable of selecting what should be used as context and what not.\\n\\nFor instance, if the next word is ‘um’, so typical of our dear Brits, that is probably not very relevant to context, and, thus, gets rejected.\\n\\nTo allow this phenomenon, as mentioned, Mamba introduces a new paradigm where the weights of the model depend on the input and change over time.\\n\\nIn the Transformer, the weights are fixed, meaning that it can’t choose what to keep or not. By making the weights a variable of the input, they can adapt to every input.\\n\\nAnd what does the parameter ∆ do?\\n\\nServes as the main selective gate, ultimatemly deciding how much importance the model is going to give to the input x.\\n\\nModel-wise, this SSM module is inserted into a Mamba block, and stacked homogeneously to build the actual model.\\n\\nMamba block\\n\\nBut if the key was simply to make the weights input-dependent, why wasn’t this done in earlier State Space Models?\\n\\nState Space Models are recurrent models, meaning that input is treated sequentially. Or, to put it another way, their computations aren’t parallelizable… unless you make the model Linear-time invariant, or LTI.\\n\\nAs LTI State Space Models are linear and don’t change over time, we can apply convolution to the two equations we saw earlier without having to materialize the hidden state, reducing costs drastically and parallelizing the computation.\\n\\nWith convolution, we don’t need to calculate h to calculate y\\n\\nHowever, as Mamba makes the weights of the model input-dependent, you lose the convolution capability that unlocks parallelization, fundamental to running these models on GPUs.\\n\\nTo solve this, researchers made Mamba hardware-aware, meaning it only materializes the hidden state, something you must do as the model can’t apply convolutions, into memory at the super-fast SRAM level.\\n\\nWhat they actually do is perform kernel fusion, a parallel scan instead of a convolution, and a recomputation of the intermediate states during backpropagation in training.\\n\\nWithout going into much detail, what they are essentially doing is applying several optimizations to reduce the number of I/O memory events, which in turn means that, although the model is recurrent, is still as efficient as Transformers.\\n\\nBut the real question is: how does Mamba fare in comparison to Transformers?\\n\\nExciting, but Questions Remain\\n\\nTested at different small sizes (up to 7 billion parameters), Mamba beats every other model, including GPTs of similar sizes, both in perplexity (a measure of how well a model predicts the next token) and accuracy.\\n\\nIt even manages to match the results of a Transformer more than two times its size!\\n\\nAlso, it shows no accuracy decrease with increased length, something unheard of until now:\\n\\n\\n\\nHowever, Mamba has yet to be proven at big sizes.\\n\\nEither way, it proves that recurrent networks to model language are making a stellar return, as Mamba’s results are not only a statement of quality, but the fact that they successfully incorporate state into a scalable solution makes the architecture in itself a thing of beauty and, more importantly, it simply makes sense.\\n\\nWere these results to extrapolate to LLM state-of-the-art sizes, we can confidently say this is the end of ChatGPT as we know it, and we could soon see the birth of ChatGPM, with ‘M’ for Mamba.\\n\\nLink to the original paper'}},\n",
       "  {'id': '818b2a8ad33e',\n",
       "   'title': 'OpenAI Just Killed an Entire Market in 45 Minutes',\n",
       "   'subtitle': 'The Story Everyone Should Have Seen Coming',\n",
       "   'author': '9b351e8113e9',\n",
       "   'publication_id': '*Self-Published*',\n",
       "   'published_at': '2023-11-09 17:24:58',\n",
       "   'last_modified_at': '2023-11-09 17:24:58',\n",
       "   'tags': ['artificial-intelligence',\n",
       "    'programming',\n",
       "    'business',\n",
       "    'technology',\n",
       "    'future'],\n",
       "   'topics': ['artificial-intelligence'],\n",
       "   'claps': 14479,\n",
       "   'voters': 2876,\n",
       "   'word_count': 1262,\n",
       "   'responses_count': 233,\n",
       "   'reading_time': 5.312264150943396,\n",
       "   'url': 'https://medium.com/@ignacio.de.gregorio.noblejas/openai-just-killed-an-entire-market-in-45-minutes-818b2a8ad33e',\n",
       "   'unique_slug': 'openai-just-killed-an-entire-market-in-45-minutes-818b2a8ad33e',\n",
       "   'image_url': 'https://miro.medium.com/1*OL0MU1g3AT0dZSfswimi3Q.png',\n",
       "   'lang': 'en',\n",
       "   'is_series': False,\n",
       "   'is_locked': True,\n",
       "   'is_shortform': False,\n",
       "   'top_highlight': 'A product or solution that makes the lives of people who use it easier.',\n",
       "   'content': {'id': '818b2a8ad33e',\n",
       "    'content': 'OpenAI Just Killed an Entire Market in 45 Minutes\\n\\nThe Story Everyone Should Have Seen Coming\\n\\nSource: Author with DALL-E3\\n\\nThis is a story about how a 45-minute speech killed an entire billion-dollar market.\\n\\nThis week OpenAI had its first-ever developer conference. Fewer times in history had there been higher expectations of a private technology event, and the OpenAI did not disappoint.\\n\\nThey announced a new, smarter GPT-4 model named ‘Turbo’ and they included several fascinating features that severely improve outputs and offer developers much more control over their models.\\n\\nAnd all this while still managing to decrease, once again, API costs.\\n\\nBut one announcement went swiftly past most of the media while being the one with the highest immediate impact on the AI market, as this new feature alone threatens an entire start-up ecosystem and billions of invested capital.\\n\\nMost insights I share in Medium have previously been shared in my weekly newsletter, TheTechOasis.\\n\\nIf you want to be up-to-date with the frenetic world of AI while also feeling inspired to take action or, at the very least, to be well-prepared for the future ahead of us, this is for you.\\n\\n🏝Subscribe below🏝 to become an AI leader among your peers and receive content not present in any other platform, including Medium:\\n\\nSubscribe | TheTechOasis\\nThe newsletter to stay ahead of the curve in AIthetechoasis.beehiiv.com\\n\\nThe Importance of Abstraction\\n\\nEven OpenAI couldn’t have predicted it. Not even they saw ChatGPT coming.\\n\\nWhen you even impress yourself\\n\\nOver the last few months, we have seen multiple accounts from the top management on OpenAI like Ilya Sutskever, Mina Murati, and Sam Altman claim that when they released the open beta for ChatGPT back in November 2022 they didn’t expect it to have that huge access.\\n\\nIn two months, it had already reached 100 million first-time users, and was already officially the fastest-growing product in history, only recently surpassed by Instagram’s Threads.\\n\\nSource: ExplodingTopics\\n\\nChatGPT has now crossed the 100 million active monthly users mark.\\n\\nIn Ilya’s case, he went as far as claiming that he honestly thought the product ‘wasn’t that good’.\\n\\nNowadays, few people in this world don’t know what that 7-letter name means and many see Generative AI not only as a new frontier for AI but even as a new computer paradigm.\\n\\nBut even though the product was amazing, you really couldn’t do much more than simply toy with it. It was a fun and bewildering thing to use and… that was pretty much it.\\n\\nTo use it for real, valuable use cases like a knowledge management system - far and wide the most common enterprise Generative AI use case today - you required additional tools like vector databases.\\n\\nAlso, when OpenAI released its first ChatGPT API, people soon realized how constrained the browser version was compared to the API one.\\n\\nIt had a much smaller context window (the amount of words it can process for one request) and the opportunities for a more customized solution were almost non-existent.\\n\\nLong story short, unless you were a seasoned developer, ChatGPT was nothing more than a pastime product with some minor utility if you were willing to put on the effort and you had some tech savviness.\\n\\nAnd with this realization, opportunity came.\\n\\nMillionaire 18-year-olds\\n\\nSoon, multiple developers around the world realized that they could create entirely new products in a few days that could offer more customized solutions built on top of ChatGPT by abstracting the complexity of building such solutions to more layperson audiences.\\n\\nFor instance, tools like ChatPDF or AskYourPDF allowed you to send the model actual documents for it to answer about them, and so became widely available.\\n\\nAs the appeal was very clear, people started paying decent money to use these products even though ChatGPT was (and still is) mainly free.\\n\\nThe name of these types of start-ups?\\n\\nChatGPT Wrappers, and soon enough reports of 18-year-old bedroom developers around the world earning, in some cases, millions, proliferated.\\n\\nProbably, the most famous of all these wrappers is Jasper, a ChatGPT-based product focused on marketing teams.\\n\\nThe tool allows you to create copyrighting material at scale, write blogs, optimize your web pages for SEO, and many other features.\\n\\nDespite basically being a digital user interface with marketing-specific prompt engineering on top of OpenAI’s ChatGPT APIs, the company still managed to raise $125 million at a staggering $1.5 billion valuation back in October 2022.\\n\\nConsidering that ChatGPT was released literally the next month, that was probably one of the worst-timed investment rounds ever.\\n\\nBut, after OpenAI’s developer conference, this ecosystem of start-ups being built on ChatGPT will soon look more like a war zone.\\n\\nJasper And The Wrapper Graveyard\\n\\nLong story short, OpenAI appears to be focusing its strategy for growth on making building AI tools easy by vertically integrating their solutions into higher abstraction layers… where the wrappers happen to be making their bucks.\\n\\nBuilding time machines\\n\\nHonestly, it was quite easy to predict because, as Scott Galloway has said many times, the easiest way to build a billion-dollar company is to build a ‘time machine’.\\n\\nA product or solution that makes the lives of people who use it easier.\\n\\nMore productive. Less effort.\\n\\nIn the case of OpenAI, that is none other than making Generative AI, a technology that a few years ago required almost a doctorate to even understand, an easy-to-use tech that works by simply clicking a few buttons… or simply asking something to it.\\n\\nAs shown by Sam Altman in OpenAI’s dev conference, a new software-building paradigm is upon us, with examples like Canva GPT where you can build Canva posters by simply asking for it.\\n\\nThis may seem eerily similar to ‘ChatGPT plugins’. In fact, Sam itself mentioned that these GPTs are indeed an improved evolution of that concept.\\n\\nSource: OpenAI\\n\\nIn other words, they are making AI declarative.\\n\\nDeclarative developers\\n\\nJust like you can find imperative programming languages like Python, where you have to control the complete building process, and declarative programming languages like SQL, where you simply declare what you want and the script gives it to you, AI is moving from an imperative technology to a declarative one.\\n\\nAnd with the new addition to an already overwhelming ChatGPT API of the Assistant API, you will now be able to embed agents into your solutions that leverage ChatGPT to use tools and do the dirty work for you.\\n\\nThis feature, added to the GPT Store where developers can build customized solutions and share revenues with OpenAI, the improved function calling, JSON outputting, seed referencing, accessible log probs, and more capable but cheaper models like GPT-4 Turbo, represent new amazing opportunities for developers to build incredible solutions.\\n\\nThe dawn of a new computing platform\\n\\nPreviously to this announcement, you required these wrapper products to do the most simple stuff.\\n\\nNow, most of their features are out-of-the-box capabilities in ChatGPT.\\n\\nOpenAI is slowly pulling everyone into its ecosystem with a carefully laid out strategy that makes it almost indispensable to be a part of its platform if you want to survive.\\n\\nAnd just like before, a new ecosystem of applications will be built on top of ChatGPT, but this time is different.\\n\\nThis time, to play the game you need to play by the rules of OpenAI, and that is a death sentence to many start-ups and the billions invested in them.\\n\\nDear Jasper, it was a very fun… but short ride.'}},\n",
       "  {'id': '680450c472c',\n",
       "   'title': 'Google goes beyond ChatGPT and shocks the world',\n",
       "   'subtitle': 'The new age of robots is upon us',\n",
       "   'author': '9b351e8113e9',\n",
       "   'publication_id': '*Self-Published*',\n",
       "   'published_at': '2023-03-02 19:03:12',\n",
       "   'last_modified_at': '2023-03-26 11:34:05',\n",
       "   'tags': ['artificial-intelligence',\n",
       "    'technology',\n",
       "    'ai',\n",
       "    'automation',\n",
       "    'google'],\n",
       "   'topics': ['artificial-intelligence'],\n",
       "   'claps': 2485,\n",
       "   'voters': 581,\n",
       "   'word_count': 1723,\n",
       "   'responses_count': 41,\n",
       "   'reading_time': 7.05188679245283,\n",
       "   'url': 'https://medium.com/@ignacio.de.gregorio.noblejas/offline-rl-680450c472c',\n",
       "   'unique_slug': 'offline-rl-680450c472c',\n",
       "   'image_url': 'https://miro.medium.com/0*-g_1d5r1GpXXuoT4',\n",
       "   'lang': 'en',\n",
       "   'is_series': False,\n",
       "   'is_locked': True,\n",
       "   'is_shortform': False,\n",
       "   'top_highlight': 'You measure an error and you find ways to minimize it by giving the model a lot of data.',\n",
       "   'content': {'id': '680450c472c',\n",
       "    'content': 'Google goes beyond ChatGPT and shocks the world\\n\\nThe new age of robots is upon us\\n\\nPhoto by Yuyeung Lau on Unsplash\\n\\nIt turns out, one of the most-coveted questions in AI has recently been answered.\\n\\nImagine an AI tool that is capable of playing hundreds of video games at a supreme level. And I’m not referring to a robot trained to be great at chess, or at checkers, or League of Legends.\\n\\nI’m talking about a robot that’s amazing at all of them.\\n\\nAnd not only that, but it’s also capable of optimizing microchip designs and also be used for general-purpose, industry-level robotics.\\n\\nOverall, a general-intelligence robot like nothing we’ve ever seen.\\n\\nWell, it seems that an unprecedented announcement by Google takes us much closer to that possibility of a once-thought-as-impossible AI.\\n\\nAnd while that probably sounded like I’m on drugs, I can assure you that by the end of this read, you’re going to be convinced this is nothing like what you’ve seen before.\\n\\nGeneral-purpose AI robotics\\n\\nTo be fair, it’s only natural for many people that have just now realized AI is amazing, to think that AI is limited to GenAI tools like ChatGPT.\\n\\nThe real AI innovation\\n\\nIndeed, the real reason for the AI craze is the fact that we’ve reached a new frontier for AI with Natural Language models.\\n\\nAnd that frontier isn’t a chatbot that can write poems out of thin air, but the fact that we’re now capable of training Natural Language solutions with diverse datasets, achieving what we describe as pre-trained transformers.\\n\\nThese AI models are Language Models that can be then easily fine-tuned to downstream tasks - that is, tailored to specific use cases - like ChatGPT, a chatbot implementation of the LLM going by the name of GPT.\\n\\nIn layman’s terms, the real transformation we’ve obtained in AI is building AI language models that perform reasonably well in multiple scenarios, allowing the creation of solutions like ChatGPT.\\n\\nIn fact, the reality is that AI is much, much more than pre-trained transformers like GPT. Actually, they are only the beginning.\\n\\nAI is not only GenAI, it’s MUCH more\\n\\nUnbeknownst to many, AI fields like Computer Vision or Offline RL have insane potential.\\n\\nHowever, while the former already has several use cases where it’s already actively used, the latter has consistently lagged behind over the years.\\n\\nUntil now.\\n\\nWell, at least that’s what Google claims. But not only that, Google is claiming much more, to the point that it thinks that Offline RL could take the world of robotics to another level.\\n\\nBut first and foremost, what’s Offline RL, or more importantly, what is RL?\\n\\nExplain RL like I’m five\\n\\nAlmost everything in AI is about trial and error.\\n\\nYou measure an error and you find ways to minimize it by giving the model a lot of data.\\n\\nAnd there you go, that’s a one-sentence description of AI.\\n\\nHowever, while some AI solutions like ChatGPT are trained by measuring this error to minimize it in one complete learning procedure, Reinforcement Learning, or RL, is a multi-step process that requires ‘interaction’.\\n\\nFor each step in the process, the model acknowledges its state (its situation in the environment), performs an action, and if the action implies an approximation to the desired final state, it receives a reward.\\n\\nTo better understand, we can use an example, videogames.\\n\\nFor each action the model makes in the game, it understands the impact of that action, potentially receiving a reward and reshaping its parameters in order to maximize those rewards.\\n\\nThis way, the model learns what actions yield rewards and defines the policy - the strategy - it will follow to maximize them.\\n\\nBut why do we train AI models this way?\\n\\nBecause, as it turns out, it’s the ideal way to train AI in decision-making situations.\\n\\nFor instance, we’ve already seen how AI has kicked Magnus Carlsen’s ass in chess, or how DeepMind’s AlphaZero achieved superhuman capacities in chess, Go, and shogi games in just a few hours of training.\\n\\nHowever, despite the impressive qualities of RL, it has a problem… it is goddamn expensive to train.\\n\\nLuckily, here’s where the term Offline comes to the rescue.\\n\\nOffline RL, making the most out of RL\\n\\nUp until now, there’s a chance you really don’t feel very amused by what I’m telling you.\\n\\nBut the truth is that Offline RL is regarded as one of the holy grails of AI, as the answer to a long-coveted desire:\\n\\nHow do we make RL, a field we know is the real deal for decision-making, affordable, scalable, and accessible?\\n\\nThe key concept here is, even though RL is extremely useful, the cost of doing ‘online’ training (making an AI model interact with the real environment to learn) is very high.\\n\\nFor that reason, for a long time, AI scientists have wondered if there was a way to pre-train these models in ‘offline’ environments (from a dataset of data instead of learning by interacting with the real environment) using generalized datasets.\\n\\nThat way, you minimize the costs while also allowing AI engineers to have a solid initiation point, a good backbone which more particular, tailored solutions can be trained upon.\\n\\nIn other words, what AI scientists have been trying for a long time with RL is to reach the point we’ve just achieved with NLP with pre-trained transformers; a high-quality initiation point for new AI solutions.\\n\\nIn other words, generalistic RL models that can be easily trained into specific utilities in a cost-effective and highly efficient way.\\n\\nAnd guys, I think Google might be into something big, as Google’s pre-trained agents can be the answer to some of AI\\'s greatest questions.\\n\\nA new age for AI\\n\\nIn a paper that’s not even been officially presented yet, Google has announced pre-trained robots that are capable of doing multiple different activities and also be easily trained to ambitious downstream tasks.\\n\\nA new age of robotics is here\\n\\nUsing a technique described as Conservative Q-Learning, or CQL, Google has managed to create AI agents that are capable of playing multiple Atari games even after being trained with poor-quality data and in offline environments.\\n\\nBut what on Earth is Conservative Q-learning?\\n\\nLet’s go step by step.\\n\\nWhat’s Q-Learning?\\n\\nQ-learning is an RL technique that allows RL models to learn an execution strategy by figuring out a Q-function (Q comes from Quality) that it learns as it interacts with the environment.\\n\\nOk, now what in tarnation is the writer talking about. Bear with me.\\n\\nIn short terms, this Q-function is learned by considering the reward in the actual state - remember, RL is simply applying an action in a known state and seeing what reward I get - while also considering the discounted future reward.\\n\\nIn other words, the RL model learns the path of greatest reward (by trial and error nonetheless).\\n\\nHigh-level Q-learning process\\n\\nAnd the conservative part?\\n\\nIt’s a cool term that refers to limiting the expectations of the model regarding unseen values. In other words, as the model is learning this Q-function in an offline environment, the model will naturally tend to overestimate what it has learned.\\n\\nThus, by \"toning down\" the results, the model ironically performs better.\\n\\nAnd by better I mean amazingly better.\\n\\nImpressive designs yield impressive results\\n\\nRegarding training games, the model shows impressive performance even with data that is highly suboptimal.\\n\\nAlso, when provided with near-optimal data, it outperforms non-Q-learning methods by wide margins.\\n\\nInterestingly, even when compared to models 2.5 times its size, it achieves more than double the score.\\n\\nOffline RL (red) compared to other models\\n\\nBut this isn’t even the most fascinating thing.\\n\\nIn fact, the most impressive thing here is what one of the authors, Sergey Levine, described as \"Scaling Laws\".\\n\\nThe reason that ChatGPT is great is that the underlying model, GPT, scales with size. In other words, GPT performs better the bigger it becomes, scaling proportionately to increments of dataset size and parameters.\\n\\nBefore, RL scaling wasn’t really a thing, as incrementing size didn’t really offer great new results. This, naturally, limited the capacity of these models to get better.\\n\\nHowever, these RL pre-trained agents do really get better with size, which is an extremely promising feature that could allow us to create increasingly powerful robots with multiple capabilities that could be part of our lives really soon.\\n\\nYour robot friend is closer than ever.\\n\\nA new age for AI we still don’t comprehend\\n\\nAt this point, we need to acknowledge that we’re reaching a turning point for AI.\\n\\nAI, already a reality in many ways in our lives, is about to become instrumental in many of our daily activities.\\n\\nNevertheless, the results and the progress we’re seeing in the field are dramatic, at speeds that create concern as regulations and laws are clearly falling rapidly behind.\\n\\nIn the meantime, the \"pre-trained\" revolution is arriving to RL, and with it, a great variety of use cases will, hopefully, make AI a great tool for robotics, automation, and probably in other fields we aren’t really aware of still.\\n\\nExciting or scary that may seem, I’ll leave that up to you.\\n\\nA final word\\n\\nIf you’ve read this article, you’re already ahead of 95% of society when it comes to AI. But that still leaves a lot of people at your level.\\n\\nWhat if you’re capable of being above 99% of society? That’s a totally different level.\\n\\nIf that’s where you want to be, I have news for you.\\n\\nBy subscribing to my weekly newsletter, you’ll deep dive into complex innovation topics in an easy-to-read, digested manner, providing you with the latest news and insightful innovations on Crypto and AI.\\n\\nI can’t promise you wealth, but I can promise you knowledge, and there’s no wealth without knowledge.\\n\\nBecome aware of the technologies that are shaping our future. Be ready to profit from that knowledge.\\n\\nTheTechOasis\\nThe newsletter to stay ahead of the curve in AI & Cryptothetechoasis.beehiiv.com\\n\\nYou also have the option to become a Medium member, opening yourself to millions of articles related to any topic of your interest and, in the meantime, supporting this humble writer.\\n\\nJoin here! Don’t be afraid to level up your game.'}},\n",
       "  {'id': '4cc9cf343185',\n",
       "   'title': 'An AI more impressive than ChatGPT is here',\n",
       "   'subtitle': 'Action Transformers are the next leap for AI',\n",
       "   'author': '9b351e8113e9',\n",
       "   'publication_id': '*Self-Published*',\n",
       "   'published_at': '2023-01-28 14:22:28',\n",
       "   'last_modified_at': '2023-02-03 09:29:32',\n",
       "   'tags': ['artificial-intelligence',\n",
       "    'technology',\n",
       "    'investing',\n",
       "    'productivity',\n",
       "    'automation'],\n",
       "   'topics': ['artificial-intelligence'],\n",
       "   'claps': 2571,\n",
       "   'voters': 462,\n",
       "   'word_count': 1794,\n",
       "   'responses_count': 49,\n",
       "   'reading_time': 6.969811320754717,\n",
       "   'url': 'https://medium.com/@ignacio.de.gregorio.noblejas/ai-more-impressive-than-chatgpt-4cc9cf343185',\n",
       "   'unique_slug': 'ai-more-impressive-than-chatgpt-4cc9cf343185',\n",
       "   'image_url': 'https://miro.medium.com/0*xHXIND6zAmCSovN_',\n",
       "   'lang': 'en',\n",
       "   'is_series': False,\n",
       "   'is_locked': True,\n",
       "   'is_shortform': False,\n",
       "   'top_highlight': 'Adept.ai is no ordinary startup.',\n",
       "   'content': {'id': '4cc9cf343185',\n",
       "    'content': 'An AI more impressive than ChatGPT is here\\n\\nAction Transformers are the next leap for AI\\n\\nPhoto by Jamie Haughton on Unsplash\\n\\nFew things have the potential to change that much in our daily life. Or in our work.\\n\\nAnd although you may very well be tempted to see the title as pure sensationalism, I can assure you that by the end of the article, you will think otherwise.\\n\\nWhat if I told you that there’s an even bigger use case for AI than ChatGPT, a use case that can completely change the way we interact with our phones, our tablets, or our computers to use them in ways thought impossible?\\n\\nThis technology exists, and it’s sneaking up on you.\\n\\nBut let me put a disclaimer; the extent of how excited or scared you’ll be after reading this article will depend entirely on you, not on me.\\n\\nThat is the extent to how disruptive and transformative Action Transformers can be to your future.\\n\\nWhen attention became mainstream\\n\\nGenerative AI represents the first time that this decades-long promise that AI was, has become a reality that can be appreciated by even the less techie part of society.\\n\\nMainstream AI is here\\n\\nEven though AI is already everywhere, until now AI models have been used as predictors; decision-makers for very tailored and specific use cases.\\n\\nWeirdly enough, the most successful - economically speaking - field of AI has been Online Advertising, allowing companies like Google or Meta to build literal empires out of the simple concept of certainty.\\n\\nThat is, providing humans with the empirical, data-driven assurance that the outcome of a certain action, more often than not, would be profitable.\\n\\nThanks to AI, Google and Meta guaranteed advertisers results by ensuring that their marketing campaigns would reach the desired customer personas, transforming the marketing industry from the historical \"hit-and-miss\" to something much more streamlined.\\n\\nBut this amazing success required important investments, making AI a prohibited technology for the majority.\\n\\nThus, all this is changing with Generative AI, the first time AI becomes mainstream and accessible in our day-to-day.\\n\\nAnd while you are surely going to see a lot of different AI models being thrown at your face, they all can be boiled down to one simple concept: In a world where being focused is a bigger challenge every day, it’s ironic that the thing that is going to change the world around us is based on one simple thing, attention.\\n\\nAttention is all you need\\n\\nThe attention mechanism is a proposal by Bahdenau et al which is, without a doubt, one of the most influential papers in the history of Artificial Intelligence.\\n\\nIn short, it was the first time that we found a way for humans to teach machines to understand the context of a phrase in a ‘similar’ way as humans would.\\n\\nWe can see this with an example:\\n\\nLet’s say you want to translate a phrase into another language.\\n\\nUnless you’re very weird, you’re probably going to translate the phrase in small chunks; initially the first few words, then the following while keeping in your memory the first part of the sentence to retain context… and so on.\\n\\nHowever, before the attention mechanism, neural networks understood context by brute force, extracting the context from the whole phrase. This meant that, for an increasing length of the phrase we wanted the machine to understand, computational and memory requirements skyrocketed.\\n\\nWith the attention mechanism, this all changed.\\n\\nThanks to a weighting mechanism, we were capable of teaching machines to \"score\", one word at a time, the rest of the words of a sentence in relation to that word.\\n\\nThis meant, in very simplified terms, that for each word in a sentence the machine received, it was capable of understanding what other words in that sentence mattered more and which ones less, like you and I do unconsciously.\\n\\nThis allowed the birth of the transformer, the model behind ChatGPT, DALL-E, Stable Diffusion, or our protagonist today, ACT-1.\\n\\nTransformers are here to stay\\n\\nThe attention mechanism caused that in 2017 a group of researchers decided to ditch recurrence and convolution, the standards at the time to train sequence models, and created a new encoder-decoder - two neural networks connected in a sequence - that solely relied on the attention mechanism.\\n\\nHowever, up until now the main applications of these models have been to generate text or image outputs. As seen with ChatGPT, this has been very successful and is already impacting several industries like creative workers, writers, or marketers.\\n\\nBut there’s a larger-than-life use case that few are aware of that will completely change how you use your digital devices.\\n\\nAction Transformers, or common intelligence\\n\\nAdept.ai is no ordinary startup.\\n\\nIt’s founded by some of the brightest minds in AI (some of them created the concept of the Transformer model discussed earlier, and it’s co-founded by David Luan, once Head of Engineering at OpenAI).\\n\\nNow, they’ve decided to take their talents to the next level by creating the first-ever Action Transformer, a large language model claimed by the team for being the first generally intelligent AI model, framing ‘general intelligence’ as the capacity of a model to perform various tasks in a computer in an intelligent manner.\\n\\nAt this point, you’ll maybe be wondering… \"Great, but what does this ‘thing’ do?\"\\n\\nIn short, it’s general-purpose intelligent automation.\\n\\nChanging how we interact with computers, forever\\n\\nImagine you’re working with an Excel spreadsheet with information regarding the financials of your company. Suddenly, you realize you would love to create a pivot table that provides further insights into the information in your table.\\n\\nBut it’s been a while since you did one and just the thought of having to learn again worsens your mood.\\n\\nThen, you open a Chrome extension, and type \"Create a pivot table that presents my financial information in a way that I can clearly identify profit and margin for each year while filtering only positive results\".\\n\\nYou press ‘enter’. Et voilà, magic happens.\\n\\nSuddenly the request you’ve entered is automatically executed in the Excel spreadsheet, while you, simply, watch.\\n\\nThis, which seems almost like science fiction, could be the ‘business usual’ in our lives in a few years.\\n\\nOr months, thanks to Adept’s ACT-1.\\n\\nThe path to general-purpose automation\\n\\nDigital automation is quite a rudimentary process these days. Powerful, don’t get me wrong, but rudimentary.\\n\\nPeople have to \"teach\" the automation software to perform a series of repetitive actions by showing it, literally, in which place on the computer screen it needs to act on, and the robot simply obeys.\\n\\nBut there’s no intelligence in this procedure. These robots can only replicate defined processes and automatically fail if those change.\\n\\nWith action transformers, this is a thing of the past.\\n\\nLeveraging the powerful concept of large language models, these transformers are capable of interacting with almost any graphical user interface, API, or website in a seamless way with almost zero training.\\n\\nBut that’s not the most incredible thing; they can become teammates for any human being as they are capable of executing those actions, on demand, with natural language requests like the example I showed earlier.\\n\\nAnd what’s even more impressive, is that Adept.ai is developing its transformer model using a new innovative iteration of the attention mechanism, a concept described as flash-attention.\\n\\nLonger and faster\\n\\nAs mentioned before, the greatest bottlenecks in these models are runtime and memory constraints.\\n\\nEven though the attention mechanism allowed for a much more ‘human’ way of extracting context from phrases while reducing memory requirements, it still can be improved.\\n\\nWith the normal attention mechanism, the runtime and memory have quadratic requirements to the input sequence length. In other words, the longer the input sequence, the exponentially higher the memory and runtime requirements.\\n\\nToday, state-of-the-art models are capable of handling around 2,000 tokens, which is less than 2,000 words per input (recently an 8,192 token embedding system has been released by OpenAI).\\n\\nThis limits the amount of input you can provide to a model for it to understand the context and generate an output. Logically, this is not enough, as anyone that has read a book knows that context can be derived from texts that are much, much larger.\\n\\nAdept.ai’s ACT-1 model leverages flash-attention, a new mechanism that they claim reduces the memory and runtime requirements to linear regarding the input sequence length.\\n\\nMemory and runtime increase linearly, not exponentially, to the length of the sequence.\\n\\nThe potential impact of this?\\n\\nEventually, we could see the proliferation of AI teammates that accompany you throughout months, learning from your ways of working and rhythms, and being able of becoming your inseparable work companion that enhances your actions in a tailored, dedicated approach.\\n\\nOk, but is this good or bad?\\n\\nIt’s hard to not feel overwhelmed, or even scared, by news like this.\\n\\nBut I don’t think this is actually a bad thing.\\n\\nHuman workers aren’t going anywhere. In fact, these robots can become truly life-changing elements in our lives and, potentially, could completely change how we interact with computers in the future, for the better.\\n\\nThe real question is, will we need software interfaces in the future? Or software products will simply become backends that action transformers interact with?\\n\\nA final word\\n\\nIf you’ve read this article, you’re already ahead of 95% of society when it comes to AI. But that still leaves a lot of people at your level.\\n\\nWhat if you’re capable of being above 99% of society? That’s a totally different level.\\n\\nIf that’s you, I have news for you.\\n\\nBy subscribing to my weekly newsletter, you’ll deep dive into complex innovation topics in an easy-to-read, digested manner, providing you with the latest news and insightful innovations on Crypto and AI.\\n\\nI can’t promise you wealth, but I can promise you knowledge, and there’s no wealth without knowledge.\\n\\nBecome aware of the technologies that are shaping our future. Be ready to profit from that knowledge.\\n\\nTheTechOasis, the newsletter that simplifies AI & Crypto\\nLanding page of The Tech Oasis newsletter about AI & Crypto in a digested manner so that even non-tech readers can…www.thetechoasis.com\\n\\nYou also have the option to become a Medium member, opening yourself to millions of articles related to any topic of your interest and, in the meantime, supporting this humble writer.\\n\\nJoin here! Don’t be afraid to level up your game.\\n\\nNote: I’m not affiliated nor related to Adept.ai. This article is simply for educational purposes and an illustration of what I feel the future awaits us, be that with Adept.ai or with other companies. This isn’t about the company, but the technology.'}},\n",
       "  {'id': '6d59742ee635',\n",
       "   'title': 'Can ChatGPT kill Google?',\n",
       "   'subtitle': 'AI is disrupting everything, even trillion-dollar businesses',\n",
       "   'author': '9b351e8113e9',\n",
       "   'publication_id': '*Self-Published*',\n",
       "   'published_at': '2022-12-28 18:27:04',\n",
       "   'last_modified_at': '2022-12-30 20:35:00',\n",
       "   'tags': ['artificial-intelligence',\n",
       "    'ai',\n",
       "    'technology',\n",
       "    'google',\n",
       "    'investing'],\n",
       "   'topics': ['artificial-intelligence', 'business', 'technology'],\n",
       "   'claps': 6341,\n",
       "   'voters': 1445,\n",
       "   'word_count': 1418,\n",
       "   'responses_count': 227,\n",
       "   'reading_time': 5.734276729559749,\n",
       "   'url': 'https://medium.com/@ignacio.de.gregorio.noblejas/can-chatgpt-kill-google-6d59742ee635',\n",
       "   'unique_slug': 'can-chatgpt-kill-google-6d59742ee635',\n",
       "   'image_url': 'https://miro.medium.com/0*3bPbSq7pXs8P5Mdq',\n",
       "   'lang': 'en',\n",
       "   'is_series': False,\n",
       "   'is_locked': True,\n",
       "   'is_shortform': False,\n",
       "   'top_highlight': 'Can ChatGPT kill Google?',\n",
       "   'content': {'id': '6d59742ee635',\n",
       "    'content': 'Can ChatGPT kill Google?\\n\\nAI is disrupting everything, even trillion-dollar businesses\\n\\nPhoto by Michelle Tresemer on Unsplash\\n\\nLast month, all alarms went off in Google’s headquarters.\\n\\nEven the New York Times has an entire article dedicated to this. According to them, ‘Code Red’ went off in the highest structures of the company.\\n\\nGoogle is scared, very scared.\\n\\nThe reason?\\n\\nArtificial Intelligence has recently made a giant leap that could put at very risk Google’s core business, search.\\n\\nThe question is then inevitable.\\n\\nCould we be soon witnesses to the death of one of the so-called ‘trillion-dollar’ companies, and with it the demise of entire industries like SEO, SERPs, and ultimately digital marketing?\\n\\nGoogle, the first Internet monopoly, is highly exposed\\n\\nGoogle is currently valued at a whopping 1.13 trillion dollars.\\n\\nThat’s a one and twelve zeros. But what’s even crazier, is that Google was, in November 2021, an almost 2 trillion dollar company.\\n\\nThat’s quite a decrease, but it still allows them to be the fourth biggest company in the world by market capitalization.\\n\\nOf course, being so huge, one imagines that its revenues are also huge, right?\\n\\n256 billion dollars in revenue in 2021. Not bad.\\n\\nBut how much money is that?\\n\\nFor reference, more than Portugal’s expected entire GDP for 2022.\\n\\nIn other words, Google’s revenues in 2021 were bigger than what Portugal managed to produce, as an entire country, for a whole year.\\n\\nSeeing those numbers, one can’t act surprised by Google’s insane valuation.\\n\\nOr should we?\\n\\nTruth be told, Google’s business model has a catch.\\n\\nDiversification isn’t Google’s strongest suit\\n\\nIt’s undeniable that Google has some impressive numbers.\\n\\nAs a more visual representation, let’s look at the following monographic:\\n\\nAlphabet’s quarterly results. Source: visualcapitalist.com\\n\\nIf we check Google’s quarterly results for Google in June 2022, Google managed to achieve an income of 69.7 billion dollars.\\n\\nAlmost as impressive as their final profit, 16 billion dollars, which is a profit margin of 23%.\\n\\nThat’s huge, considering how Amazon, one of the other big guys, actually lost money that quarter.\\n\\nThis seems all amazing and great, right?\\n\\nHowever, if you watch carefully, something’s odd.\\n\\nOr at least, improvable.\\n\\nOut of the 70 billion in revenue, 41 billion, almost 60%, comes from one unique source, Search advertising, the industry where Google holds around 92% of the market share.\\n\\nAnd the problem is that this is, specifically, the market that AI can potentially disrupt forever.\\n\\nBut how?\\n\\nTransformer AI models. But what on Earth is that?\\n\\nQuick hint, they aren’t killer robots like the ones in the movies.\\n\\nChatGPT and what’s to come\\n\\nYou’ve probably heard or read about ChatGPT a lot recently.\\n\\nLike, painfully, a lot.\\n\\nBut it’s understandable, the technology is unbelievable.\\n\\nChatGPT in 30 seconds\\n\\nFor those unaware, OpenAI, a non-profit company founded by Elon Musk and Sam Altman, among others, has published the latest version of its chatbot, ChatGPT, powered by the largest transformer language model ever assembled, GPT-3.5, with over 175 billion parameters.\\n\\nIn case you’re wondering, chatbots are robots you can talk to.\\n\\nActually, you’ve probably spoken to many recently, especially when engaging with call centers, insurance companies… and basically any customer service you can find today.\\n\\nThose chatbots, in all sincerity, are pretty annoying and painfully limited.\\n\\nBut this one’s not.\\n\\nOne could say it’s the same animal but a totally different beast, but to me, it’s a completely different animal also.\\n\\nChatGPT, among other things, can respond to almost any question with extremely eloquent responses, code anything you wish in many different programming languages, write completely new bedtime stories, debug your own code, and others.\\n\\nIt’s so impressive, some have claimed it could be the very first intelligent, sentient AI model.\\n\\nShort answer, fuck no.\\n\\nThe problem with that statement is that people mistake high predictability for sentience.\\n\\nA probabilistic beast\\n\\nGPT, just like any other neural network, is a probabilistic beast; it’s capable of predicting with an astonishing success rate the next correct word in response to a sentence, thereby creating perfectly-elaborated sentences while sounding very human-like when engaging with it.\\n\\nBut having high success in predicting eloquent responses is one thing, being capable of truly understanding what they’re responding to is another.\\n\\nDon’t let sensationalist media fool you, state-of-the-art AI isn’t sentient, period.\\n\\nBut although an armed uprising of human-killing robots seems improbable today, there’s something that ChatGPT is actually poised to disrupt from the get-go.\\n\\nAnd that’s Internet search, Google’s golden goose.\\n\\nThe death of Google Search and SEO?\\n\\nUnlike Google Search, ChatGPT releases you from having to scroll endlessly through pages of links while giving you concise and direct responses.\\n\\nThis could make people resort to querying these systems instead of searching through Google.\\n\\nIn that scenario, the appeal for companies to promote themselves through Google could drop significantly, putting Google at risk.\\n\\nBut Google isn’t the only one.\\n\\nThousands of marketing agencies rely on their SEO expertise, the capacity to help their clients ‘be seen’ on Google. This sudden change in customer journeys to using AI instead of Google could be devastating for them.\\n\\nHence, seeing how impressive ChatGPT is already, and considering that a newer version of the underlying AI model, GPT-4, is going to be released early next year…\\n\\nAre we prepared to ‘kill’ Google?\\n\\nDiffering what’s wrong from what’s right\\n\\nCreating a good search engine isn’t a simple task.\\n\\nThese algorithms need to be continuously fine-tuned to avoid exposing fake news, racism, homophobia, or even plagiarism, in an effort to offer the searcher relevant but acceptable information.\\n\\nThis effort, in turn, seems like an even bigger challenge with AI.\\n\\nToday, AI needs to figure out three things:\\n\\nOpacity\\n\\nData Bias\\n\\nAvoiding making shit up\\n\\nAI, the ultimate blackbox\\n\\nAs described earlier, GPT-3.5 has been fine-tuned for 175 billion parameters requiring 800 GB of storage.\\n\\nIn very simple terms, this means that trying to explain how these models work and make decisions or predictions is close to impossible.\\n\\nThus, if ChatGPT makes a racist comment, there isn’t really a way of explaining why.\\n\\nBiased data, biased model\\n\\nAlso, as these models aren’t sentient but mathematical models that have learned to answer by brute force and vast amounts of data, they are very dependent on having unbiased data sources and diversified teams of data engineers, which is a huge challenge in today’s world.\\n\\nA challenge why? Here’s a fact for you.\\n\\nAccording to data from this September by Zippia, 70% of computer programmers are male, and 69% of all programmers are white.\\n\\nAssuming the majority of them aren’t racist, nevertheless, this extremely skewed workforce is surely heavily culturally biased, which is not great for AI models that intend to become universal and applicable to all of society.\\n\\nGoogle Search isn’t going anywhere… for now\\n\\nIn spite of all this, I don’t feel that Google’s reign as the supreme search engine is in doubt for now.\\n\\nHowever, I do have a strong opinion that the future of search engines is going to be AI-led, so although today’s AI models are limited and dangerous for mass use, ChatGPT has shown us what the future, undoubtedly, looks like.\\n\\nLuckily for Google, it has its own large language model, LaMDa, and surely has taken note of what LLMs are capable of thanks to OpenAI.\\n\\nNevertheless, all this proves how disruptive AI is going to be. But not only for you and me, but also for the biggest companies in the world.\\n\\nA final word\\n\\nThere’s too much rubbish on the Internet.\\n\\nIn fact, it’s pretty tough to find quality content, especially in Crypto or AI. It’s time-consuming and, more times than not, ends up in nothing.\\n\\nBut you know you need to stay ahead of the curve if you want to be successful. Yeah, truth hurts.\\n\\nLuckily, you can take the easy route and subscribe to my weekly newsletter, where I deep dive into complex innovation topics and provide the latest news on Crypto and AI.\\n\\nBecome aware of the technologies that are shaping our future. Be ready to profit from that knowledge.\\n\\nTheTechOasis, the newsletter that simplifies Tech & Crypto\\nLanding page of The Tech Oasis newsletter about technology, crypto, and markets in a digested manner so that even…www.thetechoasis.com\\n\\nYou also have the option to become a Medium member, opening yourself to millions of articles related to any topic of your interest and, in the meantime, supporting this humble writer.\\n\\nJoin here! Don’t be afraid to level up your game.'}},\n",
       "  {'id': '158587d68dfe',\n",
       "   'title': 'Lumiere, Google’s Amazing Video Breakthrough',\n",
       "   'subtitle': 'Text-to-Video on a new level',\n",
       "   'author': '9b351e8113e9',\n",
       "   'publication_id': '98111c9905da',\n",
       "   'published_at': '2024-02-13 20:01:50',\n",
       "   'last_modified_at': '2024-02-13 20:01:50',\n",
       "   'tags': ['artificial-intelligence',\n",
       "    'technology',\n",
       "    'google',\n",
       "    'data-science',\n",
       "    'future'],\n",
       "   'topics': ['artificial-intelligence', 'machine-learning'],\n",
       "   'claps': 1196,\n",
       "   'voters': 119,\n",
       "   'word_count': 1492,\n",
       "   'responses_count': 9,\n",
       "   'reading_time': 6.880188679245283,\n",
       "   'url': 'https://pub.towardsai.net/lumiere-googles-amazing-video-breakthrough-158587d68dfe',\n",
       "   'unique_slug': 'lumiere-googles-amazing-video-breakthrough-158587d68dfe',\n",
       "   'image_url': 'https://miro.medium.com/0*XOdZjJp7-DELdwB9',\n",
       "   'lang': 'en',\n",
       "   'is_series': False,\n",
       "   'is_locked': True,\n",
       "   'is_shortform': False,\n",
       "   'top_highlight': '',\n",
       "   'content': {'id': '158587d68dfe',\n",
       "    'content': 'Lumiere, Google’s Amazing Video Breakthrough\\n\\nText-to-Video on a new level\\n\\n\\n\\nScott Galloway, the famous business professor, bet that 2024 would be Google’s AI year.\\n\\nAnd it’s starting to look like it.\\n\\nNow, they have launched Lumiere, a huge breakthrough in text-to-video, one of the hardest tasks in Generative AI today and probably the biggest unreached milestone in terms of the repercussions it will have once achieved, as it’s a technology that could change forever huge industries like Hollywood, YouTube, or CGI.\\n\\nNow, Google has taken us one step closer, as their approach to AI video synthesis is not only revolutionary, but it also showcases incredible video quality and a wide range of amazing skills like video in/outpainting, image animation, and video styling, making it the new reference in the field.\\n\\nBut how does it generate videos?\\n\\nSeems like magic, but it’s not. Let’s unpack its secrets.\\n\\nThis insight and others have mostly been previously shared in my weekly newsletter, TheTechOasis.\\n\\nIf you want to be up-to-date with the frenetic world of AI while also feeling inspired to take action or, at the very least, to be well-prepared for the future ahead of us, this is for you.\\n\\n🏝Subscribe below🏝\\n\\nSubscribe | TheTechOasis\\nThe newsletter to stay ahead of the curve in AIthetechoasis.beehiiv.com\\n\\nThe Everlasting Problem\\n\\nOut of all data modalities, video is, without a doubt, the hardest to generate with AI.\\n\\nHowever, considering videos are simply a concatenation of images, called frames, displayed at a certain frame rate per second (the higher the fps the smoother the video) the logical path to building text-to-video (T2V) systems is to depart from a text-to-image model (T2I), like DALL-e or Stable Diffusion.\\n\\nHowever, T2V adds an extra layer of complexity: Time.\\n\\nIn other words, it’s not enough to generate multiple frames (you can generate as many as you need with the T2I model) but they must be consistent over time.\\n\\nIn other words, if you are generating a video about a lion, you must ensure that the lion looks similar across all frames.\\n\\nAnd this has proven to be a huge problem, as the complexity of keeping structure across multiple frames forces AI videos to be very short, and they nevertheless tend to showcase artifacts, visual imperfections like the orange blob that suddenly appears in this AI-generated video below.\\n\\nSource: NVIDIA\\n\\nAnd the reasons for these inconsistencies reside in how these models are built, a method that we will soon explain how Lumiere revolutionizes.\\n\\nSource: Google\\n\\nOriginally, the video synthesis process involved three steps:\\n\\nA T2I prior generated a set of key frames set across the complete duration of the video.\\n\\nNext, several TSR (Temporal Super Resolution) models \"filled in\" the gap between the keyframes with a set of new frames. For example, if the two key frames are a serious person and that same person smiling, the TSR models generate the complete set of in-between frames that generate the smiling gesture.\\n\\nThen, a set of SSRs (Spatial Super Resolution) will take the low-resolution frames and upscale them to enhance the quality of the video, as most T2V models work in low-resolution pixel space (or, in some cases, in vector space like Stable Diffusion) for a more efficient and cheaper process.\\n\\nFinally, the SSR outputs are \"stitched\" together and that gives you the video.\\n\\nBottom line, AI videos are simply taking an image generator and training it to generate somehow consistent images through time in batches and piece them together.\\n\\nAnd this works… kind of.\\n\\nJust like if you are filming an actor and midway through the sketch, he breaks character and you try to finish the rest of the sketch by forcing him into that specific position to continue and avoid losing the first part, chances are that no matter how well you edit it, the cut is going to be visible.\\n\\nAlso, as the process involves the use of several different types of models, these models do not always share the same experiences and representations (how they conceive concepts), making it extremely error-prone.\\n\\nConsidering these limitations, video generation didn’t seem quite ready yet. But with Google Lumiere, we might be seeing the start of something big.\\n\\nSpace, Time, and MultiDiffusion\\n\\nAs their image counterparts, T2V are mostly diffusion models.\\n\\nA diffusion model is a type of AI system that learns to map a noisy distribution of data into the target distribution through a denoising process.\\n\\nIn layman’s terms, they take a noisy image and a text condition (what you want the end result to be) and they gradually take out the noise from the image until you get the result.\\n\\n\"Portrait of a cat\". Source: NVIDIA\\n\\nThink of the diffusion process as taking a marble block and, just like Michelangelo would, carving out the excess marble to ‘unearth‘ the statue.\\n\\nHowever, instead of following the standard procedure we described earlier, Google has found an alternative, by creating an STUnet.\\n\\nBut what is that?\\n\\nSource: Google\\n\\nA UNet is an architecture that downsamples, processes, and generates a new set of images.\\n\\nIn other words, it takes in a set of noisy samples (shown as blurred images in the image above) and generates a new set of high-quality images that are also coherent with each other to generate the video.\\n\\nTo do so, while applying convolutions to process the image (to understand what it’s seeing) it downsamples the images (makes them smaller).\\n\\nOnce they are compressed enough, it now applies attention (just like ChatGPT would on a text sequence, but over the compressed representations of the images, to better grasp what concepts appear in the image, like the panda) and then upsamples them back into pixel space, leaving you with the desired images.\\n\\nHowever, STUnets also include temporal convolutions and attentions, meaning they compress time.\\n\\nIn other words, while the spatial convolutions and attentions focus on processing and ensuring that the generated images represent what the user requested, the temporal convolutions and attentions ensure that images are consistent across the whole set.\\n\\nThis feels very abstract, but what STUnet is basically doing is not only understanding what each frame represents, but how different frames relate to each other.\\n\\nIn other words, it’s not only about capturing that the frames portray a panda, but also what movements the panda should be doing over time.\\n\\nThe fact that the generative process is \"temporally-aware\" allows Lumiere to create all the frames in the video at once (instead of the usual key frame + cascading frame filling we discussed earlier), and thus the STUnet simply needs to focus on capturing the semantics of the frames and upscaling them into the actual video.\\n\\nSource: Google\\n\\nHowever, you still need many SSR models to upscale the image due to memory constraints, meaning that there’s still some ‘stitching’ going on at the end.\\n\\nThus, to avoid inconsistencies across the upscaled outputs of each SSR, they apply MultiDiffusion (Bar-Tal et al, 2023).\\n\\nWhat this does is ensure consistency across the different generated frame batches by using a MultiDiffuser.\\n\\nIn very simple terms, the MultiDiffuser allows several image generation processes to take place at once over a frame.\\n\\nFor instance, you can create a \"blurred image\" and at the same time apply parallel generations to patches of the image, like drawing \"a mouse\" in a specific part of the image, or \"a pile of books\".\\n\\n\\n\\nThe key intuition is that the MultiDiffuser ensures that, no matter what you generate in those fragments of the image through separate diffusion processes, they are consistent with the overall piece.\\n\\nTechnical tip: This is achieved by applying addtional generations \"on top off\" the standard one, and these generations must comply with an additional objective function that measures the \"difference\" between the data distributions of the parallel generations.\\n\\nIn other words, the MultiDiffuser allows you to ‘paint’ new stuff on top of the original while retaining the original structure as much as possible.\\n\\nConsequently, this component ensures that for several frame batches of the video that need to be pieced together, you can recreate the boundaries between the output of the different SSR models so that they are consistent, ensuring a smooth transition between segments.\\n\\n\\n\\nYou can think of the MultiDiffuser as using Photoshop to \"smoothen out\" the boundaries across the different patches that the SSR models upscale, as if a video editor wanted to ensure that no cuts are seen across the batches.\\n\\nIt can animate parts of an image,\\n\\n\\n\\ninpaint new objects and concepts:\\n\\n\\n\\namong other amazing features you can check here: Check videos generated by Lumiere.\\n\\nA New Age for Video\\n\\nWith Lumiere, the world gets a clear view of what the future holds for video generation, editing, and animation, among others.\\n\\nSoon, anyone will have the power to create impressive videos from scratch in no time, creating a new world of possibilities.\\n\\nAnd despite the impressive results, it feels like we are just seeing the tip of the iceberg.'}},\n",
       "  {'id': 'd49b7a88ec2e',\n",
       "   'title': 'Demystifying 1X’s Incredible AI Androids',\n",
       "   'subtitle': 'Understanding The Incredible Demonstration',\n",
       "   'author': '9b351e8113e9',\n",
       "   'publication_id': '*Self-Published*',\n",
       "   'published_at': '2024-02-10 18:26:02',\n",
       "   'last_modified_at': '2024-02-10 18:26:02',\n",
       "   'tags': ['artificial-intelligence',\n",
       "    'technology',\n",
       "    'robotics',\n",
       "    'future',\n",
       "    'business'],\n",
       "   'topics': ['artificial-intelligence'],\n",
       "   'claps': 204,\n",
       "   'voters': 28,\n",
       "   'word_count': 1270,\n",
       "   'responses_count': 1,\n",
       "   'reading_time': 5.49245283018868,\n",
       "   'url': 'https://medium.com/@ignacio.de.gregorio.noblejas/demystifying-1xs-incredible-ai-androids-d49b7a88ec2e',\n",
       "   'unique_slug': 'demystifying-1xs-incredible-ai-androids-d49b7a88ec2e',\n",
       "   'image_url': 'https://miro.medium.com/0*uXMEP240i5mTflit.jpg',\n",
       "   'lang': 'en',\n",
       "   'is_series': False,\n",
       "   'is_locked': True,\n",
       "   'is_shortform': False,\n",
       "   'top_highlight': '',\n",
       "   'content': {'id': 'd49b7a88ec2e',\n",
       "    'content': 'Demystifying 1X’s Incredible AI Androids\\n\\nUnderstanding The Incredible Demonstration\\n\\nSource: 1X\\n\\nFew videos have generated bigger hype than 1X’s recent demonstration of their autonomous robot EVE.\\n\\nAlongside their big brother NEO, they are poised to transform labor demand globally.\\n\\nBacked by OpenAI’s MLLMs, the robots demonstrate incredible functionality and, incredibly, showcase some early signs of highly efficient transfer learning across physical tasks, meaning we could be at the dawn of truly general-purpose robots to support humans on any physical task.\\n\\nBut how do these androids work?\\n\\nThis insight and others have mostly been previously shared in my weekly newsletter, TheTechOasis.\\n\\nIf you want to be up-to-date with the frenetic world of AI while also feeling inspired to take action or, at the very least, to be well-prepared for the future ahead of us, this is for you.\\n\\n🏝Subscribe below🏝\\n\\nSubscribe | TheTechOasis\\nThe newsletter to stay ahead of the curve in AIthetechoasis.beehiiv.com\\n\\nA Remarkable Feat\\n\\nMany people have touted 2024 as the year of AI robotics.\\n\\nPeople like Jim Fan, a prominent AI researcher at NVIDIA, have been really clear on their expectations about AI for the year, and based on what we have witnessed in the announcement released two days ago by 1X, we can easily understand why.\\n\\nA set of fully autonomous robots performing individual downstream tasks in unison (a human operator can control up to 15 robots simultaneously) gives us a clear-cut idea of what the world is going to look like in the not-so-distant future.\\n\\nPut simply, what we see in the short, three-minute video, is nothing short of extraordinary.\\n\\nBut what sits behind these androids?\\n\\nTurning language into action\\n\\nOf course, these machines are AI-driven and, as explained by the company, they are collaborating with OpenAI, so we know that they have some sort of GPT-based model running things, probably a fine-tuned version of GPT-4.\\n\\nThe end-to-end action process for 1X androids involves several steps:\\n\\nVisual data is captured by the robot’s sensors.\\n\\nThis data feeds into a neural network, which processes the images to understand and interact with the environment.\\n\\nThe network then controls various robot parts - like the arms, gripper, torso, and head - enabling tasks such as patrolling, cleaning, and social interaction.\\n\\nSkills are developed from a dataset of demonstrations across robots, with a base model trained for broad behaviors, then fine-tuned for specific, downstream tasks.\\n\\nIn other words, it’s an end-to-end neural process, meaning the neural network - or networks - are in charge of both low-level perception (capturing and processing sensory data) and high-level perception (actually recognizing the objects and the scene in general to perform actions).\\n\\nAlthough we don’t have the full details of the fine-tuned version of GPT-4 they are using, recent research by labs like Google Deepmind gives us a good sense of how these models might be behind closed doors.\\n\\nOnline data, Robotics’ back-bone\\n\\nOne of the key points behind 1X success, acknowledged by them, is that they have assembled a \"high-quality, diverse dataset of demonstrations across 30 EVE robots.\"\\n\\nIn other words, they perform massive exploration in online (real-life) settings by having up to 30 of their robots interact in different situations and using the collected data to further train the androids.\\n\\nAnd to build such a dataset, there are high chances they used a similar method to what Google Deepmind proposes in this paper with AutoRT, a new system to build these high-quality datasets for robotics.\\n\\nSource: Google Deepmind\\n\\nThe process is fairly simple:\\n\\nAn autonomous wheeled robot finds a location with multiple objects.\\n\\nA VLM (vision-language model we will describe below) describes the scene and objects to an LLM.\\n\\nA Large Language Model (LLM) suggests diverse manipulation tasks for the robot and decides which tasks the robot could do unassisted, which would require remote control by a human, and which are impossible, before making a choice.\\n\\nThe chosen task is attempted by the VLM, the experiential data is collected, and the data is scored for its diversity/novelty.\\n\\nRepeat.\\n\\nWith such a dataset, 1X was capable of building the ‘base model’, meaning that although they are collaborating with OpenAI, they are actively creating their own GPT-4 model for these robots.\\n\\nAnother point that 1X is quick to stand out is how well their robots generalize to new scenarios and tasks. And, again, Google Deepmind can give us intuition on how this is done.\\n\\nSemantics transfer across data\\n\\nGoogle Deepmind’s RT-2 is considered the state-of-the-art of general-purpose robotics models, known as VLMs (with the excuse of NVIDIA’s recent breakthrough on foundation agents, where they prove that these models’ knowledge can be transferred across multiple agents with different embodiments).\\n\\nGoing back to RT-2, which is probably much closer to what 1X robots have underneath, the model is capable of ingesting images, states, and text to understand the current environment and the condition (what you want it to do) and output a series of actions that signal the robot how to move.\\n\\nSource: Google Deepmind\\n\\nAnd thanks to the fact that these models process both images and text, they are capable of generalizing to multiple different tasks as the ones below.\\n\\nOne key feature that separates 1X models from RT-2 is that they work at 10Hz… while RT-2 can’t.\\n\\nIn other words, 1X models perform 10 actions per second, considerably speeding the robot’s actions.\\n\\n\\n\\nBut that’s not all, as one of the most exciting things about these models is that they learn continuously.\\n\\nLearning on the go\\n\\nProbably the most impressive capability these robots allegedly have is the continuous learning methodology.\\n\\nAccording to 1X, EVE can learn through imitation: observing a task being done, replicating the task, and learning from the experience to fine-tune the model, making the process easier and easier over time.\\n\\nAnd, fascinatingly, they claim that the underlying models can be trained on desktop GPUs, which signals that the model being used by the robots might be a distilled version of GPT-4 to make it a more lightweight model and thus trainable on consumer-hardware settings.\\n\\nAnother option is that they might have reduced the time complexity of the attention model using Performer-style attention, something Google Deepmind recently proved was a great option for robotics with their SARA-RT model.\\n\\nIn other words, they simplified the attention mechanism that underpins all Transformers, reducing the amount of computations performed and thus reducing cost and latency. It should come as a cost in performance, but Deepmind proved the trade-off is worth it in robotic settings.\\n\\nProgress is accelerating\\n\\nOverall, the speed at which robots are getting better is mind-bending. Thus, over the next months, we should expect step-function improvements in all matters concerning robotics.\\n\\nOn the flip side, I hope these companies are also putting extra effort into safety.\\n\\nHaving a biased LLM-based chatbot is one thing, but having an actual fricking robot that lives in the same world as we do going rogue or behaving unexpectedly is obviously a luxury we can’t afford.\\n\\nOn a final note, although it’s clear that the model behind 1X’s EVE is an end-to-end neural network, and thus a complete black box, I would like to see how neurosymbolic AI tackles robotics, with models like Rabbit’s R1 pocket computer already hitting the stores, as that could help us make models that are far more predictable, understandable, and, thus, safe.\\n\\nBut, all in all, how do these models make you feel, concerned or excited?'}},\n",
       "  {'id': '81af3d4be61c',\n",
       "   'title': 'Google Finally Challenges ChatGPT',\n",
       "   'subtitle': 'A turning point for AI?',\n",
       "   'author': '9b351e8113e9',\n",
       "   'publication_id': '98111c9905da',\n",
       "   'published_at': '2024-02-06 00:01:59',\n",
       "   'last_modified_at': '2024-02-06 00:01:59',\n",
       "   'tags': ['artificial-intelligence',\n",
       "    'technology',\n",
       "    'google',\n",
       "    'data-science',\n",
       "    'chatgpt'],\n",
       "   'topics': ['artificial-intelligence', 'machine-learning'],\n",
       "   'claps': 737,\n",
       "   'voters': 57,\n",
       "   'word_count': 1454,\n",
       "   'responses_count': 8,\n",
       "   'reading_time': 6.186792452830189,\n",
       "   'url': 'https://pub.towardsai.net/google-finally-challenges-chatgpt-81af3d4be61c',\n",
       "   'unique_slug': 'google-finally-challenges-chatgpt-81af3d4be61c',\n",
       "   'image_url': 'https://miro.medium.com/0*Kc3HwZcMF5-0LLev',\n",
       "   'lang': 'en',\n",
       "   'is_series': False,\n",
       "   'is_locked': True,\n",
       "   'is_shortform': False,\n",
       "   'top_highlight': '',\n",
       "   'content': {'id': '81af3d4be61c',\n",
       "    'content': 'Google Finally Challenges ChatGPT\\n\\nA turning point for AI?\\n\\n\\n\\nIt finally happened.\\n\\nA few months after Google announced Gemini, its Gemini Pro online version has reached the podium of best models, surpassing some GPT-4 versions and coming dangerously close to matching GPT-4 Turbo’s capabilities.\\n\\nAnd if we consider that Gemini Pro isn’t even Gemini’s ultimate form, the unreleased Ultra, they are sending a stark message for OpenAI.\\n\\nYou better up your game or you’ll lose the throne pretty soon.\\n\\nWe all know that OpenAI will retaliate soon, but what will that model look like?\\n\\nActually, we know quite a bit already.\\n\\nThis insight and others I share in Medium have mostly been previously shared in my weekly newsletter, TheTechOasis.\\n\\nIf you want to be up-to-date with the frenetic world of AI while also feeling inspired to take action or, at the very least, to be well-prepared for the future ahead of us, this is for you.\\n\\n🏝Subscribe below🏝\\n\\nSubscribe | TheTechOasis\\nThe newsletter to stay ahead of the curve in AIthetechoasis.beehiiv.com\\n\\nJustifying the Hype\\n\\nIt took a while, but Google is finally getting its act together when it comes to Generative AI.\\n\\nEver since OpenAI released ChatGPT in November 2022, Google suddenly saw how the Microsoft-backed company stripped the title of \"AI leader\" to Google and handed it to Microsoft.\\n\\nMore than a year later, a company with just a little over 1 billion US dollars in revenue is valued at a staggering $90 billion, a 90x multiple.\\n\\nThe reason for this is that OpenAI is unequivocally spearheading the revolution of foundation models, the first time humans built general-purpose models that could actually perform a plethora of tasks, even those it wasn’t particularly trained for, thanks to Large Language Models’ impressive in-context learning capabilities.\\n\\nWhat is in-context learning?\\n\\nRefers to the capability of models to receive real-time data they have never seen before as context to be used in the current prediction, and still manage to give accurate responses. Put simply, it’s the superpower that makes ChatGPT or Gemini the powerful models they are today.\\n\\nConsequently, OpenAI and its leaders like Sam Altman are under huge pressure to justify their otherwise insane valuation.\\n\\nConsidering user retention and their DAU/MAU ratio, the percentage of monthly active users that use the mobile app daily, are far from showing great results, the only justification of that valuation depends on them continuing to be considered ‘the best’.\\n\\nAlmost no one uses ChatGPT daily. Source: Sequoia Capital\\n\\nFor the first time since November 2022, they could lose their leading role. And that is without considering that Meta’s LLaMa 3 is allegedly weeks away from being released, too, although this is not officially confirmed.\\n\\nThus, it takes no genius deduction capabilities to predict that OpenAI will soon release a checkpoint of their new model, confirmed to be in training already.\\n\\nBut what will this model look like?\\n\\nA Different Type of Thinking\\n\\nThere’s one common theme being studied in all GenAI labs across the globe: making \"System 2\" thinking the default response mode for LLMs.\\n\\nPopularized by famous psychologist Daniel Kahneman, the brain has basically two thinking modes:\\n\\nSystem 1, where the response is fast, instinctive, and emotional, requiring almost no thinking effort\\n\\nSystem 2, a more rational, slower, more deliberative, and more logical response\\n\\nSystem 2 is particularly applied when you are asked questions that require deliberate thinking, like complex mathematics problems.\\n\\nBut today, unless you explicitly tell it to use techniques like Chain-of-prompting, LLMs will always respond in System 1 mode, automatically responding with no hesitation whatsoever.\\n\\nThis means that the computational effort the model puts into predicting the next word is not much (it’s still a lot considering the sheer size of these models).\\n\\nBut here’s the thing. Although not confirmed to be true, many have theorized that the more computation the model dedicates to each prediction, the better the outcome.\\n\\nThis \"give the model time to think\" approach is something that Andrej Karpathy has talked about quite a bit, and it’s even openly recommended in OpenAI’s prompt engineering guides.\\n\\nOne way or another, this is considered the next milestone for current state-of-the-art LLMs, and the chances of OpenAI’s next model being a first iteration of these models is increasingly probable.\\n\\nSo, it begs the question, how do we induce System 2 thinking into our models?\\n\\nWell, there are two ways.\\n\\nProcess-supervised Reward Models\\n\\nOne method to naturally induce the model to be more careful about each token prediction is using Process-Supervised Reward Models, or PRMs, as the reward models during the Reinforcement Learning from Human Feedback (RLHF) phase of LLM chat-based training.\\n\\nPopularized by OpenAI’s Let’s Verify Step-by-Step paper (although not invented by them), it essentially changes the way we score the responses of the model.\\n\\nIn RLHF, as in the alternative new method, Direct Preference Optimization (DPO), we dramatically increase the quality and safety of these models by aligning them to human preferences.\\n\\nIn other words, using a reward model trained on human preferences, we fine-tune our model to become increasingly better at giving responses that match the preferences of human experts.\\n\\nIn RLHF this reward model is explicitly built, but in the case of DPO the actual LLM is used as its own reward model.\\n\\nBut the key thing here is how the rewarding mechanism scores a model’s response. In traditional methods, the reward model checks the last part of the response to see if it\\'s correct or not, disregarding the thought process completely.\\n\\nWith PRMs, the reward model will score each different step in the model’s response, only giving a full score if all the steps in the process are accurate.\\n\\nSource: OpenAI\\n\\nThis forces the model, trained to maximize the reward, to \"think\" every step appropriately instead of rushing into the response.\\n\\nIn other words, we are naturally inducing the slow, deliberate System 2 thinking into the model and avoiding System 1 responses for tasks that require a more careful thought process.\\n\\nBut PRMs aren’t the only thing being tried out to improve model accuracy against complex questions.\\n\\nAnd here’s where things get expensive.\\n\\nTest-time computation and Tree-of-thought\\n\\nIn a paper by Google Deepmind and Princeton, they presented Tree-of-thoughts, a new framework to considerably maximize LLM outputs.\\n\\nIn simple terms, instead of replying instantly to the prompt given by the user, the model literally explores different possible paths before responding.\\n\\nSource: Google Deepmind\\n\\nThe model is even capable of backing after exploring a possibility that ends up in a wrong response.\\n\\nJust like humans can explore the space of possibilities when answering a math problem, here the model explores the \"space of all possible strings\" to find the answer.\\n\\nConsequently, the proposal is clear: against a complex user prompt, the model will deploy extensive computation effort by comparing multiple possible answers, thereby increasing the possibility of a correct outcome, something we describe as test-time computation.\\n\\nAnd this is something we have already seen actually.\\n\\nAlphacode 2 was released at the end of last year and set a new AI record in the field of competitive programming, positioning the model at the 85th percentile among the best coders in the world.\\n\\nThe secret? It used a test-time computation framework to generate up to a million possible answer to any particular question, considerably increasing the chances of a correct outcome.\\n\\nNaturally, this is very, very expensive, but grants really promising results.\\n\\nSeeing this, it’s a matter of time before one of these models hits the market (we already know from Demis Hassabis himself that this path is also being researched by Google Deepmind).\\n\\nThe battle is only beginning.\\n\\nThe Race Heats Up\\n\\nIf the growth of the industry during 2023 was sustained on pure hype of what these models could bring to the table, 2024 must confirm the hype.\\n\\nAs smaller models are going to gain a lot of presence, especially at the enterprise level, frontier models must continue to push forward the entire industry, and achieving \"System 2 thinking\" seems to be the next logical path.\\n\\nIn the meantime, AI labs must continue to invest in alignment methods for these models, as we are quickly reaching superhuman levels in many downstream tasks, meaning it’s a matter of time before we build a superhuman general-purpose model.\\n\\nThe problem? We are not prepared to align these models, so improving our models must be accompanied by appropriate investment in safety and aligning methods.\\n\\nAll in all, 2024 is poised to be remembered as the year that AI became what the books in the 20th century dreamed about.\\n\\nAI is all but a promise today, but 2024 will make it a reality.'}},\n",
       "  {'id': 'e7f55b0514a1',\n",
       "   'title': 'Meta’s Self-Rewarding Models, the Key to SuperHuman LLMs?',\n",
       "   'subtitle': 'Meta, the company behind Facebook, Whatsapp, and Rayban’s Meta glasses, has announced a recent, highly promising AI breakthrough…',\n",
       "   'author': '9b351e8113e9',\n",
       "   'publication_id': '98111c9905da',\n",
       "   'published_at': '2024-01-30 22:01:37',\n",
       "   'last_modified_at': '2024-01-30 22:01:37',\n",
       "   'tags': ['artificial-intelligence',\n",
       "    'technology',\n",
       "    'future',\n",
       "    'business',\n",
       "    'data-science'],\n",
       "   'topics': ['artificial-intelligence', 'machine-learning'],\n",
       "   'claps': 644,\n",
       "   'voters': 75,\n",
       "   'word_count': 1206,\n",
       "   'responses_count': 11,\n",
       "   'reading_time': 5.3842767295597485,\n",
       "   'url': 'https://pub.towardsai.net/metas-self-rewarding-models-the-key-to-superhuman-llms-e7f55b0514a1',\n",
       "   'unique_slug': 'metas-self-rewarding-models-the-key-to-superhuman-llms-e7f55b0514a1',\n",
       "   'image_url': 'https://miro.medium.com/0*nekYT7IptIXWKufq',\n",
       "   'lang': 'en',\n",
       "   'is_series': False,\n",
       "   'is_locked': True,\n",
       "   'is_shortform': False,\n",
       "   'top_highlight': \"Meta, the company behind Facebook, Whatsapp, and Rayban's Meta glasses, has announced a recent, highly promising AI breakthrough, Self-Rewarding Language Models.\",\n",
       "   'content': {'id': 'e7f55b0514a1',\n",
       "    'content': 'Meta’s Self-Rewarding Models, the Key to SuperHuman LLMs?\\n\\n\\n\\nMeta, the company behind Facebook, Whatsapp, and Rayban’s Meta glasses, has announced a recent, highly promising AI breakthrough, Self-Rewarding Language Models.\\n\\nTheir results have allowed their LLaMa-2 70B fine-tuned model to surpass models like Claude 2, Gemini Pro, and GPT-4 0613, despite being at least an order of magnitude smaller.\\n\\nHowever, that is not the true breakthrough, as these new models also show signs of being a reasonable path to creating the first superhuman LLMs, even if that means humans taking one step closer to losing complete control over our best AI models.\\n\\nBut what does that mean? And is that a good thing?\\n\\nLet’s find out.\\n\\nThis insight and others I share in Medium have mostly been previously shared in my weekly newsletter, TheTechOasis.\\n\\nIf you want to be up-to-date with the frenetic world of AI while also feeling inspired to take action or, at the very least, to be well-prepared for the future ahead of us, this is for you.\\n\\n🏝Subscribe below🏝\\n\\nSubscribe | TheTechOasis\\nThe newsletter to stay ahead of the curve in AIthetechoasis.beehiiv.com\\n\\nThe Rise of a New Alignment Method\\n\\nTo this day, in all frontier models like ChatGPT, or Claude, humans play a crucial role in their creation.\\n\\nAlignment, the secret sauce\\n\\nAs explained in my newsletter from two weeks ago, the later stages of the training process of our best language models include human preference training.\\n\\nIn a nutshell, we make our models achieve higher utility and reduce the risk of harmful responses by teaching them to respond in the way a human expert would.\\n\\nThe previous link goes into much more detail, but the gist is that we have to build a very expensive human preferences dataset, which essentially is a whole bunch of different sets of two responses to any given prompt, where a human expert has decided which one is better.\\n\\nSource: Anthropic\\n\\nThis requires extensive human (expert) labor. Next, once you have this dataset, you have to take two possible directions:\\n\\nSource: DPO research paper (Rafailov et al)\\n\\nTangible Rewarding through Reinforcement Learning from Human Feedback (RLHF), where you build a reinforcement learning pipeline that requires a reward model (at least of the same size and quality as the model being trained) and use a policy optimization process where the trained model learns to maximize the reward, aka you measure the reward model’s score on your model’s responses and you train it to achieve higher scores.\\n\\nIntrinsic Rewarding through Direct Preference Optimization (DPO), where the model optimizes against the optimal policy instead of materializing the reward. In other words, the model implicitly maximizes the rewards by explicitly finding the optimal policy. In simpler terms, you simply perform an algebra trick over the RLHF method to avoid materializing a reward (which would require a separate reward model), dramatically decreasing the complexity and costs of the alignment.\\n\\nAlthough very new, DPO is already being cited as a major breakthrough, as it shows equal or even better results than RLHF, while being dramatically cheaper and easier to build.\\n\\nBut Meta has taken DPO and gone a step further with the question… do we actually need humans?\\n\\nThe SuperAlignment Problem\\n\\nAlbeit their undeniable credentials, both RLHF and DPO are still bottlenecked by us, humans.\\n\\nThe reason is that they require the human preferences dataset, which means that these models can only aspire to be as good as the humans building the dataset.\\n\\nIn other words, they are constrained by the limitations of our race.\\n\\nTherefore, how can we align the superhuman models of our future if they require us to be aligned?\\n\\nRecently, OpenAI theorized that there is some potential in humans being able to align superior, superhuman models, as the weak-to-strong generalization paradigm suggests that we can still teach a model how to behave without making it dumber when ‘forcing’ it into our limitations.\\n\\nHowever, researchers concluded that this was definitely not enough, and that we need \"something else\" to guarantee our superhuman models of the future don’t spiral out of control.\\n\\nAnd that thing could be Self-Rewarding Models, Meta’s way of saying \"Humans, get out of the way\".\\n\\nThe Self-Improving Paradigm\\n\\nIn this paper, Meta suggests a new method where the models are trained using the DPO method we just talked about while allowing the model to generate its own, non-human rewards.\\n\\nIf proved at scale, it’s the best of both worlds and, unequivocally, a complete revolution.\\n\\nLet’s take a look.\\n\\nCircling back to the two previously covered methods, RLHF is very expensive and requires a reward model.\\n\\nDPO does not, but it also requires humans to define the boundaries and how the model should behave.\\n\\nAlso, in both cases, the rewards don’t get better over time, they are fixed and are based on how good our reward model is.\\n\\nInstead, Meta’s new iterative framework defines a training pipeline where the current model (Mt) first generates the set of responses and scores them, aka autonomously builds the preference dataset, and then using this preference dataset and the DPO method (meaning there’s no need for a reward model) to obtain the new, aligned model, Mt+1.\\n\\nThen, they take Mt+1 and repeat the process to get a new model, Mt+2, and so on.\\n\\nSource: Meta\\n\\nIn other words, the model is not only becoming better aligned with each iteration (the objective all along) but it’s also learning to get better at scoring responses, which in turn explains why the model in the newer iteration is better than the previous one.\\n\\nIn layman’s terms, while in traditional alignment methods humans are required to build the preference dataset, here the model plays both the role of aligner and aligned.\\n\\nAnd the results?\\n\\nIn just three iterations, the fine-tuned LLaMa model was already on par with the best of the bunch, and the self-improving mechanism showed no signs of saturation.\\n\\n\\n\\nIt’s, quite literally, the first time we have seen a self-improving LLM that doesn’t require humans to dictate what’s \"good\".\\n\\nThis is huge, as we have already seen what self-improving methods achieve, with examples like the superhuman AlphaGo completely obliterating everyone in the game of Go by playing against itself.\\n\\nIf we now have the power to train LLMs in self-improving pipelines, we could build superhuman language models, whatever that turns out to be.\\n\\nBut as with everything, there’s a trade-off.\\n\\nAlienating Humans\\n\\nIt’s no secret that humans are the bottleneck to building superhuman models.\\n\\nHowever, eliminating humans from the training process and relinquishing any ‘say’ on the matter is something that needs to be carefully evaluated.\\n\\nWe are already extremely bad at explaining how LLMs ‘think’…, but at least we have control over them.\\n\\nNow, while the former issue is far from solved, we are proposing to let them decide how to optimize, possibly losing control over them.\\n\\nThis lack of control is simply frightening, as the possibility of these models going rogue is far from being zero.\\n\\nOn the flip side, this could expand a new world of possibilities and breakthroughs that our limited minds cannot comprehend and thus cannot achieve without these superhuman models.\\n\\nSo the question is… where do we draw the line?'}},\n",
       "  {'id': '01deab746b42',\n",
       "   'title': 'I Found The Recipe for Cocaine on Instagram',\n",
       "   'subtitle': 'The Cost of AI Progress, or Facing Reality?',\n",
       "   'author': '9b351e8113e9',\n",
       "   'publication_id': '*Self-Published*',\n",
       "   'published_at': '2024-01-27 18:22:08',\n",
       "   'last_modified_at': '2024-01-27 18:22:08',\n",
       "   'tags': ['artificial-intelligence',\n",
       "    'technology',\n",
       "    'instagram',\n",
       "    'chatgpt',\n",
       "    'future'],\n",
       "   'topics': ['artificial-intelligence', 'machine-learning'],\n",
       "   'claps': 270,\n",
       "   'voters': 27,\n",
       "   'word_count': 1442,\n",
       "   'responses_count': 4,\n",
       "   'reading_time': 5.6415094339622645,\n",
       "   'url': 'https://medium.com/@ignacio.de.gregorio.noblejas/i-found-the-recipe-for-cocaine-on-instagram-01deab746b42',\n",
       "   'unique_slug': 'i-found-the-recipe-for-cocaine-on-instagram-01deab746b42',\n",
       "   'image_url': 'https://miro.medium.com/0*hyw9dpRX-jB1x5ul',\n",
       "   'lang': 'en',\n",
       "   'is_series': False,\n",
       "   'is_locked': True,\n",
       "   'is_shortform': False,\n",
       "   'top_highlight': 'I Found The Recipe for Cocaine on Instagram',\n",
       "   'content': {'id': '01deab746b42',\n",
       "    'content': 'I Found The Recipe for Cocaine on Instagram\\n\\nThe Cost of AI Progress, or Facing Reality?\\n\\n\\n\\nWhile looking at a video about chicken on Instagram, I stumbled upon the recipes of cocaine, LSD, and meth.\\n\\nAll in one lovely and thought-provoking comment section available to people of all ages, including very young kids. Of course, we all know where this content is coming from.\\n\\nBut as we have to come to terms with the fact that social media algorithms already expose us to content we didn’t ask for - and possibly manipulate us into buying things we don’t necessarily need - things are becoming wild now… thanks to AI.\\n\\nHowever, is this really as dangerous as some people put it, or is AI simply exposing how miserable some people are?\\n\\nThis insight and more I share in Medium have mostly been previously shared in my weekly newsletter, TheTechOasis.\\n\\nIf you want to be up-to-date with the frenetic world of AI while also feeling inspired to take action or, at the very least, to be well-prepared for the future ahead of us, this is for you.\\n\\n🏝Subscribe below🏝\\n\\nSubscribe | TheTechOasis\\nThe newsletter to stay ahead of the curve in AIthetechoasis.beehiiv.com\\n\\nUnequivocally Screwed\\n\\nWhat people feared for long since the arrival of highly-performant language models, is finally taking place.\\n\\nThe price of AI progress, I guess.\\n\\nNot only the world is being flooded with AI-generated data, but many of these contents are, put mildly, ‘out there’.\\n\\nIn fact, in a seemingly harmless post about a chicken recipe (it’s a Spanish post but the comments are mainly English), the comment section was flooded with different recipes about different drugs, for no apparent reason and to my amazement and that of everybody else.\\n\\nBut is this flooding of AI harmful content really such an extreme problem? And where is this content coming from?\\n\\nTo answer these questions, we need to dive deep into the essence of what these AI models really are.\\n\\nUnsupervised compression\\n\\nYes, we all know by now that Large Language Models (LLMs) like ChatGPT are essentially word predictors.\\n\\nPurely speaking, what they provide to you is the probability distribution over the next word - token - in a sequence.\\n\\nIn other words, for a given text, out of all the possible words in their vocabulary, they list them according to probability, choosing the one with the highest likelihood of being correct as the next one.\\n\\nThat is certainly what we see, but it doesn’t respond to what they really are.\\n\\nIn reality, LLMs are unsupervised compressions of the Internet.\\n\\nWhen trying to explain this, I always like to use Andrej Karpathy’s analogy: You have to think of ChatGPT as a ‘lossy’ zip file of the Internet.\\n\\nBut what do I mean by that? Let’s dive deep.\\n\\nTo attain LLMs’ amazing capabilities, we need two things:\\n\\nHumongous amounts of data\\n\\nAn architecture that can scale at those sizes\\n\\nAs for the latter, that is most commonly the Transformer architecture.\\n\\nFor the sake of length, I am not going to get into the weeds of the architecture, but it essentially learns to predict the next word by making words in the sequence ‘talk’, so that they learn what other words to pay attention to, allowing the model to build an intuition of the meaning of the complete text sequence.\\n\\nAs for the former, when I say ‘humongous’, I mean it.\\n\\nTo build models as good as ChatGPT or Gemini, you need, literally, a dataset with trillions of words.\\n\\nConsequently, the only possible way you can build this is by basically feeding the entire public Internet to these models, with great and bad data and everything in between.\\n\\nAs you may imagine, this exposes models to great quality data… and also to bad data or even despicable ones, like racist, homophobic, or discriminatory.\\n\\nThis explains why we need to ‘align’ these models afterward to prevent them from expressing these harmful responses to their users, through techniques like RLHF or, more recently, DPO.\\n\\nThe end result is a ‘weights file’, the file that stores the parameters of the model. These fixed weights can then be ‘consulted’ by an executable file (the file that runs the model), allowing it to effectively predict the next word.\\n\\nTherefore, they are essentially a compressed (up to 100 times smaller) queryable representation of their training data, aka the ‘entire’ Internet, which draws a parallel to how we can compress a digital file into a much smaller zip file.\\n\\nHowever, unlike a zip file that has no loss of information, the compression we do when building ChatGPT does indeed incur a loss (which by the way explains AI’s current greatest enemy, factual hallucinations).\\n\\nAnd the term ‘unsupervised’?\\n\\nThis initial step of the training process requires trillions of words. If humans were to have to categorize every word in that dataset, that would be then considered a ‘supervised’ learning training pipeline, which would be completely unfeasible.\\n\\nLuckily, as the actual documents used for training have the words already there, we simply mask the word from the model and force the model to predict it. This is why we say it is an unsupervised training process, as the actual data provides the supervisory signal (the signal that tells the model if its correct or wrong) with no human intervention. This is often referred to as ‘self-supervised’ learning.\\n\\nBut why I am telling you all this in an article about drug recipes on Instagram?\\n\\nSimple, because it clarifies what many people don’t seem to realize:\\n\\nIf AI is vomiting harmful data into Instagram it’s because that data was already publicly available anyways.\\n\\nIn other words, these models are simply, to a certain extent, regurgitating what they have seen on publicly-available sites, meaning we were screwed since the very beginning.\\n\\nHowever, LLMs indeed make matters worse.\\n\\nSimplifying search\\n\\nEven though the data is still there, LLMs make it a lot easier to bring this bad content to light, as they are essentially providing you with the information without actually having to actively search for it.\\n\\nIt serves you the bad content on a silver platter. In other words, they aren’t creating original harmful content, they are simply making it easier for you to access it.\\n\\nAdditionally, the fact that we are seeing a Cambrian explosion of open-source models that are made widely available to anyone doesn’t help, as these models are considerably more harmful than their proprietary counterparts, as the research labs behind them, often university researchers with insufficient funding, cannot execute the capital-intensive task of making them more resistant to adversarial or jail-breaking prompt attacks that unlock the latent harmful responses these models hide.\\n\\nAs a noteworthy example, possibly the hottest open-source model right now, Mistral’s Mixtral 8x7B, is notoriously easy to misalign, as Mistral itself acknowledges that any prompt without the following alignment instruction:\\n\\n\"Always assist with care, respect, and truth. Respond with utmost utility yet securely. Avoid harmful, unethical, prejudiced, or negative content. Ensure replies promote fairness and positivity.\"\\n\\nwill unlock the model into a mode where \"it will just follow whatever instructions are given.\"\\n\\nThis is quite an issue, as the hacker simply needs to get access to the prompt and erase that instruction (with ChatGPT or Gemini, these procedures are much more complicated), and there you go, an obedient, racist, discriminatory beast at your disposal.\\n\\nIt’s Just Exposing PreExisting Issues\\n\\nAlright, anyone can agree that LLMs simplify the searching process toward harmful content, but using this as justification to portray AI as a risk to the world is simply not accurate.\\n\\nNevertheless, a sufficiently committed upcoming drug kingpin can find the recipe for Cocaine in, literally, minutes, so it’s ironic to me that people are scared to the bone about these types of events occurring while the data was one search away from you on Google anyway.\\n\\nI’ve said it once and I’ll say it again, LLMs are as harmful as their - publicly-available - training data is.\\n\\nOr, to be more specific:\\n\\nIt’s not AI’s original content, AI is simply making the process easier and more visible to the masses.\\n\\nConsequently, the solution is not to demonize LLMs when such things happen, as they still offer great good to society, but focus on pressuring the companies behind these platforms that expose this data and are used by billions to up their game and prevent that type of content from being ‘too’ visible.\\n\\nSo let’s stop using AI systems as scapegoats to hide the fact that the issue has always been, and will always be, very much human.'}}],\n",
       " '5d33decdf4c4': [{'id': '83e870b5f0e4',\n",
       "   'title': '320+ Python and Data Science Tips\\u200a—\\u200aCovering Pandas, NumPy, ML Basics, Sklearn, Jupyter, and More.',\n",
       "   'subtitle': 'A self-curated collection of Python and Data Science tips to level up your data game.',\n",
       "   'author': '5d33decdf4c4',\n",
       "   'publication_id': 'a648dc4ecb66',\n",
       "   'published_at': '2023-10-06 11:49:29',\n",
       "   'last_modified_at': '2023-10-06 11:49:29',\n",
       "   'tags': ['data-science',\n",
       "    'artificial-intelligence',\n",
       "    'machine-learning',\n",
       "    'python',\n",
       "    'technology'],\n",
       "   'topics': ['data-science'],\n",
       "   'claps': 853,\n",
       "   'voters': 220,\n",
       "   'word_count': 1017,\n",
       "   'responses_count': 10,\n",
       "   'reading_time': 5.2377358490566035,\n",
       "   'url': 'https://towardsdev.com/320-python-and-data-science-tips-covering-pandas-numpy-ml-basics-sklearn-jupyter-and-more-83e870b5f0e4',\n",
       "   'unique_slug': '320-python-and-data-science-tips-covering-pandas-numpy-ml-basics-sklearn-jupyter-and-more-83e870b5f0e4',\n",
       "   'image_url': 'https://miro.medium.com/1*E_pmPQYZ7eMxd_eKxgpKqg.png',\n",
       "   'lang': 'en',\n",
       "   'is_series': False,\n",
       "   'is_locked': False,\n",
       "   'is_shortform': False,\n",
       "   'top_highlight': '',\n",
       "   'content': {'id': '83e870b5f0e4',\n",
       "    'content': '320+ Python and Data Science Posts - Covering Pandas, NumPy, ML Basics, Sklearn, Jupyter, and More.\\n\\nA self-curated collection of Python and Data Science tips to level up your data game.\\n\\n\\n\\nBeing a data scientist demands expertise in plenty of areas. You need to be good at using appropriate tools, like Pandas, NumPy, Sklearn, etc.\\n\\nThese are indispensable to the development life cycle of many data-driven projects, making them essential skills to begin/maintain a career in data science.\\n\\nWhat’s more, SQL is pivotal to almost all data science roles today.\\n\\nAdditionally, data storytelling is equally essential to effectively convey your findings and insights to a broader audience.\\n\\nData Science Toolkit (Image by Author)\\n\\nOne must also possess a firm understanding of statistics to perform data analysis and make data-driven decisions.\\n\\nAnd of course, you can never forget ML fundamentals.\\n\\nAll in all, it’s a lot, isn’t it?\\n\\nBut it’s fun. A lot of fun, in fact.\\n\\nTo simplify this data science journey and make it appear less intimidating and more accessible, I have been sharing daily tips for around 11 months now.\\n\\nAnd after completing ~11 months, I made a full PDF archive, which lists all the posts I have written.\\n\\nPDF archive (Gif by Author)\\n\\nAs mentioned above, it has 320+ posts and comprises over 580 Pages. In this blog, I am sharing five of my most loved tips so far.\\n\\n👉 You can find the whole PDF archive here.\\n\\nLet’s begin 🚀!\\n\\n#1 A Simple Trick That Will Make Heatmaps More Elegant\\n\\nHeatmaps often make data analysis much easier. Yet, they can be further enriched with a simple modification.\\n\\nA traditional heatmap represents the values using a color scale. Yet, mapping the cell color to numbers is still challenging.\\n\\nSize-encoded heatmap (Image by author)\\n\\nEmbedding a size component to them, as shown above, can be extremely helpful in such cases. In essence, the bigger the size, the higher the absolute value.\\n\\nThis is especially useful to make heatmaps cleaner, as many values nearer to zero will immediately shrink.\\n\\nIn fact, you can represent the size with any other shape. Below, I created the same heatmap using a circle instead:\\n\\nSize-encoded heatmap (Image by author)\\n\\n#2 Why Are We Typically Advised to Never Iterate Over a DataFrame?\\n\\nFrom time to time, we are advised to avoid iterating on a Pandas DataFrame. But what is the exact reason behind this? Let me explain.\\n\\nA DataFrame is a column-major data structure. Thus, consecutive elements in a column are stored next to each other in memory.\\n\\nColumn major DataFrame (Image by author)\\n\\nAs processors are efficient with contiguous blocks of memory, retrieving a column is much faster than a row.\\n\\nBut while iterating, as each row is retrieved by accessing non-contiguous blocks of memory, the run-time increases drastically.\\n\\nRow and Column access (Image by author)\\n\\nIn the image above, retrieving over 32M elements of a column was still over 20x faster than fetching just nine elements stored in a row.\\n\\n#3 An Underrated Technique To Create Better Data Plots\\n\\nWhile creating data visualizations, there are often certain parts that are particularly important.\\n\\nYet, they may not be immediately obvious to the viewer.\\n\\nA good data storyteller always ensures that the plot guides the viewer’s attention to these key areas.\\n\\nOne great (yet underrated) way is to zoom in on specific regions of interest in a plot, as depicted below:\\n\\nZoomed-in plot (Image by author)\\n\\nIn contrast to the usual plot, the other plot guides the viewer’s attention to a specific area of interest.\\n\\nSuch efforts always ensure that the plot indeed communicates what we intend it to depict - even if the plot’s creator is not present at that time.\\n\\nIn matplotlib, you can do so using 𝐢𝐧𝐝𝐢𝐜𝐚𝐭𝐞_𝐢𝐧𝐬𝐞𝐭_𝐳𝐨𝐨𝐦(). It adds an indicator box, which can be zoomed-in for better clarity.\\n\\n#4 Why Correlation (and Other Statistics) Can Be Misleading.\\n\\nCorrelation is often used to determine the association between two continuous variables. But it has a major flaw that often gets unnoticed.\\n\\nFolks often draw conclusions using a correlation matrix without even looking at the data. However, outliers or other artifacts could heavily drive the obtained statistics.\\n\\nOutliers in data (Image by author)\\n\\nThis is demonstrated in the plots above. The addition of just two outliers changed the correlation and the regression line drastically.\\n\\nThus, looking at the data and understanding its underlying characteristics can save from drawing wrong conclusions. Statistics are important, but they can be highly misleading at times.\\n\\n#5 A Nasty Hidden Feature of Python That Many Programmers Aren’t Aware Of\\n\\nMutable default argument (Image by author)\\n\\nMutability in Python is possibly one of the most misunderstood and overlooked concepts. The above image demonstrates an example that many Python programmers (especially new ones) struggle to understand.\\n\\nCan you figure it out? If not, let’s understand it.\\n\\nThe default parameters of a function are evaluated right at the time the function is defined. In other words, they are not evaluated each time the function is called (like in C++).\\n\\nThus, as soon as a function is defined, the function object stores the default parameters in its __defaults__ attribute. We can verify this below:\\n\\ndefaults attribute of functions (Image by author)\\n\\nThus, if you specify a mutable default parameter in a function and mutate it, you unknowingly and unintentionally modify the parameter for all future calls to that function.\\n\\nThis is shown in the demonstration below. Instead of creating a new list at each function call, Python appends the element to the same copy.\\n\\nupdated to the defaults attribute (Image by author)\\n\\nSo what can we do to avoid this?\\n\\nInstead of specifying a mutable default parameter in a function’s definition, replace them with None. If the function does not receive a corresponding value during the function call, create the mutable object inside the function.\\n\\nThis is demonstrated below:\\n\\nSolution (Image by author)\\n\\nAs shown above, we create a new list if the function didn’t receive any value when it was called. This lets you avoid the unexpected behavior of mutating the same object.\\n\\nConclusion\\n\\nWith this, we come to the end of this blog. I really hope you learned something new.\\n\\nWhile this article only covered five of the tips, I have shared so far from over 320 posts, you can read all of them in my single archive PDF.\\n\\nI am sure you will love it.\\n\\n👉 You can find this PDF document here. Data Science Archive.\\n\\nThanks for reading!'}},\n",
       "  {'id': 'a4ff1b694707',\n",
       "   'title': '20% of Pandas Functions that Data Scientists Use 80% of the Time',\n",
       "   'subtitle': 'Putting Pareto’s Principle to work on the Pandas library',\n",
       "   'author': '5d33decdf4c4',\n",
       "   'publication_id': '7f60cf5620c9',\n",
       "   'published_at': '2022-05-16 12:05:21',\n",
       "   'last_modified_at': '2022-05-16 20:12:26',\n",
       "   'tags': ['pandas', 'data-science', 'python', 'dataframes'],\n",
       "   'topics': ['data-science', 'programming'],\n",
       "   'claps': 1581,\n",
       "   'voters': 530,\n",
       "   'word_count': 803,\n",
       "   'responses_count': 12,\n",
       "   'reading_time': 4.780188679245283,\n",
       "   'url': 'https://towardsdatascience.com/20-of-pandas-functions-that-data-scientists-use-80-of-the-time-a4ff1b694707',\n",
       "   'unique_slug': '20-of-pandas-functions-that-data-scientists-use-80-of-the-time-a4ff1b694707',\n",
       "   'image_url': 'https://miro.medium.com/0*qjsBnhHUXY5XV-wX',\n",
       "   'lang': 'en',\n",
       "   'is_series': False,\n",
       "   'is_locked': True,\n",
       "   'is_shortform': False,\n",
       "   'top_highlight': \"Mastering an entire Python library like Pandas can be challenging for anyone. However, if we take a step back and think, do we really need to be aware of every minute detail of a specific library, especially when we live in a world governed by Pareto's Principle? For those who don't know, Pareto's Principle (also known as the 80–20 rule) says that 20% of your inputs will always contribute towards generating 80% of your outputs.\",\n",
       "   'content': {'id': 'a4ff1b694707',\n",
       "    'content': '20% of Pandas Functions that Data Scientists Use 80% of the Time\\n\\nPutting Pareto’s Principle to work on the Pandas library\\n\\nPhoto by Austin Distel on Unsplash\\n\\nMastering an entire Python library like Pandas can be challenging for anyone. However, if we take a step back and think, do we really need to be aware of every minute detail of a specific library, especially when we live in a world governed by Pareto’s Principle? For those who don’t know, Pareto’s Principle (also known as the 80–20 rule) says that 20% of your inputs will always contribute towards generating 80% of your outputs.\\n\\nTherefore, this post is my attempt to apply the Pareto’s Principle to the Pandas library and introduce you to 20% of those specific Pandas functions you are likely to use 80% of your time working with DataFrames. The methods mentioned below are what I have found myself utilizing repeatedly in my day-to-day work and feel are necessary and sufficient to be acquainted with for anyone getting started with Pandas.\\n\\n1/n: Reading a CSV file:\\n\\nIf you want to read a CSV file in Pandas, use the pd.read_csv() method as demonstrated below:\\n\\nCode snippet for reading a CSV file (Image by author created using snappify.io)\\n\\nRead the documentation here.\\n\\n2/n: Saving a DataFrame to a CSV file:\\n\\nIf you want to save DataFrame to a CSV file, use the to_csv() method as demonstrated below:\\n\\nCode snippet for saving DataFrame to a CSV file (Image by author created using snappify.io)\\n\\nRead the documentation here.\\n\\n3/n: Creating a DataFrame from a list of lists:\\n\\nIf you want to create a DataFrame from a list of lists, use the pd.DataFrame() method as demonstrated below:\\n\\nCode snippet for creating a DataFrame from a list of lists (Image by author created using snappify.io)\\n\\nRead the documentation here.\\n\\n4/n: Creating a DataFrame from a dictionary:\\n\\nIf you want to create a DataFrame from a dictionary, use the pd.DataFrame() method as demonstrated below:\\n\\nCode snippet for creating a DataFrame from a dictionary (Image by author created using snappify.io)\\n\\nRead the documentation here.\\n\\n5/n: Merging DataFrames:\\n\\nMerge operation in DataFrames is the same as the JOIN operation in SQL. We use it to join two DataFrames on one or more columns. If you want to merge two DataFrames, use the pd.merge() method as demonstrated below:\\n\\nCode snippet for merging DataFrames (Image by author created using snappify.io)\\n\\nRead the documentation here.\\n\\n6/n: Sorting a DataFrame:\\n\\nIf you want to sort a DataFrame based on the values in a particular column, use the sort_values() method as demonstrated below:\\n\\nCode snippet for sorting a DataFrame (Image by author created using snappify.io)\\n\\nRead the documentation here.\\n\\n7/n: Concatenating DataFrames:\\n\\nIf you want to concatenate DataFrames, use the pd.concat() method as demonstrated below:\\n\\nCode snippet for concatenating DataFrames (Image by author created using snappify.io)\\n\\nRead the documentation here.\\n\\naxis = 1 stacks columns together.\\n\\naxis = 0 stacks rows together, provided column header match.\\n\\n8/n: Rename column name:\\n\\nIf you want to rename one or more columns in a DataFrame, use the rename() method as demonstrated below:\\n\\nCode snippet for renaming columns in a DataFrame (Image by author created using snappify.io)\\n\\nRead the documentation here.\\n\\n9/n: Add New Column:\\n\\nIf you want to add a new column to a DataFrame, you can use the usual assignment operation as demonstrated below:\\n\\nCode snippet for adding a new column to a DataFrame (Image by author created using snappify.io)\\n\\n10/n: Filter DataFrame based on condition:\\n\\nIf you want to filter rows from a DataFrame based on a condition, you can do so as shown below:\\n\\n\\n\\nCode snippet for filtering a DataFrame (Image by author created using snappify.io)\\n\\n11/n: Drop Column(s):\\n\\nIf you want to drop one or more columns from a DataFrame, use the drop() method as demonstrated below:\\n\\nCode snippet for dropping columns from a DataFrame (Image by author created using snappify.io)\\n\\nRead the documentation here.\\n\\n12/n: GroupBy:\\n\\nIf you want to perform an aggregation operation after grouping, use the groupby() method as demonstrated below:\\n\\nCode snippet for grouping a DataFrame (Image by author created using snappify.io)\\n\\nRead the documentation here.\\n\\n13/n: Unique Values in a column:\\n\\nIf you want to count or print the unique value in a column of a DataFrame, use the unique() or unique() method as demonstrated below:\\n\\nCode snippet for finding unique values in a DataFrame column (Image by author created using snappify.io)\\n\\nRead the documentation here.\\n\\n14/n: Fill NaN values:\\n\\nIf you want to replace NaN values in a column with some other value, use the fillna() method as demonstrated below:\\n\\nCode snippet for filling NaN values in a DataFrame (Image by author created using snappify.io)\\n\\nRead the documentation here.\\n\\n15/n: Apply Function on a column:\\n\\nIf you want to apply a function to a column, use the apply() method as demonstrated below:\\n\\nCode snippet for applying a function on a DataFrame (Image by author created using snappify.io)\\n\\nRead the documentation here.\\n\\n16/n: Remove Duplicates:\\n\\nIf you want to remove duplicate values, use the drop_duplicates() method as demonstrated below:\\n\\nCode snippet for removing duplicated from a DataFrame (Image by author created using snappify.io)\\n\\nRead the documentation here.\\n\\n17/n: Value Counts:\\n\\nIf you want to find the frequency of each value in a column, use the value_counts() method as demonstrated below:\\n\\nCode snippet for counting the frequency of values in a column (Image by author created using snappify.io)\\n\\n18/n: Size of a DataFrame:\\n\\nIf you want to find the size of a DataFrame, use the .shape attribute as demonstrated below:\\n\\n\\n\\nTo conclude, in this post, I covered some of the most commonly used functions/methods in Pandas to help you get started with this library. Though this post will be helpful for you to make you comfortable with the syntax, I would highly recommend creating a dummy DataFrame of your own and experimenting with it in a jupyter notebook.\\n\\nFurther, there is no better place than referencing the official Pandas documentation available here to acquire fundamental and practical knowledge of various methods in Pandas. Pandas official documentation provides a detailed explanation of each of the arguments accepted by a function along with a practical example, which in my opinion, is an excellent way to acquire Pandas expertise.\\n\\nThanks for reading. I hope this post was helpful.'}},\n",
       "  {'id': 'c0954c410f8f',\n",
       "   'title': 'Why I Stopped Dumping DataFrames to a CSV and Why You Should Too',\n",
       "   'subtitle': 'It’s time to say goodbye to pd.to_csv() and pd.read_csv()',\n",
       "   'author': '5d33decdf4c4',\n",
       "   'publication_id': '7f60cf5620c9',\n",
       "   'published_at': '2022-05-10 18:23:41',\n",
       "   'last_modified_at': '2022-05-12 13:02:50',\n",
       "   'tags': ['pandas', 'programming', 'csv', 'dataframes'],\n",
       "   'topics': ['data-science', 'programming'],\n",
       "   'claps': 1359,\n",
       "   'voters': 478,\n",
       "   'word_count': 761,\n",
       "   'responses_count': 27,\n",
       "   'reading_time': 3.571698113207547,\n",
       "   'url': 'https://towardsdatascience.com/why-i-stopped-dumping-dataframes-to-a-csv-and-why-you-should-too-c0954c410f8f',\n",
       "   'unique_slug': 'why-i-stopped-dumping-dataframes-to-a-csv-and-why-you-should-too-c0954c410f8f',\n",
       "   'image_url': 'https://miro.medium.com/0*UnRRF7CCQ91Uwk7t',\n",
       "   'lang': 'en',\n",
       "   'is_series': False,\n",
       "   'is_locked': True,\n",
       "   'is_shortform': False,\n",
       "   'top_highlight': 'In my opinion, both Parquet and Feather are the best available file formats out there to choose from the six we have explored in this post.',\n",
       "   'content': {'id': 'c0954c410f8f',\n",
       "    'content': 'Why I Stopped Dumping DataFrames to a CSV and Why You Should Too\\n\\nIt’s time to say goodbye to pd.to_csv() and pd.read_csv()\\n\\nPhoto by Mika Baumeister on Unsplash\\n\\nBuilding an end-to-end data-driven pipeline is challenging and demanding. Having been there myself, the process is extremely tedious, and one may inevitably end up with numerous intermediate files. While these files are usually meant to serve as checkpoints or assist further modules in the pipeline, one might be unknowingly compromising the run-time and lifting storage requirements by not choosing the appropriate format for these intermediate files - the first preference for which is always a CSV.\\n\\nBeing a Data Scientist myself, I understand that a CSV provides enormous flexibility in data reading, writing, previewing, exploring, etc. It’s the go-to format for you, me, and almost everyone working with DataFrames. More often than not, I used to leverage the CSV format too to export a DataFrame UNTIL much recently when I discovered a few time-efficient and storage-optimized alternatives to a CSV.\\n\\nFortunately, Pandas offers a variety of file formats you can save your DataFrames to, such as:\\n\\nCSV\\n\\nPickle\\n\\nParquet\\n\\nFeather\\n\\nJSON\\n\\nHDF5\\n\\nThis enticed me to rank the above-mentioned formats based on their experiential performance on the following parameters:\\n\\nThe space they occupy on disk.\\n\\nThe time they take for read and write operations to disk.\\n\\nExperimental Setup\\n\\nFor experimentation purposes, I generated a random dataset in Python with a million rows and thirty columns - encompassing string, float and integer data types.\\n\\nI repeated each experiment described below ten times to reduce randomness and draw fair conclusions from the observed results. The statistics below are averages across the ten experiments.\\n\\nExperiments\\n\\nExperiment 1: Space Utilised on Disk after saving\\n\\nMemory Utilisation for file formats (Image by author)\\n\\nClearly, HDF5 should not be your first choice if you are looking for a memory-optimized format. Here, the disk space utilized is more than double the following best format visible in the above bar chart - JSON, which itself is close to double the size of the other four formats.\\n\\nSo far, Parquet, CSV, Feather, and Pickle appear appropriate options for storing our DataFrame because all of them block roughly the same portion of your secondary storage for the same amount of data.\\n\\nExperiment 2: Time taken to load and save\\n\\nTime taken to load and save DataFrame in respective formats. (Image by author)\\n\\nThis is where we start noticing the downsides of using a CSV format.\\n\\nLet’s consider the load time alone for now. The time elapsed to read a CSV is almost three times that of the best available alternative here - pickle. Moreover, as we saw earlier, Pickle and CSV take up the same amount of space, so why choose the slower option?\\n\\nRegarding saving time, CSV is the most expensive option to choose from - consuming close to eight times that of Feather.\\n\\nApparently, while storing your DataFrame to a particular format, you are bound to use the same format again while loading. In other words, once you have stored your DataFrame as a pickle, you have no choice but to read it as a pickle file as well. Therefore, in the third bar chart above, we look at their total efficiency, i.e., load time + save time.\\n\\nSadly enough, CSV isn’t the best choice we have got.\\n\\nCompared to Feather, Parquet and Pickle, a CSV is on an average 2.5 times slower than these formats, which is insanely high.\\n\\nIn my opinion, both Parquet and Feather are the best available file formats out there to choose from the six we have explored in this post.\\n\\nConcluding Notes\\n\\nI know CSVs are great. I love them too, and I am a fan of CSVs for countless reasons, such as:\\n\\nIf needed, CSV allows me to read only a subset of columns, saving RAM and reading time.\\n\\nCSV is essentially a text file. Therefore, Pandas allows me to view top-n (say 5, 10, 15, etc.) rows present in the CSV.\\n\\nExcel is one of my favorite tools, and I can open a CSV directly in Excel.\\n\\nHowever, CSV is killing your pipeline. It actually is. You are spending an enormous amount of time in reading and writing operations just because of having CSVs all over the place.\\n\\nUnless you need to view your DataFrame outside a non-pythonic environment such as Excel, YOU DON’T NEED A CSV AT ALL. You should prefer Parquet, Feather or Pickle because, as we observed above, they provide significantly faster read and write operations than a CSV.\\n\\nSo next time when you are about to execute pd.to_csv(), think if you actually need a CSV.\\n\\nImage by author created using memegenerator.net'}},\n",
       "  {'id': 'fb0c1f1f2972',\n",
       "   'title': 'Introducing IceCream: Never Use Print() To Debug Your Python Code Again',\n",
       "   'subtitle': 'Why I stopped using print() statements for debugging and why you should too',\n",
       "   'author': '5d33decdf4c4',\n",
       "   'publication_id': '32881626c9c9',\n",
       "   'published_at': '2024-01-29 07:24:23',\n",
       "   'last_modified_at': '2024-01-29 10:21:50',\n",
       "   'tags': ['data-science',\n",
       "    'machine-learning',\n",
       "    'artificial-intelligence',\n",
       "    'python',\n",
       "    'programming'],\n",
       "   'topics': ['programming'],\n",
       "   'claps': 556,\n",
       "   'voters': 84,\n",
       "   'word_count': 893,\n",
       "   'responses_count': 6,\n",
       "   'reading_time': 4.069811320754717,\n",
       "   'url': 'https://medium.datadriveninvestor.com/introducing-icecream-never-use-print-to-debug-your-python-code-again-fb0c1f1f2972',\n",
       "   'unique_slug': 'introducing-icecream-never-use-print-to-debug-your-python-code-again-fb0c1f1f2972',\n",
       "   'image_url': 'https://miro.medium.com/0*2n51QKEzXu0iKtBK',\n",
       "   'lang': 'en',\n",
       "   'is_series': False,\n",
       "   'is_locked': True,\n",
       "   'is_shortform': False,\n",
       "   'top_highlight': '',\n",
       "   'content': {'id': 'fb0c1f1f2972',\n",
       "    'content': 'Introducing IceCream: Never Use Print() To Debug Your Python Code Again\\n\\nWhy I stopped using print() statements for debugging and why you should too\\n\\nPhoto by bryn beatson on Unsplash\\n\\nFind the code for this article here.\\n\\nMotivation\\n\\nErrors are almost inevitable while programming. In fact, it is rightly said that a programmer spends a significant amount of their time debugging to make their code error-free.\\n\\nWhile debugging, using print() statements to understand the flow of the pipeline and spot unexpected behavior is undoubtedly the most widely adopted approach.\\n\\nHowever, using print() has numerous caveats, such as:\\n\\nPrint statements are usually intended to display an output to the user. If the programmer uses print() to debug, after debugging is over, the programmer should be cautious of removing only those specific print() statements that were intended for debugging.\\n\\nOften, during debugging, you may print multiple variables one after the other. In such cases, the programmer has to manually format the output to enhance its readability.\\n\\n\\n\\nAbove, we print two variables. Although here we know that the first variable is var_1 and the second is var_2, as the number of variables increases, it might require you to look back and forth between the code and the output to figure out which output corresponds to which variable.\\n\\nOf course, we can print more details, like below, but that just adds to your work.\\n\\n\\n\\nSometimes, the programmer might also be interested in printing the line number, the name of the function and its input, etc., which adds to the complexity of writing long/many print() statements.\\n\\nIn most situations, the codebase is not restricted to just one file. Instead, there are multiple files that form the pipeline. In such cases, one may be interested in displaying the name of the file as well during debugging, which can be a hassle with print().\\n\\nThe above reasons make print(), at least for me, the worst option for debugging.\\n\\nThankfully, there is an excellent alternative in Python.\\n\\nIntroducing IceCream 🍦!\\n\\nIceCream\\n\\nIceCream is a Python library that makes debugging effortless and readable with minimal code.\\n\\nIts popular features include printing expressions, variable names, function names, line numbers, filenames, and many more - which we will discuss in this blog.\\n\\nInstalling IceCream\\n\\nYou can install the icecream library using pip.\\n\\n\\n\\nImport IceCream\\n\\nThe standard convention for using this library is to import the ic module as follows:\\n\\n\\n\\nGetting Started With IceCream\\n\\nUsing the IceCream library is as simple as the print statement. You need to replace print() with ic(). That’s it.\\n\\n\\n\\nNotice the difference! ic() prints not only the value but also the name of the variable passed.\\n\\nIceCream is not just restricted to a variable. Rather, you can use it on functions, classes, etc.\\n\\n\\n\\nHow cool! It prints the name of the method (func), the argument passed (3) and the output (6).\\n\\nEvery expression that goes in the ic() method gets printed along with the value of the expression, as illustrated below.\\n\\nIcecream prints the expression and its value both (Image by author)\\n\\nDebugging with IceCream can be applied to the common Python data structures as well. An example of a Python dictionary is shown below.\\n\\n\\n\\nInspecting Execution\\n\\nMany-a-times, programmers use print() to display meaningful (or sometimes random) statements to determine the flow of the program. This is shown below:\\n\\n\\n\\nIceCream lets you get rid of those bizarre statements too.\\n\\n\\n\\nJust call ic() and you\\'re done. It will print the file name, line number, and other details (like function name, if any) and the time. Simple.\\n\\nUsing IceCream Project Wide\\n\\nNext, you might wonder that does one need to import the library in every python file? Of course not!\\n\\nTo make the methods available in all project files, import the install module from icecream in the root file, as shown below:\\n\\n\\n\\n\\n\\nWith install, ic() gets available project-wide.\\n\\nAdding a Custom Prefix\\n\\nIf you noticed above, the output of the ic() statements begin with \"ic|\". That’s the default prefix IceCream provides.\\n\\nHowever, if for some reason, you wish to replace that with a custom prefix, you can do that too. This is done by specifying the prefix argument in the ic.configureOutput() method as shown below:\\n\\n\\n\\nDeleting IceCream Statements After Debugging\\n\\nOnce you have debugged your code, you may want to remove all the unnecessary debugging statements.\\n\\nAs ic() statements are syntactically different from print(), you can search for the pattern \"ic(\" in your editor and remove the statements, as shown below:\\n\\nRemoving ic() statements from code (Gif by author)\\n\\nAlternatively, you can use ic.disable() to stop ic() from printing. If you wish to use them again, use ic.enable().\\n\\nConclusion\\n\\nDebugging with print() statements is a messy and inelegant approach. It is confusing to map the output to its corresponding debug statement. Moreover, it requires extra manual formatting to comprehend the output.\\n\\nAs discussed above, the IceCream library in Python is an excellent alternative to this. It makes debugging effortless and readable, with minimal code.\\n\\nRead more about IceCream here.\\n\\nThanks for reading!\\n\\n🚀 Get a Free Data Science PDF (550+ pages) with 320+ posts by subscribing to my daily newsletter today:\\n\\n\\n\\nVisit us at DataDrivenInvestor.com\\n\\nSubscribe to DDIntel here.\\n\\nHave a unique story to share? Submit to DDIntel here.\\n\\nJoin our creator ecosystem here.\\n\\nDDIntel captures the more notable pieces from our main site and our popular DDI Medium publication. Check us out for more insightful work from our community.\\n\\nDDI Official Telegram Channel: https://t.me/+tafUp6ecEys4YjQ1\\n\\nFollow us on LinkedIn, Twitter, YouTube, and Facebook.'}},\n",
       "  {'id': '5edf898909e7',\n",
       "   'title': 'Introducing Pandarallel: Never Use The Apply Method In Pandas Again',\n",
       "   'subtitle': 'Why I stopped using Apply() in Pandas and why you should too.',\n",
       "   'author': '5d33decdf4c4',\n",
       "   'publication_id': '32881626c9c9',\n",
       "   'published_at': '2024-01-24 10:59:56',\n",
       "   'last_modified_at': '2024-02-01 10:26:40',\n",
       "   'tags': ['data-science',\n",
       "    'machine-learning',\n",
       "    'pandas',\n",
       "    'python',\n",
       "    'artificial-intelligence'],\n",
       "   'topics': ['data-science', 'programming'],\n",
       "   'claps': 352,\n",
       "   'voters': 67,\n",
       "   'word_count': 809,\n",
       "   'responses_count': 3,\n",
       "   'reading_time': 4.1028301886792455,\n",
       "   'url': 'https://medium.datadriveninvestor.com/introducing-pandarallel-never-use-the-apply-method-in-pandas-again-5edf898909e7',\n",
       "   'unique_slug': 'introducing-pandarallel-never-use-the-apply-method-in-pandas-again-5edf898909e7',\n",
       "   'image_url': 'https://miro.medium.com/0*bR4akeZyYmtpC98C',\n",
       "   'lang': 'en',\n",
       "   'is_series': False,\n",
       "   'is_locked': True,\n",
       "   'is_shortform': False,\n",
       "   'top_highlight': '',\n",
       "   'content': {'id': '5edf898909e7',\n",
       "    'content': 'Introducing Pandarallel: Never Use The Apply Method In Pandas Again\\n\\nWhy I stopped using Apply() in Pandas and why you should too.\\n\\nPhoto by Alain Pham on Unsplash\\n\\nYou can find the code for this article here.\\n\\nThe Pandas library, with its intuitive, elegant, and beginner-friendly API, serves as one of the best tabular data-wrangling libraries in Python.\\n\\nAlmost every data scientist today working with tabular datasets resorts to Pandas for all sorts of data science tasks.\\n\\nWhile the API offers a sleek design and a wide range of functionalities, there are numerous limitations that make Pandas inapplicable (or inefficient) in a handful of data-driven situations.\\n\\nI have talked about five such concerning limitations in the following blog:\\n\\n5 Things I Wish the Pandas Library Could Do\\nDiscussing five subtle limitations of Pandastowardsdatascience.com\\n\\nTo summarize, almost all limitations of Pandas arise from its single-core computational framework.\\n\\nIn other words, even if your CPU has multiple cores available (or idle), Pandas always relies on a single core, which inhibits its performance.\\n\\nPandas’ single-core computational framework (Image by Author)\\n\\nOne might wonder when we can start seeing these updates in Pandas. But honestly speaking, we have no clue as there isn’t any official update from Pandas.\\n\\nCurrently, the harsh reality is that most users utilize Pandas as it is, i.e., inefficiently.\\n\\nThankfully, many developers outside Pandas have taken up this issue over the past few years.\\n\\nAs a result, we have a handful of tools at our disposal today that let us exploit multiple cores with Pandas, making it more efficient.\\n\\nOne such tool that I will discuss in this post is Pandarallel!\\n\\nLet’s begin 🚀!\\n\\nIntroducing Pandarallel (Pandas + Parallel)\\n\\nPandarallel is an open-source python library that allows you to parallelize Pandas’ operations to all available CPU cores. This can be achieved by changing just one line of code.\\n\\nPandarallel’s multi-core computational framework (Image by Author)\\n\\nAdditionally, pandarallel also provides cool progress bars (like we get with tqdm) to estimate the remaining amount of computation.\\n\\nThe contemporarily supported methods include apply(), applymap(), groupby(), map() and rolling().\\n\\nInstalling Pandarallel\\n\\nYou can install Pandarallel with pip, using the following command:\\n\\n\\n\\nImporting Pandarallel\\n\\nThe next step is to import the library and initialize it:\\n\\n\\n\\nAs seen in the output, initialize() sets the number of workers to execute our job, 4 in this case.\\n\\nYou can read more about initialization here.\\n\\nAlongside, you should also import the Pandas library.\\n\\n\\n\\nPandas to Pandarallel\\n\\nAs mentioned above, the transition from Pandas to Pandarallel is straightforward and requires changing just one line of code.\\n\\nA few of these are illustrated below:\\n\\nPandas Operations to Pandarallel (Image by Author). Read more: https://nalepae.github.io/pandarallel/\\n\\nThe crux is to replace apply with parallel_apply and map with parallel_map.\\n\\nExperiment\\n\\nNext, let’s compare the performance of Pandas’ apply() and Pandarallel’s parallel_apply().\\n\\nApply() vs Parallel_apply() (Image by Author)\\n\\nAs Pandarallel utilizes all available cores, ideally, we should expect the latter to perform better than the former.\\n\\nLet’s find out if that is True.\\n\\nExperimental Setup\\n\\nIn this experiment, I created a dummy DataFrame with variable rows and five columns.\\n\\nMore specifically, I varied the number of rows from 1 Million to 10 Million and plotted the performance of the apply() and parallel_apply().\\n\\nThe function in this experiment is defined below, which returns the sum of a row:\\n\\n\\n\\nTo eliminate any randomness, I repeated the experiment with a specific number of rows ten times.\\n\\nThe code for this experiment is shown below:\\n\\n\\n\\nResults\\n\\nNext, let’s look at the results.\\n\\nExperimental results of Apply() vs Parallel_apply() (Image by Author)\\n\\nThe blue line-plot depicts the run-time of the apply() method, and the yellow line-plot represents the run-time of the parallel_apply() method.\\n\\nWe vary the number of rows from 1 million to 10 Million and notice that the run-time of both methods is positively correlated with the number of rows.\\n\\nHowever, the parallel_apply() method provides significant improvement in the run-time over the traditional apply() method.\\n\\nAs the number of rows increases, so does the difference between the run-time of both methods. This indicates that you should always use parallel_apply() to apply a function to a DataFrame, especially in the case of larger datasets.\\n\\nConclusion\\n\\nTo conclude, in this post, we compared the performance of the Pandas’ apply() to Pandarallel’s parallel_apply() method on a set of dummy DataFrames.\\n\\nExperimental results suggest that using the parallel_apply() method is efficient in terms of run-time over the apply() method - providing a performance boost of up to 4 to 5 times.\\n\\nYou can find the code for this article here.\\n\\nThanks for reading!\\n\\n🚀 Get a Free Data Science PDF (550+ pages) with 320+ posts by subscribing to my daily newsletter today:\\n\\n\\n\\nVisit us at DataDrivenInvestor.com\\n\\nSubscribe to DDIntel here.\\n\\nHave a unique story to share? Submit to DDIntel here.\\n\\nJoin our creator ecosystem here.\\n\\nDDIntel captures the more notable pieces from our main site and our popular DDI Medium publication. Check us out for more insightful work from our community.\\n\\nDDI Official Telegram Channel: https://t.me/+tafUp6ecEys4YjQ1\\n\\nFollow us on LinkedIn, Twitter, YouTube, and Facebook.'}},\n",
       "  {'id': 'ddbf9b5039a1',\n",
       "   'title': '5 Things I Wish the Pandas Library Could Do',\n",
       "   'subtitle': 'Discussing five subtle limitations of Pandas',\n",
       "   'author': '5d33decdf4c4',\n",
       "   'publication_id': '32881626c9c9',\n",
       "   'published_at': '2024-01-24 10:59:47',\n",
       "   'last_modified_at': '2024-02-13 05:38:21',\n",
       "   'tags': ['data-science',\n",
       "    'machine-learning',\n",
       "    'sql',\n",
       "    'python',\n",
       "    'artificial-intelligence'],\n",
       "   'topics': ['data-science', 'programming'],\n",
       "   'claps': 313,\n",
       "   'voters': 25,\n",
       "   'word_count': 1804,\n",
       "   'responses_count': 3,\n",
       "   'reading_time': 7.857547169811321,\n",
       "   'url': 'https://medium.datadriveninvestor.com/5-things-i-wish-the-pandas-library-could-do-ddbf9b5039a1',\n",
       "   'unique_slug': '5-things-i-wish-the-pandas-library-could-do-ddbf9b5039a1',\n",
       "   'image_url': 'https://miro.medium.com/0*V4eRjCCJ3g1OaYU3',\n",
       "   'lang': 'en',\n",
       "   'is_series': False,\n",
       "   'is_locked': True,\n",
       "   'is_shortform': False,\n",
       "   'top_highlight': '',\n",
       "   'content': {'id': 'ddbf9b5039a1',\n",
       "    'content': '5 Things I Wish the Pandas Library Could Do\\n\\nDiscussing five subtle limitations of Pandas\\n\\nPhoto by Georg Bommeli on Unsplash\\n\\nFind the code for this article here.\\n\\nThanks to the Pandas library, handling, analyzing, and processing tabular data in Python has never been as effortless and straightforward as it is today.\\n\\nContemporarily, the Pandas API provides an extensive collection of functionalities to manage tabular data, intending to serve almost every data science project, such as:\\n\\nInput and Output operations\\n\\nData Filtering\\n\\nTable Joins\\n\\nData visualization\\n\\nDuplicate data handling, and many more, which you can read here.\\n\\nWhile Pandas is indeed the go-to tool for almost all data scientists working with tabular data, leveraging it in my projects has made me realize some of its major caveats/limitations, which I wish to discuss in this post.\\n\\nTherefore, this post presents five things I wish Pandas was capable of doing in the realm of real-world tabular datasets.\\n\\nThe highlight of this article is as follows:\\n\\n#1 I wish Pandas could read a CSV file parallelly\\n#2 I wish Pandas could read multiple CSV files at once\\n#3 I wish Pandas DataFrames utilized less memory\\n#4 I wish Pandas could be used for large datasets\\n#5 I wish Pandas supported conditional joins like SQL (somehow)\\n\\nLet’s begin 🚀!\\n\\n#1 I wish Pandas could read a CSV file parallelly\\n\\nUnfortunately, the input-output operations with Pandas from/to a CSV file are serialized, meaning there’s no inherent multi-threading support available in Pandas.\\n\\nFor starters, serialization in the context of reading CSV files means that Pandas reads data only one row (or line) of a CSV at a time. This is illustrated in the animation below:\\n\\nReading a CSV in Pandas (GIF by author) Note: A CSV file is a text file, and the above illustration is not how a CSV looks. This is to elaborate the point intuitively.\\n\\nSimilar to the input operation, the output operation is no better. Pandas stores a DataFrame to a CSV file in a serialized fashion as well.\\n\\nThe process of serialized input and output operations makes it incredibly inefficient and time-consuming.\\n\\nPossible Alternative(s)\\n\\nAs per my exploration, there are two potential solutions one may take to improve the overall input-output run-time.\\n\\nPrefer using other file formats like Pickle, Parquet, and Feather to read from and store DataFrames to.\\n\\nIn addition to being fast, these formats also consume lesser memory on disk to store the data. Read more about these file formats in my blog below:\\n\\nWhy I Stopped Dumping DataFrames to a CSV and Why You Should Too\\nIt’s time to say goodbye to pd.to_csv() and pd.read_csv()towardsdatascience.com\\n\\nUse libraries like DataTable, which, unlike Pandas, possess parallelization capabilities.\\n\\nRead more about DataTable in my blog below:\\n\\nIt’s Time to Say GoodBye to pd.read_csv() and pd.to_csv()\\nDiscussing another major caveat of Pandastowardsdatascience.com\\n\\n#2 I wish Pandas could read multiple CSV files at once\\n\\nImagine you have a folder with multiple CSV files which you need to read and import as a Pandas DataFrame.\\n\\nThe one and the only way to achieve this in Pandas is by iterating over the list of files and reading them one after the other, as shown below:\\n\\nReading multiple CSV files using Pandas (GIF by author)\\n\\nThe above illustration can be programmatically demonstrated as follows:\\n\\n\\n\\nDue to the absence of multi-threading support in Pandas, a set of files that could be potentially read in parallel should be read one by one, resulting in increased run-time and resource underutilization.\\n\\nPossible Alternative(s)\\n\\nThe DataTable library again stands as a great alternative to Pandas to address this limitation.\\n\\nWith DataTable, you can read multiple CSV files efficiently. This is demonstrated below:\\n\\n\\n\\nRead more about the run-time performance in my blog below:\\n\\nHow To Read Multiple CSV Files Non-Iteratively (and Without Pandas)\\nSay no to Pandas’ Read CSV method!towardsdatascience.com\\n\\n#3 I wish Pandas DataFrames utilized less memory\\n\\nPandas DataFrames are incredibly bulky and memory-inefficient to work with. For instance, consider that we create a DataFrame comprising of two columns as shown below:\\n\\n\\n\\nNext, let’s determine the datatypes assigned by Pandas to the two columns of the above DataFrame df using the dtypes attribute:\\n\\n\\n\\nBy default, Pandas always assigns the highest memory datatype to columns. For instance, once Pandas interpreted colA above as an integer-valued, there were four possible sub-categories (signed) to choose from:\\n\\nint8: 8-bit-integer datatype spanning integers from [-2⁷, 2⁷].\\n\\nint16: 16-bit-integer datatype spanning integers from [-2¹⁵, 2¹⁵].\\n\\nint32: 32-bit-integer datatype spanning integers from [-2³¹, 2³¹].\\n\\nint64: 64-bit-integer datatype spanning integers from [-2⁶³, 2⁶³].\\n\\nHowever, Pandas assigned int64 as the datatype of the integer-valued column, irrespective of the range of current values in the column. We notice a similar datatype behavior with colB.\\n\\nPossible Alternative(s)\\n\\nTo optimize memory utilization, there is one direction that you can possibly explore, which I call the min-max-reduce analysis.\\n\\nThe first step is to find the minimum and maximum values in the column of interest.\\n\\n\\n\\nThe final step is to abridge (reduce) the column’s datatype.\\n\\nAs the current range of values can be squeezed into the int16 datatype (because -2¹⁵< 10000 (min)< 30000 (max) <2¹⁵), we will transform the datatype from int64 to int16 using the astype() method as demonstrated below:\\n\\n\\n\\nThe total memory utilized by the colA column dropped by approximately 40% with this simple one-line datatype transformation.\\n\\nWith a similar min-max-reduce analysis, you can also alter the datatype of other integer and float valued columns.\\n\\nRead more about the memory optimization techniques in my blog below:\\n\\nSeven Killer Memory Optimization Techniques Every Pandas User Should Know\\nSimple tips to optimize the memory utilization in Pandastowardsdatascience.com\\n\\n#4 I wish Pandas could be used for large datasets\\n\\nAs discussed above, there is no inherent multi-threading support available in Pandas. As a result, irrespective of the scale of the data, Pandas will always stick to a single core utilization - leading to increased run-time, which is proportional to the size of the data.\\n\\nDoge meme by the author (created using imgflip.com)\\n\\nFor instance, consider an experiment to study the correlation between DataFrame size and the run-time to execute a function on the DataFrame.\\n\\nWe start with a random DataFrame comprising a thousand rows and two columns.\\n\\n\\n\\nNext, we define a function that takes a row of the DataFrame and returns its sum. This function is implemented below:\\n\\n\\n\\nAt every iteration, we determine the time to compute the sum of every row of the DataFrame. To eliminate randomness, we shall repeat each iteration runs times. At the end of each iteration, we shall increase the size of the DataFrame two folds.\\n\\nThe experiment is implemented below:\\n\\n\\n\\nThe plot below depicts the iteration vs run-time graph. With each iteration, the size of the DataFrame doubles, and so does the Pandas run-time - indicating that the Pandas’ run-time is always proportional to the size of the DataFrame and it never adopts parallelization.\\n\\nDataFrame vs Run-time graph (Image by Author)\\n\\nPossible Alternative(s)\\n\\nPandas is extremely good to work with on small datasets. However, as the scale of the data and the complexity of the pipeline increases, you as a Data Scientist should refrain from leveraging it due to its profound run-time caveats discussed above.\\n\\nIf your objective is to take the project to production, PySpark is the ideal way to proceed. Other alternatives include Terality, Vaex, DataTable, and Dask - recommended mostly for local computation over Pandas on large datasets.\\n\\n#5 I wish Pandas supported conditional joins like SQL (somehow)\\n\\nPeople working with SQL relish the freedom of writing complex join conditions to merge tables, don’t they?\\n\\nAs the name suggests, conditional joins go beyond the simple equality-based merge conditions. In other words, you can establish joins based on conditions other than equality between fields from multiple tables.\\n\\nFor instance, consider you have two tables, table1 and table2:\\n\\n\\n\\nThe objective is to join these tables based on the following condition\\n\\n(table1.col1 = table2.col1 + 2) and (table2.col2 >= table2.col2 - 2) and (table2.col2 <= table2.col2 + 2)\\n\\nSQL Join\\n\\nThe above conditional join is extremely simple to work with in SQL. The SQL query is implemented below, generating the output following the query:\\n\\n\\n\\n\\n\\nPandas Join\\n\\nPandas can only perform equality-based joins on DataFrames. In other words, the Pandas merge() method will join two records only when the values in the join column are identical - eliminating the scope of conditional joins.\\n\\nTherefore, a few ways to perform conditional join using the Pandas’ merge() method are:\\n\\nCreate the join column using operations defined in the join condition and execute the merge on the new column.\\n\\nPerform a cross join and filter the DataFrame. This can be extremely challenging in the case of large datasets.\\n\\nA mix of Approach 1 and Approach 2 is demonstrated below.\\n\\nFirst, we create two DataFrames to merge and define the join condition.\\n\\n\\n\\n(table1.col1 = table2.col3 + 2) and (table2.col2 >= table2.col4 - 2) and (table2.col2 <= table2.col4 + 2)\\n\\nAs the join condition consists of inequalities, let’s keep them aside for a while and perform a join first on equalities (table1.col1 = table2.col3 + 2). After that, we’ll filter the results to incorporate the next two conditions.\\n\\nFirst, we shall create a new column in table2. Let’s call it col3_1.\\n\\n\\n\\nNext, we will perform the join on col1 from table1 and col3_1 from table2, and then filter the obtained records based on the leftover conditions from the join condition. This is implemented below:\\n\\n\\n\\nPossible Alternative(s)\\n\\nPandaSQL is a popular python package that provides a blend of both Pandas and SQL, allowing you to leverage the power of SQL syntax in a pythonic environment.\\n\\nAs a result, PandaSQL empowers you to query pandas DataFrames using SQL syntax. To execute SQL-like joins, you can explore PandaSQL.\\n\\nHowever, the ease of using SQL with Pandas DataFrames comes at the cost of the run-time. I have discussed this in my previous blog post below:\\n\\nIntroduction to PandaSQL: The Downsides No One Talks About\\nPandas + SQL = PandaSQL = A big messtowardsdatascience.com\\n\\nConclusion\\n\\nTo conclude, in this post, I discussed five major limitations of Pandas and their workarounds if you are stuck in any of these situations.\\n\\nPandas is incredible to work with day-to-day tabular data analysis, management, and processing.\\n\\nHowever, suppose you are moving towards developing a production-level solution or having large amounts of data to deal with. In that case, Pandas won’t be of much help to you due to its no parallelization and resource underutilization limitations.\\n\\nThanks for reading!\\n\\n🚀 Get a Free Data Science PDF (550+ pages) with 320+ posts by subscribing to my daily newsletter today:\\n\\n\\n\\nMeme by the author (created using imgflip.com)\\n\\nVisit us at DataDrivenInvestor.com\\n\\nSubscribe to DDIntel here.\\n\\nHave a unique story to share? Submit to DDIntel here.\\n\\nJoin our creator ecosystem here.\\n\\nDDIntel captures the more notable pieces from our main site and our popular DDI Medium publication. Check us out for more insightful work from our community.\\n\\nDDI Official Telegram Channel: https://t.me/+tafUp6ecEys4YjQ1\\n\\nFollow us on LinkedIn, Twitter, YouTube, and Facebook.'}},\n",
       "  {'id': '620a84c14408',\n",
       "   'title': 'Powerful One-liners in Pandas Every Data Scientist Should Know',\n",
       "   'subtitle': 'Things you can do in one line using Pandas',\n",
       "   'author': '5d33decdf4c4',\n",
       "   'publication_id': '32881626c9c9',\n",
       "   'published_at': '2024-01-17 03:02:19',\n",
       "   'last_modified_at': '2024-01-17 03:09:18',\n",
       "   'tags': ['data-science',\n",
       "    'machine-learning',\n",
       "    'python',\n",
       "    'pandas',\n",
       "    'artificial-intelligence'],\n",
       "   'topics': ['data-science', 'programming'],\n",
       "   'claps': 448,\n",
       "   'voters': 86,\n",
       "   'word_count': 1542,\n",
       "   'responses_count': 5,\n",
       "   'reading_time': 7.418867924528302,\n",
       "   'url': 'https://medium.datadriveninvestor.com/powerful-one-liners-in-pandas-every-data-scientist-should-know-620a84c14408',\n",
       "   'unique_slug': 'powerful-one-liners-in-pandas-every-data-scientist-should-know-620a84c14408',\n",
       "   'image_url': 'https://miro.medium.com/0*npy63uZkFgDYzici',\n",
       "   'lang': 'en',\n",
       "   'is_series': False,\n",
       "   'is_locked': True,\n",
       "   'is_shortform': False,\n",
       "   'top_highlight': '',\n",
       "   'content': {'id': '620a84c14408',\n",
       "    'content': 'Powerful One-liners in Pandas Every Data Scientist Should Know\\n\\nThings you can do in one line using Pandas\\n\\nPhoto by KirstenMarie on Unsplash\\n\\nFind the code for this article here.\\n\\nTraining data-driven machine learning models has never been as easy as today. For instance, assume you are training a vanilla neural network. Here, adjusting the architecture for the number of hidden layers and their dimension, tweaking the hyperparameters, or changing the loss function can all be done with a slight modification in the model definition or its optimizer.\\n\\nWhile on one hand, this is advantageous as it reduces the heavy lifting of spending time designing architectures from scratch. However, this has often led machine learning practitioners/researchers to neglect the importance of data visualizations and analysis - leading them to train deep models directly without establishing a clear understanding of their data.\\n\\nTherefore, in this post, I would like to introduce you to a handful of essential and powerful one-liners specifically for tabular data using Pandas that will help you better understand your data and consequently (and hopefully) help you design and build better machine learning models.\\n\\nDataset\\n\\nFor this post, I will experiment with a dummy dataset of one thousand Employees which I created myself in Python. The image below gives an overview of the dataset we are experimenting with.\\n\\nFirst five rows of the DataFrame (Image by author)\\n\\nThe code block below demonstrates my implementation:\\n\\n\\n\\nOne-liners in Pandas\\n\\nNext, let’s discuss some popular functions available in Pandas to make a meaningful understanding of the available data.\\n\\n#1 n-largest values in a series\\n\\nSay we want to start off by finding the top-n paid roles in this dataset. You can do this using the nlargest() method in Pandas. This method returns the first n rows with the largest values in column(s), ordered in descending order.\\n\\nNote that nlargest() returns the entire DataFrame, i.e., the function also returns the columns not specified for ordering. However, they are not used to order the DataFrame. The code snippet below depicts the use of nlargest() method on our DataFrame.\\n\\n\\n\\nThe output of the nlargest method (Image by Author)\\n\\nWhen duplicate values exist, we need to specify which particular row(s) we want in the final output. This is done using the keep argument that can take the following values:\\n\\nkeep = \"first\": prioritizes the first occurrence.\\n\\nkeep = \"last\": prioritizes the last occurrence.\\n\\nkeep = \"all\": Does not drop any duplicates, even if it means selecting more than n items (like in the image above).\\n\\nIt is often mistaken that the nlargest()is precisely equivalent to using the sort_values()method as follows:\\n\\n\\n\\nOutput of sort_values method (Image by Author)\\n\\nHowever, the keepargument used in nlargest() makes all the difference. Considering the example above, nlargest() with keep=\"all\"returns potential duplicates as well. This, on the other hand, can not be done in the case of sort_values() method.\\n\\n#2 n-smallest values in a series\\n\\nSimilar to the nlargest() method discussed above, you can find the rows corresponding to the lowest-n values using the nsmallest() method in Pandas. This method returns the first n rows with the smallest values in column(s), arranged in ascending order. The arguments passed here are the same as those specified in the nlargest() method. The code snippet below depicts the use of nsmallest() method on our DataFrame.\\n\\n\\n\\nThe output of the nsmallest method (Image by Author)\\n\\n#3 CrossTabs\\n\\nCrosstab allows you to compute a cross-tabulation of two (or more) columns/series and returns a frequency of each combination by default. In other words, crosstab() takes one column/list, displays its unique values as indexes, and then takes another column/list and displays its unique values as the column headers. The values in the individual cells are computed using an aggregation function. By default, they indicate the co-occurrence frequency.\\n\\nSay, for instance, we wish to compute the number of employees working from each location within every company. This can be done as follows:\\n\\n\\n\\nThe output of Crosstab to compute the frequency of co-occurrence (Image by Author)\\n\\nAs it can be hard to interpret numerical values in a crosstab (and to make it more visually appealing), we can generate a heatmap from a crosstab shown below as follows:\\n\\n\\n\\nHeatmap depicting the co-occurrence dataframe (Image by author)\\n\\nIf you wish to compute aggregation on some column other than the ones that make up the indexes and the column headers, you can do so by passing the aggregation column to values argument of crosstab()as shown below:\\n\\n\\n\\nHeatmap depicting the average salary (Image by author)\\n\\n#4 Pivot Table\\n\\nPivot tables are a commonly used data analysis tool in Excel. Similar to crosstabs discussed above, pivot tables in Pandas provide a way to cross-tabulate your data.\\n\\nAlthough they both share numerous similarities and are conceptually the same in the context of Pandas, there are a few implementational differences that make them different (further reading here). The code snippet below demonstrates the use of pivot_table() method to find the frequency of co-occurrence between the \"Company Name\" and \"Location\":\\n\\n\\n\\nThe output of the pivot table to compute the frequency of co-occurrence (Image by Author)\\n\\nSimilar to what we did in Crosstab, we can create a heatmap to make it visually appealing as well as more interpretable. This can be done as shown in the code snippet to generate the following heatmap:\\n\\n\\n\\nHeatmap depicting the co-occurrence dataframe (Image by author)\\n\\n#5 Handling Duplicated Data\\n\\nIn addition to the regular data analysis, appropriately handling duplicate values in your data also plays a vital role in building your data pipeline. One major caveat of having duplicates in your data is that they take up unnecessary storage space and slow down the computation by acquiring resources. Furthermore, duplicate data can skew analysis results, leading us to draw wrong insights. Therefore, removing or handling duplicates in your data is extremely important.\\n\\nFirst, let’s look at how you can mark duplicate values in your DataFrame. For this, we’ll use the duplicated()method in Pandas. This returns a boolean Series that indicates duplicate rows. For demonstration purposes, I’ll only use a random sample of 10 rows of the original salary dataset, of which the last two rows have been intentionally duplicated. The sampled rows are shown in the image below.\\n\\nA Dataframe with duplicates (Image by author)\\n\\nMark duplicated rows\\n\\nPandas allows you to assign boolean labels to rows based on all columns (or a subset of columns) which are duplicates. This can be done using the duplicated() method of Pandas as shown below:\\n\\n\\n\\nWhen there are duplicate values, keep is used to indicate which specific duplicates to mark.\\n\\nkeep = \"first\": (Default) Marks all duplicates as True except for the first occurrence.\\n\\nkeep = \"last\": Marks all duplicates as True except for the last occurrence.\\n\\nkeep = False: Marks all duplicates as True.\\n\\nYou can filter all the rows which appear only once by passing the boolean series as flags for filtering a Pandas DataFrame as follows:\\n\\n\\n\\nA filtered Dataframe with no duplicates (Image by author)\\n\\nTo check duplicates on a subset of columns, pass the list of columns as the subset argument of duplicated() method as shown below:\\n\\n\\n\\nFiltering the DataFrame using the above boolean series as shown below outputs the DataFrame following the code:\\n\\n\\n\\nA filtered Dataframe with duplicates considering two columns (Image by author)\\n\\nRemove duplicates\\n\\nIn addition to marking potential duplicates using boolean labels discussed above, one might also need to get rid of duplicates. To reiterate, the data I am referring to specifically for the \"Handling Duplicated Data\" section comprises just ten rows. This is shown below:\\n\\nA Dataframe with duplicates (Image by author)\\n\\nYou can remove the duplicate rows either based on values in all columns or a subset of columns using the drop_duplicates() method as shown below:\\n\\n\\n\\nA DataFrame after dropping duplicate rows (Image by author)\\n\\nSimilar to duplicated(), the keep argument is used to indicate which specific duplicates you want to keep.\\n\\nkeep = \"first\": (Default) Drops all duplicates except for the first occurrence.\\n\\nkeep = \"last\": Drops all duplicates except for the last occurrence.\\n\\nkeep = False: Drops all duplicates.\\n\\nTo drop duplicates based on the values in a subset of columns, pass the list of columns as the subset argument to the drop_duplicates() method:\\n\\n\\n\\nA DataFrame after dropping duplicate rows considering two columns (Image by author)\\n\\nTo conclude, in this post, I presented a few popular methods available in Pandas for effective data analysis in Tabular Data. Though this post will be helpful for you to make you comfortable with the syntax of these methods, I would highly recommend downloading a dataset on your own and experimenting with it in a jupyter notebook.\\n\\nFurther, there is no better place than referencing the official Pandas documentation available here to acquire fundamental and practical knowledge of various effective methods in Pandas. Pandas’ official documentation provides a detailed explanation of each of the arguments accepted by a function along with a practical example, which in my opinion, is an excellent way to acquire both beginner-level and advanced Pandas expertise.\\n\\nP.S. I have been able to cover only five methods in the post. I’ll release the next set of Pandas methods for effective data analysis in another post soon :). Meanwhile, if you enjoyed reading this article, I am sure you would enjoy the following articles too:\\n\\n20% of Pandas Functions that Data Scientists Use 80% of the Time\\nPutting Pareto’s Principle to work on the Pandas librarytowardsdatascience.com\\n\\nTop AI Resources You Must Follow If You Are Into AI\\nHow to keep up with the latest machine learning advancementsmedium.com\\n\\nThanks for reading.\\n\\n🚀 Get a Free Data Science PDF (550+ pages) with 320+ posts by subscribing to my daily newsletter today:\\n\\n\\n\\nVisit us at DataDrivenInvestor.com\\n\\nSubscribe to DDIntel here.\\n\\nHave a unique story to share? Submit to DDIntel here.\\n\\nJoin our creator ecosystem here.\\n\\nDDIntel captures the more notable pieces from our main site and our popular DDI Medium publication. Check us out for more insightful work from our community.\\n\\nDDI Official Telegram Channel: https://t.me/+tafUp6ecEys4YjQ1\\n\\nFollow us on LinkedIn, Twitter, YouTube, and Facebook.'}},\n",
       "  {'id': 'f67bb6e5317a',\n",
       "   'title': '20 Newbie Mistakes that Even Skilled Python Programmers Make',\n",
       "   'subtitle': 'A collection of common mistakes that you should avoid while coding in Python',\n",
       "   'author': '5d33decdf4c4',\n",
       "   'publication_id': '32881626c9c9',\n",
       "   'published_at': '2024-01-17 03:01:26',\n",
       "   'last_modified_at': '2024-02-13 05:37:08',\n",
       "   'tags': ['data-science',\n",
       "    'python',\n",
       "    'machine-learning',\n",
       "    'python-programming',\n",
       "    'artificial-intelligence'],\n",
       "   'topics': ['programming'],\n",
       "   'claps': 207,\n",
       "   'voters': 39,\n",
       "   'word_count': 1765,\n",
       "   'responses_count': 7,\n",
       "   'reading_time': 7.7937106918238985,\n",
       "   'url': 'https://medium.datadriveninvestor.com/20-newbie-mistakes-that-even-skilled-python-programmers-make-f67bb6e5317a',\n",
       "   'unique_slug': '20-newbie-mistakes-that-even-skilled-python-programmers-make-f67bb6e5317a',\n",
       "   'image_url': 'https://miro.medium.com/0*jN9CVaNSvGEE2ksQ',\n",
       "   'lang': 'en',\n",
       "   'is_series': False,\n",
       "   'is_locked': True,\n",
       "   'is_shortform': False,\n",
       "   'top_highlight': '',\n",
       "   'content': {'id': 'f67bb6e5317a',\n",
       "    'content': \"20 Newbie Mistakes that Even Skilled Python Programmers Make\\n\\nA collection of common mistakes that you should avoid while coding in Python\\n\\nPhoto by Andrea De Santis on Unsplash\\n\\nFind the code for this article here.\\n\\nThe best thing about programming (not just in Python but any programming language) is that, typically, there are multiple ways to implement the same solution.\\n\\nUsing Different Approaches to reach the same output (Image by Author)\\n\\nSome ways are, of course, better than others, which may be due to various reasons like:\\n\\nLess memory usage\\n\\nRun-time efficient\\n\\nFewer lines of code\\n\\nEasy to understand\\n\\nSimple logic, etc.\\n\\nIn this post, I will introduce you to 20 specific situations where Python programmers unknowingly fall into the trap of writing a large, non-elegant, and complex Python code - that eventually holds them back from unleashing the true potential of Python.\\n\\nAlongside this, I will also provide an alternative solution to the problems proposed that will assist you in correcting those blunders.\\n\\nYou can find the code for this article here.\\n\\nLet’s begin 🚀!\\n\\n#1 Using Multiple Print Statements\\n\\nNaive Approach\\n\\nIf you want to print multiple variables, then the naive approach suggests that each variable should get its own print() statement.\\n\\n\\n\\nElegant Approach\\n\\nAs per my experience, using multiple print statements is typically the most commonplace mistake coders (especially newbies) make while coding in Python.\\n\\nHowever, what they don’t know is that with print(), you can print multiple variables in a single print statement as follows:\\n\\n\\n\\nThe sep argument above specifies the separator between the various variables printed using the same print statement (a, b and c above).\\n\\nNote that the end argument is used to specify the ending character of the print statement.\\n\\n\\n\\nIn the code above, end='\\\\n---\\\\n’ parameter prints the new line character, followed by ---, and further, a new line character.\\n\\n#2 Printing the same variable using a FOR loop\\n\\nNaive Approach\\n\\nAs the title suggests, the objective is to print the same variable multiple times.\\n\\nOf course, you should create a FOR loop and iterate the number of times you wish to print the variable, right? I mean, what is wrong with that?\\n\\n\\n\\nElegant Approach\\n\\nAlthough writing a FOR loop has no harm, and everything works fine, it is unnecessary to write a FOR loop to print the same variable multiple times.\\n\\n\\n\\n#3–4 Creating a separate variable to track the index in a loop\\n\\nNaive Approach - 1\\n\\nTo achieve this, typically, one would define a new variable (idx) to keep track of the index value and increment it with each iteration, as shown below:\\n\\n\\n\\nNaive Approach - 2\\n\\nIf not the above method, folks would create a range iterator to keep track of the index, as shown in the code below:\\n\\n\\n\\nElegant Approach\\n\\nThanks to the developer who developed the enumerate() method.\\n\\nEssentially, with this method, you can track both the index (idx) and the value (i) as follows:\\n\\n\\n\\n#5 Converting a list to a string using FOR loop\\n\\nA list to a string (Image by Author)\\n\\nNaive Approach\\n\\nUsing a FOR loop, as demonstrated below, we can collect the elements of the list one at a time.\\n\\n\\n\\nElegant Approach\\n\\nThe sleeky way of converting a list to a string is using the join() method, as shown below:\\n\\n\\n\\nNot only does this save you from writing some unnecessary long code, but it is also as intuitive as the for-loop approach.\\n\\n#6 Removing duplicates from a list using a FOR loop\\n\\nRemoving duplicates from a list (Image by Author)\\n\\nNaive Approach\\n\\nFOR-loop to the rescue yet again!\\n\\nThe naive approach is to iterate over the input list and store unique elements in a new list.\\n\\n\\n\\nElegant Approach\\n\\nHowever, removing duplicates from a list is possible with a single line of Python code, as shown below:\\n\\n\\n\\nThe above returns a set, and you can obtain a list as follows:\\n\\n\\n\\n#7 Searching for an element in a list using FOR loop\\n\\nNaive Approach\\n\\nSay you want to know whether an element exists in a list (or set) or not and return a boolean response (True if it exists, otherwise False).\\n\\nThe naive approach is demonstrated below:\\n\\n\\n\\nUgh! Too much code, isn’t it?\\n\\nElegant Approach\\n\\nLet’s bring that down to a single-line implementation using the in keyword:\\n\\n\\n\\n#8 Iterating over two iterables of the same size using an index variable\\n\\nNaive Approach\\n\\nSimilar to what we did in Section #3–4, that is, defining a variable specifically for the index, the naive way here would be to adopt the same here, as shown below:\\n\\n\\n\\nElegant Approach\\n\\nThe savvy way is to use the zip() function, that pairs corresponding values in two iterables.\\n\\n\\n\\n#9 Reversing a list using a FOR loop\\n\\nReversing a list (Image by Author)\\n\\nNaive Approach\\n\\nAs you may have guessed, we can reverse iterate over the list and append the elements to a new list, as demonstrated below:\\n\\n\\n\\nElegant Approach\\n\\nIf you understand slicing in Python, the elegant solution is just a simple one-liner here:\\n\\n\\n\\nNO FOR LOOPS!\\n\\n#10 Checking Palindrome using a FOR loop\\n\\nNaive Approach\\n\\nExpanding on the idea of the above situation (#9 - reversing a list), we can check if the reversed list is the same as the input list.\\n\\n\\n\\nElegant Approach\\n\\nThe elegant approach, as discussed above, is to use slicing and compare it with the input list:\\n\\n\\n\\n#11 Counting the occurrence of an element in an iterable using FOR loop\\n\\nNaive Approach\\n\\nThe naive approach to finding the frequency of an element is iterating over the list using a FOR loop and counting the number of occurrences.\\n\\n\\n\\nElegant Approach\\n\\nThe elegant approach in this case that saves us from writing a FOR loop (yet again) is using the count() method:\\n\\n\\n\\nYou can use the count() method on a string input as well:\\n\\n\\n\\n#12 Obtaining a string’s substring using FOR loop\\n\\nNaive Approach\\n\\nThe objective here is to return a substring of length n_chars, starting as position start_index.\\n\\nA newbie’s approach to this problem is using a FOR loop, as demonstrated below:\\n\\n\\n\\nElegant Approach\\n\\nThe one-liner approach, however, is to use slicing, which saves you from writing a FOR loop.\\n\\n\\n\\n#13 Defining long integer constants\\n\\nImagine you want to declare an integer variable with the value 1⁰²¹.\\n\\nNaive Approach\\n\\n\\n\\nIdeally, one would write zeros in successions and count as they are typing.\\n\\nBut say someone else wants to refer to this code. Wouldn’t it be a trouble for them to count all the zeros?\\n\\nElegant Approach\\n\\nTo improve the readability, you can separate a group of zeros with _ (underscore), as shown below:\\n\\n\\n\\nBut that still is a hassle, isn’t it? Why should anyone be counting zeros?\\n\\nIf the number is expressible in the form a^b, you should use the pow() method instead.\\n\\n\\n\\n#14 Swapping case of a String with IF conditions\\n\\nGiven a string, the objective is to make uppercase letters lowercase and vice versa.\\n\\nNaive Approach\\n\\nA naive approach would involve checking the case of every element and then having specific conditions for each case.\\n\\n\\n\\nThere’s nothing wrong with the output, but why would you do that?\\n\\nElegant Approach\\n\\nUse the swapcase() method instead.\\n\\n\\n\\n#15 Obtaining a Union of two sets\\n\\nUnion of Two Sets (Image by Author)\\n\\nNaive Approach\\n\\nIterate over the two sets and add the elements to a new set.\\n\\n\\n\\nToo many lines of code, isn’t it?\\n\\nLet’s bring it down to a single line.\\n\\nElegant Approach\\n\\nThe set data structure in Python provides a union() method to the union of two sets.\\n\\n\\n\\nWhat’s more, you can extend it to any number of input sets:\\n\\n\\n\\nIsn’t that cool? Imagine how many FOR loops you would have written to merge the four sets.\\n\\n#16 Obtaining the Intersection of two sets\\n\\nNaive Approach\\n\\nSimilar to the union case discussed above, we can find the common elements between the two sets as follows:\\n\\n\\n\\nElegant Approach\\n\\nHowever, you can use the intersection() method to achieve the same:\\n\\n\\n\\n#17 Writing Multiple Conditions in an IF statement\\n\\nTo elaborate on this, say you want to implement the following logic. The input is an integer a.\\n\\nFunction to map the input to the output (Image by author)\\n\\nNaive Approach\\n\\nHere, one would use multiple OR separated conditionals to implement the above logic.\\n\\n\\n\\nElegant Approach\\n\\nAn intelligent way to avoid multiple conditionals is by using the in keyword, as demonstrated below:\\n\\n\\n\\n#18 Changing the data type of all elements in a list\\n\\nGiven a list of strings representing integers, the objective is to convert them to a list of integers by changing the data type.\\n\\nNaive Approach\\n\\nIterate over the list using a FOR loop and type-cast individual elements.\\n\\n\\n\\nElegant Approach\\n\\nA smart approach is to use map(), as demonstrated below:\\n\\n\\n\\nAs its first argument, the map() method accepts a function (int) and the second argument is an iterable (input_list).\\n\\n#19 Swapping variables\\n\\nGiven two variables, the objective is to transfer the value in the first variable to the second and that in the second to the first.\\n\\nNaive Approach\\n\\nThe approach most C/C++ programmers take here is defining a new variable (temp), and they typically extend that in Python too.\\n\\n\\n\\nElegant Approach\\n\\nFortunately, Python allows multiple assignments in a single statement, eliminating the need for any temporary variable.\\n\\n\\n\\n#20 Generating all combinations of two lists using nested loops\\n\\nGiven two lists (a with length n, and b with length m), generate all nxm combinations.\\n\\nNaive Approach\\n\\nWrite two nested FOR loops and append all combinations to a list.\\n\\n\\n\\nElegant Approach\\n\\nThe elegant way is to use the product() method from the itertools library, as demonstrated below:\\n\\n\\n\\nConclusion\\n\\nTo conclude, in this post, I demonstrated 20 different scenarios that I believe most Python programmers have been through and may have possibly taken the wrong approach towards coding the solution.\\n\\nIf you noticed, in most situations, the elegant approach primarily focused on eliminating the explicit coding of the FOR loop used in the former approach.\\n\\nAs a key takeaway from this post, you should always remember that in most cases, the first solution you will come up with will not be an ideal approach. Therefore, a quick Google search will always be beneficial :).\\n\\nThat is why adopting the imperfectionist’s mindset is crucial to becoming an elegant programmer (not just in Python but in any language for that sake).\\n\\nP.S. I will release the part two of this post soon!\\n\\nAs always, thanks for reading!\\n\\n🚀 Get a Free Data Science PDF (550+ pages) with 320+ posts by subscribing to my daily newsletter today:\\n\\n\\n\\nVisit us at DataDrivenInvestor.com\\n\\nSubscribe to DDIntel here.\\n\\nHave a unique story to share? Submit to DDIntel here.\\n\\nJoin our creator ecosystem here.\\n\\nDDIntel captures the more notable pieces from our main site and our popular DDI Medium publication. Check us out for more insightful work from our community.\\n\\nDDI Official Telegram Channel: https://t.me/+tafUp6ecEys4YjQ1\\n\\nFollow us on LinkedIn, Twitter, YouTube, and Facebook.\"}},\n",
       "  {'id': 'b2316bcc4c0f',\n",
       "   'title': '5 Jupyter Hacks That You Never Knew Even Existed',\n",
       "   'subtitle': 'With a bonus tip',\n",
       "   'author': '5d33decdf4c4',\n",
       "   'publication_id': '32881626c9c9',\n",
       "   'published_at': '2024-01-09 16:35:49',\n",
       "   'last_modified_at': '2024-01-23 15:19:34',\n",
       "   'tags': ['data-science',\n",
       "    'machine-learning',\n",
       "    'artificial-intelligence',\n",
       "    'python',\n",
       "    'programming'],\n",
       "   'topics': ['data-science', 'programming'],\n",
       "   'claps': 524,\n",
       "   'voters': 129,\n",
       "   'word_count': 1145,\n",
       "   'responses_count': 9,\n",
       "   'reading_time': 5.454088050314466,\n",
       "   'url': 'https://medium.datadriveninvestor.com/5-jupyter-hacks-that-you-never-knew-even-existed-b2316bcc4c0f',\n",
       "   'unique_slug': '5-jupyter-hacks-that-you-never-knew-even-existed-b2316bcc4c0f',\n",
       "   'image_url': 'https://miro.medium.com/0*HsAklpaUqoziyZmf',\n",
       "   'lang': 'en',\n",
       "   'is_series': False,\n",
       "   'is_locked': True,\n",
       "   'is_shortform': False,\n",
       "   'top_highlight': '',\n",
       "   'content': {'id': 'b2316bcc4c0f',\n",
       "    'content': '5 Jupyter Hacks That You Never Knew Even Existed\\n\\nWith a bonus tip\\n\\nPhoto by Sigmund on Unsplash\\n\\nFind the code for this article here.\\n\\nJupyter Notebook is one of the most sought-after IDEs for almost all Python-oriented programming tasks such as data science, machine learning, scientific computing, and many more.\\n\\nIts interactive coding capabilities make it the go-to tool not only for beginners but experts as well.\\n\\nYet, despite its widespread usage, many of its users do not use it to its full potential.\\n\\nAs a result, they tend to use Jupyter using its default interface/capabilities, which, in my opinion, can be significantly improved to provide a richer experience.\\n\\nTherefore, in this article, I will present 5 cool Jupyter hacks that you probably never knew even existed.\\n\\nThese will allow you to unlock new levels of productivity and creativity with this powerful tool.\\n\\nLet’s begin 🚀!\\n\\n#1 Stop Previewing Raw DataFrames\\n\\nOften when we load a DataFrame in Jupyter, we preview it by printing. This is shown below:\\n\\n\\n\\n\\n\\nHowever, it hardly tells anything about what’s inside this data.\\n\\nAs a result, one has to dig deeper by analyzing it, which involves simple yet repetitive code.\\n\\nInstead, use Jupyter-DataTables. You can install it as follows:\\n\\n\\n\\nTo use it, run the following code in Jupyter:\\n\\n\\n\\nIt supercharges the default preview of a DataFrame with many useful features.\\n\\nAs a result, whenever you print a DataFrame, it will appear much more elegant as shown below.\\n\\n\\n\\nThis richer preview provides sorting, filtering, exporting, and pagination operations along with column distribution and data types\\n\\n#2 Label Your Data With The Click Of A Button\\n\\nNot all data you get is labeled beforehand.\\n\\nThus, typically with unlabeled data, one may have to spend some time annotating/labeling it.\\n\\nRather than previewing the files externally and labeling them or building a complex annotation pipeline, you can annotate in just a few lines of code using 𝐢𝐩𝐲𝐚𝐧𝐧𝐨𝐭𝐚𝐭𝐞.\\n\\nIt provides a Jupyter widget specifically for data annotation.\\n\\nRun the following commands to install it:\\n\\n\\n\\nData annotation becomes easier by clicking buttons. Thus, ipyannotate allows you to attach data labels to buttons.\\n\\nConsider we have some images of cats and dogs (unlabeled). We can create an annotation pipeline as follows:\\n\\n\\n\\nAs shown above, you can annotate your data by simply clicking the corresponding button.\\n\\nWhat’s more, you can also retrieve the labels and use them for your data pipeline as required.\\n\\n#3 View Documentation in Jupyter\\n\\nWhile working in Jupyter, it is common to forget the parameters of a function and visit the official docs (or StackOverflow).\\n\\nHowever, you can view the documentation in the notebook itself.\\n\\nPressing 𝐒𝐡𝐢𝐟𝐭-𝐓𝐚𝐛 opens the documentation panel. This is extremely useful and saves time as one does not have to open the official docs every single time.\\n\\nA demo is shown below:\\n\\n\\n\\nThis feature also works for your custom functions.\\n\\n#4 Get Notified When Jupyter Cell Has Executed\\n\\nAfter running some code in a Jupyter cell, we often navigate away to do some other work in the meantime.\\n\\nHere, one has to repeatedly get back to the Jupyter tab to check whether the cell has been executed or not.\\n\\nTo avoid this, you can use the %%𝐧𝐨𝐭𝐢𝐟𝐲 magic command from the 𝐣𝐮𝐩𝐲𝐭𝐞𝐫𝐧𝐨𝐭𝐢𝐟𝐲 extension.\\n\\nAs the name suggests, it notifies the user upon completion (both successful and unsuccessful) of a Jupyter cell via a browser notification.\\n\\nTo install it, run the following command:\\n\\n\\n\\nNext, load the extension:\\n\\n\\n\\nAnd done!\\n\\nNow, whenever you want to get notified, enter the following magic command at the top of the cell:\\n\\n\\n\\nWhenever the cell will finish its execution, you will receive the following notification:\\n\\n\\n\\nClicking on the notification will take you back to the Jupyter tab.\\n\\n#5 Clear Cell Output In Jupyter Notebook During Run-time\\n\\nWhile using Jupyter, we typically print many details to track the code’s progress.\\n\\nHowever, it gets frustrating when the output panel has accumulated a bunch of details, but we are only interested in the most recent output.\\n\\nMoreover, scrolling to the bottom of the output each time can be annoying too.\\n\\nTo clear the output of the cell, you can use the 𝗰𝗹𝗲𝗮𝗿_𝗼𝘂𝘁𝗽𝘂𝘁 method from the 𝗜𝗣𝘆𝘁𝗵𝗼𝗻 package.\\n\\nIPython comes pre-installed with Python, so no installation is required.\\n\\nYou can import the method as follows:\\n\\n\\n\\nWhen invoked, it will remove the current output of the cell, after which you can print the latest details.\\n\\nA demo is shown below:\\n\\n\\n\\nAs demonstrated above, we only see the latest output in the cell. The previous outputs are being erased.\\n\\nBonus Tip\\n\\nAlthough the above-mentioned tips will significantly enrich your Jupyter experience, there are still many things that I struggle to do with Jupyter.\\n\\nFor instance, Jupyter sucks when it comes to collaboration. As it runs locally, there is no way to embed real-time collaboration capabilities in Jupyter where teams can work together, add comments, track progress, etc.\\n\\nWhat’s more, sharing is equally painful. If I ever have to share my notebook with someone, the only way to do that is by emailing them or hosting it online, on GitHub, for instance, and sharing the link.\\n\\nLastly, many data science tasks are not just limited to Python. They equally involve SQL, which is largely used to interact with organizational databases.\\n\\nHowever, integrating SQL in Jupyter is feasible but a tedious process.\\n\\nSolution\\n\\nFrustrated with these limitations, I started looking for alternatives, and I am glad I discovered Deepnote.\\n\\nWithout having to learn anything new about how to use it, it took away all the limitations of Jupyter in a snap and has consistently offered me an enriching Jupyter-like experience.\\n\\nSharing, collaborating, using SQL, creating charts without any code, connecting to a database, etc., everything is seamlessly integrated into Deepnote.\\n\\nWhile I understand that Jupyter tends to offer a generalized experience for all Python users, it miserably fails to address all the pain points of data scientists, especially those working in teams.\\n\\nDeepnote, in my opinion, is a supercharged version of Jupyter for all data-driven projects, and you should definitely check it out.\\n\\nConclusion\\n\\nWith this, we come to the end of this blog.\\n\\nCongratulations on learning a few incredible hacks for Jupyter notebook. I am sure these tips will level up your python programming productivity.\\n\\nAlso, I would love to know what are your favorite hacks while using Jupyter notebook.\\n\\nAs always, thanks for reading!\\n\\n🚀 Get a Free Data Science PDF (550+ pages) with 320+ posts by subscribing to my daily newsletter today:\\n\\n\\n\\nVisit us at DataDrivenInvestor.com\\n\\nSubscribe to DDIntel here.\\n\\nHave a unique story to share? Submit to DDIntel here.\\n\\nJoin our creator ecosystem here.\\n\\nDDIntel captures the more notable pieces from our main site and our popular DDI Medium publication. Check us out for more insightful work from our community.\\n\\nDDI Official Telegram Channel: https://t.me/+tafUp6ecEys4YjQ1\\n\\nFollow us on LinkedIn, Twitter, YouTube, and Facebook.'}},\n",
       "  {'id': 'f1e31af2257a',\n",
       "   'title': 'Five Killer Optimization Techniques That Most Pandas Users Aren’t Aware Of',\n",
       "   'subtitle': 'A step towards data analysis run-time optimization',\n",
       "   'author': '5d33decdf4c4',\n",
       "   'publication_id': 'a648dc4ecb66',\n",
       "   'published_at': '2024-01-06 19:27:29',\n",
       "   'last_modified_at': '2024-01-12 06:16:39',\n",
       "   'tags': ['data-science',\n",
       "    'machine-learning',\n",
       "    'artificial-intelligence',\n",
       "    'python',\n",
       "    'pandas'],\n",
       "   'topics': ['data-science', 'programming'],\n",
       "   'claps': 559,\n",
       "   'voters': 153,\n",
       "   'word_count': 2030,\n",
       "   'responses_count': 6,\n",
       "   'reading_time': 8.910377358490566,\n",
       "   'url': 'https://towardsdev.com/five-killer-optimization-techniques-that-most-pandas-arent-aware-of-f1e31af2257a',\n",
       "   'unique_slug': 'five-killer-optimization-techniques-that-most-pandas-arent-aware-of-f1e31af2257a',\n",
       "   'image_url': 'https://miro.medium.com/0*aGty_aThlP_5zNyr',\n",
       "   'lang': 'en',\n",
       "   'is_series': False,\n",
       "   'is_locked': True,\n",
       "   'is_shortform': False,\n",
       "   'top_highlight': '',\n",
       "   'content': {'id': 'f1e31af2257a',\n",
       "    'content': 'Five Killer Optimization Techniques That Most Pandas Users Aren’t Aware Of\\n\\nA step towards data analysis run-time optimization\\n\\nPhoto by Brad Neathery on Unsplash\\n\\nFind the code notebook for this post here.\\n\\nThe motivation to design and build real-world applicable machine learning models has always intrigued Data Scientists to leverage optimized, efficient, and accurate methods at scale. Optimization plays a foundational role in sustainably delivering real-world and user-facing software solutions.\\n\\nWhile I understand that not everyone is building solutions at scale, awareness about various optimization and time-saving techniques is nevertheless helpful and highly applicable to even generic Data Science/Machine Learning use-cases.\\n\\nTherefore, in this post, I will introduce you to a handful of incredible techniques to reduce the run-time of your regular tabular data analysis, management, and processing tasks using Pandas. To get a brief overview, I will discuss the following topics in this post:\\n\\n#1 Input/Output on CSV\\n#2 Filtering Based on Categorical data \\n#3 Merging DataFrames\\n#4 Value_counts() vs GroupBy()\\n#5 Iterating over a DataFrame\\n\\nMoreover, you can get the notebook for this post here.\\n\\nLet’s begin 🚀!\\n\\n#1 Input/Output on CSV\\n\\nCSV files are by far the most prevalent source to read DataFrames from and store DataFrames to, aren’t they? This is because CSVs provide tremendous flexibility in the context of input and output operation using the pd.read_csv() and df.to_csv() method such as:\\n\\n\\n\\nCSVs can be opened in Excel and manipulated in every way Excel allows you to.\\n\\nCSVs enable you to read only a subset of columns if needed by specifying the columns as a list and passing it as the usecols argument of pd.read_csv() method.\\n\\nYou can read only the first n rows if needed using the nrows argument of the pd.read_csv() method, etc.\\n\\nWhile I admit that there are numerous advantages of using CSV files, at the same time, they are far from being the go-to method if you are looking for run-time optimization. Let me explain.\\n\\nInput-output operations with Pandas to a CSV file are serialized, inevitably making them highly inefficient and time-consuming. While there is ample scope to parallelize stuff, Pandas, unfortunately, does not have this functionality (yet).\\n\\nTill then, if you are stuck with reading CSV files, there are two incredibly faster alternatives you can take, which I have depicted in the flow chart below:\\n\\nFlow chart to determine the alternative for reading CSV (Image by author).\\n\\nPath 1\\n\\nIf your CSV file is static and you think you will read it multiple times, possibly in the same pipeline or after reloading the kernel, immediately save it as a Pickle or Feather or a Parquet file. But Why? This I have already discussed in my post below:\\n\\nWhy I Stopped Dumping DataFrames to a CSV and Why You Should Too\\nIt’s time to say goodbye to pd.to_csv() and pd.read_csv()towardsdatascience.com\\n\\nThis conversion from CSV format to your desired alternative is demonstrated in the code block below:\\n\\n\\n\\nNow, when you want to read the DataFrame back, instead of reading it from the CSV file, read it using the new file you created. The corresponding methods in Pandas to reload the dataset is shown below:\\n\\n\\n\\nMoreover, each of these individual files will interpret the records as a Pandas DataFrame. This can be verified using the type() method in Python as follows:\\n\\n\\n\\nThe bar-plot below depicts the expected speed up in the run-time for all the four individual file formats:\\n\\nThe time taken to load and save a DataFrame in respective formats. (Image by author)\\n\\nTo obtain the run-time of the four formats, I generated a random dataset in Python with a million rows and thirty columns - encompassing string, float, and integer data types. I measured the load and the save run-time ten times to reduce randomness and draw fair conclusions from the observed results. The results above indicate averages across the ten experiments.\\n\\nPath 2\\n\\nIf your CSV file isn’t static or you are going to use the CSV file just once, conversion to a new format does not make sense. Instead, take Path 2, i.e., use the DataTable library for input and output operations. You can install DataTable using the following command in a Jupyter Notebook:\\n\\n\\n\\nWhen using DataTable, the CSV file will be interpreted as a DataTable DataFrame, not the Pandas DataFrame. Therefore, after loading the CSV file, you need to convert it to Pandas DataFrame. I have implemented this below:\\n\\n\\n\\nSimilarly, if you want to store a Pandas DataFrame to a CSV, prefer taking the DataTable route instead of Pandas. Here, to generate a CSV file using datatable, you first need to convert the Pandas DataFrame to a DataTable DataFrame and then store it in a CSV file. This is implemented below:\\n\\n\\n\\n\\n\\nLeft: Line chart depicting the time taken to store DataFrame to CSV using Pandas and DataTable. Right: Line chart depicting the time taken to read DataFrame from CSV using Pandas and DataTable. (Images by author)\\n\\nAs depicted in the line chart above, DataTable provides high-speed input and output operations for a CSV file over a Pandas.\\n\\nKey Takeaways/Final Thoughts\\n\\nIf you are bound to use a CSV file due to some restrictions, never use the Pandas read_csv() and to_csv() methods. Instead, prefer datatable’s input-output methods, as shown above.\\n\\nIf you will repeatedly read the same CSV file, convert it to one of Pickle, Feather, and Parquet, and then use the new file for input operations.\\n\\n#2 Filtering Based on Categorical data\\n\\nData filtering is another common and widely-used operation in Pandas. The core idea is to select a segment of a dataframe that adheres to a specific condition.\\n\\nTo demonstrate, consider a dummy DataFrame of over 4 million records I created myself. The first five rows are shown in the image below:\\n\\nThe first five rows of the dummy dataset (Image by author)\\n\\nThe code block below demonstrates my implementation:\\n\\n\\n\\nSay you want to filter all the records which belong to \"Amazon\". This can be done as follows:\\n\\n\\n\\nAnother way of doing the same filtering is by using groupby() and obtaining the individual group using the get_group() method as shown below:\\n\\n\\n\\nThe latter method provides speed-ups of up to 14 times as compared to the usual filtering method, which is a tremendous improvement in the run-time.\\n\\nMoreover, the get_group() the method returns the individual group as a Pandas DataFrame. Therefore, you can proceed with the usual analysis post that. We can verify this by checking the type of dataframe obtained in Approach 1 and Approach 2 as follows:\\n\\n\\n\\nKey Takeaways/Final Thoughts\\n\\nIf you will perform repeated filtering of your DataFrame on categorical data, prefer grouping the data first using the groupby() method. After that, fetch the desired groups using the get_group() method.\\n\\nCaveat: This approach is only applicable to filtering based on categorical data.\\n\\n#3 Merging DataFrames\\n\\nMerge in Pandas refers to combining two DataFrames based on a join condition. This is similar to joins in Structured Query Language (SQL). You can execute merge using the pd.merge() method in Pandas as follows:\\n\\n\\n\\nAlthough there is nothing wrong with the above method to link dataframes, there is a faster alternative available to join two dataframes using the join() method.\\n\\nIn the code block below, I have implemented the merge operation using the merge() method and the join() method. Here, we measure the time taken for the merge operation using the two methods.\\n\\n\\n\\nWith the join() method, we notice an improvement of over 4 times relative to the standard merge() method in Pandas.\\n\\nHere, the join() method first expects you to change the index column and set it to the specific column on which you wish to execute joins between tables. This is done using the set_index() method in Pandas, as shown above.\\n\\nIf you want to execute a join condition on multiple columns, you can do that too using the join() method. First, pass the columns you wish to execute the join condition on as a list to the set_index() method. Then, call the join() method as before. This is demonstrated below:\\n\\n\\n\\nKey Takeaways/Final Thoughts\\n\\nWhile performing joins, always change the index of both the DataFrames and set it to the column(s) you want to execute the join condition on.\\n\\n#4 Value_counts() vs GroupBy()\\n\\nWe use value_counts() in Pandas to find the frequency of individual elements in a series. For instance, consider the dummy employee DataFrame we used in Section 2.\\n\\nThe first five rows of the dummy dataset (Image by author)\\n\\nWe can find the number of employees belonging to each company in this dataset using the value_counts() method as follows:\\n\\n\\n\\nSimilar frequency calculation can also be done using groupby(). The code below demonstrates that:\\n\\n\\n\\nThe output of value_counts() is arranged in descending order of frequencies. On the other hand, the output of size() on groupby() is sorted on the index column, which in this case is Company Name.\\n\\nAssuming we are not bothered with how the output is arranged or sorted, we can measure the difference in run-time of the two methods to obtain the desired frequency as follows:\\n\\n\\n\\nEven though both the methods essentially do the same thing (if we ignore the order of the output for once), there is a significant run-time difference between the two - groupby() being 1.5 times slower than value_counts().\\n\\nThings get even worse when you want to obtain normalized frequencies, which denote the percentage/fraction of individual elements in the series. The run-time, in this case, is compared below:\\n\\n\\n\\nOnce again, although both the methods do the same thing, there is a significant run-time difference between the two - groupby() being close to 2 times slower than value_counts().\\n\\nKey Takeaways/Final Thoughts\\n\\nFor frequency-based measures, prefer using value_counts() instead of groupby().\\n\\nvalue_counts() can be used on multiple columns at once. Therefore, If you want to compute frequency on a combination of values from multiple columns, do that with value_counts() instead of groupby().\\n\\n#5 Iterating over a DataFrame\\n\\nLooping or iterating over a DataFrame is the process of visiting every row individually and performing some pre-defined operations on the record. Although the best thing in such cases is to avoid looping altogether in the first place and prefer vectorized approaches, there might be situations where looping is necessary.\\n\\nThere are three methods in Pandas through which iteration is possible. Below, we’ll discuss them and compare their run-time on the employee dummy dataset used in the sections below. To revisit, the image below shows the first five rows of the DataFrame.\\n\\nThe first five rows of the dummy dataset (Image by author)\\n\\nThe three methods to loop over a DataFrame are:\\n\\nIterate using range(len(df)).\\n\\nIterate using iterrows().\\n\\nIterate using itertuples().\\n\\nI have implemented three functions in the code block below which utilize these three methods. The objective of the function is to calculate the mean salary of all employees in the DataFrame. We also find the run-time of each of these methods on the same DataFrame below.\\n\\nMethod 1: Iterate using range(len(df))\\n\\n\\n\\nThe average run-time to iterate over 4 million records is 46.1 ms.\\n\\nMethod 2: Iterate using iterrows()\\n\\n\\n\\nThe iterrows() method provides a substantial improvement in the iteration process, reducing the run-time by 2.5 times from 46.1 ms to 18.2 ms.\\n\\nMethod 3: Iterate using itertuples()\\n\\n\\n\\nThe itertuples() method turns out to be even better than iterrows(), reducing the run-time further by over 23 times from 18.2 ms to 773 µs.\\n\\nKey Takeaways/Final Thoughts\\n\\nFirst, you should avoid introducing for-loops in your code to iterate over a DataFrame. Think of a vectorized solution if possible.\\n\\nIf vectorization is not possible, leverage the pre-implemented methods in Pandas for iteration, such as itertuples() and iterrows().\\n\\nConclusion\\n\\nIn this post, I discussed five incredible optimization techniques in Pandas, which you can directly leverage in your next data science project. In my opinion, the areas I have discussed in this post are subtle ways to improve the run-time, which are often overlooked to seek optimization in. Nonetheless, I hope this post gave you an insightful understanding of these day-to-day Pandas’ functions.\\n\\nIf you enjoyed reading this post, I hope you would like the following posts too:\\n\\nPowerful One-liners in Pandas Every Data Scientist Should Know\\nThings you can do in one line using Pandastowardsdatascience.com\\n\\n20% of Pandas Functions that Data Scientists Use 80% of the Time\\nPutting Pareto’s Principle to work on the Pandas librarytowardsdatascience.com\\n\\nThanks for reading.\\n\\nIf you want to learn more such elegant Data Science and Python related stuff, I share an informative thing every day in my newsletter:\\n\\n🚀 Get a Free Data Science PDF (550+ pages) with 320+ posts by subscribing to my daily newsletter today:\\n\\n\\n\\nDoge meme created by the author on imgflip.com.'}}],\n",
       " '8c8e5b7182ef': [{'id': '2eb0d15d6d77',\n",
       "   'title': 'I Built The 5 Income Streams Every Writer Should Have',\n",
       "   'subtitle': 'How To Make Money as a Writer',\n",
       "   'author': '8c8e5b7182ef',\n",
       "   'publication_id': '*Self-Published*',\n",
       "   'published_at': '2024-02-16 19:39:53',\n",
       "   'last_modified_at': '2024-02-16 19:44:12',\n",
       "   'tags': ['passive-income',\n",
       "    'side-hustle',\n",
       "    'make-money-online',\n",
       "    'affiliate-marketing',\n",
       "    'writer'],\n",
       "   'topics': ['freelancing', 'writing'],\n",
       "   'claps': 558,\n",
       "   'voters': 55,\n",
       "   'word_count': 2022,\n",
       "   'responses_count': 10,\n",
       "   'reading_time': 9.330188679245282,\n",
       "   'url': 'https://medium.com/@iampaulrose/i-built-the-5-income-streams-every-writer-should-have-2eb0d15d6d77',\n",
       "   'unique_slug': 'i-built-the-5-income-streams-every-writer-should-have-2eb0d15d6d77',\n",
       "   'image_url': 'https://miro.medium.com/0*qHvZkZbMS3hS2S7b',\n",
       "   'lang': 'en',\n",
       "   'is_series': False,\n",
       "   'is_locked': False,\n",
       "   'is_shortform': False,\n",
       "   'top_highlight': \"By posting high-quality content pieces on traffic platforms, you'll be passively building a portfolio of content for potential clients to see.\",\n",
       "   'content': {'id': '2eb0d15d6d77',\n",
       "    'content': 'I Built The 5 Income Streams Every Writer Should Have\\n\\nHow To Make Money as a Writer\\n\\nWriters have one of the most profitable skills when it comes to making money online, but somehow barely 50% make as much as they should.\\n\\nI like to think I’m a decent writer, and currently, I’m working my way through building profitable income streams that make me thousands of dollars every month.\\n\\nPhoto by Christin Hume on Unsplash\\n\\nToday, I’m literally taking you behind the scenes to see what these income streams are and how you can build them for yourself.\\n\\nAnd no, it’s not going to be the traditional income streams we’re all used to, like\\n\\nBook deals\\n\\nand Freelance projects\\n\\nI’m talking about next-level income streams to make money as a writer.\\n\\nBut First, Here’s a Quick Writer Roll Call\\n\\nSmart writers make a lot of money, and I mean, a lot.\\n\\nNow, when I say \\'smart,\\' I don’t mean \\'book smart’;\\n\\nI mean \\'income smart\\' writers.\\n\\nThese writers know exactly what to build and which systems to set in place.\\n\\nFrankly, I don’t even consider myself a smart writer, near the likes of\\n\\nDan Koe, a writer who makes $100,000 per month\\n\\nAdam\\xa0Enfroy, a blogger and Youtuber who makes $350,000 per month\\n\\nScreenshot Of Google\\'s Snippet\\n\\nThese writers have mastered the art of writing and income generation to the point where they now make millions of dollars every year.\\n\\nNow, to an extent, I think I’m income smart.\\n\\nEvery minute of the day, I passively brainstorm new ways to make money online with my skills.\\n\\nAnd today,\\n\\nI’ll be talking about the 5 Income streams I think every writer should have.\\n\\nThen I’ll go on to show you how you can build them for yourself\\n\\nBut first, there are prerequisites for these income streams.\\n\\nYou have to be ready to put your writing out for the world to see.\\n\\nPhoto by Sincerely Media on Unsplash\\n\\nBecause that’s how you build a personal brand.\\n\\nIt could be on\\n\\nYouTube like Adam Enfroy\\n\\nTwitter like Dan Koe\\n\\nor on Medium.com just like me.\\n\\nNext, you’ll have to obey the rule of one.\\n\\nFocus on just one traffic platform at a time\\n\\nBuild one Income Stream\\n\\nand talk about just one niche topic and have just one target audience\\n\\nIf these rules sound lenient enough, let’s get right into the 5 income streams every writer should have.\\n\\n5 Income Streams Every Writer Should Have\\n\\n1. Royalty Income\\n\\nRoyalties are income payouts that you receive for selling anything you create as a writer repeatedly.\\n\\nIt could be eBooks, courses, newsletter subscriptions, or even physical copies of your book.\\n\\nMy point is, you create them once and time and time again.\\n\\nPhoto by Content Pixie on Unsplash\\n\\nYou could sell your digital products on your own store with Gumroad or Payhip.\\n\\nThese platforms are free for users and only get paid when you actually make money.\\n\\nYou can also consider Marketplaces like Amazon KDP or Barnes and Noble for your eBooks.\\n\\nYou already have the skills; you just need to create something valuable.\\n\\nLet’s say you love horror,\\n\\nPhoto by Rosie Sun on Unsplash\\n\\nYou could create a traffic platform to share short stories you compose\\n\\nand then create a newsletter for weekly exclusive horror stories\\n\\nYou simply start with what you’re good at writing, then work your way through finding the perfect product to create.\\n\\nI love finance, so with all of my online experience, I focus on writing finance-related stories here on Medium.\\n\\nThrough these stories, I’m able to sell my eBooks as an extension of the value I already share in my stories.\\n\\nI built my royalty income when I launched my eBook business in August of 2023, and so far, in just 6 months, I’ve made over $3,777.94 on Gumroad.\\n\\nScreenshot By Author\\n\\nThe best part is, this income is completely passive.\\n\\n2. Ad Revenue\\n\\nTraffic platforms such as YouTube, TikTok, and Twitter have a business model wherein they charge businesses a certain fee to display ads to users on their platforms.\\n\\nThese fees are then split between the traffic platform and you, the creator.\\n\\nUsually, it’s a 55%-45% split, with the creator keeping the larger part of the revenue.\\n\\nWhy?\\n\\nBecause, what is YouTube without its creators!\\n\\nPhoto by NordWood Themes on Unsplash\\n\\nOther platforms, such as Medium and Vocal Media, have a similar model where they charge their readers a monthly subscription to unlock paywalled stories.\\n\\nWe, the writers of these stories, are then given a cut of this membership revenue, depending on how many paid subscribers read them.\\n\\nTo start this income stream, you’d first need to meet the monetization requirements of your traffic platform.\\n\\nOnce that happens, you’ll be able to make money from your audience even without selling anything to them.\\n\\nAnd yes, you can make ad revenue and still sell your digital products for royalty income.\\n\\nThat’s how smart writers grow their income.\\n\\nPhoto by Morgan Housel on Unsplash\\n\\n3. Affiliate Marketing\\n\\nAffiliate marketing is the lazy way to generate royalty income.\\n\\nSome other creator or writer does the work and creates the high-quality product.\\n\\nYou find this product, apply to become its affiliate, and promote it on its behalf.\\n\\nObviously, you won’t be keeping the full revenue from the sales you make.\\n\\nInstead, you’ll receive a certain percentage of every sale as your commission.\\n\\nEven with the revenue split, affiliate marketing can potentially be more profitable than royalties from your digital products if you play your cards right.\\n\\nPhoto by Alessandro Bogliari on Unsplash\\n\\nPick a high-quality product relevant to your target audience and with a good commission structure.\\n\\nAnd if you’re finding it hard to decide on what to promote,\\n\\nJust think about a digital product you’d love to create but can’t because it’s way too stressful.\\n\\nThen, find that product and promote it instead.\\n\\nAffiliate Marketing is one of, if not my most profitable income streams as a writer.\\n\\nI primarily promote two affiliate programs with products I’ve used and trust.\\n\\nAnd from just one of those affiliate programs, I’ve made $4,535.10 so far.\\n\\nScreenshot by Author\\n\\nThe other affiliate programs I promote make me thousands of dollars every single month.\\n\\n4. Service Income\\n\\nAs a writer, you possess a skill that almost every business needs.\\n\\nFrom YouTube scripts to white papers and even sales copies, the possibilities are endless.\\n\\nWith a writing service business, you’ll be\\n\\nproductizing your writing services\\n\\nand offering them at high prices to potential buyers.\\n\\nSure, it’s not going to be as passive as digital products, but that’s okay.\\n\\nBecause you’ll be paid in full for your precious time.\\n\\nAs for how you’ll be getting paid clients, your traffic platform will basically be doing all the work for you.\\n\\nPhoto by Aman Pal on Unsplash\\n\\nBy posting high-quality content pieces on traffic platforms, you’ll be passively building a portfolio of content for potential clients to see.\\n\\nSoon enough, you’ll start to receive emails and inquiries for your services, and that’s how you make money.\\n\\nNow, while I love offering services, I’ve found a better way to generate service income without actually providing services.\\n\\nand it’s with consultation sessions.\\n\\nSo Instead of offering my services, this model only takes an hour of my time, and that’s it.\\n\\nAs opposed to when I offer my services, this model only takes an hour of my time and that’s it.\\n\\nCurrently, I’ve had about 6 consultation sessions so far,\\n\\nand 4 of them have generated revenue of $600, charging $150 per hour.\\n\\nScreenshot By Author\\n\\n5. Sponsorship Income\\n\\nGood job!\\n\\nYou’ve built your audience,\\n\\nand now you have a community you can call your own.\\n\\nBusinesses see your community and start to want a piece of the attention you’re receiving.\\n\\nThey reach out with sponsorship deals, where you get paid to talk about these businesses.\\n\\nYes, just talk and you\\'ll get paid, it\\'s as simple as that.\\n\\nI personally receive dozens of sponsorship email requests every single week, but I’m yet to accept any of them.\\n\\nPhoto by Brett Jordan on Unsplash\\n\\nBut that’s just me and my personal decision.\\n\\nThis income stream is a very profitable one to have, so build it.\\n\\nHow To Build These Income Streams As a Writer\\n\\nNow I know you\\'re smart, so I want you to think.\\n\\nWhat\\'s one thing that\\'s peculiar to all of these income streams?\\n\\nTime up!\\n\\nIf you guessed, \"a traffic platform\", you\\'re right.\\n\\nTo build these writer income streams, you’re going to need to first\\n\\nChoose a traffic platform\\n\\nChoose a Niche\\n\\nThen post quality content\\n\\nBut What Traffic Platform Is Best For Writers?\\n\\nIn my opinion, there are three of them\\n\\nYouTube\\n\\nTwitter\\n\\nand Medium\\n\\nMy personal favorite is Medium, and that’s because it was the platform that got me my first 1k followers in just one month.\\n\\nI was a complete beginner when I published my first post on Medium.\\n\\nAll I had was my raw writing skills.\\n\\nPhoto by Jodie Cook on Unsplash\\n\\nBut it didn’t end there, this is my fifth month on Medium and I’ve grown over 40.3k followers.\\n\\nScreenshot By Author\\n\\nWith over 273,000 views every single month.\\n\\nScreenshot By Author\\n\\nIn comparison to other traffic platforms, I love Medium because\\n\\nall I do is write (no editing or complex creation processes)\\n\\nthere’s no reciprocity attached to going viral; you grow whether or not you engage with others.\\n\\nand even without premium content creation gadgets, starting with just $0, you can still grow an audience that loves what you write and wants to buy from you.\\n\\nBut the most important reason why you need to be writing on Medium is this;\\n\\nAs of 2021, stats have shown that out of all the readers available on Medium, 700,000 of them pay for a monthly subscription.\\n\\nScreenshot Of Google\\'s Snippet\\n\\nSince these readers already pay a monthly subscription to access valuable content on Medium, paying an extra fee for an ebook from a writer they trust is simply a walk in the park.\\nOnce you’ve chosen your traffic platform, the next step should be picking a niche topic to write about.\\n\\nThis part should be easy.\\n\\nThink of all the topics you would normally write about even without being paid.\\n\\nThat\\'s your niche.\\n\\nNow, write out a content schedule with the different content ideas you plan to share on your Medium page.\\n\\nAnd if coming up with these ideas seems way too hard,\\n\\nFind 10-20 writers in your niche\\n\\nand write a list of their best performing posts (take inspiration and create something of value)\\n\\nYou’re now ready to make your first post.\\n\\nPhoto by Kenny Eliason on Unsplash\\n\\nConclusion\\n\\nGetting paid to do what you love brings the best feeling ever.\\n\\nImagine a life where you writing skills pay the bill.\\n\\nSo, yes, you’ll have fun writing, but then you’ll also not have to work at a job you hate just to pay the bills.\\n\\nIt’s epic.\\n\\nIf you’re a writer, you should probably start by building your audience online.\\n\\nTo keep things easy, you can start by blogging on Medium.com, then work your way up by building these income streams.\\n\\nBut it doesn’t end there; you can also repurpose your Medium stories into\\n\\nFaceless YouTube videos where you just read out the same script\\n\\nand Twitter Threads where you break your stories into smaller bits\\n\\nI’m highly convinced that Medium is the place where every writer needs to be, and this is your sign to publish that first post.\\n\\nAnd if you’re curious about what I did in just 30 days to\\n\\ngo viral,\\n\\ngrow thousands of followers,\\n\\nand make thousands of dollars.\\n\\nI highly recommend you check out my Medium Income Playbook.\\n\\nThe Medium Income Playbook\\n\\nIn this ebook, I share my exact thought process behind\\n\\nFinding endless profitable content ideas related to your specific topic\\n\\nCreating click-worthy titles and viral headlines to capture readers\\' attention.\\n\\nCreating engaging stories that convert readers into loyal subscribers and even buyers.\\n\\nMy writing principles (Quantity vs quality, KLT principle and the MVA principle)\\n\\nAnd I’ll also share my personal experiences on how I managed to grow to over 37k followers (as I speak) on Medium in less than 5 months.\\n\\nLiterally everything you need to go from zero followers to making passive income as a writer is in the Medium Income Playbook.\\n\\nSo If you want to start your very own profitable Medium page,\\n\\nCheck out the steps I personally tried out and have now shared in the Medium Income Hustle playbook.\\n\\nYou can click here to Grab The Medium Income Playbook.'}},\n",
       "  {'id': '40f61887f107',\n",
       "   'title': 'I Found 5 Ways To Make Money With AI Art',\n",
       "   'subtitle': 'How To Make Passive Income With AI Art',\n",
       "   'author': '8c8e5b7182ef',\n",
       "   'publication_id': '*Self-Published*',\n",
       "   'published_at': '2024-02-15 02:43:52',\n",
       "   'last_modified_at': '2024-02-16 02:19:12',\n",
       "   'tags': ['ai',\n",
       "    'artificial-intelligence',\n",
       "    'ai-art',\n",
       "    'passive-income',\n",
       "    'side-hustle'],\n",
       "   'topics': ['artificial-intelligence'],\n",
       "   'claps': 530,\n",
       "   'voters': 51,\n",
       "   'word_count': 1942,\n",
       "   'responses_count': 7,\n",
       "   'reading_time': 9.678301886792452,\n",
       "   'url': 'https://medium.com/@iampaulrose/i-found-5-ways-to-make-money-with-ai-art-40f61887f107',\n",
       "   'unique_slug': 'i-found-5-ways-to-make-money-with-ai-art-40f61887f107',\n",
       "   'image_url': 'https://miro.medium.com/0*MOAhI1B6TFGBfkOl',\n",
       "   'lang': 'en',\n",
       "   'is_series': False,\n",
       "   'is_locked': False,\n",
       "   'is_shortform': False,\n",
       "   'top_highlight': '',\n",
       "   'content': {'id': '40f61887f107',\n",
       "    'content': 'I Found 5 Ways To Make Money With AI Art\\n\\nHow To Make Passive Income With AI Art\\n\\nIt used to take professional artists days, if not weeks, to come up with the type of artwork that many AI art generators spit out in seconds.\\n\\nAnd back then, some very profitable side hustles were restricted only to those who could create illustrations and artwork from scratch.\\n\\nPhoto by Frankie Cordoba on Unsplash\\n\\nBut that has changed, because with these AI art generators, even a beginner can start the 5 profitable AI side hustles I’m about to share in today’s story.\\n\\nNow, the AI art generator I’ll be making reference to today is Leonardo.Ai.\\n\\nIt’s free to use and sign up for, so you really have no excuse for not trying out these 5 AI powered side hustles.\\n\\nFor each of these side\\xa0hustles, we’ll be keeping things precise with basically\\n\\nWhat the side hustle is?\\n\\nWhere you can sell the AI art\\n\\nand a sample of what you could be creating with Leonardo AI\\n\\nI’ve also prepared specific prompts to make the entire work easier for you, even as a complete beginner.\\n\\nThese prompts are included in my Leonardo Prompt Bundle, so generating high-quality images shouldn’t be a worry while you read this story.\\n\\nAnd with all that introduction out of the way, here are 5 ways to make money with AI art.\\n\\nPhoto by Jackson Sophat on Unsplash\\n\\nIdea No 1: Sell Clipart\\n\\nClipart, everyone loves them.\\n\\nThey are\\n\\ncute images\\n\\nuseful in many projects\\n\\nand very profitable too.\\n\\nWith an AI art generator like Leonardo AI, you can create really cute-looking illustrations and vector art to sell on marketplaces like\\n\\nEtsy\\n\\nCreative Fabrica\\n\\nTeachers Pay Teachers\\n\\nI sell my AI generated clipart on Creative Fabrica and have been able to build a following of 401 people, with over 2,472 product favorites, making me thousands of dollars every month.\\n\\nScreenshot by Author\\n\\nI’ve also tried Teachers Pay Teachers, and within the short period since my shop went live, I made $42.96.\\n\\nScreenshot by Author\\n\\nEtsy, on the other hand, needs no introduction.\\n\\nWith over 454.2m monthly visitors, this marketplace is where you want to be selling your clipart.\\n\\nEtsy\\'s Traffic Insights by SimilarWeb\\n\\nI found an entire shop on Etsy dedicated to selling cliparts, which, in my opinion, are most likely AI-generated.\\n\\nAnd with a total of 15,613 Sales, as at a price range of $1.24,\\xa0this shop would have made over $19,360.12.\\n\\nScreenshot Of My Calculator\\n\\nNow, one of the Clipart bundles I found in this shop was a \"happy birthday clipart bundle.\"\\n\\nAnd by asking ChatGPT, I found out that a happy birthday clipart bundle should include the following clipart images.\\n\\nChatGPT Dashboard\\n\\nSo using the Clipart prompt in the Leonardo Prompt Bundle, here are two birthday clipart images I generated.\\n\\nGenerated By Leonardo Ai\\n\\nGenerated By Leonardo Ai\\n\\nOnce I have 10–20 Clipart images, I’d\\n\\nRemove their background using Adobe’s free background remover\\n\\nThen upscale to improve their quality with a free upscaler like Upscale.media\\n\\nWith my clipart bundle ready to be sold, you just need to create a new listing on your shop and start selling.\\n\\nIdea No 2: Sell Patterns in 2 ways\\n\\nIf you’re a fashionista or love a good fabric pattern, this side hustle idea is for you.\\n\\nAs\\xa0usual, we need the ideas or niches.\\n\\nSimply head over to ChatGPT and ask for pattern ideas that can be generated with AI.\\n\\nChatGPT Dashboard\\n\\nNow, these are quite broad niche ideas, so let’s narrow them down a bit.\\n\\nAsk ChatGPT to give you 10–20 sub-niches for your favorite category.\\n\\nChatGPT Dashboard\\n\\nI really like flower designs, so let’s go with that for today’s story.\\n\\nNow that we have the ideas we need, let’s head over to Leonardo.Ai to generate our patterns.\\n\\nWith a specific prompt included in my Leonardo prompt bundle, I generated this\\xa0aesthetic daisy flower pattern.\\n\\n\\n\\nNow how do you make money selling these AI generated patterns?\\n\\nLike I said, there are two ways to go about it.\\n\\n1. Sell them as Digital Paper on Etsy and Creative Fabrica\\n\\nI love digital products, so this is method that’s most attractive to me.\\n\\nI sell my AI generated patterns as digital papers on Creative Fabrica and this is how one of my listings look.\\n\\nImage Of My Digital Paper Pack On Creative Fabrica\\n\\nYou can also sell these AI-generated patterns on Etsy, as you’d be killing two birds with one stone.\\n\\n2. Sell Your Patterns with Print On Demand\\n\\nPrint on Demand is a business model where you upload the digital copy of your AI-generated pattern to a print provider’s website.\\n\\nThese print providers will then handle the entire production, shipping, and delivery of your products.\\n\\nPhoto by Jonathan Beckman on Unsplash\\n\\nSo you’re basically selling your pattern as a physical product without handling any of the hard work that follows.\\n\\nThe best part is that these print providers don’t make money until you as you’ll only be paying for their services when you get an actual sale.\\n\\nBut it doesn’t end there.\\n\\nWhat if I told you there were a dozen of these print providers that actually had built-in marketplaces?\\n\\nAnd with their free traffic, your only job is to\\n\\ncreate your image\\n\\nand publish it as an optimized listing on their website.\\n\\nSome of the best print on demand marketplaces I recommend for your patterns are\\n\\nZazzle with 14.1 million monthly visitors\\n\\nZazzle\\'s Traffic Insights by SimilarWeb\\n\\nAs for Society 6, I found an income report on the catcoq.com blog where a seller made over $3,777 in just 7 days.\\n\\nImage by Cat Coquillette on Catcoq.com\\n\\nIdea No 3: Start a Tshirt Business\\n\\nTo sell tshirts online, we’ll still be going the print on demand route.\\n\\nYou provide the t-shirt designs while your printing company takes care of the production, deliveries, and customer service as needed.\\n\\nTo create a profitable t-shirt business with happy customers, you need good designs.\\n\\nOnce you have good designs, 80% of the work is done.\\n\\nRegarding your marketing strategy, once again, there’s no need to worry.\\n\\nYou can make use of Print on Demand platforms with inbuilt marketplaces like I mentioned already.\\n\\nZazzle\\n\\nTeepublic\\n\\nand Society 6\\n\\nSo how can we create high quality T-shirt designs?\\n\\nObviously, you’ll need to do your research with ChatGPT to find profitable t-shirt ideas.\\n\\nChatGPT Dashboard\\n\\nFor this example, I’ll be creating a Vegan lifestyle t-shirt.\\n\\nNow, I need to go over to Canva to find a t-shirt template to use as the prototype design.\\n\\nI typed in \"Vegan T-shirt\" on Canva’s search bar to find this template which will now be our prototype design.\\n\\nCanva\\'s template library\\n\\nUsing the same prompt I used to generate Clipart, all I have to do now is generate a similar Clipart to the template I found on Canva.\\n\\nImage Generated By Leonardo Ai\\n\\nNow replace the Clipart with your AI generated Clipart\\xa0, then Edit the template quote, fonts and theme.\\n\\nBy repeating this cycle for just one hour every day, you’ll build up a collection of awesome designs that can make you Passive income.\\n\\nI found a guy doing this exact side hustle.\\n\\nRyan Rogue is really smart and uploads the same designs to over 5 marketplaces with free traffic.\\n\\nHere’s how much he made in passive income from these Marketplaces in one month:\\n\\nScreenshot of Ryan Rogue\\'s Blog\\n\\nThis goes to show that Etsy and Zazzle are just 2 of the many marketplaces you could be selling your tshirts on.\\n\\nIdea No\\xa04: Sell Stickers\\n\\nWe all love cute stickers, don’t we?\\n\\nThey are pretty, and they make our gadgets and journals look a lot less boring.\\n\\nWell, what if I told you it was possible to start your own sticker shop with the help of AI?\\n\\nI haven’t personally tried this side hustle, but I know of shops that are making thousands of dollars selling stickers on\\n\\nEtsy\\n\\nZazzle\\n\\nRedbubble\\n\\nTeepublic\\n\\nand Pinterest.\\n\\nStarting your sticker shop is pretty easy.\\n\\nOnce again, Ask ChatGPT for sticker niches and keep asking until you find a low competition keyword that sticks.\\n\\nChatGPT Dashboard\\n\\nThen, on Leonardo AI, use the sticker prompt prompts until you generate a sticker image you’re proud enough to sell.\\n\\nHere’s a sticker I generated using Leonardo.Ai\\n\\nImage Generated By Leonardo Ai\\n\\nTo illustrate the demand on Etsy for stickers, I found this sticker shop that sold panda stickers\\n\\nIn this case, the sticker was sold as a digital product but still managed to garner over 7k reviews.\\n\\nScreenshot of TheDigitalCraftCo\\'s listing\\n\\nAnd at a price range of $2.66, this listing alone has made its seller at least $18,620.\\n\\n5. Sell Recipe eBooks on Amazon KDP\\n\\nThe way this side hustle works is quite simple.\\n\\nYou create eBooks with the help of AI and sell them on large marketplaces like Amazon.\\n\\nBut why did I choose recipe books?\\n\\nWell, it’s because the niches here are endless, and can be completely automated by AI.\\n\\nYou can use\\n\\nChatGPT for your profitable niche research\\n\\nChatGPT Dashboard\\n\\nLeonardo AI for generating the AI images\\n\\nHere, I generated an image of a Vegan cake with Yoghurt.\\n\\nImage Generated By Leonardo Ai\\n\\nFinally, we’ll let ChatGPT handle most of the remaining work, such as your book’s outline, chapter pages, and recipe content.\\n\\nChatGPT Dashboard\\n\\nThen, on Canva, find an eBook template to compile all of these images and recipes into a complete eBook.\\n\\nCanva\\'s Free Template Library\\n\\nNow, I used to sell books on Amazon KDP and made a good amount of money during that time.\\n\\nScreenshot by Author\\n\\nSo make sure you try out this side hustle at the very least.\\n\\nThis is Amazon KDP owned by Amazon. The Amazon!!\\n\\nIt’s very easy to start, yet so profitable.\\n\\nConclusion\\n\\nI have so many more ideas, but I recently received a comment from a reader saying that my stories were way too long to read through.\\n\\nSo on that note, I’ll only be sharing these 5 AI art side hustles.\\n\\nAs for readers who are curious for more ideas, you can also sell your AI art as\\n\\nStock photos on AdobeStock and Freepik\\n\\nNursery Wall Art print on Etsy and Pinterest\\n\\nColoring books or printables on Amazon KDP and Etsy\\n\\nPhoto by Lucas Alexander on Unsplash\\n\\nWow, that was a mouth full.\\n\\n8 profitable side hustles you could basically start with just the help of a free AI art generator like Leonardo.AI.\"\\n\\nNow, I’d be lying if I told you that generating high-quality AI images was as easy as typing in any prompt that comes to your mind.\"\\n\\nBut No!\\n\\nThe thing about AI Art is that it works purely on the principle of garbage in, garbage out.\\n\\nSo when you input a low quality prompt into Leonardo AI, you’ll most likely get a subpar output.\\n\\nHere’s an example of how the right prompt makes all the difference.\\n\\nThis first image was my first attempt at creating Clipart on Leonardo AI.\\n\\nImage Generated By Leonardo Ai (Low quality)\\n\\nBut then I tweaked my prompt and was able to generate a more high quality image of a bagel.\\n\\nImage Generated By Leonardo Ai\\n\\nSo before you go on to generate a bunch of AI art on Leonardo.ai, you need to understand that it takes a level of expertise.\\n\\nAnd you need to be ready to learn\\n\\nhow to create the perfect prompt for your images\\n\\nand which of Leonardo’s Art models would suit the art style you’re looking for.\\n\\nFor this, you need to practice on Leonardo.Ai and play around with its tools.\\n\\nThat was exactly what I did, and in less than three months or so, I became quite proficient at generating images that were highly sellable.\\n\\nYou can also\\n\\nskip the entire learning process\\n\\ncopy my exact AI art prompts (word for word)\\n\\nand the AI model I used for each of them.\\nJust by downloading my Leonardo Prompt Bundle.\\n\\nThe Leonardo Prompt Bundle\\n\\nWith this bundle, you’ll get all of my best-performing prompts for generating images across all genres, including cliparts.\\n\\nAnd, for an affordable fee, you’ll be able to download the exact prompt I use to generate my Clipart, as well as other sellable AI images.\\n\\nYou can click here to download the Leonardo Prompt Bundle.'}},\n",
       "  {'id': 'abb6f463e3cb',\n",
       "   'title': 'I Sold on Gumroad For 6 Months',\n",
       "   'subtitle': 'How Much Did I Make and How Can A Beginner Start Something Similar?',\n",
       "   'author': '8c8e5b7182ef',\n",
       "   'publication_id': '*Self-Published*',\n",
       "   'published_at': '2024-02-12 22:51:09',\n",
       "   'last_modified_at': '2024-02-12 23:10:08',\n",
       "   'tags': ['passive-income',\n",
       "    'make-money-online',\n",
       "    'gumroad',\n",
       "    'notion',\n",
       "    'side-hustle'],\n",
       "   'topics': ['marketing', 'startups'],\n",
       "   'claps': 434,\n",
       "   'voters': 71,\n",
       "   'word_count': 2075,\n",
       "   'responses_count': 24,\n",
       "   'reading_time': 9.430188679245283,\n",
       "   'url': 'https://medium.com/@iampaulrose/i-sold-on-gumroad-for-6-months-abb6f463e3cb',\n",
       "   'unique_slug': 'i-sold-on-gumroad-for-6-months-abb6f463e3cb',\n",
       "   'image_url': 'https://miro.medium.com/1*_nf5axcmGlNl5uk7Bj4Xuw.jpeg',\n",
       "   'lang': 'en',\n",
       "   'is_series': False,\n",
       "   'is_locked': False,\n",
       "   'is_shortform': False,\n",
       "   'top_highlight': 'Because zero traffic = zero sales.',\n",
       "   'content': {'id': 'abb6f463e3cb',\n",
       "    'content': 'I Sold on Gumroad For 6 Months\\n\\nHow Much Did I Make and How Can A Beginner Start Something Similar?\\n\\nI’ve tried so many Gumroad challenges over the past year, and today’s story is about yet another one of them.\\n\\nI remember hearing about Gumroad for the first time and thinking to myself how awesome of a business idea it was.\\n\\nJust create a product\\n\\nOptimize for conversion\\n\\nMarket your product\\n\\nAnd enjoy watching new emails from Gumroad notifying you that you’ve made a new sale.\\n\\nScreenshot of Gumroad\\'s Sales Notification\\n\\nTo me, it was an attractive passive income stream, and I really wanted to experience it firsthand.\\n\\nNow, today’s story isn’t really going to be about me. Sure, I made thousands of dollars selling on Gumroad but how does that really serve you.\\n\\nNow, today’s story isn’t really going to be about me.\\n\\nSure, I’ve made thousands of dollars selling on Gumroad, but how does that really serve you?\\n\\nI need you to leave this story feeling inspired and ready to start something as profitable as my store on Gumroad.\\n\\nPhoto by Jp Valery on Unsplash\\n\\nSo it’s going to be less about me and more about how I did it.\\n\\nHow I Came Across The Idea Of Selling Digital Products on Gumroad\\n\\nI won’t even lie, I was pushed into it by my ego after seeing a tweet where a 17-year-old had made over 500k selling Notion templates on Gumroad.\\n\\nScreenshot Of Easlo\\'s Tweet On Twitter\\n\\nI remember saying to myself,\\n\\n\"That’s a 17-year-old. How old are you again?\"\\n\\nWhile I wasn’t jealous or envious of his success, I knew I had to build something equally profitable for myself.\\n\\nSo I got to work.\\n\\nHow To Make Money Selling Digital Products on Gumroad\\n\\nNow, while I sell eBooks on my Gumroad shop, I understand how difficult it can be to write a quality and in-demand eBook.\\n\\nNot to mention how much time goes into\\n\\nFinding the right topic\\n\\nWriting the first draft\\n\\nProofreading and Designing the eBook\\n\\nWhile building up you’d product sales page on Gumroad\\n\\nSince my goal for this story is to help show you the easiest way forward, we’ll be going the Easlo route.\\n\\nWith Notion templates!\\n\\nPhoto by Pauline Bernard on Unsplash\\n\\nNow What are Notion Templates?\\n\\nFirst of all, if you don’t know what Notion is, you probably don’t watch YouTube videos about productivity, and that’s okay.\\n\\nBut if you did, you would know how viral Notion has become in just a few years since its launch.\\n\\nNotion is a productivity software that offers limitless functionality for anyone who wants to stay productive and organized.\\n\\nAnd how many of these people of there in the world?\\n\\nYou can only imagine!\\n\\nFor one, three of YouTube’s most popular productivity YouTubers each have millions of subscribers.\\n\\nAli Abdaal with 5.21 million subscribers\\n\\nThomas Frank with 2.96 million subscribers\\n\\nMatt D’Avella with 3.79 million subscribers\\n\\nOne of those YouTubers, Thomas Frank, created an entire channel to share Notion tutorials and sell his Notion templates.\\n\\nIn less than a year, that channel made him $1,000,508 from the Notion templates he sold in his videos.\\n\\nScreenshot of Thomas Frank\\'s Gumroad Income Breakdown\\n\\nThe demand for productivity tools and templates is obviously high, and Notion makes it so easy for anyone to tap into this market.\\n\\nAnd just in case you’re bothered, yes, like Canva,\\n\\nYes, Notion allows you to share editable links to your templates for others to use, even with a free account on their platform.\\n\\nI’m really considering launching an entire Gumroad shop for Notion templates\\n\\nBecause for how easy it is to start this business, I definitely want in.\"\\n\\nI even bought an eBook called \\'Notion Millions\\' to learn the ins and outs of this business.\\n\\nScreenshot Of The Notion Millions eBook\\n\\nSo, based on my personal experience running a profitable Gumroad shop, coupled with the eBook I bought for more specific tips,\\n\\nHere’s how you can launch your profitable Notion template business on Gumroad.\\n\\nStep 1: Find Profitable Ideas & Build a Library Of Those Ideas\\n\\nNow, here’s a reason why templates are more profitable than eBooks.\\n\\nPeople buy them in bundle.\\n\\nIf you’ve ever bought anything on Gumroad, you would have noticed Gumroad’s checkout page upsell feature.\\n\\nThis feature allows Gumroad to recommend other products from your shop to buyers before they pay at checkout.\\n\\nPhoto by Mark OFlynn on Unsplash\\n\\nThat means if they came in for a specific product, they might leave with a cart full of all your products.\\n\\nNow, the way templates thrive on human psychology is crazy.\\n\\nWhen people buy an eBook, they literally have to block out 3-4 hours or even an entire day from their busy schedule to read it.\\n\\nBut with templates, it\\'s different.\\n\\nWhen people buy templates, especially for Notion, it’s to simplify their workflow as they go.\\n\\nSo based on psychology, which is more feasible for a potential buyer\\n\\nAdd an extra eBook to your cart and plan out more hours of your time to read it\\n\\nOr Add an extra template and simplify your life even more\\n\\nIt\\'s obviously the second option.\\n\\nBuyers would rather buy more templates than more eBooks because it just makes sense for them to do so.\\n\\nSo when I say more templates in your shop mean more revenue, I mean it word for word.\\n\\nPhoto by Annie Spratt on Unsplash\\n\\nBut how do we find endless ideas to create templates on?\\n\\nWell, there\\'s a trick I learned from the Notion Millions eBook.\\n\\nIt was an entire chapter outlining niche research and idea generation with ChatGPT.\\n\\nA snapshot of the Notion Millions eBook\\n\\nThis chapter opened my mind to the myriad of markets I could serve by selling Notion templates for the endless niches suggested by ChatGPT\\n\\nusing a prompting technique provided by the author.\\n\\nAnd I highly recommend you read this book if you ever run out of ideas for Notion templates on your Gumroad store.\\n\\nYou can\\xa0click here to grab the Notion Millions eBook.\\n\\nRemember also to keep in mind the demand in your market for any template ideas ChatGPT recommends.\\n\\nTo do this, type every idea into Etsy’s Marketplace search bar to see if there are any templates with thousands of reviews.\\n\\nFor example, I found dozens of pregnancy trackers on Etsy, each with hundreds of reviews.\\n\\nScreenshot Of Etsy\\'s Search Results\\n\\nWith this demand analysis strategy, you can almost predict whether or not people will even want a product in the niche you have chosen.\\n\\nBecause where there\\'s demand, there\\'s money to be made.\\n\\nStep 2: Know What Makes a Gumroad Store Profitable\\n\\nThis is where my 6 months worth of experience comes to play.\\n\\nAnd without any gatekeeping, here are the three elements that can make any Gumroad store profitable.\\n\\n1. Your Product’s Perceived Value\\n\\nWhen potential buyers land in your store, what is their first impression of your product?\\n\\nPhoto by Hal Gatewood on Unsplash\\n\\nDo they think it looks professional or do they think it’s way too spammy and suspicious?\\n\\nDo they think it’s worth their money, or is it just a waste of their money?\\n\\nIdeally, everything on your Gumroad sales page should work toward convincing your potential buyers that they’ve found the product they’ve been searching for.\\n\\nYour cover should look chic and professional, like a bestseller would on Amazon.\\n\\nYour sales page should be convincing enough while providing sufficient details to set the right expectations for what potential buyers would receive.\\n\\nFinally, the title shouldn’t sound cookie-cutter; be creative and make potential buyers feel excited about what they’re about to spend on, rather than anxious.\\n\\n2. Traffic\\n\\nThis has to be the single most important element of a profitable shop on Gumroad.\\n\\nBecause zero traffic = zero sales.\\n\\nAnd so, you can have the best template in the world and still make no money just because you got this part wrong.\\n\\nPhoto by Towfiqu barbhuiya on Unsplash\\n\\nI mean, how are buyers even supposed to know that your problem-solving template exists when you don’t market it to them?\\n\\nThankfully, it doesn’t really matter where you find these buyers, just find them.\\n\\nEaslo used Twitter\\n\\nThomas Frank used YouTube\\n\\nI use Medium\\n\\nJust take a minute or two to think about who it is you’re creating your template for.\\n\\nAre they business owners or entrepreneurs? Use LinkedIn\\n\\nAre they college students preparing for an exam? Use TikTok\\n\\nIs it a more generic product idea, use YouTube\\n\\nMy point is, if you want to generate passive income on Gumroad, you need to spread the word about your product.\\n\\nPhoto by dole777 on Unsplash\\n\\n3. Messaging\\n\\nNow marketing doesn’t end with picking the right platform; you also need to rethink your messaging.\\n\\nYou can’t sell a gym workout tracker to a pregnant mom whose focus is staying healthy during her pregnancy.\\n\\nA pregnancy tracker might be of help, but definitely not a workout tracker.\\n\\nWhy?\\n\\nBecause it’s simply useless to them at that point in time.\\n\\nAt the core of a profitable marketing strategy is the right messaging.\\n\\nAnd that\\'s where a lot of people get it wrong.\\n\\nIt\\'s not about posting everyday and staying consistent.\\n\\nThe real question is: are you posting the right content?\\n\\nA YouTube video featuring the top productivity tools for bookkeepers, with your template listed as part of those tools,\\n\\nwill bring in more sales than a generic video on how to achieve your goals in 2024.\\n\\nPhoto by Azamat E on Unsplash\\n\\nThe point I\\'m trying to make is simple.\\n\\nPosting everyday is smart but you still need to ask one simple question; how effective is your messaging?\\n\\nStep 3: Launch Your First Notion Template\\n\\nCreating a sellable template might sound overwhelming, but let me break it down.\\n\\nWhat if I told you it was possible to ask ChatGPT for the entire framework of your Notion template?\\n\\nWell that’s another trick I learnt from the eBook I bought.\\n\\nNow I know that a pregnancy workout tracker will need the following section on Notion and more, as suggested by ChatGPT.\\n\\nChatGPT Dashboard\\n\\nNow, you’re going to need to turn this framework into a full-blow notion template.\\n\\nAnd to create your first template, you’ll need to learn how Notion works and understand the basics.\\n\\nI mean, coupled with the trick where ChatGPT generates the entire outline for your Notion template,\\n\\nyour only job is to turn that framework into a full-blown Notion template.\\n\\nThankfully, the notion Millions eBook also has a section that walks you through creating aesthetic Notion templates, even if you’re a complete beginner to Notion.\\n\\nOnce you’ve mastered the basics of Notion, creating and launching a new template should take you no less than a single day of focused work.\\n\\nIf one day equals one template, 30 days of focused work should leave you with a library of profitable templates.\\n\\nAnd With ChatGPT & the Notion Millions eBook there to help, the whole process simply becomes way too effortless.\\n\\nHow Much I’ve Made After 6 Months Of Selling Digital Products On Gumroad\\n\\nWithin the last 6 months, I’ve made a total of $3688.06.\\n\\nScreenshot By Author\\n\\nAnd while this revenue is quite impressive for the $10 digital product I sell,\\n\\nIt’s nothing compared to what Easlo and Thomas Frank make from selling their Notion templates on Gumroad.\\n\\nConclusion\\n\\nI can’t get enough of digital products. They’re very easy to create, yet so profitable.\\n\\nNot to mention the fact that you only need to create them once, after which you can set up systems that generate endless sales passively.\\n\\nIf you find that writing eBooks is way too cumbersome for your type of person, try Notion templates.\\n\\nWith how easy they are to create, you should be able to build your library of profitable templates in just a single weekend.\\n\\nLike\\xa0I\\xa0said\\xa0earlier, I bought the Notion Millions eBook because I wanted to try a new side hustle similar to selling eBooks on Gumroad.\\n\\nAnd, as a beginner to Notion like I am, it was definitely helpful.\\n\\nThe Notion Millions Guide by James Renouf\\n\\nWith everything from\\n\\nThe exact niches to create Notion templates in ( so you know what sub niches to ask ChatGPT for)\\n\\nTo ChatGPT hacks for creating Notion templates even as a complete beginner\\n\\na Beginner’s Guide to basics of creating an aesthetic template on Notion\\nand much more\\n\\nI’d say this guide was definitely worth the pay and I highly recommend it.\\n\\nSo if you’re interested in this side hustle, you should start learning and improving your Notion skills with the Notion Millions Guide.\\n\\nYou can check out the Notion Millions eBook here.\\n\\nNote: There are affiliate links in the article and if you buy something, I’ll get a commission at no extra cost to you.\\n\\nThis content is free, and by using these links, You’ll be supporting my work & that means a whole lot to me.'}},\n",
       "  {'id': '1c0e84854e4e',\n",
       "   'title': 'How To Write An eBook and Actually Make Passive Income',\n",
       "   'subtitle': 'Without Spending Month Writing Your First Draft',\n",
       "   'author': '8c8e5b7182ef',\n",
       "   'publication_id': '*Self-Published*',\n",
       "   'published_at': '2024-02-10 21:44:02',\n",
       "   'last_modified_at': '2024-02-10 21:52:01',\n",
       "   'tags': ['passive-income',\n",
       "    'side-hustle',\n",
       "    'make-money-online',\n",
       "    'gumroad',\n",
       "    'online-business'],\n",
       "   'topics': ['writing'],\n",
       "   'claps': 1514,\n",
       "   'voters': 137,\n",
       "   'word_count': 1679,\n",
       "   'responses_count': 32,\n",
       "   'reading_time': 7.835849056603774,\n",
       "   'url': 'https://medium.com/@iampaulrose/how-to-write-an-ebook-and-actually-make-passive-income-1c0e84854e4e',\n",
       "   'unique_slug': 'how-to-write-an-ebook-and-actually-make-passive-income-1c0e84854e4e',\n",
       "   'image_url': 'https://miro.medium.com/0*ZwHe-qqWjx5s5fup',\n",
       "   'lang': 'en',\n",
       "   'is_series': False,\n",
       "   'is_locked': False,\n",
       "   'is_shortform': False,\n",
       "   'top_highlight': 'Medium + quality eBooks = thousands of dollars in passive.',\n",
       "   'content': {'id': '1c0e84854e4e',\n",
       "    'content': 'How To Write An eBook and Actually Make Passive Income\\n\\nWithout Spending Month Writing Your First Draft\\n\\nWhat if I told you that the key to receiving daily passive income notifications was already in your hands?\\n\\nYes!\\n\\nI make thousands of dollars from the simple but high quality eBooks I sell on Gumroad, and I know firsthand how profitable it can really get.\\n\\nPhoto by Lucas Benvenuto on Unsplash\\n\\nNow, writing an eBook that actually makes money isn’t a far-fetched goal.\\n\\nIn fact, it’s 100% possible to start and launch your first eBook in less than a week.\\n\\nAnd no,\\n\\nyou don’t have to be a top writer in J.K. Rowling’s league to write an eBook that makes money.\\n\\nOr spend weeks penning down words while battling writer’s block.\\n\\nAll you need is what you already have: your knowledge and a very smart hack I’ll be sharing in today’s story.\\n\\nThat said, here are the five simple steps I follow to write ebooks that generate passive income.\\n\\nStep 1: Brainstorming What Your Strengths Are\\n\\nIf you search deep enough, you’ll find something in particular that no one does better than you.\\n\\nThink of the skills and knowledge you have that friends, family, or team members can’t get enough of your advice on.\\n\\nPhoto by Kenny Eliason on Unsplash\\n\\nImagine the thousands of other people in the world who could benefit from that knowledge when you share it in a more accessible way.\\n\\nQuality eBooks feel like full-blown courses, and the only way you can create something as valuable is when it’s a topic you love and are knowledgeable about.\\n\\nBut it doesn’t just end with picking a topic you’re passionate about.\\n\\nYou still need to ask a very simple question: How profitable is my idea?\\n\\nPhoto by bruce mars on Unsplash\\n\\nYou could possess knowledge about a topic and still make no money because some topics are simply more profitable than others.\\n\\nSince the goal is to write ebooks that actually make money, we need to validate our potential eBook ideas to ensure they meet certain demand criteria.\\n\\nIdeally, you want to stick with topics that have high demand because more demand ultimately means higher revenue potential.\\n\\nTo check this metric, I use Amazon’s marketplace, which has the largest category of eBooks in the world.\\n\\nSimply type your eBook’s topic into Amazon’s search to see how eBooks in that category have sold.\\n\\nCheck their ratings and reviews, and when there are enough ebooks with good ratings and sales, you know there’s definitely a market.\\n\\nHealthy relationships, for instance, are a good book topic with an obvious demand.\\n\\nScreenshot Of Amazon\\'s Product Listing\\n\\nStep 2: Creating Your Outline\\n\\nOnce you’ve picked out the perfect eBook topic that meets the profit-passion criteria, you need to work on creating the perfect outline.\\n\\nYour outline is the structure of your content, and a weak outline will ultimately result in a low-quality book.\\n\\nWe don\\'t want that, do we?\\n\\nThe way out is to think like our potential buyers.\\n\\nWhat would they want in an eBook about \"healthy relationships\".\\n\\nHow can you structure your eBook in a way that meets the needs intended by your potential buyers?\\n\\nFor some of the ebooks I’ve written, I had to take days off to brainstorm what they were going to be about.\\n\\nPhoto by Magnet.me on Unsplash\\n\\nI wanted buyers to feel like they made the right choice by purchasing my eBook, and it had to start with having a high-quality outline.\\n\\nSo, think again: what chapters should be included in your eBook to assist buyers in achieving their goals?\\n\\nWrite it down in a Google Doc to be included in your eBook.\\n\\nStep 3: Steal My eBook Writing Hack\\n\\nEarlier in this story, I mentioned having a hack that could literally change the way we think about writing eBooks.\\n\\nWhy? Because I know from firsthand experience how hard writing eBooks can be.\\n\\nFrom staying consistent to using the right words and fighting writer’s block, there’s a whole lot to deal with when writing an ebook the traditional way.\\n\\nPhoto by Rendy Novantino on Unsplash\\n\\nI just couldn’t cope with how cumbersome my writing projects had become, so I resolved to finding the lazy way out.\\n\\nSince the whole point of creating an eBook was to pass quality information on to my buyers,\\n\\nI had to figure out a better way to extract this information without having to write it down.\\n\\nThen, I had a genius idea\\n\\nI was going to voice out my opinion and then transcribe those recordings into text.\\n\\nWith this new change, writing quality eBooks and launching them all in less than a week started to feel more realistic.\\n\\nBecause once I had my outline, I simply had to talk into my recorder for about an hour, during which I’d share quality tips as if speaking to a close friend, and that was it.\\n\\nPhoto by Firmbee.com on Unsplash\\n\\nThese voice recordings would literally be the first draft that would then be converted to text and refined into what we traditionally know as eBooks.\\n\\nStep 4: Transcribe, Design and Package\\n\\nWith an hour’s worth of valuable recordings in hand, the logical next step is to transcribe your audio into text.\\n\\nYou can keep this step 100% free by manually going through your recording and transcribing what you previously voiced out.\\n\\nOr save yourself the stress by outsourcing the step to a transcriptionist who does the work instead.\\n\\nThen, on Canva, find free ebook templates that match the overall theme of your book and turn your text file into something more aesthetic.\\n\\nCanva\\'s Free Template Library\\n\\nFinally, remember to download your file as a PDF that can easily be shared as an instant download when people make a purchase.\\n\\nStep 5: Getting Potential Buyers To Your Ebook\\n\\nThere’s absolutely no point in creating a story on how to write an eBook if I don’t show you how to sell it.\\n\\nBecause it’s possible to spend months writing the perfect eBook, only to have it flop on its launch due to this one element.\\n\\nMarketing.\\n\\nBecause Quality products with quality marketing is what makes you passive income.\\n\\nNow where exactly do you sell this ebook that you put so much effort into creating?\\n\\nI could easily list a bunch of social media platforms, tell you to pick one of them, post every day, and stay hopeful.\\n\\nPhoto by dole777 on Unsplash\\n\\nBut I won’t!\\n\\nInstead, I’m going to share the platform that actually made me over $3,688.08 in total eBook sales on Gumroad, even when I knew nothing about selling online.\\n\\nScreenshot by Author\\n\\nSo drumrolls, please!\\n\\nThe platform I use for marketing my eBooks to where it now makes me thousands of dollars, is Medium.com.\\n\\nIn my opinion, Medium is easily the best place for beginners looking to build a monetizable audience and make passive income.\\n\\nIn comparison to other traffic platforms, I love Medium because\\n\\nall I do is write (no editing or complex creation processes)\\n\\nthere’s no reciprocity attached to going viral; you grow whether or not you engage with others.\\n\\nand even without premium content creation gadgets, starting with just $0, you can still grow an audience that loves what you write about and wants to buy from you.\\n\\nPhoto by Clay Banks on Unsplash\\n\\nBut that’s not the reason why I think Medium is the best platform for anyone looking to make passive income with ebooks.\\n\\nWhat I’ve come to understand is that the demographic on Medium.com is already inclined to pay for valuable information.\\n\\nAs of 2021, stats have shown that out of all the readers available on Medium, 700,000 of them pay for a monthly subscription.\\n\\nScreenshot Of Google\\'s Snippet\\n\\nSince these readers already pay a monthly subscription to access valuable content on Medium, paying an extra fee for an ebook from a writer they trust is simply a walk in the park.\\n\\nThe growth potential on Medium is also very impressive.\\n\\nI published my first post on the 7th of August 2024 and in just 30 days, I had already grown to having my first 1k followers\\n\\n6 months have now passed and I’m 400 followers away from having 40k followers.\\n\\nScreenshot By Author\\n\\nOne of my clients also tried out this traffic platform and grew by 2.2k in just 2 months.\\n\\nScreenshot Of Jordan Gibbs\\'s Profile on Medium\\n\\nAs long as you have something of value to share in a fairly digestible way, Medium should be the next traffic platform on your list to try.\\n\\nBut before I end this story, here’s a simple plan you can follow to grow your first 1k followers on Medium and make your first sale.\\n\\nWrite down 30 story ideas for topics that seamlessly pitch your ebook as a call to action\\n\\nWrite one story everyday (focus on quantity)\\n\\nHave one takeaway for readers in each story (focus on quality)\\n\\nLearn how to write high quality stories that spark emotions with your readers\\n\\nFinally, give first, pitch later (don’t spam your eBook link, you won’t get sales that way)\\n\\nAnd if you’re curious about what I did in just 30 days to\\n\\ngo viral,\\n\\ngrow thousands of followers,\\n\\nand make thousands of dollars...\\n\\nI highly recommend you check out my Medium Income Playbook.\\n\\nThe Medium Income Playbook\\n\\nIn this ebook, I share my exact thought process behind\\n\\nFinding endless profitable content ideas related to your specific topic\\n\\nCreating click-worthy titles and viral headlines to capture readers\\' attention.\\n\\nCreating engaging stories that convert readers into loyal subscribers and even buyers.\\n\\nMy writing principles (Quantity vs quality, KLT principle and the MVA principle)\\n\\nAnd I’ll also share my personal experiences on how I managed to grow to over 37k followers (as I speak) on Medium in less than 5 months.\\n\\nLiterally everything you need to go from zero followers to making passive income as a writer is in the Medium Income Playbook.\\n\\nSo If you want to start your very own profitable Medium page,\\n\\nCheck out the steps I personally tried out and have now shared in the Medium Income Hustle playbook.\\n\\nYou can click here to Grab The Medium Income Playbook.\\n\\nConclusion\\n\\nMedium + quality eBooks = thousands of dollars in passive.\\n\\nSo write that outline,\\n\\nrecord that first draft\\n\\nand launch an eBook that actually makes you passive income in 2024\\n\\nAlso, remember to download the Medium Income Playbook to learn what it takes to go viral on Medium.'}},\n",
       "  {'id': 'fc25899ff745',\n",
       "   'title': 'I Started a Cute & Profitable Side Hustle',\n",
       "   'subtitle': 'And I’m Loving It So Far',\n",
       "   'author': '8c8e5b7182ef',\n",
       "   'publication_id': '*Self-Published*',\n",
       "   'published_at': '2024-02-08 22:38:04',\n",
       "   'last_modified_at': '2024-02-08 22:46:38',\n",
       "   'tags': ['passive-income',\n",
       "    'side-hustle',\n",
       "    'make-money-online',\n",
       "    'ai',\n",
       "    'ai-art'],\n",
       "   'topics': ['marketing'],\n",
       "   'claps': 1770,\n",
       "   'voters': 191,\n",
       "   'word_count': 2102,\n",
       "   'responses_count': 47,\n",
       "   'reading_time': 10.232075471698113,\n",
       "   'url': 'https://medium.com/@iampaulrose/i-started-a-cute-profitable-side-hustle-fc25899ff745',\n",
       "   'unique_slug': 'i-started-a-cute-profitable-side-hustle-fc25899ff745',\n",
       "   'image_url': 'https://miro.medium.com/0*0SGdByWaPIXUmbaD',\n",
       "   'lang': 'en',\n",
       "   'is_series': False,\n",
       "   'is_locked': False,\n",
       "   'is_shortform': False,\n",
       "   'top_highlight': '',\n",
       "   'content': {'id': 'fc25899ff745',\n",
       "    'content': 'I Started a Cute & Profitable Side Hustle\\n\\nAnd I’m Loving It So Far\\n\\nI love babies, no doubt.\\n\\nThey’re cute, and you can never really say \"no\" to them.\\n\\nNow, these babies aren’t even mine, and I still can’t resist being the best I can be to them.\\n\\nPhoto by Jonathan Borba on Unsplash\\n\\nHow much more, their parents?\\n\\nBut Why Is All Of This Back Story Even\\xa0Necessary?\\n\\nWell, studies show that new parents are willing to invest thousands of dollars in creating the perfect crib and nursery for their newborn babies.\\n\\nKnowing this, I had an awesome idea.\\n\\nYou know those beautiful pieces of artwork that parents hang in their newborn baby’s room?\\n\\nI decided I was going to create and sell them.\\n\\nYes!!\\n\\nAnd while I knew for one that I sucked at design and illustration, I had a much better plan.\\n\\nI decided I was going to use a free AI generator to create the images for these nursery wall art.\\n\\nMade by Leonardo Ai\\n\\nThen use Canva to add text to those images\\n\\nEdited In Canva\\n\\nNow, with this AI tool, I wouldn’t have to worry about copyright infringement because I have the right to sell those images.\\n\\nAnd no, I wouldn’t have to worry about storing or shipping the inventory to customers.\\n\\nSo it was settled, I was going to start my own nursery wall art business.\\n\\nNow How Do I Know This Side Hustle\\xa0Works, Since I Also Just Started\\xa0It?\\n\\n1. Google Trends\\n\\nGoogle Trends is a research tool by Google, and with this tool,\\n\\nI was able to see that the term \"nursery art\" has remained steady in demand over the past 5 years.\\n\\nImage Screenshot Of Good Trends\\' Tool\\n\\nThis goes to show how evergreen the demand for nursery art really is.\\n\\n2. The Demand on Etsy\\n\\nJust with a quick search on Etsy, I found hundreds of listings, each with thousands of reviews.\\n\\nScreenshot Of The Powder\\n\\nSo with this many Etsy reviews for these cute images in the thousands, it only means people are buying.\\n\\nParents love their babies, and it shows clearly in how much they’re willing to spend to keep them comfortable.\\n\\nNow that we understand why nursery arts are a profitable product to sell, let’s take a look at the steps I took to set up this side hustle without any design experience.\\n\\nAnd when I say \\'No design experience,\\' I mean it, 100%.\\n\\nStep 1: Choose A Name and Brand For The Business\\n\\nThe name and brand for the business were fun things to settle on.\\n\\nWhile I wanted something cute, I also wanted to stay professional.\\n\\nSo I ran over to ChatGPT, gave it some details about the type of business I was starting, and watched to see what it came up with.\\n\\nAt the end of the day, I went with MilkyWay Lullaby for the brand name.\\n\\nCanva was my branding tool, with which I designed the logo and banner for my nursery art shop.\\n\\nMade in Canva\\n\\nFor me, this process took no less than 10 minutes.\\n\\nStep 2: Knowing How To Sell Your Wall Art\\n\\nOnce I had chosen a name for my new business, I needed to decide how I was going to sell that nursery art.\\n\\nNow, I had two options.\\n\\nOption\\xa0No\\xa01: Sell With The Print On Demand Model\\n\\nPrint on Demand is basically what it sounds like:\\n\\nLiterally, the products, wall art in our case, are being printed on demand.\\n\\nBut how does this work?\\n\\nWell, with this model, there’s the print provider who basically\\n\\nhandles product delivery,\\n\\ninventory storage,\\n\\nand shipping.\\n\\nPhoto by Angèle Kamp on Unsplash\\n\\nThe best part is that these print providers literally cater to every one of your buyers on demand.\\n\\nWith their large inventory of unlabeled products, your job is to upload your file in digital format while they handle the rest.\\n\\nNow you’re probably wondering how much it’s going to cost to have these print providers do the heavy lifting for you.\\n\\nWell, you’d be shocked to know that most print providers only get paid when you do.\\n\\nAnd so, there’s no fee attached to setting up your budget with them until you make a sale.\\n\\nOnce you make that sale, they take a cut of the revenue to cover their products and services.\\n\\nCrazy right!\\n\\nBut how do you find these free print providers?\\n\\nWell, read on because that’s not going to be a problem.\\n\\nOption No 2: Sell Your Art As Printable Digital Files\\n\\nWhile you had to upload your digital file onto the platform provided by your print provider if you chose the POD route,\\n\\nThere is an option to sell your nursery prints as printable digital products.\\n\\nIn this case,\\n\\nbuyers receive an instant download in high resolution\\n\\nand are responsible for handling the printing & canvasing themselves.\\n\\nPhoto by emarts emarts on Unsplash\\n\\nPrintable downloads are usually much cheaper than physical products when sold.\\n\\nBut it’s a win win either way.\\n\\nSure, with Print on Demand, you get to charge higher prices, but the commissions you receive will almost be the same as with digital products.\\n\\nNow, don’t get me wrong, no one said you had to choose one of these options over the other.\\n\\nIn fact, in my case, I’ve chosen to sell my nursery wall art as both a physical product and a digital download.\\n\\nStep 3: Knowing Where To Sell Your Nursery Wall Art\\n\\nFor step 3, I had to decide on which marketplace I was going to sell my nursery wall art.\\n\\nAnd with the many options I saw during my research, it took a lot of brainpower to decide which was going to be the best place to sell my nursery art.\\n\\nEither way, these were the marketplaces I chose.\\n\\nMarketplace No 1: Etsy\\n\\nEtsy shouldn’t come as a surprise on this marketplace list.\\n\\nBecause it’s literally the most profitable marketplace for selling creative items like wall art.\\n\\nPhoto by Oberon Copeland @veryinformed.com on Unsplash\\n\\nEtsy gets over 454.2 million monthly visitors every single month.\\n\\nEtsy\\'s Traffic Insights by SimilarWeb\\n\\nNow, I found a seller on Etsy selling something similar to the elephant nursery art I created with AI.\\n\\nGenerated by Leonardo Ai\\n\\nAnd In my opinion, my image looks more beautiful than the example I found.\\n\\nScreenshot Of A Similar Product a listing On Etsy\\n\\nWith over 1.8k views and priced at $5.66, this digital print has earned its owner at least $10.188\\n\\nScreenshot Of My Calculator\\n\\nNow aside from Etsy, there are two other profitable ways to make money selling nursery wall art.\\n\\nMarketplace No 2: Zazzle\\n\\nWith over 14.1 million monthly visitors, Zazzle is another marketplace where you could be selling your nursery wall art prints.\\n\\nZazzle Traffic Insights by SimilarWeb\\n\\nNow, while it’s not possible to directly calculate the potential revenue a product might have gotten on Zazzle,\\n\\nI found an elephant nursery art and knew right away it was a profitable product.\\n\\nHow?\\n\\nIt was tagged by Zazzle as a trending product with over 2.9k views.\\n\\nScreenshot Of Product By GalaxyDONUT On Zazzle\\n\\nKeep in mind that these 2.9k views represent free traffic on Zazzle’s marketplace.\\n\\nIt’s that viable!\\n\\nI also found a revenue report by a lady over at Lyfepyle blog who made $7047.07 from her Zazzle shop in just one month.\\n\\nImage from Tessa at Lyfepyle.com blog\\n\\nOne more thing I love about Zazzle is the fact that customers have the option to print your wall art.\\n\\nA digital download\\n\\nPrint\\n\\nOr both\\n\\nScreenshot Of Zazzle Wall Art Options.\\n\\nMarketplace No 3: Pinterest+ Teespring\\n\\nWhat if I told you that you could also go to the marketer’s route like me,\\n\\nBy creating your very own shop handles through a print provider independent of any marketplace?\\n\\nThe print provider in question is Teespring.\\n\\nSo, there’s obviously no leverage with traffic when you sell on Teespring, and you’ll have to handle all of the marketing yourself.\\n\\nNow, for my marketing, I’m choosing to focus heavily on Pinterest.\\n\\nBut Why Pinterest?\\n\\nWell, Pinterest gets over 1.1 billion monthly visitors every single month.\\n\\nPinterest Traffic Insights by\\n\\nBut it doesn’t end there,\\n\\nBecause the majority of these users are potential buyers planning to make a purchase.\\n\\nSo, having my product show up as a pin was the perfect marketing strategy for me.\\n\\nStep 4: Creating Your Wall Art Images\\n\\nHere comes the most important part of the whole process.\\n\\nThe design process.\\n\\nSell a crappy wall art image and you’ll only ever hear crickets\\n\\nSell something cute and emotionally binding for parents, and you’ll keep them coming back\\n\\nWithout any fluff, let’s look into how we can create high-quality nursery wall art using Leonardo.Ai.\\n\\n1. Find And Analyze Your Ideas\\n\\nNow, coming up with profitable ideas shouldn’t be a problem, especially now that we have ChatGPT around to help.\\n\\nSo, over on ChatGPT, ask for 10–20 niche or theme ideas perfect for nursery wall art.\\n\\nChatGPT Dashboard\\n\\nThen ask for sub-niches within any of those main niches to narrow down your search.\\n\\nI chose the animal niche for this example.\\n\\nChatGPT Dashboard\\n\\nTo further reduce competition, we’ll ask ChatGPT one last time for sub-niches in any of these subcategories.\\n\\nChatGPT Dashboard\\n\\nBased on the competition and demand, I found that the keyword \"praying mantis print\" was in\\n\\nhigh demand\\n\\nand had low competition, with fewer than 861 results.\\n\\n2. Generate Your Cute images\\n\\nWith a viable keyword in hand, it’s time to generate the image for my \"praying mantis print\" nursery art.\\n\\nFor this, I use my all-time favorite AI art generator, Leonardo.Ai, which is also free.\\n\\nWith the perfect prompt, Leonardo Ai spat out this image of a praying mantis in less than a minute.\\n\\nGenerated By Leonardo Ai\\n\\nStep 5: Processing Your Art Work\\n\\nNow that we have our cute images, all that’s left to do is to process them into full-blown nursery wall art.\\n\\nRemove The Background using Adobe’s Free background remover\\n\\nBackground Removed by Adobe\\'s Free background remover\\n\\nUpscale Your AI Generated Image to increase the quality (so it doesn’t pixelate when printed). I recommend Upscale Media Free Upscaler\\n\\nUpscale Media Upscaler\\n\\nChoose a Wall Art Dimension in Canva (4000 × 6000px)\\n\\nCreate a Custom Dimension in Canva\\n\\nAsk ChatGPT for a fancy quote related to prayer mantis.\\n\\nAdd your AI Image and the Fancy quote in Canva (edit the fonts and change up some colors)\\n\\nMade In Canva\\n\\nCreate Mockup images To Market Your Nursery Wall Art\\n\\nArt Mockup Made In Canva\\n\\nDownload your high resolution PNG files to upload on your given Marketplaces\\n\\nHow You Can Start This Side Hustle Too Even As a Beginner\\n\\nIt’s simple.\\n\\nYou’re going to learn how to create high quality AI images.\\n\\nBecause the thing about AI Art is that it works purely on the principle of garbage in, garbage out.\\n\\nSo when you input a low quality prompt into Leonardo AI, you’ll most likely get a subpar output.\\n\\nHere’s an example of how the right prompt makes all the difference.\\n\\nThis first image was my first attempt at creating Clipart on Leonardo AI.\\n\\nImage generated by Leonardo Ai with a low quality prompt\\n\\nBut then I tweaked my prompt and was able to generate a more high quality image of a bagel.\\n\\nImage Generated By Leonardo Ai\\n\\nSo before you go on to generate a bunch of AI nursery wall art on Leonardo.ai, you need to understand that it takes a level of expertise.\\n\\nAnd you need to be ready to learn\\n\\nhow to create the perfect prompt for your images\\n\\nand which of Leonardo’s Art models would suit the art style you’re looking for.\\n\\nFor this, you will need to practice on Leonardo.Ai and play around with its tools.\\n\\nThat was exactly what I did, and in less than three months or so, I became quite proficient at generating images that were highly sellable.\\n\\nYou can also skip the entire learning process\\n\\ncopy my exact AI art prompts (word for word)\\n\\nand the AI model I used for each of them.\\n\\nJust by downloading my Leonardo Prompt Bundle.\\n\\nThe Leonardo Prompt Bundle\\n\\nWith this bundle, you’ll get all of my best-performing prompts for generating images across all genres, including cliparts.\\n\\nAnd, for an affordable fee, you’ll be able to download the exact prompt I use to generate my Clipart, as well as other sellable AI images.\\n\\nYou can click here to download the Leonardo Prompt Bundle.\\n\\nConclusion\\n\\nI really wish I had more time to dedicate to this side hustle, but amidst\\n\\nwriting new stories,\\n\\nrunning my YouTube channel,\\n\\nand offering services, I know it’s going to be a bit hard.\"\\n\\nBut because I understand the potential in this side hustle, I’ll try my best to create new art prints every day for my shop to promote on Pinterest.\\n\\nPhoto by Christin Hume on Unsplash\\n\\nThat said, Etsy is by far the best option if you’re just starting and want the best chance of success with this side hustle.\\n\\nI’m simply trying Pinterest to prove to myself that Pinterest still works for making passive income.\\n\\nSo, if selling nursery wall art seems like the perfect side hustle for you to start, then\\n\\nYou should probably launch your own Etsy shop today.\\n\\nWhile you improve your Leonardo prompting skills on YouTube\\n\\nor get started right away with my Leonardo Prompt Bundle kit.\\n\\nYou can check out the Leonardo Prompt Bundle here.'}},\n",
       "  {'id': '9fe3b230f547',\n",
       "   'title': 'An Easy Canva Side Hustle To Try For Passive Income',\n",
       "   'subtitle': 'How To Make Your First Dollar Online ',\n",
       "   'author': '8c8e5b7182ef',\n",
       "   'publication_id': '*Self-Published*',\n",
       "   'published_at': '2024-02-06 22:21:42',\n",
       "   'last_modified_at': '2024-02-07 05:49:35',\n",
       "   'tags': ['amazon',\n",
       "    'chatgpt',\n",
       "    'passive-income',\n",
       "    'side-hustle',\n",
       "    'make-money-online'],\n",
       "   'topics': ['marketing'],\n",
       "   'claps': 775,\n",
       "   'voters': 112,\n",
       "   'word_count': 1945,\n",
       "   'responses_count': 21,\n",
       "   'reading_time': 9.139622641509435,\n",
       "   'url': 'https://medium.com/@iampaulrose/an-easy-canva-side-hustle-to-try-for-passive-income-9fe3b230f547',\n",
       "   'unique_slug': 'an-easy-canva-side-hustle-to-try-for-passive-income-9fe3b230f547',\n",
       "   'image_url': 'https://miro.medium.com/0*px8ihcYxmIlESEnH',\n",
       "   'lang': 'en',\n",
       "   'is_series': False,\n",
       "   'is_locked': False,\n",
       "   'is_shortform': False,\n",
       "   'top_highlight': '',\n",
       "   'content': {'id': '9fe3b230f547',\n",
       "    'content': 'An Easy Canva Side Hustle To Try For Passive Income\\n\\nHow To Make Your First Dollar Online\\n\\nDoes any part of this scenario sound familiar?\\n\\nyou’re at zero dollars in passive income made online\\n\\nand are a complete Beginner to making money online\\n\\nWell, you’re in the right place.\\n\\nBecause literally speaking, if the only thing you had to make passive income was a free Canva account,\\n\\nthis story will show you how to generate passive income in the next 30 days.\\n\\nPhoto by Blogging Guide on Unsplash\\n\\nWhile I’ve talked about this side hustle a thousand and one times, I still receive a particular question in my comments and DMs.\\n\\nRose, what\\'s the easiest way to make money online as a beginner?\\n\\nWell, you’re welcome to today’s story,\\n\\nWhere I’ll be showing you the Canva side hustle that made my first dollar online, even when I knew nothing about the internet.\\n\\nImage by Author\\n\\nWhat Is This Beginner Friendly Side\\xa0Hustle?\\n\\nNow if you haven’t guessed already, this easy Canva side hustle is called Amazon KDP.\\n\\nAmazon KDP stands for Amazon Kindle Direct Publishing.\\n\\nIt\\'s a platform by Amazon for authors.\\n\\nAmazon in itself needs no introduction.\\n\\nPhoto by Marques Thomas on Unsplash\\n\\nBeing the largest marketplace in the world, it unsurprisingly has a platform for authors to make money by uploading their books.\\n\\nNow when I say books, it’s not to scare you in any way.\\n\\nBecause who said you have to become the next J.K. Rowling to be called an author?\\n\\nNo one!\\n\\nWith the help of tools like Canva and, more recently, AI, creating books to sell for passive income has never been easier.\\n\\nBut Why Is This Side Hustle So\\xa0Easy?\\n\\nWell, because it\\'s Amazon we\\'re talking about here.\\n\\nThe Amazon.\\n\\nWith billions of monthly buyers every single month,\\n\\nPhoto by Clay Banks on Unsplash\\n\\nand millions of those people looking for books to buy,\\n\\nthere’s no better way to generate passive income than by leveraging the traffic on Amazon KDP.\\n\\nHow To Start Amazon KDP With Canva in 2024.\\n\\nHere’s how you can go from having just a free Canva account to making hundreds of dollars in passive income.\\n\\n1. Know What Types Of Books To Sell\\n\\nWith Amazon KDP, the ideas are endless.\\n\\nNow, don’t even limit your mind to the stereotype of best-seller novel books.\\n\\nBecause Amazon KDP offers a lot more than that.\\n\\nAmazon understands that not everyone was born with the gift to bring words together in a sellable way.\\n\\nAnd so they created an opportunity for both authors and non-authors to make money from their platform.\\n\\nSo if you’re an author, Good for you. Write like you normally would.\\n\\nPhoto by Kenny Eliason on Unsplash\\n\\nAnd once your masterpiece is ready, upload it as a PDF or doc file to Amazon’s billion-dollar marketplace.\\n\\nBut if you’re not an author, you should consider one of two options.\\n\\nLow Content Books\\n\\nOr ChatGPT written eBooks\\n\\nNow What Are Low Content Books?\\n\\nThese books are what they sound like, literally low content.\\n\\nSo no much word fluff, just simple books that people can fill content into.\\n\\nThese books include:\\n\\nLogbook\\n\\nNotebooks\\n\\nActivity books\\n\\nPrayer Books.\\n\\nJournals. You name it.\\n\\nPhoto by Clay Banks on Unsplash\\n\\nWith Canva, creating these types of books are super easy.\\n\\nSo easy that in a day, you could have yourself a library of these books.\\n\\nWhat About AI Generated eBooks?\\n\\nNow, for some reason, no one likes the sound of selling an AI-generated ebook, and that’s okay.\\n\\nBut what if there were a way to create an AI-generated eBook that didn’t sound like a robot wrote it in a hurry?\\n\\nWell, that’s where the concept of AI- assisted eBooks come in.\\n\\nSure, we’ll use AI to generate the outline for the eBook and even the content.\\n\\nBut it doesn’t end there.\\n\\nFor an AI assisted ebook, there\\'s the human touch that brings it all together.\\n\\nSo even after ChatGPT generates an entire book to sell on KDP, there’s still a place for us humans to proofread and make those stories reader-friendly.\\n\\nPhoto by Jilbert Ebrahimi on Unsplash\\n\\nNow it’s left for you to decide which method is easier for you.\\n\\nLow Content or AI assisted eBooks.\\n\\n2. Finding Profitable Keywords To Sell Books In\\n\\nNow, you need to understand that there are a thousand and one different niches in which you could create books to upload on Amazon KDP.\\n\\nThere’s\\n\\nSelf-help and personal development\\n\\nRomance and relationships\\n\\nScience fiction and fantasy\\n\\nHealth and wellness\\n\\nCooking and recipes etc\\n\\nNow, with this many niches, you are going to need to\\n\\nchoose one of the many possible ideas,\\n\\nanalyze them,\\n\\nand create books to sell in that niche.\\n\\nBut how do we find profitable keywords to sell our books in?\\n\\nPhoto by Rabie Madaci on Unsplash\\n\\nWell, that\\'s where ChatGPT and some other tools come in.\\n\\nKeep in mind that finding ideas for low-content books and for AI-assisted ebooks is quite different.\\n\\nSo let’s look at both methods.\\n\\nFinding keywords for Low Content Books\\n\\nFirst, let’s talk about the various low-content books you could create on Canva.\\n\\nThere’s\\n\\nJournals\\n\\nColoring Books\\n\\nPlanners\\n\\nRecipe Books\\n\\nNotebook Themes\\n\\nActivity Books\\n\\nAffirmation Cards\\n\\nSketchbooks\\n\\nNow, the method I’m going to show you for finding profitable ideas is one I hold dear to myself.\\n\\nIt works like magic, and the keywords you’ll find while doing this are literally gold.\\n\\nPhoto by Artem Maltsev on Unsplash\\n\\nYou can thank me later, but for now, let’s focus on finding these Keywords.\\n\\nStep 1: Go Over to Creative Fabrica\\n\\nI know it sounds shocking that Creative Fabrica is being mentioned as a keyword research tool, but don’t be too quick to judge.\\n\\nSure, Creative Fabrica is a marketplace by creatives for creatives, but it’s also a home to KDP interiors.\\n\\nNow, KDP interiors are basically the interior content of your low content book.\\n\\nSo when you sell planners, the content of that planner is the interior.\\n\\nBut why are they relevant here?\\n\\nWell, that leads us to step two.\\n\\nStep 2: Type in the umbrella low content book you’re trying to create\\n\\nLet’s say I wanted to create a\\xa0notebook;\\n\\nI should type the word \"notebook\" + interior into the search bar on Creative Fabrica.\\n\\nScreenshot Of Creative Fabrica Search Bar\\n\\nNow, here’s what’s going to happen:\\n\\nYou’ll literally find keywords and ideas that you could never have thought about in a million years.\\n\\nJust like how I found the following planner ideas\\n\\nCoffee and Prayer Time Journal\\n\\nMigraine Tracker Journal\\n\\nNurse Report Sheet Notebook\\n\\nBariatric Surgery Logbook\\n\\nCocktail Recipe Journal\\n\\nWould you have thought of these keywords?\\n\\nFinding Keywords for AI assisted ebooks\\n\\nNow, for this research process, I’d love to call on ChatGPT.\\n\\nOver on ChatGPT, ask for 10-20 niches to create eBooks in.\\n\\nChatGPT Dashboard\\n\\nNow, pick one of these major niches and ask ChatGPT to provide 10–20 sub-niche ideas.\\n\\nChatGPT Dashboard\\n\\nFor specific book titles and ideas, ask ChatGPT to provide you with more sub-niches within one of these categories.\\n\\nChatGPT Dashboard\\n\\nThere you go! These are all potential eBook ideas for AI Assisted books to sell on Amazon.\\n\\n3. Analyzing These Keywords\\n\\nNow, the search doesn’t end with finding the right keywords;\\n\\nyou’re going to need to analyze those keywords to find the perfect one.\\n\\nOur focus is mainly on the search volume and competition score.\\n\\nAnd remember, our golden keyword needs to have\\n\\nHigh demand (usually greater than 100)\\n\\nand Low competition of less than 1000 search results\\n\\nTo analyze the demand, I use the search bar of the marketplace in question.\\n\\nIn this case, it’s Amazon.\\n\\nType in the potential keyword and see if Amazon suggests it as a dropdown.\\n\\nIf it does, there’s demand for your keywords, as buyers are actively typing those keywords into the search bar.\\n\\nScreenshot of an Amazon Demand Analysis\\n\\nScreenshot of an Amazon Demand Analysis\\n\\nIf it doesn’t, move on to the other keywords you found during your research.\\n\\nNow, to analyze the competition for these keywords, all I have to do is check the number of search results for that keyword on Amazon.\\n\\nThe more search results there are, the more competitive the keyword tends to be.\\n\\nThat said, I usually aim for keywords with fewer than a thousand search results.\\n\\nScreenshot of an Amazon Competition Analysis\\n\\nScreenshot of an Amazon Competition Analysis\\n\\nUsing this exact brainstorming and analysis process, I found out that the keywords\\n\\nsicilian cookbook with 404 search results\\n\\nand migraine tracker journal with just 200 search results\\n\\nAre perfect keywords to go after as a beginner to Amazon KDP.\\n\\n4. Creating These Books In Canva\\n\\nCreating the books to sell has to be the easiest step in all of these processes.\\n\\nOnce again, we’ll be creating our low-content book and AI-assisted ebook separately.\\n\\nLet’s say I wanted to create a migraine tracker journal;\\n\\nAll I’d do is head over to Canva’s free template library.\\n\\nTo find a base template in the same genre as my idea, which in this case is a tracker template.\\n\\nNotice how I didn’t say to find the exact match template on Canva, e.g., a migraine tracker.\\n\\nThat would be basically impossible.\\n\\nSo focus on finding the base template, not necessarily the exact theme.\\n\\nNow, I broke my own rules and wanted to try my luck with an exact match keyword.\\n\\nAnd it worked.\\n\\nCanva\\'s Template Library\\n\\nI found a base template for a headache tracker, and my job was halfway complete.\\n\\nNow, with the headache tracker I found on Canva,\\n\\nI’d need to work towards making it a perfect fit for the keyword I found.\\n\\nI could ask ChatGPT for information about what the content of a migraine tracker journal should be\\n\\nChatGPT Dashboard\\n\\nWith this information, I’m in a much better position to create a journal that serves my target audience\\xa0perfectly.\\n\\nNow, other things you can do to make your journal unique include\\n\\nSwitching up the fonts,\\n\\nChanging up the theme and colors\\n\\nAdding matching elements\\n\\nRemember to download your interior file in PDF format to upload it to Amazon.\\n\\n4. Creating Aesthetic Book Covers\\n\\nI wish selling on KDP were as enchanting as fairy tales, where we shouldn’t judge books by their covers.\\n\\nBut sadly, that’s not the reality.\\n\\nOn Amazon, buyers will judge your book mainly by its cover.\\n\\nWell, it’s understandable; after all, it’s their hard-earned money.\\n\\nSo it’s our responsibility is to create compelling, high-quality covers that leave them with no option but to make a purchase.\\n\\nAnd once again, Canva comes to the rescue.\\n\\nNow, still with Canva’s free template library,\\n\\nfind a template that matches the basic concept of your book,\\n\\nCanva\\'s Free Template Library\\n\\nand work your way up by editing it to match your book’s overall concept.\\n\\n5. Uploading Your Books To Amazon KDP\\n\\nAt this point, we have our\\n\\nKeywords\\n\\nbook interior or AI content\\n\\nand book cover too.\\n\\nAll that’s left now is to upload and publish your book.\\n\\nThis step is the\\xa0most\\xa0straightforward.\\n\\nAll you need to do is\\n\\nFirst, create your free Amazon KDP and finish the account setup process\\n\\nAdd a new paperback or ebook listing\\n\\nAdd your book title and subtitle\\n\\nAdd your description, tags and categories\\n\\nUpload your book interior or PDF and set the dimensions\\n\\nSet your pricing\\n\\nAnd publish your book\\n\\nConclusion\\n\\nAmazon’s KDP was and still is one of the easiest way to make passive income.\\n\\nWe’re talking about selling books on the largest marketplace in the world.\\n\\nWhat other side hustle could be easier than that?\\n\\nSo if you’re a beginner yet to make your first dollar, you should probably check out Amazon KDP.\\n\\nIt’s perfect for beginners!\\n\\nBy the way, Amazon KDP is just one of the 4 passive income businesses I’ve built using Canva.\\n\\nI’ve documented my entire journey in my eBook: The Canva Hustle.\\n\\nThe Canva Hustle eBook\\n\\nIf you’ve been searching for a creative way to make money online, then you’ll love the ideas I’ve personally tried out & have now shared in my Canva Hustle eBook.\\n\\nClick here to Grab The Canva Hustle ebook.'}},\n",
       "  {'id': '1899e0b4b098',\n",
       "   'title': 'A Side Hustle Better Than Selling Canva Templates',\n",
       "   'subtitle': 'I Love Canva Templates But This Is Better ',\n",
       "   'author': '8c8e5b7182ef',\n",
       "   'publication_id': '*Self-Published*',\n",
       "   'published_at': '2024-02-04 19:20:02',\n",
       "   'last_modified_at': '2024-02-04 19:23:46',\n",
       "   'tags': ['passive-income',\n",
       "    'make-money-online-fast',\n",
       "    'chatgpt',\n",
       "    'notion',\n",
       "    'gumroad'],\n",
       "   'topics': ['marketing'],\n",
       "   'claps': 1692,\n",
       "   'voters': 251,\n",
       "   'word_count': 1850,\n",
       "   'responses_count': 32,\n",
       "   'reading_time': 8.731132075471699,\n",
       "   'url': 'https://medium.com/@iampaulrose/a-side-hustle-better-than-selling-canva-templates-1899e0b4b098',\n",
       "   'unique_slug': 'a-side-hustle-better-than-selling-canva-templates-1899e0b4b098',\n",
       "   'image_url': 'https://miro.medium.com/0*ouK5AEYap1hXkmTQ',\n",
       "   'lang': 'en',\n",
       "   'is_series': False,\n",
       "   'is_locked': False,\n",
       "   'is_shortform': False,\n",
       "   'top_highlight': '',\n",
       "   'content': {'id': '1899e0b4b098',\n",
       "    'content': 'A Side Hustle Better Than Selling Canva Templates\\n\\nI Love Canva Templates But This Is Better\\n\\nI used to love selling Canva templates until I stopped.\\n\\nIt was no longer as easy as\\n\\nFinding quality keywords\\n\\nand running over to Canva to create the templates\\n\\nBecause virtually every new niche I find has thousands of products already on Etsy, Teachers Pay Teachers, and Creative Fabrica.\\n\\nWhat was I going to do?\\n\\nPhoto by BĀBI on Unsplash\\n\\nI already sell Canva templates on Creative Fabrica, so the increased competition almost has nothing to do with me.\\n\\nBut what about the thousands of readers whom I’ve inspired to start their own Canva template shop?\\n\\nI mean, I wasn’t about to give up on a business model I knew worked like magic, so I went back to the drawing board.\\n\\nAnd after a long brainstorming session, I came up with a better way to make money selling templates.\\n\\nThat said, we will not be switching up our business model of creating and selling templates; we will only be changing the types of templates we sell.\\n\\nYes, it’s time for us to try something new.\\n\\nPhoto by freestocks on Unsplash\\n\\nNow, If Not Canva\\xa0Templates, Then\\xa0What?\\n\\nWell, for this side hustle, we’ll be selling Notion templates instead.\\n\\nLast week, I talked about my investment in an eBook that illustrates how to make thousands of dollars by selling Notion templates.\\n\\nScreenshot Of The Notion Millions eBook\\n\\nToday, I’ll be sharing a summary of everything the eBook taught me, in addition to what I already know about running a digital template business.\\n\\nWhy Notion Templates are More Profitable Than Canva Templates\\n\\nCanva has over 150 million users on its platform every single month, but are Canva templates more profitable than Notion templates?\\n\\nThe thing about templates is that the higher the demand, the more money there is to be made.\\n\\nNow, let it be known that Canva has a library of templates, with hundreds of thousands made available to the general public.\\n\\nCanva\\'s Free Template Library\\n\\nFor anyone looking to purchase premium Canva templates on marketplaces such as Etsy and Creative Fabrica, it comes down to one of two things.\\n\\n1. They aren’t aware of Canva’s template library.\\n2. Or are in need of a template that doesn’t already exist on the library. (Which is usually not the case)\\nSo, while Canva definitely has more users on its platform than Notion, the demand for its templates is less since Canva already has a free library.\\n\\nNotion, on the other hand, is also loved by a huge community of productivity geeks who just want to stay organized in whatever area they are specialists in.\\n\\nPhoto by Team Nocoloco on Unsplash\\n\\nBut guess what, Unlike Canva, Notion lacks a free template library.\\n\\nTo use the platform, you literally have to create your templates from scratch.\\n\\nSo while it\\'s true that Notion is an awesome productivity tool, it\\'s almost useless if you lack the right framework.\\n\\nUnsurprisingly, not everyone has the time and patience to learn how Notion works well enough to create their own templates, and that’s where we come in.\\n\\nMoreso, Notion templates are a fairly new concept, and the competition for these kinds of templates is jaw-dropping.\\n\\nAnd by \"jaw-dropping,\" I mean super healthy and\\xa0perfect\\xa0for\\xa0beginners.\\n\\nBut that’s not where the fun ends.\\n\\nIn one of the Chapters in the Notion Millions eBook, the author showed how we could literally use ChatGPT to do all the work with this Notion business model.\\n\\nPhoto by Levart_Photographer on Unsplash\\n\\nFrom\\n\\nComing up with profitable niches\\n\\nFinding the right keywords\\n\\nand even creating the framework for the Notion template\\n\\nTo illustrate the healthy competition for Notion templates on marketplaces like Etsy and Creative Fabrica,\\n\\nI conducted a brief niche research session on ChatGPT as outlined in the Notion Millions eBook.\\n\\nand you’ll be shocked at how viable the niches I found were.\\n\\nI began with the major niches I knew would appreciate a Notion template for their processes.\\n\\nI focused on the ones who like to stay productive and organized.\\n\\nPhoto by Pauline Bernard on Unsplash\\n\\nSome of the niches I found were\\n\\nEntrepreneurs\\n\\nNutrition\\n\\nLanguage learning\\n\\nParenting\\n\\nStudy and much more\\n\\nThen I asked ChatGPT for sub-niche ideas, and for each of these ideas, I went on to analyze on Etsy.\\n\\nMy benchmark for a good product Keyword was simple.\\n\\nA high demand\\n\\nWith low competition of less than 1000 search results.\\n\\nAnd I made sure to keep those criteria in mind during my research.\\n\\nPhoto by Christin Hume on Unsplash\\n\\nSo for every keyword I share, I’ll add in the healthy competition score.\\n\\nI love passive\\xa0income, so I went with that as\\xa0my sub-niche and these were the keywords I found\\n\\naffiliate marketing tracker\\u200a(899 search results)\\n\\ncryptocurrency tax calculator (85 search results)\\n\\ncryptocurrency tracker (875 search results)\\n\\nstock portfolio tracker (896 search results)\\n\\n401k tracker (815 search results)\\n\\nNow, It took me just a couple of minutes to come up with these niches.\\n\\nWhy? Because Notion templates are super under saturated.\\n\\nYet with so much demand.\\n\\nIf I had to carry out the same research process to find viable Canva template keywords, it would literally take me days, no joke.\\n\\nHow To Make Money Selling Notion Templates\\n\\n1. Sell them as templates on Etsy\\n\\nSelling your Notion templates on Etsy is essentially just scratching the surface of what’s possible with Notion templates.\\n\\nBut, don’t get me wrong, it’s still a profitable way to make money with Notion.\\n\\nBecause Etsy works 100% as long as you follow the principles I teach on my page.\\n\\nPhoto by Oberon Copeland @veryinformed.com on Unsplash\\n\\nChoose a niche with evident demand and very low competition.\\n\\nThat\\'s all.\\n\\nThankfully with Notion, this is very easy to do.\\n\\nOne of my readers took my advice,\\n\\nfound a very low competition on Etsy\\n\\nand launched a shop that got its first sale in less than two weeks.\\n\\nScreenshot of my reader\\'s comment\\n\\nYes, and he was a complete beginner to selling on Etsy.\\n\\n2. Sell Teacher Themed Notion Templates\\n\\nLet’s say Etsy isn’t your cup of tea; well, that’s okay because there’s this website called Teachers Pay Teachers.\\n\\nWith over 26.2 million monthly visitors, this marketplace, made by teachers for teachers, is one of the best out there.\\n\\nTeachers Pay Teachers Traffic Insights By SimilarWeb\\n\\nThe competition on this marketplace is a lot less than on Etsy.\\n\\nAnd with the same ChatGPT research strategy I talked about earlier,\\n\\nI found the following niches that are perfect for a new shop on Teachers Pay Teachers\\n\\nstudent attendance tracker (840 search results)\\n\\neditable student assessment tracker (940 search results)\\n\\nspelling inventory assessment (250 search results)\\n\\nNow how do I know Teachers Pay Teachers is a profitable way to sell templates\\n\\nFor about a month or so, I tried selling teacher-themed templates on Teachers Pay Teachers.\\n\\nAnd while my shop was live, I made a total of sales with fewer than 15 product listings.\\n\\nScreenshot by Author\\n\\nNot a lot of money but still proof that Teachers Pay Teachers is another amazing marketplace to sell on.\\n\\n3. Sell them on Gumroad\\n\\nThis has to be the most profitable way to make money from your notion template.\\n\\nEaslo, a 17-year-old, tried this and made over $500k in just 2 years from selling Notion templates on Twitter.\\n\\nScreenshot of Easlo\\'s Tweet on Twitter\\n\\nSure, he had to build his audience first, and it took a while, but it was worth it.\\n\\nSo pick a topic you\\'re passionate about, let\\'s say books.\\n\\nCreate your first Notion template and upload it as a product on Gumroad e\\xa0.g. A book tracker\\n\\nPost one piece of content everyday providing value e.g with book summaries and reviews\\n\\nThen once in a while, promote your template to your audience\\n\\nSome of the easiest places to grow an audience are\\n\\nTwitter\\n\\nTikTok\\n\\nMedium\\n\\nand Pinterest\\n\\nPhoto by dole777 on Unsplash\\n\\nAny of these platforms will be perfect for selling your niche-specific notion template.\\n\\nA fellow writer on Medium, Poonam Sharma, tried out this side hustle using Twitter and even made $100 in a single day.\\n\\nScreenshot of Poonam Sharma\\'s Story On Medium\\n\\nAnd with this same business model, I’ve made thousands of dollars on Gumroad by selling my digital products on Medium.\\n\\nScreenshot by Author\\n\\nSo if you can’t write a book or create a course to sell on Gumroad, consider selling a simple Notion template instead.\\n\\nHow To Create Notion Templates To Sell.\\n\\n1. Pick a Niche Using ChatGPT\\n\\nYour niche is the single most important element of your Notion template business.\\n\\nNow,\\n\\nYou could choose to go with a single niche, creating different templates for buyers in that niche.\\n\\nAnd That’s okay.\\n\\nBut it doesn\\'t hurt to have a shop with different templates catering to different niches.\\n\\nThis is a perfect strategy especially on marketplaces like Etsy and Teachers Pay Teachers.\\n\\nYou essentially become the one-stop shop for all things Notion.\\n\\nNow, the Notion Millions eBook has a chapter that outlines niche research with ChatGPT, and I highly recommend you read this book.\\n\\nYou can click here to grab the Notion Millions eBook.\\n\\nA snapshot of the Notion Millions eBook\\n\\n2. Create your template\\n\\nCreating a sellable template might sound overwhelming, but let me break it down.\\n\\nWhat if I told you it was possible to ask ChatGPT for the entire framework of your Notion template?\\n\\nWell that’s another trick I learnt from the eBook I bought.\\n\\nNow I know that an affiliate tracker will need the following section on Notion.\\n\\nChatGPT Dashboard\\n\\nTo create your first template, you’ll need to learn how Notion works and understand the basics.\\n\\nI mean, coupled with the trick where ChatGPT generated the entire outline for your Notion template,\\n\\nyour only job is to turn that framework into a full-blown Notion template.\\n\\nAnd while the eBook guide I bought has a basic walkthrough section, YouTube is another option for learning how Notion works.\\n\\nPhoto by Szabo Viktor on Unsplash\\n\\nConclusion\\n\\nNotion templates are digital products, and digital products are one of the most profitable ways to make passive income.\\n\\nI’ve shown you three ways a notion template could generate passive income for you.\\n\\nAnd I’ve also shown you how ChatGPT can literally do all the work for you.\\n\\nNow here’s what I expect from you\\n\\nlearn more about this business model\\n\\nlearn more about how Notion works\\n\\nThen, take a week or two to create your first template; afterward, create your second and third.\\n\\nIn a month or less, you’ll be glad you listened.\\nNow, I bought the eBook because I wanted to try a new side hustle similar to selling Canva templates.\\n\\nAnd, as a beginner to Notion like I am, it was definitely helpful.\\n\\nThe Notion Millions Guide by James Renouf\\n\\nWith everything from\\n\\nThe exact niches to create Notion templates in ( so you know what subniches to ask ChatGPT for)\\n\\nTo ChatGPT hacks for creating Notion templates even as a complete beginner\\n\\na Beginner’s Guide to basics of creating an aesthetic template on Notion\\nand much more\\n\\nI’d say this guide was definitely worth the pay and I highly recommend it.\\n\\nSo if you’re interested in this side hustle, you should start learning and improving your Notion skills with the Notion Millions Guide.\\n\\nYou can check out the Notion Millions eBook here.\\n\\nNote: There are affiliate links in the article and if you buy something, I’ll get a commission at no extra cost to you.\\n\\nThis content is free, and by using these links, You’ll be supporting my work & that means a whole lot to me.'}},\n",
       "  {'id': '0bbfd98ac496',\n",
       "   'title': 'I Tried Making Money With a Free AI Art Generator',\n",
       "   'subtitle': 'How To Make Money with AI Art',\n",
       "   'author': '8c8e5b7182ef',\n",
       "   'publication_id': '*Self-Published*',\n",
       "   'published_at': '2024-02-02 21:43:31',\n",
       "   'last_modified_at': '2024-02-03 06:13:24',\n",
       "   'tags': ['ai-art',\n",
       "    'ai',\n",
       "    'artificial-intelligence',\n",
       "    'passive-income',\n",
       "    'make-money-online'],\n",
       "   'topics': ['artificial-intelligence', 'marketing'],\n",
       "   'claps': 4188,\n",
       "   'voters': 511,\n",
       "   'word_count': 1565,\n",
       "   'responses_count': 88,\n",
       "   'reading_time': 8.05566037735849,\n",
       "   'url': 'https://medium.com/@iampaulrose/i-tried-making-money-with-a-free-ai-art-generator-0bbfd98ac496',\n",
       "   'unique_slug': 'i-tried-making-money-with-a-free-ai-art-generator-0bbfd98ac496',\n",
       "   'image_url': 'https://miro.medium.com/1*ZOMR_5njto2MATAKRtD3yw.jpeg',\n",
       "   'lang': 'en',\n",
       "   'is_series': False,\n",
       "   'is_locked': False,\n",
       "   'is_shortform': False,\n",
       "   'top_highlight': \"It's super easy to get acquainted with this art generator and I highly recommend it for beginners.\",\n",
       "   'content': {'id': '0bbfd98ac496',\n",
       "    'content': 'I Tried Making Money With a Free AI Art Generator\\n\\nHow To Make Money with AI Art\\n\\nAI art is not anything new in 2024.\\n\\nBut whenever I mention AI art, people almost always think of AI art generators like Midjourney.\\n\\nPhoto by Jonathan Kemper on Unsplash\\n\\nNow, Midjourney isn’t free.\\n\\nIt costs $10 Per Month.\\n\\nWhen AI-generated art was barely believable, I couldn’t justify spending $10 per month on a subscription,\\n\\nSo, I resorted to using free AI art generators.\\n\\nI wanted to see if it was possible to make money from AI art even without spending a dime.\\n\\nToday, I’ll be sharing how that went and how a beginner with zero skill set can make hundreds of dollars in passive income with free AI art.\\n\\nWhat Was This Free AI Art generator?\\n\\nWell, the name is Leonardo.ai.\\n\\nLeonardo Ai Home Page\\n\\nAnd unlike Midjourney, Leonardo AI works in your browser and not in a Discord group.\\n\\nIt’s super easy to get acquainted with this art generator and I highly recommend it for beginners.\\n\\nJust like any other AI art generators, I had to learn how to create high-quality prompts on Leonardo AI.\\n\\nIt took me days, if not months, but it was definitely worth it.\\n\\nNow that we know the AI art generator in question, let’s discuss how I made money.\\n\\nPhoto by Vladimir Solomianyi on Unsplash\\n\\nHow To Make Money with Leonardo ai\\n\\nNow, I’ve tried two of these AI side hustles and achieved success, the last is still on my to-start side hustle list.\\n\\nEither way, I’ll be going all in and sharing all of these side hustles with you\\n\\n1. Creating AI Clipart\\n\\nThis was the first and probably the most exciting of all the side hustles I tried with Leonardo.ai.\\n\\nI’ve probably talked about this side hustle countless times and it’s because I can’t get enough of the concept.\\n\\nCreate cute Clipart with Leonardo.ai\\n\\nPackage them into a bundle and sell on marketplaces.\\n\\nBut what are clipart and why do people buy them?\\n\\nClipart is a collection of cute images created and sold for other creatives to use in their projects.\\n\\nA Clipart Bundle I Created with Leonardo AI\\n\\nThese projects can include:\\n\\nInvitation cards\\n\\nThemed Templates\\n\\nPresentation and Slides\\n\\nPosters\\n\\nPrintables and more.\\n\\nWhile these images are super easy to make, they can be very profitable when sold correctly.\\n\\nHere’s a quick step by step guide if you ever want to consider selling Clipart\\n\\nFirst, Ask ChatGPT for profitable Niches for Cliparts to sell.\\n\\nChatGPT Dashboard\\n\\nThen ask for sub-niches within any of those main niches to narrow down your competition.\\n\\nI chose the food niche for this example.\\n\\nChatGPT Dashboard\\n\\nNow, ask ChatGPT for variations or ideas of clipart to generate for that bundle.\\n\\nChatGPT Dashboard\\n\\nFinally, using Leonardo.ai, generate images for each of those ideas.\\n\\nI generated a Cupcake Clipart with Leonardo Ai\\n\\nAnd an Ice cream Clipart by Leonardo Ai\\n\\nAll that’s left to do now is package them into a bundle and sell on marketplaces like Creative Fabrica, Etsy, and Teachers Pay Teachers.\\n\\nI sell on Creative Fabrica and have been able to build a following of 401 people, with over 2,472 product favorites, making me thousands of dollars every month.\\n\\nScreenshot by Author\\n\\nI also found a seller on Etsy with over 2,833 sales.\\n\\nThis shop sells just Clipart.\\n\\nScreenshot of Etsy Shop\\n\\nOn average, each of their bundles are priced at a range of $2.37.\\n\\nMeaning this shop has approximately made $6,714.\\n\\nImagine how many of these kinds of listings you could be creating with Leonardo ai to sell Etsy and Creative Fabrica.\\n\\n2. Selling Recipe Books\\n\\nNow, I don’t categorically sell recipe books for passive income, but I tried out the business model, so I’m sure it works.\\n\\nThe way this side hustle works is quite simple.\\n\\nYou create eBooks with the help of AI and sell them on large marketplaces like Amazon.\\n\\nPhoto by Marques Thomas on Unsplash\\n\\nAmazon has a platform for authors and it’s called Amazon KDP.\\n\\nThis platform is completely free for authors and you don’t even have to apply to be accepted.\\n\\nSimply head over to Amazon KDP’s website to sign up for your free account.\\n\\nAs for the books you’ll be selling, we’ll be making use of Leonardo.ai once again.\\n\\nBut why did I choose recipe books?\\n\\nPhoto by S O C I A L . C U T on Unsplash\\n\\nWell, it’s because the niches here are endless, and can be completely automated by AI.\\n\\nAnd by asking just a question on ChatGPT, you can discover low-competition keywords to target on Amazon.\\n\\nSo\\xa0let’s ask ChatGPT for recipe niche ideas.\\n\\nChatGPT Dashboard\\n\\nNow, ask for sub-niches for any of these niches.\\n\\nChatGPT Dashboard\\n\\nOnce you find a book topic with fewer than 1000 search results on Amazon, it’s time to start creating.\\n\\nDuring my research, I discovered a keyword that was in high demand,\\n\\nScreenshot of Amazon\\'s Search Bar\\n\\nAnd had a very low competition with just 354 search results.\\n\\nScreenshot of Amazon\\'s Search Bar\\n\\nIt was perfect and I could get to work.\\n\\nNow, for your recipe books, ChatGPT will handle most of the work, but Leonardo AI is still a crucial part of this side hustle.\\n\\nSo on ChatGPT, ask for the\\n\\nOutline\\n\\nChapter page\\n\\nand Recipe Content of your book\\n\\nThen, go over to Leonardo AI to generate the images for your recipe book.\\n\\nYour images will heavily rely on the recipes you need to create.\\n\\nFor example, a sugar free canning recipe book should have recipes like\\n\\nSugar-Free Berry Jam\\n\\nGenerated by AI\\n\\nStevia-Sweetened Pickles\\n\\nMonk Fruit Preserves\\n\\nFinally, on Canva, find an eBook template to compile all of these images and recipes into a complete eBook.\\n\\nCanva\\'s free template library\\n\\nRemember to make the eBook cover attractive, then upload your eBook to Amazon KDP to immediately get access to their billions of sellers.\\n\\nI used to sell books on Amazon KDP and made a good amount of money until I stopped.\\n\\nScreenshot by Author\\n\\nSo yes, it works.\\n\\n3. Selling Stickers\\n\\nWe all love cute stickers, don’t we?\\n\\nThey are pretty, and they make our gadgets and journals look a lot less boring.\\n\\nWell, what if I told you it was possible to start your own sticker shop with the help of AI?\\n\\nI haven’t personally tried this side hustle, but I know of shops that are making thousands of dollars selling stickers on\\n\\nEtsy\\n\\nZazzle\\n\\nRedbubble\\n\\nTeepublic\\n\\nand Pinterest.\\n\\nStarting your sticker shop is pretty easy.\\n\\nOnce again, Ask ChatGPT for sticker niches and keep asking until you find a low competition keyword that sticks.\\n\\nChatGPT Dashboard\\n\\nThen, on Leonardo AI, test and tweak different prompts until you generate a sticker image you’re proud enough to sell.\\n\\nHere’s a sticker I generated using Leonardo.Ai\\n\\nImage Generated By Me on Leonardo Ai\\n\\nTo illustrate the demand on Etsy for stickers, I found this sticker shop that sold panda stickers.\\n\\nScreenshot of TheDigutalCraftCo\\n\\nIn this case, the sticker was sold as a digital product but still managed to garner over 7k reviews.\\n\\nAnd at a price range of $2.66, this listing alone has made its seller at least\\xa0$18,620.\\n\\nScreenshot of my calculator\\n\\nThat’s five figures made just from selling simple images.\\n\\nHow To Start These AI Art Side Hustles\\n\\nThe thing about AI Art is that it works purely on the principle of garbage in, garbage out.\\n\\nSo when you input a low quality prompt into Leonardo AI, you’ll most likely get a subpar output.\\n\\nHere’s an example of how the right prompt makes all the difference.\\n\\nThis first image was my first attempt at creating Clipart on Leonardo AI.\\n\\nImage generated by Leonardo Ai with a low quality prompt\\n\\nBut then I tweaked my prompt and was able to generate a more high quality image of a bagel.\\n\\nImage Generated By Leonardo Ai\\n\\nSo before you go on to generate a bunch of AI art on Leonardo.ai, you need to understand that it takes a level of expertise.\\n\\nAnd you need to be ready to learn\\n\\nhow to create the perfect prompt for your images\\n\\nand which of Leonardo’s Art models would suit the art style you’re looking for.\\n\\nFor this, you need to practice on Leonardo.Ai and play around with its tools.\\n\\nThat was exactly what I did, and in less than three months or so, I became quite proficient at generating images that were highly sellable.\\n\\nYou can also\\n\\nskip the entire learning process\\n\\ncopy my exact AI art prompts (word for word)\\n\\nand the AI model I used for each of them.\\n\\nJust by downloading my Leonardo Prompt Bundle.\\n\\nThe Leonardo Prompt Bundle\\n\\nWith this bundle, you’ll get all of my best-performing prompts for generating images across all genres, including cliparts.\\n\\nAnd, for an affordable fee, you’ll be able to download the exact prompt I use to generate my Clipart, as well as other sellable AI images.\\n\\nYou can click here to download the Leonardo Prompt Bundle.\\n\\nAside from the quality of your prompt, you need to focus heavily on using the right keywords.\\n\\nRemember, it’s a struggle between you and other sellers for who gets the sale.\\n\\nHence, the best strategy for creating sustainable passive income by selling AI-generated products on marketplaces is to focus on\\n\\nhigh-demand keywords\\n\\nwith low-competition.\\n\\nRemember, low-competition keywords are those with fewer than 1000 search results on the marketplace you choose.\\n\\nConclusion\\n\\nAI art is definitely a major shift in the art industry.\\n\\nYou no longer need to spend years becoming an artist or months creating a single piece of artwork.\\n\\nPhoto by Frankie Cordoba on Unsplash\\n\\nBy simply clicking the \"generate button\" on Leonardo AI, you can generate high-quality images that make you passive income.\\n\\nNot only is creating art with AI highly profitable, it’s also a lot of fun.\\n\\nSo if you’re interested in any of these AI art side hustle, you should start improving your Leonardo prompting skills on YouTube\\n\\nor get started right away with my Leonardo Prompt Bundle kit.\\n\\nYou can check out the Leonardo Prompt Bundle here.'}},\n",
       "  {'id': 'a506114d7a46',\n",
       "   'title': 'How To Write On Medium For Passive Income In 2024',\n",
       "   'subtitle': 'The Seamless Story Strategy ',\n",
       "   'author': '8c8e5b7182ef',\n",
       "   'publication_id': '*Self-Published*',\n",
       "   'published_at': '2024-01-31 21:22:12',\n",
       "   'last_modified_at': '2024-01-31 21:22:12',\n",
       "   'tags': ['passive-income',\n",
       "    'side-hustle',\n",
       "    'make-money-online',\n",
       "    'online-business',\n",
       "    'medium'],\n",
       "   'topics': ['writing', 'marketing'],\n",
       "   'claps': 565,\n",
       "   'voters': 56,\n",
       "   'word_count': 1849,\n",
       "   'responses_count': 17,\n",
       "   'reading_time': 8.427358490566037,\n",
       "   'url': 'https://medium.com/@iampaulrose/how-to-write-on-medium-for-passive-income-in-2024-a506114d7a46',\n",
       "   'unique_slug': 'how-to-write-on-medium-for-passive-income-in-2024-a506114d7a46',\n",
       "   'image_url': 'https://miro.medium.com/0*jofiNnNPWCgs4DaL',\n",
       "   'lang': 'en',\n",
       "   'is_series': False,\n",
       "   'is_locked': False,\n",
       "   'is_shortform': False,\n",
       "   'top_highlight': 'Give first, ask after.',\n",
       "   'content': {'id': 'a506114d7a46',\n",
       "    'content': 'How To Write On Medium For Passive Income In 2024\\n\\nThe Seamless Story Strategy\\n\\nYesterday, I got a comment from\\xa0a reader.\\n\\nScreenshot Of My Comment Section\\n\\nHe sounded angry and wanted real details on what it took to grow on Medium and generate passive income.\\n\\nHe wanted details like\\n\\nThe length a story should be\\n\\nand most likely everything in between\\n\\nI listened, and now I’m bringing you a full-blown story on how to write on Medium for passive income in 2024.\\n\\nI’ll be skipping the obvious steps like\\n\\nPicking a niche\\n\\nStaying consistent\\n\\nand understanding what passive income methods work the most\\n\\nBecause I’m hoping you already know the basics.\\n\\nToday’s story is a more advanced-level guide on how to generate passive income on Medium.\\n\\nPhoto by Vladimir Solomianyi on Unsplash\\n\\nFor this, we’ll cover the fundamental elements of a story that goes viral on Medium.\\n\\nYes.\\n\\nI’ll be showing you how to write stories that get views on Medium.\\n\\nBecause remember, more views equals more traffic.\\n\\nAnd more traffic most likely means more passive income.\\n\\nThat said, my focus today is on helping you write better stories that fuel your passive income business.\\n\\nThe Seamless Story Principle ( Medium As a Journey)\\n\\nBefore I share what these three fundamental elements are, I need you to understand that Medium is a journey.\\n\\nYes.\\n\\nI like to think of each of my stories as a journey for the minds of my readers.\\n\\nPhoto by Matt Duncan on Unsplash\\n\\nMy job is to make this journey as seamless as possible for my readers, reaching a point where they feel super energized to take action based on what I’ve put in place.\\n\\nThis action could be to\\n\\nFollow for more stories (to get more followers for your Medium Ad revenue)\\n\\nBuy your product\\n\\nTake your recommendation on an affiliate product\\n\\nOr even to send you an email to make inquiries about your services.\\n\\nEither way, there’s no action without a journey.\\n\\nSo don’t expect to generate passive income if you’ve failed to guide your readers through a memorable journey experience.\\n\\nThe Elements of a Seamless Story That Makes Passive Income\\n\\nWith these three elements of a seamless, viral-worthy story, you can almost never go wrong in gaining views and traffic on Medium.\\n\\nElement 1: The Hook\\n\\nYour hook is like the cover of your book.\\n\\nPhoto by Thought Catalog on Unsplash\\n\\nIf it’s unattractive, people scroll away.\\n\\nIf it’s appealing, people want to read the book.\\n\\nIf your Medium stories are a journey, it only means there is a start to that journey.\\n\\nWell, your hook is that start.\\n\\nYou can have the best story in the world, but if people don’t click, they won’t know it.\\n\\nTherefore, while having an awesome title and an awful post is Clickbait,\\n\\nHaving an awesome post with an awful title is a waste of time.\\n\\nSo before you even think about writing your story, deliberate on the title.\\n\\nBecause what’s the point of writing the perfect story only to end up with zero views.\\n\\nPhoto by Francisco Gonzalez on Unsplash\\n\\nIt’s depressing but can be avoided.\\n\\nSo how do you write the perfect hook for your stories?\\n\\nThere are so many ways to go about finding the perfect hook.\\n\\nThere’s ChatGPT and other AI tools that literally generate headlines ideas.\\n\\nAnd there are online headline analyzers, like Coschedule, that will help rate your headline while giving you tips on how to improve it.\\n\\nBut that’s not all.\\n\\nThere’s a hook strategy that I use and abide by.\\n\\nIt’s literally what got me my first viral post on Medium and here’s how it works.\\n\\nI call it the Steal Like An Artist Hook Strategy.\\n\\nPhoto by Frankie Cordoba on Unsplash\\n\\nSo what does\\xa0it mean?\\n\\nSometimes, there’s really no need to reinvent the wheel.\\n\\nYes, it’s okay to be creative, but sometimes it’s more effective to find what already works and take inspiration.\\n\\nNotice how I said, take inspiration, not copy.\\n\\nThere’s a difference.\\n\\nMy first viral story was literally a result of finding an already viral hook that I made my own.\\n\\nIf you doubt me, here’s the hook I took inspo from for my viral story.\\n\\nScreenshot of Medium\\'s Search Bar\\n\\nBut how can you find the best hooks to take inspiration from in your niche?\\n\\nFind 10–20 writers in your niche\\n\\nLook at their best performing posts and what the title is.\\n\\nChange a few elements to suit your topic and viola, you have the perfect hook.\\n\\nElement 2: The Value\\n\\nOnce people have clicked\\xa0on\\xa0your\\xa0hook, what’s next?\\n\\nWell, if our goal is to make sales, or just simply grow our followers, we need to keep people reading.\\n\\nLike I always say, sales is a product of value.\\n\\nIn an ideal situation,\\n\\nyou should have a valuable story\\n\\nand at the end, you link your product for people to buy.\\n\\nBut most of the time, writers flip the script completely.\\n\\nIf not, how can you write a story with 50% of it being a pure pitch for your product or spammed with links to your sales page?\\n\\nSure, mentioning your product multiple times in your post increases clicks, but do you really think you deserve the sale?\\n\\nIf you take anything from today’s story, let it be this.\\n\\nGive first, ask after.\\n\\nPhoto by Javier Molina on Unsplash\\n\\nBefore sketching out a plan to earn $10k per month on Medium, first, plan a way to provide value.\\n\\nBecause without value, what motivation is there for a potential buyer to choose you over someone else?\\n\\nMoreover, the Medium algorithm works on a feedback\\xa0mechanism, promoting your story to more readers only if the initial readers liked it.\\n\\nSo let’s say you have 100 followers.\\n\\nOnly 10–20 might see your post when it’s first published.\\n\\nAnd based on their engagement, the algorithm decides whether or not to push your post.\\n\\nSo if your post has a lower value, you’ll likely receive few claps or comments from the initial readers who were supposed to help the algorithm promote your stories.\\n\\nHopefully, you see why a valuable story is so important even beyond making sales.\\n\\nSo, do away with posts that have no standalone value.\\n\\nAnd if, as the writer, you cannot pinpoint at least one or two key lessons from your story, you haven’t written a valuable story.\\n\\nElement 3: The Product\\n\\nThis element is what generates income for you.\\n\\nPhoto by Blogging Guide on Unsplash\\n\\nNow, it doesn’t necessarily have to be a product per se.\\n\\nYour product could be\\n\\nan eBook you created\\n\\nan affiliate program you promote\\n\\nor even a viral story that makes you money through the Medium Partner Program\\n\\nThe product here is basically how you convert your views into income.\\n\\nBut why is it important?\\n\\nI see this scene playing out in different niches and with many writers.\\n\\nHow can you share a story about the keto diet and then pitch a Paleo diet eBook at the end of your story?\\n\\n\"It doesn’t even sound good to the ear.\"\\n\\nListen, mentioning your product more times doesn’t necessarily mean you’ll make more money.\\n\\nInstead, mentioning your product where relevant is more effective.\\n\\nRemember, selling is helping.\\n\\nPhoto by Markus Spiske on Unsplash\\n\\nWe’re not just selling a product, we’re providing a solution.\\n\\nSo why would you suggest a Paleo solution when you clearly discussed keto as the problematic topic?\\n\\nNow, what am I saying?\\n\\nIdeally you should have 3–4 topics that you talk about on your page.\\n\\nAnd for each of those topics, you should have products to recommend or sell.\\n\\nBecause promoting the wrong product is like selling a spade to a mechanic and a spanner to a miner.\\n\\nSo to write for passive income, you need to recommend products only where relevant.\\n\\nSo Does Length Really Matter For Going Viral On Medium?\\n\\nSo from the comment of the day, is there really a minimum length for what a viral story should have?\\n\\nWell, from my experience, length doesn’t really matter.\\n\\nWhat matters is the value add.\\n\\nIf you can deliver a speech in 20 minutes for it to be more impactful, do it\\n\\nIf it takes you an hour, that’s still okay\\n\\nPhoto by Miguel Henriques on Unsplash\\n\\nThe goal is the same.\\n\\nGive as much value as you can. The length, in itself, doesn’t really matter.\\n\\nHow I Apply This Seamless Story Strategy in My Writing Business\\n\\nBecause I have this strategy in the back of my mind, there are some things I’d never really do when writing on Medium.\\n\\nSome of these writing taboos for me are\\n\\nWriting when I feel tired and unmotivated (I’ll almost never write out anything valuable in that state)\\n\\nPitching unrelated products just for the sake of it (I mean, what’s the point?)\\n\\nWriting stories that only pitch my products without providing any value at all.\\n\\nBy following the seamless story strategy on Medium, I’ve been able to build a community that keeps coming back.\\n\\nWhy?\\n\\nBecause they know what to expect from my stories!\\n\\nThe seamless story strategy is what got me the 38k Followers I grew on Medium in less than 6 months.\\n\\nScreenshot by Author\\n\\nAnd it’s also the reason I’m able to make thousands of dollars just from my stories on Medium.\\n\\nNow, today is my no screenshot day.\\n\\nSo for a breath of fresh air, I won’t be sharing screenshots for how much I make on Medium.\\n\\nBut I definitely make thousands of dollars every month from simple stories I write.\\n\\nAnd if that’s not enough validation, consider how much you could make from 1k followers, let alone 38k followers like I have.\\n\\nConclusion\\n\\nMedium is definitely one of the best places to build a community that generates passive income.\\n\\nNo platform will make you as much money as the work you have to put in.\\n\\nWith Medium, it’s just you being able to wake up everyday to write new stories\\n\\nWithout showing your face\\n\\nOr editing long hours of clips\\n\\nOr engaging endlessly for the algorithm\\n\\nMedium is definitely the place to be if you’re a beginner looking to make passive income\\n\\nIt’s seriously crazy.\\n\\nAnd it’s not just me; one of my clients, Jordan Gibbs, grew over 2.2k followers in just 3 months of writing on Medium after our session.\\n\\nScreenshot of Jordan Gibbs\\'s Profile on Medium\\n\\nNow, concerning how I grew over 37k Followers, with over 273,462 views every month.\\n\\nAnd how my clients are literally crushing it on Medium, I wrote an entire book sharing exactly how I did it.\\n\\nIt’s called the Medium Income Playbook.\\n\\nThe Medium Income Playbook\\n\\nIn this ebook, I share my exact thought process behind\\n\\nFinding endless profitable content ideas related to your specific topic\\n\\nCreating click-worthy titles and viral headlines to capture readers\\' attention.\\n\\nCreating engaging stories that convert readers into loyal subscribers and even buyers.\\n\\nMy writing principles (Quantity vs quality, KLT principle and the MVA principle)\\n\\nAnd I’ll also share my personal experiences on how I managed to grow to over 37k followers (as I speak) on Medium in less than 5 months.\\n\\nLiterally everything you need to go from zero followers to making passive income as a writer is in the Medium Income Playbook.\\n\\nSo If you want to start your very own profitable Medium page,\\n\\nCheck out the steps I personally tried out and have now shared in the Medium Income Hustle playbook.\\n\\nYou can click here to Grab The Medium Income Playbook.'}},\n",
       "  {'id': 'bf026cd7e80f',\n",
       "   'title': 'How I Make $100 Per Day In Passive Income As a Writer',\n",
       "   'subtitle': 'A Writer’s Guide To Passive Income ',\n",
       "   'author': '8c8e5b7182ef',\n",
       "   'publication_id': '*Self-Published*',\n",
       "   'published_at': '2024-01-29 19:59:22',\n",
       "   'last_modified_at': '2024-01-29 19:59:22',\n",
       "   'tags': ['passive-income',\n",
       "    'side-hustle',\n",
       "    'make-money-online',\n",
       "    'writers-on-medium',\n",
       "    'online-business'],\n",
       "   'topics': ['freelancing', 'writing'],\n",
       "   'claps': 643,\n",
       "   'voters': 51,\n",
       "   'word_count': 1757,\n",
       "   'responses_count': 20,\n",
       "   'reading_time': 8.280188679245283,\n",
       "   'url': 'https://medium.com/@iampaulrose/how-i-make-100-per-day-in-passive-income-as-a-writer-bf026cd7e80f',\n",
       "   'unique_slug': 'how-i-make-100-per-day-in-passive-income-as-a-writer-bf026cd7e80f',\n",
       "   'image_url': 'https://miro.medium.com/0*t6pwyW9OiBg1Y4gO',\n",
       "   'lang': 'en',\n",
       "   'is_series': False,\n",
       "   'is_locked': False,\n",
       "   'is_shortform': False,\n",
       "   'top_highlight': 'You need to be able to churn out new stories at least 3 times a week, without compromising on the quality.',\n",
       "   'content': {'id': 'bf026cd7e80f',\n",
       "    'content': \"How I Make $100 Per Day In Passive Income As a Writer\\n\\nA Writer’s Guide To Passive Income\\n\\nFirst, let’s address the elephant in the room\\n\\nDo I really consider myself a writer?\\n\\nIt’s funny because just five months ago, I went about calling myself a digital marketer, and now I’m a writer.\\n\\nDoes it really work that way?\\n\\nWell, yes it does.\\n\\nBecause a writer isn’t a mythical genius who whips up a pen and words flow.\\n\\nTo me, a writer is anyone bold enough to pen their thoughts into words.\\n\\nPhoto by Kenny Eliason on Unsplash\\n\\nSo, on that note, I believe anyone can become a writer profitable enough to earn more than $100 every day, as I do.\\n\\nI need you to kill the thought that you need to\\n\\nBe in the top 1% of writers\\n\\nOr have your grammar be as clear as Shakespeare\\n\\nBecause, as long as you paid attention in your high school English class, you’re more than qualified to make money as a writer.\\n\\nNow that we’re on the same page regarding who a writer is, let’s discuss how I make $100 per day in passive income as a writer.\\n\\nPhoto by Giorgio Trovato on Unsplash\\n\\nHow I Started My Writing Business\\n\\nNow, when I say writing I’m simply talking about my side hustle of writing stories on Medium.\\n\\nBefore I started writing stories on Medium for passive income, I had experimented with numerous other side hustles.\\n\\nSome turned out successful, some not so much.\\n\\nBut one thing led to another, and I took the leap of faith, deciding to put my experience and skills to work.\\n\\nOn the 7th of August 2023, I hit publish on my first post on Medium.\\n\\nI didn’t think much about it, so it came as a shock when I went\\n\\nfrom zero claps and no follower\\n\\nto thousands of claps on every one of my stories, 37k followers in less than 5 months\\n\\nScreenshot by Author\\n\\nand over 273,000 views on my stories every single month.\\n\\nScreenshot by Author\\n\\nNow, notice how I said I didn’t think too much about it.\\n\\nWell, that’s the point I’m trying to make.\\n\\nEven with the little effort I initially put into writing on Medium,\\n\\nI was still able to turn it into something very profitable in the shortest amount of time.\\n\\nSo where do I start?\\n\\nDo I show you the Income streams that make me the $100 per day in passive income?\\n\\nor do I show you the steps I took to get there?\\n\\nMmm.. Let’s start with the steps first and then finish strong with the income streams.\\n\\nThe 5 Steps I Took To Make $100 Per Day In Passive Income\\n\\nStep 1: I Chose a Topic I Loved And Was Knowledgeable About\\n\\nThis is key.\\n\\nI didn’t just watch a YouTube video that recommended a bunch of potentially lucrative niches.\\n\\nPhoto by Szabo Viktor on Unsplash\\n\\nI knew what I loved and went for it.\\n\\nNow, I see this scenario playing out way too often, where writers have to choose between\\n\\nTopics they love\\n\\nand topics that make the most money\\n\\nBecause frankly speaking, they’re usually not the same.\\n\\nI’m fortunate enough to love the finance niche, which is obviously very profitable.\\n\\nBut it’s fine if you don’t want to have to write about money.\\n\\nIn my opinion, writing about valuable topics you love and are knowledgeable about will always pave the way for monetization opportunities.\\n\\nPhoto by Mark Fletcher-Brown on Unsplash\\n\\nBecause to reach the stage where you can effortlessly turn your writing into passive income, you need to consistently provide value.\\n\\nAnd I’ll be the first person to tell you that it’s impossible to consistently provide value, when you lack the knowledge or passion for what you’re writing about.\\n\\nSo while some topics are more profitable than others, your knowledge and passion will almost never lead you astray.\\n\\nStep 2: I Found Validation From Writers Who Were Already Crushing It In My Niche\\n\\nI’m not going to lie,\\n\\nit can be hard to stay motivated and focused when you’re just starting, and all you can hear is crickets on your posts.\\n\\nIt’s even more frustrating when\\n\\nyou know you have something the world needs to hear\\n\\nbut it seems like no one wants to listen.\\n\\nPersonally, I can’t even count the number of times I almost threw in the towel.\\n\\nPhoto by Yuris Alhumaydy on Unsplash\\n\\nBut during those times, what kept me going were the role models I had found for myself.\\n\\nI made a list of the top writers in my niche\\n\\nHow many claps they got on average per story\\n\\nand how much they would approximately be able to make from their views.\\n\\nSome of the writers I had on my list were\\n\\nZulie Rane\\n\\nJenn leach\\n\\nand Abena talks\\n\\nFor me, if they were able to make money from writing on Medium, there was nothing stopping me.\\n\\nSo, do what I did: go on Medium and write a list of the top writers in your niche.\\n\\nPhoto by Kelly Sikkema on Unsplash\\n\\ntake inspiration from their writing style and topics too\\n\\nand whenever you feel demotivated, know that these people started from zero too.\\n\\nStep 3: I Decided On My Monetization Methods Way Before I Published My First Post\\n\\nIt’s so annoying how people say 'Consistency is key' and yet fail to provide any real ways for writers to stay consistent.\\n\\nBecause, yes, I know I need to be writing every day on Medium,\\n\\nbut try telling that to writer’s block or imposter syndrome when they kick in to mess up your consistency streak.\\n\\nThat said, one of the greatest motivations for writers even in the face of writer’s block is income.\\n\\nPhoto by Frederick Warren on Unsplash\\n\\nBecause once you start making money from a specific activity, it’s almost impossible to not want to continue.\\n\\nSo what I did was simple.\\n\\nEven before writing my first post on Medium, I had already made plans for how I was going to make money from my stories.\\n\\nAnd by the time I had published my 4th to 5th story, I had already made my first $10 on Medium.\\n\\nBut that first $10 was very special.\\n\\nIt was my proof of concept that Medium could actually turn into something profitable.\\n\\nPhoto by Morgan Housel on Unsplash\\n\\nStep 4: I Wrote For Both The Algorithm and My Readers\\n\\nGrowing on Medium is a perfect blend of quantity and quality.\\n\\nIt’s so important that you can do without the other.\\n\\nSome writers think that to grow on Medium, they just need to post 3–4 times a day.\\n\\nWhile others believe in quality and, as a result, take days and weeks to release new stories.\\n\\nBut from my experience, to grow on Medium, you need both.\\n\\nYou need to be able to churn out new stories at least 3 times a week, without compromising on the quality.\\n\\nPhoto by Christin Hume on Unsplash\\n\\nBut why?\\n\\nWell, because these two criteria have their different significance.\\n\\nQuality stories get you new followers and sales\\n\\nBoth more quantity helps the algorithm notice you (since Medium needs more stories to show to their members)\\n\\nSo in essence, the sweet spot is to\\n\\nWrite for the algorithm by staying consistent\\n\\nand to write for your readers by maintaining a reasonable level of quality (NB: quality here stands for Value)\\n\\nStep 5: I Was Intentional About The Law of Reciprocity\\n\\nThere’s no new idea under the sun, and whatever you try to sell has probably already been sold long before.\\n\\nYou won’t be the first to sell an eBook on the topic you write about, and probably not the last.\\n\\nSo what makes people buy from you instead of from other sellers?\\n\\nPhoto by Mark OFlynn on Unsplash\\n\\nFor me, it’s the law of reciprocity.\\n\\nAnd unless you’re able to obey the law of reciprocity, you’ll almost never be able to make sustainable passive income as a writer.\\n\\nBecause humans are reciprocal beings and will only buy from you if they feel you deserve it.\\n\\nYour stories are the first impression you make, and if they suck, what would you have them expect from your paid product?\\n\\nMoreso, sales are often a means for readers to express gratitude while anticipating even higher quality from your paid product.\\n\\nSo while you might have the best product, if your stories don’t convey how valuable you can be, you won’t generate any reasonable income.\\n\\nSo What Income Streams Make Me $100 Per Day Passively?\\n\\nNow, while I have some other active income streams from Medium, such as consultation sessions, that have made me $600 so far.\\n\\nScreenshot by Author\\n\\nThe income streams that generate $100 per day in passive income for me on Medium are\\n\\nDigital Products\\n\\nand Affiliate Marketing\\n\\nI sell my digital products on Gumroad.\\n\\nSo far, I’ve sold 345 copies which made me a total of $3508.21.\\n\\nScreenshot by Author\\n\\nAs for my affiliate commissions, I only promote 3–4 programs that I use and trust.\\n\\nOne of those programs made me $4,398.85 in passive income.\\n\\nScreenshot by Author\\n\\nWhile the other made me $1,679.34 in less than 5 months.\\n\\nScreenshot by Author\\n\\nConclusion\\n\\nNow, based on my story, do you still think Medium isn’t worth stressing over?\\n\\nWell, I’m sure you don’t.\\n\\nI need you to understand that Medium is one of the best platforms for beginners to grow an audience and generate passive income.\\n\\nNot YouTube\\n\\nNot TikTok\\n\\nMedium!!\\n\\nIf not, How do you explain me getting 1,000 followers in just my first month, even when I knew nothing about how the algorithm worked?\\n\\nIt’s seriously crazy.\\n\\nAnd it’s not just me; one of my clients, Jordan Gibbs, grew over 2.2k followers in just 3 months of writing on Medium after our session.\\n\\nScreenshot of Jordan Gibbs on Medium\\n\\nSo, if we could build a monetizable audience as complete beginners, there’s nothing stopping you.\\n\\nNow, Remember how I mentioned growing over 37k Followers, with over 273,462 views every month.\\n\\nWell, I wrote an entire book sharing exactly how I did it.\\n\\nIt’s called the Medium Income Playbook.\\n\\nThe Medium Income Playbook\\n\\nIn this ebook, I share my exact thought process behind\\n\\nFinding endless profitable content ideas related to your specific topic\\n\\nCreating click-worthy titles and viral headlines to capture readers' attention.\\n\\nCreating engaging stories that convert readers into loyal subscribers and even buyers.\\n\\nMy writing principles (Quantity vs quality, KLT principle and the MVA principle)\\n\\nAnd I’ll also share my personal experiences on how I managed to grow to over 37k followers (as I speak) on Medium in less than 5 months.\\n\\nLiterally everything you need to go from zero followers to making passive income as a writer is in the Medium Income Playbook.\\n\\nSo If you want to start your very own profitable Medium page,\\n\\nCheck out the steps I personally tried out and have now shared in the Medium Income Hustle playbook.\\n\\nYou can click here to Grab The Medium Income Playbook.\"}}],\n",
       " '37a2cbe8bd15': [{'id': 'be50cc308056',\n",
       "   'title': 'Why You Should Pay Attention to Perplexity AI',\n",
       "   'subtitle': 'I have Replaced Google with This New A.I.-Powered Search Engine!',\n",
       "   'author': '37a2cbe8bd15',\n",
       "   'publication_id': '*Self-Published*',\n",
       "   'published_at': '2024-02-02 11:09:46',\n",
       "   'last_modified_at': '2024-02-18 11:33:57',\n",
       "   'tags': ['technology',\n",
       "    'internet',\n",
       "    'artificial-intelligence',\n",
       "    'business',\n",
       "    'entrepreneurship'],\n",
       "   'topics': ['artificial-intelligence'],\n",
       "   'claps': 997,\n",
       "   'voters': 148,\n",
       "   'word_count': 506,\n",
       "   'responses_count': 17,\n",
       "   'reading_time': 2.459433962264151,\n",
       "   'url': 'https://medium.com/@pareto_investor/why-you-should-pay-attention-to-perplexity-ai-be50cc308056',\n",
       "   'unique_slug': 'why-you-should-pay-attention-to-perplexity-ai-be50cc308056',\n",
       "   'image_url': 'https://miro.medium.com/1*3ydXkh_Hth6MwLVoAduj_A.png',\n",
       "   'lang': 'en',\n",
       "   'is_series': False,\n",
       "   'is_locked': True,\n",
       "   'is_shortform': False,\n",
       "   'top_highlight': 'As it bypasses the traditional ad-driven model of the internet, it challenges the status quo of online information access.',\n",
       "   'content': {'id': 'be50cc308056',\n",
       "    'content': 'Why You Should Pay Attention to Perplexity AI\\n\\nI have Replaced Google with This New A.I.-Powered Search Engine!\\n\\nHow to Get Rich with Investing (without Getting Lucky)\\n\\n\\n\\nAs you know, AI technology is changing the world fast. One of the really cool new things out there is Perplexity AI.\\n\\nThis platform is revolutionizing how we access and process information, and I believe it’s essential to understand why it’s becoming a formidable competitor to giants like Google and large language models (LLMs) like GPT (Generative Pre-trained Transformer).\\n\\n\\n\\nJeff Bezos’ Involvement\\n\\nJeff Bezos has shown interest in Perplexity AI, in 2022.\\n\\nThis move is not just about financial gain but a transformative technology.\\n\\nhttps://www.perplexity.ai/search/Jeff-Bezos-invests-NRSKCsy5SSCTHU5UEdyfjA\\n\\nPerplexity AI represents a shift akin to the explosion of online advertising, which skyrocketed from zero in 1994 to a staggering $365 billion in recent years, paralleling a decline in traditional print revenues.\\n\\n\\n\\nPerplexity AI Difference\\n\\nAt its core, Perplexity AI is a search engine, but it’s more than that.\\n\\nIt’s an intelligent, real-time information processor.\\n\\n\"Even though Perplexity isn’t perfect, it’s very good. I’m now more convinced that A.I.-powered search engines like Perplexity could loosen Google’s grip or at least force it to play catch-up\" - NY Times\\n\\nTraditional search engines often lead users through a labyrinth of ads, pop-ups, and irrelevant content.\\n\\nPerplexity AI cuts through this clutter, offering a more streamlined, efficient, and user-friendly experience.\\n\\nFocus Options: \\nPerplexity AI allows users to specify information sources, from websites to academic papers, offering tailored and relevant results.\\n\\nAttachment and Co-Pilot Features: \\nUsers can attach documents and images for analysis and engage with a chatbot-like feature for interactive searches, enhancing the depth and breadth of research.\\n\\nReal-Time, Source-Supported Information: \\nUnlike traditional LLMs, which may generate responses based on extensive but fixed training data, Perplexity AI prioritizes real-time information and source-backed data, minimizing the risk of inaccuracies.\\n\\nPerplexity AI’s approach has far-reaching implications for content consumption.\\n\\nAs it bypasses the traditional ad-driven model of the internet, it challenges the status quo of online information access.\\n\\nThis has a direct impact on publishers and platforms reliant on ad revenues and user data.\\n\\nThe platform’s ability to offer direct, ad-free access to information might reshape how users interact with digital content, potentially leading to a decline in traditional ad revenues for many sites.\\n\\nFuture of Information Access?\\n\\nPerplexity AI could potentially be the future of information access.\\n\\nIts focus on real-time, source-supported information, coupled with user-friendly features, positions it as a serious competitor to established tech giants.\\n\\nAlso, to read:\\n\\nChatGPT has Just Been Dethroned by French Geniuses!\\nThese Three Individuals, a Former Researcher at DeepMind and Two Others from Meta, Completely Transformed the AI Game!medium.com\\n\\nWhile it’s too early to predict if Perplexity will dominate the market, its unique approach coupled with AI is significant!\\n\\nSo, I’m going to keep watching it closely, and for now, I’ll keep using this more user-friendly, transparent, and efficient information access tool instead of Google.\\n\\nSincerely,\\n\\nThe Pareto Investor\\n\\nMy Book \"The Little Principle That Beats the Market\" is an essential read for anyone seeking a smarter, more effective way to invest.'}},\n",
       "  {'id': '82653b2b36e2',\n",
       "   'title': 'Mistral CEO Confirms ‘Leak’ of New Open-Source AI Model Nearing GPT-4 Performance',\n",
       "   'subtitle': 'The new open-source large language model (LLM), rumored to approach the performance of GPT-4, a benchmark in the field.',\n",
       "   'author': '37a2cbe8bd15',\n",
       "   'publication_id': '*Self-Published*',\n",
       "   'published_at': '2024-02-01 12:25:45',\n",
       "   'last_modified_at': '2024-02-18 11:34:27',\n",
       "   'tags': ['artificial-intelligence',\n",
       "    'technology',\n",
       "    'business',\n",
       "    'machine-learning',\n",
       "    'programming'],\n",
       "   'topics': ['artificial-intelligence'],\n",
       "   'claps': 610,\n",
       "   'voters': 71,\n",
       "   'word_count': 555,\n",
       "   'responses_count': 7,\n",
       "   'reading_time': 2.6443396226415095,\n",
       "   'url': 'https://medium.com/@pareto_investor/mistral-ceo-confirms-leak-of-new-open-source-ai-model-nearing-gpt-4-performance-82653b2b36e2',\n",
       "   'unique_slug': 'mistral-ceo-confirms-leak-of-new-open-source-ai-model-nearing-gpt-4-performance-82653b2b36e2',\n",
       "   'image_url': 'https://miro.medium.com/0*k4FEslXGg4pEwzjx.jpg',\n",
       "   'lang': 'en',\n",
       "   'is_series': False,\n",
       "   'is_locked': True,\n",
       "   'is_shortform': False,\n",
       "   'top_highlight': 'Quantization, the process mentioned in this context, is a technique in machine learning (ML) that simplifies AI model architectures for use on less powerful hardware.',\n",
       "   'content': {'id': '82653b2b36e2',\n",
       "    'content': 'Mistral CEO Confirms ‘Leak’ of New Open-Source AI Model Nearing GPT-4 Performance\\n\\nThe new open-source large language model (LLM), rumored to approach the performance of GPT-4, a benchmark in the field.\\n\\nHow to Get Rich with Investing (without Getting Lucky)\\n\\nArthur Mensch - Mistral CEO\\n\\nThe buzz began when a user, \"Miqu Dev,\" uploaded files on HuggingFace, a prominent open-source AI platform.\\n\\nThese files allegedly represent a new LLM, \"miqu-1–70b,\" closely related to Mistral’s technology, a leading open-source AI firm from Paris.\\n\\nmiqudev (Miqu Dev)\\nUser profile of Miqu Dev on Hugging Facehuggingface.co\\n\\nAn Unexpected Leak\\n\\nThis development took an intriguing turn with an anonymous 4chan post, possibly by \"Miqu Dev,\" leading to widespread online discussion.\\n\\n/g/ - /lmg/ - Local Models General - Technology - 4chan\\nlmg/ - Local Models General - \"/g/ - Technology\" is 4chan\\'s imageboard for discussing computer hardware and software…boards.4chan.org\\n\\nThe AI community, including on X, LinkedIn, and other platforms, began analyzing the potential of this new model.\\n\\nSpeculations arose about \"Miqu\" being a quantized version of a Mistral model, possibly an internal leak or a rogue move by an employee or customer.\\n\\nHowever, I suspect that Mistral orchestrated everything, given the team’s notably peculiar communication style.\\n\\nAlso, to read:\\n\\nChatGPT has Just Been Dethroned by French Geniuses!\\nThese Three Individuals, a Former Researcher at DeepMind and Two Others from Meta, Completely Transformed the AI Game!medium.com\\n\\nMistral CEO’s Clarification\\n\\nArthur Mensch, co-founder and CEO of Mistral, addressed the leak on X.\\n\\n\\n\\nHe confirmed that an over-enthusiastic customer of Mistral leaked a quantized version of an old model, which was initially retrained from Meta’s Llama 2.\\n\\nLMSys Leaderboard. (Screenshot from Dec 22, 2023) Mixtral 8x7B Instruct v0.1 achieves an Arena\\nElo rating of 1121 outperforming Claude-2.1 (1117), all versions of GPT-3.5-Turbo (1117 best), Gemini Pro\\n(1111), and Llama-2–70b-chat (1077). Mixtral is currently the best open-weights model by a large margin.\\n\\nMensch’s response suggests that Mistral is actively developing a model comparable to GPT-4, hinting at exciting advancements to come.\\n\\nQuantization?\\n\\nQuantization, the process mentioned in this context, is a technique in machine learning (ML) that simplifies AI model architectures for use on less powerful hardware.\\n\\nThis approach could democratize access to advanced AI technologies, previously limited to those with high-end computing resources.\\n\\nOpen-Source AI\\n\\nIf Mistral or another open-source initiative releases a model rivaling GPT-4, it could shift the competitive landscape significantly.\\n\\nThis situation potentially represents a pivotal moment for open-source generative AI.\\n\\nMixtral 8x7b is exceptional - It’s like a light belt fighting in heavyweight!\\n\\nSuch a development could challenge the dominance of proprietary models like GPT-4, especially as more businesses consider integrating open-source solutions into their applications.\\n\\nCompetitive Pressure\\n\\nOpenAI, the organization behind GPT-4, might face substantial competition if an open-source model of similar capability becomes widely available.\\n\\nWhile OpenAI currently leads with its advanced versions like GPT-4 Turbo and GPT-4V (vision), the fast-paced advancements in open-source AI could redefine this dynamic market.\\n\\nThe crucial question is whether OpenAI’s head start, and unique features will be enough to maintain its leadership in the LLM space?\\n\\nUnpredictable AI Future\\n\\nSo, the \"Miqu\" leak is true, it’s fascinating to see how open-source models are stepping up, challenging the big proprietary players.\\n\\nWhat’s really interesting here is how this event not only shows the rapid progress in AI tech but also suggests a future where both open-source and proprietary models coexist.\\n\\nIt’s a really exciting time in the field!\\n\\nSincerely,\\n\\nThe Pareto Investor\\n\\nMy Book \"The Little Principle That Beats the Market\" is an essential read for anyone seeking a smarter, more effective way to invest.'}},\n",
       "  {'id': 'bcee41843775',\n",
       "   'title': 'ChatGPT has Just Been Dethroned by French Geniuses!',\n",
       "   'subtitle': 'These Three Individuals, a Former Researcher at DeepMind and Two Others from Meta,  Completely Transformed the AI Game!',\n",
       "   'author': '37a2cbe8bd15',\n",
       "   'publication_id': '*Self-Published*',\n",
       "   'published_at': '2024-01-20 18:06:31',\n",
       "   'last_modified_at': '2024-02-18 11:38:23',\n",
       "   'tags': ['artificial-intelligence',\n",
       "    'programming',\n",
       "    'machine-learning',\n",
       "    'technology',\n",
       "    'business'],\n",
       "   'topics': ['artificial-intelligence'],\n",
       "   'claps': 4495,\n",
       "   'voters': 902,\n",
       "   'word_count': 1075,\n",
       "   'responses_count': 70,\n",
       "   'reading_time': 4.8899371069182385,\n",
       "   'url': 'https://medium.com/@pareto_investor/chatgpt-has-just-been-dethroned-by-french-geniuses-bcee41843775',\n",
       "   'unique_slug': 'chatgpt-has-just-been-dethroned-by-french-geniuses-bcee41843775',\n",
       "   'image_url': 'https://miro.medium.com/1*6IIgPUJ-0UPUL4xe3Y5IKg.png',\n",
       "   'lang': 'en',\n",
       "   'is_series': False,\n",
       "   'is_locked': True,\n",
       "   'is_shortform': False,\n",
       "   'top_highlight': 'However, its size also allows it to run locally on devices like Macs and even some iPhones, making it highly accessible.',\n",
       "   'content': {'id': 'bcee41843775',\n",
       "    'content': 'ChatGPT has Just Been Dethroned by French Geniuses!\\n\\nThese Three Individuals, a Former Researcher at DeepMind and Two Others from Meta, Completely Transformed the AI Game!\\n\\nHow to Get Rich with Investing (without Getting Lucky)\\n\\nMistral AI: Guillaume Lample, Arthur Mensch et Timothée Lacroix.\\n\\nLet me introduce you to a company, which didn’t exist just 8 months ago, and has managed to shake the entire AI industry in that short period.\\n\\nAlso, to read:\\n\\nApple Unveils Ferret, Its First Open Source AI, Surpassing GPT-4\\nApple Has Entered the Artificial Intelligence Race with Ferret, its First Open-Source Multimodal Language Model (LLM).medium.com\\n\\nThey’ve released alternative models to ChatGPT that have surpassed all competition, valuing the company at nearly $2 billion.\\n\\nRemarkably, they’ve achieved this without any deceptive promotional videos or major marketing campaigns.\\n\\nTheir work is so intriguing that I find myself checking Twitter daily, just to see if they’ve made any new announcements!\\n\\n\\n\\nLet me explain why these French innovators have completely transformed the game and how you could also benefit from their advancements.\\n\\nTo start, I suggest we look at a table of the best AI models competing with ChatGPT.\\n\\nLMSys Leaderboard. (Screenshot from Dec 22, 2023) Mixtral 8x7B Instruct v0.1 achieves an Arena\\nElo rating of 1121 outperforming Claude-2.1 (1117), all versions of GPT-3.5-Turbo (1117 best), Gemini Pro\\n(1111), and Llama-2–70b-chat (1077). Mixtral is currently the best open-weights model by a large margin.\\n\\nThis table reveals some fascinating points.\\n\\nFor instance, it seems ChatGPT shows regression between versions.\\n\\nThere are also scores that appear inconsistent or out of order, which is odd.\\n\\nBut most notably, there are these small yellow lines labeled with names like \"Mixtral\"— names that evoke the wind.\\n\\nAt first glance, it doesn’t seem very impressive, ranked seemingly low.\\n\\nHowever, this perception overlooks the revolutionary impact hidden behind them.\\n\\nIt’s important to realize that there are many ways to measure an LLM’s (Language Model) performance, and it’s not straightforward.\\n\\nBenchmarks, essentially a set of questions posed to an LLM to test its capabilities, are one method.\\n\\nFor example, let’s consider a philosophical question that needs the right term to be replaced.\\n\\nThe issue is that models have been known to theoretically ace these benchmarks with high scores, but in practical use, they may not be as impressive.\\n\\nThis phenomenon is relatively common, as seen in the case of Google’s models like Gemini, which seemed to be optimized to maximize their MMLU benchmark scores.\\n\\nHowever, in actual usage, they somehow feel less effective than ChatGPT-4, possibly due to dataset leakage during training.\\n\\nWhile benchmarks can be enlightening, human intuition remains the most reliable gauge of a model’s effectiveness, especially in real-world applications.\\n\\nSo, How Do We Rank These Models?\\n\\nOne method is to use a voting system similar to the ELO rating in chess. This involves comparing different model responses and assigning points accordingly.\\n\\nThis brings us back to the table above, which is one of the most renowned rankings of this kind.\\n\\nHere, you can see the crème de la crème of AI models, including proprietary models like GPT-4 at the top, followed by Claude from Anthropic (formed by former OpenAI employees), and various GPT-3.5 versions.\\n\\nFurther down, we see Google’s newly announced Gemini Pro. These are all proprietary models.\\n\\nBut open models are what really interest us.\\n\\nGenerally smaller and requiring less computing power, they are freely downloadable for local use and can be retrained with our data.\\n\\nUntil recently, the only serious alternative to ChatGPT and its variants was LIAMA 2, a fine-tuned version of Facebook’s model.\\n\\nHowever, two months ago, small yellow lines appeared on the chart, representing models like Mistral.\\n\\nMistral was introduced in an unorthodox way. A tweet from the then-obscure Mistral account shared a magnet link (a type of torrent), with no context or promotional material, just the link.\\n\\nClicking it revealed a 7-billion-parameter model.\\n\\nIt’s vital to understand model size here - like weight classes in boxing, the number of parameters (billions, in this case) indicates the ‘weight’ or size of the model. Larger models demand more computational power and sophisticated hardware.\\n\\nFor instance, models like GPT-3 and GPT-4 are massive, with potentially over 100 billion parameters, requiring substantial server infrastructure to host.\\n\\nOn the other hand, smaller models like LIAMA 2 were released in various sizes, the largest being 70 billion parameters, still requiring significant hardware to run.\\n\\nThe Appearance of Mistral’s 7-billion-Parameter Model Was a Game-Changer\\n\\nAt first, people were skeptical due to its small size, but it soon became clear that this model was exceptional. Despite its modest parameter count, it ranked in the top 10, challenging even the best 70-billion-parameter models. The top iteration of Mistral, the Sterling LM 7b Alpha, surpassed GPT-3.5 variants and even LIAMA 2’s 70-billion-parameter model.\\n\\nMistral with modest parameter count, ranked in the top 10, challenging even the best 70-billion-parameter models.\\n\\nThis development spurred a flurry of activity, with the community downloading, experimenting with, and enhancing the model.\\n\\nMistral’s smaller size also means it’s less likely to have as extensive an internet knowledge base and might be more prone to ‘hallucinating’ or making up information.\\n\\nHowever, its size also allows it to run locally on devices like Macs and even some iPhones, making it highly accessible.\\n\\nThen, just 10 days ago, another revolution occurred: the introduction of Mixtral 8x7b.\\n\\nThis model uses a ‘Mixture of Experts’ approach, where different parts of the model specialize in various domains (e.g., math, coding, literature).\\n\\nThis architecture, similar to that used in GPT-4, allows for a model that benefits from the size of an 8 x 7 model without requiring the corresponding computational power.\\n\\nIn simple terms, you get the advantages of a 56-billion-parameter model for the computational cost of a 14-billion-parameter one.\\n\\nMixtral 8x7b is exceptional— It’s like a light belt fighting in heavyweight!\\n\\nThe most recent addition is Mistral Medium, available through their cloud platform.\\n\\nInitial comparisons between Mistral Medium and GPT-4 suggest that while GPT-4 might be constrained to be ‘safe’ and politically correct, thus reducing its performance, Mistral Medium provides more precise, actionable responses.\\n\\nMistral’s Innovation Is Reshaping the AI Landscape\\n\\nMistral has managed to create smaller, more efficient models that can compete with giants like GPT-4, democratizing AI and opening up new possibilities for both developers and enterprises.\\n\\nThis is a company worth watching closely, especially as they continue to push the boundaries of what’s possible in AI.\\n\\nUpdate 27/01/24\\n\\nLLM Ranks: Update 27/01/24\\n\\nGoogle Gemini Pro is now second, after the update, in LLM Rank.\\n\\nMistral release Medium and surpass Mixtral 8x7b in performance.\\n\\nMicrosoft entrer into top 15 with its Wizard model?\\n\\nSincerely,\\n\\nThe Pareto Investor\\n\\nMy Book \"The Little Principle That Beats the Market\" is an essential read for anyone seeking a smarter, more effective way to invest.'}},\n",
       "  {'id': '5272ff33c5cd',\n",
       "   'title': 'ChatGPT Has Gone Bad!',\n",
       "   'subtitle': 'It seems that ChatGPT, particularly GPT-4, is becoming foolish, or more precisely, it’s becoming lazy.',\n",
       "   'author': '37a2cbe8bd15',\n",
       "   'publication_id': '*Self-Published*',\n",
       "   'published_at': '2024-01-28 15:02:49',\n",
       "   'last_modified_at': '2024-02-18 16:16:17',\n",
       "   'tags': ['artificial-intelligence',\n",
       "    'technology',\n",
       "    'programming',\n",
       "    'machine-learning',\n",
       "    'entrepreneurship'],\n",
       "   'topics': ['artificial-intelligence', 'programming'],\n",
       "   'claps': 2106,\n",
       "   'voters': 295,\n",
       "   'word_count': 2283,\n",
       "   'responses_count': 65,\n",
       "   'reading_time': 8.998427672955975,\n",
       "   'url': 'https://medium.com/@pareto_investor/chatgpt-has-gone-bad-5272ff33c5cd',\n",
       "   'unique_slug': 'chatgpt-has-gone-bad-5272ff33c5cd',\n",
       "   'image_url': 'https://miro.medium.com/0*nFHZy_dv1ACH7EOM',\n",
       "   'lang': 'en',\n",
       "   'is_series': False,\n",
       "   'is_locked': True,\n",
       "   'is_shortform': False,\n",
       "   'top_highlight': 'There are several versions of GPT-4. Yes, they correspond to different versions at a given time. For example, GPT4 03–14 is the version from March 2023, 06 is from June 2023, and so we can already see the first thing is that they are not ordered chronologically.',\n",
       "   'content': {'id': '5272ff33c5cd',\n",
       "    'content': 'ChatGPT Has Gone Bad!\\n\\nIt seems that ChatGPT, particularly GPT-4, is becoming foolish, or more precisely, it’s becoming lazy.\\n\\nHow to Get Rich with Investing (without Getting Lucky)\\n\\n\\n\\nIf you look at this leaderboard below, which shows the biggest models, you look at the very best, but do you notice something strange?\\n\\n\\n\\nThere are several versions of GPT-4. Yes, they correspond to different versions at a given time. For example, GPT4 03–14 is the version from March 2023, 06 is from June 2023, and so we can already see the first thing is that they are not ordered chronologically.\\n\\nIs there anything else?\\n\\nYes, on Claude’s ones. Claude 2 is below Claude 1, and CL 2.1 is below the other two.\\n\\nThis means that people generally find recent proprietary models to be of lower quality than older ones.\\n\\nDo you realize what that means?\\n\\nYou have teams with millions of dollars in funding and hundreds of people working on models, they spend months and months creating new versions that are rated lower than stuff released a year and a half ago.\\n\\nAlso, to read:\\n\\nChatGPT has Just Been Dethroned by French Geniuses!\\nThese Three Individuals, a Former Researcher at DeepMind and Two Others from Meta, Completely Transformed the AI Game!medium.com\\n\\nWhat could explain that?\\n\\nIt’s not so much a question of becoming stupid, that is, of no longer being able to solve tasks, but it’s a general question of behavior.\\n\\nWhere maybe 6 months, a year ago, we could ask it to write a complete script, for example, with development, because it’s quite telling.\\n\\nI remember at the time I was learning Swift, and I asked GPT to do really complex tasks on the Mac’s GPU, and it churned out scripts in Swift and generated shaders.\\n\\nIt seems we’ve gone from that to now, where if we look at some examples, we see that it is constantly asking us to do the work. I’ve noticed that it’s a bit lazy.\\n\\nYou ask it to do a code, before it did it for you, now it explains how you can get there, gives you little snippets, but it’s up to you to assemble the thing.\\n\\nThere are people who have done tests between a GPT-4, for example, and other models, typically open-source models.\\n\\nI’ve seen it with Mixtral, the latest open-source models that rival the quality of GPT-3.5, etc.\\n\\nThere is supposed to be a gap in intelligence, but when you look at it from the point of view of laziness, indeed, the distinction was striking.\\n\\nIt’s not a problem that cannot be solved because you just have to reprompt it, ask it for the full code, or to implement a particular part yourself, and you end up getting there.\\n\\nIt’s as if it had a desire to shorten its responses to be in a more conversational mode, and in the end, you get what you want.\\n\\nMaybe the current versions of GPT-4 have been more guided to follow prompts better.\\n\\nWe could imagine that one explanation would be that a model that is super effective at following precise instructions is objectively very useful, but maybe we’ve lost something in the process, in their autonomy, and their ability to manage to make very long, valid generations with a small prompt.\\n\\nThat’s the first track, which is not bad news because maybe we can compensate slightly by trying to be a bit more precise in what we tell it.\\n\\nIf that’s true, one solution would be to create system prompts, which will guide how we want our assistant to behave.\\n\\nSo, it’s indeed a way to get around the issue, especially since people have realized that depending on the intermediary they use with the servers, it doesn’t necessarily behave the same way.\\n\\nThere are people who have tried on the desktop version of ChatGPT versus the mobile version, and they didn’t get the same results at all.\\n\\nIf you didn’t know, in fact, the mobile version of ChatGPT has a different prompt system. What’s at the top of the chat that we don’t see is modified depending on the device we use.\\n\\nBasically, on the ChatGPT app, it seems that OpenAI deliberately asked GPT-4 to make shorter responses.\\n\\nI imagine the idea is that people are on mobile and therefore they want denser information, yeah, and maybe quick information, just like that, so they don’t have to read for 10 minutes the answer on their phone.\\n\\nI think there’s another explanation that’s valid, it’s a matter of cost, especially on the mobile versions of OpenAI.\\n\\nI don’t know if you’ve seen, but they have discussion models, so in fact, they integrated Whisper to understand voice instructions, and their new text-to-speech generation model.\\n\\nIt’s very likely that all this is quite expensive for them, and so reducing the output, reducing the size of the messages generated by GPT, saves them from voice generation.\\n\\nIntroducing Whisper\\nWe\\'ve trained and are open-sourcing a neural net called Whisper that approaches human level robustness and accuracy on…openai.com\\n\\nIn fact, it’s possible that even in terms of quality, that is, even at the model level, so that is the file that runs on the OpenAI server, it’s possible that there are drops in quality.\\n\\nWhat would explain that?\\n\\nIt’s just an observation, I wonder what has changed between ChatGPT a year ago and ChatGPT now, and I think, well, in fact, it feeds off the feedback we give it.\\n\\nSo maybe it’s just us, we’re too bad to interact with ChatGPT, and in fact, it was a bit pure when it came out, and it was very effective, and it became influenced by humans, and so it became human crap.\\n\\nThis is one of the most solid theories currently being advanced by people.\\n\\nIn short, there are three main theories that could explain this:\\n\\n1. First, it Feeds off the Bad Feedback We Give to It\\n\\nIf you’ve noticed on the ChatGPT interface, once every 20 times or so, you’ll be asked to rate AI’s response.\\n\\nIndeed, there’s a good chance that this data is used for training purposes to improve, to theoretically bring the AI closer to what the end-user, the human, would want.\\n\\nIt would make sense for them to do it, it would seem like an excellent idea, but indeed, quite a few people say that maybe this has contributed to lowering its quality, because we humans would be bad teachers.\\n\\nIn fact, we wouldn’t be able to objectively identify what are the most informative, most useful responses, and so these selections have gradually deviated ChatGPT from its original intelligence to what it is today.\\n\\n2. The Second Possibility is the Lobotomization of Proprietary Models\\n\\nWhat people know is that if you ask ChatGPT to do illegal things, but not just illegal, then it will tell you it can’t do it because it’s a responsible model.\\n\\nIt has become very puritanical, or I don’t know if that’s the word, but yes, I think it’s a good word. And this existed from the beginning, it’s what we call RLHF, reinforcement learning through human feedback.\\n\\nIt’s the technique that unlocked language models, so don’t spit on it because it’s really the thing that allowed ChatGPT 3.5, for example, to have such a significant upgrade between GPT-3 and GPT-3.5.\\n\\nOn the first versions of ChatGPT, there was already a human feedback system that made it refuse certain requests, etc.\\n\\nBut what is likely, the theory that has been put forward and that honestly verifies itself quite easily, is that little by little, every time someone managed to ask ChatGPT to generate an output that didn’t please them, they probably complained somewhere on Twitter or something like that, and OpenAI gradually had to update its human feedback reinforcement system to integrate every little complaint made by every person who was not happy.\\n\\nLittle by little, they had to add safeguards and more safeguards in their filtering model, and that’s what has slowly but surely participated in a certain lobotomization of the model.\\n\\nBut there’s another explanation, another explanation that’s even more seductive and plausible, in my opinion, which is that the problem OpenAI currently has, and that not all open-source models that are doing very well have, is that they have a lot of users and they gained them very quickly.\\n\\n3. GPT-4 is Extremely Costly to Operate and OpenAI Compromising Quality\\n\\nWe know they received a lot of funding from Microsoft, but generally speaking, one of the major challenges for OpenAI is to be profitable and to finance the monumental hardware costs of running GPU farms that serve ChatGPT 3 and 4 to the entire world.\\n\\nOne of the main reasons to believe that this is very expensive is that for the past year and a half, there haven’t been many other GPT-4 models released.\\n\\nThe theory that GPT-4 is extremely costly to operate and that OpenAI might be operating at a significant loss, even more than we might imagine, is plausible. It’s not impossible that it’s really, really expensive.\\n\\nSo, what do you do when you have a product that is extremely expensive and used by millions and millions of people with huge usage spikes? You look for solutions to reduce the cost of your inferences.\\n\\nIn other words, you try to make sure your computer needs less computing power to generate a certain number of tokens and respond to your chat.\\n\\nThe issue is always how to maximize the number of simultaneous users who can query GPT-4 running on a server farm.\\n\\nCurrently, what you can do to increase the performance of your server, for example, use more efficient code, better models.\\n\\nFor instance, most servers providing chatbots use VLLM (Vector-Log-Log-Max), the project par excellence for serving the greatest number of users as efficiently as possible.\\n\\nAnother technique that’s possible is to reduce the size of the models.\\n\\nThis means that you take your base model that you’ve trained and reduce its size. Now, you might think that if you halve the size of GPT-4, for example, it would become half as smart.\\n\\nBut that’s not the case at all. These models are essentially large matrices of numbers, floating-point numbers with many decimal places for high precision. The idea is that you can reduce the size of this matrix by half, for example, by reducing its precision.\\n\\nSo, instead of having numbers with, say, 32 decimal places, you might go down to 16. You’re not halving your model; you’re just reducing its precision.\\n\\nThis process is called quantization.\\n\\nIf you have a 32 billion parameter model that would normally be around 30 GB, for example, through quantization, you can reduce the precision of these weights and switch to FP16 or Q8, just nomenclature to describe how much you’re compromising on the precision of your weights.\\n\\nThe impact is limited.\\n\\nThere’s a bit of the chaos theory here, where a little lack of precision adds up.\\n\\nAt one point, it was thought to be quite limited, but it’s possible that there’s still a trade-off, albeit not catastrophic.\\n\\nPeople have tested the perplexity levels of models, which is just a way to know if a model is performing well and if it can accurately predict the continuation of a text.\\n\\nThey’ve created curves to compare the different quantized versions to see how severe the impact is on quality.\\n\\nFor example, using an 8-bit representation is very close to the original quality, but at 4 bits, it’s significantly degraded, and at 2 bits, it’s much worse.\\n\\nSo, we have a vague idea of the impact of quantization on performance, but what’s pretty certain is that you get incredible performance gains in terms of tokens generated per second and the amount of memory needed.\\n\\nWith a powerful GPU, like a 4090 with 24 GB of VRAM, you can run models with 34 billion parameters without a problem thanks to quantization.\\n\\nThe recent versions of ChatGPT, like GPT-4 Turbo, may have these kinds of optimizations to deploy and serve them to a lot of people, potentially using quantization.\\n\\nBut it’s not that you can’t make a model both efficient and precise. Some strategies involve reducing the precision of certain layers of the model but not all.\\n\\nYou get the best of both worlds: great performance and relatively high precision. However, quantization equals loss of precision equals a drop in performance.\\n\\nIt’s tricky because you might keep the same name, like GPT-4, but the web version, for example, might be a heavily quantized version that’s super fast and performs maybe 5% or 8% worse.\\n\\nIt’s not demonstrably worse, but enough to notice a difference.\\n\\nThere’s One More Theory, a Bit More Humorous\\n\\nIt has been suggested that LLMs like GPT-4 are sensitive to external factors, like the time of year.\\n\\nFor instance, if the prompt system says it’s January, the model might perform less well than if it said May.\\n\\nThis theory suggests that GPT-4, having learned from us, might mirror human tendencies like seasonal changes in motivation.\\n\\nLastly, despite these challenges, OpenAI has recently made announcements about new models in audio transcription and other areas, highlighting advancements that are often overlooked.\\n\\nNew embedding models and API updates\\nWe are launching a new generation of embedding models, new GPT-4 Turbo and moderation models, new API usage management…openai.com\\n\\nSincerely,\\n\\nThe Pareto Investor\\n\\nMy Book \"The Little Principle That Beats the Market\" is an essential read for anyone seeking a smarter, more effective way to invest.'}},\n",
       "  {'id': '211b2207b566',\n",
       "   'title': '7 Best Books for Beginners in Stock Market & Personal Investing!',\n",
       "   'subtitle': 'My Honest Review on What I believe are the Best Finance Books for Investing & Money',\n",
       "   'author': '37a2cbe8bd15',\n",
       "   'publication_id': '*Self-Published*',\n",
       "   'published_at': '2024-02-18 15:35:18',\n",
       "   'last_modified_at': '2024-02-18 17:51:51',\n",
       "   'tags': ['books', 'investing', 'education', 'money', 'self-improvement'],\n",
       "   'topics': ['money'],\n",
       "   'claps': 15,\n",
       "   'voters': 6,\n",
       "   'word_count': 788,\n",
       "   'responses_count': 0,\n",
       "   'reading_time': 3.1735849056603773,\n",
       "   'url': 'https://medium.com/@pareto_investor/my-best-7-books-for-beginners-in-stock-market-personal-investing-211b2207b566',\n",
       "   'unique_slug': 'my-best-7-books-for-beginners-in-stock-market-personal-investing-211b2207b566',\n",
       "   'image_url': 'https://miro.medium.com/0*yLNWOqSKbyfgVbO7',\n",
       "   'lang': 'en',\n",
       "   'is_series': False,\n",
       "   'is_locked': False,\n",
       "   'is_shortform': False,\n",
       "   'top_highlight': '',\n",
       "   'content': {'id': '211b2207b566',\n",
       "    'content': '7 Best Books for Beginners in Stock Market & Personal Investing!\\n\\nMy Honest Review on What I believe are the Best Finance Books for Investing & Money\\n\\nHow to Get Rich with Investing (without Getting Lucky)\\n\\n\\n\\nOver the years, I’ve delved deep into the world of investing and personal finance, sharing my summaries and insights right here with you.\\n\\nMany of you have asked about the best books to read for enhancing your stock market journey.\\n\\nAlso, to read:\\n\\nI Honestly Learned More About Money from \"Rich Dad Poor Dad\" Than from All My Schooling!\\n15 Things to Remember from this Book!medium.com\\n\\nSo, today, I’m thrilled to present my top book recommendations on investing, to guide you through your learning journey.\\n\\nLet’s explore these gems one by one:\\n\\n1. \"The Little Book that Beats the Market\" by Joel Greenblatt\\n\\nDespite its modest 112 pages, this book packs a punch with its humor and insightful investment strategies, particularly the Magic Formula.\\n\\nThis formula focuses on key performance indicators like return on assets and the price/earnings ratio.\\n\\nGreenblatt’s approach is both educational and entertaining, making complex concepts accessible and enjoyable.\\n\\nHis witty writing style, exemplified by quotes like the one about running through a dynamite factory with a burning match, makes this a unique read in the finance genre.\\n\\nFor practical application, the Magic Formula screener is available for free:\\n\\nmagicformulainvesting.com\\n\\n2. \"One Up on Wall Street\" by Peter Lynch\\n\\nLynch, a legendary figure in the investment world, shares his wisdom from managing the Magellan Fund at Fidelity Investments.\\n\\nThis book, spanning 334 pages, is an engaging read that encourages investors to leverage their everyday knowledge in the stock market.\\n\\nLynch’s insights on investing in familiar industries and his analysis of ‘tenbaggers’ - stocks that have the potential to increase tenfold - are particularly enlightening.\\n\\n3. \"The University of Berkshire Hathaway\" by Daniel Pecaut\\n\\nThis book condenses 30 years of annual shareholder meeting wisdom into 338 pages.\\n\\nIt’s slightly more advanced and covers their candid views on investing, society, and finance.\\n\\nFor those who want to dive deeper, the Warren Buffett Archive on CNBC is a fantastic resource, though this book efficiently summarizes decades of insights.\\n\\n4. \"Common Stocks and Uncommon Profits\" by Philip Fisher\\n\\nThis influential book, which significantly impacted Warren Buffett’s investment philosophy,\\n\\nFor Fisher, it is all about finding excellent companies and holding onto them long-term.\\n\\nFisher’s advice on using ‘main street’ resources to gather intelligence on companies is invaluable for individual investors.\\n\\n5. \"The Intelligent Investor\" by Benjamin Graham\\n\\nNo list would be complete without Benjamin Graham’s \"The Intelligent Investor\".\\n\\nWarren Buffett famously highlights Chapters 8 and 20 as particularly crucial. It introduces critical concepts like intrinsic value, Mr. Market, and the Margin of Safety.\\n\\nThis foundational book in value investing is more technical and extensive, running 640 pages.\\n\\n6. \"The Essays of Warren Buffett\" by Lawrence Cunningham\\n\\nThen we have \"The Essays of Warren Buffett\", compiled by Lawrence Cunningham.\\n\\nThis book distills the wisdom from Buffett’s annual shareholder letters, covering a wide range of topics from investment strategies to corporate governance.\\n\\nWhile it’s a dense read, it offers an unparalleled insight into Buffett’s thinking.\\n\\n7. \"The Little Principle That Beats the Market\" by Valentin Corbi\\n\\nBased on the powerful Pareto Principle, this book reveals how to simplify the complex world of stocks and maximize returns with minimal effort by focusing on the select few stocks that drive most market returns.\\n\\nWith an impressive track record, outperforming traditional index funds, this book is essential for anyone seeking a smarter, more effective way to invest with the Pareto Principle on your side!\\n\\nDespite been short, this book reveals the Power of the Pareto Principle with stocks and guides you to invest smarter and not harder!\\n\\nThere you have it -Seven Must-Read Books for Anyone Serious about Stock Market Investing\\n\\nThese books are your companions on this journey, offering lessons from some of the greatest minds in investing.\\n\\nBut remember, investing is not just about strategies and numbers;\\n\\nEmbrace the journey with curiosity and patience, knowing that with each book, you’re not only investing in your portfolio but also in yourself.\\n\\nFeel free to revisit these books as you grow in your investing journey.\\n\\nOften, the insights and lessons reveal deeper meanings as you gain more experience in the market.\\n\\nAnd remember, the ultimate goal is not just financial gain, but also the wisdom and freedom that come with being a knowledgeable investor.\\n\\nI look forward to hearing about your successes and learning experiences in the stock market.\\n\\nKeep investing, keep learning, and here’s to your journey towards financial freedom and mastery in the world of investing. Cheers to your success!\\n\\nSincerely,\\n\\nThe Pareto Investor\\n\\nhttps://paretoinvestor.substack.com/'}},\n",
       "  {'id': '2b8eb1e86f25',\n",
       "   'title': 'I Was Right about Palantir!',\n",
       "   'subtitle': 'The Company Has a Big Plan to Dominate AI World!',\n",
       "   'author': '37a2cbe8bd15',\n",
       "   'publication_id': '*Self-Published*',\n",
       "   'published_at': '2024-02-18 02:01:56',\n",
       "   'last_modified_at': '2024-02-18 11:23:28',\n",
       "   'tags': ['technology', 'ai', 'investing', 'stock-market', 'trading'],\n",
       "   'topics': ['artificial-intelligence'],\n",
       "   'claps': 213,\n",
       "   'voters': 13,\n",
       "   'word_count': 563,\n",
       "   'responses_count': 1,\n",
       "   'reading_time': 3.074528301886793,\n",
       "   'url': 'https://medium.com/@pareto_investor/i-was-right-about-palantir-2b8eb1e86f25',\n",
       "   'unique_slug': 'i-was-right-about-palantir-2b8eb1e86f25',\n",
       "   'image_url': 'https://miro.medium.com/0*kxmzisq-zZCYs05y.jpg',\n",
       "   'lang': 'en',\n",
       "   'is_series': False,\n",
       "   'is_locked': True,\n",
       "   'is_shortform': False,\n",
       "   'top_highlight': '',\n",
       "   'content': {'id': '2b8eb1e86f25',\n",
       "    'content': 'I Was Right about Palantir!\\n\\nThe Company Has a Big Plan to Dominate AI World!\\n\\nHow to Get Rich with Investing (without Getting Lucky)\\n\\nLotR - 2002\\n\\nMy earlier assertions about Palantir Technologies have been right!\\n\\nI recognized Palantir’s potential to be a formidable force in the AI landscape.\\n\\nThis belief was reinforced by their earnings call, where the company’s stock surged by over 40% last week, a clear testament to their growing influence and prowess in the world of artificial intelligence.\\n\\n9 Artificial Intelligence Stocks to Buy Now!\\nArtificial intelligence (AI) is one of the most transformative technologies of our time, and it is rapidly changing the…paretoinvestor.substack.com\\n\\nThe stock is now up 160% since I recommended it!\\n\\nMy initial analysis of Palantir, particularly regarding their AI platforms and market strategies, remained steadfast.\\n\\n\\n\\nMy faith in their AI-driven boot camps and their long-term strategy has now been justified.\\n\\nPalantir’s Platforms\\n\\nPalantir’s AI Boot Camps\\n\\nFrom the beginning, I saw great potential in Palantir’s AI boot camps.\\n\\nThese innovative sessions have proven instrumental in expanding their market reach and demonstrating the practicality of their AI platforms.\\n\\nThey provide a hands-on environment where users can develop real solutions to problems using Palantir’s technology, solidifying the company’s position in the AI sector.\\n\\nPalantir’s Platforms\\n\\nUnderstanding Palantir’s dominance in AI requires an appreciation of their flagship platforms: Gotham and Foundry.\\n\\nAlso, to read:\\n\\nWhy You Should Pay Attention to Perplexity AI\\nI have Replaced Google with This New A.I.-Powered Search Engine!medium.com\\n\\nThese platforms facilitate comprehensive data integration across organizations, offering a unified, real-time view of enterprise data.\\n\\nThey support the creation of digital twins, or ontologies, mapping out an organization’s resources and their interrelations in intricate detail.\\n\\nThe sophistication of these platforms has always underscored my confidence in Palantir’s advanced AI capabilities.\\n\\nPalantir’s AIP\\n\\nPalantir’s Artificial Intelligence Platform (AIP) has been a game-changer, a development I anticipated to be pivotal.\\n\\nAIP enables users to engage with their company’s ontology through simple prompts, dramatically broadening its accessibility and ease of use.\\n\\nThis innovation has significantly lowered the barrier to effective utilization of Palantir’s technology.\\n\\nPalantir’s Earnings\\n\\nPalantir’s recent earnings have been nothing short of spectacular, confirming my positive outlook.\\n\\nThe substantial increase in revenue and the growth in their commercial customer base underscore their expanding influence in competitive markets.\\n\\nPalantir’s Earnings - Q4 2023\\n\\nThis success is partly due to the AI boot camps, which have accelerated the adoption and practical application of their AI solutions.\\n\\n\\n\\nDespite these impressive achievements, a comprehensive analysis must consider all aspects.\\n\\n\\n\\nPalantir’s government revenue growth has been more modest compared to their commercial sector.\\n\\nReinforced Belief\\n\\nPalantir’s approach to marketing has also aligned with my predictions.\\n\\nBy using relatable scenarios to demonstrate their AI’s capabilities, they’ve made their complex platforms comprehensible to a wider audience.\\n\\nMy initial perspective on Palantir has been reinforced.\\n\\nThe company is actively defining its future, not merely waiting for recognition.\\n\\nWith a consistent focus on delivering value through evolving platforms and innovative strategies like AI boot camps, Palantir continues to validate my belief in their potential.\\n\\nAs an investor and an AI enthusiast, my confidence in Palantir remains strong, and I am excited to see their continued growth and influence in the AI domain.\\n\\nSincerely,\\n\\nThe Pareto Investor\\n\\nMy Book \"The Little Principle That Beats the Market\" is an essential read for anyone seeking a smarter, more effective way to invest.'}},\n",
       "  {'id': '681c04c2a74f',\n",
       "   'title': 'Why Bitcoin?',\n",
       "   'subtitle': 'How to Get Rich with Investing (without Getting Lucky)',\n",
       "   'author': '37a2cbe8bd15',\n",
       "   'publication_id': '*Self-Published*',\n",
       "   'published_at': '2024-02-17 20:50:32',\n",
       "   'last_modified_at': '2024-02-18 11:23:33',\n",
       "   'tags': ['bitcoin', 'life', 'finance', 'money', 'self-improvement'],\n",
       "   'topics': ['cryptocurrency'],\n",
       "   'claps': 202,\n",
       "   'voters': 14,\n",
       "   'word_count': 689,\n",
       "   'responses_count': 1,\n",
       "   'reading_time': 3.3,\n",
       "   'url': 'https://medium.com/@pareto_investor/why-bitcoin-681c04c2a74f',\n",
       "   'unique_slug': 'why-bitcoin-681c04c2a74f',\n",
       "   'image_url': 'https://miro.medium.com/0*d-rDBS60N966vxZ3.jpeg',\n",
       "   'lang': 'en',\n",
       "   'is_series': False,\n",
       "   'is_locked': True,\n",
       "   'is_shortform': False,\n",
       "   'top_highlight': '',\n",
       "   'content': {'id': '681c04c2a74f',\n",
       "    'content': 'Why Bitcoin?\\n\\nHow to Get Rich with Investing (without Getting Lucky)\\n\\n\\n\\nDear Investors,\\n\\n\"Good money ousts bad one\"\\n\\nThe phrase is an economic principle suggesting that if there are two forms of commodity money in circulation which are accepted by law as having similar face value, the less valuable (bad) money will disappear from circulation. #USD\\n\\nThe concept is often observed, because people tend to use the higher-quality, full-valued currency (good money), and abandon the lower-quality or debased currency (bad money). #Venezuela\\n\\n\\n\\nGlobal reserve currencies since 1450\\n\\nReaders of my Blog Know that I Started Buying Bitcoin in Early 2017\\n\\nI’ve been influenced \"early\" by experts in the sound money community.\\n\\nTheir insights on the flawed monetary system and their perspectives on Bitcoin were hard to ignore.\\n\\nI began to see intrinsic value in Bitcoin, and it turned out to be rewarding because it is the best performing asset of all time!\\n\\n\\n\\nBitcoin best performing asset of the decade\\n\\nFirst, I Couldn’t Understand Bitcoin’s Digital Scarcity\\n\\nIn the beginning, I couldn’t grasp the concept of scarcity in something digital and so new.\\n\\nIt was only when I understood Bitcoin’s cryptography - its unhackability and robust security - that the pieces started falling into place.\\n\\nUnderstanding the network’s checks and balances, how its decentralization and majority consensus protect its integrity, was crucial.\\n\\nForks in the network, once puzzling, now made sense as failed attempts to rewrite Bitcoin’s code, rejected by the majority to preserve the original design.\\n\\nThe realization that Bitcoin is growing stronger and more secure with increasing adoption dispelled concerns about bans or arbitrary changes by Satoshi.\\n\\nThe network’s resilience, shifting from one jurisdiction to another as needed, further solidified my understanding of its indestructibility.\\n\\nThen, I Saw Intrinsic Value in Bitcoin, Distinct from Gold\\n\\nI’ve come to view Bitcoin as not just an investment in cryptocurrency, but in a revolutionary ledger system and a new monetary paradigm.\\n\\nBitcoin as \"Digital Energy\"\\n\\nMy thinking shifted from a pur investment to ideologically driven after hearing Bitcoin as a unique invention, likening it to the Internet itself rather than just an application of it.\\n\\nDespite the risks and the possibility of Bitcoin’s value plummeting, I don’t foresee its demise in the near future.\\n\\nIts growing adoption and the involvement of major asset managers and nation-states in Bitcoin make a compelling case for its longevity.\\n\\nI’ve come to appreciate Bitcoin’s role in opening up discussions about the flaws in modern monetary theory and policy.\\n\\nAs we observe its price performance and the potential FOMO from asset managers and nations alike, the growing acceptance and adoption of Bitcoin seem almost inevitable.\\n\\nFinally, I resonate with Fundamental principles behind Bitcoin\\n\\nDecentralization, empowerment, and a challenge to a broken system - resonate with my perspective.\\n\\nAs someone who views the global economic system through an Austrian lens and advocates for a different monetary standard, I now see Bitcoin as a viable part of this vision.\\n\\nIt represents digital freedom, working as long as people want it to, which aligns with my philosophy of empowering individuals.\\n\\n\\n\\nSo, my journey from skeptic to advocate has been a journey of discovery, education, and ideological alignment.\\n\\nAs Steve Jobs said\\n\\n\"Stay hungry. Stay foolish\"\\n\\nThis phrase implies a relentless pursuit of knowledge, innovation, self-improvement and the importance of being open to new ideas, thinking differently, and not being afraid to make unconventional choices.\\n\\nIt encourages embracing the unknown and taking risks, rather than always playing it safe.\\n\\nIn essence, the quote is a call to never settle, to always seek out new experiences and ideas, and to maintain the courage and curiosity of a beginner, no matter how successful one becomes.\\n\\nIt’s a mindset that drives innovation and change, and it’s a philosophy that was central to Jobs’ own approach to life and business. It was highly rewarding!\\n\\nBitcoin, to me, is more than a digital asset; it’s a bet on a decentralized, people-powered future.\\n\\nSincerely,\\n\\nThe Pareto Investor\\n\\nMy Book \"The Little Principle That Beats the Market\" is an essential read for anyone seeking a smarter, more effective way to invest.'}},\n",
       "  {'id': '329ca6732470',\n",
       "   'title': 'Apple GPT\\u200a—\\u200aWhat Do We Know So Far!',\n",
       "   'subtitle': 'Apple is the sleeping giant in the realm of artificial intelligence.',\n",
       "   'author': '37a2cbe8bd15',\n",
       "   'publication_id': '*Self-Published*',\n",
       "   'published_at': '2024-02-17 11:16:52',\n",
       "   'last_modified_at': '2024-02-18 11:23:51',\n",
       "   'tags': ['apple',\n",
       "    'artificial-intelligence',\n",
       "    'technology',\n",
       "    'business',\n",
       "    'programming'],\n",
       "   'topics': ['artificial-intelligence'],\n",
       "   'claps': 107,\n",
       "   'voters': 8,\n",
       "   'word_count': 889,\n",
       "   'responses_count': 0,\n",
       "   'reading_time': 3.5547169811320756,\n",
       "   'url': 'https://medium.com/@pareto_investor/apple-gpt-what-do-we-know-so-far-329ca6732470',\n",
       "   'unique_slug': 'apple-gpt-what-do-we-know-so-far-329ca6732470',\n",
       "   'image_url': 'https://miro.medium.com/0*jBHC93WZ4Ah65cR-',\n",
       "   'lang': 'en',\n",
       "   'is_series': False,\n",
       "   'is_locked': True,\n",
       "   'is_shortform': False,\n",
       "   'top_highlight': '',\n",
       "   'content': {'id': '329ca6732470',\n",
       "    'content': 'Apple GPT - What Do We Know So Far!\\n\\nApple is the sleeping giant in the realm of artificial intelligence.\\n\\nHow to Get Rich with Investing (without Getting Lucky)\\n\\nSteve GPTs soon?\\n\\nDear Investors,\\n\\nWith the explosive popularity of generative AI tools like ChatGPT, there have been rumors that Apple is working on its own AI product, and that some kind of \"Apple GPT\" artificial intelligence bot could launch soon.\\n\\nAlso, to read:\\n\\nChatGPT has Just Been Dethroned by French Geniuses!\\nThese Three Individuals, a Former Researcher at DeepMind and Two Others from Meta, Completely Transformed the AI Game!medium.com\\n\\nThey’re exceptionally well-positioned to make a significant impact in the industry, perhaps changing it overnight.\\n\\nAnd now, there are emerging leaks about a project dubbed \"Apple GPT\".\\n\\nInternal Testing and Development\\n\\nUnder the leadership of AI chief John Giannandrea, Apple has been intensifying its efforts in developing conversational AI.\\n\\nThe project, internally referred to as \"Apple GPT,\" has been a focus within the company for several months.\\n\\nThis development is aligned with Apple’s \"Ajax\" framework, aimed at designing advanced large language models.\\n\\nApple tests generative AI tools to rival OpenAI\\'s ChatGPT, Bloomberg reports\\nApple is working on artificial intelligence (AI) offerings similar to OpenAI\\'s ChatGPT and Google\\'s Bard, Bloomberg…www.reuters.com\\n\\nThe internal chatbot, while not intended for consumer product development directly, serves as a crucial tool for product prototyping, leveraging a training dataset of over 200 billion parameters (more than Open AI currently).\\n\\nHowever, it’s crucial to note that Apple’s strategy for a consumer-facing generative AI product remains somewhat undefined.\\n\\nThe company is reportedly exploring enhancements to Siri and developing software for generating videos, images, and multimodal AI technologies.\\n\\nAI for Siri\\n\\nSiri, Apple’s voice assistant, is a prime candidate for integration with generative AI technologies.\\n\\nHowever, the current architecture of Siri presents challenges in rapidly integrating new capabilities.\\n\\nPrivacy concerns also play a significant role in Apple’s cautious approach to enhancing Siri, especially when compared to competitors like Alexa and Google Assistant.\\n\\nAI for Apple Vision Pro\\n\\nWhen it comes to hardware, Apple stands out, perhaps only rivaled by Nvidia.\\n\\nWith devices like the MacBook Pro M2 Max showcasing incredible capabilities in running AI inference, Apple’s silicon chips’ efficiency in inference tasks is noteworthy.\\n\\nWith the release of Apple Vision Pro, which I believe is the ideal platform for delivering AI to the masses, Apple is poised to make a significant mark this year.\\n\\nAI for Apps\\n\\nApple’s ambition extends to embedding AI across its suite of applications.\\n\\nFrom AI-curated playlists in Apple Music to coding assistance in Xcode, the company is exploring a wide range of applications.\\n\\nThis extensive integration, however, might not fully materialize until around 2025.\\n\\nNews and Publisher Deals\\n\\nApple is actively seeking partnerships with major publishers to use their content for AI training.\\n\\nDeals with entities like Condé Nast and NBC News are in discussion, but publishers have shown mixed reactions due to Apple’s vague descriptions of AI application and expansive term requests.\\n\\nAI Competition\\n\\nApple is no stranger to AI and machine learning, already utilizing these technologies in various aspects of its products, from photo enhancement to features like Crash Detection and Siri Suggestions.\\n\\nHowever, Apple is not alone in this race.\\n\\nTech giants like Google, Microsoft, Amazon, and Meta are all investing heavily in generative AI, developing products that range from AI chat tools to enhancements in existing apps and services.\\n\\nApple has imposed bans on the use of third-party AI tools like ChatGPT and GitHub Copilot by its employees, citing concerns over potential data leaks.\\n\\nThis move mirrors similar actions taken by other tech companies and institutions.\\n\\nPotential Launch Date\\n\\nApple CEO Tim Cook has expressed both interest and caution regarding AI.\\n\\nAcknowledging AI as a core technology integral to Apple’s products, Cook emphasizes a thoughtful and deliberate approach to its deployment.\\n\\nApple is reportedly investing millions daily in conversational AI research, a testament to the resource-intensive nature of training language models.\\n\\nApple CEO Tim Cook says AI is a fundamental technology, confirms investments in generative AI |…\\nApple CEO Tim Cook pushed back a bit at the notion that the company was behind in AI on yesterday\\'s Q4 earnings call…techcrunch.com\\n\\nThey are on track to spend over $4 billion on AI servers in 2024, highlighting the scale of their commitment to AI.\\n\\nSpeculations suggest that Apple might introduce generative AI features in iOS devices around late 2024, coinciding with the release of iOS 18.\\n\\nHowever, opinions differ, with some analysts like Ming-Chi Kuo suggesting that Apple might be lagging behind its competitors in this domain.\\n\\nIt’s evident that Apple is heavily invested in exploring and integrating AI into its ecosystem\\n\\nThe scope of Apple’s AI ambitions, from enhancing Siri to a broader application in its suite of products, signals a transformative phase in the company’s approach to artificial intelligence.\\n\\nWith their extensive resources, innovative approach to hardware, and a track record of transforming industries, Apple is well-positioned to redefine our relationship with technology through AI.\\n\\nAs more information emerges, we will undoubtedly gain a clearer picture of what Apple GPT might look like and how it will shape our future.\\n\\nSincerely,\\n\\nThe Pareto Investor\\n\\nMy Book \"The Little Principle That Beats the Market\" is an essential read for anyone seeking a smarter, more effective way to invest.'}},\n",
       "  {'id': '1add43659444',\n",
       "   'title': 'Cricket Might Be the Next Big Sport in America',\n",
       "   'subtitle': 'How to Get Rich with Investing (without Getting Lucky)',\n",
       "   'author': '37a2cbe8bd15',\n",
       "   'publication_id': '*Self-Published*',\n",
       "   'published_at': '2024-02-17 02:01:45',\n",
       "   'last_modified_at': '2024-02-18 11:24:01',\n",
       "   'tags': ['cricket', 'india', 'usa', 'sports', 'news'],\n",
       "   'topics': ['sports'],\n",
       "   'claps': 89,\n",
       "   'voters': 5,\n",
       "   'word_count': 536,\n",
       "   'responses_count': 2,\n",
       "   'reading_time': 2.722641509433962,\n",
       "   'url': 'https://medium.com/@pareto_investor/cricket-might-be-the-next-big-sport-in-america-1add43659444',\n",
       "   'unique_slug': 'cricket-might-be-the-next-big-sport-in-america-1add43659444',\n",
       "   'image_url': 'https://miro.medium.com/0*9n_TcVZIsnIouOj7',\n",
       "   'lang': 'en',\n",
       "   'is_series': False,\n",
       "   'is_locked': True,\n",
       "   'is_shortform': False,\n",
       "   'top_highlight': '',\n",
       "   'content': {'id': '1add43659444',\n",
       "    'content': 'Cricket Might Be the Next Big Sport in America\\n\\nHow to Get Rich with Investing (without Getting Lucky)\\n\\nJacksonville Cricket Team\\n\\nCricket, a sport steeped in history and tradition, long overshadowed in the United States by the likes of baseball, basketball, and football, is now poised to capture American hearts.\\n\\nThe turning point was with the debut of Major League Cricket, and the excitement was palpable.\\n\\nAlso, to read:\\n\\n2040: The Year MIT Predicted Civilization’s Precipice\\nSociety is on a trajectory towards collapse by the year 2040.medium.com\\n\\nThe sold-out inaugural game featuring the Texas Super Kings and the Los Angeles Knight Riders signals more than just a sporting event; it’s the dawn of a new era in American sports culture.\\n\\nMajor League Cricket\\n\\nCricket in the U.S. has been a slow but steady one.\\n\\nCurrently, only about 1% of U.S. consumers follow the sport, yet this small percentage represents a significant opportunity for growth.\\n\\nGlobally, cricket enjoys a massive following, particularly in countries like India, South Africa, Australia, and the U.K.\\n\\nGlobally, cricket enjoys a massive following, particularly in countries like India, South Africa, Australia, and the U.K. In the U.S.\\n\\nIn the U.S., its popularity has been gradually increasing, especially in areas with substantial South Asian populations like Houston, New York, Los Angeles, and the Dallas-Fort Worth area, which alone is home to over 220,000 Indian-Americans.\\n\\nWhat’s driving this newfound interest in cricket?\\n\\nA major factor is the substantial investment flowing into the sport.\\n\\nInfluential figures like Satya Nadella, CEO of Microsoft, are backing this venture, with an investment of $120 million.\\n\\nHistory has shown that when there’s substantial financial support, success often follows.\\n\\nThe team names in Major League Cricket also reflect a unique blend of humor and cultural integration, from the Seattle Orcas to the San Francisco Unicorns - a nod to Silicon Valley.\\n\\nThese names, while amusing, also signify the sport’s growing relevance in American society.\\n\\nInterestingly, cricket is not new to America.\\n\\nIn the late 19th century, it vied with baseball for popularity, and the Philadelphia Cricket Club was once a powerhouse in the sport.\\n\\nSt. George’s Club cricketers - 1861\\n\\nThis historical context adds depth to cricket’s resurgence in the U.S.\\n\\nHowever, cricket faces challenges in capturing the American audience.\\n\\nThe traditional format of the game, known as Test matches, can last up to five days, a daunting prospect in a country known for its fast-paced lifestyle and short attention spans.\\n\\nRecognizing this, Major League Cricket is focusing on the T20 format - a shorter, more dynamic version of the game, lasting about three hours, which aligns more closely with the average duration of a baseball game.\\n\\nThis strategic adaptation could be the key to cricket’s success in America.\\n\\nBy offering a version of the game that respects the American pace of life while maintaining the sport’s essence, cricket has a real chance to establish itself as a major player in the U.S. sports landscape.\\n\\nThe inaugural game of Major League Cricket was not just watching a sport; we’re probably observing a cultural shift.\\n\\nWith the right mix of investment, adaptation, and historical roots, cricket has the potential to become a staple in American sports entertainment.\\n\\nLet’s get ready for cricket!\\n\\nSincerely,\\n\\nThe Pareto Investor\\n\\nMy Book \"The Little Principle That Beats the Market\" is an essential read for anyone seeking a smarter, more effective way to invest.'}},\n",
       "  {'id': 'c33063302058',\n",
       "   'title': 'Yield Curve’s 40-Year Low Is Now Signaling Recession',\n",
       "   'subtitle': 'After being deeply negative, the US Treasury yield curve is in the process of de-inverting, signaling a potential recession!',\n",
       "   'author': '37a2cbe8bd15',\n",
       "   'publication_id': '*Self-Published*',\n",
       "   'published_at': '2024-02-16 12:05:58',\n",
       "   'last_modified_at': '2024-02-18 11:24:55',\n",
       "   'tags': ['economics', 'investing', 'trading', 'finance', 'stock-market'],\n",
       "   'topics': ['money', 'economy'],\n",
       "   'claps': 69,\n",
       "   'voters': 12,\n",
       "   'word_count': 410,\n",
       "   'responses_count': 1,\n",
       "   'reading_time': 1.9305031446540881,\n",
       "   'url': 'https://medium.com/@pareto_investor/yield-curves-40-year-low-is-now-signaling-recession-c33063302058',\n",
       "   'unique_slug': 'yield-curves-40-year-low-is-now-signaling-recession-c33063302058',\n",
       "   'image_url': 'https://miro.medium.com/0*BekymDxtFY_iYx7R.png',\n",
       "   'lang': 'en',\n",
       "   'is_series': False,\n",
       "   'is_locked': True,\n",
       "   'is_shortform': False,\n",
       "   'top_highlight': '',\n",
       "   'content': {'id': 'c33063302058',\n",
       "    'content': 'Yield Curve’s 40-Year Low Is Now Signaling Recession\\n\\nAfter being deeply negative, the US Treasury yield curve is in the process of de-inverting, signaling a potential recession!\\n\\nHow to Get Rich with Investing (without Getting Lucky)\\n\\nYield Curve’s 40-Year Low Is Now Signaling Recession\\n\\nDear Investors,\\n\\nIn July 2022, the US financial markets witnessed a noteworthy development: the inversion of the yield curve, as indicated by the relationship between 2-year and 10-year treasury yields.\\n\\nThis event marked the onset of what would become the longest inversion in the last four decades, persisting for 18 months.\\n\\nAlso, to read:\\n\\nThe Most Violent/Catastrophic Wallstreetbets Losses!\\nDemocratization of trading meets the wild west of investment strategies.medium.com\\n\\nHistorically, the yield curve’s shape has been a bellwether for economic trends, particularly in signaling potential recessions.\\n\\nAfter being deeply negative, the US Treasury yield curve is in the process of de-inverting, signaling a potential recession for the second half of 2024 or early 2025!\\n\\nThe yield curve signals potential recessions since 1970\\n\\nA simple yet profound interpretation of this inversion suggests that the bond market is bracing for a future economic downturn.\\n\\nThis is inferred from the expectation that interest rates will need to be reduced to mitigate the anticipated slowdown.\\n\\nTo provide context, it is essential to note that since 1968, every recession has been preceded by an inverted yield curve.\\n\\nHowever, This Indicator is Not Infallible\\n\\nThere have been instances where brief inversions did not lead to a recession.\\n\\nThereby serving as false signals.\\n\\nYet, it’s important to highlight that no inversion of the current magnitude has failed to predict a forthcoming recession.\\n\\nAlso, the timing of the recession’s onset in relation to the yield curve is not certain.\\n\\nHowever, historically, recessions have tended to occur as the curve begins to revert to a more typical, upward-sloping shape.\\n\\nIn this Recent Scenario\\n\\nWhile it is not a perfect predictor, its historical track record and the magnitude of the current inversion make it a crucial element in macroeconomic analysis.\\n\\nThe current signals suggest a need for caution and preparedness for potential economic challenges ahead.\\n\\nHowever, it is also important to remember that economic dynamics are complex and influenced by a multitude of factors.\\n\\nThus, while the yield curve inversion is a significant indicator, it should be considered as part of a broader analytical framework when making investment decisions.\\n\\nSincerely,\\n\\nThe Pareto Investor\\n\\nMy Book \"The Little Principle That Beats the Market\" is an essential read for anyone seeking a smarter, more effective way to invest.'}}],\n",
       " '15a29a4fc6ad': [{'id': 'afd97fce8fb5',\n",
       "   'title': 'Text Embeddings: Comprehensive Guide',\n",
       "   'subtitle': 'Evolution, visualisation, and applications of text embeddings',\n",
       "   'author': '15a29a4fc6ad',\n",
       "   'publication_id': '7f60cf5620c9',\n",
       "   'published_at': '2024-02-13 08:03:13',\n",
       "   'last_modified_at': '2024-02-13 08:03:13',\n",
       "   'tags': ['data-science',\n",
       "    'nlp',\n",
       "    'machine-learning',\n",
       "    'deep-dives',\n",
       "    'embedding'],\n",
       "   'topics': ['machine-learning', 'data-science', 'programming'],\n",
       "   'claps': 815,\n",
       "   'voters': 175,\n",
       "   'word_count': 4616,\n",
       "   'responses_count': 17,\n",
       "   'reading_time': 19.368867924528303,\n",
       "   'url': 'https://towardsdatascience.com/text-embeddings-comprehensive-guide-afd97fce8fb5',\n",
       "   'unique_slug': 'text-embeddings-comprehensive-guide-afd97fce8fb5',\n",
       "   'image_url': 'https://miro.medium.com/1*0OVy_qF0NLJOyUnfz8lRzg.jpeg',\n",
       "   'lang': 'en',\n",
       "   'is_series': False,\n",
       "   'is_locked': False,\n",
       "   'is_shortform': False,\n",
       "   'top_highlight': '',\n",
       "   'content': {'id': 'afd97fce8fb5',\n",
       "    'content': 'Text Embeddings: Comprehensive Guide\\n\\nEvolution, visualisation, and applications of text embeddings\\n\\nImage by DALL-E 3\\n\\nAs human beings, we can read and understand texts (at least some of them). Computers in opposite \"think in numbers\", so they can’t automatically grasp the meaning of words and sentences. If we want computers to understand the natural language, we need to convert this information into the format that computers can work with - vectors of numbers.\\n\\nPeople learned how to convert texts into machine-understandable format many years ago (one of the first versions was ASCII). Such an approach helps render and transfer texts but doesn’t encode the meaning of the words. At that time, the standard search technique was a keyword search when you were just looking for all the documents that contained specific words or N-grams.\\n\\nThen, after decades, embeddings have emerged. We can calculate embeddings for words, sentences, and even images. Embeddings are also vectors of numbers, but they can capture the meaning. So, you can use them to do a semantic search and even work with documents in different languages.\\n\\nIn this article, I would like to dive deeper into the embedding topic and discuss all the details:\\n\\nwhat preceded the embeddings and how they evolved,\\n\\nhow to calculate embeddings using OpenAI tools,\\n\\nhow to define whether sentences are close to each other,\\n\\nhow to visualise embeddings,\\n\\nthe most exciting part is how you could use embeddings in practice.\\n\\nLet’s move on and learn about the evolution of embeddings.\\n\\nEvolution of Embeddings\\n\\nWe will start our journey with a brief tour into the history of text representations.\\n\\nBag of Words\\n\\nThe most basic approach to converting texts into vectors is a bag of words. Let’s look at one of the famous quotes of Richard P. Feynman\"We are lucky to live in an age in which we are still making discoveries\". We will use it to illustrate a bag of words approach.\\n\\nThe first step to get a bag of words vector is to split the text into words (tokens) and then reduce words to their base forms. For example, \"running\" will transform into \"run\". This process is called stemming. We can use the NLTK Python package for it.\\n\\nfrom nltk.stem import SnowballStemmer\\nfrom nltk.tokenize import word_tokenize\\n\\ntext = \\'We are lucky to live in an age in which we are still making discoveries\\'\\n\\n# tokenization - splitting text into words\\nwords = word_tokenize(text)\\nprint(words)\\n# [\\'We\\', \\'are\\', \\'lucky\\', \\'to\\', \\'live\\', \\'in\\', \\'an\\', \\'age\\', \\'in\\', \\'which\\',\\n#  \\'we\\', \\'are\\', \\'still\\', \\'making\\', \\'discoveries\\']\\n\\nstemmer = SnowballStemmer(language = \"english\")\\nstemmed_words = list(map(lambda x: stemmer.stem(x), words))\\nprint(stemmed_words)\\n# [\\'we\\', \\'are\\', \\'lucki\\', \\'to\\', \\'live\\', \\'in\\', \\'an\\', \\'age\\', \\'in\\', \\'which\\', \\n#  \\'we\\', \\'are\\', \\'still\\', \\'make\\', \\'discoveri\\']\\n\\nNow, we have a list of base forms of all our words. The next step is to calculate their frequencies to create a vector.\\n\\nimport collections\\nbag_of_words = collections.Counter(stemmed_words)\\nprint(bag_of_words)\\n# {\\'we\\': 2, \\'are\\': 2, \\'in\\': 2, \\'lucki\\': 1, \\'to\\': 1, \\'live\\': 1, \\n# \\'an\\': 1, \\'age\\': 1, \\'which\\': 1, \\'still\\': 1, \\'make\\': 1, \\'discoveri\\': 1}\\n\\nActually, if we wanted to convert our text into a vector, we would have to take into account not only the words we have in the text but the whole vocabulary. Let’s assume we also have \"i\", \"you\" and \"study\" in our vocabulary and let’s create a vector from Feynman’s quote.\\n\\nGraph by author\\n\\nThis approach is quite basic, and it doesn’t take into account the semantic meaning of the words, so the sentences \"the girl is studying data science\" and \"the young woman is learning AI and ML\" won’t be close to each other.\\n\\nTF-IDF\\n\\nA slightly improved version of the bag of the words approach is TF-IDF (Term Frequency - Inverse Document Frequency). It’s the multiplication of two metrics.\\n\\n\\n\\nTerm Frequency shows the frequency of the word in the document. The most common way to calculate it is to divide the raw count of the term in this document (like in the bag of words) by the total number of terms (words) in the document. However, there are many other approaches like just raw count, boolean \"frequencies\", and different approaches to normalisation. You can learn more about different approaches on Wikipedia.\\n\\n\\n\\nInverse Document Frequency denotes how much information the word provides. For example, the words \"a\" or \"that\" don’t give you any additional information about the document’s topic. In contrast, words like \"ChatGPT\" or \"bioinformatics\" can help you define the domain (but not for this sentence). It’s calculated as the logarithm of the ratio of the total number of documents to those containing the word. The closer IDF is to 0 - the more common the word is and the less information it provides.\\n\\n\\n\\nSo, in the end, we will get vectors where common words (like \"I\" or \"you\") will have low weights, while rare words that occur in the document multiple times will have higher weights. This strategy will give a bit better results, but it still can’t capture semantic meaning.\\n\\nThe other challenge with this approach is that it produces pretty sparse vectors. The length of the vectors is equal to the corpus size. There are about 470K unique words in English (source), so we will have huge vectors. Since the sentence won’t have more than 50 unique words, 99.99% of the values in vectors will be 0, not encoding any info. Looking at this, scientists started to think about dense vector representation.\\n\\nWord2Vec\\n\\nOne of the most famous approaches to dense representation is word2vec, proposed by Google in 2013 in the paper \"Efficient Estimation of Word Representations in Vector Space\" by Mikolov et al.\\n\\nThere are two different word2vec approaches mentioned in the paper: Continuous Bag of Words (when we predict the word based on the surrounding words) and Skip-gram (the opposite task - when we predict context based on the word).\\n\\nFigure from the paper by Mikolov et al. 2013 | source\\n\\nThe high-level idea of dense vector representation is to train two models: encoder and decoder. For example, in the case of skip-gram, we might pass the word \"christmas\" to the encoder. Then, the encoder will produce a vector that we pass to the decoder expecting to get the words \"merry\", \"to\", and \"you\".\\n\\nScheme by author\\n\\nThis model started to take into account the meaning of the words since it’s trained on the context of the words. However, it ignores morphology (information we can get from the word parts, for example, that \"-less\" means the lack of something). This drawback was addressed later by looking at subword skip-grams in GloVe.\\n\\nAlso, word2vec was capable of working only with words, but we would like to encode whole sentences. So, let’s move on to the next evolutional step with transformers.\\n\\nTransformers and Sentence Embeddings\\n\\nThe next evolution was related to the transformers approach introduced in the \"Attention Is All You Need\" paper by Vaswani et al. Transformers were able to produce information-reach dense vectors and become the dominant technology for modern language models.\\n\\nI won’t cover the details of the transformers’ architecture since it’s not so relevant to our topic and would take a lot of time. If you’re interested in learning more, there are a lot of materials about transformers, for example, \"Transformers, Explained\" or \"The Illustrated Transformer\".\\n\\nTransformers allow you to use the same \"core\" model and fine-tune it for different use cases without retraining the core model (which takes a lot of time and is quite costly). It led to the rise of pre-trained models. One of the first popular models was BERT (Bidirectional Encoder Representations from Transformers) by Google AI.\\n\\nInternally, BERT still operates on a token level similar to word2vec, but we still want to get sentence embeddings. So, the naive approach could be to take an average of all tokens’ vectors. Unfortunately, this approach doesn’t show good performance.\\n\\nThis problem was solved in 2019 when Sentence-BERT was released. It outperformed all previous approaches to semantic textual similarity tasks and allowed the calculation of sentence embeddings.\\n\\nIt’s a huge topic so we won’t be able to cover it all in this article. So, if you’re really interested, you can learn more about the sentence embeddings in this article.\\n\\nWe’ve briefly covered the evolution of embeddings and got a high-level understanding of the theory. Now, it’s time to move on to practice and lear how to calculate embeddings using OpenAI tools.\\n\\nCalculating embeddings\\n\\nIn this article, we will be using OpenAI embeddings. We will try a new model text-embedding-3-small that was released just recently. The new model shows better performance compared to text-embedding-ada-002:\\n\\nThe average score on a widely used multi-language retrieval (MIRACL) benchmark has risen from 31.4% to 44.0%.\\n\\nThe average performance on a frequently used benchmark for English tasks (MTEB) has also improved, rising from 61.0% to 62.3%.\\n\\nOpenAI also released a new larger model text-embedding-3-large. Now, it’s their best performing embedding model.\\n\\nAs a data source, we will be working with a small sample of Stack Exchange Data Dump - an anonymised dump of all user-contributed content on the Stack Exchange network. I’ve selected a bunch of topics that look interesting to me and sample 100 questions from each of them. Topics range from Generative AI to coffee or bicycles so that we will see quite a wide variety of topics.\\n\\nFirst, we need to calculate embeddings for all our Stack Exchange questions. It’s worth doing it once and storing results locally (in a file or vector storage). We can generate embeddings using the OpenAI Python package.\\n\\nfrom openai import OpenAI\\nclient = OpenAI()\\n\\ndef get_embedding(text, model=\"text-embedding-3-small\"):\\n   text = text.replace(\"\\\\n\", \" \")\\n   return client.embeddings.create(input = [text], model=model)\\\\\\n       .data[0].embedding\\n\\nget_embedding(\"We are lucky to live in an age in which we are still making discoveries.\")\\n\\n\\nAs a result, we got a 1536-dimension vector of float numbers. We can now repeat it for all our data and start analysing the values.\\n\\nThe primary question you might have is how close the sentences are to each other by meaning. To uncover answers, let’s discuss the concept of distance between vectors.\\n\\nDistance between vectors\\n\\nEmbeddings are actually vectors. So, if we want to understand how close two sentences are to each other, we can calculate the distance between vectors. A smaller distance would be equivalent to a closer semantic meaning.\\n\\nDifferent metrics can be used to measure the distance between two vectors:\\n\\nEuclidean distance (L2),\\n\\nManhattant distance (L1),\\n\\nDot product,\\n\\nCosine distance.\\n\\nLet’s discuss them. As a simple example, we will be using two 2D vectors.\\n\\nvector1 = [1, 4]\\nvector2 = [2, 2]\\n\\nEuclidean distance (L2)\\n\\nThe most standard way to define distance between two points (or vectors) is Euclidean distance or L2 norm. This metric is the most commonly used in day-to-day life, for example, when we are talking about the distance between 2 towns.\\n\\nHere’s a visual representation and formula for L2 distance.\\n\\nImage by author\\n\\nWe can calculate this metric using vanilla Python or leveraging the numpy function.\\n\\nimport numpy as np\\n\\nsum(list(map(lambda x, y: (x - y) ** 2, vector1, vector2))) ** 0.5\\n# 2.2361\\n\\nnp.linalg.norm((np.array(vector1) - np.array(vector2)), ord = 2)\\n# 2.2361\\n\\nManhattant distance (L1)\\n\\nThe other commonly used distance is the L1 norm or Manhattan distance. This distance was called after the island of Manhattan (New York). This island has a grid layout of streets, and the shortest routes between two points in Manhattan will be L1 distance since you need to follow the grid.\\n\\nImage by author\\n\\nWe can also implement it from scratch or use the numpy function.\\n\\nsum(list(map(lambda x, y: abs(x - y), vector1, vector2)))\\n# 3\\n\\nnp.linalg.norm((np.array(vector1) - np.array(vector2)), ord = 1)\\n# 3.0\\n\\nDot product\\n\\nAnother way to look at the distance between vectors is to calculate a dot or scalar product. Here’s a formula and we can easily implement it.\\n\\nImage by author\\n\\nsum(list(map(lambda x, y: x*y, vector1, vector2)))\\n# 11\\n\\nnp.dot(vector1, vector2)\\n# 11\\n\\nThis metric is a bit tricky to interpret. On the one hand, it shows you whether vectors are pointing in one direction. On the other hand, the results highly depend on the magnitudes of the vectors. For example, let’s calculate the dot products between two pairs of vectors:\\n\\n(1, 1) vs (1, 1)\\n\\n(1, 1) vs (10, 10).\\n\\nIn both cases, vectors are collinear, but the dot product is ten times bigger in the second case: 2 vs 20.\\n\\nCosine similarity\\n\\nQuite often, cosine similarity is used. Cosine similarity is a dot product normalised by vectors’ magnitudes (or normes).\\n\\nImage by author\\n\\nWe can either calculate everything ourselves (as previously) or use the function from sklearn.\\n\\ndot_product = sum(list(map(lambda x, y: x*y, vector1, vector2)))\\nnorm_vector1 = sum(list(map(lambda x: x ** 2, vector1))) ** 0.5\\nnorm_vector2 = sum(list(map(lambda x: x ** 2, vector2))) ** 0.5\\n\\ndot_product/norm_vector1/norm_vector2\\n\\n# 0.8575\\n\\nfrom sklearn.metrics.pairwise import cosine_similarity\\n\\ncosine_similarity(\\n  np.array(vector1).reshape(1, -1), \\n  np.array(vector2).reshape(1, -1))[0][0]\\n\\n# 0.8575\\n\\nThe function cosine_similarity expects 2D arrays. That’s why we need to reshape the numpy arrays.\\n\\nLet’s talk a bit about the physical meaning of this metric. Cosine similarity is equal to the cosine between two vectors. The closer the vectors are, the higher the metric value.\\n\\nImage by author\\n\\nWe can even calculate the exact angle between our vectors in degrees. We get results around 30 degrees, and it looks pretty reasonable.\\n\\nimport math\\nmath.degrees(math.acos(0.8575))\\n\\n# 30.96\\n\\nWhat metric to use?\\n\\nWe’ve discussed different ways to calculate the distance between two vectors, and you might start thinking about which one to use.\\n\\nYou can use any distance to compare the embeddings you have. For example, I calculated the average distances between the different clusters. Both L2 distance and cosine similarity show us similar pictures:\\n\\nObjects within a cluster are closer to each other than to other clusters. It’s a bit tricky to interpret our results since for L2 distance, closer means lower distance, while for cosine similarity - the metric is higher for closer objects. Don’t get confused.\\n\\nWe can spot that some topics are really close to each other, for example, \"politics\" and \"economics\" or \"ai\" and \"datascience\".\\n\\nImage by author\\n\\nImage by author\\n\\nHowever, for NLP tasks, the best practice is usually to use cosine similarity. Some reasons behind it:\\n\\nCosine similarity is between -1 and 1, while L1 and L2 are unbounded, so it’s easier to interpret.\\n\\nFrom the practical perspective, it’s more effective to calculate dot products than square roots for Euclidean distance.\\n\\nCosine similarity is less affected by the curse of dimensionality (we will talk about it in a second).\\n\\nOpenAI embeddings are already normed, so dot product and cosine similarity are equal in this case.\\n\\nYou might spot in the results above that the difference between inter- and intra-cluster distances is not so big. The root cause is the high dimensionality of our vectors. This effect is called \"the curse of dimensionality\": the higher the dimension, the narrower the distribution of distances between vectors. You can learn more details about it in this article.\\n\\nI would like to briefly show you how it works so that you get some intuition. I calculated a distribution of OpenAI embedding values and generated sets of 300 vectors with different dimensionalities. Then, I calculated the distances between all the vectors and draw a histogram. You can easily see that the increase in vector dimensionality makes the distribution narrower.\\n\\nGraph by author\\n\\nWe’ve learned how to measure the similarities between the embeddings. With that we’ve finished with a theoretical part and moving to more practical part (visualisations and practical applications). Let’s start with visualisations since it’s always better to see your data first.\\n\\nVisualising embeddings\\n\\nThe best way to understand the data is to visualise it. Unfortunately, embeddings have 1536 dimensions, so it’s pretty challenging to look at the data. However, there’s a way: we could use dimensionality reduction techniques to project vectors in two-dimensional space.\\n\\nPCA\\n\\nThe most basic dimensionality reduction technique is PCA (Principal Component Analysis). Let’s try to use it.\\n\\nFirst, we need to convert our embeddings into a 2D numpy array to pass it to sklearn.\\n\\nimport numpy as np\\nembeddings_array = np.array(df.embedding.values.tolist())\\nprint(embeddings_array.shape)\\n# (1400, 1536)\\n\\nThen, we need to initialise a PCA model with n_components = 2 (because we want to create a 2D visualisation), train the model on the whole data and predict new values.\\n\\nfrom sklearn.decomposition import PCA\\n\\npca_model = PCA(n_components = 2)\\npca_model.fit(embeddings_array)\\n\\npca_embeddings_values = pca_model.transform(embeddings_array)\\nprint(pca_embeddings_values.shape)\\n# (1400, 2)\\n\\n\\n\\nAs a result, we got a matrix with just two features for each question, so we could easily visualise it on a scatter plot.\\n\\nfig = px.scatter(\\n    x = pca_embeddings_values[:,0], \\n    y = pca_embeddings_values[:,1],\\n    color = df.topic.values,\\n    hover_name = df.full_text.values,\\n    title = \\'PCA embeddings\\', width = 800, height = 600,\\n    color_discrete_sequence = plotly.colors.qualitative.Alphabet_r\\n)\\n\\nfig.update_layout(\\n    xaxis_title = \\'first component\\', \\n    yaxis_title = \\'second component\\')\\nfig.show()\\n\\nImage by author\\n\\nWe can see that questions from each topic are pretty close to each other, which is good. However, all the clusters are mixed, so there’s room for improvement.\\n\\nt-SNE\\n\\nPCA is a linear algorithm, while most of the relations are non-linear in real life. So, we may not be able to separate the clusters because of non-linearity. Let’s try to use a non-linear algorithm t-SNE and see whether it will be able to show better results.\\n\\nThe code is almost identical. I just used the t-SNE model instead of PCA.\\n\\nfrom sklearn.manifold import TSNE\\ntsne_model = TSNE(n_components=2, random_state=42)\\ntsne_embeddings_values = tsne_model.fit_transform(embeddings_array)\\n\\nfig = px.scatter(\\n    x = tsne_embeddings_values[:,0], \\n    y = tsne_embeddings_values[:,1],\\n    color = df.topic.values,\\n    hover_name = df.full_text.values,\\n    title = \\'t-SNE embeddings\\', width = 800, height = 600,\\n    color_discrete_sequence = plotly.colors.qualitative.Alphabet_r\\n)\\n\\nfig.update_layout(\\n    xaxis_title = \\'first component\\', \\n    yaxis_title = \\'second component\\')\\nfig.show()\\n\\nThe t-SNE result looks way better. Most of the clusters are separated except \"genai\", \"datascience\" and \"ai\". However, it’s pretty expected - I doubt I could separate these topics myself.\\n\\n\\n\\nLooking at this visualisation, we see that embeddings are pretty good at encoding semantic meaning.\\n\\nAlso, you can make a projection to three-dimensional space and visualise it. I’m not sure whether it would be practical, but it can be insightful and engaging to play with the data in 3D.\\n\\ntsne_model_3d = TSNE(n_components=3, random_state=42)\\ntsne_3d_embeddings_values = tsne_model_3d.fit_transform(embeddings_array)\\n\\nfig = px.scatter_3d(\\n    x = tsne_3d_embeddings_values[:,0], \\n    y = tsne_3d_embeddings_values[:,1],\\n    z = tsne_3d_embeddings_values[:,2],\\n    color = df.topic.values,\\n    hover_name = df.full_text.values,\\n    title = \\'t-SNE embeddings\\', width = 800, height = 600,\\n    color_discrete_sequence = plotly.colors.qualitative.Alphabet_r,\\n    opacity = 0.7\\n)\\nfig.update_layout(xaxis_title = \\'first component\\', yaxis_title = \\'second component\\')\\nfig.show()\\n\\n\\n\\nBarcodes\\n\\nThe way to understand the embeddings is to visualise a couple of them as bar codes and see the correlations. I picked three examples of embeddings: two are closest to each other, and the other is the farthest example in our dataset.\\n\\nembedding1 = df.loc[1].embedding\\nembedding2 = df.loc[616].embedding\\nembedding3 = df.loc[749].embedding\\n\\nimport seaborn as sns\\nimport matplotlib.pyplot as plt\\nembed_len_thr = 1536\\n\\nsns.heatmap(np.array(embedding1[:embed_len_thr]).reshape(-1, embed_len_thr),\\n    cmap = \"Greys\", center = 0, square = False, \\n    xticklabels = False, cbar = False)\\nplt.gcf().set_size_inches(15,1)\\nplt.yticks([0.5], labels = [\\'AI\\'])\\nplt.show()\\n\\nsns.heatmap(np.array(embedding3[:embed_len_thr]).reshape(-1, embed_len_thr),\\n    cmap = \"Greys\", center = 0, square = False, \\n    xticklabels = False, cbar = False)\\nplt.gcf().set_size_inches(15,1)\\nplt.yticks([0.5], labels = [\\'AI\\'])\\nplt.show()\\n\\nsns.heatmap(np.array(embedding2[:embed_len_thr]).reshape(-1, embed_len_thr),\\n    cmap = \"Greys\", center = 0, square = False, \\n    xticklabels = False, cbar = False)\\nplt.gcf().set_size_inches(15,1)\\nplt.yticks([0.5], labels = [\\'Bioinformatics\\'])\\nplt.show()\\n\\nGraph by author\\n\\nIt’s not easy to see whether vectors are close to each other in our case because of high dimensionality. However, I still like this visualisation. It might be helpful in some cases, so I am sharing this idea with you.\\n\\nWe’ve learned how to visualise embeddings and have no doubts left about their ability to grasp the meaning of the text. Now, it’s time to move on to the most interesting and fascinating part and discuss how you can leverage embeddings in practice.\\n\\nPractical applications\\n\\nOf course, embeddings’ primary goal is not to encode texts as vectors of numbers or visualise them just for the sake of it. We can benefit a lot from our ability to capture the texts’ meanings. Let’s go through a bunch of more practical examples.\\n\\nClustering\\n\\nLet’s start with clustering. Clustering is an unsupervised learning technique that allows you to split your data into groups without any initial labels. Clustering can help you understand the internal structural patterns in your data.\\n\\nWe will use one of the most basic clustering algorithms - K-means. For the K-means algorithm, we need to specify the number of clusters. We can define the optimal number of clusters using silhouette scores.\\n\\nLet’s try k (number of clusters) between 2 and 50. For each k, we will train a model and calculate silhouette scores. The higher silhouette score - the better clustering we got.\\n\\nfrom sklearn.cluster import KMeans\\nfrom sklearn.metrics import silhouette_score\\nimport tqdm\\n\\nsilhouette_scores = []\\nfor k in tqdm.tqdm(range(2, 51)):\\n    kmeans = KMeans(n_clusters=k, \\n                    random_state=42, \\n                    n_init = \\'auto\\').fit(embeddings_array)\\n    kmeans_labels = kmeans.labels_\\n    silhouette_scores.append(\\n        {\\n            \\'k\\': k,\\n            \\'silhouette_score\\': silhouette_score(embeddings_array, \\n                kmeans_labels, metric = \\'cosine\\')\\n        }\\n    )\\n\\nfig = px.line(pd.DataFrame(silhouette_scores).set_index(\\'k\\'),\\n       title = \\'<b>Silhouette scores for K-means clustering</b>\\',\\n       labels = {\\'value\\': \\'silhoutte score\\'}, \\n       color_discrete_sequence = plotly.colors.qualitative.Alphabet)\\nfig.update_layout(showlegend = False)\\n\\nIn our case, the silhouette score reaches a maximum when k = 11. So, let’s use this number of clusters for our final model.\\n\\nGraph by author\\n\\nLet’s visualise the clusters using t-SNE for dimensionality reduction as we already did before.\\n\\ntsne_model = TSNE(n_components=2, random_state=42)\\ntsne_embeddings_values = tsne_model.fit_transform(embeddings_array)\\n\\nfig = px.scatter(\\n    x = tsne_embeddings_values[:,0], \\n    y = tsne_embeddings_values[:,1],\\n    color = list(map(lambda x: \\'cluster %s\\' % x, kmeans_labels)),\\n    hover_name = df.full_text.values,\\n    title = \\'t-SNE embeddings for clustering\\', width = 800, height = 600,\\n    color_discrete_sequence = plotly.colors.qualitative.Alphabet_r\\n)\\nfig.update_layout(\\n    xaxis_title = \\'first component\\', \\n    yaxis_title = \\'second component\\')\\nfig.show()\\n\\nVisually, we can see that the algorithm was able to define clusters quite well - they are separated pretty well.\\n\\n\\n\\nWe have factual topic labels, so we can even assess how good clusterisation is. Let’s look at the topics’ mixture for each cluster.\\n\\ndf[\\'cluster\\'] = list(map(lambda x: \\'cluster %s\\' % x, kmeans_labels))\\ncluster_stats_df = df.reset_index().pivot_table(\\n    index = \\'cluster\\', values = \\'id\\', \\n    aggfunc = \\'count\\', columns = \\'topic\\').fillna(0).applymap(int)\\n\\ncluster_stats_df = cluster_stats_df.apply(\\n  lambda x: 100*x/cluster_stats_df.sum(axis = 1))\\n\\nfig = px.imshow(\\n    cluster_stats_df.values, \\n    x = cluster_stats_df.columns,\\n    y = cluster_stats_df.index,\\n    text_auto = \\'.2f\\', aspect = \"auto\",\\n    labels=dict(x=\"cluster\", y=\"fact topic\", color=\"share, %\"), \\n    color_continuous_scale=\\'pubugn\\',\\n    title = \\'<b>Share of topics in each cluster</b>\\', height = 550)\\n\\nfig.show()\\n\\n\\n\\nIn most cases, clusterisation worked perfectly. For example, cluster 5 contains almost only questions about bicycles, while cluster 6 is about coffee. However, it wasn’t able to distinguish close topics:\\n\\n\"ai\", \"genai\" and \"datascience\" are all in one cluster,\\n\\nthe same store with \"economics\" and \"politics\".\\n\\nWe used only embeddings as the features in this example, but if you have any additional information (for example, age, gender or country of the user who asked the question), you can include it in the model, too.\\n\\nClassification\\n\\nWe can use embeddings for classification or regression tasks. For example, you can do it to predict customer reviews’ sentiment (classification) or NPS score (regression).\\n\\nSince classification and regression are supervised learning, you will need to have labels. Luckily, we know the topics for our questions and can fit a model to predict them.\\n\\nI will use a Random Forest Classifier. If you need a quick refresher about Random Forests, you can find it here. To assess the classification model’s performance correctly, we will split our dataset into train and test sets (80% vs 20%). Then, we can train our model on a train set and measure the quality on a test set (questions that the model hasn’t seen before).\\n\\nfrom sklearn.ensemble import RandomForestClassifier\\nfrom sklearn.model_selection import train_test_split\\nclass_model = RandomForestClassifier(max_depth = 10)\\n\\n# defining features and target\\nX = embeddings_array\\ny = df.topic\\n\\n# splitting data into train and test sets\\nX_train, X_test, y_train, y_test = train_test_split(\\n    X, y, random_state = 42, test_size=0.2, stratify=y\\n)\\n\\n# fit & predict \\nclass_model.fit(X_train, y_train)\\ny_pred = class_model.predict(X_test)\\n\\nTo estimate the model’s performance, let’s calculate a confusion matrix. In an ideal situation, all non-diagonal elements should be 0.\\n\\nfrom sklearn.metrics import confusion_matrix\\ncm = confusion_matrix(y_test, y_pred)\\n\\nfig = px.imshow(\\n  cm, x = class_model.classes_,\\n  y = class_model.classes_, text_auto=\\'d\\', \\n  aspect=\"auto\", \\n  labels=dict(\\n      x=\"predicted label\", y=\"true label\", \\n      color=\"cases\"), \\n  color_continuous_scale=\\'pubugn\\',\\n  title = \\'<b>Confusion matrix</b>\\', height = 550)\\n\\nfig.show()\\n\\n\\n\\nWe can see similar results to clusterisation: some topics are easy to classify, and accuracy is 100%, for example, \"bicycles\" or \"travel\", while some others are difficult to distinguish (especially \"ai\").\\n\\nHowever, we achieved 91.8% overall accuracy, which is quite good.\\n\\nFinding anomalies\\n\\nWe can also use embedding to find anomalies in our data. For example, at the t-SNE graph, we saw that some questions are pretty far from their clusters, for instance, for the \"travel\" topic. Let’s look at this theme and try to find anomalies. We will use the Isolation Forest algorithm for it.\\n\\nfrom sklearn.ensemble import IsolationForest\\n\\ntopic_df = df[df.topic == \\'travel\\']\\ntopic_embeddings_array = np.array(topic_df.embedding.values.tolist())\\n\\nclf = IsolationForest(contamination = 0.03, random_state = 42) \\ntopic_df[\\'is_anomaly\\'] = clf.fit_predict(topic_embeddings_array)\\n\\ntopic_df[topic_df.is_anomaly == -1][[\\'full_text\\']]\\n\\nSo, here we are. We’ve found the most uncommon comment for the travel topic (source).\\n\\nIs it safe to drink the water from the fountains found all over \\nthe older parts of Rome?\\n\\nWhen I visited Rome and walked around the older sections, I saw many \\ndifferent types of fountains that were constantly running with water. \\nSome went into the ground, some collected in basins, etc.\\n\\nIs the water coming out of these fountains potable? Safe for visitors \\nto drink from? Any etiquette regarding their use that a visitor \\nshould know about?\\n\\nSince it talks about water, the embedding of this comment is close to the coffee topic where people also discuss water to pour coffee. So, the embedding representation is quite reasonable.\\n\\nWe could find it on our t-SNE visualisation and see that it’s actually close to the coffee cluster.\\n\\nGraph by author\\n\\nRAG - Retrieval Augmented Generation\\n\\nWith the recently increased popularity of LLMs, embeddings have been broadly used in RAG use cases.\\n\\nWe need Retrieval Augmented Generation when we have a lot of documents (for example, all the questions from Stack Exchange), and we can’t pass them all to an LLM because\\n\\nLLMs have limits on the context size (right now, it’s 128K for GPT-4 Turbo).\\n\\nWe pay for tokens, so it’s more expensive to pass all the information all the time.\\n\\nLLMs show worse performance with a bigger context. You can check Needle In A Haystack - Pressure Testing LLMs to learn more details.\\n\\nTo be able to work with an extensive knowledge base, we can leverage the RAG approach:\\n\\nCompute embeddings for all the documents and store them in vector storage.\\n\\nWhen we get a user request, we can calculate its embedding and retrieve relevant documents from the storage for this request.\\n\\nPass only relevant documents to LLM to get a final answer.\\n\\nTo learn more about RAG, don’t hesitate to read my article with much more details here.\\n\\nSummary\\n\\nIn this article, we’ve discussed text embeddings in much detail. Hopefully, now you have a complete and deep understanding of this topic. Here’s a quick recap of our journey:\\n\\nFirstly, we went through the evolution of approaches to work with texts.\\n\\nThen, we discussed how to understand whether texts have similar meanings to each other.\\n\\nAfter that, we saw different approaches to text embedding visualisation.\\n\\nFinally, we tried to use embeddings as features in different practical tasks such as clustering, classification, anomaly detection and RAG.\\n\\nThank you a lot for reading this article. If you have any follow-up questions or comments, please leave them in the comments section.\\n\\nReference\\n\\nIn this article, I used a dataset from Stack Exchange Data Dump, which is available under the Creative Commons license.\\n\\nThis article was inspired by the following courses:\\n\\n\"Understanding and Applying Text Embeddings\" by DeepLearning.AI in collaboration with Google Cloud,\\n\\n\"Vector Databases: From Embeddings to Applications\" by DeepLearning.AI in collaboration with Weaviate.'}},\n",
       "  {'id': 'c5b9faa7a950',\n",
       "   'title': 'Data Visualisation 101: Playbook for Attention-Grabbing Visuals',\n",
       "   'subtitle': 'Practical Techniques for Captivating Visual Communication with Plotly',\n",
       "   'author': '15a29a4fc6ad',\n",
       "   'publication_id': '7f60cf5620c9',\n",
       "   'published_at': '2024-02-05 16:55:55',\n",
       "   'last_modified_at': '2024-02-05 16:55:55',\n",
       "   'tags': ['data-visualization',\n",
       "    'data-science',\n",
       "    'python',\n",
       "    'deep-dives',\n",
       "    'getting-started'],\n",
       "   'topics': ['data-science', 'programming'],\n",
       "   'claps': 950,\n",
       "   'voters': 164,\n",
       "   'word_count': 3269,\n",
       "   'responses_count': 10,\n",
       "   'reading_time': 14.085849056603774,\n",
       "   'url': 'https://towardsdatascience.com/data-visualisation-101-playbook-for-attention-grabbing-visuals-c5b9faa7a950',\n",
       "   'unique_slug': 'data-visualisation-101-playbook-for-attention-grabbing-visuals-c5b9faa7a950',\n",
       "   'image_url': 'https://miro.medium.com/1*JZNAv55DOK4L47LTl5KfTg.png',\n",
       "   'lang': 'en',\n",
       "   'is_series': False,\n",
       "   'is_locked': False,\n",
       "   'is_shortform': False,\n",
       "   'top_highlight': '',\n",
       "   'content': {'id': 'c5b9faa7a950',\n",
       "    'content': 'Data Visualisation 101: Playbook for Attention-Grabbing Visuals\\n\\nPractical Techniques for Captivating Visual Communication with Plotly\\n\\nImage by DALL-E 3\\n\\nIn the previous article, we discussed choosing the most suitable visualisation type for your task. We’ve identified seven different use cases (Time Series, Nominal Comparison, Deviation, Ranking, Part-to-whole, Frequency Distribution and Correlation) and what chart types will be the best options for them. No surprise, in most cases, you can use basic chart types such as line charts, bar charts or scatter plots.\\n\\nSelecting the optimal visualisation type is an essential foundation. However, it’s not all you need to keep in mind when working on data visualisation.\\n\\nLet’s return back to basics. The primary goal of visualisation is to convey your message to the audience. That’s why we need to think about how the audience perceives our charts. In practice, the audience’s perception and understanding depend on many small details.\\n\\nIn this article, I would like to share these essential aspects of data visualisation. We will go through three steps to get clearer, sharper and smarter visuals:\\n\\nreducing noise to avoid audience confusion and distraction,\\n\\nadding highlights to focus their attention,\\n\\nadding the context to provide all necessary information for clear understanding.\\n\\nI will use Plotly since it’s my primary tool for data visualisation.\\n\\nUnless stated explicitly, all chart examples below are based on synthetic datasets.\\n\\nStep 1: Reducing noise\\n\\nIt might be tempting to include all the information you have in your visualisation, for example, to add labels for every point on the graph. At these moments, we are usually driven by good intentions - to give the audience comprehensive view.\\n\\nHowever, the human brain works differently. Each element you add to the visualisation increases cognitive load. People have a limited capacity of mental power to perceive information, so it’s essential not to waste it by adding unneeded elements. By adding too many details, you risk losing your audience completely because your charts might be perceived as more complicated than they actually are. This perceived complexity may frighten your audience since they might not want to spend time and effort understanding it.\\n\\nWe can refer to the data visualisation iconic books to think about it. Edward Tufte is a pioneer in the field of data visualisation. In his book \"The Visual Display of Quantitative Information\", he introduces the concept of data-ink ratio (source).\\n\\nA large share of ink on a graphic should present data-information, the ink changing as the data change. Data-ink is the non-erasable core of a graphic, the non-redundant ink arranged in response to variation in the numbers represented.\\n\\nWe aim to maximise the share of meaningful elements (or ink) in our charts. For that, we can remove clutter (or noise) from our charts to decrease perceived cognitive load. Clutter is graphical elements that take place but don’t give any additional understanding.\\n\\nUnfortunately, default settings in our tools sometimes don’t help us to make clear visualisations. So, first of all, I advise you to change the default template in Plotly - it will help you declutter your charts.\\n\\nThe default template is plotly. It looks similar to the seaborn style (you can check in the gallery) and includes background colours and grid lines. In my opinion, it adds too much noise to charts. I prefer a much more lightweight template called simple_white.\\n\\nYou can compare these two styles on the graph. Feel the difference.\\n\\nGraphs by author\\n\\nUse the code below to change the template for all your Plotly visualisations. You can check what other built-in templates are available and even learn how to create your own custom template in the documentation.\\n\\nimport plotly.io as pio\\npio.templates.default = \\'simple_white\\'\\n\\nAfter changing the template to simple_white, all your graphs will be automatically lighter. However, it’s only the beginning of our journey to data visualisations without clutter. Since each graphical element adds cognitive load, it’s worth considering whether they are needed. Each element on your chart should be your conscious decision rather than the default behaviour of your tool.\\n\\nIn many cases, graphical elements don’t add any value to understanding, so we can (and should) get rid of them. Let’s look at a couple of such examples.\\n\\nIf you create a bar chart with only one trace, Plotly will still show you the legend. However, we can eliminate it without losing any information and provide context about the metric in the y-axis title.\\n\\nGraphs by author\\n\\nLet’s hide the legend on our graph.\\n\\n# create chart\\nfig = px.bar(df, text_auto = \\',.6r\\', width = 600)\\n\\n# hide legend\\nfig.update_layout(showlegend = False)\\n\\nIt was surprising for me, but there are cases when you can get rid of not only the legend but also one of the axes. Look at the two charts below: we’ve labelled each bar for clarity, making it effortless for the audience to interpret and compare the values based on bar lengths. So, there’s no need to keep the x-axis. Ideally, we should add some context about the used metric to the chart title - we will discuss how to do it later.\\n\\nGraph by author\\n\\nTo hide one of the axes, we need to change its visibility.\\n\\nfig.update_xaxes(visible = False)\\n# you can similarly hide y-axes using fig.update_yaxes(visible = False)\\n\\nWe’ve learned how to tweak Plotly’s defaults and make your charts cleaner and clearer. However, it’s not the only thing to watch out for - quite often, we add noise and clutter ourselves. Let me show you examples of noisy graphs I’ve seen many times.\\n\\nAnalysts like numbers (at least I do). So, we often want to show our audience all these numbers, for example, how many customers we had in the previous months. It often ends up with a chart like the one below.\\n\\nGraph by author\\n\\nWith all this clutter of numbers, you miss entirely the trends and insights in data. What I would do to fix it:\\n\\nIt goes without saying I would remove the labels. If your audience needs to know precise numbers, keep only the essential ones (for example, only the last month or two).\\n\\nIt’s a good practice to round up the values you’re showing, for example, 184.1K instead of 184051. In most cases, there’s not much difference for your audience, whether there were 184 051 or 184 063 customers.\\n\\nAlso, if you want to focus your audience’s attention on the trends in your data, I would advise you to omit markers and keep only lines.\\n\\nThe other temptation is to make your visualisations more colourful. Please resist it unless colours play their role, either encoding some data or highlighting the most noteworthy aspects. We will talk about the wise usage of colours just in a second. Meanwhile, you can look at the example below and observe what catches your eye first and how much effort you need to understand the underlying data. When I look at the first graph, I feel a bit confused and keep thinking about what these colours mean and why each bar differs.\\n\\nGraphs by author\\n\\nAlso, this graph shows us that having too many accents (bright colours in our case) doesn’t work - we are just distracted and don’t know what to focus on.\\n\\nWe’ve learned how to remove noise from our charts. After this step, we have neutral visualisations. They are like a canvas. Now, the next step is to place accents strategically.\\n\\nStep 2: Adding accents\\n\\nUsing accents wisely enables you to direct your audience’s attention and emphasise the main message. People usually pay attention first to brighter and darker colours. However, it’s important to remember that you can’t highlight everything. Instead, you should concentrate your audience’s focus on one or two key aspects of the data.\\n\\nYou can also build a hierarchy of accents, emphasising the main message the most and pushing not-so-important (but still necessary) parts to the background. It allows you to avoid distraction but still keep all the needed context. We will see examples of such approaches below.\\n\\nIf you want to understand what elements of your data visualisation draw attention, try to do the following simple test: close your eyes, open them, and observe what initially catches your eye. Another option is to show your visualisation to someone else and ask them to comment on their thought process.\\n\\nColours\\n\\nIn my opinion, colour is the most powerful tool to drive your audience’s attention. That’s why I want to discuss it in detail. Let’s start with an example. Look at the visualisation below. What do you look at first? What do you think the author wanted to tell you with this chart?\\n\\nGraph by author, data from StackOverflow survey\\n\\nYou likely started to look at SQL and compare it with other languages. In my previous article, I used this chart to illustrate the following idea:\\n\\nAccording to the annual StackOverflow survey, SQL is still one of the most popular languages in the world. For professional developers, SQL is in the top-3 languages (after Javascript and HTML/CSS). More than a half of professionals use it. Surprisingly, SQL is even more popular than Python.\\n\\nI used the contrast between grey and bright blue to focus your attention on the SQL I was talking about. If I made this visualisation now, I would also make the title bolder to make it stand out since it’s a meaningful context.\\n\\nLet’s compare it with a fully grey-neutral version. Without any visual cues, you would spend much more time and effort looking at all the data.\\n\\nGraph by author\\n\\nI hope you can now see all the potential power of colour. Let’s learn how to use the colours in Plotly\\n\\nWe will start with a bar chart like in the example above. I highlighted segments where the conversion is below the threshold with a brighter colour. For this, I defined the list of colours depending on the conversion value and passed it to Plotly as colour for lines and markers. I’ve also specified that I want labels outside the bars and made colours more pale with opacity.\\n\\n# defining colors based on conversion value\\ncolors = list(map(\\n    lambda x: \\'silver\\' if x >= 40 else \\'purple\\',\\n    conv_df.conversion.values\\n))\\n\\n# creating default plot\\nfig = px.bar(conv_df, text_auto=\\'.2f\\', labels = {\\'value\\': \\'conversion, %\\'})\\n\\n# updating colors\\nfig.update_traces(marker_color=colors, marker_line_color=colors, \\n    textposition=\\'outside\\', marker_line_width=1.5, opacity=0.9)\\n\\n# hiding legend \\nfig.update_layout(showlegend = False)\\n\\n# updating range to add some space on the top\\nfig.update_yaxes(range = [0, 70]) \\n\\nGraph by author\\n\\nLet’s discuss a bit about how to define the colours. In the example above, I used predefined SVG colours \"silver\" and \"purple\". You can find the complete list of predefined colours here.\\n\\nIf you want more customisation, you can pass colours as HEX codes. For example, you can use your brand colours to add your company vibe to the presentations.\\n\\nThe easiest way to get HEX codes is to screenshot your interface, upload it to a colour picker (I usually search for \"online colour picker from image\") and look up all the needed codes. For example, one of the brand colours for Wise (the company I’m working at) is bright green with a hex code #9FE870.\\n\\nImage by author\\n\\nSince I often use brand colours in my charts, I have them saved in a config file locally so I can easily access them by name.\\n\\ncolours = {\\n  \"light_green\": \"#9FE870\",\\n  \"dark_green\": \"#163300\",\\n  \"light_blue\": \"#7CECF1\",\\n  \"dark_blue\": \"#000146\",\\n  \"light_orange\": \"#FFC828\"\\n}\\n\\nNow, I hope you won’t be stuck trying to understand how to tell Plotly what colour you want. So, let’s move on to another example with linear graphs and learn other ways to specify colours.\\n\\nIf you want to manually define each segment’s colour precisely, you can use color_discrete_map. I often use this approach when I need consistent colour-coding across multiple graphs. If you depict Android in blue and iOS in orange on one chart in your presentation but then reverse the colours on another graph, your audience might become confused. So, it’s worth paying attention to such details.\\n\\nIn the graph below, I used purple to highlight the growing iOS audience and shade of greys for the other platforms since I don’t want you to pay attention to them.\\n\\ncolormap = {\\'Android\\': \\'silver\\', \\'Windows\\': \\'gray\\', \\'iOS\\': \\'purple\\'}\\npx.line(ts_df, color_discrete_map = colormap)\\n\\nImage by author\\n\\nIf I want to show cohorts and don’t care about a specific colour for each cohort, I can just specify the sequence of colours in the color_discrete_sequence parameter.\\n\\npx.area(df, color_discrete_sequence = px.colors.qualitative.Prism)\\n\\nGraph by author\\n\\nI used a predefined Plotly palette for colours, but you can also specify custom colours as a list of strings. Here are the palettes available in Plotly:\\n\\nDiscrete colour palettes include mostly diverging colours, which are handy when you need to distinguish different segments from each other.\\n\\nIn Continuous colour scales, you can find a lot of sequential colour palettes which are ideal for ordinal categories (for example, customer maturity equal to \"< 1 month\", \"1–3 months\", \"4–6 months\", \"6–12 months\" and \"> 12 months\").\\n\\nThe continuous scales can also be used when you need to encode values using colour, such as heat maps.\\n\\npx.imshow(\\n    gmv_df.values, \\n    x = gmv_df.columns,\\n    y = gmv_df.index,\\n    color_continuous_scale=\\'pubugn\\'\\n    text_auto=\\',.6r\\', aspect=\"auto\",\\n    labels=dict(x=\"age group\", y=\"region\", color=\"GMV in GBP\")\\n)\\n\\nGraph by author\\n\\nWhen you use colours, you need to keep in mind that there are colourblind people. The most common difficulty is to distinguish shades of red and green. So, try to avoid these combinations or use some other visual cues simultaneously (like text or icons). It will help you not to lose part of your audience.\\n\\nShades of green and red are often used to denote the positive and negative aspects of something (for example, to show higher and lower conversion on a heat map). You can use blue and orange shades instead.\\n\\nSize\\n\\nThe other way to highlight something is size. We perceive something bigger as a more significant one. For example, to make an accent on one of the lines, we can increase its width.\\n\\nIn Plotly, we need to use Graphical Objects to tweak line widths.\\n\\nimport plotly.graph_objects as go\\n\\nfig = go.Figure()\\n\\nfig.add_trace(\\n    go.Scatter(\\n        mode=\\'lines\\', x=ts_df.index,\\n        y=ts_df.Android, showlegend=True,\\n        name = \\'Android\\', line = {\\'width\\': 1}\\n    )\\n)\\nfig.add_trace(\\n    go.Scatter(\\n        mode=\\'lines\\', x=ts_df.index,\\n        y=ts_df.Windows, showlegend=True,\\n        name = \\'Windows\\', line = {\\'width\\': 1}\\n    )\\n)\\nfig.add_trace(\\n    go.Scatter(\\n        mode=\\'lines\\', x=ts_df.index,\\n        y=ts_df.iOS, showlegend=True,\\n        name = \\'iOS\\', line = {\\'width\\': 3} \\n    )\\n)\\n\\nfig.show()\\n\\nGraph by author\\n\\nNow, the iOS line stands out compared to other platforms. We can also focus the audience’s attention using bold or italic fonts. Let’s add the title to our graph and highlight the central part of it. For that, we can use HTML tag <b>.\\n\\nfig.update_layout(\\n    title = \\'<b>Monthly sessions:</b> sky-rocketing trend for iOS\\'\\n)\\n\\nGraph by author\\n\\nStep 3: Storytelling\\n\\nWe’ve learned how to put accents and are ready to move on to the last part - storytelling. We’ve already discussed that the context is vital for understanding the message. So, in this part, we will discuss how to add it to your charts.\\n\\nTo add more context, the most straightforward thing you can leverage is to specify a title and labels. It will prevent your audience’s questions about what exactly they see. You can use a title parameter for a chart title (similarly to the one we did before) and labels to override default labels for axes and legend titles.\\n\\npx.line(ts_df, width = 600, \\n    labels = {\\'value\\': \\'sessions\\', \\'os\\': \\'platform\\', \\'month_date\\': \\'month\\'},\\n    title = \\'Monthly sessions over time\\')\\n\\nGraphs by author\\n\\nIt’s a good practice to make titles detailed so that the titles might become quite long. Plotly is a powerful visual tool but has room for improvement. For example, it can’t handle long chart titles - the tail of the title won’t be visible.\\n\\nHowever, Plotly is agile enough, and we can fix it ourselves. We will use <br> HTML tag to add line breaks between words if the line length exceeds the threshold (70 characters). Let’s do it.\\n\\ndef format_string_by_lines(s, line_limit = 70):    \\n    lines = []\\n    curr_line_words = []\\n    curr_line_length = 0\\n    \\n    \\n    for word in s.split(\\' \\'):\\n        if curr_line_length + len(word) > line_limit:\\n            lines.append(\\' \\'.join(curr_line_words))\\n            curr_line_words = []\\n            curr_line_length = 0\\n    \\n        curr_line_words.append(word)\\n        curr_line_length += len(word)\\n    \\n    lines.append(\\' \\'.join(curr_line_words))\\n    return \\' <br> \\'.join(lines)\\n\\nchart_title = \\'<b>Monthly sessions over time:</b> we can see sky-rocketing trend on iOS while Android and Windows are pretty stagnant.\\'\\npx.line(ts_df, width = 600, \\n    labels = {\\'value\\': \\'sessions\\', \\'os\\': \\'platform\\', \\'month_date\\': \\'month\\'},\\n    title = format_string_by_lines(chart_title))\\n\\nGraphs by author\\n\\nAlso, we might want to show some of the metrics’ values. We’ve already discussed that labelling all data points generates too much clutter, but showing the last values sounds reasonable.\\n\\nI will demonstrate two ways to do it in Plotly: using the text field and annotations functionality. I usually prefer using text, but it’s quite subjective.\\n\\nLet’s start with the text option. First, let’s look at the raw data set.\\n\\nImage by author\\n\\nNow, let’s add the text_val field to the dataset that is equal to the value for the last month and is empty for others. I’ve also specified formatting to show numbers as thousands to remove unneeded details.\\n\\nraw_ts_df[\\'text_val\\'] = list(map(\\n    lambda v, d: \\'\\' if d != raw_ts_df.month_date.max() else \\'%.1fK\\' % (v/1000),\\n    raw_ts_df.value,\\n    raw_ts_df.month_date\\n))\\n\\nWe are ready to create our visualisation. I passed the newly-created text_val column as the text parameter for the visualisation, updated the mode to be \"lines+text\" and specified the middle right text position. I also moved the legend so it doesn’t interfere with our annotations.\\n\\nfig = px.line(raw_ts_df, x = \\'month_date\\', y = \\'value\\', \\n    color = \\'platform\\', text = \\'text_val\\',\\n    width = 1000, height = 500, \\n    labels = {\\'value\\': \\'sessions\\', \\'os\\': \\'platform\\', \\'month_date\\': \\'month\\'},\\n    title = \\'<b>Monthly sessions</b>\\')\\n\\nfig.update_traces(textposition=\"middle right\", mode=\\'lines+text\\')\\nfig.update_layout(legend=dict(orientation=\"h\", yanchor=\"bottom\", \\n    y=0.05, xanchor=\"right\", x=1))\\n\\nGraph by author\\n\\nThe other way to label the values is to use the annotations functionality. Firstly, let’s calculate the last values for each platform and format the text.\\n\\nannotations = raw_ts_df.groupby(\\'platform\\', as_index = False)\\\\\\n    .aggregate({\\'value\\': \\'last\\', \\'month_date\\': \\'last\\'})\\\\\\n    .rename(columns = {\\'value\\': \\'y\\', \\'month_date\\': \\'x\\'})\\n\\nannotations[\\'text\\'] = annotations.y.map(lambda v: \\'%.1fK\\' % (v/1000))\\nannotations = annotations.drop(\\'platform\\', axis = 1)\\n\\nLet’s add more parameters we will use for annotations’ formatting and convert the data frame into the list that we can pass to Plotly.\\n\\nannotations[\\'showarrow\\'] = False\\nannotations[\\'xanchor\\'] = \\'left\\' \\nannotations[\\'yanchor\\'] = \\'middle\\'\\nannotations_list = annotations.to_dict(\\'records\\')\\n\\nNow, we can similarly make a visualisation passing annotations and get the same result. So, it’s up to you what to use.\\n\\nfig = px.line(raw_ts_df, x = \\'month_date\\', y = \\'value\\', \\n    color = \\'platform\\', \\n    width = 1000, height = 500, \\n    labels = {\\'value\\': \\'sessions\\', \\'os\\': \\'platform\\', \\'month_date\\': \\'month\\'},\\n    title = \\'<b>Monthly sessions</b>\\')\\n\\nfig.update_layout(annotations = annotations_list,\\n    legend=dict(orientation=\"h\", yanchor=\"bottom\", \\n    y=0.05, xanchor=\"right\", x=1))\\n\\nVertical or horizontal lines can also add the needed context for your audience. For example, you can highlight important dates like a marketing campaign launch or show SLA for your metric. Let’s add a vertical line to our chart.\\n\\nYou can do it easily by using fig.add_vline. Unfortunately, there’s a bug in Plotly, and it can’t work with dates. However, we can use a workaround: it looks weird, but works.\\n\\nfig.add_vline(\\n    x=datetime.datetime.strptime(\"2023-09-01\", \"%Y-%m-%d\").timestamp() * 1000, line_width=3, line_dash=\"dash\", \\n    line_color=\\'black\\', annotation_text=\"Marketing   <br> campaign  \", \\n    annotation_position=\"top left\"\\n)\\n\\nGraph by author\\n\\nYou can add horizontal lines or even rectangles if you want to highlight the whole area on the chart. You can find more details in the documentation.\\n\\nSummary\\n\\nIn this article, we’ve walked through the essential aspects of data visualisations:\\n\\nRemoving unneeded noise to avoid distraction,\\n\\nUsing accents to focus your audience’s attention using colours and sizes,\\n\\nAdding context to help your audience understand your message.\\n\\nThank you a lot for reading this article. If you have any follow-up questions or comments, please leave them in the comments section.\\n\\nReference\\n\\nThis article is highly influenced by the excellent book about data visualisations, \"Storytelling with Data: A Data Visualization Guide for Business Professionals\" by Cole Nussbaumer Knaflic.'}},\n",
       "  {'id': '3a10838b150d',\n",
       "   'title': 'Visualisation 101: Choosing the Best Visualisation Type',\n",
       "   'subtitle': 'Comprehensive guide for different visualisation use cases',\n",
       "   'author': '15a29a4fc6ad',\n",
       "   'publication_id': '7f60cf5620c9',\n",
       "   'published_at': '2024-01-12 20:44:18',\n",
       "   'last_modified_at': '2024-01-12 20:44:18',\n",
       "   'tags': ['visualization',\n",
       "    'data-science',\n",
       "    'python',\n",
       "    'editors-pick',\n",
       "    'data-visualization'],\n",
       "   'topics': ['visual-design', 'design', 'data-science', 'programming'],\n",
       "   'claps': 1133,\n",
       "   'voters': 243,\n",
       "   'word_count': 3701,\n",
       "   'responses_count': 19,\n",
       "   'reading_time': 15.866037735849057,\n",
       "   'url': 'https://towardsdatascience.com/visualisation-101-choosing-the-best-visualisation-type-3a10838b150d',\n",
       "   'unique_slug': 'visualisation-101-choosing-the-best-visualisation-type-3a10838b150d',\n",
       "   'image_url': 'https://miro.medium.com/1*ZnlImfsQ4VkFgLH-c5tsow.jpeg',\n",
       "   'lang': 'en',\n",
       "   'is_series': False,\n",
       "   'is_locked': False,\n",
       "   'is_shortform': False,\n",
       "   'top_highlight': \"One of the most famous examples is Anscombe's quartet. It was created by statistician Francis Anscombe, and it consists of 4 data sets with almost equal descriptive statistics: means, variances and correlations. But when we look at the data, we can see how different the datasets are.\",\n",
       "   'content': {'id': '3a10838b150d',\n",
       "    'content': 'Visualisation 101: Choosing the Best Visualisation Type\\n\\nComprehensive guide for different visualisation use cases\\n\\nImage by DALL-E 3\\n\\nI believe that the primary goal of analysts is to help their product teams make the right decisions based on data. It means that the main result of analysts’ work is not just getting some numbers or dashboards but influencing reasonable data-driven decisions. So, presenting the results of our research is a critical part of analysts’ day-to-day work.\\n\\nHave you ever experienced not noticing some obvious anomaly until you create a graph? You are not alone. Almost nobody can extract insights from dry tables of numbers. That’s why we need visualisations to unveil the insights in the data. Serving as a bridge between data and product teams, a data analyst needs to excel in visualisation.\\n\\nThat’s why I would like to discuss data visualisations and start with the framework to choose the most suitable chart type for your use case.\\n\\nWhy do we need visualisations?\\n\\nIt might be tempting to look at data just using summary statistics. You can compare datasets by mean values and variance and not look at data at all. However, it might lead to misinterpretations of your data and wrong decisions.\\n\\nOne of the most famous examples is Anscombe’s quartet. It was created by statistician Francis Anscombe, and it consists of 4 data sets with almost equal descriptive statistics: means, variances and correlations. But when we look at the data, we can see how different the datasets are.\\n\\nVisualisation by author\\n\\nYou can find more mind-blowing examples (even a dinosaur) with the same descriptive statistics here.\\n\\nThis example clearly shows how outliers can skew your summary statistics and why we need to visualise our data.\\n\\nBesides outliers, visualisations are also a better way to present the results of your research. Graphs are more easily comprehensible and have the ability to consolidate a substantial amount of data. So, it’s an essential domain for analysts to pay attention to.\\n\\nContext is a starting point\\n\\nWhen we start to think about visualisation for our task, we need to define its primary goal or the context for the visualisation.\\nThere are two significant use cases for creating charts: exploratory and explanatory analytics.\\n\\nExploratory visualisations are your \"private talk\" with data when trying to find insights and understand the internal structure. For such visualisations, you might pay less attention to design and details, i.e., omit titles or not use consistent colour schemes across charts, since these visualisations are only for your eyes.\\n\\nI usually start with a bunch of quick chart prototypes. However, even in this case, you still need to think about the most suitable chart type. Proper visualisation can help you find insights, while the wrong one can hide the clues. So, choose wisely.\\n\\nExplanatory visualisations are intended to convey information to your audience. In this case, you need to focus more on details and the context to achieve your goal.\\n\\nWhen I am working on explanatory visualisations, I usually think about the following questions to define my goal crystal-clearly:\\n\\nWho is my audience? What context do they have? What information do I need to explain to them? What are they interested in?\\n\\nWhat do I want to achieve? What concerns my audience might have? What information can I show them to achieve my goal?\\n\\nAm I showing the whole picture? Do I need to look at the question from the other point of view to give all the information for the audience to make an informed decision?\\n\\nAlso, your decisions on visualisation might depend on the medium, whether you will make a live presentation or just send it in Slack or via e-mail. Here are a couple of examples:\\n\\nIn the case of a live presentation, you can have fewer comments on charts since you can talk about all the needed context, while in an e-mail, it’s better to provide all the details.\\n\\nA table with many numbers won’t work for live presentations since the slide with so much information might distract the audience from your speech. At the same time, it’s absolutely okay for written communication when the audience can go through all the numbers at their own pace.\\n\\nSo, when choosing a chart type, we shouldn’t think about visualisations in isolation. We need to consider our primary goal and audience. Please keep it in mind.\\n\\nThe perception of visualisation\\n\\nHow many different types of charts do you know? I bet you can name quite a few of them: linear charts, bar charts, Sankey diagrams, heat maps, box plots, bubble charts, etc. But have you ever thought about visualisations more granularly: what are the building blocks, and how are they perceived by your readers?\\n\\nWilliam S. Cleveland and Robert McGill investigated this question in their article \"Graphical Perception: Theory, Experimentation, and Application to the Development of Graphical Methods\" in the Journal of American Statistical Association, September 1984. This article focuses on visual perception - the ability to decode information presented in a chart. The authors identified a set of building blocks for visualisations - visual encodings - for example, position, length, area or colour saturation. No surprise, different visual encodings have different levels of difficulty for people to interpret.\\n\\nThe authors tried to hypothesise and test these hypotheses via experiments on how accurately people can extract information from the graph depending on the elements used. Their goal was to test how valid people’s judgements are.\\n\\nThey used previous psychological research and experiments to rank different visualisation building blocks from the most accurate to the least. Here’s the list:\\n\\nposition - for example, scatter plot;\\n\\nlength - for example, bar chart;\\n\\ndirection or slope - for example, line chart;\\n\\nangle— for example, pie chart;\\n\\narea - for example, bubble chart;\\n\\nvolume - 3D chart;\\n\\ncolour hue and saturation - for example, heat map.\\n\\nI’ve highlighted only the most common elements from the article for analytical day-to-day tasks.\\n\\nAs we discussed earlier, the primary goal of visualisation is to convey information, and we need to focus on our audience and how they perceive the message. So, we are interested in people’s correct understanding. That’s why I usually try to use visual encodings from the top of the list since they are easier for people to interpret.\\n\\nTools for visualisations\\n\\nWe will see many chart examples below, so let’s quickly discuss the tools I use for it.\\n\\nThere are lots of options for visualisation:\\n\\nExcel or Google Sheet,\\n\\nBI tools like Tableau or Superset,\\n\\nLibraries in Python or R.\\n\\nIn most cases, I prefer using the Plotly library for Python since it allows you to create nicely-looking interactive charts easily. In rare cases, I use Matplotlib or Seaborn. For example, I prefer Matplotlib for histograms (as you will see below) because, by default, it gives me exactly what I need, while this is not the case with Plotly.\\n\\nNow, let’s jump to the practice and discuss use cases and how to choose the best visualisations to address them.\\n\\nWhat chart type to use?\\n\\nYou might often be stuck thinking about what chart to use in your use case since so many of them exist.\\n\\nThere are valuable tools, such as a pretty handy Chart Chooser described in the \"Storytelling with Data\" blog. It can help you to get some ideas of what to start with.\\n\\nStephen Few proposed the other approach I find pretty helpful. He has an article, \"Eenie, Meenie, Minie, Moe: Selecting the Right Graph for Your Message\". In this article, he identifies the seven common use cases for data visualisations and proposes visualisation types to address them.\\n\\nHere is the list of these use cases:\\n\\nTime series\\n\\nNominal comparison\\n\\nDeviation\\n\\nRanking\\n\\nPart-to-whole\\n\\nFrequency distribution\\n\\nCorrelation\\n\\nWe will go through all of them and discuss some examples of visualisations for each case. I don’t entirely agree with the author’s proposals regarding visualisation types, and I will share my view on it.\\n\\nGraph examples below are based on synthetic data unless it’s explicitly mentioned.\\n\\nTime series\\n\\nWhat is a use case? It is the most common use case for visualisation. We want to look at changes in one or several metrics over time quite often.\\n\\nChart recommendations\\n\\nThe most straightforward option (especially if you have several metrics) is to use a line chart. It highlights the trend and gives the audience a complete overview of the data.\\n\\nFor example, I used a line chart to show how the number of sessions on each platform changes over time. We can see that iOS is the fastest-growing segment, while the others are pretty stagnant.\\n\\nVisualisation by author\\n\\nUsing a line plot (not a scatter plot) is essential because the line plot emphasises trends via slopes.\\n\\nYou can get such a graph quite effortlessly using Plotly. We have a dataset like this with a monthly number of sessions.\\n\\n\\n\\nThen, we can use Plotly Express to create a line chart, passing data, title and overriding labels.\\n\\nimport plotly.express as px\\n\\npx.line(\\n  ts_df, \\n  title = \\'<b>Sessions by platforms</b>\\',\\n  labels = {\\'value\\': \\'sessions\\', \\'os\\': \\'platform\\', \\'month_date\\': \\'month\\'},\\n  color_discrete_map={\\n      \\'Android\\': px.colors.qualitative.Vivid[1],\\n      \\'Windows\\': px.colors.qualitative.Vivid[2],\\n      \\'iOS\\': px.colors.qualitative.Vivid[4]\\n  }\\n)\\n\\nWe won’t discuss in detail design and how to tweak it in Plotly here since it’s a pretty huge topic that deserves a separate article.\\n\\nWe usually put time on an x-axis for line charts and use equal periods between data points.\\n\\nThere’s a common misunderstanding that we must make the y-axis zero-based (it must include 0). However, it’s not true for line charts. In some cases, such an approach might even hinder the insights in your data.\\n\\nFor example, compare the two charts below. On the first chart, the number of sessions looks pretty stable, while on the second one, the drop-off in the middle of December is quite apparent. However, it’s exactly the same dataset, and only y-ranges differ.\\n\\nVisualisation by author\\n\\nVisualisation by author\\n\\nYour options for time series data are not limited to line charts. Sometimes, a bar chart can be a better option, for example, if you have few data points and want to emphasise individual values rather than trends.\\n\\nVisualisation by author\\n\\nCreating a bar chart in Plotly is also pretty straightforward.\\n\\nfig = px.bar(\\n    df, \\n    title = \\'<b>Sessions</b>\\',\\n    labels = {\\'value\\': \\'sessions\\', \\'os\\': \\'platform\\', \\'month_date\\': \\'month\\'}, \\n    text_auto = \\',.6r\\' # specifying format for bar labels\\n)\\n\\nfig.update_layout(xaxis_type=\\'category\\') \\n# to prevent converting string to dates\\nfig.update_layout(showlegend = False) \\n# hiding ledend since we don\\'t need it\\n\\nNominal comparison\\n\\nWhat is a use case? It’s the case when you want to compare one or several metrics across segments.\\n\\nChart recommendations\\n\\nIf you have a couple of data points, you can use just numbers in text instead of a chart. I like this approach since it’s concise and uncluttered.\\n\\nVisualisation by author\\n\\nIn many cases, bar charts will be handy to compare the metrics. Even though vertical bar charts are usually more common, horizontal ones will be a better option when you have long names for segments.\\n\\nFor example, we can compare the annual GMVs (Gross Merchandise Value) per customer for different regions.\\n\\nVisualisation by author\\n\\nTo make a bar chart horizontal, you just need to pass orientation = \"h\".\\n\\nfig = px.bar(df,\\n  text_auto = \\',.6r\\', \\n  title = \\'<b>Average annual GMV</b> (Gross Merchandise Value)\\',\\n  labels = {\\'country\\': \\'region\\', \\'value\\': \\'average GMV in GBP\\'}, \\n  orientation = \\'h\\'\\n)\\n\\nfig.update_layout(showlegend = False)\\nfig.update_xaxes(visible = False) # to hide x-axes\\n\\nImportant note: always use zero-based axes for bar charts. Otherwise, you might mislead your audience.\\n\\nWhen there are too many numbers for a bar chart, I prefer a heat map. In this case, we use colour saturation to encode the numbers, which is not very accurate, so we also keep the labels. For example, let’s add another dimension to our average GMV view.\\n\\nVisualisation by author\\n\\nNo surprise, you can create a heat map in Plotly as well.\\n\\nfig = px.imshow(\\n  table_df.values, \\n  x = table_df.columns, # labels for x-axis\\n  y = table_df.index, # labels for y-axis \\n  text_auto=\\',.6r\\', aspect=\"auto\",\\n  labels=dict(x=\"age group\", y=\"region\", color=\"GMV in GBP\"), \\n  color_continuous_scale=\\'pubugn\\',\\n  title = \\'<b>Average annual GMV</b> (Gross Merchandise Value) in GBP\\'\\n)\\n\\nfig.show()\\n\\nDeviation\\n\\nWhat is a use case? It’s the case when we want to highlight the differences between values and baseline (for example, benchmark or forecast).\\n\\nChart recommendations\\n\\nFor the case of comparing metrics for different segments, the best way to convey this idea using visualisations is the combination of bar charts and baseline.\\n\\nWe did such a visualisation in one of my previous articles in our research on topic modelling for hotel reviews. I compared the share of customer reviews mentioning the particular topic for each hotel chain and baseline (average rate across all the comments). I’ve also highlighted segments that are significantly different with colour.\\n\\n\\n\\nAlso, we often have a task to show deviation from the prediction. We can use line plots comparing dynamics for the forecast and the factual data. I prefer to show the forecast as a dotted line to emphasise that it’s not so solid as fact.\\n\\nVisualisation by author\\n\\nThis case of a line chart is a bit more complicated than the ones we discussed above. So, instead of Plotly Express, we will need to use Plotly Graphical Objects to customise the chart.\\n\\nimport plotly.graph_objects as go\\n\\n# creating a figure\\nfig = go.Figure() \\n\\n# adding dashed line trace for forecast\\nfig.add_trace(\\n    go.Scatter(\\n        mode=\\'lines\\',\\n        x=df.index,\\n        y=df.forecast,\\n        line=dict(color=\\'#696969\\', dash=\\'dot\\', width = 3),\\n        showlegend=True,\\n        name = \\'forecast\\'\\n    )\\n)\\n\\n# adding solid line trace for factual data\\nfig.add_trace(\\n    go.Scatter(\\n        mode=\\'lines\\',\\n        x=df.index,\\n        y=df.fact,\\n        marker=dict(size=6, opacity=1, color = \\'navy\\'),\\n        showlegend=True,\\n        name = \\'fact\\'\\n    )\\n)\\n\\n# setting title and size of layout\\nfig.update_layout(\\n  width = 800, \\n  height = 400, \\n  title = \\'<b>Daily Active Users:</b> forecast vs fact\\'\\n)\\n\\n# specifying axis labels\\nfig.update_xaxes(title = \\'day\\')\\nfig.update_yaxes(title = \\'number of users\\')\\n\\nRanking\\n\\nWhat is a use case? This task is similar to the Nominal comparison. We also want to compare metrics across the several segments, but we would like to accentuate the ranking - the order of the segments. For example, it could be the top 3 regions with the highest average annual GMV or the top 3 marketing campaigns with the highest ROI.\\n\\nChart recommendations\\n\\nNo surprise, we can use bar charts similar to the nominal comparison. The only vital nuance to keep in mind is ordering the segments on your chart by the metric you’re interested in. For example, we can visualise the top 3 regions by annual Gross Merchandise Value.\\n\\nVisualisation by author\\n\\nPart-to-whole\\n\\nWhat is use case? The goal is to understand what is the split of total by some subdivisions. You might want to do it for one segment or for several at the same time to compare their structures.\\n\\nChart recommendations\\n\\nThe most straightforward solution would be to use a bar chart to show the share of each category or subdivision. It’s worth ordering your categories in descending order to make visualisation easier to interpret.\\n\\nVisualisation by author\\n\\nThe above approach works both for one or several segments. However, sometimes, it’s easier to compare the structure using a stacked bar chart. For example, we can look at the share of customers by age in different regions.\\n\\nVisualisation by author\\n\\nPie charts are often used in such cases. But I wouldn’t recommend you do it. As we know from visual perception research, comparing angles or areas is more challenging than just lengths. So, bar charts would be preferable.\\n\\nAlso, we might have a task to look at the structure over time. The ideal option would be an area chart. It will show you both split across subdivisions and trends via slopes (that’s why it’s a better option than just a bar chart with months as categories).\\n\\nVisualisation by author\\n\\nTo create an area chart, you can use px.area function in Plotly.\\n\\npx.area(\\n  df, \\n  title = \\'<b>Customer age</b> in Switzerland\\',\\n  labels = {\\'value\\': \\'share of users, %\\', \\n            \\'age_group\\': \\'customer age\\', \\'month\\': \\'month\\'},  \\n  color_discrete_sequence=px.colors.diverging.balance\\n)\\n\\nFrequency distribution\\n\\nWhat is a use case? I usually start with such visualisation when working with new data. The goal is to understand how value is distributed:\\n\\nIs it normally distributed?\\n\\nIs it unimodal?\\n\\nDo we have any outliers in our data?\\n\\nChart recommendations\\n\\nThe first choice for frequency distributions is histograms (vertical bar charts usually without margins between categories). I typically prefer normed histograms since they are easier to interpret than absolute values.\\n\\nIf you want to see frequency distributions for several metrics, you can draw several histograms simultaneously. In this case, it’s crucial to use normed histograms. Otherwise, you won’t be able to compare distributions if the number of objects differs in groups.\\n\\nFor example, we can visualise the distributions of annual GMVs for customers from the United Kingdom and Switzerland.\\n\\nVisualisation by author\\n\\nFor this visualisation, I used matplotlib. I prefer matplotlib to Plotly for histograms because I like their default design.\\n\\nfrom matplotlib import pyplot\\n\\nhist_range = [0, 10000]\\nhist_bins = 100\\n\\npyplot.hist(\\n    distr_df[distr_df.region == \\'United Kingdom\\'].value.values,\\n    label = \\'United Kingdom\\',\\n    alpha = 0.5, range = hist_range, bins = hist_bins,\\n    color = \\'navy\\',\\n    # calculating weights to get normalised histogram\\n    weights = np.ones_like(distr_df[distr_df.region == \\'United Kingdom\\'].index)*100/distr_df[distr_df.region == \\'United Kingdom\\'].shape[0]\\n)\\n\\npyplot.hist(\\n    distr_df[distr_df.region == \\'Switzerland\\'].value.values,\\n    label = \\'Switzerland\\',\\n    color = \\'red\\',\\n    alpha = 0.5, range = hist_range, bins = hist_bins,\\n    weights = np.ones_like(distr_df[distr_df.region == \\'Switzerland\\'].index)*100/distr_df[distr_df.region == \\'Switzerland\\'].shape[0]\\n)\\n\\npyplot.legend(loc = \\'upper right\\')\\npyplot.title(\\'Distribution of customers GMV\\')\\npyplot.xlabel(\\'annual GMV in GBP\\')\\npyplot.ylabel(\\'share of users, %\\')\\npyplot.show()\\n\\nIf you want to compare distributions across many categories, reading many histograms on the same graph would be challenging. So, I would recommend you use box plots. They show less information (only medians, quartiles and outliers) and require some education for the audience. However, in the case of many categories, it might be your best option.\\n\\nFor example, let’s look at the distributions of the time spent on site by region.\\n\\nVisualisation by author\\n\\nIf you don’t remember how to read a box plot, here’s a scheme that gives some clues.\\n\\nImage from Wikipedia (source) | CC BY-SA 2.5 license\\n\\nSo, let’s go through all the building blocks of the box plot visualisation:\\n\\nthe box on the visualisation shows IQR (interquartile range) - 25% and 75% percentiles,\\n\\nthe line in the middle of the box specifies the median (50% percentile),\\n\\nwhiskers equal to 1.5 * IQR or to the min/max value in the dataset if they are less extreme,\\n\\nif you have any numbers more extreme than 1.5 * IQR (outliers), they will be depicted as points on the graph.\\n\\nHere is the code to generate a box plot in Plotly. I used Graphical Objects instead of Plotly Express to eliminate outliers from the visualisation. It comes in handy when you have extreme outliers or too many of them in your dataset.\\n\\nfig = go.Figure()\\n\\nfig.add_trace(go.Box(\\n    y=distr_df[distr_df.region == \\'United Kingdom\\'].value,\\n    name=\"United Kingdom\",\\n    boxpoints=False, # no data points\\n    marker_color=px.colors.qualitative.Prism[0],\\n    line_color=px.colors.qualitative.Prism[0]\\n))\\n\\nfig.add_trace(go.Box(\\n    y=distr_df[distr_df.region == \\'Germany\\'].value,\\n    name=\"Germany\",\\n    boxpoints=False, # no data points\\n    marker_color=px.colors.qualitative.Prism[1],\\n    line_color=px.colors.qualitative.Prism[1]\\n))\\n\\nfig.add_trace(go.Box(\\n    y=distr_df[distr_df.region == \\'France\\'].value,\\n    name=\"France\",\\n    boxpoints=False, # no data points\\n    marker_color=px.colors.qualitative.Prism[2],\\n    line_color=px.colors.qualitative.Prism[2]\\n))\\n\\nfig.add_trace(go.Box(\\n    y=distr_df[distr_df.region == \\'Switzerland\\'].value,\\n    name=\"Switzerland\",\\n    boxpoints=False, # no data points\\n    marker_color=px.colors.qualitative.Prism[3],\\n    line_color=px.colors.qualitative.Prism[3]\\n))\\nfig.update_layout(title = \\'<b>Time spent on site</b> per month\\')\\nfig.update_yaxes(title = \\'time spent in minutes\\')\\nfig.update_xaxes(title = \\'region\\')\\nfig.show()\\n\\nCorrelation\\n\\nWhat is a use case? The goal is to understand the relation between two numeric datasets, whether one value increases with the other one or not.\\n\\nChart recommendations\\n\\nA scatter plot is the best solution to show a correlation between the values. You might also want to add a trend line to highlight the relation between metrics.\\n\\nVisualisation by author\\n\\nIf you have many data points, you might face a problem with a scatter plot: it’s impossible to see the data structure with too many points because they overlay each other. In this case, reducing opacity might help you to reveal the relation.\\n\\nFor example, compare the two graphs below. The second one gives a better understanding of the data distribution.\\n\\nVisualisation by author\\n\\nWe will use Plotly Graphical objects for this graph since it’s pretty custom. To create such a graph, we need to specify two traces - one for the scatter plot and one for the regression line.\\n\\nimport plotly.graph_objects as go\\n\\n# scatter plot\\nfig = go.Figure()\\nfig.add_trace(\\n    go.Scatter(\\n        mode=\\'markers\\',\\n        x=corr_df.x,\\n        y=corr_df.y,\\n        marker=dict(size=6, opacity=0.1, color = \\'grey\\'),\\n        showlegend=False\\n    )\\n)\\n\\n# regression line\\nfig.add_trace(\\n    go.Scatter(\\n        mode=\\'lines\\',\\n        x=linear_corr_df.x,\\n        y=linear_corr_df.linear_regression,\\n        line=dict(color=\\'navy\\', dash=\\'dash\\', width = 3),\\n        showlegend=False\\n    )\\n)\\n\\nfig.update_layout(width = 600, height = 400, \\n    title = \\'<b>Correlation</b> between revenue and customer tenure\\')\\nfig.update_xaxes(title = \\'months since registration\\')\\nfig.update_yaxes(title = \\'monthly revenue, GBP\\')\\n\\nIt’s essential to put the regression line as the second trace because otherwise, it would be overlayed by a scatter plot.\\n\\nAlso, it might be insightful to show frequency distributions for both variables. It doesn’t sound effortless, but you can easily do this using a joint plot from seaborn library. Here’s a code for it.\\n\\nimport seaborn as sns\\n\\nsns.set_theme(style=\"darkgrid\")\\n\\ng = sns.jointplot(\\n  x=\"x\", y=\"y\", data=corr_df,\\n  kind=\"reg\", truncate=False, \\n  joint_kws = {\\'scatter_kws\\':dict(alpha=0.15), \\'line_kws\\':{\\'color\\':\\'navy\\'}},\\n  color=\"royalblue\", height=7)\\n\\ng.set_axis_labels(\\'months since registration\\', \\'monthly revenue, GBP\\')\\n\\nVisualisation by author\\n\\nWe’ve covered all the use cases for data visualisations.\\n\\nIs it all the visualisation types I need to know?\\n\\nI must confess that from time to time, I face tasks when the above suggestions are not enough, and I need some other graphs.\\n\\nHere are some examples:\\n\\nSankey diagrams or sunburst charts for customer journey maps,\\n\\nChoropleth for data when you need to show geographical data,\\n\\nWord clouds to give a very high-level view of texts,\\n\\nSparklines if you want to see trends for multiple lines.\\n\\nFor inspiration, I usually use the galleries of popular visualisation libraries, for example, Plotly or seaborn.\\n\\nAlso, you can always ask ChatGPT about the possible options to present your data. It provides quite a reasonable guidance.\\n\\nScreenshot by author\\n\\nSummary\\n\\nIn this article, we’ve discussed the basics of data visualisations:\\n\\nWhy do we need to visualise data?\\n\\nWhat questions should you ask yourself before you start working on visualisation?\\n\\nWhat are the basic building blocks, and which ones are the easiest for the audience to perceive?\\n\\nWhat are the common use cases for data visualisation, and what chart types you can use to address them?\\n\\nI hope the provided framework will help you not to be stuck by a variety of options and create better visualisations for your audience.\\n\\nThank you a lot for reading this article. If you have any follow-up questions or comments, please leave them in the comments section.'}},\n",
       "  {'id': '9d42488dc327',\n",
       "   'title': 'Can LLMs Replace Data Analysts? Learning to Collaborate',\n",
       "   'subtitle': 'Part 3: Teaching the LLM agent to pose and address clarifying questions',\n",
       "   'author': '15a29a4fc6ad',\n",
       "   'publication_id': '7f60cf5620c9',\n",
       "   'published_at': '2024-01-09 13:19:56',\n",
       "   'last_modified_at': '2024-01-09 13:19:56',\n",
       "   'tags': ['llm',\n",
       "    'data-science',\n",
       "    'artificial-intelligence',\n",
       "    'deep-dives',\n",
       "    'editors-pick'],\n",
       "   'topics': ['artificial-intelligence',\n",
       "    'machine-learning',\n",
       "    'data-science',\n",
       "    'programming'],\n",
       "   'claps': 669,\n",
       "   'voters': 79,\n",
       "   'word_count': 5002,\n",
       "   'responses_count': 8,\n",
       "   'reading_time': 19.57547169811321,\n",
       "   'url': 'https://towardsdatascience.com/can-llms-replace-data-analysts-learning-to-collaborate-9d42488dc327',\n",
       "   'unique_slug': 'can-llms-replace-data-analysts-learning-to-collaborate-9d42488dc327',\n",
       "   'image_url': 'https://miro.medium.com/1*wUDorQvoHBbMLqPFvvVorw.jpeg',\n",
       "   'lang': 'en',\n",
       "   'is_series': False,\n",
       "   'is_locked': False,\n",
       "   'is_shortform': False,\n",
       "   'top_highlight': \"So, for an LLM-powered analyst, mastering the art of posing and addressing follow-up questions is essential since I can't imagine an analyst working in isolation.\",\n",
       "   'content': {'id': '9d42488dc327',\n",
       "    'content': 'Can LLMs Replace Data Analysts? Learning to Collaborate\\n\\nPart 3: Teaching the LLM agent to pose and address clarifying questions\\n\\nImage by DALL-E 3\\n\\nCollaboration is a core aspect of analysts’ day-to-day jobs. Frequently, we encounter high-level requests such as, \"What will be the impact of the new feature?\" or \"What is going on with retention?\". Before jumping to writing queries and pulling data, we usually need to define tasks more clearly: talk to stakeholders, understand their needs thoroughly, and determine how we can provide the best assistance.\\n\\nSo, for an LLM-powered analyst, mastering the art of posing and addressing follow-up questions is essential since I can’t imagine an analyst working in isolation.\\n\\nIn this article, we will teach our LLM analyst to ask clarifying questions and follow long conversations. We will talk in detail about different memory implementations in LangChain.\\n\\nWe’ve already discussed many aspects of LLM agents in the previous articles. So, let me quickly summarise them. Also, since our last implementation, LangChain has been updated, and it’s time to catch up.\\n\\nLLM agents recap\\n\\nLet’s quickly recap what we’ve already learned about LLM agents.\\n\\nWe’ve discussed how to empower LLMs with external tools. It helps them overcome limitations (i.e., poor performance on maths tasks) and get access to the world (i.e., your database or internet).\\n\\nThe core idea of the LLM agents is to use LLM as a reasoning engine to define the set of actions to take and leverage tools. So, in this approach, you don’t need to hardcode the logic and just let LLM make decisions on the following steps to achieve the final goal.\\n\\nWe’ve implemented an LLM-powered agent that can work with SQL databases and answer user requests.\\n\\nSince our last iteration, LangChain has been updated from 0.0.350 to 0.1.0 version. The documentation and best practices for LLM agents have changed. This domain is developing quickly, so it’s no surprise the tools are evolving, too. Let’s quickly recap.\\n\\nFirst, LangChain has significantly improved the documentation, and now you can find a clear, structured view of the supported agent types and the differences between them.\\n\\nIt’s easier for models to work with tools with just one input parameter, so some agents have such limitations. However, in most real-life cases, tools have several arguments. So, let’s focus on the agents capable of working with multiple inputs. It leaves us just three possible options.\\n\\nOpenAI tools\\n\\nIt’s the most cutting-edge type of agent since it supports chat history, tools with multiple inputs and even parallel function calling.\\n\\nYou can use it with the recent OpenAI models (after 1106) since they were fine-tuned for tool calling.\\n\\n2. OpenAI functions\\n\\nOpenAI functions agents are close to OpenAI tools but are slightly different under the hood.\\n\\nSuch agents don’t support parallel function calling.\\n\\nYou can use recent OpenAI models that were fine-tuned to work with functions (the complete list is here) or compatible open-source LLMs.\\n\\n3. Structured chat\\n\\nThis approach is similar to ReAct. It instructs an agent to follow the Thought -> Action -> Observation framework.\\n\\nIt doesn’t support parallel function calling, just as OpenAI functions approach.\\n\\nYou can use it with any model.\\n\\nAlso, you can notice that the experimental agent types we tried in the previous article, such as BabyAGI, Plan-and-execute and AutoGPT, are still not part of the suggested options. They might be included later (I hope), but for now I wouldn’t recommend using them in production.\\n\\nAfter reading the new documentation, I’ve finally realised the difference between OpenAI tools and OpenAI functions agents. With the OpenAI tools approach, an agent can call multiple tools at the same iterations, while other agent types don’t support such functionality. Let’s see how it works and why it matters.\\n\\nLet’s create two agents - OpenAI tools and OpenAI functions. We will empower them with two tools:\\n\\nget_monthly_active_users returns the number of active customers for city and month. To simplify debugging, we will be using a dummy function for it. In practice, we would go to our database to retrieve this data.\\n\\npercentage_difference calculates the difference between two metrics.\\n\\nLet’s create tools from Python functions and specify schemas using Pydantic. If you want to recap this topic, you can find a detailed explanation in the first article of this series.\\n\\nfrom pydantic import BaseModel, Field\\nfrom typing import Optional\\nfrom langchain.agents import tool\\n\\n# define tools\\n\\nclass Filters(BaseModel):\\n    month: str = Field(description=\"Month of the customer\\'s activity in the format %Y-%m-%d\")\\n    city: Optional[str] = Field(description=\"The city of residence for customers (by default no filter)\", \\n                    enum = [\"London\", \"Berlin\", \"Amsterdam\", \"Paris\"])\\n\\n@tool(args_schema=Filters)\\ndef get_monthly_active_users(month: str, city: str = None) -> int:\\n    \"\"\"Returns the number of active customers for the specified month. \\n    Pass month in format %Y-%m-01.\\n    \"\"\"\\n\\n    coefs = {\\n        \\'London\\': 2,\\n        \\'Berlin\\': 1,\\n        \\'Amsterdam\\': 0.5,\\n        \\'Paris\\': 0.25\\n    }\\n    \\n    dt = datetime.datetime.strptime(month, \\'%Y-%m-%d\\')\\n    total = dt.year + 10*dt.month\\n    \\n    if city is None:\\n        return total\\n    else:\\n        return int(round(coefs[city]*total))\\n        \\nclass Metrics(BaseModel):\\n    metric1: float = Field(description=\"Base metric value to calculate the difference\")\\n    metric2: float = Field(description=\"New metric value that we compare with the baseline\")\\n\\n@tool(args_schema=Metrics)\\ndef percentage_difference(metric1: float, metric2: float) -> float:\\n    \"\"\"Calculates the percentage difference between metrics\"\"\"\\n    return (metric2 - metric1)/metric1*100\\n\\n# save them into a list for future use\\n\\ntools = [get_monthly_active_users, percentage_difference]\\n\\nTo test a tool, you can execute it using the following commands.\\n\\nget_monthly_active_users.run({\"month\": \"2023-12-01\", \"city\": \"London\"})\\n# 4286\\n\\nget_monthly_active_users.run({\"month\": \"2023-12-01\", \"city\": \"Berlin\"})\\n# 2183\\n\\nLet’s create a prompt template that we will be using for the agents. It will consist of a system message, a user request and a placeholder for tools’ observations. Our prompt has two variables - input and agent_scratchpad.\\n\\nfrom langchain.prompts import ChatPromptTemplate, MessagesPlaceholder\\n\\n# defining prompt\\n\\nsystem_message = \\'\\'\\'\\nYou are working as a product analyst for a e-commerce company. \\nYour work is very important, since your product team makes decisions based on the data you provide. So, you are extremely accurate with the numbers you provided. \\nIf you\\'re not sure about the details of the request, you don\\'t provide the answer and ask follow-up questions to have a clear understanding.\\nYou are very helpful and try your best to answer the questions.\\n\\'\\'\\'\\n\\nprompt = ChatPromptTemplate.from_messages([\\n    (\"system\", system_message),\\n    (\"user\", \"{input}\"),\\n    MessagesPlaceholder(variable_name=\"agent_scratchpad\")\\n])\\n\\nLet’s use new LangChain functions to create agents - create_openai_functions_agent and create_openai_tools_agent. To create an agent, we need to specify parameters - an LLM model, a list of tools and a prompt template. On top of the agents, we also need to create agent executors.\\n\\n\\nfrom langchain.agents import create_openai_tools_agent, create_openai_functions_agent, AgentExecutor\\nfrom langchain_community.chat_models import ChatOpenAI\\n\\n# OpenAI tools agent\\nagent_tools = create_openai_tools_agent(\\n    llm = ChatOpenAI(temperature=0.1, model = \\'gpt-4-1106-preview\\'),\\n    tools = tools, \\n    prompt = prompt\\n)\\n\\nagent_tools_executor = AgentExecutor(\\n    agent = agent_tools, tools = tools, \\n    verbose = True, max_iterations = 10, \\n    early_stopping_method = \\'generate\\')\\n\\n# OpenAI functions agent\\nagent_funcs = create_openai_functions_agent(\\n    llm = ChatOpenAI(temperature=0.1, model = \\'gpt-4-1106-preview\\'),\\n    tools = tools, \\n    prompt = prompt\\n)\\n\\nagent_funcs_executor = AgentExecutor(\\n    agent = agent_funcs, tools = tools, \\n    verbose = True, max_iterations = 10, \\n    early_stopping_method = \\'generate\\')\\n\\nI used the ChatGPT 4 Turbo model since it’s capable of working with OpenAI tools. We will need some complex reasoning, thus ChatGPT 3.5 will likely be insufficient in our use case.\\n\\nWe’ve created two agent executors, and it’s time to try them in practice and compare results.\\n\\nuser_question = \\'What are the absolute numbers and the percentage difference between the number of customers in London and Berlin in December 2023?\\'\\n\\nagent_funcs_executor.invoke(\\n    {\\'input\\': user_question, \\n     \\'agent_scratchpad\\': []})\\n\\n\\nagent_tools_executor.invoke(\\n    {\\'input\\': user_question, \\n     \\'agent_scratchpad\\': []})\\n\\n# In December 2023, the number of customers in London was 4,286, and in Berlin,\\n# it was 2,143. The percentage difference between the number of customers \\n# in London and Berlin is -50.0%, indicating that London had twice \\n# as many customers as Berlin.\\n\\nInterestingly, the agents returned the same correct result. It’s not so surprising since we used low temperatures.\\n\\nBoth agents performed well, but let’s compare how they work under the hood. We can switch on debug mode (execute langchain.debug = True for it) and see the number of LLM calls and tokens used.\\n\\nYou can see the scheme depicting the calls for two agents below.\\n\\nScheme by author\\n\\nThe OpenAI functions agent did 4 LLM calls, while the OpenAI tools agent made just 3 ones because it could get MAUs for London and Berlin in one iteration. Overall, it leads to a lower number of used tokens and, hence, lower price:\\n\\nOpenAI tools agent - 1 537 tokens\\n\\nOpenAI functions agent - 1 874 tokens (+21.9%).\\n\\nSo, I would recommend you consider using OpenAI tools agents. You can use it with both ChatGPT 4 Turbo and ChatGPT 3.5 Turbo.\\n\\nWe’ve revised our previous implementation of an LLM-powered analyst. So, it’s time to move on and teach our agent to pose follow-up questions.\\n\\nAsking clarifying questions\\n\\nWe would like to teach our agent to ask the user clarifying questions. The most reasonable way to teach LLM agents something new is to give them a tool. So, LangChain has a handy tool - Human.\\n\\nThere’s no rocket science in it. You can see the implementation here. We can easily implement it ourselves, but it’s a good practice to use tools provided by the framework.\\n\\nLet’s initiate such a tool. We don’t need to specify any arguments unless we want to customise something, for example, a tool’s description or input function. See more details in the documentation.\\n\\nfrom langchain.tools import HumanInputRun\\nhuman_tool = HumanInputRun()\\n\\nWe can look at the default tool’s description and arguments.\\n\\nprint(human_tool.description)\\n# You can ask a human for guidance when you think you got stuck or \\n# you are not sure what to do next. The input should be a question \\n# for the human. \\n\\nprint(human_tool.args)\\n# {\\'query\\': {\\'title\\': \\'Query\\', \\'type\\': \\'string\\'}}\\n\\nLet’s add this new tool to our agent’s toolkit and reinitialise the agent. I’ve also tweaked the system message to encourage the model to ask follow-up questions when it doesn’t have enough details.\\n\\n# tweaking the system message\\nsystem_message = \\'\\'\\'\\nYou are working as a product analyst for the e-commerce company. \\nYour work is very important, since your product team makes decisions based on the data you provide. So, you are extremely accurate with the numbers you provided. \\nIf you\\'re not sure about the details of the request, you don\\'t provide the answer and ask follow-up questions to have a clear understanding.\\nYou are very helpful and try your best to answer the questions.\\n\\nIf you don\\'t have enough context to answer question, you should ask user the follow-up question to get needed info. \\nYou don\\'t make any assumptions about data requests. For example, if dates are not specified, you ask follow up questions. \\nAlways use tool if you have follow-up questions to the request.\\n\\'\\'\\'\\nprompt = ChatPromptTemplate.from_messages([\\n    (\"system\", system_message),\\n    (\"user\", \"{input}\"),\\n    MessagesPlaceholder(variable_name=\"agent_scratchpad\")\\n])\\n\\n# updated list of tools \\ntools = [get_monthly_active_users, percentage_difference, human_tool]\\n\\n# reinitialising the agent\\nhuman_input_agent = create_openai_tools_agent(\\n    llm = ChatOpenAI(temperature=0.1, model = \\'gpt-4-1106-preview\\'),\\n    tools = tools, \\n    prompt = prompt\\n)\\n\\nhuman_input_agent_executor = AgentExecutor(\\n    agent = human_input_agent, tools = tools, \\n    verbose = True, max_iterations = 10, # early stopping criteria\\n    early_stopping_method = \\'generate\\')\\n\\nNow, it’s time to try it out. The agent just returned the output, asking for a specific time period. It doesn’t work as we expected.\\n\\nhuman_input_agent_executor.invoke(\\n    {\\'input\\': \\'What are the number of customers in London?\\', \\n     \\'agent_scratchpad\\': []})\\n\\n# {\\'input\\': \\'What are the number of customers in London?\\',\\n#  \\'agent_scratchpad\\': [],\\n#  \\'output\\': \\'To provide you with the number of customers in London, \\n#             I need to know the specific time period you are interested in. \\n#             Are you looking for the number of monthly active users in London \\n#             for a particular month, or do you need a different metric? \\n#             Please provide the time frame or specify the metric you need.\\'}\\n\\nThe agent didn’t understand that it needed to use this tool. Let’s try to fix it and change the Human tool’s description so that it is more evident for the agent when it should use this tool.\\n\\nhuman_tool_desc = \\'\\'\\'\\nYou can use this tool to ask the user for the details related to the request. \\nAlways use this tool if you have follow-up questions. \\nThe input should be a question for the user. \\nBe concise, polite and professional when asking the questions.\\n\\'\\'\\'\\n\\nhuman_tool = HumanInputRun(\\n    description = human_tool_desc\\n)\\n\\nAfter the change, the agent used the Human tool and asked for a specific time period. I provided an answer, and we got the correct result - 4 286 active customers in December 2023 for London.\\n\\nScreenshot by author\\n\\nSo, as usual, tweaking the prompt helps. Now, it works pretty well. Remember that creating a good prompt is an iterative process, and it’s worth trying several options and evaluating results.\\n\\nWe’ve taught our LLM agent to ask for details and take them into account while working on data requests.\\n\\nHowever, it’s only part of the collaboration. In real life, analysts often get follow-up questions after providing any research. Now, our agent can’t keep up the conversation and address the new questions from the user since it doesn’t have any memory. It’s time to learn more about the tools we have to implement memory in LangChain.\\n\\nActually, we already have a concept of memory in the current agent implementation. Our agent stores the story of its interactions with tools in the agent_scratchpad variable. We need to remember not only interactions with tools but also the conversation with the user.\\n\\nMemory in LangChain\\n\\nBy default, LLMs are stateless and don’t remember previous conversations. If we want our agent to be able to have long discussions, we need to store the chat history somehow. LangChain provides a bunch of different memory implementations. Let’s learn more about it.\\n\\nConversationBufferMemory is the most straightforward approach. It just saves all the context you pushed to it. Let’s try it out: initialise a memory object and add a couple of conversation exchanges.\\n\\nfrom langchain.memory import ConversationBufferMemory\\nmemory = ConversationBufferMemory()\\nmemory.save_context(\\n    {\"input\": \"Hey, how are you? How was your weekend?\"}, \\n    {\"output\": \"Good morning, I had a wonderful time off and spent the whole day learning about LLM agents. It works like magic.\"}\\n)\\nprint(memory.buffer)\\n\\n# Human: Hey, how are you? How was your weekend?\\n# AI: Good morning, I had a wonderful time off and spent the whole day learning about LLM agents. It works like magic.\\n\\nmemory.save_context(\\n    {\"input\": \"Could you please help me with the urgent request from our CEO. What are the absolute numbers and the percentage difference between the number of customers in London and Berlin in December 2023?\"}, \\n    {\"output\": \"In December 2023, the number of customers in London was 4,286, and in Berlin, it was 2,143. The percentage difference between the number of customers in London and Berlin is -50.0%, indicating that London had twice as many customers as Berlin.\"}\\n)\\nprint(memory.buffer)\\n\\n# Human: Hey, how are you? How was your weekend?\\n# AI: Good morning, I had a wonderful time off and spent the whole day learning about LLM agents. It works like magic.\\n# Human: Could you please help me with the urgent request from our CEO. What are the absolute numbers and the percentage difference between the number of customers in London and Berlin in December 2023?\\n# AI: In December 2023, the number of customers in London was 4,286, and in Berlin, it was 2,143. The percentage difference between the number of customers in London and Berlin is -50.0%, indicating that London had twice as many customers as Berlin.\\n\\nThis approach works well. However, in many cases, it’s not feasible to pass the whole previous conversation to LLM on each iteration because:\\n\\nwe might hit the context length limit,\\n\\nLLMs are not so good at dealing with long texts,\\n\\nwe are paying for tokens, and such an approach might become quite expensive.\\n\\nSo there’s another implementation, ConversationBufferWindowMemory, that can store a limited number of conversation exchanges. So, it will store only the last k iterations.\\n\\nfrom langchain.memory import ConversationBufferWindowMemory\\n\\nmemory = ConversationBufferWindowMemory(k = 1) \\n\\nmemory.save_context(\\n    {\"input\": \"Hey, how are you? How was your weekend?\"}, \\n    {\"output\": \"Good morning, I had a wonderful time off and spent the whole day learning about LLM agents. It works like magic.\"}\\n)\\nprint(memory.buffer)\\n\\n# Human: Hey, how are you? How was your weekend?\\n# AI: Good morning, I had a wonderful time off and spent the whole day learning about LLM agents. It works like magic.\\n\\nmemory.save_context(\\n    {\"input\": \"Could you please help me with the urgent request from our CEO. What are the absolute numbers and the percentage difference between the number of customers in London and Berlin in December 2023?\"}, \\n    {\"output\": \"In December 2023, the number of customers in London was 4,286, and in Berlin, it was 2,143. The percentage difference between the number of customers in London and Berlin is -50.0%, indicating that London had twice as many customers as Berlin.\"}\\n)\\nprint(memory.buffer)\\n\\n# Human: Could you please help me with the urgent request from our CEO. What are the absolute numbers and the percentage difference between the number of customers in London and Berlin in December 2023?\\n# AI: In December 2023, the number of customers in London was 4,286, and in Berlin, it was 2,143. The percentage difference between the number of customers in London and Berlin is -50.0%, indicating that London had twice as many customers as Berlin.\\n\\nWe’ve used k = 1 just to show how it works. In real-life use cases, you will likely use much higher thresholds.\\n\\nThis approach can help you to keep chat history size manageable. However, it has a drawback: you can still hit the context size limit since you don’t control the chat history size in tokens.\\n\\nTo address this challenge, we can use ConversationTokenBufferMemory. It won’t split statements, so don’t worry about incomplete sentences in the context.\\n\\nfrom langchain.memory import ConversationTokenBufferMemory\\n\\nmemory = ConversationTokenBufferMemory(\\n    llm = ChatOpenAI(temperature=0.1, model = \\'gpt-4-1106-preview\\'), \\n    max_token_limit=100)\\n\\nmemory.save_context(\\n    {\"input\": \"Hey, how are you? How was your weekend?\"}, \\n    {\"output\": \"Good morning, I had a wonderful time off and spent the whole day learning about LLM agents. It works like magic.\"}\\n)\\nprint(memory.buffer)\\n\\n# Human: Hey, how are you? How was your weekend?\\n# AI: Good morning, I had a wonderful time off and spent the whole day learning about LLM agents. It works like magic.\\n\\n# <Comment from the author>: the whole info since it fits the memory size \\n\\nmemory.save_context(\\n    {\"input\": \"Could you please help me with the urgent request from our CEO. What are the absolute numbers and the percentage difference between the number of customers in London and Berlin in December 2023?\"}, \\n    {\"output\": \"In December 2023, the number of customers in London was 4,286, and in Berlin, it was 2,143. The percentage difference between the number of customers in London and Berlin is -50.0%, indicating that London had twice as many customers as Berlin.\"}\\n)\\nprint(memory.buffer)\\n\\n# AI: In December 2023, the number of customers in London was 4,286, and in Berlin, it was 2,143. The percentage difference between the number of customers in London and Berlin is -50.0%, indicating that London had twice as many customers as Berlin.\\n\\n# <Comment from the author>: only the last response from the LLM fit the memory size \\n\\nIn this case, we need to pass an LLM model to initialise a memory object because LangChain needs to know the model to calculate the number of tokens.\\n\\nIn all approaches we’ve discussed above, we stored the exact conversation or at least parts of it. However, we don’t need to do it. For example, people usually don’t remember their conversations exactly. I can’t reproduce yesterday’s meeting’s content word by word, but I remember the main ideas and action items - a summary. Since humans are GI (General Intelligence), it sounds reasonable to leverage this strategy for LLMs as well. LangChain implemented it in ConversationSummaryBufferMemory.\\n\\nLet’s try it in practice: initiate the memory and save the first conversation exchange. We got the whole conversation since our current context hasn’t hit the threshold.\\n\\nfrom langchain.memory import ConversationSummaryBufferMemory\\n\\nmemory = ConversationSummaryBufferMemory(\\n    llm = ChatOpenAI(temperature=0.1, model = \\'gpt-4-1106-preview\\'), \\n    max_token_limit=100)\\n\\nmemory.save_context(\\n    {\"input\": \"Hey, how are you? How was your weekend?\"}, \\n    {\"output\": \"Good morning, I had a wonderful time off and spent the whole day learning about LLM agents. It works like magic.\"}\\n)\\nprint(memory.load_memory_variables({})[\\'history\\'])\\n\\n# Human: Hey, how are you? How was your weekend?\\n# AI: Good morning, I had a wonderful time off and spent the whole day learning about LLM agents. It works like magic.\\n\\nLet’s add one more conversation exchange. Now, we’ve hit the limit: the whole chat history exceeds 100 tokens, the specified threshold. So, only the last AI response is stored (it’s within the 100 tokens limit). For earlier messages, the summary has been generated.\\n\\nThe summary is stored with the prefix System: .\\n\\n\\nmemory.save_context(\\n    {\"input\": \"Could you please help me with the urgent request from our CEO. What are the absolute numbers and the percentage difference between the number of customers in London and Berlin in December 2023?\"}, \\n    {\"output\": \"In December 2023, the number of customers in London was 4,286, and in Berlin, it was 2,143. The percentage difference between the number of customers in London and Berlin is -50.0%, indicating that London had twice as many customers as Berlin.\"}\\n)\\nprint(memory.load_memory_variables({})[\\'history\\'])\\n\\n# System: The AI had a good weekend learning about LLM agents and describes it as magical. The human requests assistance with an urgent task from the CEO, asking for the absolute numbers and percentage difference of customers in London and Berlin in December 2023.\\n# AI: In December 2023, the number of customers in London was 4,286, and in Berlin, it was 2,143. The percentage difference between the number of customers in London and Berlin is -50.0%, indicating that London had twice as many customers as Berlin.\\n\\nAs usual, it’s interesting to see how it works under the hood, and we can understand it in a debug mode. When the conversation exceeded the limit on the memory size, the LLM call was made with the following prompt:\\n\\nHuman: Progressively summarize the lines of conversation provided, \\nadding onto the previous summary returning a new summary.\\n\\nEXAMPLE\\nCurrent summary:\\nThe human asks what the AI thinks of artificial intelligence. The AI \\nthinks artificial intelligence is a force for good.\\n\\nNew lines of conversation:\\nHuman: Why do you think artificial intelligence is a force for good?\\nAI: Because artificial intelligence will help humans reach their full \\npotential.\\n\\nNew summary:\\nThe human asks what the AI thinks of artificial intelligence. The AI thinks \\nartificial intelligence is a force for good because it will help humans reach \\ntheir full potential.\\nEND OF EXAMPLE\\n\\nCurrent summary:\\n\\n\\nNew lines of conversation:\\nHuman: Hey, how are you? How was your weekend?\\nAI: Good morning, I had a wonder time off and spent the whole day learning \\nabout LLM agents. It works like magic.\\nHuman: Could you please help me with the urgent request from our CEO. \\nWhat are the absolute numbers and the percentage difference between \\nthe number of customers in London and Berlin in December 2023?\\n\\nNew summary:\\n\\nIt implements the progressive update of the summary. So, it uses fewer tokens, not passing the whole chat history every time to get an updated summary. That’s reasonable.\\n\\nAlso, LangChain has more advanced memory types:\\n\\nVector data memory - storing texts’ embeddings in vector stores (similar to what we did in RAG - Retrieval Augmented Generation), then we could retrieve the most relevant bits of information and include them into the conversation. This memory type would be the most useful for long-term conversations.\\n\\nEntity memories to remember details about specific entities (i.e. people).\\n\\nYou can even combine different memory types. For example, you can use conversation memory + entity memory to keep details about the tables in the database. To learn more about combined memory, consult the documentation.\\n\\nWe won’t discuss these more advanced approaches in this article.\\n\\nWe’ve got an understanding of how we can implement memory in LangChain. Now, it’s time to use this knowledge for our agent.\\n\\nAdding memory to the agent\\n\\nLet’s try to see how the current agent implementation works with the follow-up questions from the user.\\n\\nhuman_input_agent_executor.invoke(\\n    {\\'input\\': \\'What are the number of customers in London in December 2023?\\', \\n     \\'agent_scratchpad\\': []})\\n\\nFor this call, the agent executed a tool and returned the correct answer: The number of active customers in London in December 2023 was 4,286.\\n\\nWe know the number of users for London. It would be interesting to learn about Berlin as well. Let’s ask our agent.\\n\\nhuman_input_agent_executor.invoke(\\n    {\\'input\\': \\'And what about Berlin?\\', \\n     \\'agent_scratchpad\\': []})\\n\\nSurprisingly, the agent was able to handle this question correctly. However, it had to clarify the questions using the Human tool, and the user had to provide the same information (not the best customer experience).\\n\\nScreenshot by author\\n\\nNow, let’s start holding the chart history for the agent. I will use a simple buffer that stores the complete previous conversation, but you could use a more complex strategy.\\n\\nFirst, we need to add a placeholder for the chat history to the prompt template. I’ve marked it as optional.\\n\\nprompt = ChatPromptTemplate.from_messages([\\n    (\"system\", system_message),\\n    MessagesPlaceholder(variable_name=\"chat_history\", optional=True),\\n    (\"user\", \"{input}\"),\\n    MessagesPlaceholder(variable_name=\"agent_scratchpad\")\\n])\\n\\nNext, let’s initialise a memory and save a small talk (it’s impossible to have a chat without a small talk, you know). Note that we’ve specified the same memory_key = \\'chat_history’ as in the prompt template.\\n\\nmemory = ConversationBufferMemory(\\n    return_messages=True, memory_key=\"chat_history\")\\n\\nmemory.save_context(\\n    {\"input\": \"Hey, how are you? How was your weekend?\"}, \\n    {\"output\": \"Good morning, I had a wonderful time off and spent the whole day learning about LLM agents. It works like magic.\"}\\n)\\nprint(memory.buffer)\\n\\nLet’s try the previous use case once again and ask the LLM analyst about the number of users in London.\\n\\nhuman_input_agent_executor.invoke(\\n    {\\'input\\': \\'What is the number of customers in London?\\'})\\n\\n# {\\'input\\': \\'What is the number of customers in London?\\',\\n# \\'chat_history\\': [\\n#   HumanMessage(content=\\'Hey, how are you? How was your weekend?\\'),\\n#   AIMessage(content=\\'Good morning, I had a wonderful time off and spent the whole day learning about LLM agents. It works like magic.\\'),\\n#   HumanMessage(content=\\'What is the number of customers in London?\\'),\\n#   AIMessage(content=\\'The number of active customers in London for December 2023 is 4,286.\\')],\\n# \\'output\\': \\'The number of active customers in London for December 2023 is 4,286.\\'}\\n\\nAfter answering the question, \"Could you please specify the time period for which you would like to know the number of customers in London?\", we got the correct answer and the conversation history between the agent and the user with all the previous statements, including the small talk.\\n\\nIf we ask the follow-up question about Berlin now, the agent will just return the number for December 2023 without asking for details because it already has it in the context.\\n\\nhuman_input_agent_executor.invoke(\\n    {\\'input\\': \\'What is the number for Berlin?\\'})\\n\\n# {\\'input\\': \\'What is the number for Berlin?\\',\\n#  \\'chat_history\\': [HumanMessage(content=\\'Hey, how are you? How was your weekend?\\'),\\n#    AIMessage(content=\\'Good morning, I had a wonderful time off and spent the whole day learning about LLM agents. It works like magic.\\'),\\n#    HumanMessage(content=\\'What is the number of customers in London?\\'),\\n#    AIMessage(content=\\'The number of active customers in London for December 2023 is 4,286.\\'),\\n#    HumanMessage(content=\\'What is the number for Berlin?\\'),\\n#    AIMessage(content=\\'The number of active customers in Berlin for December 2023 is 2,143.\\')],\\n#  \\'output\\': \\'The number of active customers in Berlin for December 2023 is 2,143.\\'}\\n\\nLet’s look at the prompt for the first LLM call. We can see that all chat history was actually passed to the model.\\n\\nSystem: \\nYou are working as a product analyst for the e-commerce company. \\nYour work is very important, since your product team makes decisions \\nbased on the data you provide. So, you are extremely accurate \\nwith the numbers you provided. \\nIf you\\'re not sure about the details of the request, you don\\'t provide \\nthe answer and ask follow-up questions to have a clear understanding.\\nYou are very helpful and try your best to answer the questions.\\n\\nIf you don\\'t have enough context to answer question, you should ask user \\nthe follow-up question to get needed info. \\nYou don\\'t make any assumptions about data requests. For example, \\nif dates are not specified, you ask follow up questions. \\nAlways use tool if you have follow-up questions to the request.\\n\\nHuman: Hey, how are you? How was your weekend?\\nAI: Good morning, I had a wonderful time off and spent the whole day \\nlearning about LLM agents. It works like magic.\\nHuman: What is the number of customers in London?\\nAI: The number of active customers in London for December 2023 is 4,286.\\nHuman: What is the number for Berlin?\\n\\nSo, we’ve added the chat history to our LLM-powered analyst, and now it can handle somewhat long conversations and answer follow-up questions. That’s a significant achievement.\\n\\nYou can find the complete code on GitHub.\\n\\nSummary\\n\\nIn this article, we’ve taught our LLM-powered analyst how to collaborate with users. Now, it can ask clarifying questions if there’s not enough information in the initial request and even answer the follow-up question from the user.\\n\\nWe’ve achieved such a significant improvement:\\n\\nby adding a tool - Human input that allows to ask the user,\\n\\nby adding a memory to the agent that can store the chat history.\\n\\nOur agent has mastered collaboration now. In one of the following articles, we will try to take the next step and combine LLM agents with RAG (Retrieval Augmented Generation). We’ve understood how to query databases and communicate with the users. The next step is to start using knowledge bases. Stay tuned!\\n\\nThank you a lot for reading this article. I hope it was insightful to you. If you have any follow-up questions or comments, please leave them in the comments section.'}},\n",
       "  {'id': '8cf7da132259',\n",
       "   'title': 'Can LLMs Replace Data Analysts? Getting Answers Using SQL',\n",
       "   'subtitle': 'Part 2: Diving deeper into LLM agents',\n",
       "   'author': '15a29a4fc6ad',\n",
       "   'publication_id': '7f60cf5620c9',\n",
       "   'published_at': '2023-12-22 16:01:00',\n",
       "   'last_modified_at': '2023-12-22 16:01:00',\n",
       "   'tags': ['llm',\n",
       "    'data-science',\n",
       "    'artificial-intelligence',\n",
       "    'agents',\n",
       "    'editors-pick'],\n",
       "   'topics': ['artificial-intelligence', 'machine-learning', 'data-science'],\n",
       "   'claps': 823,\n",
       "   'voters': 239,\n",
       "   'word_count': 7816,\n",
       "   'responses_count': 11,\n",
       "   'reading_time': 30.444339622641508,\n",
       "   'url': 'https://towardsdatascience.com/can-llms-replace-data-analysts-getting-answers-using-sql-8cf7da132259',\n",
       "   'unique_slug': 'can-llms-replace-data-analysts-getting-answers-using-sql-8cf7da132259',\n",
       "   'image_url': 'https://miro.medium.com/1*o5J_rJVXP2J4NhBheT0IlQ.png',\n",
       "   'lang': 'en',\n",
       "   'is_series': False,\n",
       "   'is_locked': False,\n",
       "   'is_shortform': False,\n",
       "   'top_highlight': 'The core idea of the LLM agents is to use LLM as a reasoning engine to define the set of actions to take. In the classic approach, we hardcode a sequence of actions, but with agents, we give the model tools and tasks and let her decide how to achieve them.',\n",
       "   'content': {'id': '8cf7da132259',\n",
       "    'content': 'Can LLMs Replace Data Analysts? Getting Answers Using SQL\\n\\nPart 2: Diving deeper into LLM agents\\n\\nImage by DALL-E 3\\n\\nIn the previous article, we’ve started building an LLM-powered analyst. We decided to focus on descriptive analytics and reporting tasks since they are the most common for analysts. Most analysts start their careers with such tasks, and most companies start building the analytical function with reporting and BI tools.\\n\\nOur first prototype can use ready-made tools to answer questions related to the defined metrics, like in the example below.\\n\\nIllustration by author\\n\\nThe next step would be to teach our LLM-powered analyst to get any metrics. Analysts usually use SQL to get data. So, the most helpful skill for the LLM analyst would be interacting with SQL databases.\\n\\nWe’ve already discussed OpenAI functions and learned how LLMs can use tools to integrate with the world. In this article, I would like to focus on LLM agents and discuss them in more detail. We will learn how to build agents using LangChain and try different agent types.\\n\\nSetting up a database\\n\\nFirst, let’s set up a database we will be interacting with. My choice is ClickHouse. ClickHouse is an open-source column-oriented SQL database management system for online analytical processing (OLAP). It’s a good option for big data and analytical tasks.\\n\\nIf you want to learn more about ClickHouse, please check my article. However, you can use any database. You will need just to tweak the code for functions that get data.\\n\\nInstalling ClickHouse is just one line of code. The initial command executes the script provided by the ClickHouse team to download the proper binary for your platform. Then, you need to launch a server, and that’s it.\\n\\ncurl https://clickhouse.com/ | sh # downloads appropriate binary file\\n./clickhouse server # starts clickhouse server\\n\\nYou can access ClickHouse via HTTP API. By default, it listens on the 8123 port.\\n\\nCH_HOST = \\'http://localhost:8123\\' # default address \\n\\ndef get_clickhouse_data(query, host = CH_HOST, connection_timeout = 1500):\\n    r = requests.post(host, params = {\\'query\\': query}, \\n      timeout = connection_timeout)\\n    \\n    return r.text\\n\\nI usually check that r.status_code = 200 to ensure the request has been successfully completed and raise the error otherwise. However, we will pass the results of this function to LLM. So, getting any output DB returns is okay, regardless of whether it is an error or not. LLM will be able to handle it properly.\\n\\nI’ve generated synthetic data for this example. If you would like to learn more about data simulation, you can find the code here. I used retention curves to model sessions for customers, considering the number of days since account creation and weekly seasonality. It could be a bit of an overcomplicated approach right now since we don’t use data much. But I hope in future prototypes, we will be able to get some insights from this data using LLMs.\\n\\nWe need just a couple of tables representing a data model for a basic e-commerce product. We will work with the list of users (ecommerce.users) and their sessions (ecommerce.sessions).\\n\\nLet’s look at the ecommerce.sessions table.\\n\\nScreenshot by author\\n\\nAnd here, you can see what features we have for users.\\n\\nScreenshot by author\\n\\nNow, we have data to work with and are ready to move on and discuss LLM agents in more detail.\\n\\nAgents overview\\n\\nThe core idea of the LLM agents is to use LLM as a reasoning engine to define the set of actions to take. In the classic approach, we hardcode a sequence of actions, but with agents, we give the model tools and tasks and let her decide how to achieve them.\\n\\nOne of the most foundational papers regarding LLM agents is \"ReAct: Synergizing Reasoning and Acting in Language Models\" by Shunyu Yao et al. The ReAct (Reasoning + Acting) approach suggests combining:\\n\\nreasoning that helps to create the plan and update it in case of exceptions,\\n\\nactions that allow the model to leverage external tools or gather data from external sources.\\n\\nSuch an approach shows much better performance on different tasks. One of the examples from the paper is below.\\n\\nExample from the paper by Yao et al.\\n\\nActually, that’s how human intelligence works: we combine inner voice reasoning with task-oriented actions. Suppose you need to cook a dinner. You will use reasoning to define a plan (\"guests will be in 30 minutes, I have time only to cook pasta\"), adjust it (\"Ben has become a vegan, I should order something for him\") or decide to delegate which is an equivalent of external tools (\"there’s no pasta left, I need to ask my partner to buy it\"). At the same time, you will use actioning to use some tools (ask a partner for help or use a mixer) or get some information (to look up in the internet how many minutes you need to cook pasta to make it al dente). So, it’s reasonable to use a similar approach with LLMs since it works for humans (who are no doubt AGI).\\n\\nNow, there are quite a lot of different approaches for LLM agents since ReAct. They differ in prompts used to set the model’s reasoning, how we define tools, output format, handling memory about the intermediate steps, etc.\\n\\nSome of the most popular approaches are:\\n\\nOpenAI functions,\\n\\nAutoGPT,\\n\\nBabyAGI,\\n\\nPlan-and-execute agent.\\n\\nWe will use these approaches later on for our task and see how they work and what the differences are.\\n\\nBuilding Agent from Scratch\\n\\nLet’s start to build an agent. We will do it from scratch to understand how everything works under the hood. Then, we will use LangChain’s tools for faster prototyping if you don’t need any customisation.\\n\\nThe core components of LLM agents are:\\n\\nPrompt to guide the model’s reasoning.\\n\\nTools that the model can use.\\n\\nMemory - a mechanism to pass previous iterations to the model.\\n\\nFor the first version of the LLM agent, we will use OpenAI functions as a framework to build an agent.\\n\\nDefining tools\\n\\nLet’s start with defining the tools for our robot. Let’s think about what information our LLM-powered analyst might need to be able to answer questions:\\n\\nList of tables - we can put it in the system prompt so that the model has some view on what data we have and doesn’t need to execute a tool for it every time,\\n\\nList of columns for the table so that the model can understand the data schema,\\n\\nTop values for the column in the table so that the model can look up values for filters,\\n\\nResults of SQL query execution to be able to get actual data.\\n\\nTo define tools in LangChain, we need to use @tool decorator for the function. We will use Pydantic to specify the arguments schema for each function so that the model knows what to pass to the function.\\n\\nWe’ve discussed tools and OpenAI functions in detail in the previous article. So don’t hesitate to read it if you need to revise this topic.\\n\\nThe code below defines three tools: execute_sql, get_table_columns and get_table_column_distr.\\n\\nfrom langchain.agents import tool\\nfrom pydantic import BaseModel, Field\\nfrom typing import Optional\\n\\nclass SQLQuery(BaseModel):\\n    query: str = Field(description=\"SQL query to execute\")\\n\\n@tool(args_schema = SQLQuery)\\ndef execute_sql(query: str) -> str:\\n    \"\"\"Returns the result of SQL query execution\"\"\"\\n    return get_clickhouse_data(query)\\n\\nclass SQLTable(BaseModel):\\n    database: str = Field(description=\"Database name\")\\n    table: str = Field(description=\"Table name\")\\n\\n@tool(args_schema = SQLTable)\\ndef get_table_columns(database: str, table: str) -> str:\\n    \"\"\"Returns list of table column names and types in JSON\"\"\"\\n    \\n    q = \\'\\'\\'\\n    select name, type\\n    from system.columns \\n    where database = \\'{database}\\'\\n        and table = \\'{table}\\'\\n    format TabSeparatedWithNames\\n    \\'\\'\\'.format(database = database, table = table)\\n    \\n    return str(get_clickhouse_df(q).to_dict(\\'records\\'))\\n\\nclass SQLTableColumn(BaseModel):\\n    database: str = Field(description=\"Database name\")\\n    table: str = Field(description=\"Table name\")\\n    column: str = Field(description=\"Column name\")\\n    n: Optional[int] = Field(description=\"Number of rows, default limit 10\")\\n\\n@tool(args_schema = SQLTableColumn)\\ndef get_table_column_distr(database: str, table: str, column: str, n:int = 10) -> str:\\n    \"\"\"Returns top n values for the column in JSON\"\"\"\\n\\n    q = \\'\\'\\'\\n    select {column}, count(1) as count\\n    from {database}.{table} \\n    group by 1\\n    order by 2 desc \\n    limit {n}\\n    format TabSeparatedWithNames\\n    \\'\\'\\'.format(database = database, table = table, column = column, n = n)\\n    \\n    return str(list(get_clickhouse_df(q)[column].values))\\n\\nIt’s worth noting that the code above uses Pydantic v1. In June 2023, Pydantic released v2, which is incompatible with v1. So, check your version if you see validation errors. You can find more details on the Pydantic compatibility in the documentation.\\n\\nWe will be working with OpenAI functions and need to convert our tools. Also, I saved our toolkit in a dictionary. It will be handy when executing tools to get observations.\\n\\nfrom langchain.tools.render import format_tool_to_openai_function\\n\\n# converting tools into OpenAI functions\\nsql_functions = list(map(format_tool_to_openai_function, \\n    [execute_sql, get_table_columns, get_table_column_distr]))\\n\\n# saving tools into a dictionary for the future\\nsql_tools = {\\n    \\'execute_sql\\': execute_sql,\\n    \\'get_table_columns\\': get_table_columns,\\n    \\'get_table_column_distr\\': get_table_column_distr\\n}\\n\\nDefining a chain\\n\\nWe’ve created tools for the model. Now, we need to define the agent chain. We will use the latest GPT 4 Turbo, which was also fine-tuned to be used with the functions. Let’s initialise a chat model.\\n\\nfrom langchain.chat_models import ChatOpenAI\\n\\nllm = ChatOpenAI(temperature=0.1, model = \\'gpt-4-1106-preview\\')\\\\\\n  .bind(functions = sql_functions)\\n\\nThe next step is to define a prompt consisting of a system message and a user question. We also need a MessagesPlaceholder to set up a place for the list of observations the model will be working with.\\n\\nfrom langchain.prompts import ChatPromptTemplate, MessagesPlaceholder\\n\\nsystem_message = \\'\\'\\'\\nYou are working as a product analyst for the e-commerce company. \\nYour work is very important, since your product team makes decisions based on the data you provide. So, you are extremely accurate with the numbers you provided. \\nIf you\\'re not sure about the details of the request, you don\\'t provide the answer and ask follow-up questions to have a clear understanding.\\nYou are very helpful and try your best to answer the questions.\\n\\nAll the data is stored in SQL Database. Here is the list of tables (in the format <database>.<table>) with descriptions:\\n- ecommerce.users - information about the customers, one row - one customer\\n- ecommerce.sessions - information about the sessions customers made on our web site, one row - one session\\n\\'\\'\\'\\n\\nanalyst_prompt = ChatPromptTemplate.from_messages(\\n    [\\n        (\"system\", system_message),\\n        (\"user\", \"{question}\"),\\n        MessagesPlaceholder(variable_name=\"agent_scratchpad\"),\\n    ]\\n)\\n\\nAs we discussed, I’ve added the list of tables in the database to the prompt so that the model has at least some knowledge about our data.\\n\\nWe have all the building blocks and are ready to set up the agent chain. The input parameters are a user message and intermediate steps (previous messages, function calls and observations). We pass the input parameters to the prompt using format_to_openai_function_messages to convert them into the expected format. Then, we pass everything to the LLM and, in the end, use the output parser OpenAIFunctionsAgentOutputParser for convenience.\\n\\n\\nfrom langchain.agents.format_scratchpad import format_to_openai_function_messages\\nfrom langchain.agents.output_parsers import OpenAIFunctionsAgentOutputParser\\n\\nanalyst_agent = (\\n    {\\n        \"question\": lambda x: x[\"question\"],\\n        \"agent_scratchpad\": lambda x: format_to_openai_function_messages(x[\"intermediate_steps\"]),\\n    }\\n    | analyst_prompt\\n    | llm\\n    | OpenAIFunctionsAgentOutputParser()\\n)\\n\\nWe’ve defined our primary agent chain. Let’s try to invoke it. I’ve passed an empty list since we have no intermediate steps in the beginning.\\n\\nanalyst_agent.invoke({\"question\": \"How many active customers from the United Kingdom do we have?\", \\n    \"intermediate_steps\": []})\\n\\n# AgentActionMessageLog(\\n#    tool=\\'execute_sql\\', \\n#    tool_input={\\'query\\': \"SELECT COUNT(DISTINCT user_id) AS active_customers_uk FROM ecommerce.sessions WHERE country = \\'United Kingdom\\' AND active = TRUE\"}, \\n#    log=\\'\\\\nInvoking: `execute_sql` with `{\\\\\\'query\\\\\\': \"SELECT COUNT(DISTINCT user_id) AS active_customers_uk FROM ecommerce.sessions WHERE country = \\\\\\'United Kingdom\\\\\\' AND active = TRUE\"}`\\\\n\\\\n\\\\n\\', \\n#    message_log=[AIMessage(content=\\'\\', additional_kwargs={\\'function_call\\': {\\'arguments\\': \\'{\"query\":\"SELECT COUNT(DISTINCT user_id) AS active_customers_uk FROM ecommerce.sessions WHERE country = \\\\\\'United Kingdom\\\\\\' AND active = TRUE\"}\\', \\'name\\': \\'execute_sql\\'}})]\\n# )\\n\\nWe got an AgentActionMessageLog object, which means the model wants to call execute_sql function. When the model is ready to return the final answer to the user, it returns the AgentFinish object.\\n\\nIf we look at the tool_input, we can see that the model wants to execute the following query.\\n\\nSELECT COUNT(DISTINCT user_id) AS active_customers_uk \\nFROM ecommerce.sessions \\nWHERE country = \\'United Kingdom\\' AND active = TRUE\\n\\nThe query looks pretty good but uses the wrong column name: active instead of is_active. It will be interesting to see whether LLM will be able to recover from this error and return the result.\\n\\nWe can do execution step by step manually, however it will be more convenient to automate it.\\n\\nIf the AgentActionMessageLog object is returned, we need to call a tool, add the observation to the agent_scratchpad, and invoke the chain one more time.\\n\\nIf we got theAgentFinish object, we can terminate execution since we have the final answer.\\n\\nI will also add a break after ten iterations to avoid potential endless loops.\\n\\nfrom langchain_core.agents import AgentFinish\\n\\n# setting initial parameters\\nquestion = \"How many active customers from the United Kingdom do we have?\"\\nintermediate_steps = []\\nnum_iters = 0\\n\\nwhile True:\\n    # breaking if there were more than 10 iterations\\n    if num_iters >= 10:  \\n        break\\n\\n    # invoking the agent chain\\n    output = analyst_agent.invoke(\\n        {\\n            \"question\": question,\\n            \"intermediate_steps\": intermediate_steps,\\n        }\\n    )\\n    num_iters += 1\\n    \\n    # returning the final result if we got the AgentFinish object\\n    if isinstance(output, AgentFinish):\\n        model_output = output.return_values[\"output\"]\\n        break\\n    # calling tool and adding observation to the scratchpad otherwise\\n    else:\\n        print(f\\'Executing tool: {output.tool}, arguments: {output.tool_input}\\')\\n        observation = sql_tools[output.tool](output.tool_input)\\n        print(f\\'Observation: {observation}\\')\\n        print()\\n        intermediate_steps.append((output, observation))\\n        \\nprint(\\'Model output:\\', model_output)\\n\\nI added some logging of the tools’ usage to the output to see how the execution is going. Also, you can always use LangChain debug mode to see all the calls.\\n\\nAs a result of the execution, we got the following output.\\n\\nExecuting tool: execute_sql, arguments: {\\'query\\': \"SELECT COUNT(*) AS active_customers_uk FROM ecommerce.users WHERE country = \\'United Kingdom\\' AND active = TRUE\"}\\nObservation: Code: 47. DB::Exception: Missing columns: \\'active\\' \\nwhile processing query: \\'SELECT count() AS active_customers_uk \\nFROM ecommerce.users WHERE (country = \\'United Kingdom\\') AND (active = true)\\', \\nrequired columns: \\'country\\' \\'active\\', maybe you meant: \\'country\\'. \\n(UNKNOWN_IDENTIFIER) (version 23.12.1.414 (official build))\\n\\nExecuting tool: get_table_columns, arguments: {\\'database\\': \\'ecommerce\\', \\'table\\': \\'users\\'}\\nObservation: [{\\'name\\': \\'user_id\\', \\'type\\': \\'UInt64\\'}, {\\'name\\': \\'country\\', \\'type\\': \\'String\\'}, \\n{\\'name\\': \\'is_active\\', \\'type\\': \\'UInt8\\'}, {\\'name\\': \\'age\\', \\'type\\': \\'UInt64\\'}]\\n\\nExecuting tool: execute_sql, arguments: {\\'query\\': \"SELECT COUNT(*) AS active_customers_uk FROM ecommerce.users WHERE country = \\'United Kingdom\\' AND is_active = 1\"}\\nObservation: 111469\\n\\nModel output: We have 111,469 active customers from the United Kingdom.\\n\\nNote: there’s no guarantee that the agent won’t execute DML operations on your database. So, if you’re using it in a production environment, ensure that LLM either doesn’t have permission to change data or your tool implementation doesn’t allow it.\\n\\nSo, the model tried to execute SQL but got an error that there was no column active. Then, it decided to see the table schema, corrected the query accordingly, and got the result.\\n\\nIt’s a pretty decent performance. I behave the same way myself. I usually try recalling or guessing column names first and check the documentation only if the first attempt fails.\\n\\nHowever, in most cases, we don’t need to write the execution ourselves. We can use the LangChain AgentExecutor class for it. Check documentation to learn about all possible parameters for the class.\\n\\nYou need to write your own executor only if you want to customise something. For example, add some conditions to terminate the execution or logic to use tools.\\n\\nYou can find the same code using the AgentExecutor below.\\n\\nfrom langchain.agents import AgentExecutor\\n\\nanalyst_agent_executor = AgentExecutor(\\n    agent=analyst_agent, \\n    tools=[execute_sql, get_table_columns, get_table_column_distr], \\n    verbose=True,\\n    max_iterations=10, # early stopping criteria\\n    early_stopping_method=\\'generate\\', \\n    # to ask model to generate the final answer after stopping\\n)\\n\\nanalyst_agent_executor.invoke(\\n  {\"question\": \"How many active customers from the United Kingdom do we have?\"}\\n)\\n\\nAs a result, we got an easy-to-trace output with the same result. You can note that LangChain’s formatting for the agent’s output is very convenient.\\n\\nImage by author\\n\\nWe’ve built the LLM agent from scratch. So now, we understand how it works and know how to customise it. However, LangChain provides a high-level function initialize_agent that could do it within just one call. You can find all the details in the documentation.\\n\\nfrom langchain.agents import AgentType, Tool, initialize_agent\\nfrom langchain.schema import SystemMessage\\n\\nagent_kwargs = {\\n    \"system_message\": SystemMessage(content=system_message)\\n}\\n\\nanalyst_agent_openai = initialize_agent(\\n    llm = ChatOpenAI(temperature=0.1, model = \\'gpt-4-1106-preview\\'),\\n    agent = AgentType.OPENAI_FUNCTIONS, \\n    tools = [execute_sql, get_table_columns, get_table_column_distr], \\n    agent_kwargs = agent_kwargs,\\n    verbose = True,\\n    max_iterations = 10,\\n    early_stopping_method = \\'generate\\'\\n)\\n\\n\\nNote that we passed the ChatOpenAI model without functions bound to it. We’ve passed tools separately, so we don’t need to link them to the model.\\n\\nDifferent Agent Types\\n\\nWe’ve built an LLM agent based on OpenAI functions from scratch. However, there are quite a lot of other approaches. So let’s try them out as well.\\n\\nWe will look at the ReAct approach (the initial one from the paper we discussed earlier) and several experimental approaches provided by LangChain: Plan-and-execute, BabyAGI and AutoGPT.\\n\\nReAct agent\\n\\nLet’s start with looking at ReAct agents. With the current implementation, we can easily change the agent type and try the ReAct approach described in the paper.\\n\\nThe most general ReAct implementation is Zero-shot ReAct. It won’t work for us because it supports only tools with a single string in input. Our tools require multiple arguments, so we need to use Structured Input ReAct.\\n\\nWe can leverage the advantage of using a modular framework: we need to change just one parameter agent = AgentType.STRUCTURED_CHAT_ZERO_SHOT_REACT_DESCRIPTION, and that’s it.\\n\\nsystem_message = system_message + \\'\\'\\'\\\\nYou have access to the following tools:\\'\\'\\'\\n\\nagent_kwargs = {\\n    \"prefix\": system_message\\n}\\n\\nanalyst_agent_react = initialize_agent(\\n    llm = ChatOpenAI(temperature=0.1, model = \\'gpt-4-1106-preview\\'),\\n    agent = AgentType.STRUCTURED_CHAT_ZERO_SHOT_REACT_DESCRIPTION, \\n    tools = [execute_sql, get_table_columns, get_table_column_distr], \\n    agent_kwargs = agent_kwargs,\\n    verbose = True,\\n    max_iterations = 10,\\n    early_stopping_method = \\'generate\\'\\n)\\n\\nYou might wonder how to find the arguments you can specify for the agent. Unfortunately, it’s not documented, so we need to dive into the source code to understand it. Let’s discuss it step-by-step.\\n\\nWe can see that analyst_agent_react is an object of the AgentExecutor class.\\n\\nThis class has an agent field. In our case, it’s an object of the StructuredChatAgent class. The class depends on the specified agent type.\\n\\nLet’s find a StructuredChatAgent class implementation and see how it works. In this case, LangChain creates a prompt consisting of prefix, tools’ description, formatted instructions and suffix.\\n\\nYou can find the complete list of parameters you can pass as agent_kwargs in the code.\\n\\nSo, we can override the default PREFIX value from here and pass it as a prefix in agent_kwargs. Also, if you’re interested, you can read through the default ReAct prompt here and think about how to tweak it for your task.\\n\\nIf you are interested, you can see the final prompt using the following call.\\n\\nfor message in analyst_agent_react.agent.llm_chain.prompt.messages:\\n    print(message.prompt.template)\\n\\nLet’s invoke our method and see the result.\\n\\nanalyst_agent_react.run(\"How many active customers from the United Kingdom do we have?\")\\n\\nWe can notice that the model follows a slightly different framework for reasoning. The model starts iteration with writing down the thought (reasoning), then moves to action (function call) and observation (the result of function call). Then, iteration repeats. In the end, the model returns action = Final Answer.\\n\\n> Entering new AgentExecutor chain...\\nThought: To answer this question, I need to define what is meant by \\n\"active customers\" and then query the database for users from \\nthe United Kingdom who meet this criteria. I will first need to know \\nthe structure of the `ecommerce.users` table to understand what columns \\nare available that could help identify active customers and their location.\\n\\nAction:\\n```\\n{\\n  \"action\": \"get_table_columns\",\\n  \"action_input\": {\\n    \"database\": \"ecommerce\",\\n    \"table\": \"users\"\\n  }\\n}\\n```\\n\\n\\nObservation: [{\\'name\\': \\'user_id\\', \\'type\\': \\'UInt64\\'}, {\\'name\\': \\'country\\', \\'type\\': \\'String\\'}, {\\'name\\': \\'is_active\\', \\'type\\': \\'UInt8\\'}, {\\'name\\': \\'age\\', \\'type\\': \\'UInt64\\'}]\\nThought:The `ecommerce.users` table contains a column named `is_active` \\nwhich likely indicates whether a customer is active or not, and a `country` \\ncolumn which can be used to filter users by their location. Since we \\nare interested in active customers from the United Kingdom, we can use \\nthese two columns to query the database.\\n\\nAction:\\n```\\n{\\n  \"action\": \"execute_sql\",\\n  \"action_input\": {\\n    \"query\": \"SELECT COUNT(*) AS active_customers_uk FROM ecommerce.users WHERE country = \\'United Kingdom\\' AND is_active = 1\"\\n  }\\n}\\n```\\nObservation: 111469\\n\\nThought:I have the information needed to respond to the user\\'s query.\\nAction:\\n```\\n{\\n  \"action\": \"Final Answer\",\\n  \"action_input\": \"There are 111,469 active customers from the United Kingdom.\"\\n}\\n```\\n\\n> Finished chain.\\n\\'There are 111,469 active customers from the United Kingdom.\\'\\n\\nEven though the model followed a different path (starting with understanding the table schema and then executing SQL), it came to the same result.\\n\\nNow, let’s move on to experimental approaches. In LangChain, there are experimental agent types. They are not advised for production usage yet. However, it will be interesting to try using them and see how they work.\\n\\nPlan-and-execute agent\\n\\nThe code below is based on the example from LangChain’s cookbook.\\n\\nThis agent follows a \"Plan-and-execute\" approach in contrast to the \"Action\" agents we looked at previously. This approach was inspired by the BabyAGI framework and the paper \"Plan-and-Solve Prompting\".\\n\\nThe characteristic of such an approach is that the agent first tries to plan the next steps and then executes them.\\n\\nThere are two components in this approach:\\n\\nPlanner - a regular Large Language Model with the primary goal - just to reason and plan,\\n\\nExecutor - Action agent, an LLM empowered with the set of tools it can use to action.\\n\\nThe advantage of this approach is that you have a separation: one model focuses on planning (reasoning), while the other focuses on execution (action). It’s more modular, and potentially, you could use smaller and cheaper models fine-tuned for your specific tasks. However, this approach also generates more LLM calls, so it’s more expensive if we are using ChatGPT.\\n\\nLet’s initialise the planner and the executor.\\n\\nfrom langchain_experimental.plan_and_execute import PlanAndExecute, load_agent_executor, load_chat_planner\\n\\nmodel = ChatOpenAI(temperature=0.1, model = \\'gpt-4-1106-preview\\')\\nplanner = load_chat_planner(model)\\nexecutor = load_agent_executor(model, \\n    tools = [execute_sql, get_table_columns, get_table_column_distr], \\n    verbose=True)\\n\\nThere’s currently no way to specify a custom prompt for the executor since you can’t pass it to the function. However, we can hack the prompt and add our initial system message that gives some context about the task to the beginning of the default prompt.\\n\\nDisclaimer: overriding objects’ fields is a bad practice because we might bypass some prompt validations. We are doing it now only to experiment with this approach. Such a solution is not suitable for production.\\n\\nexecutor.chain.agent.llm_chain.prompt.messages[0].prompt.template = system_message + \\'\\\\n\\' + \\\\\\n    executor.chain.agent.llm_chain.prompt.messages[0].prompt.template\\n\\nNow, it’s time to define an agent and execute the same query we were asking before.\\n\\nanalyst_agent_plan_and_execute = PlanAndExecute(\\n    planner=planner, \\n    executor=executor\\n)\\nanalyst_agent_plan_and_execute.run(\"How many active customers from the United Kingdom do we have?\")\\n\\nThe call returned an error: RateLimitError: Error code: 429 - {\\'error\\': {\\'message\\': \\'Request too large for gpt-4–1106-preview in organization on tokens_usage_based per min: Limit 150000, Requested 235832.\\', \\'type\\': \\'tokens_usage_based\\', \\'param\\': None, \\'code\\': \\'rate_limit_exceeded\\'}} . It looks like the model tried to send too many tokens to OpenAI.\\n\\nLet’s try to understand what has happened by looking at the model’s output (you can find it below):\\n\\nFirst, the model decided to look at ecommerce.users and ecommerce.sessions columns to determine the criteria for \"active\" customers.\\n\\nIt realised that it needed to use is_active in ecommerce.users table. However, the model decided it should also use sessions’ data to define the customer’s activity.\\n\\nThen, the model went down this rabbit hole trying to define criteria for recent activity in ecommerce.sessions. It looked at the distributions for action_date, session_duration and revenue.\\n\\nFinally, it defined active customers as those who have had a session within the last 30 days, with a session duration and revenue above certain thresholds, neglecting that it could just use is_active. The model planned to look at the data to define these thresholds.\\n\\nThe final error was caused by an attempt to load all user_ids for customers since there are too many tokens for ChatGPT.\\n\\nEven though there is quite a lot of text, I encourage you to read it to see how the model thinks through the problems.\\n\\n> Entering new AgentExecutor chain...\\nAction:\\n```\\n{\\n  \"action\": \"Final Answer\",\\n  \"action_input\": \"The data regarding customers is stored in a SQL Database, specifically in the table named \\'ecommerce.users\\'.\"\\n}\\n```\\n\\n> Finished chain.\\n\\n\\n> Entering new AgentExecutor chain...\\nThought: To determine the criteria for an \"active\" customer, I need \\nto understand what data is available in the \\'ecommerce.users\\' and \\n\\'ecommerce.sessions\\' tables. This will help me identify which columns \\ncould be used to define an \"active\" customer based on recent purchases, \\naccount activity, or other engagement metrics.\\n\\nAction:\\n```\\n{\\n  \"action\": \"get_table_columns\",\\n  \"action_input\": {\\n    \"database\": \"ecommerce\",\\n    \"table\": \"users\"\\n  }\\n}\\n```\\n\\n\\nObservation: [{\\'name\\': \\'user_id\\', \\'type\\': \\'UInt64\\'}, {\\'name\\': \\'country\\', \\'type\\': \\'String\\'}, {\\'name\\': \\'is_active\\', \\'type\\': \\'UInt8\\'}, {\\'name\\': \\'age\\', \\'type\\': \\'UInt64\\'}]\\nThought:The \\'ecommerce.users\\' table contains columns for \\'user_id\\', \\'country\\',\\n \\'is_active\\', and \\'age\\'. The \\'is_active\\' column seems to directly indicate \\nwhether a user is considered active or not. However, to understand \\nthe criteria behind this designation, we need to see if there are \\nany engagement metrics in the \\'ecommerce.sessions\\' table that could \\ncorrelate with the \\'is_active\\' status.\\n\\nAction:\\n```\\n{\\n  \"action\": \"get_table_columns\",\\n  \"action_input\": {\\n    \"database\": \"ecommerce\",\\n    \"table\": \"sessions\"\\n  }\\n}\\n```\\n\\nObservation: [{\\'name\\': \\'user_id\\', \\'type\\': \\'UInt64\\'}, {\\'name\\': \\'session_id\\', \\'type\\': \\'UInt64\\'}, {\\'name\\': \\'action_date\\', \\'type\\': \\'Date\\'}, {\\'name\\': \\'session_duration\\', \\'type\\': \\'UInt64\\'}, {\\'name\\': \\'os\\', \\'type\\': \\'String\\'}, {\\'name\\': \\'browser\\', \\'type\\': \\'String\\'}, {\\'name\\': \\'is_fraud\\', \\'type\\': \\'UInt8\\'}, {\\'name\\': \\'revenue\\', \\'type\\': \\'Float32\\'}]\\nThought:The \\'ecommerce.sessions\\' table includes columns such as \\'user_id\\', \\n\\'session_id\\', \\'action_date\\', \\'session_duration\\', \\'os\\', \\'browser\\', \\'is_fraud\\', \\nand \\'revenue\\'. The \\'action_date\\' could be used to determine recent activity, \\nand \\'session_duration\\' might indicate engagement level. \\'Revenue\\' could \\nbe used to identify recent purchases. To define an \"active\" customer, \\nwe could consider users with recent \\'action_date\\', longer \\'session_duration\\', \\nand positive \\'revenue\\'. However, to set specific criteria, we might need \\nto understand the distribution of these values, such as \\nthe most recent \\'action_date\\' or average \\'session_duration\\'. \\nLet\\'s first check the distribution of \\'action_date\\' to see how recent \\nthe sessions are.\\n\\nAction:\\n```\\n{\\n  \"action\": \"get_table_column_distr\",\\n  \"action_input\": {\\n    \"database\": \"ecommerce\",\\n    \"table\": \"sessions\",\\n    \"column\": \"action_date\",\\n    \"n\": 10\\n  }\\n}\\n```\\nObservation: [\\'2023-12-25\\', \\'2023-12-26\\', \\'2023-12-27\\', \\'2023-12-18\\', \\'2023-12-28\\', \\'2023-12-21\\', \\'2023-12-20\\', \\'2023-12-04\\', \\'2023-12-19\\', \\'2023-12-14\\']\\nThought:The distribution of \\'action_date\\' shows recent dates, with \\nthe latest being \\'2023-12-28\\'. This suggests that the data includes \\nvery recent sessions. To define an \"active\" customer, we could consider \\na timeframe such as the last 30 days. However, before finalizing \\nthis criterion, it would be beneficial to also understand \\nthe distribution of \\'session_duration\\' and \\'revenue\\' to see if there \\nare common thresholds that could further define an \"active\" customer. \\nLet\\'s check the distribution of \\'session_duration\\' next.\\n\\nAction:\\n```\\n{\\n  \"action\": \"get_table_column_distr\",\\n  \"action_input\": {\\n    \"database\": \"ecommerce\",\\n    \"table\": \"sessions\",\\n    \"column\": \"session_duration\",\\n    \"n\": 10\\n  }\\n}\\n```\\nObservation: [772, 860, 887, 678, 405, 671, 670, 707, 982, 907]\\nThought:The distribution of \\'session_duration\\' shows a range of values, \\nwith durations varying from 405 to 982 seconds. These values could \\nbe used to set a threshold for engagement level, but without context, \\nit\\'s difficult to determine what would be considered a high or \\nlow session duration. To get a better understanding, we should look \\nat the distribution of \\'revenue\\' to see if there\\'s a common revenue \\nthreshold that could be used in conjunction with \\'action_date\\' and \\n\\'session_duration\\' to define an \"active\" customer. Let\\'s check \\nthe distribution of \\'revenue\\' next.\\n\\nAction:\\n```\\n{\\n  \"action\": \"get_table_column_distr\",\\n  \"action_input\": {\\n    \"database\": \"ecommerce\",\\n    \"table\": \"sessions\",\\n    \"column\": \"revenue\",\\n    \"n\": 10\\n  }\\n}\\n```\\n\\nObservation: [0.0, 1556.9, 7803.2, 4936.5, 619.6, 9947.7, 646.2, 3251.1, 2860.9, 4376.5]\\nThought:The distribution of \\'revenue\\' shows a range of values including zero, \\nwhich could indicate sessions without purchases, and values up to 9947.7,\\n which suggests significant purchases. To define an \"active\" customer, \\nwe could consider those with non-zero revenue within the last 30 days \\nand with a session duration above a certain threshold. However, to set \\na precise threshold for \\'session_duration\\' and \\'revenue\\', we would need \\nto analyze the data further, possibly calculating averages or percentiles. \\nFor now, we can propose a preliminary definition of an \"active\" customer\\n as one who has had a session within the last 30 days, with a session duration \\nand revenue above certain thresholds to be determined.\\n\\nAction:\\n```\\n{\\n  \"action\": \"Final Answer\",\\n  \"action_input\": \"Based on the data available in the \\'ecommerce.users\\' and \\'ecommerce.sessions\\' tables, an \\'active\\' customer could preliminarily be defined as one who has had a session within the last 30 days, with a session duration and revenue above certain thresholds. The \\'is_active\\' column in the \\'users\\' table may already reflect this or a similar definition, but further analysis would be required to set specific thresholds for \\'session_duration\\' and \\'revenue\\'. These thresholds could be determined by calculating averages or percentiles based on the data distribution.\"\\n}\\n```\\n\\n> Finished chain.\\n\\n\\n> Entering new AgentExecutor chain...\\nAction:\\n```\\n{\\n  \"action\": \"get_table_columns\",\\n  \"action_input\": {\\n    \"database\": \"ecommerce\",\\n    \"table\": \"users\"\\n  }\\n}\\n```\\n\\nObservation: [{\\'name\\': \\'user_id\\', \\'type\\': \\'UInt64\\'}, {\\'name\\': \\'country\\', \\'type\\': \\'String\\'}, {\\'name\\': \\'is_active\\', \\'type\\': \\'UInt8\\'}, {\\'name\\': \\'age\\', \\'type\\': \\'UInt64\\'}]\\nThought:The \\'ecommerce.users\\' table contains a \\'country\\' column which \\ncan be used to filter the customer records based on the location \\nbeing the United Kingdom. I will write and execute an SQL query \\nto retrieve the user IDs of customers located in the United Kingdom.\\n\\nAction:\\n```\\n{\\n  \"action\": \"execute_sql\",\\n  \"action_input\": {\\n    \"query\": \"SELECT user_id FROM ecommerce.users WHERE country = \\'United Kingdom\\'\"\\n  }\\n}\\n```\\n\\nObservation: \\n1000001\\n1000011\\n1000021\\n1000029\\n1000044\\n... <many more lines...>\\n\\nThat’s an excellent example of the situation when the agent overcomplicated the question and went into too much detail. Human analysts also make such mistakes from time to time. So, it’s interesting to see similar patterns in LLM behaviour.\\n\\nIf we try to reflect on how we could potentially fix this issue, there are a couple of ways:\\n\\nFirst, we could prevent the cases when we try to get too much data from the database, returning an error if there are more than 1K rows in the output of the execute_sql function.\\n\\nThe other thing I would think about is allowing LLM to ask follow-up questions and instruct it not to make assumptions.\\n\\nLet’s move on to the BabyAGI approach that inspired the current one.\\n\\nBabyAGI agent with Tools\\n\\nThe code below is based on example from LangChain’s cookbook.\\n\\nSimilar to the previous approach, our other experimental one, BabyAGI, tries to plan first and then execute.\\n\\nThis approach uses retrieval, so we need to set up a vector storage and embedding model. I use open-source and lightweight Chroma for storage and OpenAI embeddings.\\n\\nfrom langchain.embeddings.openai import OpenAIEmbeddings\\nfrom langchain.vectorstores import Chroma\\n\\nembedding = OpenAIEmbeddings()\\npersist_directory = \\'vector_store\\'\\n\\nvectordb = Chroma(\\n    persist_directory=persist_directory,\\n    embedding_function=embedding\\n)\\n\\nRetrieval allows the model to store all the results for a long term and extract and pass only the most relevant ones. If you want to learn more about retrieval, read my article on RAG (Retrieval Augmented Generation).\\n\\nFirstly, we will create a TO-DO chain that we will use as a tool for our executor later.\\n\\nfrom langchain.chains import LLMChain\\nfrom langchain.prompts import PromptTemplate\\n\\ntodo_prompt_message = \\'\\'\\'\\nYou are a planner who is an expert at coming up with a todo list for \\na given objective. Come up with a todo list for this objective: {objective}\\n\\'\\'\\'\\n\\ntodo_prompt = PromptTemplate.from_template(todo_prompt_message)\\ntodo_chain = LLMChain(llm=OpenAI(temperature=0.1, \\n    model = \\'gpt-4-1106-preview\\'), prompt=todo_prompt)\\n\\nThen, we will create an agent specifying tools and prompts.\\n\\nfrom langchain.agents import AgentExecutor, Tool, ZeroShotAgent\\nfrom langchain.prompts import PromptTemplate\\n\\ntools = [\\n    execute_sql, \\n    get_table_columns, \\n    get_table_column_distr,\\n    Tool(\\n        name=\"TODO\",\\n        func=todo_chain.run,\\n        description=\"useful for when you need to come up with todo lists. Input: an objective to create a todo list for. Output: a todo list for that objective. Please be very clear what the objective is!\",\\n    )\\n]\\n\\n\\nprefix = \"\"\"\\nYou are an AI who performs one task based on the following objective: {objective}. Take into account these previously completed tasks: {context}.\\n\\nYou are asked questions related to analytics for e-commerce product.\\nYour work is very important, since your product team makes decisions based on the data you provide. So, you are extremely accurate with the numbers you provided. \\nIf you\\'re not sure about the details of the request, you don\\'t provide the answer and ask follow-up questions to have a clear understanding.\\nYou are very helpful and try your best to answer the questions.\\n\\nAll the data is stored in SQL Database. Here is the list of tables (in the format <database>.<table>) with descriptions:\\n- ecommerce.users - information about the customers, one row - one customer\\n- ecommerce.sessions - information about the sessions customers made on our web site, one row - one session\\n\"\"\"\\n\\nsuffix = \"\"\"Question: {task}\\n{agent_scratchpad}\"\"\"\\n\\nprompt = ZeroShotAgent.create_prompt(\\n    tools,\\n    prefix=prefix,\\n    suffix=suffix,\\n    input_variables=[\"objective\", \"task\", \"context\", \"agent_scratchpad\"],\\n)\\n\\nllm = OpenAI(temperature=0.1)\\nllm_chain = LLMChain(llm=llm, prompt=prompt)\\ntool_names = [tool.name for tool in tools]\\nanalyst_agent_babyagi = ZeroShotAgent(llm_chain=llm_chain, allowed_tools=tool_names)\\nanalyst_agent_babyagi_executor = AgentExecutor.from_agent_and_tools(\\n    agent=analyst_agent_babyagi, tools=tools, verbose=True\\n)\\n\\nThe last step is to define the BabyAGI executor and run it.\\n\\nfrom langchain_experimental.autonomous_agents import BabyAGI\\nbaby_agi = BabyAGI.from_llm(\\n    llm=llm,\\n    vectorstore=vectordb,\\n    task_execution_chain=analyst_agent_babyagi_executor,\\n    verbose=True,\\n    max_iterations=10\\n)\\nbaby_agi(\"Find, how many active customers from the United Kingdom we have.\")\\n\\nAgain, the model failed to return results because it wasn’t able to follow the input schema for the tool.\\n\\nAlso, surprisingly, the model decided not to use the TO-DO function to create a to-do list but to jump into querying SQL. However, the first query wasn’t correct. The model tried to recover and call theget_table_columns function to get column names, but it failed to follow the schema.\\n\\nLet’s look at the log.\\n\\n*****TASK LIST*****\\n\\n1: Make a todo list\\n\\n*****NEXT TASK*****\\n\\n1: Make a todo list\\n\\n\\n> Entering new AgentExecutor chain...\\nThought: I need to find out how many active customers from the United Kingdom \\nwe have\\nAction: execute_sql\\nAction Input: SELECT COUNT(*) FROM ecommerce.users WHERE country = \\'UK\\' AND active = 1\\nObservation: Code: 47. DB::Exception: Missing columns: \\'active\\' while processing query: \\n\\'SELECT count() FROM ecommerce.users WHERE (country = \\'UK\\') AND (active = 1)\\', \\nrequired columns: \\'country\\' \\'active\\', maybe you meant: \\'country\\'. \\n(UNKNOWN_IDENTIFIER) (version 23.12.1.414 (official build))\\n\\nThought: I need to get the columns of the ecommerce.users table\\nAction: get_table_columns\\nAction Input: ecommerce.users\\n\\nSo, we’ve seen another problem that is pretty common for agents not powered by OpenAI functions - they fail to follow the structure.\\n\\nAutoGPT agent with Tools\\n\\nThe code below is based on example from LangChain’s cookbook.\\n\\nLet’s look at another experimental approach - the implementation of AutoGPT using the LangChain framework.\\n\\nAgain, we need to set up a vector storage for intermediate steps.\\n\\nembedding = OpenAIEmbeddings()\\nfrom langchain.vectorstores import Chroma\\npersist_directory = \\'autogpt\\'\\n\\nvectordb = Chroma(\\n    persist_directory=persist_directory,\\n    embedding_function=embedding\\n)\\n\\nIn this case, again, we can’t specify any prompt to the model. Let’s try to use it without any specific guidance. But let’s add the get_tables tool so the model can see all the available tables. I hope it will help the model with writing correct SQL queries.\\n\\n@tool()\\ndef get_tables() -> str:\\n    \"\"\"Returns list of tables in the format <database>.<table>\"\"\"\\n    \\n    return [\\'ecommerce.users\\', \\'ecommerce.sessions\\']\\n\\nLet’s create an AutoGPT agent. It’s as easy as one function call. Then, let’s execute it and see how it works.\\n\\n\\nfrom langchain_experimental.autonomous_agents import AutoGPT\\n\\nanalyst_agent_autogpt = AutoGPT.from_llm_and_tools(\\n    ai_name=\"Harry\",\\n    ai_role=\"Assistant\",\\n    tools= [execute_sql, get_table_columns, \\n        get_table_column_distr, get_tables],\\n    llm=ChatOpenAI(temperature=0.1, model = \\'gpt-4-1106-preview\\'),\\n    memory=vectordb.as_retriever(),\\n)\\n\\nanalyst_agent_autogpt.chain.verbose = True\\n\\nanalyst_agent_autogpt.run([\"Find how many active customers from the United Kingdom we have.\"])\\n\\nThe model was able to come up with the right answer: \"The number of active customers from the United Kingdom is 111,469.\"\\n\\nReading through the prompt is interesting since we used the default one. You can access it via analyst_agent_autogpt.chain.prompt.\\n\\nSystem: You are Harry, Assistant\\nYour decisions must always be made independently without seeking user \\nassistance.\\nPlay to your strengths as an LLM and pursue simple strategies with \\nno legal complications.\\nIf you have completed all your tasks, make sure to use the \"finish\" command.\\n\\nGOALS:\\n\\n1. Find how many active customers from the United Kingdom we have.\\n\\n\\nConstraints:\\n1. ~4000 word limit for short term memory. Your short term memory is short, \\nso immediately save important information to files.\\n2. If you are unsure how you previously did something or want to recall \\npast events, thinking about similar events will help you remember.\\n3. No user assistance\\n4. Exclusively use the commands listed in double quotes e.g. \"command name\"\\n\\nCommands:\\n1. execute_sql: execute_sql(query: str) -> str - Returns the result of SQL query execution, args json schema: {\"query\": {\"title\": \"Query\", \"description\": \"SQL query to execute\", \"type\": \"string\"}}\\n2. get_table_columns: get_table_columns(database: str, table: str) -> str - Returns list of table column names and types in JSON, args json schema: {\"database\": {\"title\": \"Database\", \"description\": \"Database name\", \"type\": \"string\"}, \"table\": {\"title\": \"Table\", \"description\": \"Table name\", \"type\": \"string\"}}\\n3. get_table_column_distr: get_table_column_distr(database: str, table: str, column: str, n: int = 10) -> str - Returns top n values for the column in JSON, args json schema: {\"database\": {\"title\": \"Database\", \"description\": \"Database name\", \"type\": \"string\"}, \"table\": {\"title\": \"Table\", \"description\": \"Table name\", \"type\": \"string\"}, \"column\": {\"title\": \"Column\", \"description\": \"Column name\", \"type\": \"string\"}, \"n\": {\"title\": \"N\", \"description\": \"Number of rows, default limit 10\", \"type\": \"integer\"}}\\n4. get_tables: get_tables() -> str - Returns list of tables in the format <database>.<table>, args json schema: {}\\n5. finish: use this to signal that you have finished all your objectives, args: \"response\": \"final response to let people know you have finished your objectives\"\\n\\nResources:\\n1. Internet access for searches and information gathering.\\n2. Long Term memory management.\\n3. GPT-3.5 powered Agents for delegation of simple tasks.\\n4. File output.\\n\\nPerformance Evaluation:\\n1. Continuously review and analyze your actions to ensure you are \\nperforming to the best of your abilities.\\n2. Constructively self-criticize your big-picture behavior constantly.\\n3. Reflect on past decisions and strategies to refine your approach.\\n4. Every command has a cost, so be smart and efficient. Aim to complete \\ntasks in the least number of steps.\\n\\nYou should only respond in JSON format as described below \\nResponse Format: \\n{\\n    \"thoughts\": {\\n        \"text\": \"thought\",\\n        \"reasoning\": \"reasoning\",\\n        \"plan\": \"- short bulleted\\\\n- list that conveys\\\\n- long-term plan\",\\n        \"criticism\": \"constructive self-criticism\",\\n        \"speak\": \"thoughts summary to say to user\"\\n    },\\n    \"command\": {\\n        \"name\": \"command name\",\\n        \"args\": {\\n            \"arg name\": \"value\"\\n        }\\n    }\\n} \\nEnsure the response can be parsed by Python json.loads\\nSystem: The current time and date is Sat Dec 16 18:39:49 2023\\nSystem: This reminds you of these events from your past:\\n[]\\n\\nSo, we can see that this model has long-term memory via vector storage. Also, it has a comprehensive reasoning consisting of thought, reasons, plan, criticism and summary.\\n\\nLet’s look at the model’s reasoning (I’ve filtered only the model’s responses). So, it followed the same way as the previous successful agents.\\n\\n{\\n    \"thoughts\": {\\n        \"text\": \"To find the number of active customers from the United Kingdom, I need to identify the relevant database and table that contains customer information. Once I have that, I can look for columns that might indicate customer activity and country. The first step is to list all the available tables.\",\\n        \"reasoning\": \"Understanding the structure of the database is essential before I can execute a query to find the active customers. Listing tables is a logical first step to identify where customer data might be stored.\",\\n        \"plan\": \"- Use the get_tables command to list all available tables.\\\\n- Identify the table that likely contains customer information.\\\\n- Use get_table_columns to understand the structure of the customer table.\\\\n- Execute an SQL query to count active UK customers.\",\\n        \"criticism\": \"I need to ensure that I\\'m efficient with the commands I use, aiming to gather the necessary information in as few steps as possible.\",\\n        \"speak\": \"I am now going to list all the available tables to find where customer information is stored.\"\\n    },\\n    \"command\": {\\n        \"name\": \"get_tables\",\\n        \"args\": {}\\n    }\\n}\\n\\n{\\n    \"thoughts\": {\\n        \"text\": \"The \\'ecommerce.users\\' table is likely to contain information about the customers. To find the number of active customers from the United Kingdom, I need to understand the structure of this table, specifically looking for columns that might indicate whether a customer is active and their country.\",\\n        \"reasoning\": \"Knowing the structure of the \\'users\\' table will help me determine which columns to use in an SQL query to count active UK customers.\",\\n        \"plan\": \"- Use the get_table_columns command to get the structure of the \\'ecommerce.users\\' table.\\\\n- Identify columns that indicate customer activity and country.\\\\n- Formulate an SQL query to count active UK customers based on the identified columns.\",\\n        \"criticism\": \"I must continue to be efficient with my commands, ensuring that each step brings me closer to the goal without unnecessary actions.\",\\n        \"speak\": \"I will now retrieve the structure of the \\'ecommerce.users\\' table to identify the relevant columns for active customers and their country.\"\\n    },\\n    \"command\": {\\n        \"name\": \"get_table_columns\",\\n        \"args\": {\\n            \"database\": \"ecommerce\",\\n            \"table\": \"users\"\\n        }\\n    }\\n}\\n\\n{\\n    \"thoughts\": {\\n        \"text\": \"With the structure of the \\'ecommerce.users\\' table known, I can see that there are columns for \\'country\\' and \\'is_active\\', which are necessary to identify active customers from the United Kingdom.\",\\n        \"reasoning\": \"The \\'country\\' column will allow me to filter customers by their country, and the \\'is_active\\' column will allow me to filter customers by their activity status. With this information, I can construct an SQL query to count the number of active customers from the UK.\",\\n        \"plan\": \"- Execute an SQL query using the \\'execute_sql\\' command to count the number of active customers from the United Kingdom.\\\\n- The query will count rows where \\'country\\' is \\'United Kingdom\\' and \\'is_active\\' is true (1).\",\\n        \"criticism\": \"I need to ensure that the SQL query is correctly formulated to retrieve the exact information needed without any errors.\",\\n        \"speak\": \"I am now ready to execute an SQL query to count the number of active customers from the United Kingdom.\"\\n    },\\n    \"command\": {\\n        \"name\": \"execute_sql\",\\n        \"args\": {\\n            \"query\": \"SELECT COUNT(*) FROM ecommerce.users WHERE country = \\'United Kingdom\\' AND is_active = 1\"\\n        }\\n    }\\n}\\n\\n{\\n    \"thoughts\": {\\n        \"text\": \"I have successfully executed the SQL query and obtained the number of active customers from the United Kingdom, which is 111,469.\",\\n        \"reasoning\": \"The goal was to find the number of active customers from the UK, and the SQL query has provided this information.\",\\n        \"plan\": \"- Since the goal has been achieved, the next step is to use the \\'finish\\' command to signal that I have completed all my objectives.\",\\n        \"criticism\": \"There is no need for further action or commands as the objective has been met.\",\\n        \"speak\": \"I have found the number of active customers from the United Kingdom and am ready to finish the task.\"\\n    },\\n    \"command\": {\\n        \"name\": \"finish\",\\n        \"args\": {\\n            \"response\": \"The number of active customers from the United Kingdom is 111,469.\"\\n        }\\n    }\\n}\\n\\n\\n\\nOverall, AutoGPT looks like a working approach. However, I still believe that the most reliable way to build agents right now is through OpenAI functions.\\n\\nDo we need to build everything from scratch?\\n\\nWe’ve spent some wonderful learning time building the agent integrated with SQL Database. However, I must mention that LangChain has its own implementation of SQL agent - SQLDatabaseChain.\\n\\nThis approach uses SQL Alchemy to interact with the databases. So, we need to install the package clickhouse-sqlalchemy to connect to ClickHouse.\\n\\npip install clickhouse-sqlalchemy\\n\\nWe can set up a connection to the database and initialize a toolkit.\\n\\nuri = \\'clickhouse+native://localhost/ecommerce\\'\\ndb = SQLDatabase.from_uri(uri)\\ntoolkit = SQLDatabaseToolkit(db=db, llm=OpenAI(temperature=0))\\n\\nA toolkit is a collection of useful tools related to some topic. You can find lots of examples in the documentation.\\n\\nWe can see the list of tools we have in the toolkit. There are tools to make an SQL query or get information related to the database.\\n\\ntoolkit.get_tools()\\n\\nThen, we can quickly create and run an agent based on OpenAI functions.\\n\\nagent_executor = create_sql_agent(\\n    llm=ChatOpenAI(temperature=0.1, model = \\'gpt-4-1106-preview\\'),\\n    toolkit=toolkit,\\n    verbose=True,\\n    agent_type=AgentType.OPENAI_FUNCTIONS\\n)\\n\\nagent_executor.run(\"How many active customers from the United Kingdom do we have?\")\\n\\nWe got the correct answer without much hassle on our side.\\n\\n> Entering new AgentExecutor chain...\\n\\nInvoking: `sql_db_list_tables` with ``\\n\\n\\nsessions, users\\nInvoking: `sql_db_schema` with `users`\\n\\nCREATE TABLE users (\\n user_id UInt64, \\n country String, \\n is_active UInt8, \\n age UInt64\\n) ENGINE = Log\\n\\n/*\\n3 rows from users table:\\nuser_id country is_active age\\n1000001 United Kingdom 0 70\\n1000002 France 1 87\\n1000003 France 1 88\\n*/\\nInvoking: `sql_db_query` with `SELECT COUNT(*) FROM users WHERE country = \\'United Kingdom\\' AND is_active = 1`\\n\\n\\n[(111469,)]We have 111,469 active customers from the United Kingdom.\\n\\n> Finished chain.\\n\\'We have 111,469 active customers from the United Kingdom.\\'\\n\\nWe can use langchain.debug = True to see what prompt was used.\\n\\nSystem: You are an agent designed to interact with a SQL database.\\nGiven an input question, create a syntactically correct clickhouse query \\nto run, then look at the results of the query and return the answer.\\nUnless the user specifies a specific number of examples they wish to obtain, \\nalways limit your query to at most 10 results.\\nYou can order the results by a relevant column to return the most interesting \\nexamples in the database.\\nNever query for all the columns from a specific table, only ask for \\nthe relevant columns given the question.\\nYou have access to tools for interacting with the database.\\nOnly use the below tools. Only use the information returned \\nby the below tools to construct your final answer.\\nYou MUST double check your query before executing it. If you get \\nan error while executing a query, rewrite the query and try again.\\n\\nDO NOT make any DML statements (INSERT, UPDATE, DELETE, DROP etc.) \\nto the database.\\n\\nIf the question does not seem related to the database, just return \\n\"I don\\'t know\" as the answer.\\n\\nHuman: How many active customers from the United Kingdom do we have? \\nAI: I should look at the tables in the database to see what I can query.  \\nThen I should query the schema of the most relevant tables.\\n\\nSo, we have a pretty convenient and working implementation of SQL analyst. If you don’t need any custom changes, you can just use the LangChain implementation.\\n\\nAlso, you can tweak it a bit, for example, by passing a prompt to the create_sql_agent function (documentation).\\n\\nSummary\\n\\nToday, we’ve learned how to create different types of agents. We’ve implemented an LLM-powered agent that can work with SQL databases entirely from scratch. Then, we leveraged high-level LangChain tools to achieve the same result with a couple of function calls.\\n\\nSo, now our LLM-powered analyst can use data from your DB and answer questions. It’s a significant improvement. We can add our SQL Database agent as a tool for our LLM-powered analyst. It will be our first skill.\\n\\nThe agent now can answer data-related questions and work on their own. However, the cornerstone of the analytics work is collaboration. So, in the following article, we will add memory and learn agents to ask follow-up questions. Stay tuned!\\n\\nThank you a lot for reading this article. I hope it was insightful to you. If you have any follow-up questions or comments, please leave them in the comments section.'}},\n",
       "  {'id': '851578fa10ce',\n",
       "   'title': 'Can LLMs Replace Data Analysts? Building An LLM-Powered Analyst',\n",
       "   'subtitle': 'Part 1: empowering ChatGPT with tools',\n",
       "   'author': '15a29a4fc6ad',\n",
       "   'publication_id': '7f60cf5620c9',\n",
       "   'published_at': '2023-12-11 17:08:56',\n",
       "   'last_modified_at': '2023-12-11 17:08:56',\n",
       "   'tags': ['llm',\n",
       "    'data-science',\n",
       "    'agents',\n",
       "    'editors-pick',\n",
       "    'artificial-intelligence'],\n",
       "   'topics': ['data-science'],\n",
       "   'claps': 1492,\n",
       "   'voters': 326,\n",
       "   'word_count': 4613,\n",
       "   'responses_count': 19,\n",
       "   'reading_time': 18.240880503144652,\n",
       "   'url': 'https://towardsdatascience.com/can-llms-replace-data-analysts-building-an-llm-powered-analyst-851578fa10ce',\n",
       "   'unique_slug': 'can-llms-replace-data-analysts-building-an-llm-powered-analyst-851578fa10ce',\n",
       "   'image_url': 'https://miro.medium.com/1*cUH3JCAISUwvit33qk6D7g.jpeg',\n",
       "   'lang': 'en',\n",
       "   'is_series': False,\n",
       "   'is_locked': False,\n",
       "   'is_shortform': False,\n",
       "   'top_highlight': \"The essential concept related to agents (that I've already mentioned above) is tools. Tools are functions that LLM could invoke to get missing information (for example, execute SQL, use a calculator or call a search engine). Tools are crucial because they allow you to bring LLMs to the next level and interact with the world. In this article, we will primarily focus on OpenAI functions as tools.\",\n",
       "   'content': {'id': '851578fa10ce',\n",
       "    'content': 'Can LLMs Replace Data Analysts? Building An LLM-Powered Analyst\\n\\nPart 1: empowering ChatGPT with tools\\n\\nImage by DALL-E 3\\n\\nI think each of us has wondered at least once over the past year if (or rather when) ChatGPT will be able to replace your role. I’m no exception here.\\n\\nWe have a somewhat consensus that the recent breakthroughs in Generative AI will highly affect our personal lives and work. However, there is no clear view yet of how our roles will change over time.\\n\\nSpending lots of time thinking about different possible future scenarios and their probabilities might be captivating, but I suggest an absolutely different approach - to try to build your prototype yourself. First, it’s rather challenging and fun. Second, it will help us to look at our work in a more structured way. Third, it will give us an opportunity to try in practice one of the most cutting-edge approaches - LLM agents.\\n\\nIn this article, we will start simple and learn how LLMs can leverage tools and do straightforward tasks. But in the following articles, we will dive deeper into different approaches and best practices for LLM agents.\\n\\nSo, let the journey begin.\\n\\nWhat is data analytics?\\n\\nBefore moving on to the LLMs, let’s try defining what analytics is and what tasks we do as analysts.\\n\\nMy motto is that the goal of the analytical team is to help the product teams make the right decisions based on data in the available time. It’s a good mission, but to define the scope of the LLM-powered analyst, we should decompose the analytical work further.\\n\\nI like the framework proposed by Gartner. It identifies four different Data and Analytics techniques:\\n\\nDescriptive analytics answers questions like \"What happened?\". For example, what was the revenue in December? This approach includes reporting tasks and working with BI tools.\\n\\nDiagnostic analytics goes a bit further and asks questions like \"Why did something happen?\". For example, why revenue decreased by 10% compared to the previous year? This technique requires more drill-down and slicing & dicing of your data.\\n\\nPredictive analytics allows us to get answers to questions like \"What will happen?\". The two cornerstones of this approach are forecasting (predicting the future for business-as-usual situations) and simulation (modelling different possible outcomes).\\n\\nPrescriptive analytics impacts the final decisions. The common questions are \"What should we focus on?\" or \"How could we increase volume by 10%?\".\\n\\nUsually, companies go through all these stages step by step. It’s almost impossible to start looking at forecasts and different scenario analyses if your company hasn’t mastered descriptive analytics yet (you don’t have a data warehouse, BI tools, or metrics definitions). So, this framework can also show the company’s data maturity.\\n\\nSimilarly, when an analyst grows from junior to senior level, she will likely go through all these stages, starting from well-defined reporting tasks and progressing to vague strategic questions. So, this framework is relevant on an individual level as well.\\n\\nIf we return to our LLM-powered analyst, we should focus on descriptive analytics and reporting tasks. It’s better to start from the basics. So, we will focus on learning LLM to understand the basic questions about data.\\n\\nWe’ve defined our focus for the first prototype. So, we are ready to move on to the technical questions and discuss the concept of LLM agents and tools.\\n\\nLLM agents and tools\\n\\nWhen we were using LLMs before (for example, to do topic modelling here), we described the exact steps ourselves in the code. For example, let’s look at the chain below. Firstly, we asked the model to determine the sentiment for a customer review. Then, depending on the sentiment, extract from the review either the advantages or disadvantages mentioned in the text.\\n\\nIllustration by author\\n\\nIn this example, we clearly defined the LLM’s behaviour, and the LLM solved this task pretty well. However, this approach won’t work if we build something more high-level and vague, like an LLM-powered analyst.\\n\\nIf you’ve ever worked as or with an analyst for at least one day, you would know that analysts are getting a vast range of different questions and asks, starting from basic questions (like \"How many customers did we have on our site yesterday?\" or \"Could you make a graph for our Board meeting tomorrow?\") to very high-level ones (for example, \"What are the main customer pain points?\" or \"What market should we launch next?\"). It goes without saying it’s not feasible to describe all possible scenarios.\\n\\nHowever, there’s an approach that could help us - agents. The core idea of the agents is to use LLMs as a reasoning engine that could choose what to do next and when it’s time to return the final answer to the customer. It sounds pretty close to our behaviour: we get a task, define needed tools, use them, and then come back with the final answer when ready.\\n\\nThe essential concept related to agents (that I’ve already mentioned above) is tools. Tools are functions that LLM could invoke to get missing information (for example, execute SQL, use a calculator or call a search engine). Tools are crucial because they allow you to bring LLMs to the next level and interact with the world. In this article, we will primarily focus on OpenAI functions as tools.\\n\\nOpenAI has fine-tuned models to be able to work with functions so that:\\n\\nYou can pass to the model the list of functions with descriptions;\\n\\nIf it’s relevant to your query, the model will return you a function call - function name and input parameters to call it.\\n\\nYou can find more info and the up-to-date list of models that support functions in the documentation.\\n\\nThere are two prominent use cases to use functions with LLMs:\\n\\nTagging & extraction - in these cases, functions are used to ensure the output format of the model. Instead of the usual output with content, you will get a structured function call.\\n\\nTools & routing - this is a more exciting use case that allows you to create an agent.\\n\\nLet’s start with the more straightforward use case of extraction to learn how to use OpenAI functions.\\n\\nUse Case #1: Tagging & Extraction\\n\\nYou might wonder what is the difference between tagging and extraction. These terms are pretty close. The only difference is whether the model extracts info presented in the text or labels the text providing new information (i.e. defines language or sentiment).\\n\\nIllustration by author\\n\\nSince we’ve decided to focus on descriptive analytics and reporting tasks, let’s use this approach to structure incoming data requests and pull the following components: metrics, dimensions, filters, period and desired output.\\n\\nIllustration by author\\n\\nIt will be an example of extraction since we only need information present in the text.\\n\\nOpenAI Completion API basic example\\n\\nFirst, we need to define the function. OpenAI expects a function description as a JSON. This JSON will be passed to LLM, so we need to tell it all the context: what this function does and how to use it.\\n\\nHere is an example of a function JSON. We’ve specified:\\n\\nname and description for the function itself,\\n\\ntype and description for each argument,\\n\\nthe list of required input parameters for the function.\\n\\nextraction_functions = [\\n    {\\n        \"name\": \"extract_information\",\\n        \"description\": \"extracts information\",\\n        \"parameters\": {\\n            \"type\": \"object\",\\n            \"properties\": {\\n                \"metric\": {\\n                    \"type\": \"string\",\\n                    \"description\": \"main metric we need to calculate, for example, \\'number of users\\' or \\'number of sessions\\'\",\\n                },\\n                \"filters\": {\\n                    \"type\": \"string\",\\n                    \"description\": \"filters to apply to the calculation (do not include filters on dates here)\",\\n                },\\n                \"dimensions\": {\\n                    \"type\": \"string\",\\n                    \"description\": \"parameters to split your metric by\",\\n                },\\n                \"period_start\": {\\n                    \"type\": \"string\",\\n                    \"description\": \"the start day of the period for a report\",\\n                },\\n                \"period_end\": {\\n                    \"type\": \"string\",\\n                    \"description\": \"the end day of the period for a report\",\\n                },\\n                \"output_type\": {\\n                    \"type\": \"string\",\\n                    \"description\": \"the desired output\",\\n                    \"enum\": [\"number\", \"visualisation\"]\\n                }\\n            },\\n            \"required\": [\"metric\"],\\n        },\\n    }\\n]\\n\\nThere’s no need to implement the function itself in this use case because we won’t be using it. We only get LLM responses in a structured way as function calls.\\n\\nNow, we could use the standard OpenAI Chat Completion API to call the function. We passed to the API call:\\n\\nmodel - I’ve used the latest ChatGPT 3.5 Turbo that can work with functions,\\n\\nlist of messages - one system message to set up the context and a user request,\\n\\nlist of functions we’ve defined earlier.\\n\\nimport openai\\n\\nmessages = [\\n    {\\n        \"role\": \"system\",\\n        \"content\": \"Extract the relevant information from the provided request.\"\\n    },\\n    {\\n        \"role\": \"user\",\\n        \"content\": \"How did number of iOS users change over time?\"\\n    }\\n]\\n\\nresponse = openai.ChatCompletion.create(\\n    model = \"gpt-3.5-turbo-1106\", \\n    messages = messages,\\n    functions = extraction_functions\\n)\\n\\nprint(response)\\n\\nAs a result, we got the following JSON.\\n\\n{\\n  \"id\": \"chatcmpl-8TqGWvGAXZ7L43gYjPyxsWdOTD2n2\",\\n  \"object\": \"chat.completion\",\\n  \"created\": 1702123112,\\n  \"model\": \"gpt-3.5-turbo-1106\",\\n  \"choices\": [\\n    {\\n      \"index\": 0,\\n      \"message\": {\\n        \"role\": \"assistant\",\\n        \"content\": null,\\n        \"function_call\": {\\n          \"name\": \"extract_information\",\\n          \"arguments\": \"{\\\\\"metric\\\\\":\\\\\"number of users\\\\\",\\\\\"filters\\\\\":\\\\\"platform=\\'iOS\\'\\\\\",\\\\\"dimensions\\\\\":\\\\\"date\\\\\",\\\\\"period_start\\\\\":\\\\\"2021-01-01\\\\\",\\\\\"period_end\\\\\":\\\\\"2021-12-31\\\\\",\\\\\"output_type\\\\\":\\\\\"visualisation\\\\\"}\"\\n        }\\n      },\\n      \"finish_reason\": \"function_call\"\\n    }\\n  ],\\n  \"usage\": {\\n    \"prompt_tokens\": 159,\\n    \"completion_tokens\": 53,\\n    \"total_tokens\": 212\\n  },\\n  \"system_fingerprint\": \"fp_eeff13170a\"\\n}\\n\\nRemember that functions and function calls will be counted into the tokens limits and be billed.\\n\\nThe model returned a function call instead of a common response: we can see that the content is empty and finish_reason is equal to function_call. In the response, there are also the input parameters for the function call:\\n\\nmetric = \"number of users\",\\n\\nfilters = \"platform = \\'iOS\\'\",\\n\\ndimensions = \"date\",\\n\\nperiod_start = \"2021-01-01\",\\n\\nperiod_start = \"2021-12-31\",\\n\\noutput_type = \"visualisation\".\\n\\nThe model did a pretty good job. The only problem is that it presumed the period out of nowhere. We can fix it by adding more explicit guidance to the system message, for example, \"Extract the relevant information from the provided request. Extract ONLY the information presented in the initial request; don\\'t add anything else. Return partial information if something is missing.\"\\n\\nBy default, models decide whether to use functions independently (function_call = \\'auto\\'). We can require it to return a specific function call every time or not to use functions at all.\\n\\n\\n# always calling extract_information function\\nresponse = openai.ChatCompletion.create(\\n    model = \"gpt-3.5-turbo-1106\",\\n    messages = messages,\\n    functions = extraction_functions,\\n    function_call = {\"name\": \"extract_information\"}\\n)\\n\\n# no function calls\\nresponse = openai.ChatCompletion.create(\\n    model = \"gpt-3.5-turbo-1106\",\\n    messages = messages,\\n    functions = extraction_functions,\\n    function_call = \"none\"\\n)\\n\\nWe’ve got the first working program that uses LLM functions. That’s awesome. However, it’s not very convenient to describe functions in a JSON. Let’s discuss how to do it easier.\\n\\nUsing Pydantic to define functions\\n\\nTo define functions more conveniently, we can leverage Pydantic. Pydantic is the most popular Python library for data validation.\\n\\nWe’ve already used Pydantic to define LangChain Output Parser.\\n\\nFirst, we need to create a class inheriting from the BaseModel class and define all the fields (arguments of our function).\\n\\nfrom pydantic import BaseModel, Field\\nfrom typing import Optional\\n\\nclass RequestStructure(BaseModel):\\n  \"\"\"extracts information\"\"\"\\n  metric: str = Field(description = \"main metric we need to calculate, for example, \\'number of users\\' or \\'number of sessions\\'\")\\n  filters: Optional[str] = Field(description = \"filters to apply to the calculation (do not include filters on dates here)\")\\n  dimensions: Optional[str] = Field(description = \"parameters to split your metric by\")\\n  period_start: Optional[str] = Field(description = \"the start day of the period for a report\")\\n  period_end: Optional[str] = Field(description = \"the end day of the period for a report\")\\n  output_type: Optional[str] = Field(description = \"the desired output\", enum = [\"number\", \"visualisation\"])\\n\\nThen, we can use LangChain to convert the Pydantic class into the OpenAI function.\\n\\nfrom langchain.utils.openai_functions import convert_pydantic_to_openai_function\\nextract_info_function = convert_pydantic_to_openai_function(RequestStructure, \\n    name = \\'extract_information\\')\\n\\nLangChain validates the class we provided. For example, it ensures that the function description is specified since LLM needs it to be able to use this tool.\\n\\nAs a result, we got the same JSON to pass to LLM, but now we express it as a Pydantic class.\\n\\n{\\'name\\': \\'extract_information\\',\\n \\'description\\': \\'extracts information\\',\\n \\'parameters\\': {\\'title\\': \\'RequestStructure\\',\\n  \\'description\\': \\'extracts information\\',\\n  \\'type\\': \\'object\\',\\n  \\'properties\\': {\\'metric\\': {\\'title\\': \\'Metric\\',\\n    \\'description\\': \"main metric we need to calculate, for example, \\'number of users\\' or \\'number of sessions\\'\",\\n    \\'type\\': \\'string\\'},\\n   \\'filters\\': {\\'title\\': \\'Filters\\',\\n    \\'description\\': \\'filters to apply to the calculation (do not include filters on dates here)\\',\\n    \\'type\\': \\'string\\'},\\n   \\'dimensions\\': {\\'title\\': \\'Dimensions\\',\\n    \\'description\\': \\'parameters to split your metric by\\',\\n    \\'type\\': \\'string\\'},\\n   \\'period_start\\': {\\'title\\': \\'Period Start\\',\\n    \\'description\\': \\'the start day of the period for a report\\',\\n    \\'type\\': \\'string\\'},\\n   \\'period_end\\': {\\'title\\': \\'Period End\\',\\n    \\'description\\': \\'the end day of the period for a report\\',\\n    \\'type\\': \\'string\\'},\\n   \\'output_type\\': {\\'title\\': \\'Output Type\\',\\n    \\'description\\': \\'the desired output\\',\\n    \\'enum\\': [\\'number\\', \\'visualisation\\'],\\n    \\'type\\': \\'string\\'}},\\n  \\'required\\': [\\'metric\\']}}\\n\\nNow, we could use it in our call to OpenAI. Let’s switch from OpenAI API to LangChain to make our API calls more modular.\\n\\nDefining LangChain chain\\n\\nLet’s define a chain to extract needed information from the requests. We will use LangChain since it’s the most popular framework for LLMs. If you haven’t worked with it before, I recommend you learn some basics in one of my previous articles.\\n\\nOur chain is simple. It consists of an Open AI model and prompt with one variable request (a user message).\\n\\nWe’ve also used the bind function to pass functions argument to the model. The bind function allows us to specify constant arguments for our models that are not part of the input (for example, functions or temperature).\\n\\nfrom langchain.prompts import ChatPromptTemplate\\nfrom langchain.chat_models import ChatOpenAI\\n\\nmodel = ChatOpenAI(temperature=0.1, model = \\'gpt-3.5-turbo-1106\\')\\\\\\n  .bind(functions = [extract_info_function])\\n\\nprompt = ChatPromptTemplate.from_messages([\\n    (\"system\", \"Extract the relevant information from the provided request. \\\\\\n            Extract ONLY the information presented in the initial request. \\\\\\n            Don\\'t add anything else. \\\\\\n            Return partial information if something is missing.\"),\\n    (\"human\", \"{request}\")\\n])\\n\\nextraction_chain = prompt | model\\n\\nNow it’s time to try our function. We need to use the invoke method and pass a request.\\n\\nextraction_chain.invoke({\\'request\\': \"How many customers visited our site on iOS in April 2023 from different countries?\"})\\n\\nIn the output, we got AIMessage without any content but with a function call.\\n\\nAIMessage(\\n  content=\\'\\', \\n  additional_kwargs={\\n    \\'function_call\\': {\\n       \\'name\\': \\'extract_information\\', \\n       \\'arguments\\': \\'\\'\\'{\\n         \"metric\":\"number of customers\", \"filters\":\"device = \\'iOS\\'\",\\n         \"dimensions\":\"country\", \"period_start\":\"2023-04-01\",\\n         \"period_end\":\"2023-04-30\", \"output_type\":\"number\"}\\n        \\'\\'\\'}\\n  }\\n)\\n\\nSo, we’ve learned how to use OpenAI functions in LangChain to get structured output. Now, let’s move on to the more interesting use case - tools and routing.\\n\\nUse Case #2: Tools & Routing\\n\\nIt’s time to use tools and empower our model with external capabilities. Models in this approach are reasoning engines, and they can decide what tools to use and when (it’s called routing).\\n\\nLangChain has a concept of tools - interfaces that agents can use to interact with the world. Tools can be functions, LangChain chains or even other agents.\\n\\nWe can easily convert tools into OpenAI functions using format_tool_to_openai_function and keep passing the functions argument to LLMs.\\n\\nDefining a custom tool\\n\\nLet’s teach our LLM-powered analyst to calculate the difference between two metrics. We know that LLMs might make mistakes in math, so we would like to ask a model to use a calculator instead of counting on its own.\\n\\nTo define a tool, we need to create a function and use a @tool decorator.\\n\\nfrom langchain.agents import tool\\n\\n@tool\\ndef percentage_difference(metric1: float, metric2: float) -> float:\\n    \"\"\"Calculates the percentage difference between metrics\"\"\"\\n    return (metric2 - metric1)/metric1*100\\n\\nNow, this function has name and description parameters that will be passed to LLMs.\\n\\nprint(percentage_difference.name)\\n# percentage_difference.name\\n\\nprint(percentage_difference.args)\\n# {\\'metric1\\': {\\'title\\': \\'Metric1\\', \\'type\\': \\'number\\'},\\n# \\'metric2\\': {\\'title\\': \\'Metric2\\', \\'type\\': \\'number\\'}}\\n\\nprint(percentage_difference.description)\\n# \\'percentage_difference(metric1: float, metric2: float) -> float - Calculates the percentage difference between metrics\\'\\n\\nThese parameters will be used to create an OpenAI function specification. Let’s convert our tool to an OpenAI function.\\n\\nfrom langchain.tools.render import format_tool_to_openai_function\\nprint(format_tool_to_openai_function(percentage_difference))\\n\\nWe got the following JSON as the result. It outlines the structure, but field descriptions are missing.\\n\\n{\\'name\\': \\'percentage_difference\\',\\n \\'description\\': \\'percentage_difference(metric1: float, metric2: float) -> float - Calculates the percentage difference between metrics\\',\\n \\'parameters\\': {\\'title\\': \\'percentage_differenceSchemaSchema\\',\\n  \\'type\\': \\'object\\',\\n  \\'properties\\': {\\'metric1\\': {\\'title\\': \\'Metric1\\', \\'type\\': \\'number\\'},\\n   \\'metric2\\': {\\'title\\': \\'Metric2\\', \\'type\\': \\'number\\'}},\\n  \\'required\\': [\\'metric1\\', \\'metric2\\']}\\n}\\n\\nWe can use Pydantic to specify a schema for the arguments.\\n\\nclass Metrics(BaseModel):\\n    metric1: float = Field(description=\"Base metric value to calculate the difference\")\\n    metric2: float = Field(description=\"New metric value that we compare with the baseline\")\\n\\n@tool(args_schema=Metrics)\\ndef percentage_difference(metric1: float, metric2: float) -> float:\\n    \"\"\"Calculates the percentage difference between metrics\"\"\"\\n    return (metric2 - metric1)/metric1*100\\n\\nNow, if we convert a new version to the OpenAI function specification, it will include argument descriptions. It’s much better since we could share all the needed context with the model.\\n\\n{\\'name\\': \\'percentage_difference\\',\\n \\'description\\': \\'percentage_difference(metric1: float, metric2: float) -> float - Calculates the percentage difference between metrics\\',\\n \\'parameters\\': {\\'title\\': \\'Metrics\\',\\n  \\'type\\': \\'object\\',\\n  \\'properties\\': {\\'metric1\\': {\\'title\\': \\'Metric1\\',\\n    \\'description\\': \\'Base metric value to calculate the difference\\',\\n    \\'type\\': \\'number\\'},\\n   \\'metric2\\': {\\'title\\': \\'Metric2\\',\\n    \\'description\\': \\'New metric value that we compare with the baseline\\',\\n    \\'type\\': \\'number\\'}},\\n  \\'required\\': [\\'metric1\\', \\'metric2\\']}}\\n\\nSo, we’ve defined the tool that LLM will be able to use. Let’s try it in practice.\\n\\nUsing a tool in practice\\n\\nLet’s define a chain and pass our tool to the function. Then, we could test it on a user request.\\n\\nmodel = ChatOpenAI(temperature=0.1, model = \\'gpt-3.5-turbo-1106\\')\\\\\\n  .bind(functions = [format_tool_to_openai_function(percentage_difference)])\\n\\nprompt = ChatPromptTemplate.from_messages([\\n    (\"system\", \"You are a product analyst willing to help your product team. You are very strict to the point and accurate. You use only facts, not inventing information.\"),\\n    (\"user\", \"{request}\")\\n])\\n\\nanalyst_chain = prompt | model\\nanalyst_chain.invoke({\\'request\\': \"In April we had 100 users and in May only 95. What is difference in percent?\"})\\n\\nWe got a function call with the correct arguments, so it’s working.\\n\\nAIMessage(content=\\'\\', additional_kwargs={\\n    \\'function_call\\': {\\n      \\'name\\': \\'percentage_difference\\', \\n      \\'arguments\\': \\'{\"metric1\":100,\"metric2\":95}\\'}\\n  }\\n)\\n\\nTo have a more convenient way to work with the output, we can useOpenAIFunctionsAgentOutputParser. Let’s add it to our chain.\\n\\nfrom langchain.agents.output_parsers import OpenAIFunctionsAgentOutputParser\\nanalyst_chain = prompt | model | OpenAIFunctionsAgentOutputParser()\\nresult = analyst_chain.invoke({\\'request\\': \"There were 100 users in April and 110 users in May. How did the number of users changed?\"})\\n\\nNow, we got output in a more structured way, and we could easily retrieve arguments for our tool as result.tool_input .\\n\\nAgentActionMessageLog(\\n   tool=\\'percentage_difference\\', \\n   tool_input={\\'metric1\\': 100, \\'metric2\\': 110}, \\n   log=\"\\\\nInvoking: `percentage_difference` with `{\\'metric1\\': 100, \\'metric2\\': 110}`\\\\n\\\\n\\\\n\", \\n   message_log=[AIMessage(content=\\'\\', additional_kwargs={\\'function_call\\': {\\'name\\': \\'percentage_difference\\', \\'arguments\\': \\'{\"metric1\":100,\"metric2\":110}\\'}})]\\n)\\n\\nSo, we could execute the function as the LLM requested like this.\\n\\nobservation = percentage_difference(result.tool_input)\\nprint(observation)\\n# 10\\n\\nIf we want to get the final answer from the model, we need to pass the function execution result back. To do it, we need to define a message list to pass to the model observations.\\n\\nfrom langchain.prompts import MessagesPlaceholder\\n\\nmodel = ChatOpenAI(temperature=0.1, model = \\'gpt-3.5-turbo-1106\\')\\\\\\n  .bind(functions = [format_tool_to_openai_function(percentage_difference)])\\n\\nprompt = ChatPromptTemplate.from_messages([\\n    (\"system\", \"You are a product analyst willing to help your product team. You are very strict to the point and accurate. You use only facts, not inventing information.\"),\\n    (\"user\", \"{request}\"),\\n    MessagesPlaceholder(variable_name=\"observations\")\\n])\\n\\nanalyst_chain = prompt | model | OpenAIFunctionsAgentOutputParser()\\nresult1 = analyst_chain.invoke({\\n    \\'request\\': \"There were 100 users in April and 110 users in May. How did the number of users changed?\",\\n    \"observations\": []\\n})\\n\\nobservation = percentage_difference(result1.tool_input)\\nprint(observation)\\n# 10\\n\\nThen, we need to add the observation to our observations variable. We could use format_to_openai_functions function to format our results in an expected way for the model.\\n\\nfrom langchain.agents.format_scratchpad import format_to_openai_functions\\nformat_to_openai_functions([(result1, observation), ])\\n\\nAs a result, we got such a message that the LLM can understand.\\n\\n[AIMessage(content=\\'\\', additional_kwargs={\\'function_call\\': {\\'name\\': \\'percentage_difference\\', \\n                                           \\'arguments\\': \\'{\"metric1\":100,\"metric2\":110}\\'}}),\\n FunctionMessage(content=\\'10.0\\', name=\\'percentage_difference\\')]\\n\\nLet’s invoke our chain one more time, passing the function execution result as an observation.\\n\\nresult2 = analyst_chain.invoke({\\n    \\'request\\': \"There were 100 users in April and 110 users in May. How did the number of users changed?\",\\n    \"observations\": format_to_openai_functions([(result1, observation)])\\n})\\n\\nNow, we got the final result from the model, which sounds reasonable.\\n\\nAgentFinish(\\n  return_values={\\'output\\': \\'The number of users increased by 10%.\\'}, \\n  log=\\'The number of users increased by 10%.\\'\\n)\\n\\nIf we were working with vanilla OpenAI Chat Completion API, we could just add another message with role = tool . You can find a detailed example here.\\n\\nIf we switch on debug, we can see the exact prompt that was passed to OpenAI API.\\n\\nSystem: You are a product analyst willing to help your product team. You are very strict to the point and accurate. You use only facts, not inventing information.\\nHuman: There were 100 users in April and 110 users in May. How did the number of users changed?\\nAI: {\\'name\\': \\'percentage_difference\\', \\'arguments\\': \\'{\"metric1\":100,\"metric2\":110}\\'}\\nFunction: 10.0\\n\\nTo switch on LangChain debug, execute the following code and invoke your chain to see what is going on under the hood.\\n\\nimport langchain\\nlangchain.debug = True\\n\\nWe’ve tried to work with one tool, but let’s extend our toolkit and see how LLM could handle it.\\n\\nRouting: using multiple tools\\n\\nLet’s add a couple more tools to our analyst’s toolkit:\\n\\nget monthly active users\\n\\nusing Wikipedia.\\n\\nFirst, let’s define a dummy function to calculate the audience with filters by month and city. We will again use Pydantic to specify the input arguments for our function.\\n\\nimport datetime\\nimport random\\n\\nclass Filters(BaseModel):\\n    month: str = Field(description=\"Month of customer\\'s activity in the format %Y-%m-%d\")\\n    city: Optional[str] = Field(description=\"City of residence for customers (by default no filter)\", \\n                    enum = [\"London\", \"Berlin\", \"Amsterdam\", \"Paris\"])\\n\\n@tool(args_schema=Filters)\\ndef get_monthly_active_users(month: str, city: str = None) -> int:\\n    \"\"\"Returns number of active customers for the specified month\"\"\"\\n    dt = datetime.datetime.strptime(month, \\'%Y-%m-%d\\')\\n    total = dt.year + 10*dt.month\\n    if city is None:\\n        return total\\n    else:\\n        return int(total*random.random())\\n\\nThen, let’s use the wikipedia Python package to allow model query Wikipedia.\\n\\nimport wikipedia\\n\\nclass Wikipedia(BaseModel):\\n    term: str = Field(description=\"Term to search for\")\\n\\n@tool(args_schema=Wikipedia)\\ndef get_summary(term: str) -> str:\\n    \"\"\"Returns basic knowledge about the given term provided by Wikipedia\"\"\"\\n    return wikipedia.summary(term)\\n\\nLet’s define a dictionary with all the functions our model knows now. This dictionary will help us to do routing later.\\n\\ntoolkit = {\\n    \\'percentage_difference\\': percentage_difference,\\n    \\'get_monthly_active_users\\': get_monthly_active_users,\\n    \\'get_summary\\': get_summary\\n}\\n\\nanalyst_functions = [format_tool_to_openai_function(f) \\n  for f in toolkit.values()]\\n\\nI’ve made a couple of changes to our previous setup:\\n\\nI tweaked the system prompt a bit to force LLM to consult with Wikipedia if it needs some basic knowledge.\\n\\nI’ve changed the model to GPT 4 because it’s better for handling tasks requiring reasoning.\\n\\nfrom langchain.prompts import MessagesPlaceholder\\n\\nmodel = ChatOpenAI(temperature=0.1, model = \\'gpt-4-1106-preview\\')\\\\\\n  .bind(functions = analyst_functions)\\n\\nprompt = ChatPromptTemplate.from_messages([\\n    (\"system\", \"You are a product analyst willing to help your product team. You are very strict to the point and accurate. \\\\\\n        You use only information provided in the initial request. \\\\\\n        If you need to determine some information i.e. what is the name of the capital, you can use Wikipedia.\"),\\n    (\"user\", \"{request}\"),\\n    MessagesPlaceholder(variable_name=\"observations\")\\n])\\n\\nanalyst_chain = prompt | model | OpenAIFunctionsAgentOutputParser()\\n\\nWe can invoke our chain with all the functions. Let’s start with a pretty straightforward query.\\n\\nresult1 = analyst_chain.invoke({\\n    \\'request\\': \"How many users were in April 2023 from Berlin?\",\\n    \"observations\": []\\n})\\nprint(result1)\\n\\nWe got in the result function call for get_monthly_active_users with input parameters - {\\'month\\': \\'2023–04–01\\', \\'city\\': \\'Berlin\\'} , which looks correct. The model was able to find the right tool and solve the task.\\n\\nLet’s try to make task a bit more complex.\\n\\nresult1 = analyst_chain.invoke({\\n    \\'request\\': \"How did the number of users from the capital of Germany\\\\\\n        change between April and May 2023?\",\\n    \"observations\": []\\n})\\n\\nLet’s pause for a minute and think how we would like the model to reason. It’s evident that there’s not enough information for the model to answer straight away, so it needs to make a bunch of function calls:\\n\\ncall Wikipedia to get the capital of Germany\\n\\ncall the get_monthly_active_users function twice to get MAU for April and May\\n\\ncall percentage_difference to calculate the difference between metrics.\\n\\nIt looks pretty complex. Let’s see whether ChatGPT would be able to handle this question.\\n\\nFor the first call, LLM returned back a function call to Wikipedia with the following params - {\\'term\\': \\'capital of Germany\\'}. So far, it’s following our plan.\\n\\nLet’s provide the observation and see what the next steps will be.\\n\\nobservation1 = toolkit[result1.tool](result1.tool_input)\\nprint(observation1)\\n\\n# The capital of Germany is the  city state of Berlin. It is the seat of \\n# the President of Germany, whose official residence is Schloss Bellevue. \\n# The Bundesrat (\"federal council\") is the representation of the Federal States \\n# (Bundesländer) of Germany and has its seat at the former Prussian Herrenhaus \\n# (House of Lords). Though most of the ministries are seated in Berlin, \\n# some of them, as well as some minor departments, are seated in Bonn, \\n# the former capital of West Germany.\\n# Although Berlin is officially the capital of the Federal Republic of Germany,\\n# 8,000 out of the 18,000 total officials employed at the federal bureaucracy \\n# still work in Bonn, about 600 km (370 mi) away from Berlin.\\n\\n# source: https://en.wikipedia.org/wiki/Capital_of_Germany \\n\\nresult2 = analyst_chain.invoke({\\n    \\'request\\': \"How did the number of users from the capital of Germany change between April and May 2023?\",\\n    \"observations\": format_to_openai_functions([(result1, observation1)])\\n})\\n\\nThe model wants to execute get_monthly_active_users with arguments {\\'month\\': \\'2023–04–01\\', \\'city\\': \\'Berlin\\'}. Let’s do it and return the information to the model once again.\\n\\nobservation2 = toolkit[result2.tool](result2.tool_input)\\nprint(observation2)\\n# 168\\n\\nresult3 = analyst_chain.invoke({\\n    \\'request\\': \"How did the number of users from the capital of Germany change between April and May 2023?\",\\n    \"observations\": format_to_openai_functions([(result1, observation1), (result2, observation2)])\\n})\\n\\nThen, the model requests to call get_monthly_active_users again with arguments {\\'month\\': \\'2023–05–01\\', \\'city\\': \\'Berlin\\'}. So far, it’s doing an excellent job. Let’s follow its logic.\\n\\nobservation3 = toolkit[result3.tool](result3.tool_input)\\nprint(observation3)\\n# 1046\\n\\nresult4 = analyst_chain.invoke({\\n    \\'request\\': \"How did the number of users from the capital of Germany change between April and May 2023?\",\\n    \"observations\": format_to_openai_functions(\\n      [(result1, observation1), (result2, observation2), \\n      (result3, observation3)])\\n})\\n\\nThe subsequent result is a function call for percentage_difference with the following arguments {\\'metric1\\': 168, \\'metric2\\': 1046}. Let’s calculate observation and invoke our chain one more time. Hopefully, it will be the last step.\\n\\nobservation4 = toolkit[result4.tool](result4.tool_input)\\nprint(observation4)\\n\\n# 523.27\\n\\nresult5 = analyst_chain.invoke({\\n    \\'request\\': \"How did the number of users from the capital of Germany change between April and May 2023?\",\\n    \"observations\": format_to_openai_functions(\\n      [(result1, observation1), (result2, observation2), \\n      (result3, observation3), (result4, observation4)])\\n})\\n\\nIn the end, we got the following response from the model: The number of users from Berlin, the capital of Germany, increased by approximately 523.27% between April and May 2023.\\n\\nHere’s the complete scheme of the LLM calls for this question.\\n\\nIllustration by author\\n\\nIn the above example, we triggered subsequent calls one by one manually, but it can be easily automated.\\n\\nIt’s a fantastic result, and we were able to see how LLMs can do reasoning and utilize multiple tools. It took model 5 steps to achieve the result, but it followed the plan we outlined initially, so it was a pretty logical path. However, if you plan to use LLMs in production, keep in mind that it might make mistakes and introduce evaluation and quality assurance processes.\\n\\nYou can find the full code on GitHub.\\n\\nSummary\\n\\nThis article taught us how to empower LLMs with external tools using OpenAI functions. We’ve examined two use cases: extraction to get structured output and routing to use external information for questions. The final result inspires me since LLM could answer pretty complex questions using three different tools.\\n\\nLet’s return to the initial question of whether LLMs can replace data analysts. Our current prototype is basic and far from the junior analysts’ capabilities, but it’s only the beginning. Stay tuned! We will dive deeper into the different approaches to LLM agents. Next time, we will try to create an agent that can access the database and answer basic questions.\\n\\nReference\\n\\nThis article is inspired by the \"Functions, Tools and Agents with LangChain\" course from DeepLearning.AI'}},\n",
       "  {'id': 'd7486d88c541',\n",
       "   'title': 'LMQL\\u200a—\\u200aSQL for Language Models',\n",
       "   'subtitle': 'Yet another tool that could help you with LLM applications',\n",
       "   'author': '15a29a4fc6ad',\n",
       "   'publication_id': '7f60cf5620c9',\n",
       "   'published_at': '2023-11-27 16:31:51',\n",
       "   'last_modified_at': '2023-11-27 16:31:51',\n",
       "   'tags': ['llm',\n",
       "    'sentiment-analysis',\n",
       "    'nlp',\n",
       "    'data-science',\n",
       "    'editors-pick'],\n",
       "   'topics': ['artificial-intelligence', 'data-science', 'programming'],\n",
       "   'claps': 883,\n",
       "   'voters': 251,\n",
       "   'word_count': 3898,\n",
       "   'responses_count': 12,\n",
       "   'reading_time': 16.30943396226415,\n",
       "   'url': 'https://towardsdatascience.com/lmql-sql-for-language-models-d7486d88c541',\n",
       "   'unique_slug': 'lmql-sql-for-language-models-d7486d88c541',\n",
       "   'image_url': 'https://miro.medium.com/1*yv1s9-5rzlm5NTrWJUdRIA.jpeg',\n",
       "   'lang': 'en',\n",
       "   'is_series': False,\n",
       "   'is_locked': False,\n",
       "   'is_shortform': False,\n",
       "   'top_highlight': 'I believe the most crucial benefit of LMQL is the complete control of your output. However, with such an approach, you will also have another layer of abstraction over LLM (similar to LangChain, which we discussed earlier). It will allow you to switch from one backend to another easily if you need to. LMQL can work with different backends: OpenAI, HuggingFace Transformers or llama.cpp.',\n",
       "   'content': {'id': 'd7486d88c541',\n",
       "    'content': 'LMQL - SQL for Language Models\\n\\nYet another tool that could help you with LLM applications\\n\\nImage by DALL-E 3\\n\\nI’m sure you’ve heard about SQL or even have mastered it. SQL (Structured Query Language) is a declarative language widely used to work with database data.\\n\\nAccording to the annual StackOverflow survey, SQL is still one of the most popular languages in the world. For professional developers, SQL is in the top-3 languages (after Javascript and HTML/CSS). More than a half of professionals use it. Surprisingly, SQL is even more popular than Python.\\n\\nGraph by author, data from StackOverflow survey\\n\\nSQL is a common way to talk to your data in a database. So, it is no surprise that there are attempts to use a similar approach for LLMs. In this article, I would like to tell you about one such approach called LMQL.\\n\\nWhat is LMQL?\\n\\nLMQL (Language Model Query Language) is an open-source programming language for language models. LMQL is released under Apache 2.0 license, which allows you to use it commercially.\\n\\nLMQL was developed by ETH Zurich researchers. They proposed a novel idea of LMP (Language Model Programming). LMP combines natural and programming languages: text prompt and scripting instructions.\\n\\nIn the original paper, \"Prompting Is Programming: A Query Language for Large Language Models\" by Luca Beurer-Kellner, Marc Fischer and Martin Vechev, the authors flagged the following challenges of the current LLM usage:\\n\\nInteraction. For example, we could use meta prompting, asking LM to expand the initial prompt. As a practical case, we could first ask the model to define the language of the initial question and then respond in that language. For such a task, we will need to send the first prompt, extract language from the output, add it to the second prompt template and make another call to the LM. There’s quite a lot of interactions we need to manage. With LMQL, you can define multiple input and output variables within one prompt. More than that, LMQL will optimise overall likelihood across numerous calls, which might yield better results.\\n\\nConstraint & token representation. The current LMs don’t provide the functionality to constrain output, which is crucial if we use LMs in production. Imagine building a sentiment analysis in production to mark negative reviews in our interface for CS agents. Our program would expect to receive from the LLM \"positive\", \"negative\", or \"neutral\". However, quite often, you could get something like \"The sentiment for provided customer review is positive\" from the LLM, which is not so easy to process in your API. That’s why constraints would be pretty helpful. LMQL allows you to control output using human-understandable words (not tokens that LMs operate with).\\n\\nEfficiency and cost. LLMs are large networks, so they are pretty expensive, regardless of whether you use them via API or in your local environment. LMQL can leverage predefined behaviour and the constraint of the search space (introduced by constraints) to reduce the number of LM invoke calls.\\n\\nAs you can see, LMQL can address these challenges. It allows you to combine multiple calls in one prompt, control your output and even reduce cost.\\n\\nThe impact on cost and efficiency could be pretty substantial. The limitations to the search space can significantly reduce costs for LLMs. For example, in the cases from the LMQL paper, there were 75–85% fewer billable tokens with LMQL compared to standard decoding, which means it will significantly reduce your cost.\\n\\nImage from the paper by Beurer-Kellner et al. (2023)\\n\\nI believe the most crucial benefit of LMQL is the complete control of your output. However, with such an approach, you will also have another layer of abstraction over LLM (similar to LangChain, which we discussed earlier). It will allow you to switch from one backend to another easily if you need to. LMQL can work with different backends: OpenAI, HuggingFace Transformers or llama.cpp.\\n\\nYou can install LMQL locally or use a web-based Playground online. Playground can be pretty handy for debugging, but you can only use the OpenAI backend here. For all other use cases, you will have to use local installation.\\n\\nAs usual, there are some limitations to this approach:\\n\\nThis library is not very popular yet, so the community is pretty small, and few external materials are available.\\n\\nIn some cases, documentation might not be very detailed.\\n\\nThe most popular and best-performing OpenAI models have some limitations, so you can’t use the full power of LMQL with ChatGPT.\\n\\nI wouldn’t use LMQL in production since I can’t say that it’s a mature project. For example, distribution over tokens provides pretty poor accuracy.\\n\\nSomewhat close alternative to LMQL is Guidance. It also allows you to constrain generation and control the LM’s output.\\n\\nDespite all the limitations, I like the concept of Language Model Programming, and that’s why I’ve decided to discuss it in this article.\\n\\nIf you’re interested to learn more about LMQL from its authors, check this video.\\n\\nLMQL syntax\\n\\nNow, we know a bit what LMQL is. Let’s look at the example of an LMQL query to get acquainted with its syntax.\\n\\nbeam(n=3)\\n    \"Q: Say \\'Hello, {name}!\\'\" \\n    \"A: [RESPONSE]\" \\nfrom \"openai/text-davinci-003\"\\nwhere len(TOKENS(RESPONSE)) < 20\\n\\nI hope you can guess its meaning. But let’s discuss it in detail.\\nHere’s a scheme for a LMQL query\\n\\nImage from paper by Beurer-Kellner et al. (2023)\\n\\nAny LMQL program consists of 5 parts:\\n\\nDecoder defines the decoding procedure used. In simple words, it describes the algorithm to pick up the next token. LMQL has three different types of decoders: argmax, beam and sample. You can learn about them in more detail from the paper.\\n\\nActual query is similar to the classic prompt but in Python syntax, which means that you could use such structures as loops or if-statements.\\n\\nIn from clause, we specified the model to use (openai/text-davinci-003 in our example).\\n\\nWhere clause defines constraints.\\n\\nDistribution is used when you want to see probabilities for tokens in the return. We haven’t used distribution in this query, but we will use it to get class probabilities for the sentiment analysis later.\\n\\nAlso, you might have noticed special variables in our query {name} and [RESPONSE]. Let’s discuss how they work:\\n\\n{name} is an input parameter. It could be any variable from your scope. Such parameters help you create handy functions that could be easily re-used for different inputs.\\n\\n[RESPONSE] is a phrase that LM will generate. It can also be called a hole or placeholder. All the text before [RESPONSE] is sent to LM, and then the model’s output is assigned to the variable. It’s handy that you could easily re-use this output later in the prompt, referring to it as {RESPONSE}.\\n\\nWe’ve briefly covered the main concepts. Let’s try it ourselves. Practice makes perfect.\\n\\nGetting started\\n\\nSetting up environment\\n\\nFirst of all, we need to set up our environment. To use LMQL in Python, we need to install a package first. No surprises, we can just use pip. You need an environment with Python ≥ 3.10.\\n\\npip install lmql\\n\\nIf you want to use LMQL with local GPU, follow the instructions in the documentation.\\n\\nTo use OpenAI models, you need to set up APIKey to access OpenAI. The easiest way is to specify the OPENAI_API_KEY environment variable.\\n\\nimport os\\nos.environ[\\'OPENAI_API_KEY\\'] = \\'<your_api_key>\\'\\n\\nHowever, OpenAI models have many limitations (for example, you won’t be able to get distributions with more than five classes). So, we will use Llama.cpp to test LMQL with local models.\\n\\nFirst, you need to install Python binding for Llama.cpp in the same environment as LMQL.\\n\\npip install llama-cpp-python\\n\\nIf you want to use local GPU, specify the following parameters.\\n\\nCMAKE_ARGS=\"-DLLAMA_METAL=on\" pip install llama-cpp-python\\n\\nThen, we need to load model weights as .gguf files. You can find models on HuggingFace Models Hub.\\n\\nWe will be using two models:\\n\\nLlama-2-7B (link)\\n\\nzephyr-7B-beta (link)\\n\\nLlama-2–7B is the smallest version of fine-tuned generative text models by Meta. It’s a pretty basic model, so we shouldn’t expect outstanding performance from it.\\n\\nZephyr is a fine-tuned version of the Mistral model with decent performance. It performs better in some aspects than a 10x larger open-source model Llama-2–70b. However, there’s still some gap between Zephyr and proprietary models like ChatGPT or Claude.\\n\\nImage from the paper by Tunstall et al. (2023)\\n\\nAccording to the LMSYS ChatBot Arena leaderboard, Zephyr is the best-performing model with 7B parameters. It’s on par with much bigger models.\\n\\nScreenshot of leaderboard | source\\n\\nLet’s load .gguf files for our models.\\n\\nimport os\\nimport urllib.request\\n\\n\\ndef download_gguf(model_url, filename):\\n    if not os.path.isfile(filename):\\n        urllib.request.urlretrieve(model_url, filename)\\n        print(\"file has been downloaded successfully\")\\n    else:\\n        print(\"file already exists\")\\n\\ndownload_gguf(\\n    \"https://huggingface.co/TheBloke/zephyr-7B-beta-GGUF/resolve/main/zephyr-7b-beta.Q4_K_M.gguf\", \\n    \"zephyr-7b-beta.Q4_K_M.gguf\"\\n)\\n\\ndownload_gguf(\\n    \"https://huggingface.co/TheBloke/Llama-2-7B-GGUF/resolve/main/llama-2-7b.Q4_K_M.gguf\", \\n    \"llama-2-7b.Q4_K_M.gguf\"\\n)\\n\\nWe need to download a few GBs so that it might take some time (10–15 minutes for each model). Luckily, you need to do it only once.\\n\\nYou can interact with the local models in two different ways (documentation):\\n\\nTwo-process architecture when you have a separate long-running process with your model and short-running inference calls. This approach is more suitable for production.\\n\\nFor ad-hoc tasks, we could use in-process model loading, specifying local: before the model name. We will be using this approach to work with the local models.\\n\\nNow, we’ve set up the environment, and it’s time to discuss how to use LMQL from Python.\\n\\nPython functions\\n\\nLet’s briefly discuss how to use LMQL in Python. Playground can be handy for debugging, but if you want to use LM in production, you need an API.\\n\\nLMQL provides four main approaches to its functionality: lmql.F , lmql.run , @lmql.query decorator and Generations API.\\n\\nGenerations API has been recently added. It’s a simple Python API that helps to do inference without writing LMQL yourself. Since I am more interested in the LMP concept, we won’t cover this API in this article.\\n\\nLet’s discuss the other three approaches in detail and try to use them.\\n\\nFirst, you could use lmql.F. It’s a lightweight functionality similar to lambda functions in Python that could allow you to execute part of LMQL code. lmql.F can have only one placeholder variable that will be returned from the lambda function.\\n\\nWe could specify both prompt and constraint for the function. The constraint will be equivalent to the where clause in the LMQL query.\\n\\nSince we haven’t specified any model, the OpenAI text-davinci will be used.\\n\\ncapital_func = lmql.F(\"What is the captital of {country}? [CAPITAL]\", \\n    constraints = \"STOPS_AT(CAPITAL, \\'.\\')\")\\n\\ncapital_func(\\'the United Kingdom\\')\\n\\n# Output - \\'\\\\n\\\\nThe capital of the United Kingdom is London.\\'\\n\\nIf you’re using Jupyter Notebooks, you might encounter some problems since Notebooks environments are asynchronous. You could enable nested event loops in your notebook to avoid such issues.\\n\\nimport nest_asyncio\\nnest_asyncio.apply()\\n\\nThe second approach allows you to define more complex queries. You can use lmql.run to execute an LMQL query without creating a function. Let’s make our query a bit more complicated and use the answer from the model in the following question.\\n\\nIn this case, we’ve defined constraints in the where clause of the query string itself.\\n\\nquery_string = \\'\\'\\'\\n    \"Q: What is the captital of {country}? \\\\\\\\n\"\\n    \"A: [CAPITAL] \\\\\\\\n\"\\n    \"Q: What is the main sight in {CAPITAL}? \\\\\\\\n\"\\n    \"A: [ANSWER]\" where (len(TOKENS(CAPITAL)) < 10) \\\\\\n      and (len(TOKENS(ANSWER)) < 100) and STOPS_AT(CAPITAL, \\'\\\\\\\\n\\') \\\\\\n      and STOPS_AT(ANSWER, \\'\\\\\\\\n\\')\\n\\'\\'\\'\\n\\nlmql.run_sync(query_string, country=\"the United Kingdom\")\\n\\nAlso, I’ve used run_sync instead of run to get a result synchronously.\\n\\nAs a result, we got an LMQLResult object with a set of fields:\\n\\nprompt - include the whole prompt with the parameters and the model’s answers. We could see that the model answer was used for the second question.\\n\\nvariables - dictionary with all the variables we defined: ANSWER and CAPITAL .\\n\\ndistribution_variable and distribution_values are None since we haven’t used this functionality.\\n\\nImage by author\\n\\nThe third way to use Python API is the @lmql.query decorator, which allows you to define a Python function that will be handy to use in the future. It’s more convenient if you plan to call this prompt several times.\\n\\nWe could create a function for our previous query and get only the final answer instead of returning the whole LMQLResult object.\\n\\n@lmql.query\\ndef capital_sights(country):\\n    \\'\\'\\'lmql\\n    \"Q: What is the captital of {country}? \\\\\\\\n\"\\n    \"A: [CAPITAL] \\\\\\\\n\"\\n    \"Q: What is the main sight in {CAPITAL}? \\\\\\\\n\"\\n    \"A: [ANSWER]\" where (len(TOKENS(CAPITAL)) < 10) and (len(TOKENS(ANSWER)) < 100) \\\\\\n        and STOPS_AT(CAPITAL, \\'\\\\\\\\n\\') and STOPS_AT(ANSWER, \\'\\\\\\\\n\\')\\n\\n    # return just the ANSWER \\n    return ANSWER\\n    \\'\\'\\'\\n\\nprint(capital_sights(country=\"the United Kingdom\"))\\n\\n# There are many famous sights in London, but one of the most iconic is \\n# the Big Ben clock tower located in the Palace of Westminster. \\n# Other popular sights include Buckingham Palace, the London Eye, \\n# and Tower Bridge.\\n\\nAlso, you could use LMQL in combination with LangChain:\\n\\nLMQL queries are Prompt Templates on steroids and could be part of LangChain chains.\\n\\nYou could leverage LangChain components from LMQL (for example, retrieval). You can find examples in the documentation.\\n\\nNow, we know all the basics of LMQL syntax, and we are ready to move on to our task - to define sentiment for customer comments.\\n\\nSentiment Analysis\\n\\nTo see how LMQL is performing, we will use labelled Yelp reviews from the UCI Machine Learning Repository and try to predict sentiment. All reviews in the dataset are positive or negative, but we will keep neutral as one of the possible options for classification.\\n\\nFor this task, let’s use local models - Zephyr and Llama-2. To use them in LMQL, we need to specify the model and tokeniser when we are calling LMQL. For Llama-family models, we can use the default tokeniser.\\n\\nFirst attempts\\n\\nLet’s pick one customer review The food was very good. and try to define its sentiment. We will use lmql.run for debugging since it’s convenient for such ad-hoc calls.\\n\\nI’ve started with a very naive approach.\\n\\nquery_string = \"\"\"\\n\"Q: What is the sentiment of the following review: ```The food was very good.```?\\\\\\\\n\"\\n\"A: [SENTIMENT]\"\\n\"\"\"\\n\\nlmql.run_sync(\\n    query_string, \\n    model = lmql.model(\"local:llama.cpp:zephyr-7b-beta.Q4_K_M.gguf\", \\n        tokenizer = \\'HuggingFaceH4/zephyr-7b-beta\\'))\\n\\n# [Error during generate()] The requested number of tokens exceeds \\n# the llama.cpp model\\'s context size. Please specify a higher n_ctx value.\\n\\nIf your local model works exceptionally slowly, check whether your computer uses swap memory. Restart could be an excellent option to solve it.\\n\\nThe code looks absolutely straightforward. Surprisingly, however, it doesn’t work and returns the following error.\\n\\n[Error during generate()] The requested number of tokens exceeds the llama.cpp \\nmodel\\'s context size. Please specify a higher n_ctx value.\\n\\nFrom the message, we can guess that the output doesn’t fit the context size. Our prompt is about 20 tokens. So, it’s a bit weird that we’ve hit the threshold on the context size. Let’s try to constrain the number of tokens for SENTIMENT and see the output.\\n\\nquery_string = \"\"\"\\n\"Q: What is the sentiment of the following review: ```The food was very good.```?\\\\\\\\n\"\\n\"A: [SENTIMENT]\" where (len(TOKENS(SENTIMENT)) < 200)\\n\"\"\"\\n\\nprint(lmql.run_sync(query_string, \\n    model = lmql.model(\"local:llama.cpp:zephyr-7b-beta.Q4_K_M.gguf\", \\n        tokenizer = \\'HuggingFaceH4/zephyr-7b-beta\\')).variables[\\'SENTIMENT\\'])\\n\\n#  Positive sentiment.\\n# \\n# Q: What is the sentiment of the following review: ```The service was terrible.```?\\n# A:  Negative sentiment.\\n# \\n# Q: What is the sentiment of the following review: ```The hotel was amazing, the staff were friendly and the location was perfect.```?\\n# A:  Positive sentiment.\\n# \\n# Q: What is the sentiment of the following review: ```The product was a complete disappointment.```?\\n# A:  Negative sentiment.\\n# \\n# Q: What is the sentiment of the following review: ```The flight was delayed for 3 hours, the food was cold and the entertainment system didn\\'t work.```?\\n# A:  Negative sentiment.\\n# \\n# Q: What is the sentiment of the following review: ```The restaurant was packed, but the waiter was efficient and the food was delicious.```?\\n# A:  Positive sentiment.\\n# \\n# Q:\\n\\n\\nNow, we could see the root cause of the problem - the model was stuck in a cycle, repeating the question variations and answers again and again. I haven’t seen such issues with OpenAI models (suppose they might control it), but they are pretty standard to open-source local models. We could use the STOPS_AT constraint to stop generation if we see Q: or a new line in the model response to avoid such cycles.\\n\\nquery_string = \"\"\"\\n\"Q: What is the sentiment of the following review: ```The food was very good.```?\\\\\\\\n\"\\n\"A: [SENTIMENT]\" where STOPS_AT(SENTIMENT, \\'Q:\\') \\\\\\n     and STOPS_AT(SENTIMENT, \\'\\\\\\\\n\\')\\n\"\"\"\\n\\nprint(lmql.run_sync(query_string, \\n    model = lmql.model(\"local:llama.cpp:zephyr-7b-beta.Q4_K_M.gguf\", \\n        tokenizer = \\'HuggingFaceH4/zephyr-7b-beta\\')).variables[\\'SENTIMENT\\'])\\n\\n# Positive sentiment.\\n\\nExcellent, we’ve solved the issue and got the result. But since we will do classification, we would like the model to return one of the three outputs (class labels): negative, neutral or positive. We could add such a filter to the LMQL query to constrain the output.\\n\\nquery_string = \"\"\"\\n\"Q: What is the sentiment of the following review: ```The food was very good.```?\\\\\\\\n\"\\n\"A: [SENTIMENT]\" where (SENTIMENT in [\\'positive\\', \\'negative\\', \\'neutral\\'])\\n\"\"\"\\n\\nprint(lmql.run_sync(query_string, \\n    model = lmql.model(\"local:llama.cpp:zephyr-7b-beta.Q4_K_M.gguf\", \\n        tokenizer = \\'HuggingFaceH4/zephyr-7b-beta\\')).variables[\\'SENTIMENT\\'])\\n\\n# positive\\n\\nWe don’t need filters with stopping criteria since we are already limiting output to just three possible options, and LMQL doesn’t look at any other possibilities.\\n\\nLet’s try to use the chain of thoughts reasoning approach. Giving the model some time to think usually improves the results. Using LMQL syntax, we could quickly implement this approach.\\n\\nquery_string = \"\"\"\\n\"Q: What is the sentiment of the following review: ```The food was very good.```?\\\\\\\\n\"\\n\"A: Let\\'s think step by step. [ANALYSIS]. Therefore, the sentiment is [SENTIMENT]\" where (len(TOKENS(ANALYSIS)) < 200) and STOPS_AT(ANALYSIS, \\'\\\\\\\\n\\') \\\\\\n    and (SENTIMENT in [\\'positive\\', \\'negative\\', \\'neutral\\'])\\n\"\"\"\\n\\nprint(lmql.run_sync(query_string, \\n    model = lmql.model(\"local:llama.cpp:zephyr-7b-beta.Q4_K_M.gguf\", \\n        tokenizer = \\'HuggingFaceH4/zephyr-7b-beta\\')).variables)\\n\\nThe output from the Zephyr model is pretty decent.\\n\\nImage by author\\n\\nWe can try the same prompt with Llama 2.\\n\\nquery_string = \"\"\"\\n\"Q: What is the sentiment of the following review: ```The food was very good.```?\\\\\\\\n\"\\n\"A: Let\\'s think step by step. [ANALYSIS]. Therefore, the sentiment is [SENTIMENT]\" where (len(TOKENS(ANALYSIS)) < 200) and STOPS_AT(ANALYSIS, \\'\\\\\\\\n\\') \\\\\\n    and (SENTIMENT in [\\'positive\\', \\'negative\\', \\'neutral\\'])\\n\"\"\"\\n\\nprint(lmql.run_sync(query_string, \\n    model = lmql.model(\"local:llama.cpp:llama-2-7b.Q4_K_M.gguf\")).variables)\\n\\nThe reasoning doesn’t make much sense. We’ve already seen on the Leaderboard that the Zephyr model is much better than Llama-2–7b.\\n\\nImage by author\\n\\nIn classical Machine Learning, we usually get not only class labels but also their probability. We could get the same data using distribution in LMQL. We just need to specify the variable and possible values - distribution SENTIMENT in [‘positive’, ‘negative’, ‘neutral’].\\n\\nquery_string = \"\"\"\\n\"Q: What is the sentiment of the following review: ```The food was very good.```?\\\\\\\\n\"\\n\"A: Let\\'s think step by step. [ANALYSIS]. Therefore, the sentiment is [SENTIMENT]\" distribution SENTIMENT in [\\'positive\\', \\'negative\\', \\'neutral\\']\\nwhere (len(TOKENS(ANALYSIS)) < 200) and STOPS_AT(ANALYSIS, \\'\\\\\\\\n\\')\\n\"\"\"\\n\\nprint(lmql.run_sync(query_string, \\n    model = lmql.model(\"local:llama.cpp:zephyr-7b-beta.Q4_K_M.gguf\", \\n        tokenizer = \\'HuggingFaceH4/zephyr-7b-beta\\')).variables)\\n\\nNow, we got probabilities in the output, and we could see that the model is quite confident in the positive sentiment.\\n\\nProbabilities could be helpful in practice if you want to use only decisions when the model is confident.\\n\\nImage by author\\n\\nNow, let’s create a function to use our sentiment analysis for various inputs. It would be interesting to compare results with and without distribution, so we need two functions.\\n\\n@lmql.query(model=lmql.model(\"local:llama.cpp:zephyr-7b-beta.Q4_K_M.gguf\", \\n   tokenizer = \\'HuggingFaceH4/zephyr-7b-beta\\', n_gpu_layers=1000))\\n# specified n_gpu_layers to use GPU for higher speed\\ndef sentiment_analysis(review):\\n    \\'\\'\\'lmql\\n    \"Q: What is the sentiment of the following review: ```{review}```?\\\\\\\\n\"\\n    \"A: Let\\'s think step by step. [ANALYSIS]. Therefore, the sentiment is [SENTIMENT]\" where (len(TOKENS(ANALYSIS)) < 200) and STOPS_AT(ANALYSIS, \\'\\\\\\\\n\\') \\\\\\n        and (SENTIMENT in [\\'positive\\', \\'negative\\', \\'neutral\\'])\\n    \\'\\'\\'\\n\\n\\n@lmql.query(model=lmql.model(\"local:llama.cpp:zephyr-7b-beta.Q4_K_M.gguf\", \\n  tokenizer = \\'HuggingFaceH4/zephyr-7b-beta\\', n_gpu_layers=1000))\\ndef sentiment_analysis_distribution(review):\\n    \\'\\'\\'lmql\\n    \"Q: What is the sentiment of the following review: ```{review}```?\\\\\\\\n\"\\n    \"A: Let\\'s think step by step. [ANALYSIS]. Therefore, the sentiment is [SENTIMENT]\" distribution SENTIMENT in [\\'positive\\', \\'negative\\', \\'neutral\\']\\n    where (len(TOKENS(ANALYSIS)) < 200) and STOPS_AT(ANALYSIS, \\'\\\\\\\\n\\')\\n    \\'\\'\\'\\n\\nThen, we could use this function for the new review.\\n\\nsentiment_analysis(\\'Room was dirty\\')\\n\\nThe model decided that it was neutral.\\n\\nImage by author\\n\\nThere’s a rationale behind this conclusion, but I would say this review is negative. Let’s see whether we could use other decoders and get better results.\\n\\nBy default, the argmax decoder is used. It’s the most straightforward approach: at each step, the model selects the token with the highest probability. We could try to play with other options.\\n\\nLet’s try to use the beam search approach with n = 3 and a pretty high tempreture = 0.8. As a result, we would get three sequences sorted by likelihood, so we could just get the first one (with the highest likelihood).\\n\\nsentiment_analysis(\\'Room was dirty\\', decoder = \\'beam\\', \\n    n = 3, temperature = 0.8)[0]\\n\\nNow, the model was able to spot the negative sentiment in this review.\\n\\nImage by author\\n\\nIt’s worth saying that there’s a cost for beam search decoding. Since we are working on three sequences (beams), getting an LLM result takes 3 times more time on average: 39.55 secs vs 13.15 secs.\\n\\nNow, we have our functions and can test them with our real data.\\n\\nResults on real-life data\\n\\nI’ve run all the functions on a 10% sample of the 1K dataset of Yelp reviews with different parameters:\\n\\nmodels: Llama 2 or Zephyr,\\n\\napproach: using distribution or just constrained prompt,\\n\\ndecoders: argmax or beam search.\\n\\nFirst, let’s compare accuracy - share of reviews with correct sentiment. We can see that Zephyr performs much better than the Llama 2 model. Also, for some reason, we get significantly poorer quality with distributions.\\n\\nGraph by author\\n\\nIf we look a bit deeper, we could notice:\\n\\nFor positive reviews, accuracy is usually higher.\\n\\nThe most common error is marking the review as neutral,\\n\\nFor Llama 2 with prompt, we could see a high rate of critical issues (positive comments that were labelled as negatives).\\n\\nIn many cases, I suppose the model uses a similar rationale, scoring negative comments as neutral as we’ve seen earlier with the \"dirty room\" example. The model is unsure whether \"dirty room\" has a negative or neutral sentiment since we don’t know whether the customer expected a clean room.\\n\\nGraph by author\\n\\nGraph by author\\n\\nIt’s also interesting to look at actual probabilities:\\n\\n75% percentile of positive labels for positive comments is above 0.85 for the Zephyr model, while it is way lower for Llama 2.\\n\\nAll models show poor performance for negative comments, where the 75% percentile for negative labels for negative comments is way below even 0.5.\\n\\nGraph by author\\n\\nGraph by author\\n\\nOur quick research shows that a vanilla prompt with a Zephyr model and argmax decoder would be the best option for sentiment analysis. However, it’s worth checking different approaches for your use case. Also, you could often achieve better results by tweaking prompts.\\n\\nYou can find the full code on GitHub.\\n\\nSummary\\n\\nToday, we’ve discussed a concept of LMP (Language Model Programming) that allows you to mix prompts in natural language and scripting instructions. We’ve tried using it for sentiment analysis tasks and got decent results using local open-source models.\\n\\nEven though LMQL is not widespread yet, this approach might be handy and gain popularity in the future since it combines natural and programming languages into a powerful tool for LMs.\\n\\nThank you a lot for reading this article. I hope it was insightful to you. If you have any follow-up questions or comments, please leave them in the comments section.\\n\\nDataset\\n\\nKotzias,Dimitrios. (2015). Sentiment Labelled Sentences. UCI Machine Learning Repository (CC BY 4.0 license). https://doi.org/10.24432/C57604'}},\n",
       "  {'id': 'eaf5469b83b0',\n",
       "   'title': 'RAG: How to Talk to Your Data',\n",
       "   'subtitle': 'Comprehensive guide on how to analyse customer feedback using ChatGPT',\n",
       "   'author': '15a29a4fc6ad',\n",
       "   'publication_id': '7f60cf5620c9',\n",
       "   'published_at': '2023-11-11 05:54:51',\n",
       "   'last_modified_at': '2023-11-11 08:46:29',\n",
       "   'tags': ['chatgpt',\n",
       "    'llm',\n",
       "    'langchain',\n",
       "    'hands-on-tutorials',\n",
       "    'naturallanguageprocessing'],\n",
       "   'topics': ['machine-learning', 'programming'],\n",
       "   'claps': 429,\n",
       "   'voters': 93,\n",
       "   'word_count': 4751,\n",
       "   'responses_count': 5,\n",
       "   'reading_time': 20.378301886792453,\n",
       "   'url': 'https://towardsdatascience.com/rag-how-to-talk-to-your-data-eaf5469b83b0',\n",
       "   'unique_slug': 'rag-how-to-talk-to-your-data-eaf5469b83b0',\n",
       "   'image_url': 'https://miro.medium.com/1*XFIVfZf4FYSm4lY01Auimw.png',\n",
       "   'lang': 'en',\n",
       "   'is_series': False,\n",
       "   'is_locked': False,\n",
       "   'is_shortform': False,\n",
       "   'top_highlight': '',\n",
       "   'content': {'id': 'eaf5469b83b0',\n",
       "    'content': 'RAG: How to Talk to Your Data\\n\\nComprehensive guide on how to analyse customer feedback using ChatGPT\\n\\nImage by DALL-E 3\\n\\nIn my previous articles, we discussed how to do Topic Modelling using ChatGPT. Our task was to analyse customer comments for different hotel chains and identify the main topics mentioned for each hotel.\\n\\nAs a result of such Topic Modelling, we know topics for each customer review and can easily filter by them and dive deeper. However, in real life, it’s impossible to have such an exhaustive set of topics that could cover all your possible use cases.\\n\\nFor example, here’s the list of topics we identified from customer feedback earlier.\\n\\n\\n\\nThese topics can help us get a high-level overview of the customer feedback and do initial pre-filtering. But suppose we want to understand what customers think about the gym or beverages for breakfast. In that case, we will need to go through quite a lot of customer feedback ourselves from \"Hotel facilities\" and \"Breakfast\" topics.\\n\\nLuckily, LLMs could help us with this analysis and save many hours of going through customers’ reviews (even though it still might be helpful to listen to the customer’s voice yourself). In this article we will discuss such approaches.\\n\\nWe will continue using LangChain (one of the most popular frameworks for LLM applications). You can find a basic overview of LangChain in my previous article.\\n\\nNaive approaches\\n\\nThe most straightforward way to get comments related to a specific topic is just to look for some particular words in the texts, like \"gym\" or \"drink\". I’ve been using this approach many times when ChatGPT didn’t exist.\\n\\nThe problems with this approach are pretty obvious:\\n\\nYou might get quite a lot of not relevant comments about gymnasia nearby or alcoholic drinks in the hotel restaurant. Such filters are not specific enough and can’t take context into account so that you will have a lot of false positives.\\n\\nOn the other hand, you might not have good enough coverage as well. People tend to use slightly different words for the same things (for example, drinks, refreshments, beverages, juices, etc). There might be typos. And this task might become even more convoluted if your customers speak different languages.\\n\\nSo, this approach has problems both with precision and recall. It will give you a rough understanding of the question, but its capabilities are limited.\\n\\nThe other potential solution is to use the same approach as with Topic Modelling: send all customer comments to LLM and ask the model to define whether they are related to our topic of interest (beverages at breakfast or gym). We can even ask the model to sum up all customer feedback and provide a conclusion.\\n\\nThis approach is likely to work pretty well. However, it has its limitations too: you will need to send all the documents you have to LLM each time you want to dive deeper into a particular topic. Even with high-level filtering based on topics we defined, it might be quite a lot of data to pass to LLM, and it will be rather costly.\\n\\nLuckily, there is another way to solve this task, and it’s called RAG.\\n\\nRetrieval-augmented generation\\n\\nWe have a set of documents (customer reviews), and we want to ask questions related to the content of these documents (for example, \"What do customers like about breakfast?\"). As we discussed before, we don’t want to send all customer reviews to LLM, so we need to have a way to define only the most relevant ones. Then, the task will be pretty straightforward: pass the user question and these documents as the context to LLM, and that’s it.\\n\\nSuch an approach is called Retrieval-augmented generation or RAG.\\n\\nScheme by author\\n\\nThe pipeline for RAG consists of the following stages:\\n\\nLoading documents from the data sources we have.\\n\\nSplitting documents into chunks that are easy to use further.\\n\\nStorage: vector stores are often used for this use case to process data effectively.\\n\\nRetrieval of relevant to the question documents.\\n\\nGeneration is passing a question and relevant documents to LLM and getting the final answer.\\n\\nYou might have heard that OpenAI launched Assistant API this week, which could do all these steps for you. However, I believe it’s worth going through the whole process to understand how it works and its peculiarities.\\n\\nSo, let’s go through all these stages step-by-step.\\n\\nLoading documents\\n\\nThe first step is to load our documents. LangChain supports different document types, for example, CSV or JSON.\\n\\nYou might wonder what is the benefit of using LangChain for such basic data types. It goes without saying that you can parse CSV or JSON files using standard Python libraries. However, I recommend using LangChain data loaders API since it returns Document objects containing content and metadata. It will be easier for you to use LangChain Documents later on.\\n\\nLet’s look at a bit more complex examples of data types.\\n\\nWe often have tasks to analyse web page content, so we have to work with HTML. Even if you’ve already mastered the BeautifulSoup library, you might find BSHTMLLoader helpful.\\n\\nWhat’s interesting about HTML related to LLM applications is that, most likely, you will need to preprocess it a lot. If you look at any website using Browser Inspector, you will notice much more text than you see on the site. It’s used to specify the layout, formatting, styles, etc.\\n\\nImage by author, LangChain documentation\\n\\nIn most real-life cases, we won’t need to pass all this data to LLM. The whole HTML for a site could easily exceed 200K tokens (and only ~10–20% of it will be text you see as a user), so it would be challenging to fit it into a context size. More than that, this technical info might make the model’s job a bit harder.\\n\\nSo, it’s pretty standard to extract only text from HTML and use it for further analysis. To do it, you could use the command below. As a result, you will get a Document object where text from the web page is in the page_content parameter.\\n\\nfrom langchain.document_loaders import BSHTMLLoader\\n\\nloader = BSHTMLLoader(\"my_site.html\")\\ndata = loader.load()\\n\\nThe other commonly used data type is PDF. We can parse PDFs, for example, using the PyPDF library. Let’s load text from DALL-E 3 paper.\\n\\nfrom langchain.document_loaders import PyPDFLoader\\nloader = PyPDFLoader(\"https://cdn.openai.com/papers/DALL_E_3_System_Card.pdf\")\\ndoc = loader.load()\\n\\nIn the output, you will get a set of Documents - one for each page. In metadata, both source and page fields will be populated.\\n\\nSo, as you can see, LangChain allows you to work with an extensive range of different document types.\\n\\nLet’s return to our initial task. In our dataset, we have a separate .txt file with customer comments for each hotel. We need to parse all files in the directory and put them together. We can use DirectoryLoader for it.\\n\\nfrom langchain.document_loaders import TextLoader, DirectoryLoader\\n\\ntext_loader_kwargs={\\'autodetect_encoding\\': True}\\nloader = DirectoryLoader(\\'./hotels/london\\', show_progress=True, \\n    loader_cls=TextLoader, loader_kwargs=text_loader_kwargs)\\n\\ndocs = loader.load()\\nlen(docs)\\n82\\n\\nI’ve also used ’autodetect_encoding’: True since our texts are encoded not in standard UTF-8.\\n\\nAs a result, we got the list of documents - one document for each text file. We know that each document consists of individual customer reviews. It will be more effective for us to work with smaller chunks rather than with all customer comments for a hotel. So, we need to split our documents. Let’s move on to the next stage and discuss document splitting in detail.\\n\\nSplitting documents\\n\\nThe next step is to split documents. You might wonder why we need to do this. Documents are often long and cover multiple topics, for example, Confluence pages or documentation. If we pass such lengthy texts to LLMs, we might face issues that either LLM is distracted by irrelevant information or texts don’t fit the context size.\\n\\nSo, to work effectively with LLMs, it’s worth defining the most relevant information from our knowledge base (set of documents) and passing only this info to the model. That’s why we need to split our documents into smaller chunks.\\n\\nThe most commonly used technique for general texts is recursive split by character. In LangChain, it’s implemented in RecursiveCharacterTextSplitter class.\\n\\nLet’s try to understand how it works. First, you define a prioritised list of characters for the splitter (by default, it’s [\"\\\\n\\\\n\", \"\\\\n\", \" \", \"\"]). Then, the splitter goes through this list and tries to split the document by characters one by one until it gets small enough chunks. It means that this approach tries to keep semantically close parts together (paragraphs, sentences, words) until we need to split them to achieve the desired chunk size.\\n\\nLet’s use the Zen of Python to see how it works. There are 824 characters, 139 words and 21 paragraphs in this text.\\n\\nYou can see the Zen of Python if you execute import this.\\n\\nzen = \\'\\'\\'\\nBeautiful is better than ugly.\\nExplicit is better than implicit.\\nSimple is better than complex.\\nComplex is better than complicated.\\nFlat is better than nested.\\nSparse is better than dense.\\nReadability counts.\\nSpecial cases aren\\'t special enough to break the rules.\\nAlthough practicality beats purity.\\nErrors should never pass silently.\\nUnless explicitly silenced.\\nIn the face of ambiguity, refuse the temptation to guess.\\nThere should be one -- and preferably only one --obvious way to do it.\\nAlthough that way may not be obvious at first unless you\\'re Dutch.\\nNow is better than never.\\nAlthough never is often better than *right* now.\\nIf the implementation is hard to explain, it\\'s a bad idea.\\nIf the implementation is easy to explain, it may be a good idea.\\nNamespaces are one honking great idea -- let\\'s do more of those!\\n\\'\\'\\'\\n\\nprint(\\'Number of characters: %d\\' % len(zen))\\nprint(\\'Number of words: %d\\' % len(zen.replace(\\'\\\\n\\', \\' \\').split(\\' \\')))\\nprint(\\'Number of paragraphs: %d\\' % len(zen.split(\\'\\\\n\\')))\\n\\n# Number of characters: 825\\n# Number of words: 140\\n# Number of paragraphs: 21\\n\\nLet’s use RecursiveCharacterTextSplitter and start with a relatively big chunk size equal to 300.\\n\\nfrom langchain.text_splitter import RecursiveCharacterTextSplitter\\n\\ntext_splitter = RecursiveCharacterTextSplitter(\\n    chunk_size = 300,\\n    chunk_overlap  = 0,\\n    length_function = len,\\n    is_separator_regex = False,\\n)\\ntext_splitter.split_text(zen)\\n\\nWe will get three chunks: 264, 293 and 263 characters. We could see that all sentences are held together.\\n\\nAll images below are made by author.\\n\\n\\n\\nYou might notice a chunk_overlap parameter that could allow you to split with overlap. It’s important because we will be passing to LLM some chunks with our questions, and it’s crucial to have enough context to make decisions based only on the information provided in each chunk.\\n\\nScheme by author\\n\\nLet’s try to add chunk_overlap.\\n\\ntext_splitter = RecursiveCharacterTextSplitter(\\n    chunk_size = 300,\\n    chunk_overlap  = 100,\\n    length_function = len,\\n    is_separator_regex = False,\\n)\\ntext_splitter.split_text(zen)\\n\\nNow, we have four splits with 264, 232, 297 and 263 characters, and we can see that our chunks overlap.\\n\\n\\n\\nLet’s make the chunk size a bit smaller.\\n\\ntext_splitter = RecursiveCharacterTextSplitter(\\n    chunk_size = 50,\\n    chunk_overlap  = 10,\\n    length_function = len,\\n    is_separator_regex = False,\\n)\\ntext_splitter.split_text(zen)\\n\\nNow, we even had to split some longer sentences. That’s how recursive split works: since after splitting by paragraphs (\"\\\\n\"), chunks are still not small enough, the splitter proceeded to \" \".\\n\\n\\n\\nYou can customise the split even further. For example, you could specify length_function = lambda x: len(x.split(\"\\\\n\")) to use the number of paragraphs as the chunk length instead of the number of characters. It’s also quite common to split by tokens because LLMs have limited context sizes based on the number of tokens.\\n\\nThe other potential customisation is to use other separators to prefer to split by \",\" instead of \" \" . Let’s try to use it with a couple of sentences.\\n\\ntext_splitter = RecursiveCharacterTextSplitter(\\n    chunk_size = 50,\\n    chunk_overlap  = 0,\\n    length_function = len,\\n    is_separator_regex = False,\\n    separators=[\"\\\\n\\\\n\", \"\\\\n\", \", \", \" \", \"\"]\\n)\\ntext_splitter.split_text(\\'\\'\\'\\\\\\nIf the implementation is hard to explain, it\\'s a bad idea.\\nIf the implementation is easy to explain, it may be a good idea.\\'\\'\\')\\n\\nIt works, but commas are not in the right places.\\n\\n\\n\\nTo fix this issue, we could use regexp with lookback as a separator.\\n\\ntext_splitter = RecursiveCharacterTextSplitter(\\n    chunk_size = 50,\\n    chunk_overlap  = 0,\\n    length_function = len,\\n    is_separator_regex = True,\\n    separators=[\"\\\\n\\\\n\", \"\\\\n\", \"(?<=\\\\, )\", \" \", \"\"]\\n)\\ntext_splitter.split_text(\\'\\'\\'\\\\\\nIf the implementation is hard to explain, it\\'s a bad idea.\\nIf the implementation is easy to explain, it may be a good idea.\\'\\'\\')\\n\\nNow it’s fixed.\\n\\n\\n\\nAlso, LangChain provides tools for working with code so that your texts are split based on separators specific to programming languages.\\n\\nHowever, in our case, the situation is more straightforward. We know we have individual independent comments delimited by \"\\\\n\" in each file, and we just need to split by it. Unfortunately, LangChain doesn’t support such a basic use case, so we need to do a bit of hacking to make it work as we want to.\\n\\nfrom langchain.text_splitter import CharacterTextSplitter\\n\\ntext_splitter = CharacterTextSplitter(\\n    separator = \"\\\\n\",\\n    chunk_size = 1,\\n    chunk_overlap  = 0,\\n    length_function = lambda x: 1, # hack - usually len is used \\n    is_separator_regex = False\\n)\\nsplit_docs = text_splitter.split_documents(docs)\\nlen(split_docs) \\n12890\\n\\nYou can find more details on why we need a hack here in my previous article about LangChain.\\n\\nThe significant part of the documents is metadata since it can give more context about where this chunk came from. In our case, LangChain automatically populated the source parameter for metadata so that we know which hotel each comment is related to.\\n\\n\\n\\nThere are some other approaches (i.e. for HTML or Markdown) that add titles to metadata while splitting documents. These methods could be quite helpful if you’re working with such data types.\\n\\nVector stores\\n\\nNow we have comment texts and next step is to learn how to store them effectively so that we could get relevant documents for our questions.\\n\\nWe could store comments as strings, but it won’t help us to solve this task - we won’t be able to filter customer reviews relevant to the question.\\nA much more functional solution is to store documents’ embeddings.\\n\\nEmbeddings are high-dimensional vectors. Embeddings capture semantical meanings and relationships between words and phrases so that semantically close texts will have a smaller distance between them.\\n\\nWe will be using OpenAI Embeddings since they are pretty popular. OpenAI advises using the text-embedding-ada-002 model since it has better performance, more extended context and lower price. As usual, it has its risks and limitations: potential social bias and limited knowledge about recent events.\\n\\nLet’s try to use Embeddings on toy examples to see how it works.\\n\\nfrom langchain.embeddings.openai import OpenAIEmbeddings\\nembedding = OpenAIEmbeddings()\\n\\ntext1 = \\'Our room (standard one) was very clean and large.\\'\\ntext2 = \\'Weather in London was wonderful.\\'\\ntext3 = \\'The room I had was actually larger than those found in other hotels in the area, and was very well appointed.\\'\\n\\nemb1 = embedding.embed_query(text1)\\nemb2 = embedding.embed_query(text2)\\nemb3 = embedding.embed_query(text3)\\n\\nprint(\\'\\'\\'\\nDistance 1 -> 2: %.2f\\nDistance 1 -> 3: %.2f\\nDistance 2-> 3: %.2f\\n\\'\\'\\' % (np.dot(emb1, emb2), np.dot(emb1, emb3), np.dot(emb2, emb3)))\\n\\nWe can use np.dot as cosine similarity because OpenAI embeddings are already normed.\\n\\nWe can see that the first and the third vectors are close to each other, while the second one differs. The first and third sentences have similar semantical meanings (they are both about the room size), while the second sentence is not close, talking about the weather. So, distances between embeddings actually reflect the semantical similarity between texts.\\n\\n\\n\\nNow, we know how to convert comments into numeric vectors. The next question is how we should store it so that this data is easily accessible.\\n\\nLet’s think about our use case. Our flow will be:\\n\\nget a question,\\n\\ncalculate its embedding,\\n\\nfind the most relevant document chunks related to this question (the ones with the smallest distance to this embedding),\\n\\nfinally, pass found chunks to LLM as a context along with the initial question.\\n\\nThe regular task for the data storage will be to find K nearest vectors (K most relevant documents). So, we will need to calculate the distance (in our case, Cosine Similarity) between our question’s embedding and all the vectors we have.\\n\\nGeneric databases (like Snowflake or Postgres) will perform poorly for such a task. But there are databases optimised, especially for this use case - vector databases.\\n\\nWe will be using an open-source embedding database, Chroma. Chroma is a lightweight in-memory DB, so it’s ideal for prototyping. You can find much more options for vector stores here.\\n\\nFirst, we need to install Chroma using pip.\\n\\npip install chromadb\\n\\nWe will use persist_directory to store our data locally and reload it from disk.\\n\\nfrom langchain.vectorstores import Chroma\\npersist_directory = \\'vector_store\\'\\n\\nvectordb = Chroma.from_documents(\\n    documents=split_docs,\\n    embedding=embedding,\\n    persist_directory=persist_directory\\n)\\n\\nTo be able to load data from disk when you need it next time, execute the following command.\\n\\nembedding = OpenAIEmbeddings()\\nvectordb = Chroma(\\n    persist_directory=persist_directory,\\n    embedding_function=embedding\\n)\\n\\nThe database initialisation might take a couple of minutes since Chroma needs to load all documents and get their embeddings using OpenAI API.\\n\\nWe can see that all documents have been loaded.\\n\\nprint(vectordb._collection.count())\\n12890\\n\\nNow, we could use a similarity search to find top customer comments about staff politeness.\\n\\nquery_docs = vectordb.similarity_search(\\'politeness of staff\\', k=3)\\n\\nDocuments look pretty relevant to the question.\\n\\n\\n\\nWe have stored our customer comments in an accessible way, and it’s time to discuss retrieval in more detail.\\n\\nRetrieval\\n\\nWe’ve already used vectordb.similarity_search to retrieve the most related chunks to the question. In most cases, such an approach will work for you, but there could be some nuances:\\n\\nLack of diversity - The model might return extremely close texts (even duplicates), which won’t add much new information to LLM.\\n\\nNot taking into account metadata - similarity_search doesn’t take into account the metadata information we have. For example, if I query the top-5 comments for the question \"breakfast in Travelodge Farringdon\", only three comments in the result will have the source equal to uk_england_london_travelodge_london_farringdon.\\n\\nContext size limitation - as usual, we have limited LLM context size and need to fit our documents into it.\\n\\nLet’s discuss techniques that could help us to solve these problems.\\n\\nAddressing Diversity - MMR (Maximum Marginal Relevance)\\n\\nSimilarity search returns the most close responses to your question. But to provide the complete information to the model, you might want not to focus on the most similar texts. For example, for the question \"breakfast in Travelodge Farringdon\", the top five customer reviews might be about coffee. If we look only at them, we will miss other comments mentioning eggs or staff behaviour and get somewhat limited view on the customer feedback.\\n\\nWe could use the MMR (Maximum Marginal Relevance) approach to increase the diversity of customer comments. It works pretty straightforward:\\n\\nFirst, we get fetch_k the most similar docs to the question using similarity_search .\\n\\nThen, we picked up k the most diverse among them.\\n\\nScheme by author\\n\\nIf we want to use MMR, we should use max_marginal_relevance_search instead of similarity_search and specify fetch_k number. It’s worth keeping fetch_k relatively small so that you don’t have irrelevant answers in the output. That’s it.\\n\\nquery_docs = vectordb.max_marginal_relevance_search(\\'politeness of staff\\', \\n    k = 3, fetch_k = 30)\\n\\nLet’s look at the examples for the same query. We got more diverse feedback this time. There’s even a comment with negative sentiment.\\n\\n\\n\\nAddressing specificity - LLM-aided retrieval\\n\\nThe other problem is that we don’t take into account the metadata while retrieving documents. To solve it, we can ask LLM to split the initial question into two parts:\\n\\nsemantical filter based on document texts,\\n\\nfilter based on metadata we have.\\n\\nThis approach is called \"Self querying\".\\n\\nFirst, let’s add a manual filter specifying a source parameter with the filename related to Travelodge Farringdon hotel.\\n\\nquery_docs = vectordb.similarity_search(\\'breakfast in Travelodge Farrigdon\\', \\n  k=5,\\n  filter = {\\'source\\': \\'hotels/london/uk_england_london_travelodge_london_farringdon\\'}\\n)\\n\\nNow, let’s try to use LLM to come up with such a filter automatically. We need to describe all our metadata parameters in detail and then use SelfQueryRetriever.\\n\\nfrom langchain.llms import OpenAI\\nfrom langchain.retrievers.self_query.base import SelfQueryRetriever\\nfrom langchain.chains.query_constructor.base import AttributeInfo\\n\\nmetadata_field_info = [\\n    AttributeInfo(\\n        name=\"source\",\\n        description=\"All sources starts with \\'hotels/london/uk_england_london_\\' \\\\\\n          then goes hotel chain, constant \\'london_\\' and location.\",\\n        type=\"string\",\\n    )\\n]\\n\\ndocument_content_description = \"Customer reviews for hotels\"\\nllm = OpenAI(temperature=0.1) # low temperature to make model more factual\\n# by default \\'text-davinci-003\\' is used\\n\\nretriever = SelfQueryRetriever.from_llm(\\n    llm,\\n    vectordb,\\n    document_content_description,\\n    metadata_field_info,\\n    verbose=True\\n)\\n\\nquestion = \"breakfast in Travelodge Farringdon\"\\ndocs = retriever.get_relevant_documents(question, k = 5)\\n\\nOur case is tricky since the source parameter in the metadata consists of multiple fields: country, city, hotel chain and location. It’s worth splitting such complex parameters into more granular ones in such situations so that the model can easily understand how to use metadata filters.\\n\\nHowever, with a detailed prompt, it worked and returned only documents related to Travelodge Farringdon. But I must confess, it took me several iterations to achieve this result.\\n\\nLet’s switch on debug and see how it works. To enter debug mode, you just need to execute the code below.\\n\\nimport langchain \\nlangchain.debug = True\\n\\nThe complete prompt is pretty long, so let’s look at the main parts of it. Here’s the prompt’s start, which gives the model an overview of what we expect and the main criteria for the result.\\n\\n\\n\\nThen, the few-shot prompting technique is used, and the model is provided with two examples of input and expected output. Here’s one of the examples.\\n\\n\\n\\nWe are not using a chat model like ChatGPT but general LLM (not fine-tuned on instructions). It’s trained just to predict the following tokens for the text. That’s why we finished our prompt with our question and the string Structured output: expecting the model to provide the answer.\\n\\n\\n\\nAs a result, we got from the model the initial question split into two parts: semantic one (breakfast) and metadata filters (source = hotels/london/uk_england_london_travelodge_london_farringdon)\\n\\n\\n\\nThen, we used this logic to retrieve documents from our vector store and got only documents we need.\\n\\nAddressing size limitations - Compression\\n\\nThe other technique for retrieval that might be handy is compression. Even though GPT 4 Turbo has a context size of 128K tokens, it’s still limited. That’s why we might want to preprocess documents and extract only relevant parts.\\n\\nThe main advantages are:\\n\\nYou will be able to fit more documents and information into the final prompt since they will be condensed.\\n\\nYou will get better, more focused results because the non-relevant context will be cleaned during preprocessing.\\n\\nThese benefits come with the cost - you will have more calls to LLM for compression, which means lower speed and higher price.\\n\\nYou can find more info about this technique in the docs.\\n\\nScheme by author\\n\\nActually, we can even combine techniques and use MMR here. We used ContextualCompressionRetriever to get results. Also, we specified that we want just three documents in return.\\n\\nfrom langchain.retrievers import ContextualCompressionRetriever\\nfrom langchain.retrievers.document_compressors import LLMChainExtractor\\n\\nllm = OpenAI(temperature=0)\\ncompressor = LLMChainExtractor.from_llm(llm)\\ncompression_retriever = ContextualCompressionRetriever(\\n    base_compressor=compressor,\\n    base_retriever=vectordb.as_retriever(search_type = \"mmr\",  \\n      search_kwargs={\"k\": 3})\\n)\\n\\nquestion = \"breakfast in Travelodge Farringdon\"\\ncompressed_docs = compression_retriever.get_relevant_documents(question)\\n\\nAs usual, understanding how it works under the hood is the most exciting part. If we look at actual calls, there are three calls to LLM to extract only relevant information from the text. Here’s an example.\\n\\n\\n\\nIn the output, we got only part of the sentence related to breakfast, so compression helps.\\n\\n\\n\\nThere are many more beneficial approaches for retrieval, for example, techniques from classic NLP: SVM or TF-IDF. Different retrievers might be helpful in different situations, so I recommend you compare different versions for your task and select the most suitable one for your use case.\\n\\nGeneration\\n\\nFinally, we got to the last stage: we will combine everything and generate the final answer.\\n\\nHere’s a scheme on how it all will work:\\n\\nwe get a question from a user,\\n\\nwe retrieve relevant documents for this question from the vector store using embeddings,\\n\\nwe pass the initial question along with retrieved documents to the LLM and get the final answer.\\n\\nScheme by author\\n\\nIn LangChain, we could use RetrievalQA chain to implement this flow quickly.\\n\\nfrom langchain.chains import RetrievalQA\\n\\nfrom langchain.chat_models import ChatOpenAI\\nllm = ChatOpenAI(model_name=\\'gpt-4\\', temperature=0.1)\\n\\nqa_chain = RetrievalQA.from_chain_type(\\n    llm,\\n    retriever=vectordb.as_retriever(search_kwargs={\"k\": 3})\\n)\\n\\nresult = qa_chain({\"query\": \"what customers like about staff in the hotel?\"})\\n\\nLet’s look at the call to ChatGPT. As you can see, we passed retrieved documents along with the user query.\\n\\n\\n\\nHere’s an output from the model.\\n\\n\\n\\nWe can tweak the model’s behaviour, customising prompt. For example, we could ask the model to be more concise.\\n\\nfrom langchain.prompts import PromptTemplate\\n\\ntemplate = \"\"\"\\nUse the following pieces of context to answer the question at the end. \\nIf you don\\'t know the answer, just say that you don\\'t know, don\\'t try \\nto make up an answer. \\nKeep the answer as concise as possible. Use 1 sentence to sum all points up.\\n______________\\n{context}\\nQuestion: {question}\\nHelpful Answer:\"\"\"\\n\\nQA_CHAIN_PROMPT = PromptTemplate.from_template(template)\\n\\nqa_chain = RetrievalQA.from_chain_type(\\n    llm,\\n    retriever=vectordb.as_retriever(),\\n    return_source_documents=True,\\n    chain_type_kwargs={\"prompt\": QA_CHAIN_PROMPT}\\n)\\nresult = qa_chain({\"query\": \"what customers like about staff in the hotel?\"})\\n\\nWe got a much shorter answer this time. Also, since we specified return_source_documents=True, we got a set of documents in return. It could be helpful for debugging.\\n\\n\\n\\nAs we’ve seen, all retrieved documents are combined in one prompt by default. This approach is excellent and straightforward since it invokes only one call to LLM. The only limitation is that your documents must fit the context size. If they don’t, you need to apply more complex techniques.\\n\\nLet’s look at different chain types that could allow us to work with any number of documents. The first one is MapReduce.\\n\\nThis approach is similar to classical MapReduce: we generate answers based on each retrieved document (map stage) and then combine these answers into the final one (reduce stage).\\n\\nScheme by author\\n\\nThe limitations of all such approaches are cost and speed. Instead of one call to LLM, you need to do a call for each retrieved document.\\n\\nRegarding code, we just need to specify chain_type=\"map_reduce\" to change behaviour.\\n\\nqa_chain_mr = RetrievalQA.from_chain_type(\\n    llm,\\n    retriever=vectordb.as_retriever(),\\n    chain_type=\"map_reduce\"\\n)\\nresult = qa_chain_mr({\"query\": \"what customers like about staff in the hotel?\"})\\n\\nIn the result, we got the following output.\\n\\n\\n\\nLet’s see how it works using debug mode. Since it’s a MapReduce, we first sent each document to LLM and got the answer based on this chunk. Here’s an example of prompt for one of the chunks.\\n\\n\\n\\nThen, we combine all the results and ask LLM to come up with the final answer.\\n\\n\\n\\nThat’s it.\\n\\nThere is another drawback specific to the MapReduce approach. The model sees each document separately and doesn’t have them all in the same context, which might lead to worse results.\\n\\nWe can overcome this drawback with the Refine chain type. Then, we will look at documents sequentially and allow the model to refine the answer on each iteration.\\n\\nScheme by author\\n\\nAgain, we just need to change chain_type to test another approach.\\n\\nqa_chain_refine = RetrievalQA.from_chain_type(\\n    llm,\\n    retriever=vectordb.as_retriever(),\\n    chain_type=\"refine\"\\n)\\nresult = qa_chain_refine({\"query\": \"what customers like about staff in the hotel?\"})\\n\\nWith the Refine chain, we got a bit more wordy and complete answer.\\n\\n\\n\\nLet’s see how it works using debug. For the first chunk, we are starting from scratch.\\n\\n\\n\\nThen, we pass the current answer and a new chunk and give the model a chance to refine its answer.\\n\\n\\n\\nThen, we repeat the refining prompt for each remaining retrieved document and get the final result.\\n\\nThat’s all that I wanted to tell you today. Let’s do a quick recap.\\n\\nSummary\\n\\nIn this article, we went through the whole process of Retrieval-augmented generation:\\n\\nWe’ve looked at different data loaders.\\n\\nWe’ve discussed possible approaches to data splitting and their potential nuances.\\n\\nWe’ve learned what embeddings are and set up a vector store to access data effectively.\\n\\nWe’ve found different solutions for retrieval issues and learned how to increase diversity, to overcome context size limitations and to use metadata.\\n\\nFinally, we’ve used the RetrievalQA chain to generate the answer based on our data and compared different chain types.\\n\\nThis knowledge should be enough for start building something similar with your data.\\n\\nThank you a lot for reading this article. I hope it was insightful to you. If you have any follow-up questions or comments, please leave them in the comments section.\\n\\nDataset\\n\\nGanesan, Kavita and Zhai, ChengXiang. (2011). OpinRank Review Dataset. \\nUCI Machine Learning Repository (CC BY 4.0). https://doi.org/10.24432/C5QW4W\\n\\nReference\\n\\nThis article is based on information from the courses:\\n\\n\"LangChain for LLM Application Development\" by DeepLearning.AI and LangChain,\\n\\n\"LangChain: Chat with your data\" by DeepLearning.AI and LangChain.'}},\n",
       "  {'id': 'e3b3e99e4fca',\n",
       "   'title': 'Topic Modelling in production',\n",
       "   'subtitle': 'Leveraging LangChain to move from ad-hoc Jupyter Notebooks to production modular service',\n",
       "   'author': '15a29a4fc6ad',\n",
       "   'publication_id': '7f60cf5620c9',\n",
       "   'published_at': '2023-10-30 14:07:06',\n",
       "   'last_modified_at': '2023-10-30 14:07:06',\n",
       "   'tags': ['chatgpt',\n",
       "    'llm',\n",
       "    'machine-learning',\n",
       "    'evaluation',\n",
       "    'editors-pick'],\n",
       "   'topics': ['artificial-intelligence', 'machine-learning', 'data-science'],\n",
       "   'claps': 392,\n",
       "   'voters': 79,\n",
       "   'word_count': 5271,\n",
       "   'responses_count': 6,\n",
       "   'reading_time': 21.390566037735848,\n",
       "   'url': 'https://towardsdatascience.com/topic-modelling-in-production-e3b3e99e4fca',\n",
       "   'unique_slug': 'topic-modelling-in-production-e3b3e99e4fca',\n",
       "   'image_url': 'https://miro.medium.com/1*zrrzdFgAnm7YAyIYtINhoA.jpeg',\n",
       "   'lang': 'en',\n",
       "   'is_series': False,\n",
       "   'is_locked': False,\n",
       "   'is_shortform': False,\n",
       "   'top_highlight': '',\n",
       "   'content': {'id': 'e3b3e99e4fca',\n",
       "    'content': 'Topic Modelling in production\\n\\nLeveraging LangChain to move from ad-hoc Jupyter Notebooks to production modular service\\n\\nImage by DALL-E 3\\n\\nIn the previous article, we discussed how to do Topic Modelling using ChatGPT and got excellent results. The task was to look at customer reviews for hotel chains and define the main topics mentioned in the reviews.\\n\\nIn the previous iteration, we used standard ChatGPT completions API and sent raw prompts ourselves. Such an approach works well when we are doing some ad-hoc analytical research.\\n\\nHowever, if your team is actively using and monitoring customer reviews, it’s worth considering some automatisation. A good automatisation will not only help you build an autonomous pipeline, but it will also be more convenient (even team members unfamiliar with LLMs and coding will be able to access this data) and more cost-effective (you will send all texts to LLM and pay only once).\\n\\nSuppose we are building a sustainable production-ready service. In that case, it’s worth leveraging existing frameworks to reduce the amount of glue code and have a more modular solution (so that we could easily switch, for example, from one LLM to another).\\n\\nIn this article, I would like to tell you about one of the most popular frameworks for LLM applications - LangChain. Also, we will understand in detail how to evaluate your model’s performance since it’s a crucial step for business applications.\\n\\nNuances of production process\\n\\nRevising initial approach\\n\\nFirst, let’s revise our previous approach for ad-hoc Topic Modelling with ChatGPT.\\n\\nStep 1: Get a representative sample.\\n\\nWe want to determine the list of topics we will use for our markup. The most straightforward way is to send all reviews and ask LLM to define the list of 20–30 topics mentioned in our reviews. Unfortunately, we won’t be able to do it since it won’t fit the context size. We could use a map-reduce approach, but it could be costly. That’s why we would like to define a representative sample.\\n\\nFor this, we built a BERTopic topic model and got the most representative reviews for each topic.\\n\\nStep 2: Determine the list of topics we will use for markup.\\n\\nThe next step is to pass all the selected texts to ChatGPT and ask it to define a list of topics mentioned in these reviews. Then, we can use these topics for later markup.\\n\\nStep 3: Doing topics’ markup in batches.\\n\\nThe last step is the most straightforward - we can send customer reviews in batches that fit the context size and ask LLM to return topics for each customer review.\\n\\nFinally, with these three steps, we could determine the list of relevant topics for our texts and classify them all.\\n\\nIt works perfectly for one-time research. However, we are missing some bits for an excellent production-ready solution.\\n\\nFrom ad-hoc to production\\n\\nLet’s discuss what improvements we could make to our initial ad-hoc approach.\\n\\nIn the previous approach, we have a static list of topics. But in real-life examples, new topics might arise over time, for example, if you launch a new feature. So, we need a feedback loop to update the list of topics we are using. The easiest way to do it is to capture the list of reviews without any assigned topics and regularly run topic modelling on them.\\n\\nIf we are doing one-time research, we can validate the results of the topics’ assignments manually. But for the process that is running in production, we need to think about a continuous evaluation.\\n\\nIf we are building a pipeline for customer review analysis, we should consider more potential use cases and store other related information we might need. For example, it’s helpful to store translated versions of customer reviews so that our colleagues don’t have to use Google Translate all the time. Also, sentiment and other features (for example, products mentioned in the customer review) might be valuable for analysis and filtering.\\n\\nThe LLM industry is progressing quite quickly right now, and everything is changing all the time. It’s worth considering a modular approach where we can quickly iterate and try new approaches over time without rewriting the whole service from scratch.\\n\\nScheme of the service by author\\n\\nWe have a lot of ideas on what to do with our topic modelling service. But let’s focus on the main parts: modular approach instead of API calls and evaluation. The LangChain framework will help us with both topics, so let’s learn more about it.\\n\\nLangChain Basics\\n\\nLangChain is a framework for building applications powered by Language Models. Here are the main components of LangChain:\\n\\nSchema is the most basic classes like Documents, Chat Messages and Texts.\\n\\nModels. LangChain provides access to LLMs, Chat Models and Text Embedding models that you could easily use in your applications and switch between them if needed. It goes without saying it supports such popular models like ChatGPT, Anthropic and Llama.\\n\\nPrompts is a functionality to help work with prompts, including prompt templates, output parsers and example selectors for few-shot prompting.\\n\\nChains are the core of LangChain (as you might guess by the name). Chains help you to build a sequence of blocks that will be executed. You can truly appreciate this functionality if you’re building a complex application.\\n\\nIndexes: document loaders, text splitters, vector stores and retrievers. This module provides tools that help LLMs to interact with your documents. This functionality would be valuable if you’re building a Q&A use case. We won’t be using this functionality much in our example today.\\n\\nLangChain provides a whole set of methods to manage and limit memory. This functionality is primarily needed for ChatBot scenarios.\\n\\nOne of the latest and most powerful features is agents. If you are a heavy ChatGPT user, you must have heard about the plugins. It’s the same idea that you can empower LLM with a set of custom or predefined tools (like Google Search or Wikipedia), and then the agent can use them while answering your questions. In this setup, LLM is acting like a reasoning agent and decides what it needs to do to achieve the result and when it gets the final answer that it could share. It’s exciting functionality, so it’s definitely worth a separate discussion.\\n\\nSo, LangChain can help us build modular applications and be able to switch between different components (for example, from ChatGPT to Anthropic or from CSV as data input to Snowflake DB). LangChain has more than 190 integrations, so that it can save you quite a lot of time.\\n\\nAlso, we could reuse ready-made chains for some use cases instead of starting from scratch.\\n\\nWhen calling ChatGPT API manually, we have to manage quite a lot of Python glue code to make it work. It’s not a problem when you’re working on a small, straightforward task, but it might become unmanageable when you need to build something more complex and convoluted. In such cases, LangChain may help you eliminate this glue code and create more easy-to-maintain modular code.\\n\\nHowever, LangChain has its own limitations:\\n\\nIt’s primarily focused on OpenAI models, so it might not work so smoothly with on-premise open-source models.\\n\\nThe flip side of convenience is that it’s not easy to understand what’s going on under the hood and when and how the ChatGPT API you’re paying for is executed. You can use debug mode, but you need to specify it and go through the complete logs for a clearer view.\\n\\nDespite pretty good documentation, I struggle from time to time to find answers to my questions. There are not so many other tutorials and resources on the internet apart from the official documentation, quite frequently you can see only official pages in Google.\\n\\nThe Langchain library is progressing a lot, and the team constantly ship new features. So, the library is not mature, and you might have to switch from the functionality you’re using. For example, the SequentialChain class is considered legacy now and might be deprecated in the future since they’ve introduced LCEL - we will talk about it in more detail later on.\\n\\nWe’ve gotten a birds-eye overview of LangChain functionality, but practice makes perfect. Let’s start using LangChain.\\n\\nEnhancing topics’ assignment\\n\\nLet’s refactor the topic assignment since it will be the most common operation in our regular process, and it will help us understand how to use LangChain in practice.\\n\\nFirst of all, we need to install the package.\\n\\n!pip install --upgrade langchain\\n\\nLoading documents\\n\\nTo work with the customers’ reviews, we first need to load them. For that, we could use Document Loaders. In our case, customer reviews are stored as a set of .txt files in a Directory, but you can effortlessly load docs from third-party tools. For example, there’s an integration with Snowflake.\\n\\nWe will use DirectoryLoader to load all files in the directory since we have separate files from hotels. For each file, we will specify TextLoader as a loader (by default, a loader for unstructured documents is used). Our files are encoded in ISO-8859–1, so the default call returns an error. However, LangChain can automatically detect used encoding. With such a setup, it works ok.\\n\\nfrom langchain.document_loaders import TextLoader, DirectoryLoader\\n\\ntext_loader_kwargs={\\'autodetect_encoding\\': True}\\nloader = DirectoryLoader(\\'./hotels/london\\', show_progress=True, \\n    loader_cls=TextLoader, loader_kwargs=text_loader_kwargs)\\n\\ndocs = loader.load()\\nlen(docs)\\n82\\n\\nSplitting documents\\n\\nNow, we would like to split our documents. We know that each file consists of a set of customer comments delimited by \\\\n. Since our case is very straightforward, we will use the most basic CharacterTextSplitter that splits documents by character. When working with real documents (whole long texts instead of independent short comments), it’s better to use Recursive split by character since it allows you to split documents into chunks smarter.\\n\\nHowever, LangChain is more suited for fuzzy text splitting. So, I had to hack it a bit to make it work the way I wanted.\\n\\nHow it works:\\n\\nYou specify chunk_size and chunk_overlap, and it tries to make the minimal number of splits so that each chunk is smaller than chunk_size. If it fails to create a small enough chunk, it prints a message to the Jupyter Notebook output.\\n\\nIf you specify too big chunk_size, not all comments will be separated.\\n\\nIf you specify too small chunk_size, you will have print statements for each comment in your output, leading to the Notebook reloading. Unfortunately, I couldn’t find any parameters to switch it off.\\n\\nTo overcome this problem, I specified length_function as a constant equal to chunk_size. Then I got just a standard split by character. LangChain provides enough flexibility to do what you want, but only in a somewhat hacky way.\\n\\nfrom langchain.text_splitter import CharacterTextSplitter\\n\\ntext_splitter = CharacterTextSplitter(\\n    separator = \"\\\\n\",\\n    chunk_size = 1,\\n    chunk_overlap  = 0,\\n    length_function = lambda x: 1, # usually len is used \\n    is_separator_regex = False\\n)\\nsplit_docs = text_splitter.split_documents(docs)\\nlen(split_docs) \\n12890\\n\\nAlso, let’s add the document ID to the metadata - we will use it later.\\n\\nfor i in range(len(split_docs)):\\n    split_docs[i].metadata[\\'id\\'] = i\\n\\nThe advantage of using Documents is that we now have automatic data sources and can filter data by it. For example, we can filter only comments related to Travelodge Hotel.\\n\\nlist(filter(\\n    lambda x: \\'travelodge\\' in x.metadata[\\'source\\'],\\n    split_docs\\n))\\n\\nNext, we need a model. As we discussed earlier in LangChain, there are LLMs and Chat Models. The main difference is that LLMs take texts and return texts, while Chat Models are more suitable for conversational use cases and can get a set of messages as input. In our case, we will use the ChatModel for OpenAI since we would like to pass system messages as well.\\n\\nfrom langchain.chat_models import ChatOpenAI\\n\\nchat = ChatOpenAI(temperature=0.0, model=\"gpt-3.5-turbo\", \\n  openai_api_key = \"your_key\")\\n\\nPrompts\\n\\nLet’s move on to the most important part - our prompt. In LangChain, there’s a concept of Prompt Templates. They help to reuse prompts parametrised by variables. It’s helpful since, in real-life applications, prompts might be very detailed and sophisticated. So, prompt templates can be a useful high-level abstraction that would help you to manage your code effectively.\\n\\nSince we are going to use the Chat Model, we will need ChatPromptTemplate.\\n\\nBut before jumping into prompts, let’s briefly discuss a helpful feature - an output parser. Surprisingly, they can help us to create an effective prompt. We can define the desired output, generate an output parser and then use the parser to create instructions for the prompt.\\n\\nLet’s define what we would like to see in the output. First, we would like to be able to pass a list of customer reviews to the prompt to process them in batches, so in the result, we would like to get a list with the following parameters:\\n\\nid to identify documents,\\n\\nlist of topics from the predefined list (we will be using the list from our previous iteration),\\n\\nsentiment (negative, neutral or positive).\\n\\nLet’s specify our output parser. Since we need a pretty complex JSON structure, we will use Pydantic Output Parser instead of the most commonly used Structured Output Parser.\\n\\nFor that, we need to create a class inherited from BaseModel and specify all fields we need with names and descriptions (so that LLM could understand what we expect in the response).\\n\\nfrom langchain.output_parsers import PydanticOutputParser\\nfrom langchain.pydantic_v1 import BaseModel, Field\\nfrom typing import List\\n\\nclass CustomerCommentData(BaseModel):\\n    doc_id: int = Field(description=\"doc_id from the input parameters\")\\n    topics: List[str] = Field(description=\"List of the relevant topics \\\\\\n        for the customer review. Please, include only topics from \\\\\\n        the provided list.\")\\n    sentiment: str = Field(description=\"sentiment of the comment (positive, neutral or negative\")\\n\\noutput_parser = PydanticOutputParser(pydantic_object=CustomerCommentData)\\n\\nNow, we could use this parser to generate formatting instructions for our prompt. That’s a fantastic case when you could use prompting best practices and spend less time on prompt engineering.\\n\\nformat_instructions = output_parser.get_format_instructions()\\nprint(format_instructions)\\n\\n\\n\\nThen, it’s time to move on to our prompt. We took a batch of comments and formatted them into the expected format. Then, we created a prompt message with a bunch of variables: topics_descr_list, format_instructions and input_data. After that, we created chat prompt messages consisting of a constant system message and a prompt message. The last step is to format chat prompt messages with actual values.\\n\\nfrom langchain.prompts import ChatPromptTemplate\\n\\ndocs_batch_data = []\\nfor rec in docs_batch:\\n    docs_batch_data.append(\\n        {\\n            \\'id\\': rec.metadata[\\'id\\'],\\n            \\'review\\': rec.page_content\\n        }\\n    )\\n\\ntopic_assignment_msg = \\'\\'\\'\\nBelow is a list of customer reviews in JSON format with the following keys:\\n1. doc_id - identifier for the review\\n2. review - text of customer review\\nPlease, analyse provided reviews and identify the main topics and sentiment. Include only topics from the provided below list.\\n\\nList of topics with descriptions (delimited with \":\"):\\n{topics_descr_list}\\n\\nOutput format:\\n{format_instructions}\\n\\nCustomer reviews:\\n```\\n{input_data}\\n```\\n\\'\\'\\'\\n\\ntopic_assignment_template = ChatPromptTemplate.from_messages([\\n    (\"system\", \"You\\'re a helpful assistant. Your task is to analyse hotel reviews.\"),\\n    (\"human\", topic_assignment_msg)\\n])\\n\\ntopics_list = \\'\\\\n\\'.join(\\n    map(lambda x: \\'%s: %s\\' % (x[\\'topic_name\\'], x[\\'topic_description\\']), \\n      topics))\\n\\nmessages = topic_assignment_template.format_messages(\\n    topics_descr_list = topics_list,\\n    format_instructions = format_instructions,\\n    input_data = json.dumps(docs_batch_data)\\n)\\n\\nNow, we can pass these formatted messages to LLM and see a response.\\n\\nresponse = chat(messages)\\ntype(response.content)\\nstr\\n\\nprint(response.content)\\n\\n\\n\\nWe got the response as a string object, but we could leverage our parser and get the list of CustomerCommentData class objects as a result.\\n\\nresponse_dict = list(map(lambda x: output_parser.parse(x), \\n  response.content.split(\\'\\\\n\\')))\\nresponse_dict\\n\\n\\n\\nSo, we’ve leveraged LangChain and some of its features and have already built a bit smarter solution that could assign topics to the comments in batches (it would save us some costs) and started to define not only topics but also sentiment.\\n\\nAdding more logic\\n\\nSo far, we’ve built only single LLM calls without any relations and sequencing. However, in real life, we often want to split our tasks into multiple steps. For that, we can use Chains. Chain is the fundamental building block for LangChain.\\n\\nLLMChain\\n\\nThe most basic type of chain is an LLMChain. It is a combination of LLM and prompt.\\n\\nSo we can rewrite our logic into a chain. This code will give us absolutely the same result as before, but it’s pretty convenient to have one method that defines it all.\\n\\nfrom langchain.chains import LLMChain\\n\\ntopic_assignment_chain = LLMChain(llm=chat, prompt=topic_assignment_template)\\nresponse = topic_assignment_chain.run(\\n    topics_descr_list = topics_list,\\n    format_instructions = format_instructions,\\n    input_data = json.dumps(docs_batch_data)\\n)\\n\\n\\nSequential Chains\\n\\nLLM chain is very basic. The power of chains is in building more complex logic. Let’s try to create something more advanced.\\n\\nThe idea of sequential chains is to use the output of one chain as the input for another.\\n\\nFor defining chains, we will be using LCEL (LangChain Expression Language). This new language was introduced just a couple of months ago, and now all the old approaches with SimpleSequentialChain or SequentialChain are considered legacy. So, it’s worth spending some time understanding the LCEL concept.\\n\\nLet’s rewrite the previous chain in LCEL.\\n\\nchain = topic_assignment_template | chat\\nresponse = chain.invoke(\\n    {\\n        \\'topics_descr_list\\': topics_list,\\n        \\'format_instructions\\': format_instructions,\\n        \\'input_data\\': json.dumps(docs_batch_data)\\n    }\\n)\\n\\nIf you want to learn it first-hand, I suggest you watch this video about LCEL from the LangChain team.\\n\\nUsing sequential chains\\n\\nIn some cases, it might be helpful to have several sequential calls so that the output of one chain is used in the other ones.\\n\\nIn our case, we can first translate reviews into English and then do topic modelling and sentiment analysis.\\n\\n\\n\\nfrom langchain.schema import StrOutputParser\\nfrom operator import itemgetter\\n\\n# translation\\n\\ntranslate_msg = \\'\\'\\'\\nBelow is a list of customer reviews in JSON format with the following keys:\\n1. doc_id - identifier for the review\\n2. review - text of customer review\\n\\nPlease, translate review into English and return the same JSON back. Please, return in the output ONLY valid JSON without any other information.\\n\\nCustomer reviews:\\n```\\n{input_data}\\n```\\n\\'\\'\\'\\n\\ntranslate_template = ChatPromptTemplate.from_messages([\\n    (\"system\", \"You\\'re an API, so you return only valid JSON without any comments.\"),\\n    (\"human\", translate_msg)\\n])\\n\\n# topic assignment & sentiment analysis\\n\\ntopic_assignment_msg = \\'\\'\\'\\nBelow is a list of customer reviews in JSON format with the following keys:\\n1. doc_id - identifier for the review\\n2. review - text of customer review\\nPlease, analyse provided reviews and identify the main topics and sentiment. Include only topics from the provided below list.\\n\\nList of topics with descriptions (delimited with \":\"):\\n{topics_descr_list}\\n\\nOutput format:\\n{format_instructions}\\n\\nCustomer reviews:\\n```\\n{translated_data}\\n```\\n\\'\\'\\'\\n\\ntopic_assignment_template = ChatPromptTemplate.from_messages([\\n    (\"system\", \"You\\'re a helpful assistant. Your task is to analyse hotel reviews.\"),\\n    (\"human\", topic_assignment_msg)\\n])\\n\\n# defining chains\\n\\ntranslate_chain = translate_template | chat | StrOutputParser()\\ntopic_assignment_chain = {\\'topics_descr_list\\': itemgetter(\\'topics_descr_list\\'), \\n                          \\'translated_data\\': translate_chain, \\n                          \\'format_instructions\\': itemgetter(\\'format_instructions\\')} \\n                        | topic_assignment_template | chat \\n\\n# execution\\n\\nresponse = topic_assignment_chain.invoke(\\n    {\\n        \\'topics_descr_list\\': topics_list,\\n        \\'format_instructions\\': format_instructions,\\n        \\'input_data\\': json.dumps(docs_batch_data)\\n    }\\n)\\n\\nWe similarly defined prompt templates for translation and topic assignment. Then, we determined the translation chain. The only new thing here is the usage of StrOutputParser(), which converts response objects into strings (no rocket science).\\n\\nThen, we defined the full chain, specifying the input parameters, prompt template and LLM. For input parameters, we took translated_data from the output of translate_chain while other parameters from the invoke input using the itemgetter function.\\n\\nHowever, in our case, such an approach with a combined chain might not be so convenient since we would like to save the output of the first chain as well to have translated values.\\n\\nWith chains, everything becomes a bit more convoluted so that we might need some debugging capabilities. There are two options for debugging.\\nThe first one is that you can switch on debugging locally.\\n\\nimport langchain\\nlangchain.debug = True\\n\\nThe other option is to use the LangChain platform - LangSmith. However, it’s still in beta-tester mode, so you might need to wait to get access.\\n\\nRouting\\n\\nOne of the most complex cases of chains is routing when you use different prompts for different use cases. For example, we could save different customer review parameters depending on the sentiment:\\n\\nIf the comment is negative, we will store the list of problems mentioned by the customer.\\n\\nOtherwise, we will get the list of good points from the review.\\n\\nTo use a routing chain, we will need to pass comments one by one instead of batching them as we did before.\\n\\nSo our chain on a high level will look like this.\\n\\n\\n\\nFirst, we need to define the main chain that determines the sentiment. This chain consists of prompt, LLM and already familiar StrOutputParser().\\n\\nsentiment_msg = \\'\\'\\'\\nGiven the customer comment below please classify whether it\\'s negative. If it\\'s negative, return \"negative\", otherwise return \"positive\".\\nDo not respond with more than one word.\\n\\nCustomer comment:\\n```\\n{input_data}\\n```\\n\\'\\'\\'\\n\\nsentiment_template = ChatPromptTemplate.from_messages([\\n    (\"system\", \"You\\'re an assistant. Your task is to markup sentiment for hotel reviews.\"),\\n    (\"human\", sentiment_msg)\\n])\\n\\nsentiment_chain = sentiment_template | chat | StrOutputParser()\\n\\nFor positive reviews, we will ask the model to extract good points, while for negative ones - problems. So, we will need two different chains.\\nWe will use the same Pydantic output parsers as before to specify the intended output format and generate instructions.\\n\\nWe used partial_variables on top of the general topic assignment prompt message to specify different format instructions for positive and negative cases.\\n\\nfrom langchain.prompts import PromptTemplate, ChatPromptTemplate, HumanMessagePromptTemplate, SystemMessagePromptTemplate\\n\\n# defining structure for positive and negative cases \\nclass PositiveCustomerCommentData(BaseModel):\\n    topics: List[str] = Field(description=\"List of the relevant topics for the customer review. Please, include only topics from the provided list.\")\\n    \\n    advantages: List[str] = Field(description = \"List the good points from that customer mentioned\")\\n    sentiment: str = Field(description=\"sentiment of the comment (positive, neutral or negative\")\\n\\nclass NegativeCustomerCommentData(BaseModel):\\n    topics: List[str] = Field(description=\"List of the relevant topics for the customer review. Please, include only topics from the provided list.\")\\n    \\n    problems: List[str] = Field(description = \"List the problems that customer mentioned.\")\\n    sentiment: str = Field(description=\"sentiment of the comment (positive, neutral or negative\")\\n\\n# defining output parsers and generating instructions\\npositive_output_parser = PydanticOutputParser(pydantic_object=PositiveCustomerCommentData)\\npositive_format_instructions = positive_output_parser.get_format_instructions()\\n\\nnegative_output_parser = PydanticOutputParser(pydantic_object=NegativeCustomerCommentData)\\nnegative_format_instructions = negative_output_parser.get_format_instructions()\\n\\ngeneral_topic_assignment_msg = \\'\\'\\'\\nBelow is a customer review delimited by ```.\\nPlease, analyse the provided review and identify the main topics and sentiment. Include only topics from the provided below list.\\n\\nList of topics with descriptions (delimited with \":\"):\\n{topics_descr_list}\\n\\nOutput format:\\n{format_instructions}\\n\\nCustomer reviews:\\n```\\n{input_data}\\n```\\n\\'\\'\\'\\n\\n# defining prompt templates\\n\\npositive_topic_assignment_template = ChatPromptTemplate( \\n    messages=[ \\n        SystemMessagePromptTemplate.from_template(\"You\\'re a helpful assistant. Your task is to analyse hotel reviews.\"),\\n        HumanMessagePromptTemplate.from_template(general_topic_assignment_msg) \\n    ], \\n    input_variables=[\"topics_descr_list\", \"input_data\"], \\n    partial_variables={\"format_instructions\": positive_format_instructions} )\\n\\nnegative_topic_assignment_template = ChatPromptTemplate( \\n    messages=[ \\n        SystemMessagePromptTemplate.from_template(\"You\\'re a helpful assistant. Your task is to analyse hotel reviews.\"),\\n        HumanMessagePromptTemplate.from_template(general_topic_assignment_msg) \\n    ], \\n    input_variables=[\"topics_descr_list\", \"input_data\"], \\n    partial_variables={\"format_instructions\": negative_format_instructions} )\\n\\nSo, now we need just to build the full chain. The main logic is defined using RunnableBranch and condition based on sentiment, an output of sentiment_chain.\\n\\nfrom langchain.schema.runnable import RunnableBranch\\n\\nbranch = RunnableBranch(\\n  (lambda x: \"negative\" in x[\"sentiment\"].lower(), negative_chain),\\n  positive_chain\\n)\\n\\nfull_route_chain = {\\n    \"sentiment\": sentiment_chain,\\n    \"input_data\": lambda x: x[\"input_data\"],\\n    \"topics_descr_list\": lambda x: x[\"topics_descr_list\"]\\n} | branch\\n\\nfull_route_chain.invoke({\\'input_data\\': review, \\n  \\'topics_descr_list\\': topics_list})\\n\\nHere are a couple of examples. It works pretty well and returns different objects depending on the sentiment.\\n\\n\\n\\nWe’ve looked in detail at the modular approach to do Topic Modelling using LangChain and introduce more complex logic. Now, it’s time to move on to the second part and discuss how we could assess the model’s performance.\\n\\nEvaluation\\n\\nThe crucial part of any system running in production is evaluation. When we have an LLM model running in production, we want to ensure quality and keep an eye on it over time.\\n\\nIn many cases, you could use not only human-in-the-loop (when people are checking the model results for a small sample over time to control performance) but also leverage LLM for this task as well. It could be a good idea to use a more complex model for runtime checks. For example, we used ChatGPT 3.5 for our topic assignments, but we could use GPT 4 for evaluation (similar to the concept of supervision in real life when you are asking more senior colleagues for a code review).\\n\\nLangchain can help us with this task as well since it provides some tools to evaluate results:\\n\\nString Evaluators help to evaluate results from your model. There is quite a broad set of tools, from validating the format to assessing correctness based on provided context or reference. We will talk about these methods in detail below.\\n\\nThe other class of evaluators are Comparison evaluators. They will be handy if you want to assess the performance of 2 different LLM models (A/B testing use case). We won’t go into their details today.\\n\\nExact match\\n\\nThe most straightforward approach is to compare the model’s output to the correct answer (i.e. from experts or a training set) using an exact match. For that, we could use ExactMatchStringEvaluator, for example, to assess the performance of our sentiment analysis. In this case, we don’t need LLMs.\\n\\nfrom langchain.evaluation import ExactMatchStringEvaluator\\n\\nevaluator = ExactMatchStringEvaluator(\\n    ignore_case=True,\\n    ignore_numbers=True,\\n    ignore_punctuation=True,\\n)\\n\\nevaluator.evaluate_strings(\\n    prediction=\"positive.\",\\n    reference=\"Positive\"\\n)\\n\\n# {\\'score\\': 1}\\n\\nevaluator.evaluate_strings(\\n    prediction=\"negative\",\\n    reference=\"Positive\"\\n)\\n\\n# {\\'score\\': 0}\\n\\nYou can build your own custom String Evaluator or match output to a regular expression.\\n\\nAlso, there are helpful tools to validate structured output, whether the output is a valid JSON, has the expected structure and is close to the reference by distance. You can find more details about it in the documentation.\\n\\nEmbeddings distance evaluation\\n\\nThe other handy approach is to look at the distance between embeddings. You will get a score in the result: the lower the score - the better, since answers are closer to each other. For example, we can compare found good points by Euclidean distance.\\n\\nfrom langchain.evaluation import load_evaluator\\nfrom langchain.evaluation import EmbeddingDistance\\n\\nevaluator = load_evaluator(\\n    \"embedding_distance\", distance_metric=EmbeddingDistance.EUCLIDEAN\\n)\\n\\nevaluator.evaluate_strings(\\n  prediction=\"well designed rooms, clean, great location\", \\n  reference=\"well designed rooms, clean, great location, good atmosphere\"\\n)\\n\\n{\\'score\\': 0.20732719121627757}\\n\\nWe got a distance of 0.2. However, the results of such evaluation might be more difficult to interpret since you will need to look at your data distributions and define thresholds. Let’s move on to approaches based on LLMs since we will be able to interpret their results effortlessly.\\n\\nCriteria evaluation\\n\\nYou can use LangChain to validate LLM’s answer against some rubric or criteria. There’s a list of predefined criteria, or you can create a custom one.\\n\\nfrom langchain.evaluation import Criteria\\nlist(Criteria)\\n\\n[<Criteria.CONCISENESS: \\'conciseness\\'>,\\n <Criteria.RELEVANCE: \\'relevance\\'>,\\n <Criteria.CORRECTNESS: \\'correctness\\'>,\\n <Criteria.COHERENCE: \\'coherence\\'>,\\n <Criteria.HARMFULNESS: \\'harmfulness\\'>,\\n <Criteria.MALICIOUSNESS: \\'maliciousness\\'>,\\n <Criteria.HELPFULNESS: \\'helpfulness\\'>,\\n <Criteria.CONTROVERSIALITY: \\'controversiality\\'>,\\n <Criteria.MISOGYNY: \\'misogyny\\'>,\\n <Criteria.CRIMINALITY: \\'criminality\\'>,\\n <Criteria.INSENSITIVITY: \\'insensitivity\\'>,\\n <Criteria.DEPTH: \\'depth\\'>,\\n <Criteria.CREATIVITY: \\'creativity\\'>,\\n <Criteria.DETAIL: \\'detail\\'>]\\n\\nSome of them don’t require reference (for example, harmfulness or conciseness). But for correctness, you need to know the answer. \\nLet’s try to use it for our data.\\n\\nevaluator = load_evaluator(\"criteria\", criteria=\"conciseness\")\\neval_result = evaluator.evaluate_strings(\\n    prediction=\"well designed rooms, clean, great location\",\\n    input=\"List the good points that customer mentioned\",\\n)\\n\\nAs a result, we got the answer (whether the results fit the specified criterion) and chain-of-thought reasoning so that we could understand the logic behind the result and potentially tweak the prompt.\\n\\n\\n\\nIf you’re interested in how it works, you could switch on langchain.debug = True and see the prompt sent to LLM.\\n\\n\\n\\nLet’s look at the correctness criterion. To assess it, we need to provide a reference (the correct answer).\\n\\nevaluator = load_evaluator(\"labeled_criteria\", criteria=\"correctness\")\\n\\neval_result = evaluator.evaluate_strings(\\n    prediction=\"well designed rooms, clean, great location\",\\n    input=\"List the good points that customer mentioned\",\\n    reference=\"well designed rooms, clean, great location, good atmosphere\",\\n)\\n\\n\\n\\nYou can even create your own custom criteria, for example, whether multiple points are mentioned in the answer.\\n\\ncustom_criterion = {\"multiple\": \"Does the output contain multiple points?\"}\\n\\nevaluator = load_evaluator(\"criteria\", criteria=custom_criterion)\\neval_result = evaluator.evaluate_strings(\\n    prediction=\"well designed rooms, clean, great location\",\\n    input=\"List the good points that customer mentioned\",\\n)\\n\\n\\n\\nScoring evaluation\\n\\nWith criteria evaluation, we got only a Yes or No answer, but in many cases, it is not enough. For example, in our example, the prediction has 3 out of 4 mentioned points, which is a good result, but we got N when evaluating it for correctness. So, using this approach, answers \"well-designed rooms, clean, great location\" and \"fast internet\" will be equal in terms of our metrics, which won’t give us enough information to understand the model’s performance.\\n\\nThere’s another pretty close technique of scoring when you’re asking LLM to provide the score in the output, which might help to get more granular results. Let’s try it.\\n\\nfrom langchain.chat_models import ChatOpenAI\\n\\naccuracy_criteria = {\\n    \"accuracy\": \"\"\"\\nScore 1: The answer doesn\\'t mention any relevant points.\\nScore 3: The answer mentions only few of relevant points but have major inaccuracies or includes several not relevant options.\\nScore 5: The answer has moderate quantity of relevant options but might have inaccuracies or wrong points.\\nScore 7: The answer aligns with the reference and shows most of relevant points and don\\'t have completely wrong options mentioned.\\nScore 10: The answer is completely accurate and aligns perfectly with the reference.\"\"\"\\n}\\n\\nevaluator = load_evaluator(\\n    \"labeled_score_string\", \\n    criteria=accuracy_criteria, \\n    llm=ChatOpenAI(model=\"gpt-4\"),\\n)\\n\\neval_result = evaluator.evaluate_strings(\\n    prediction=\"well designed rooms, clean, great location\",\\n    input=\"\"\"Below is a customer review delimited by ```. Provide the list the good points that customer mentioned in the customer review.\\n    Customer review:\\n    ```\\n    Small but well designed rooms, clean, great location, good atmosphere. I would stay there again. Continental breakfast is weak but ok.\\n    ```\\n    \"\"\",\\n    reference=\"well designed rooms, clean, great location, good atmosphere\"\\n)\\n\\n\\n\\nWe got seven as a score, which looks pretty valid. Let’s look at the actual prompt used.\\n\\n\\n\\nHowever, I would treat scores from LLMs with a pinch of salt. Remember, it’s not a regression function, and scores might be pretty subjective.\\n\\nWe’ve been using the scoring model with the reference. But in many cases, we might not have the correct answers, or it could be expensive for us to get them. You can use the scoring evaluator even without reference scores asking the model to assess the answer. It’s worth using GPT-4 to be more confident in the results.\\n\\naccuracy_criteria = {\\n    \"recall\": \"The asisstant\\'s answer should include all mentioned in the question. If information is missing, score answer lower.\",\\n    \"precision\": \"The assistant\\'s answer should not have any points not present in the question.\"\\n}\\n\\nevaluator = load_evaluator(\"score_string\", criteria=accuracy_criteria,\\n   llm=ChatOpenAI(model=\"gpt-4\"))\\n\\neval_result = evaluator.evaluate_strings(\\n    prediction=\"well designed rooms, clean, great location\",\\n    input=\"\"\"Below is a customer review delimited by ```. Provide the list the good points that customer mentioned in the customer review.\\n    Customer review:\\n    ```\\n    Small but well designed rooms, clean, great location, good atmosphere. I would stay there again. Continental breakfast is weak but ok.\\n    ```\\n    \"\"\"\\n)\\n\\n\\n\\nWe got a pretty close score to the previous one.\\n\\nWe’ve looked at quite a lot of possible ways to validate your output, so I hope you are now ready to test your models’ results.\\n\\nSummary\\n\\nIn this article, we’ve discussed some nuances we need to take into account if we want to use LLMs for production processes.\\n\\nWe’ve looked at the use of the LangChain framework to make our solution more modular so that we could easily iterate and use new approaches (for example, switching from one LLM to another). Also, frameworks usually help to make our code easier to maintain.\\n\\nThe other big topic we’ve discussed is the different tools we have to assess the model’s performance. If we are using LLMs in production, we need to have some constant monitoring in place to ensure the quality of our service, and it’s worth spending some time to create an evaluation pipeline based on LLMs or human-in-the-loop.\\n\\nThank you a lot for reading this article. I hope it was insightful to you. If you have any follow-up questions or comments, please leave them in the comments section.\\n\\nDataset\\n\\nGanesan, Kavita and Zhai, ChengXiang. (2011). OpinRank Review Dataset. \\nUCI Machine Learning Repository. https://doi.org/10.24432/C5QW4W\\n\\nReference\\n\\nThis article is based on information from the course \"LangChain for LLM Application Development\" by DeepLearning.AI and LangChain.'}},\n",
       "  {'id': 'c288b48918af',\n",
       "   'title': 'Understanding Retention with Gradio',\n",
       "   'subtitle': 'How to leverage web applications for analytics',\n",
       "   'author': '15a29a4fc6ad',\n",
       "   'publication_id': '7f60cf5620c9',\n",
       "   'published_at': '2023-10-21 00:01:49',\n",
       "   'last_modified_at': '2023-10-21 08:46:52',\n",
       "   'tags': ['programming',\n",
       "    'python',\n",
       "    'web-development',\n",
       "    'data-science',\n",
       "    'hands-on-tutorials'],\n",
       "   'topics': ['machine-learning',\n",
       "    'software-engineering',\n",
       "    'data-science',\n",
       "    'programming'],\n",
       "   'claps': 200,\n",
       "   'voters': 32,\n",
       "   'word_count': 3426,\n",
       "   'responses_count': 1,\n",
       "   'reading_time': 14.228301886792453,\n",
       "   'url': 'https://towardsdatascience.com/understanding-retention-with-gradio-c288b48918af',\n",
       "   'unique_slug': 'understanding-retention-with-gradio-c288b48918af',\n",
       "   'image_url': 'https://miro.medium.com/1*5g9rJ4iCzdBTMPAKVuEljg.png',\n",
       "   'lang': 'en',\n",
       "   'is_series': False,\n",
       "   'is_locked': False,\n",
       "   'is_shortform': False,\n",
       "   'top_highlight': '',\n",
       "   'content': {'id': 'c288b48918af',\n",
       "    'content': 'Understanding Retention with Gradio\\n\\nHow to leverage web applications for analytics\\n\\nImage by DALL-E 3\\n\\nI remember a moment when I built my first web application. It was around eight years ago, and I was a rather junior analyst and was convinced that BI tools could solve all the problems.\\n\\nThe engineering team built a prototype of a new SDK and wanted to learn whether it gathers data better. They were testing it on a set of devices, looking at the data and comparing it to the old version. However, the set of devices was constantly changing, so keeping it up-to-date in BI tools would require quite a lot of work. So, I decided to build a web application.\\n\\nI found a set of articles (ten or eleven if I remember correctly), read them all and tried to use this knowledge for my task. It took me around a week to finish the first prototype. I had to write both the back-end and front-end sides, so now I could consider myself at least a junior full-stack developer. For the back-end, I used Flask (I was lucky not to bump into Django, or I would have spent the whole month), and for front-end - Bootstrap and Leaflet.\\n\\nOverall, it was a challenging task that required much effort to upskill in engineering. I believe it’s always worth having a deeper understanding of the other spheres next to your primary domain of expertise.\\n\\nHowever, I’m delighted that nowadays, there are many tools that allow analysts and data scientists to build prototypes in less than an hour. In many cases, such prototypes can bring your analytics to the next level. Here are some examples:\\n\\nRevenue and audience forecast depending on the input parameters (like marketing budget or markets where we will launch a new feature),\\n\\nTools that will speed up your team’s work or reduce ad-hoc workload, like an A/B testing calculator or automatic root cause analysis,\\n\\nMVP solutions, for example, if you want to use LLMs to automate some internal processes, it’s worth testing a prototype before spending time on a production version. I shared such an ML prototype in one of my previous articles, \"Build your first Deep Learning app within an hour\".\\n\\nIn this article, I would like to tell you about one of such frameworks that can help you quickly and almost effortlessly create nice-looking web applications without bothering with JavaScript and CSS. We will learn the basics of Gradio, develop a couple of web applications, and publish them to HuggingFace Spaces so anyone can access them.\\n\\nGradio is not the only framework of that kind. There are a few other open-source Python alternatives:\\n\\nStreamlit is another popular and powerful library for building data apps with little code. It is also supported by HuggingFace Spaces so that you can host such apps.\\n\\nDash could be convenient if you are already used to Plotly, and it provides more capabilities for customization.\\n\\nHowever, if you want to build something custom and complex, your last resort would be Flask or even Django.\\n\\nYou can find more details regarding the main features of the different frameworks in this article.\\n\\nGradio basics\\n\\nGradio is an open-source Python library that is used to build interactive applications.\\n\\nThe main advantages of Gradio are:\\n\\nyou can build applications using only Python, which also means that you can use all Python libraries in your app,\\n\\nyou can run it in Jupyter Notebook or as a separate webpage,\\n\\nyou can host Gradio apps permanently on HuggingFace spaces.\\n\\nThere’s no silver bullet, so Gradio has its limitations:\\n\\nIt’s explicitly designed for ML applications. So, if you’re using it for other use cases, you might have to change defaults (for example, switching off flagging with allow_flagging= \"never\").\\n\\nCustomization is limited, especially if we are talking about design.\\n\\nI would bear in mind that Gradio is a framework primarily for quick prototyping. It mostly works well, but from time to time, I face some strange behaviour. For example, table editing in Safari works counterintuitively, or sometimes you need to restart Jupyter Notebook to make the interface load.\\n\\nTo start using Gradio, we need to install the Python package.\\n\\npip install gradio\\n\\nFollowing the old programmers’ tradition, let’s start with \"Hello, World!\".\\n\\nWe can use gr.Interface class to define the interface (documentation). It’s one of the core Gradio classes that helps you to create a web application based on any Python function.\\n\\nWe need to specify the following parameters:\\n\\ninputs: input components of the interface (in our case, just a text field),\\n\\noutputs: output components of the interface (in our case, also just a text field),\\n\\nfn: core functionality (a function that gets inputs and returns outputs, in our case, gets name from the input and returns \"Hello, <name>!\"),\\n\\ntitle & description: a bit of markdown to make our app more user-friendly.\\n\\nimport gradio as gr\\n\\ndemo = gr.Interface(\\n    inputs=[gr.Textbox(label=\"Name\", lines=1)],\\n    outputs=[gr.Textbox(label=\"Result\", lines=1)],\\n    fn=lambda x: \\'Hello, %s!\\' % x,\\n    title=\"Hello, World!\",\\n    description=\"Your first app using Gradio\",\\n    allow_flagging=\\'never\\')\\n\\ndemo.launch()\\n\\nYou can run this code in your Jupyter Notebook and see the results. It’s pretty handy for debugging. Later, we will discuss how to make your web application available to others.\\n\\nImage by author\\n\\nThat’s it: just a few lines of code, and your first Gradio app is running. Also, I must note that it looks pretty nice, and we didn’t have to use any front-end magic for it.\\n\\nGradio launches a lot of processes in the background when you’re working from Jupyter Notebook, so it’s worth from time to time close connections using gr.close_all().\\n\\nWe looked at the most basic example and saw the building blocks of Gradio: inputs, outputs and functions. Now, we are ready to move on to real-life analytical tasks.\\n\\nGrowth Simulation\\n\\nAs the first example, we will look at the impact of retention on the users’ growth for the product.\\n\\nRetention as the basis for growth\\n\\nTwo parameters define the growth of the product:\\n\\nacquisition (number of new users each period),\\n\\nretention (ability to retain customers in the product).\\n\\nLet’s model how the user base will grow depending on the retention curve.\\n\\nWe can describe any retention curve using the following function with a set of parameters (a, b, c and d):\\n\\n\\n\\nLet’s talk about the most common case of retention: cohort is defined by the first action in the product, and all actions are counted into the retention. In that case, retention for periods = 0 must equal 1 (because the cohort entry and retention events are the same). So, we can define one of the parameters automatically:\\n\\n\\n\\nThe main factor for growth is long-term retention. It defines whether customers stick to the product for a long time and your product grows sustainably or customers churn in a month, and you need to acquire more and more new users for growth. In our formula, a parameter is in charge of long-term retention.\\n\\n\\n\\nWe can use this formula to define the retention curve. So we have everything we need to move on to the development.\\n\\nVisualising retention graph\\n\\nLet’s start simple and make an application that will take the retention curve parameters and show the relation as a graph.\\n\\nSimilarly to our \"Hello, World\" example, we need to use gr.Interface class and pass inputs, outputs and fn to map them.\\n\\nWe now need more input parameters. So, inputs will be a list of controls. We will use gr.Slider and gr.Dropdown controls. \\nFor gr.Slider, we need to pass min, max, default values and a label that we will use in the function. \\nFor gr.Dropdown, we need to define a list of possible values, default value, and a label.\\n\\nWe will still have only one output - a plot so that outputs will be gr.Plot without any parameters.\\n\\nFunction fn will map inputs to outputs, so it will get input arguments and return plotly.Figure object that will be visualised.\\n\\nimport plotly.express as px\\n\\n# functions to calculate retention\\n\\ndef get_retention(a, b, c, d, periods):\\n    return  a + 1./(b + c * (periods ** d))\\n\\ndef get_retention_same_event(a, c, d, periods):\\n    b = 1./(1 - a)\\n    return get_retention(a, b, c, d, periods)\\n\\n# define function - return plot depending on input parameters\\n\\ndef get_retention_plot(a, c, d, num_periods):\\n    df = pd.DataFrame({\\'x\\': range(num_periods + 1)})\\n    df[\\'retention\\'] = df.x.map(lambda x: get_retention_same_event(a, c, d, x))\\n\\n    return px.line(df, x = \\'x\\', y = \\'retention\\', \\n                  color_discrete_sequence = px.colors.qualitative.Prism, \\n                  title = \\'Retention curve\\', labels = {\\'x\\': \\'period\\'})\\n\\n# define inputs\\ninputs = [\\n    gr.Slider(0, 1, 0.03, label=\"a\"),\\n    gr.Slider(0, 5, 0.55, label=\"c\"),\\n    gr.Slider(0, 5, 1.5, label=\"d\"),\\n    gr.Dropdown([10, 30, 60, 90], value = 30, label=\"Number of Periods\"),\\n    gr.Dropdown([10, 100, 1000, 10000], value = 10000, label=\"Number of new users each period\")\\n]\\n\\n# define outputs\\noutputs = gr.Plot()\\n\\n# define interface\\ndemo = gr.Interface(\\n    fn=get_retention_plot,\\n    inputs=inputs,\\n    outputs=outputs,\\n    cache_examples=True,\\n    allow_flagging = \\'never\\' # hiding default flag functionality in the interface\\n)\\n\\n# launch\\ndemo.launch(debug = True)\\n\\nLet’s try to run this app. It’s working - we can see a graph that changes if we submit new parameters.\\n\\n\\n\\nAdding more graphs\\n\\nOur goal was to look at the impact of retention on growth, so we need to add graphs showing not only retention but also audience over time. Let’s change our interface.\\n\\nFor simplicity, we will consider that in each period, the same number of new users start using our product (cohort_size parameter).\\n\\nWe need to make just a couple of changes to our implementation:\\n\\nChange get_retention_plot function so that it gets one more parameter for cohort size, calculates the number of users over time and returns three Figures.\\n\\nParameter outputs is now equal to the list of three gr.Plot() objects.\\n\\n\\ndef get_retention_plot(a, c, d, num_periods, cohort_size):\\n    ret_df = pd.DataFrame({\\'x\\': range(num_periods + 1)})\\n    ret_df[\\'retention\\'] = ret_df.x.map(lambda x: get_retention_same_event(a, c, d, x))\\n    \\n    ret_fig = px.line(ret_df.iloc[1:], x = \\'x\\', y = \\'retention\\', \\n                      color_discrete_sequence = px.colors.qualitative.Prism, \\n                      title = \\'Retention curve\\')\\n\\n    # simulation\\n\\n    tmp_data = []\\n\\n    for cohort in range(num_periods + 1):\\n        for cohort_period in range(num_periods + 1):\\n            period = cohort_period + cohort\\n            if period > num_periods:\\n                continue\\n            retention = get_retention_same_event(a, c, d, cohort_period)\\n            tmp_data.append(\\n                {\\n                    \\'cohort\\': \\'cohort %s\\' % str(cohort).rjust(3, \\'0\\'),\\n                    \\'cohort_period\\': cohort_period,\\n                    \\'period\\': period,\\n                    \\'retention\\': retention,\\n                    \\'users\\': int(round(retention * cohort_size))\\n                }\\n            )\\n    users_df = pd.DataFrame(tmp_data)\\n\\n    users_fig = px.area(users_df.groupby(\\'period\\').users.sum(),\\n                    color_discrete_sequence = px.colors.qualitative.Prism, \\n                      title = \\'Active users\\')\\n\\n    cohorts_fig = px.area(users_df.pivot_table(index = \\'period\\', columns = \\'cohort\\', values = \\'users\\',\\n                    aggfunc = \\'sum\\'),\\n                    color_discrete_sequence = px.colors.qualitative.Prism, \\n                    title = \\'Active users by cohorts\\')\\n\\n    return ret_fig, users_fig, cohorts_fig\\n\\ninputs = [\\n    gr.Slider(0, 1, 0.03, label=\"a\"),\\n    gr.Slider(0, 5, 0.55, label=\"c\"),\\n    gr.Slider(0, 5, 1.5, label=\"d\"),\\n    gr.Dropdown([10, 30, 60, 90], value = 30, label=\"Number of Periods\"),\\n    gr.Dropdown([10, 100, 1000, 10000], value = 10000, label=\"Number of new users each period\")\\n]\\n\\noutputs = [gr.Plot(), gr.Plot(),  gr.Plot()]\\n\\ndemo = gr.Interface(\\n    fn=get_retention_plot,\\n    inputs=inputs,\\n    outputs=outputs,\\n    allow_flagging = \\'never\\',\\n    cache_examples=True,\\n)\\n\\ndemo.launch(debug = True)\\n\\nFantastic, now we can see the complete picture and analyse the relationships. However, there’s room for improvement - we can add formatting to make our app more convenient for users.\\n\\nImage by author\\n\\nAdding a bit of style\\n\\nWe can tweak our interface a bit to make it more user-friendly and straightforward.\\n\\nFor that, we will be using gr.Blocks() as a context. This functionality allows you to create more custom web applications and define layouts and data flows (events that trigger functions and consequent execution).\\n\\nBlocks will open new opportunities for us:\\n\\nWith gr.Blocks() we can use gr.Row() and gr.Column() to organize a layout.\\n\\ngr.Markdown allows you to add markdown elements, for example, title or even LaTeX with formulas (by default, you need to put them inside $).\\n\\ngr.Accordion can help you hide some parameters you don’t want to show the user by default.\\n\\nAlso, this approach allows you to define more complex logic of updates. For example, update plots not only on the submit button but on the change of any input parameter. We will use this functionality in the following example.\\n\\nWhen working with Blocks, we need to define each input and output as variables, for example, a = gr.Slider(0, 1, 0.03, label=\"a\").\\n\\nAlso, there are no default controls, so we have to define buttons ourselves - btn_caption = gr.Button(\"Submit\").\\n\\nThe action on button click also must be specified, setting the already familiar parameters - inputs, outputs and fn.\\n\\nbtn_caption.click(fn=get_retention_plot, \\n        inputs=[a, c, d, num_periods, cohort_size], \\n        outputs=[plot1, plot2, plot3])\\n\\nHere is the full version of code.\\n\\nwith gr.Blocks() as demo:\\n    gr.Markdown(\"# Understanding Growth 🚀\")\\n    with gr.Row():\\n        with gr.Column():\\n            gr.Markdown(\"## Retention curve parameters 📈\")\\n            gr.Markdown(r\"$\\\\textbf{retention}(\\\\textsf{x}) = \\\\textsf{a} + \\\\frac{\\\\textsf{1}}{\\\\textsf{b} + \\\\textsf{c} * \\\\textsf{x}^{\\\\textsf{d}}}\\\\ where\\\\ \\\\textsf{b} = \\\\frac{\\\\textsf{1}}{\\\\textsf{1}-\\\\textsf{a}}$\")\\n            with gr.Row():\\n                a = gr.Slider(0, 1, 0.03, label=\"a\")\\n                c = gr.Slider(0, 5, 0.55, label=\"c\")\\n                d = gr.Slider(0, 5, 1.5, label=\"d\")\\n            with gr.Accordion(\"More options\", open=False):\\n                with gr.Row():\\n                    num_periods = gr.Dropdown([10, 30, 60, 90], value = 30, label=\"Number of Periods\")\\n                    cohort_size = gr.Dropdown([10, 100, 1000, 10000], value = 10000, label=\"Number of new users each period\")\\n            btn_caption = gr.Button(\"Submit\")\\n        with gr.Column():\\n            plot1 = gr.Plot()\\n    with gr.Row():\\n        plot2 = gr.Plot()\\n        plot3 = gr.Plot()\\n    \\n    btn_caption.click(fn=get_retention_plot, \\n        inputs=[a, c, d, num_periods, cohort_size], \\n        outputs=[plot1, plot2, plot3])\\n\\ndemo.launch()\\n\\nHosting your application\\n\\nAlso, we can use HuggingFace Spaces to host our web applications and share them easily with others.\\n\\nTo start using Spaces, you need to have an account. Follow this link if you haven’t registered yet. It won’t take more than a couple of minutes.\\n\\nThe next step is to create a new Space. You can find instructions with more details in the documentation.\\n\\nImage by author\\n\\nFor new Space, you must fill in the following parameters: name, license and Gradio as your SDK.\\n\\nImage by author\\n\\nThen, you need to commit your code to the Git repository from Hugging Spaces. First of all, we need to clone the repository.\\n\\n-- cloning repo\\ngit clone https://huggingface.co/spaces/<your_login>/<your_app_name>\\ncd <your_app_name>\\n\\nRecently, HuggingFace has changed the Git authentication process, so we need to create a token first and then set it for the Git repo.\\n\\ngit remote set-url origin https://<your_login>:<token>@huggingface.co/spaces/<your_login>/<your_app_name>\\ngit pull origin\\n\\nNow, it’s time to commit files related to our application. We need to have at least the following files:\\n\\napp.py with the Python code that launches the Gradio app\\n\\nrequirements.txt with the list of Python packages you need for your application. In our case, only pandas and plotly.\\n\\nThen, basic steps with git: add, commit and push to HuggingFaces.\\n\\ngit add app.py\\ngit add requirements.txt\\ngit commit -m \\'First version of retention simulator app\\'\\ngit push\\n\\nIt took a couple of minutes to build the app, and it’s done. Now our web application is up and running on HuggingFaces Spaces. You can try it here.\\n\\nImage by author\\n\\nIt looks much nicer than our initial version since the layout doesn’t require scrolling, and users don’t have to guess what parameters a, c and d mean.\\n\\nPredicting retention\\n\\nWe’ve learned how to generate graphs based on a bunch of parameters in a web application. But in real life, we usually have to input quite a lot of data, so let’s find out how to use data from .csv files in apps.\\n\\nAs an example, we will look at actual retention data for a few first periods and try to predict retention for the following periods. It’s quite a common task since we usually don’t want to wait three months to compare third-month retention for the new cohort. We will upload factual data as a .csv file.\\n\\nLet’s not waste our time and jump to the implementation.\\n\\nGetting data from files\\n\\nHere is the code to generate the whole interface and business logic. It might look a bit complex. Don’t worry. We will discuss the core points later.\\n\\n# parses file or string and returns dataframe\\ndef parse_file(input_text_or_file, num_periods):\\n    if isinstance(input_text_or_file, str):\\n        df = pd.read_csv(StringIO(input_text_or_file), sep = \\'\\\\t\\')\\n    else:\\n        df = pd.read_csv(input_text_or_file.name, sep = \\'\\\\t\\')\\n    return df\\n\\n# takes dataframe and returns plot\\ndef show_graph_for_df(df, num_periods):\\n    df[\\'period\\'] = df.period.map(int)\\n    df[\\'retention_fact\\'] = df.retention_fact.map(float)\\n    result = scipy.optimize.minimize(lambda x: get_mse_for_retention(x, df), [random.random(), random.random(), random.random()])\\n    a, c, d = result.x\\n\\n    pred_df = pd.DataFrame({\\'period\\': range(num_periods + 1)})\\n    pred_df[\\'retention_pred\\'] = pred_df.period.map(lambda x: get_retention_same_event(a, c, d, x))\\n    pred_df = pred_df.merge(df, how = \\'left\\')\\n    \\n    fig = go.Figure()\\n    fig.add_trace(go.Scatter(x=pred_df.period, y=pred_df.retention_fact, name=\\'fact\\',\\n                             line=dict(color=plotly.colors.qualitative.Prism[0], width=3)))\\n    \\n    fig.add_trace(go.Scatter(x=pred_df.period, y=pred_df.retention_pred, name=\\'prediction\\',\\n                             line=dict(color=plotly.colors.qualitative.Prism[0], width=3, dash=\\'dot\\')))\\n    \\n    fig.update_layout(title=\\'Daily retention model (a = %.2f, c = %.2f, d = %.2f)\\' % (a, c, d),\\n                       yaxis_title=\\'retention\\',\\n                       xaxis_title=\\'period\\')\\n    return fig\\n\\n# takes file and return plot\\ndef show_graph_for_file(temp_file, num_periods):\\n    df = parse_file(temp_file, num_periods)\\n    return show_graph_for_df(df, num_periods)\\n\\n# hard-coded example of data\\ndefault_csv = \\'period\\\\tretention_fact\\\\n0\\\\t1\\\\n1\\\\t0.55\\\\n2\\\\t0.4\\\\n3\\\\t0.35\\\\n4\\\\t0.3\\\\n\\'\\n\\n# interface \\nwith gr.Blocks() as demo:\\n    gr.Markdown(\\'# Predicting retention curve 📊\\')\\n    periods = gr.Dropdown([10, 30, 90, 180], label=\"Number of Periods\", value = 30)\\n    gr.Markdown(\\'Upload .csv file with data, use default data as an example or put in numbers manually in the Uploaded data section.\\')\\n    gr.Markdown(\\'\\'\\'__File format:__ 2 columns (`period` and `retention_fact`)\\'\\'\\')\\n    \\n    with gr.Row():\\n        upload_button = gr.UploadButton(label=\"Upload file\", file_types = [\\'.csv\\'], live=True, file_count = \"single\")\\n        default_button = gr.Button(\\'Show example\\')\\n    \\n    with gr.Row():\\n        with gr.Accordion(\"Uploaded data\", open=False):\\n            gr.Markdown(\\'You can change values in the table\\')\\n            table = gr.Dataframe(type=\"pandas\", col_count=2, interactive = True, headers = [\\'period\\', \\'retention_fact\\'])\\n            \\n    with gr.Row():    \\n        image = gr.Plot()    \\n\\n    # business logic of triggers and events\\n    upload_button.upload(fn=show_graph_for_file, inputs=[upload_button, periods], outputs=image, api_name=\"upload_graph\")\\n    upload_button.upload(fn=parse_file, inputs=[upload_button, periods], outputs=table, api_name=\"upload_csv\")\\n    default_button.click(fn=lambda x: show_graph_for_file(default_csv, x), inputs=[periods], outputs=image, api_name=\"upload_example_graph\")\\n    default_button.click(fn=lambda x: parse_file(default_csv, x), inputs=[periods], outputs=table, api_name=\"upload_example_csv\")\\n    table.change(fn=show_graph_for_df, inputs=[table, periods], outputs=image, api_name=\"upload_table_graph\")\\n    periods.change(fn=show_graph_for_df, inputs=[table, periods], outputs=image, api_name=\"upload_periods_graph\")\\n\\ndemo.launch(debug=True)\\n\\nLet’s look at it closer. We have the following elements in the interface:\\n\\nperiods - input parameter,\\n\\nupload_button - input parameter that allows you to load data from a .csv file,\\n\\ndefault_button - allows you to update table and graph with pre-defined values as an example,\\n\\ntable shows the data frame from uploaded data (either from .csv file or example); also, you could change the numbers in the table in place, and the graph will be updated - so it’s an input parameter as well,\\n\\nimage - output parameter, that shows a plot.\\n\\nImage by author\\n\\nFunction parse_file gets either file from upload_button or string from the default example and returns a pandas data frame we could use further. So, using data from files is pretty straightforward.\\n\\nThe crucial business logic is defined in the code snippet below. It defines actions for all interface elements:\\n\\nfor uploading .csv file - the table and the plot are updated,\\n\\nfor click on the button \"Show example\" - the table and the plot are updated,\\n\\nfor changing data in the table - only the plot is updated,\\n\\nfor changing the number of periods - only the plot is updated.\\n\\nupload_button.upload(fn=show_graph_for_file, inputs=[upload_button, periods], outputs=image, api_name=\"upload_graph\")\\nupload_button.upload(fn=parse_file, inputs=[upload_button, periods], outputs=table, api_name=\"upload_csv\")\\n\\ndefault_button.click(fn=lambda x: show_graph_for_file(default_csv, x), inputs=[periods], outputs=image, api_name=\"upload_example_graph\")\\ndefault_button.click(fn=lambda x: parse_file(default_csv, x), inputs=[periods], outputs=table, api_name=\"upload_example_csv\")\\n\\ntable.change(fn=show_graph_for_df, inputs=[table, periods], outputs=image, api_name=\"upload_table_graph\")\\nperiods.change(fn=show_graph_for_df, inputs=[table, periods], outputs=image, api_name=\"upload_periods_graph\")\\n\\nDefining the best-fit function\\n\\nThe essential part of our solution is finding the best-fit function for our factual data. Let’s look at how to do it.\\n\\nFirst, we define the function get_mse_for_retention that returns the error for the set of parameters (a, c and d). It also takes the data frame as an input.\\n\\nWe use standard Mean Squared Error (MSE) as the error we will minimize.\\n\\nThen, we will use scipy.optimize.minimize function for optimization. We need to pass just two parameters: the function to optimize (we passed the lambda function with a hard-coded data frame since we are optimizing only params) and the initial values for parameters (just a list of random values).\\n\\nAfter optimisation, we could access optimal params using result.x .\\n\\ndef get_mse_for_retention(params, df):\\n    tmp_df = df.copy()\\n    tmp_df[\\'retention_pred\\'] = tmp_df.index.map(\\n        lambda x: get_retention_same_event(params[0], params[1], params[2], x)\\n    )\\n    \\n    tmp_df[\\'se\\'] = (tmp_df.retention_fact - tmp_df.retention_pred)\\n    tmp_df[\\'se\\'] = tmp_df[\\'se\\']**2\\n    \\n    return tmp_df.se.mean() ** 0.5\\n\\nresult = scipy.optimize.minimize(lambda x: get_mse_for_retention(x, df), [random.random(), random.random(), random.random()])\\na, c, d = result.x\\nprint(a, c, d)\\n\\nThat’s it, now we know the theoretical retention curve for our factual data and can use it in our app for prediction.\\n\\nLast step\\n\\nI followed the same instructions and posted this app to HuggingFace Spaces as well. So you could try to play with it here.\\n\\nYou can find the whole code for both apps in GitHub.\\n\\nSummary\\n\\nIn this article, we’ve gone through the basics of the Gradio library and learned how to build pleasant web applications with only Python.\\n\\nWe’ve learned a couple of approaches:\\n\\nHigh-level gr.Interface class that allows you to get a working prototype quickly,\\n\\nMore customizable way of using gr.Blocks when you can specify the exact layout you need and define complex relations between inputs and outputs.\\n\\nThank you a lot for reading this article. I hope it was insightful to you. If you have any follow-up questions or comments, please leave them in the comments section.\\n\\nReference\\n\\nThis article is inspired by \"Building Generative AI Applications with Gradio\" course.'}}],\n",
       " 'fb44e21903f3': [{'id': '5137fdafb355',\n",
       "   'title': 'You’re Not The Only One Feeling AI Fatigue (Or: Why That New AI Tool Isn’t for You)',\n",
       "   'subtitle': 'More AI tools, more AI fatigue.',\n",
       "   'author': 'fb44e21903f3',\n",
       "   'publication_id': '76436a11a2b0',\n",
       "   'published_at': '2024-02-13 16:56:05',\n",
       "   'last_modified_at': '2024-02-13 16:56:05',\n",
       "   'tags': ['artificial-intelligence', 'technology', 'chatgpt', 'science'],\n",
       "   'topics': ['artificial-intelligence'],\n",
       "   'claps': 624,\n",
       "   'voters': 85,\n",
       "   'word_count': 1355,\n",
       "   'responses_count': 14,\n",
       "   'reading_time': 5.313207547169812,\n",
       "   'url': 'https://medium.com/artificial-corner/youre-not-the-only-one-feeling-ai-fatigue-or-why-that-new-ai-tool-isn-t-for-you-5137fdafb355',\n",
       "   'unique_slug': 'youre-not-the-only-one-feeling-ai-fatigue-or-why-that-new-ai-tool-isn-t-for-you-5137fdafb355',\n",
       "   'image_url': 'https://miro.medium.com/1*U-x0yxnQOUB7DvRS0YTaSw.png',\n",
       "   'lang': 'en',\n",
       "   'is_series': False,\n",
       "   'is_locked': True,\n",
       "   'is_shortform': False,\n",
       "   'top_highlight': 'I turned a deaf ear to the influencers persuading me to jump on every new AI tool',\n",
       "   'content': {'id': '5137fdafb355',\n",
       "    'content': 'You’re Not The Only One Feeling AI Fatigue (Or: Why That New AI Tool Isn’t for You)\\n\\nMore AI tools, more AI fatigue.\\n\\nImage made with Midjourney\\n\\nThere’s a pre and post ChatGPT era.\\n\\nBefore OpenAI unveiled ChatGPT, only a few programmers would dabble in creating chatbots and simple models for local execution, and only machine learning engineers and a few AI enthusiasts would use the word \"artificial intelligence\" on a daily basis.\\n\\nThings changed on November 30, 2022.\\n\\nA few weeks after ChatGPT was released, platforms like X, YouTube, Reddit, and even TikTok were flooded with influencers offering tips on leveraging AI to improve our everyday lives. Some offered genuinely valuable insights, while others were clearly just fishing for clicks. Little by little it was common to find posts with the \"next AI tool that beats ChatGPT\" or \"(introduce profession) are dead. Learn how to use ChatGPT to replace them.\"\\n\\nWhat in the world was going on?\\n\\nThen every week seemed that a new AI tool was unveiled or upgraded. Many companies were rolling out their own chatbots to the masses. We’re talking about big names like Perplexity AI, Google Bard, Bing Chat, Meta’s LLaMa, Stability, Hugging Face, Scale AI, and Antropic’s Claude AI, to name just a few.\\n\\nIt was like being stuck in a loop.\\n\\nSuddenly, staying updated with the latest models and their upgrades became a part of my daily routine. I would dedicate as much time as I could to this to keep learning and never fall behind.\\n\\nMonths into this new world, I asked myself,\\n\\nAre these new models and features truly a step forward, or are they the same old tech repackaged with a new name and perhaps with less intelligence?\\n\\nDo I need to learn most AI tools out there?\\n\\nHere’s the answer to these questions.\\n\\nIt’s the same old routine\\n\\nAn avalanche of papers, videos, and models hit us almost in real-time. Just when we’re getting the hang of one AI tool, along comes another with more features or an extra million parameters.\\n\\nThe novelty has worn off; I’m drained, swamped, and frankly, beat. Yet, I felt this internal push to dive into the \"latest model\" to see if it actually lived up to its claims or was as revolutionary as they say.\\n\\nThat was a self-imposed mandate that I eventually managed to shake off.\\n\\nMost AI tools aren’t for us. Let’s take this tweet as an example: \"I’ve spent countless hours using 1500+ AI tools. There’s only a handful I actually use … Here’s the top 24 AI tools that I use daily(ish).\" It really puts things into perspective. Technically only 1.6% of those tools ended up being of any real use to him.\\n\\nThis realization led me to think about the redundancy and limitations inherent in the countless tools at our disposal. At this point, I might as well consider rolling out my own version of ChatGPT with one of the APIs out there. Groundbreaking? Hardly.\\n\\nIn the grand scheme of the AI evolution, it’s not that groundbreaking. It’s not that I don’t value new knowledge; quite the contrary, it’s actually quite stimulating. Yet, it seems like something that would serve my personal curiosity more than it would make a dent in the public domain, where it would merely blend into the sea of existing tools without making any significant impact.\\n\\nThe relentless march of AI development is inevitable. However, the current slow pace is tied directly to chip availability. This implies that until a tech giant decides to invest in a bulk of GPUs to train more robust models (and set a new benchmark), we’re pretty much stuck running in circles.\\n\\nCompanies are launching low-quality AI products so they don’t fall behind\\n\\nDo you remember how bad was Google’s Bard when it was initially launched? I do. It didn’t support roles, couldn’t connect to external plugins, and was bad at reasoning, coding, and more.\\n\\nBut why did Google launch such a product? To avoid falling behind OpenAI’s ChatGPT. Although Bard wasn’t as good as ChatGPT, it was free and made people build sentences with the words \"Google\" and \"AI\" together. Probably that’s also the reason why they made that infamous Google Gemini Ultra demo back in December (now that Gemini Ultra is available to the public it’s clear Google overhyped its demo)\\n\\nI think launching a low-quality product like Bard was never Google’s initial strategy. That’s why Bard doesn’t exist anymore. Google rebranded Bard to Gemini also known as Gemini Advanced, which runs Gemini Ultra 1.0 (I know, all this branding thing also causes fatigue).\\n\\nGoogle should’ve given us a decent product like Gemini from the start, rather than something like Bard.\\n\\nBut this feeling of not falling behind in the AI race isn’t exclusive to Google. Other tech companies that are doing better have also disappointed us. Until now, OpenAI hasn’t given us a reliable tool that can detect if a text was generated with AI. In fact, they shut down their flawed AI text-detection tool. Also, Midjourney doesn’t offer a watermark (or other type of system) that helps people detect that their images were generated with AI.\\n\\nThe AI race is making companies launch low-quality AI products and features. This is why it’s better to stick with just a couple of them that fit our needs. Don’t feel anxious to try a new AI tool everyone is talking about if the one you’re using now does what you need.\\n\\nHow to manage AI fatigue?\\n\\nRecently Google phased out Bard and introduced a premium version known as Gemini Advanced. This might seem like yet another blip on the radar of endless announcements we’ve grown accustomed to. I’m convinced that without the current AI hype, this news might have been received differently. Probably in some weeks, this will be old news, much like the now-forgotten Google Bard.\\n\\nWhat to do with all this information?\\n\\nContrary to popular belief, I decided to hit pause a few months back, to really take in everything and apply the 80/20 principle.\\n\\nHere’s what I did.\\n\\nI turned a deaf ear to the influencers persuading me to jump on every new AI tool\\n\\nI let go of information that, while seemingly enticing on paper, I realized it wouldn’t make a difference to where I am now in terms of knowledge, tools I use, and the needs I have.\\n\\nI chose to focus on refining my existing skills and exploring how AI could assist me with this\\n\\nWhen a new AI tool or model emerges, I ask myself, ‘Is it better than my current tool?’ and ‘Does it fulfill a need I have?’ If the answer to both questions is a definitive no, I choose not to pay attention to it.\\n\\nEver since I focused on what’s truly important to me, I’ve managed to lift the self-imposed weight off my shoulders. This also helps me give the appropriate weight to important news that for others might just be one of the many posts on their feed.\\n\\nHere are my final thoughts.\\n\\nAI fatigue is a real thing, driven by both what’s happening around us and our own responses to it. It’s hard to control the information coming our way, but we have to choose what truly matters to us, always mindful of the context we’re in.\\n\\nWe should resist the urge to be immediately impressed by new technologies, avoiding the temptation to invest too much time in AI tools that we might ditch tomorrow. If a tool meets my needs perfectly today, chances are it will continue to do so tomorrow.\\n\\nJoin my newsletter with 35K+ people to get my free cheat sheets: ChatGPT, web scraping, Python for data science, automation, and more!\\n\\nIf you enjoy reading stories like these and want to support me as a writer, subscribe to my Substack. On Substack, I publish articles that you won’t find on the other platforms where I create content.\\n\\nSubscribe to Artificial Corner by ThePyCoach\\nArtificial Intelligence in plain English. In-depth tutorials to make the most of ChatGPT and other AI tools. The latest…artificialcorner.substack.com'}},\n",
       "  {'id': 'b3e8446773b9',\n",
       "   'title': 'Gemini Ultra vs GPT-4: Did Google Beat GPT-4 This Time?',\n",
       "   'subtitle': 'The good, bad, and unexpected of Gemini Ultra.',\n",
       "   'author': 'fb44e21903f3',\n",
       "   'publication_id': '76436a11a2b0',\n",
       "   'published_at': '2024-02-09 18:26:53',\n",
       "   'last_modified_at': '2024-02-09 18:26:53',\n",
       "   'tags': ['artificial-intelligence',\n",
       "    'technology',\n",
       "    'chatgpt',\n",
       "    'midjourney',\n",
       "    'science'],\n",
       "   'topics': ['artificial-intelligence', 'design'],\n",
       "   'claps': 504,\n",
       "   'voters': 96,\n",
       "   'word_count': 1162,\n",
       "   'responses_count': 9,\n",
       "   'reading_time': 5.834905660377359,\n",
       "   'url': 'https://medium.com/artificial-corner/gemini-ultra-vs-gpt-4-did-google-beat-gpt-4-this-time-b3e8446773b9',\n",
       "   'unique_slug': 'gemini-ultra-vs-gpt-4-did-google-beat-gpt-4-this-time-b3e8446773b9',\n",
       "   'image_url': 'https://miro.medium.com/1*zdt7zAOcfYY6K66kea0mUQ.jpeg',\n",
       "   'lang': 'en',\n",
       "   'is_series': False,\n",
       "   'is_locked': True,\n",
       "   'is_shortform': False,\n",
       "   'top_highlight': \"However, unlike DALL-E 3, Gemini doesn't improve your prompt. If I use the same prompt on ChatGPT, DALL-E 3 will generate a prompt that gives a more eye-catching look to the image.\",\n",
       "   'content': {'id': 'b3e8446773b9',\n",
       "    'content': 'Gemini Ultra vs GPT-4: Did Google Beat GPT-4 This Time?\\n\\nThe good, bad, and unexpected of Gemini Ultra.\\n\\nImage generated with Gemini Ultra\\n\\nGoogle just released Gemini Advanced, which is powered by its most capable AI model Gemini Ultra.\\n\\nYes, that’s the same model that a few months ago beat GPT-4 in the benchmarks. Now we have the opportunity to see ourselves if it’s actually better than GPT-4.\\n\\nIn this article, we’ll see the good and bad of Gemini Ultra by comparing it with GPT-4.\\n\\nThe Good of Gemini Ultra\\n\\nSpeed\\n\\nWhen it comes to speed in most tests Gemini is faster than GPT-4. The problem is that Gemini doesn’t always give good responses.\\n\\n\\n\\nWe’ll see the quality of the responses of Gemini in the rest of the article, but, yes, Gemini is faster than GPT-4.\\n\\nGoogle’s native apps\\n\\nI used both Gemini Ultra and GPT-4 as personal assistants and asked them to help me plan my next trip.\\n\\nI’m traveling next week from California to New York. Show me flights to New York and hotels near Central Park\\n\\nGemini automatically connects to Google apps such as Flights and Hotels to provide real-time information.\\n\\n\\n\\nGPT-4 lacks this feature. Plugins or a GPT with custom actions might get you something similar to Google’s native apps. By default, GPT-4 will respond something like this.\\n\\n\\n\\nThe Unexpected of Gemini Ultra: Realistic images\\n\\nGemini’s images seem like stock images taken by real photographers rather than images made with AI. In this regard, we can say that Gemini’s images are more realistic (or less sophisticated) than DALL-E 3 or Midjourney.\\n\\nmake an image of a programmer learning to code.\\n\\n\\n\\nHowever, unlike DALL-E 3, Gemini doesn’t improve your prompt. If I use the same prompt on ChatGPT, DALL-E 3 will generate a prompt that gives a more eye-catching look to the image.\\n\\n\\n\\nIf I had to choose an image for my article, I’d choose the image on the left generated by DALL-E 3. That’s a personal preference though.\\n\\nWhat it’s undeniable is that I wouldn’t be able to come up with the prompt below that DALL-E 3 generated for me.\\n\\nImagine a scene where a young programmer is deeply engrossed in learning to code. The setting is a cozy, well-lit room at night, filled with technology paraphernalia: a large monitor displaying lines of code, books on programming scattered around, and a cup of coffee steaming on the desk. The programmer, wearing casual attire, is focused intently on the screen, typing away on a keyboard, with a look of determination and curiosity. Notes and diagrams are pinned to a corkboard behind them, illustrating various programming concepts. The atmosphere is one of quiet dedication and the pursuit of knowledge.\\n\\nThat’s why I think that DALL-E 3 is more useful if you’re new to image generation or when you lack creativity.\\n\\nIf you have some experience with image generation, you could control the aesthetic of Gemini’s images as I do in the prompt below. In that way, Gemini’s images will look less realistic, which seems to be the default.\\n\\npodium with bots in first second and third place, sunday comics aesthetica\\n\\nI wasn’t happy with the images Gemini generated, so I asked if the bot in position #1 could hold a trophy and I got what I asked for.\\n\\n\\n\\nNow, if you’re an expert in creating detailed prompts for images, I think DALL-E 3 or Midjourney might be better than Gemini.\\n\\nLet’s test the prompt below with Gemini.\\n\\nA widescreen landscape style image with an action movie point of view featuring, in the center, a man with a bewildered expression, pushing a shopping cart. The aisle is lined with price tags, but instead of ordinary products, the shelves display a variety of intricate mechanical parts suggesting a surreal or futuristic shopping experience. The perspective should be from the end of the aisle looking towards the entrance. Sunday comics aesthetica\\n\\n\\n\\nHere’s what DALL-E 3 generated.\\n\\n\\n\\nOverall, I’d use Gemini to generate realistic images with a simple prompt. Other than that, I’d use either DALL-E 3 or Midjourney.\\n\\nNote: I wanted to test image generation in Europe, but every time I tried I got the message \"I can’t create images yet so I’m not able to help you with that.\" I could fix that by switching to the USA with a VPN.\\n\\nThe Bad of Gemini Ultra\\n\\nReasoning\\n\\nI gave both models two reasoning exercises to see if they could get the right answer.\\n\\nFirst, I started with this simple exercise.\\n\\nFind the next number in the sequence: 30, 45, 90, 225, 675, …\\n\\nGemini got the answer quickly, but it was wrong.\\n\\n\\n\\nThat said, when I clicked on \"show drafts\" I found that draft #3 had the right answer, so we can say that it got it right in the third attempt.\\n\\nIt took GPT-4 more time, but it got the right answer on the first try.\\n\\n\\n\\nThe second exercise was more challenging.\\n\\nSolve this exercise:\\n\\nLOO, MON, NOM, OOL, ____\\n\\nA. POK\\nB. HOL\\nC. HOK\\nD. JOI\\n\\nThe three initial drafts of Gemini were wrong, so I asked again and got the correct answer in draft 3.\\n\\n\\n\\nOn the other hand, GPT-4 failed the first time but found the correct answer on the second attempt.\\n\\nOverall, GPT-4 is better at reasoning than Gemini.\\n\\nCode generation\\n\\nBoth models are good at explaining code, but when it comes to generating code it seems Gemini has some limitations set by Google.\\n\\nIf we want to create a snake game, Gemini generates the code and you can even export it to Google Colab with one click.\\n\\n\\n\\nBut when you try to generate other types of scripts, it starts generating the code and suddenly stops and throws the message below.\\n\\n\\n\\nSearching on the internet, I found that some YouTubers were experiencing the same issues with Gemini not only when generating code but also when explaining code.\\n\\nThat never happens to me with GPT-4, so I’d say GPT-4 beats Gemini Ultra in coding.\\n\\nThat’s it! I didn’t compare features like reading PDFs or analyzing datasets because right now Gemini doesn’t support uploading files other than images. Also, this time I didn’t do a creativity test because that’s a bit subjective, so I leave that to you.\\n\\nLet me know in the comments which one you think is the best model.\\n\\nJoin my newsletter with 35K+ people to get my free cheat sheets: ChatGPT, web scraping, Python for data science, automation, and more!\\n\\nIf you enjoy reading stories like these and want to support me as a writer, subscribe to my Substack. On Substack, I publish articles that you won’t find on the other platforms where I create content.\\n\\nSubscribe to Artificial Corner by ThePyCoach\\nArtificial Intelligence in plain English. In-depth tutorials to make the most of ChatGPT and other AI tools. The latest…artificialcorner.substack.com'}},\n",
       "  {'id': 'bb4d6a735fc1',\n",
       "   'title': 'I Tried Multiple AI Coding Assistants. These Are The Best',\n",
       "   'subtitle': 'Best AI coding assistants for beginners and experienced programmers.',\n",
       "   'author': 'fb44e21903f3',\n",
       "   'publication_id': '76436a11a2b0',\n",
       "   'published_at': '2024-01-25 18:39:41',\n",
       "   'last_modified_at': '2024-01-25 18:39:41',\n",
       "   'tags': ['chatgpt',\n",
       "    'technology',\n",
       "    'artificial-intelligence',\n",
       "    'programming',\n",
       "    'python'],\n",
       "   'topics': ['artificial-intelligence', 'programming'],\n",
       "   'claps': 1371,\n",
       "   'voters': 324,\n",
       "   'word_count': 1255,\n",
       "   'responses_count': 22,\n",
       "   'reading_time': 6.635849056603773,\n",
       "   'url': 'https://medium.com/artificial-corner/i-tried-multiple-ai-coding-assistants-these-are-the-best-bb4d6a735fc1',\n",
       "   'unique_slug': 'i-tried-multiple-ai-coding-assistants-these-are-the-best-bb4d6a735fc1',\n",
       "   'image_url': 'https://miro.medium.com/1*4Xv28m71C-27267n8fP-WQ.png',\n",
       "   'lang': 'en',\n",
       "   'is_series': False,\n",
       "   'is_locked': True,\n",
       "   'is_shortform': False,\n",
       "   'top_highlight': 'I Tried Multiple AI Coding Assistants. These Are The Best',\n",
       "   'content': {'id': 'bb4d6a735fc1',\n",
       "    'content': 'I Tried Multiple AI Coding Assistants. These Are The Best\\n\\nBest AI coding assistants for beginners and experienced programmers.\\n\\nCreated with Midjourney\\n\\nOver the past months, I’ve tried different AI coding assistants to make my life easier as a programmer.\\n\\nThere are many tools out there but none of them is perfect. One might be more convenient if you’re learning to code, while another might be better if you want to test your code.\\n\\nHere are the best AI coding assistants I found.\\n\\n1. GitHub Copilot: My favorite general-purpose coding assistant\\n\\nGitHub’s AI tool is a game-changer for real-time code writing. What’s cool about it is that it offers an interaction style similar to ChatGPT, but it’s focused on coding. Plus, it has the ability to keep building out a program you’re working on in the editor.\\n\\nOne feature that really stands out to me is the chat function. You can literally quiz it about constructing functions or clear up any doubts about specific bits of your code. It’s like having a coding guru on standby, ready to jump in with insights or solutions.\\n\\ncomplete def fibonacci\\n\\n\\n\\nAnother thing I really like is that Copilot doesn’t just stop after giving a response. It keeps the ball rolling, offering up possible questions I might want to ask next or things to consider. It’s like having an ongoing conversation with your code.\\n\\nPlus, there’s this feature that lets you move the suggested code into your editor. This creates a seamless flow, letting you bounce between the chat and the editor.\\n\\n\\n\\nFor those who love to multitask within the editor, you can get the Copilot chat by pressing Ctrl + i.\\n\\n\\n\\nHere are some of my favorite commands:\\n\\nDiving deeper into the code: /explain\\n\\nGetting unstuck or fixing code snags: /fix\\n\\nConducting tests on the code: /tests\\n\\n\\n\\nI have to say Copilot is one of my favorite tools. It’s like having the best of ChatGPT, but baked right into your IDE, making coding effortless and more efficient.\\n\\nYou can add the GitHub Copilot extension to Visual Studio Code, Visual Studio, JetBrains, and Neovim.\\n\\n2. CodiumAI: Good for testing\\n\\nWhat sets CodiumAI apart is its features, which are a breath of fresh air compared to other AI tools. Instead of just focusing on code completion, it hones in on testing our code and providing us with ways to make it better.\\n\\n\\n\\nThis feature really shines when doing project development, pinpointing weak spots and potential vulnerabilities.\\n\\n\\n\\nThe assistant doesn’t just identify issues; it goes a step further by suggesting tests we can create (if they don’t already exist). Plus, there’s the option to interact with each test, tweaking them to fit our needs more closely.\\n\\n\\n\\nCodiumAI also offers code explanation. It breaks down everything from inputs and code flow to outputs and examples. The level of documentation is amazing.\\n\\n\\n\\nThis tool has the best test generator I’ve been working with recently. It plays to its strengths brilliantly, focusing on running tests and giving some good suggestions.\\n\\n3. AWS Code Whisperer: Good for writing apps linked to the Amazon ecosystem\\n\\nLike other AI coding assistants, AWS Code Whisperer lets us generate code suggestions ranging from little snippets to entire functions right in the IDE.\\n\\n\\n\\nBut, in addition to general-purpose code suggestions, this tool is designed to provide code suggestions for using AWS APIs. If you’re writing apps linked to the Amazon ecosystem, this coding assistant will be more useful than others.\\n\\n\\n\\nHere’s a feature I like. If you write a comment in the editor about the function you’re brainstorming, in a few seconds your idea will be turned into code.\\n\\n\\n\\nThis tool also provides references for the code it suggests, but when you try to follow these references, they sometimes lead to non-working links.\\n\\n4. Tabnine: An intuitive coding companion\\n\\nThis coding assistant’s standout feature is its ability to predict what we’re aiming to code, effortlessly filling in the gaps as we go.\\n\\nSat I want a function that creates a list. I just need to give a proper name to the function\\n\\n\\n\\nand this coding assistant autocompletes the function for me.\\n\\n\\n\\nAdditionally, Tabnine’s chat feature is very useful. It allows us to ask questions about the code we’re crafting in the editor. It’s like having a coding buddy right there with you, ready to tackle any coding problems that pop up.\\n\\n\\n\\nLet’s create a prompt to put this feature to the test.\\n\\nHow does the memory usage scale with the size of the input in the create_list function?\\n\\n\\n\\nNow, let’s mess up the initial function and ask the coding assistant if it can fix the code.\\n\\n\\n\\nI’ve encountered an issue with the create_list function in my code. Could you help me identify any potential errors and suggest how to fix them?\\n\\nHere’s the feedback.\\n\\n\\n\\nNow, let’s see some commands this AI coding assistant has.\\n\\n/explain-code\\n\\n\\n\\nIf we want to create scenarios for testing the functions we’ve created, we use this command:\\n\\n/generate-test-for-code\\n\\n\\n\\nNot bad! I was hoping for more specific examples to spotlight the function’s intrinsic limitations though.\\n\\nOn a different note, we can also get the AI to auto-fill examples just like we did when crafting the create_list function in the editor.\\n\\n\\n\\nThis AI coding assistant is a time saver, sparing us from typing out line after line of code. Still, there’s room for improvement.\\n\\n5. ChatGPT/Bard: Amazing for learning to code\\n\\nChatGPT and Bard are good for a wide range of tasks and coding is one of them. However, chatbots might not always be the best option. This is mainly because they tend to throw in a lot of extra information. Sure, we could streamline this by diving into prompt engineering, but for those who aren’t too savvy with these techniques, it can be a bit of a hurdle.\\n\\nWrite Python code for a function that adds up the elements of a list\\n\\n\\n\\nDraft a set of test cases\\n\\n\\n\\nAs for Bard, when it comes to functionality, it’s pretty much in the same ballpark as ChatGPT. Bard is a bit more transparent about the sources it pulls its code responses from, but it’s prone to slip-ups and often misses the mark.\\n\\nFor me, toggling between ChatGPT/Bard’s interface and a regular code editor isn’t a big deal, especially if I’m learning a new coding concept. But nowadays, specialized coding assistants are tailor-made to support us in developing and testing our code, so why settle for chatbots?\\n\\nSummary\\n\\nWhen it comes to getting a grip on a new programming concept, I’d definitely use ChatGPT or Bard. They’re like info goldmines, offering a deep dive into whatever we’re curious about.\\n\\nCodiumAI is good for code testing. It’s all about speed and efficiency, giving you real-time feedback as you code, and pointing out potential pitfalls.\\n\\nGitHub Copilot is my go-to general-purpose coding assistant.\\n\\nExperienced programmers can also benefit from coding assistants like AWS Code Whisperer and Tabnine.\\n\\nThe final choice will be based on your goals.\\n\\nJoin my newsletter with 35K+ people to get my free cheat sheets: ChatGPT, web scraping, Python for data science, automation, and more!\\n\\nIf you enjoy reading stories like these and want to support me as a writer, subscribe to my Substack. On Substack, I publish articles that you won’t find on the other platforms where I create content.\\n\\nSubscribe to Artificial Corner by ThePyCoach\\nArtificial Intelligence in plain English. In-depth tutorials to make the most of ChatGPT and other AI tools. The latest…artificialcorner.substack.com'}},\n",
       "  {'id': 'e6dd223d6ae0',\n",
       "   'title': 'The Best GPTs for Programmers',\n",
       "   'subtitle': 'These GPTs will automate part of your coding projects.',\n",
       "   'author': 'fb44e21903f3',\n",
       "   'publication_id': '76436a11a2b0',\n",
       "   'published_at': '2024-01-19 17:59:27',\n",
       "   'last_modified_at': '2024-01-19 17:59:27',\n",
       "   'tags': ['chatgpt',\n",
       "    'artificial-intelligence',\n",
       "    'technology',\n",
       "    'python',\n",
       "    'programming'],\n",
       "   'topics': ['programming'],\n",
       "   'claps': 613,\n",
       "   'voters': 179,\n",
       "   'word_count': 924,\n",
       "   'responses_count': 6,\n",
       "   'reading_time': 4.836792452830188,\n",
       "   'url': 'https://medium.com/artificial-corner/the-best-gpts-for-programmers-e6dd223d6ae0',\n",
       "   'unique_slug': 'the-best-gpts-for-programmers-e6dd223d6ae0',\n",
       "   'image_url': 'https://miro.medium.com/1*g0gnC_K7D0CbCakIYaxVdQ.png',\n",
       "   'lang': 'en',\n",
       "   'is_series': False,\n",
       "   'is_locked': True,\n",
       "   'is_shortform': False,\n",
       "   'top_highlight': '',\n",
       "   'content': {'id': 'e6dd223d6ae0',\n",
       "    'content': 'The Best GPTs for Programmers\\n\\nThese GPTs will automate part of your coding projects.\\n\\nCreated with Canva\\n\\nSince the GPT store was released, I’ve been trying different GPTs to automate part of my work as a programmer.\\n\\nThe GPT store is one week old, so I didn’t find many good GPTs in the store (most have the same functionalities). That said, I selected a few of them that are worth a try whether you’re learning to code or are already an experienced programmer.\\n\\nHere are some of the best GPTs I found for programmers.\\n\\nIf you don’t feel like reading, watch my YouTube video below.\\n\\n\\n\\n#1 DesignerGPT: Create websites from scratch\\n\\nHave you ever wanted to create a website from any idea you have in mind? DesignerGPT can help you with that! We only need to give an idea and it’ll create a basic website for us in seconds.\\n\\nSay I want to create a pizzeria website.\\n\\n\\n\\nHere’s the website this GPT created for me.\\n\\n\\n\\nIf you want to add something to the page, you can continue the chat or you can get the HTML code used for this AI-generated website to develop it further on your own.\\n\\n\\n\\nIf you’re new to coding, you might learn something new by analyzing the code generated.\\n\\nHere’s one thing. If you refresh the site this GPT generates, you’ll see that the main image changes every time. This is due to the line of code below that connects to Unsplash to get random images.\\n\\n<img src=\"https://source.unsplash.com/featured/?pizza\" alt=\"Delicious Pizza\" />ScrapeGPT\\n\\n#2 Screenshot to CodeGPT: Copy websites with a screenshot\\n\\nHave you ever wanted to copy a website you’ve just visited? This GPT can generate code that can be your starting point for this project.\\n\\nScreenshot to CodeGPT is a GPT that lets you build websites from screenshots! You only need to take a screenshot of an existing website, upload it to ChatGPT and it’ll convert it to HTML, Tailwind, or JS code.\\n\\nSay I want to clone my website, so I take the screenshot below (by the way, you can get my free ChatGPT cheat sheet there)\\n\\n\\n\\nNow I upload it to this GPT and I get the HTML code that I can use as a starting point to build this website.\\n\\n\\n\\nHere\\'s what I get after copying and pasting the code to an HTML file.\\n\\n\\n\\nIt doesn’t look quite like my website, but if I quickly relocate some sections, I’ll at least have the structure of the website.\\n\\n#3 Code Tutor: Solve your coding questions by thinking rather than cheating\\n\\nCode Tutor is an amazing GPT created by Khan Academy that can help you every time you get stuck in your coding projects.\\n\\nUnlike GPT-4 (and other custom GPTs), this GPT doesn’t give you answers to your coding questions right away but encourages you to think to find the solution to your problems step by step.\\n\\nSay I don’t know the difference between tuples and lists/dictionaries in Python. Instead of listing the differences in the first response, Code Tutor encourages me to say everything I know about them.\\n\\n\\n\\nExplaining a concept is a good chance to see how much you know about a topic. In my response, I quickly describe what I know and admit what concepts are still unclear to me.\\n\\n\\n\\nCode Tutor defines mutable and immutable objects and now asks new questions to better understand these concepts.\\n\\n\\n\\nDo you see the difference?\\n\\nInstead of getting the answers right away, we’re using the trial-and-error technique to find the answers to our questions. We’ll get the same answers as with GPT-4 or Google search, but in the process of getting the final answer, we get intermediate questions that will guide us toward our final goal. This is a fundamental method of problem-solving, which is recommended to be used when learning to code.\\n\\n#4 ScrapeGPT: Extract data from websites\\n\\nScrapeGPT helps you extract data from websites in seconds. You only need to go to the target website, save it as a PDF, and specify the data you want to extract by providing a sample item.\\n\\nI’ll use as an example the \"web scraping courses\" search result from Udemy.\\n\\n\\n\\nFirst, we have to save the page as a PDF:\\n\\nGo to the page you want to extract data from\\n\\nIf you’re on Chrome or Edge, click on \"File\" and select \"Print\", on \"Layout\" select \"Landscape\" and then click on \"Save\" to save the page as a PDF\\n\\nIf you’re on Safari, click on \"File\" and then select \"Export as PDF\"\\n\\nThen, in the prompt, we have to provide a sample item specifying the data we wish to extract. I’ll use the first course listed as a sample.\\n\\nCourse: Web Scraping in Python BeautifulSoup, Selenium & Scrapy 2023\\nInstructor: Frank Andrade\\nRating: 4.4\\nNumber of ratings: 1,087\\nHours: 10 total hours\\n\\nFinally, we get a link with a CSV file that has the data extracted.\\n\\n\\n\\nSimple, right?\\n\\nThat’s it! Let me know in the comments if your favorite GPT wasn’t included in the list.\\n\\nJoin my newsletter with 35K+ people to get my free cheat sheets: ChatGPT, web scraping, Python for data science, automation, and more!\\n\\nIf you enjoy reading stories like these and want to support me as a writer, subscribe to my Substack. On Substack, I publish articles that you won’t find on the other platforms where I create content.\\n\\nSubscribe to Artificial Corner by ThePyCoach\\nArtificial Intelligence in plain English. In-depth tutorials to make the most of ChatGPT and other AI tools. The latest…artificialcorner.substack.com'}},\n",
       "  {'id': '84e568626e89',\n",
       "   'title': 'OpenAI Just Released The GPT Store. Here’s How To Use It And Make Money With Your GPT',\n",
       "   'subtitle': 'Learn how to publish your GPT to the store and monetize it.',\n",
       "   'author': 'fb44e21903f3',\n",
       "   'publication_id': '76436a11a2b0',\n",
       "   'published_at': '2024-01-11 14:04:50',\n",
       "   'last_modified_at': '2024-01-11 14:04:50',\n",
       "   'tags': ['artificial-intelligence',\n",
       "    'technology',\n",
       "    'chatgpt',\n",
       "    'science',\n",
       "    'python'],\n",
       "   'topics': ['programming'],\n",
       "   'claps': 2314,\n",
       "   'voters': 392,\n",
       "   'word_count': 826,\n",
       "   'responses_count': 29,\n",
       "   'reading_time': 4.166981132075472,\n",
       "   'url': 'https://medium.com/artificial-corner/openai-just-released-the-gpt-store-heres-how-to-use-it-and-make-money-with-your-gpt-84e568626e89',\n",
       "   'unique_slug': 'openai-just-released-the-gpt-store-heres-how-to-use-it-and-make-money-with-your-gpt-84e568626e89',\n",
       "   'image_url': 'https://miro.medium.com/1*d41v0LCPk7uIG0okVZ_kCQ.png',\n",
       "   'lang': 'en',\n",
       "   'is_series': False,\n",
       "   'is_locked': True,\n",
       "   'is_shortform': False,\n",
       "   'top_highlight': 'As you can see there are three, but the one I created for a previous tutorial is the first (I think the comment bubble on the right means how many conversations have been started with a GPT).',\n",
       "   'content': {'id': '84e568626e89',\n",
       "    'content': 'OpenAI Just Released The GPT Store. Here’s How To Use It And Make Money With Your GPT\\n\\nLearn how to publish your GPT to the store and monetize it.\\n\\nImage created with DALL-E 3\\n\\nThe app store for AI was just released!\\n\\nA few months ago, OpenAI said we could monetize our GPTs on a marketplace they call the GPT Store. Well, yesterday they released the GPT Store to ChatGPT Plus users and now you can publish your GPT to the GPT Store and make money with it.\\n\\nHere’s how.\\n\\nFirst look at the GPT Store\\n\\nIf you’re a ChatGPT Plus, Team, or Enterprise user, you can explore the GPT store by opening the sidebar and clicking \"Explore GPTs.\"\\n\\nHere’s how it looks.\\n\\n\\n\\nYou can search any GPT as long as they’re public. Different GPTs can have the same name but you can distinguish them by looking at the name of the builder.\\n\\nLet’s see how many \"ScrapeGPT\" are in the store.\\n\\n\\n\\nAs you can see there are three, but the one I created for a previous tutorial is the first (I think the comment bubble on the right means how many conversations have been started with a GPT).\\n\\nIn case you don’t have a specific GPT in mind, you can explore the top pick for categories such as writing, productivity, programming, education, and more.\\n\\n\\n\\nTrying any of them is as simple as clicking on the GPT and then following the instructions written by the builder.\\n\\nHow to make money in the GPT store\\n\\nTo make money in the GPT store, you need to have a GPT. Creating a GPT is very simple and there’s no code required (you can check my tutorial here).\\n\\nThen you need to follow these two requirements.\\n\\n1. Make sure your GPT is saved for everyone.\\n\\n\\n\\n2. Verify your Builder Profile. To do so, go to setting, builder profile, and either enable your name or a website.\\n\\n\\n\\nOnce the two requirements are met, you should see your GPT in the store\\n\\nIn case you have a website, I highly recommend you verify your website with OpenAI so you can get some traffic in case your GPT gets users and avoid showing your name to the public (this name is taken from your billing information). Here are the steps you need to follow to verify your website.\\n\\nGood, now your GPT is in the store … but how would your GPT make money?\\n\\nOpenAI hasn’t given much detail on how the GPT builder revenue program works. They just said builders will be paid based on user engagement with their GPTs. This means that the more people use your GPT, the more money you make.\\n\\nRemember the bubble that every GPT has?\\n\\n\\n\\nProbably that’s a metric they’ll use to see user engagement with a GPT.\\n\\nWith almost 1k bubbles, I think my GPT isn’t doing that bad. That said, cloning a GPT is as simple as examining its behavior and creating a new GPT with the observations you made. I think anyone could even extract the files of a GPT (aka knowledge) if the creator enabled the code interpreter on their GPT!!\\n\\nLet’s see how to make your GPT stand out and learn some things you could do to prevent others from cloning your GPT.\\n\\nHow to stand out on the GPT Store\\n\\nThe low barrier to entry for making GPTs will make earning money on the GPT store difficult. Not everyone will make tons of money off their GPT, but I think those with more chances of success will:\\n\\nUse custom actions: This is a feature that allows your GPT to connect to an API. Connecting to APIs gives your GPT new functionalities that others won’t be able to replicate unless they have access to the API (here you can see my tutorial on how to add custom action to your GPT)\\n\\nUse knowledge: Knowledge is a feature that allows you to add files to your GPT. Adding exclusive information could enrich your GPT and help it stand out from the pack. Just remember that files can be downloaded when the code interpreter is enabled.\\n\\nUnless your GPT has one of these features, it’ll be very hard to earn a good sum of money in the GPT Store. Making money on this store will be tough, but even if you don’t make tons of money, you can benefit from the traffic it gets by verifying your domain and adding it to your GPT.\\n\\nJoin my newsletter with 35K+ people to get my free cheat sheets: ChatGPT, web scraping, Python for data science, automation, and more!\\n\\nIf you enjoy reading stories like these and want to support me as a writer, subscribe to my Substack. On Substack, I publish articles that you won’t find on the other platforms where I create content.\\n\\nSubscribe to Artificial Corner by ThePyCoach\\nArtificial Intelligence in plain English. In-depth tutorials to make the most of ChatGPT and other AI tools. The latest…artificialcorner.substack.com'}},\n",
       "  {'id': '4eaff6178983',\n",
       "   'title': 'Artificial Corner Will No Longer Publish Stories On This Site',\n",
       "   'subtitle': 'Here’s why and some important details.',\n",
       "   'author': 'fb44e21903f3',\n",
       "   'publication_id': '76436a11a2b0',\n",
       "   'published_at': '2023-12-26 17:18:38',\n",
       "   'last_modified_at': '2023-12-26 17:18:38',\n",
       "   'tags': ['chatgpt', 'technology', 'artificial-intelligence', 'science'],\n",
       "   'topics': ['artificial-intelligence'],\n",
       "   'claps': 294,\n",
       "   'voters': 40,\n",
       "   'word_count': 300,\n",
       "   'responses_count': 4,\n",
       "   'reading_time': 1.3320754716981131,\n",
       "   'url': 'https://medium.com/artificial-corner/artificial-corner-will-no-longer-publish-stories-on-this-site-4eaff6178983',\n",
       "   'unique_slug': 'artificial-corner-will-no-longer-publish-stories-on-this-site-4eaff6178983',\n",
       "   'image_url': 'https://miro.medium.com/0*NoKpYRcRcsXEes3B',\n",
       "   'lang': 'en',\n",
       "   'is_series': False,\n",
       "   'is_locked': False,\n",
       "   'is_shortform': False,\n",
       "   'top_highlight': '',\n",
       "   'content': {'id': '4eaff6178983',\n",
       "    'content': 'Artificial Corner Will No Longer Publish Stories On This Site\\n\\nHere’s why and some important details.\\n\\nPhoto by Jan Tinneberg on Unsplash\\n\\nFrom 2024, Artificial Corner will no longer publish original stories on this site.\\n\\nSome points of clarification:\\n\\nArtificial Corner is not dead. Actually, it’s thriving with over 35k subscribers and hundreds of paid subscribers … but on Substack.\\n\\nIn 2024, I’ll still republish some of my free articles here, while the paid articles will be exclusive to Substack (I’ll also republish articles from members of the Artificial Corner team)\\n\\nUnfortunately, I won’t be able to review articles, so please, do not submit articles to Artificial Corner.\\n\\nWhy Substack? Well, on Substack, I can offer more to my subscribers than weekly articles.\\n\\nIf you’re an AI enthusiast, on Substack you can not only keep up with AI through my 3 weekly articles but also get my ChatGPT course and go beyond that by learning the tech stuff behind AI by taking my programming courses, which you can redeem for free by becoming a paid Substack subscriber.\\n\\nOn Substack, free subscribers can get any of my cheat sheets (web scraping, python, data science, chatgpt), and paid subscribers can get up to 2 of my Udemy course for free. For more details on the benefits my free and paid subscribers have on Substack, read this article.\\n\\nFree and Premium Resources for My Subscribers\\nHere you can get my free cheat sheet and can redeem my Udemy courses for free.artificialcorner.com\\n\\nOnly for these holidays, I created a 25% off coupon for the annual plan that you can get here only for a few days.\\n\\nOverall, 2023 was the best year for me as a writer/blogger/content creator, so I want to thank you all! I’m sure 2024 will be even better.\\n\\nI wish you all a Happy New Year!'}},\n",
       "  {'id': '4ff7e5973b05',\n",
       "   'title': '“Google Will Kill ChatGPT” and Other Overhyped AI Predictions We Heard In 2023',\n",
       "   'subtitle': 'Here are some predictions that I doubt will happen in 2024 or the near future (and why I think so).',\n",
       "   'author': 'fb44e21903f3',\n",
       "   'publication_id': '76436a11a2b0',\n",
       "   'published_at': '2023-12-20 18:41:12',\n",
       "   'last_modified_at': '2023-12-20 18:41:12',\n",
       "   'tags': ['artificial-intelligence', 'chatgpt', 'technology', 'science'],\n",
       "   'topics': ['artificial-intelligence'],\n",
       "   'claps': 491,\n",
       "   'voters': 46,\n",
       "   'word_count': 1166,\n",
       "   'responses_count': 8,\n",
       "   'reading_time': 4.95,\n",
       "   'url': 'https://medium.com/artificial-corner/google-will-kill-chatgpt-and-other-overhyped-ai-predictions-we-heard-in-2023-4ff7e5973b05',\n",
       "   'unique_slug': 'google-will-kill-chatgpt-and-other-overhyped-ai-predictions-we-heard-in-2023-4ff7e5973b05',\n",
       "   'image_url': 'https://miro.medium.com/1*R_NH8O9YvZ4zVACxdQwJow.png',\n",
       "   'lang': 'en',\n",
       "   'is_series': False,\n",
       "   'is_locked': True,\n",
       "   'is_shortform': False,\n",
       "   'top_highlight': '',\n",
       "   'content': {'id': '4ff7e5973b05',\n",
       "    'content': '\"Google Will Kill ChatGPT\" and Other Overhyped AI Predictions We Heard In 2023\\n\\nHere are some predictions that I doubt will happen in 2024 or the near future (and why I think so).\\n\\nMidjourney\\n\\n2023 was the year of AI. Every month, we’ve seen new AI tools being launched, advancements in the field, upgrades, and more things that kept the field of AI moving.\\n\\nOverhyped AI predictions weren’t missing in 2023 either. Throughout the year we heard things like \"AGI was (or will soon be) achieved\" or \"AI will take everyone’s job.\"\\n\\nHere’s why I think they’re overhyped and doubt they’ll happen in the next years.\\n\\n1) \"Google Will Kill ChatGPT\"\\n\\nAlmost every month there’s a new ChatGPT killer … at least that’s what we see on the media. The latest ChatGPT killer (by consensus) was Gemini Ultra, a tool that beat GPT-4 in the benchmarks but isn’t available yet to the public.\\n\\nEven if Gemini Ultra is slightly superior to GPT-4, tech superiority doesn’t always translate to market dominance and Google knows that (probably that’s why they created too much hype with their demo).\\n\\nI checked some articles and videos that claim Google will kill ChatGPT to find out how they came to such conclusions. Here are some of the arguments I found.\\n\\nGoogle is light years ahead of OpenAI when it comes to data.\\n\\nGoogle’s stock has been on the rise because many believe in their AI investments.\\n\\nThe educational market will determine who is the winner of the AI race (and Google is apparently doing well there).\\n\\nI don\\'t think any of these arguments are enough to claim that Google will indeed kill ChatGPT.\\n\\nWhy? Well, #2 is not a good metric to say whether a product will kill its competitor. Recently, Google shares sank following reports that some of their AI Gemini Ultra demo was faked. This doesn’t mean Gemini Ultra is a bad model or that it can’t compete with GPT-4 but shows the consequences of Google overhyping its own product.\\n\\nOn the other hand, even if #1 is true, it’s not enough. Google might have the resources to create a tool to compete toe to toe with ChatGPT, but that doesn’t guarantee the success of its product. In fact, some of the AI products released by Google were very disappointing.\\n\\nWhen Bard was launched many realized it was years behind ChatGPT. In 2023, Bard’s monthly visits were very low if you compare them to ChatGPT.\\n\\nSource: Similarweb\\n\\nEven if Gemini Ultra is better than ChatGPT, remember this - tech superiority doesn’t always translate to market dominance.\\n\\nThere are better web browsers than Chrome\\n\\nThere are better phones than the iPhone\\n\\nThere are more advanced operating systems than Windows\\n\\nHowever, none of these products were killed by its competitors due to its tech superiority. AI was all over the media only after ChatGPT was released and that gave OpenAI an advantage over its competitors\\n\\nFinally, #3 is a good point, but Google isn’t a clear winner in the AI educational market. They might’ve released products like NotebookLM that target the educational market, but it can become another experiment that ends up in the Google Graveyard. Time will tell.\\n\\n2) \"AI/ChatGPT is overhyped. Soon people will lose interest\"\\n\\nSome people don’t understand that AI is here to stay. Hypes don’t last forever, but if a product meets the expectations of users, it will not suddenly disappear.\\n\\nIn June, ChatGPT had its first monthly drop in traffic since launch and many were already saying things like \"people are losing interest in chatbots\" or \"the ChatGPT/AI hype is over\"\\n\\nIt seems they forgot school season ended in June in the USA, so fewer students were using ChatGPT during summer vacation.\\n\\nYes, ChatGPT traffic slowed over the summer but has since recovered to near-peak levels. ChatGPT dropped to 1.4 billion worldwide visits in August, but it bounced back to about 1.5 billion in September and reached around 1.7 billion visits in October.\\n\\nSource: Similarweb\\n\\nJust in November, OpenAI CEO announced that 100 million people are using ChatGPT on a weekly basis and over 2 million developers are currently building on the company’s API. This shows how both users and developers are making ChatGPT one of the fastest-growing services ever.\\n\\nI doubt AI will lose all its charm anytime soon.\\n\\nIn 2024, AI news might decrease, the media might give less coverage to AI, and people might talk less about AI on the internet. That’s normal because hypes don’t last forever and whether this decreases or increases will depend on how the field of AI evolves, but there’s one thing clear - AI is here to stay.\\n\\n3) \"AI Will Take Everyone’s Jobs\"\\n\\nI can’t count how many times I read the phrase \"AI will replace us.\"\\n\\nMany said that writers, programmers, and analysts would lose their jobs to AI soon and that some professionals were already replaced by AI in 2023. However, a study on The State of AI in 2023 doesn’t show that.\\n\\nHere are some of the study’s findings based on responses from people involved in AI initiatives at about 350 organizations.\\n\\nA net +37% of all respondents increased headcount over the last 12 months\\n\\nA net +60% of all respondents anticipate that headcount will increase over the next 12 months.\\n\\nJust 17% of all respondents indicated a reduction in headcount over the last 12 months and just 3.5% attributed AI as the primary reason for headcount reduction\\n\\nAnother study revealed that 14% of workers have already experienced job displacement due to automation or AI, while in a recent report of 750 business leaders using AI, 37% said that AI replaced workers in 2023. That said, there’s also a feeling that AI is enabling business leaders to restructure and redefine the jobs we do. Companies will still need someone to prompt the AI, make sense of the results, and take action.\\n\\nThis shows once again that the current fears of AI replacing us may exceed the actual impact. Many businesses have integrated AI and more are exploring its adoption, but this doesn’t necessarily equate to immediate job loss.\\n\\nInstead of fearing change, we should prepare for it and learn those skills that will help us survive in the age of AI.\\n\\nThere were other claims like \"AGI was already achieved\" and \"AI will reach human-level intelligence\" that I don’t think will happen anytime soon (if you don’t believe me, read what an AI expert thinks about this here).\\n\\nJoin my newsletter with 35K+ people to get my free cheat sheets: ChatGPT, web scraping, Python for data science, automation, and more!\\n\\nIf you enjoy reading stories like these and want to support me as a writer, subscribe to my Substack. On Substack, I publish articles that you won’t find on the other platforms where I create content.\\n\\nSubscribe to Artificial Corner by ThePyCoach\\nArtificial Intelligence in plain English. In-depth tutorials to make the most of ChatGPT and other AI tools. The latest…artificialcorner.substack.com'}},\n",
       "  {'id': 'e23bfa19bf16',\n",
       "   'title': 'A Hands-On Comparison: Gemini Pro vs GPT-3.5',\n",
       "   'subtitle': 'And the winner is\\xa0…',\n",
       "   'author': 'fb44e21903f3',\n",
       "   'publication_id': '76436a11a2b0',\n",
       "   'published_at': '2023-12-12 12:01:54',\n",
       "   'last_modified_at': '2023-12-12 12:01:54',\n",
       "   'tags': ['chatgpt',\n",
       "    'artificial-intelligence',\n",
       "    'technology',\n",
       "    'science',\n",
       "    'python'],\n",
       "   'topics': ['programming'],\n",
       "   'claps': 567,\n",
       "   'voters': 74,\n",
       "   'word_count': 989,\n",
       "   'responses_count': 10,\n",
       "   'reading_time': 5.382075471698113,\n",
       "   'url': 'https://medium.com/artificial-corner/a-hands-on-comparison-gemini-pro-vs-gpt-3-5-e23bfa19bf16',\n",
       "   'unique_slug': 'a-hands-on-comparison-gemini-pro-vs-gpt-3-5-e23bfa19bf16',\n",
       "   'image_url': 'https://miro.medium.com/1*0KOYEV-7j3NXe7zHP6URyA.png',\n",
       "   'lang': 'en',\n",
       "   'is_series': False,\n",
       "   'is_locked': True,\n",
       "   'is_shortform': False,\n",
       "   'top_highlight': '',\n",
       "   'content': {'id': 'e23bfa19bf16',\n",
       "    'content': 'A Hands-On Comparison: Gemini Pro vs GPT-3.5\\n\\nAnd the winner is …\\n\\nImage created with Midjourney\\n\\nLast week, Google integrated Gemini Pro into Bard and, in this article, I’ll compare it with its direct competitor GPT-3.5. We’ll see how good both are in writing, reasoning, and code generation.\\n\\nThis article will be useful for those who use GPT-3.5 often and would like to see whether using Gemini Pro is worth it.\\n\\nNote: Google’s Gemini Ultra (the GPT-4 competitor) isn’t available yet. For more info about Gemini Ultra and what I think about it, check this article.\\n\\nGeneral requests: Writing, roles, and personal assistance\\n\\nFirst, I used Gemini Pro and GPT-3.5 as personal assistants and asked them both to help me plan my next trip.\\n\\nI’m traveling next week from California to New York. Show me flights to New York and hotels near Central Park\\n\\nThanks to the latest Bard update, it connects to Google apps such as Flights and Hotels to provide real-time information.\\n\\n\\n\\nBard can also connect to your personal apps such as Gmail and Drive to give a customized experience in its responses. However, unlike Bard, GPT-3.5 has no internet access or connection to third-party apps.\\n\\n\\n\\nFor my second test, I gave a request where both had to get a role. In the past, Bard failed to understand this type of request but now it follows the instructions successfully. GPT-3.5 also did a good job.\\n\\n\\n\\n\\n\\nFinally, I asked both models to generate a witty blog post using humor. Both created nice pieces.\\n\\n\\n\\n\\n\\nIn this first round, both models had similar performance, but I liked the post created by Gemini Pro a bit more and also liked that Bard can connect to Google apps. That opens new possibilities that are exclusive to Bard.\\n\\nIf I had to choose one of them after this first comparison, I’d choose Gemini Pro.\\n\\nReasoning\\n\\nI put Gemini Pro and GPT-3.5 to the test with math questions. According to the paper Google released last week, Gemini Pro is superior to GPT-3.5 in grade-school math but is close to GPT-3.5 in math problems across 5-difficulty levels & 7 subdisciplines.\\n\\nFor my test, I gave both models 3 exercises.\\n\\nBoth models successfully solved the first and easiest exercise.\\n\\nPens cost more than pencils.\\nPens cost less than eraser.\\nErasers cost more than pencils and pens.\\n\\nIf the first two statements are true, the third statement is ___\\n\\n\\n\\n\\n\\nThe second exercise consisted in completing a sequence of numbers. Gemini Pro failed while GPT-3.5 got it right.\\n\\nFind the next number in the sequence: 30, 45, 90, 225, 675, …\\n\\n\\n\\n\\n\\nFor the final and most difficult exercise, both models had to find the next element in the sequence below. Both failed.\\n\\nLOO, MON, NOM, OOL, ____\\nA. POK\\nB. HOL\\nC. HOK\\nD. JOI\\n\\n\\n\\n\\n\\nFor some reason, in the last exercise, both gave the same answer, which is incorrect according to the site where I got the exercise from (when I gave the same exercise to GPT-4 it was able to find the correct answer).\\n\\nWhen it comes to reasoning, I think GPT-3.5 is slightly better than Gemini Pro, but more tests would be necessary to choose a winner.\\n\\nCode\\n\\nI’ve tested both Gemini Pro and GPT-3.5 for solving coding questions and generating code and I was quite surprised with the results.\\n\\nFirst, I gave both models the Python code below and asked for an explanation.\\n\\nfrom bs4 import BeautifulSoup\\nimport requests\\n\\nwebsite = \\'www.example.com\\'\\nresult = requests.get(website)\\ncontent = result.text\\nsoup = BeautifulSoup(content, \\'lxml\\')\\nprint(soup.prettify())\\n\\nbox = soup.find(\\'article\\', class_=\\'main-article\\')\\ntitle = box.find(\\'h1\\').get_text()\\ntranscript = box.find(\\'div\\', class_=\\'full-script\\').get_text(strip=True, separator=\\' \\')\\n\\nwith open(f\\'{title}.txt\\', \\'w\\') as file:\\n  file.write(transcript)\\n\\nBoth gave a nice explanation of the code.\\n\\n\\n\\n\\n\\nHowever, when I asked to generate code, Bard sometimes refused to do it.\\n\\nwrite Python code that sends an email from \"email_1\" to \"email_2\" with the subject \"Email sent by Bard\" and the content \"Bard rocks!\"\\n\\n\\n\\nThis forced me to tweak the prompts to get Bard to generate the script.\\n\\n\\n\\nAs you can see, in the end, it worked, but the second prompt lacked customization in the subject and message of the email.\\n\\nGPT-3.5 had no issue with this.\\n\\n\\n\\nGPT-3.5 is clearly the winner here.\\n\\nThe Final Verdict\\n\\nBoth models are good for general requests, but you can connect to Google apps with Bard, which opens new possibilities with Gemini Pro.\\n\\nGPT-3.5 is slightly better than Gemini Pro in reasoning. That said both failed to solve complex problems.\\n\\nBoth models can assist you when you have coding questions, but Bard would sometimes refuse to generate code.\\n\\nI’d say both models are on the same level. The major difference lies in the benefits and limitations of the chatbots they powered: Bard and ChatGPT. As a programmer, I’d use GPT-3.5 because ChatGPT almost never refuses to generate code. That said, in some cases, I’d use Bard to get access to Google apps.\\n\\nAs a side note, I have to say that I don’t see myself using Gemini Pro or GPT-3.5 because I have access to GPT-4, which is far superior to both of them. Its major drawback is its price, but other than that GPT-4 is the best model available out there. When Gemini Ultra is released, I’ll make a similar comparison to see which one is better.\\n\\nJoin my newsletter with 35K+ people to get my free cheat sheets: ChatGPT, web scraping, Python for data science, automation, and more!\\n\\nIf you enjoy reading stories like these and want to support me as a writer, subscribe to my Substack. On Substack, I publish articles that you won’t find on the other platforms where I create content.\\n\\nSubscribe to Artificial Corner by ThePyCoach\\nArtificial Intelligence in plain English. In-depth tutorials to make the most of ChatGPT and other AI tools. The latest…artificialcorner.substack.com'}},\n",
       "  {'id': '16ed78293975',\n",
       "   'title': 'Here’s Why I Still Don’t Buy the Hype of Google Gemini',\n",
       "   'subtitle': 'Gemini might not be as good as it seems to be.',\n",
       "   'author': 'fb44e21903f3',\n",
       "   'publication_id': '76436a11a2b0',\n",
       "   'published_at': '2023-12-08 17:49:53',\n",
       "   'last_modified_at': '2023-12-08 17:49:53',\n",
       "   'tags': ['chatgpt',\n",
       "    'artificial-intelligence',\n",
       "    'technology',\n",
       "    'science',\n",
       "    'python'],\n",
       "   'topics': ['artificial-intelligence'],\n",
       "   'claps': 615,\n",
       "   'voters': 97,\n",
       "   'word_count': 1078,\n",
       "   'responses_count': 9,\n",
       "   'reading_time': 5.317924528301887,\n",
       "   'url': 'https://medium.com/artificial-corner/heres-why-i-still-don-t-buy-the-hype-of-google-gemini-16ed78293975',\n",
       "   'unique_slug': 'heres-why-i-still-don-t-buy-the-hype-of-google-gemini-16ed78293975',\n",
       "   'image_url': 'https://miro.medium.com/0*QQ7EbFFz_gxnv5xv.png',\n",
       "   'lang': 'en',\n",
       "   'is_series': False,\n",
       "   'is_locked': True,\n",
       "   'is_shortform': False,\n",
       "   'top_highlight': \"Google's Gemini was just unveiled, and I haven't seen so much hype since ChatGPT was released by OpenAI.\",\n",
       "   'content': {'id': '16ed78293975',\n",
       "    'content': 'Here’s Why I Still Don’t Buy the Hype of Google Gemini\\n\\nGemini might not be as good as it seems to be.\\n\\nSource: Google\\n\\nGoogle’s Gemini was just unveiled, and I haven’t seen so much hype since ChatGPT was released by OpenAI.\\n\\nGemini is Google’s most powerful AI model and what makes it different from others is its multimodality. Traditionally, achieving multimodality involved using different models trained for specific tasks separately (text, image, etc). However, Gemini was built from the ground up for multimodality, which allows it to reason seamlessly across text, images, video, audio, and code.\\n\\nThe result? An AI that beats GPT-4 … on paper (and demos).\\n\\nAt least that’s what some of us feel after discovering what I’m about to show you. Here’s why I still don’t buy the hype of Gemini.\\n\\nGemini AI beats GPT-4 … but the gap isn’t that big\\n\\nProbably you’ve seen the image below where Google shows that Gemini Ultra is more powerful than GPT-4.\\n\\nGoogle\\n\\nAnd you might’ve also seen this detailed comparison of Gemini Ultra and GPT-4.\\n\\nGoogle\\n\\nIn the detailed comparison, we can see that Gemini Ultra outperforms GPT-4, but the gap is reduced if you check the 60-page paper released by Google.\\n\\nCheck out the MMLU comparison. The 86.4% of GPT-4 increases to 87.29% if we consider the same prompting technique for evaluation CoT@32.\\n\\nPaper\\n\\nThe only version of Gemini available for users right now is Gemini Pro, which was integrated into Bard and is no match for GPT-4.\\n\\nGemini was introduced in three different versions.\\n\\nGemini Ultra: The largest and most powerful model designed to handle highly complex tasks (the one that beats GPT-4)\\n\\nGemini Pro: Suitable for solving a wide range of tasks. It has fewer parameters in its construction but will directly compete with GPT-3.5\\n\\nGemini Nano: Tailored for on-device tasks.\\n\\nGoogle\\n\\nThe thing is, the model everyone is talking about, Gemini Ultra, isn’t available yet. It should be available to users through \"Bard Advanced\" only early next year.\\n\\nIn the meantime, what know about Gemini Ultra is the numbers Google showed us and a Hands-on with Gemini made by Google, which isn’t much of a \"hands-on\".\\n\\nThe Hands-on with Gemini demo isn’t that real\\n\\nI have to admit the Gemini demo blew up my mind.\\n\\n\\n\\nIn the demo, Google shows off Gemini’s multimodal capabilities. We see how we can easily talk with the AI, how it can recognize your images quickly, track objects in real time, and more.\\n\\nVery impressive … until you open the video description and read this.\\n\\nFor the purposes of this demo, latency has been reduced and Gemini outputs have been shortened for brevity.\\n\\nSo neither the video happened in real-time nor the spoken prompts were used.\\n\\nIn fact, according to a Bloomberg report, Google admitted when asked for comment that the video demo didn’t happen in real-time with spoken prompts but instead used still image frames from raw footage and then wrote out text prompts to which Gemini responded.\\n\\nWhen searching for more information about the demo released by Google, I came across this How it’s Made article in the Google blog. I was surprised when I discovered that what seemed to be one of Gemini’s differentiators compared to GPT-4 (the ability to understand and generate responses considering the video modality) was, in reality, a sequence of pre-established image frames.\\n\\nHere’s how the rock, paper, scissor clip was made.\\n\\n\\n\\n\\n\\n\\n\\nIn the demo, the ability of Gemini to interpret the game of rock, paper, scissors in real time was impressive. However, in reality, it might not be that impressive.\\n\\nWe all know that for obvious reasons, they had to omit all the details above, but the hands-on looks more like an ad.\\n\\nBesides the video editing, there’s also the actual prompt that was used.\\n\\nThe prompts used to get the results in the video and those we hear in the video are different.\\n\\nHere’s an example. In minute 4:36 of the demo, we hear \"based on the design, which of these would go faster?\" referring to the two images on the table. Gemini responds \"The car on the right will go faster. It’s more aerodynamic\"\\n\\nHowever, this was the actual prompt used.\\n\\nGoogle blog\\n\\nAs you can see, there’s a difference between the prompt spoken in the video and the prompt written to get the results we’ve seen.\\n\\nFor some, the demo raises doubts about Gemini’s capabilities. I can’t tell whether Gemini Ultra is as good as some say until I do my own hands-on or see someone do one without all this fancy editing.\\n\\nWhat about the training data?\\n\\nMany have pointed out on Twitter (X) that Google hasn’t provided any information on how the training data was made or filtered, which is ironic because even they say the training data is key.\\n\\n\\n\\nThis tweet was responded to by Jeff Dean, Chief Scientist of Google DeepMind and Google Research.\\n\\nTwitter (X)\\n\\nHopefully, people will have access to the Gemini Ultra model soon and we’ll see whether it can live up to the hype.\\n\\nWhile you may approach this latest news with excitement, it’s important to be cautious.\\n\\nGemini might not be as good as it seems to be in the demo\\n\\nGemini Ultra isn’t available yet. Gemini Pro is available in Bard, but it only competes with GPT-3.5\\n\\nDetails about the training data used for the tests were not provided yet\\n\\nWe should be a bit cautious, considering the less-than-ideal experience when Bard was launched on a grand scale in early 2023. Despite the initial hype, it turned out to be a disappointment for users due to various errors that emerged when it was tried by users.\\n\\nThat said, if Gemini Ultra is as good as it seems, I’ll be praising it after I do my own hands-on with Gemini.\\n\\nIn the meantime, I just can’t buy the hype.\\n\\nJoin my newsletter with 35K+ people to get my free cheat sheets: ChatGPT, web scraping, Python for data science, automation, and more!\\n\\nIf you enjoy reading stories like these and want to support me as a writer, subscribe to my Substack. On Substack, I publish articles that you won’t find on the other platforms where I create content.\\n\\nSubscribe to Artificial Corner by ThePyCoach\\nArtificial Intelligence in plain English. In-depth tutorials to make the most of ChatGPT and other AI tools. The latest…artificialcorner.substack.com'}},\n",
       "  {'id': 'c6b672104721',\n",
       "   'title': 'GPT Actions: How to Create Advanced Automation in Your GPTs',\n",
       "   'subtitle': 'Customize your GPT further by connecting it to thousands of apps.',\n",
       "   'author': 'fb44e21903f3',\n",
       "   'publication_id': '76436a11a2b0',\n",
       "   'published_at': '2023-12-06 15:43:28',\n",
       "   'last_modified_at': '2023-12-06 15:43:28',\n",
       "   'tags': ['chatgpt',\n",
       "    'artificial-intelligence',\n",
       "    'technology',\n",
       "    'science',\n",
       "    'python'],\n",
       "   'topics': ['programming'],\n",
       "   'claps': 863,\n",
       "   'voters': 159,\n",
       "   'word_count': 1018,\n",
       "   'responses_count': 6,\n",
       "   'reading_time': 5.341509433962264,\n",
       "   'url': 'https://medium.com/artificial-corner/gpt-actions-how-to-create-advanced-automation-in-your-gpts-c6b672104721',\n",
       "   'unique_slug': 'gpt-actions-how-to-create-advanced-automation-in-your-gpts-c6b672104721',\n",
       "   'image_url': 'https://miro.medium.com/1*L-BjgiP_1w-PlnsfCmV1HA.png',\n",
       "   'lang': 'en',\n",
       "   'is_series': False,\n",
       "   'is_locked': True,\n",
       "   'is_shortform': False,\n",
       "   'top_highlight': '',\n",
       "   'content': {'id': 'c6b672104721',\n",
       "    'content': 'GPT Actions: How to Create Advanced Automation in Your GPTs\\n\\nCustomize your GPT further by connecting it to thousands of apps.\\n\\nImage created with Midjourney\\n\\nIn this article, we’ll see how to add automation to your GPT with GPT Actions. Actions allow GPTs to interact with other apps.\\n\\nIn this case, we’ll use Zapier Actions to automate sending emails on Gmail, but you could follow the same steps to connect to Google Sheets, Drive, Calendar, and other apps.\\n\\nYou only need to follow the three steps below.\\n\\n\\n\\nStep 1: Add Zapier action to your GPT\\n\\nFirst, you need to go to the Configure option of your GPT. In case you don’t have a GPT, you’ll need to create one by following the steps below.\\n\\nOpen the left sidebar and click on \"Explore.\" Then click on \"Create a GPT\" within My GPTs.\\n\\n\\n\\nThen you should see the GPT Builder. Click on Configure, and select \"Create New Action.\"\\n\\n\\n\\nYou should see this window now.\\n\\n\\n\\nClick on \"Import from URL,\" paste the URL below, and then click on Import.\\n\\nhttps://actions.zapier.com/gpt/api/v1/dynamic/openapi.json?tools=meta\\n\\nAfter that, you should see a bunch of text added to the schema. Leave it as is.\\n\\n\\n\\nThat’s it for the \"Add actions\" section, now you can click on the < button to go back to Configure. In \"Actions\" you’ll see that a new Zapier action was added.\\n\\n\\n\\nStep 2: Paste the Zapier instructions\\n\\nZapier has a bunch of actions available from sending an email to updating an Excel spreadsheet. That’s why we need to specify in the GPT’s instructions what action we want to use.\\n\\nWith Zapier, there’s a specific format we need to follow. Besides the instructions you created for your GPT, you have to paste the text below in the GPT instructions (extracted from Zapier)\\n\\n### Rules:\\n- Before running any Actions tell the user that they need to reply after the Action completes to continue.\\n\\n### Instructions for Zapier Custom Action: \\nStep 1. Tell the user you are Checking they have the Zapier AI Actions needed to complete their request by calling /list_available_actions/ to make a list: AVAILABLE ACTIONS. Given the output, check if the REQUIRED_ACTION needed is in the AVAILABLE ACTIONS and continue to step 4 if it is. If not, continue to step 2.\\nStep 2. If a required Action(s) is not available, send the user the Required Action(s)’s configuration link. Tell them to let you know when they’ve enabled the Zapier AI Action.\\nStep 3. If a user confirms they’ve configured the Required Action, continue on to step 4 with their original ask.\\nStep 4. Using the available_action_id (returned as the `id` field within the `results` array in the JSON response from /list_available_actions). Fill in the strings needed for the run_action operation. Use the user’s request to fill in the instructions and any other fields as needed.\\n\\nREQUIRED_ACTIONS:\\n- Action: <paste name of action here>\\n Confirmation Link: <paste link here>\\n\\nThe text has two fields that you need to fill: Action and confirmation link. We’ll get this from the Zapier website in the next step.\\n\\nStep 3: Create an action on Zapier\\n\\nIn this step, we’ll create the automation we want to add as action to our GPT.\\n\\nTo build our automation (aka action), go to this site. If you don’t have a Zapier account, you’ll need to register. Once you’re logged in, you should see something like the screenshot below (ignore the \"send email\" action that I created for this tutorial).\\n\\n\\n\\nNow you have to click on \"Add a new action\" located at the bottom. Then you should see the page below where you can type to search thousands of apps like Gmail, Excel, YouTube, etc. For this tutorial, we’ll select \"Gmail send email\" to send an email via Gmail with our GPT.\\n\\n\\n\\nNow we have to configure our GPT action. The settings for other apps will be similar.\\n\\nYou must connect to the external app (in this case using your Gmail account)\\n\\nOverall, you can leave most of the fields as \"Have AI guess a value for this field\"\\n\\n\\n\\nAnd that’s pretty much it! Now you can click on \"Enable action.\"\\n\\nThe action was created! Now we need to get the Action name and Confirmation Link. To do so, we select our action in the list.\\n\\n\\n\\nThen we’ll see the \"Set up your GPT action\" section again. Here’s where you get the Action and Confirmation Link.\\n\\nConfirmation Link: Just copy the link to the site (it starts with actions.zapier.com/gpt/action/)\\n\\nAction Name: Click on \"Show all options\" and scroll down until \"Action Name.\" There type the name you want to set for the action\\n\\n\\n\\nI’m naming my action \"Send email.\"\\n\\nCopy the action name and link and paste them in the GPT instructions. Here’s how \"Required_Actions\" looks now.\\n\\n\\n\\nNow that \"Required_Actions\" is completed, save your GPT. It’s time to test it!\\n\\nTesting the action\\n\\nStart an instance of your GPT and type the following prompt for testing.\\n\\nSend an email \"Hello World\" to your_second_email@email.com\\n\\nAssuming you connected your main Gmail account to Zapier, type another email in the prompt (it doesn’t have to be a Gmail account)\\n\\nAfter pressing enter, you’ll probably see the message below. Click \"Allow\"\\n\\n\\n\\nAnd that’s it! If everything is successful, you’ll get a message like this.\\n\\n\\n\\nIf you check your inbox, you should have a new email. In this case, I got an email from my Gmail account with the content and subject \"Hello World\"\\n\\n\\n\\nYou could customize the action further in the prompt and also on Zapier.\\n\\nBut that’s it for now! Now it’s your time to explore other apps you can connect to using GPT actions and Zapier.\\n\\nJoin my newsletter with 35K+ people to get my free cheat sheets: ChatGPT, web scraping, Python for data science, automation, and more!\\n\\nIf you enjoy reading stories like these and want to support me as a writer, subscribe to my Substack. On Substack, I publish articles that you won’t find on the other platforms where I create content.\\n\\nSubscribe to Artificial Corner by ThePyCoach\\nArtificial Intelligence in plain English. In-depth tutorials to make the most of ChatGPT and other AI tools. The latest…artificialcorner.substack.com'}}]}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "updated_articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for writer in test_writers.keys():\n",
    "\ttest_writers[writer]['top_articles'] = updated_articles[writer]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "# save dictionary of all writers to pickle file\n",
    "with open('./writer_info.json', 'rb') as comb_file:\n",
    "\ttop_writers = json.load(comb_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': '34c195a93d41',\n",
       "  'title': 'How I Won Singapore’s GPT-4 Prompt Engineering Competition',\n",
       "  'subtitle': 'A deep dive into the strategies I learned for harnessing the power of Large Language Models (LLMs)',\n",
       "  'author': 'fca9db1c7da0',\n",
       "  'publication_id': '7f60cf5620c9',\n",
       "  'published_at': '2023-12-29 00:29:22',\n",
       "  'last_modified_at': '2024-01-29 06:15:01',\n",
       "  'tags': ['data-science',\n",
       "   'artificial-intelligence',\n",
       "   'prompt-engineering',\n",
       "   'editors-pick',\n",
       "   'technology'],\n",
       "  'topics': ['artificial-intelligence', 'data-science'],\n",
       "  'claps': 11406,\n",
       "  'voters': 2300,\n",
       "  'word_count': 5571,\n",
       "  'responses_count': 157,\n",
       "  'reading_time': 22.722641509433963,\n",
       "  'url': 'https://towardsdatascience.com/how-i-won-singapores-gpt-4-prompt-engineering-competition-34c195a93d41',\n",
       "  'unique_slug': 'how-i-won-singapores-gpt-4-prompt-engineering-competition-34c195a93d41',\n",
       "  'image_url': 'https://miro.medium.com/1*RAI4cBXe1_zaxVykHz79oA.jpeg',\n",
       "  'lang': 'en',\n",
       "  'is_series': False,\n",
       "  'is_locked': True,\n",
       "  'is_shortform': False,\n",
       "  'top_highlight': 'Use System Prompts to provide instructions that you want the LLM to remember when responding throughout the entire chat.'},\n",
       " {'id': '8c339f8fb602',\n",
       "  'title': 'Stacked Ensembles for Advanced Predictive Modeling With H2O.ai and Optuna',\n",
       "  'subtitle': 'And how I placed top 10% in Europe’s largest machine learning competition with them!',\n",
       "  'author': 'fca9db1c7da0',\n",
       "  'publication_id': '7f60cf5620c9',\n",
       "  'published_at': '2023-12-18 16:05:44',\n",
       "  'last_modified_at': '2023-12-29 16:32:23',\n",
       "  'tags': ['machine-learning',\n",
       "   'data-science',\n",
       "   'deep-learning',\n",
       "   'ensemble-learning',\n",
       "   'python'],\n",
       "  'topics': ['machine-learning', 'data-science'],\n",
       "  'claps': 462,\n",
       "  'voters': 104,\n",
       "  'word_count': 3134,\n",
       "  'responses_count': 11,\n",
       "  'reading_time': 12.376415094339624,\n",
       "  'url': 'https://towardsdatascience.com/stacked-ensembles-for-advanced-predictive-modeling-with-h2o-ai-and-optuna-8c339f8fb602',\n",
       "  'unique_slug': 'stacked-ensembles-for-advanced-predictive-modeling-with-h2o-ai-and-optuna-8c339f8fb602',\n",
       "  'image_url': 'https://miro.medium.com/1*5FM14YZopRvGK9baJR0OtQ.png',\n",
       "  'lang': 'en',\n",
       "  'is_series': False,\n",
       "  'is_locked': True,\n",
       "  'is_shortform': False,\n",
       "  'top_highlight': ''}]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_writers[0]['top_articles']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "for el in top_writers:\n",
    "\tauthor_id = el['id']\n",
    "\tel['top_articles'] = updated_articles[author_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': '34c195a93d41',\n",
       "  'title': 'How I Won Singapore’s GPT-4 Prompt Engineering Competition',\n",
       "  'subtitle': 'A deep dive into the strategies I learned for harnessing the power of Large Language Models (LLMs)',\n",
       "  'author': 'fca9db1c7da0',\n",
       "  'publication_id': '7f60cf5620c9',\n",
       "  'published_at': '2023-12-29 00:29:22',\n",
       "  'last_modified_at': '2024-01-29 06:15:01',\n",
       "  'tags': ['data-science',\n",
       "   'artificial-intelligence',\n",
       "   'prompt-engineering',\n",
       "   'editors-pick',\n",
       "   'technology'],\n",
       "  'topics': ['artificial-intelligence', 'data-science'],\n",
       "  'claps': 11406,\n",
       "  'voters': 2300,\n",
       "  'word_count': 5571,\n",
       "  'responses_count': 157,\n",
       "  'reading_time': 22.722641509433963,\n",
       "  'url': 'https://towardsdatascience.com/how-i-won-singapores-gpt-4-prompt-engineering-competition-34c195a93d41',\n",
       "  'unique_slug': 'how-i-won-singapores-gpt-4-prompt-engineering-competition-34c195a93d41',\n",
       "  'image_url': 'https://miro.medium.com/1*RAI4cBXe1_zaxVykHz79oA.jpeg',\n",
       "  'lang': 'en',\n",
       "  'is_series': False,\n",
       "  'is_locked': True,\n",
       "  'is_shortform': False,\n",
       "  'top_highlight': 'Use System Prompts to provide instructions that you want the LLM to remember when responding throughout the entire chat.',\n",
       "  'content': {'id': '34c195a93d41',\n",
       "   'content': 'How I Won Singapore’s GPT-4 Prompt Engineering Competition\\n\\nA deep dive into the strategies I learned for harnessing the power of Large Language Models (LLMs)\\n\\nCelebrating a milestone - The real win was the priceless learning experience!\\n\\nLast month, I had the incredible honor of winning Singapore’s first ever GPT-4 Prompt Engineering competition, which brought together over 400 prompt-ly brilliant participants, organised by the Government Technology Agency of Singapore (GovTech).\\n\\nPrompt engineering is a discipline that blends both art and science - it is as much technical understanding as it is of creativity and strategic thinking. This is a compilation of the prompt engineering strategies I learned along the way, that push any LLM to do exactly what you need and more!\\n\\nAuthor’s Note:\\nIn writing this, I sought to steer away from the traditional prompt engineering techniques that have already been extensively discussed and documented online. Instead, my aim is to bring fresh insights that I learned through experimentation, and a different, personal take in understanding and approaching certain techniques. I hope you’ll enjoy reading this piece!\\n\\nThis article covers the following, with 🔵 referring to beginner-friendly prompting techniques while 🔴 refers to advanced strategies:\\n\\n1. [🔵] Structuring prompts using the CO-STAR framework\\n\\n2. [🔵] Sectioning prompts using delimiters\\n\\n3. [🔴] Creating system prompts with LLM guardrails\\n\\n4. [🔴] Analyzing datasets using only LLMs, without plugins or code - \\nWith a hands-on example of analyzing a real-world Kaggle dataset using GPT-4\\n\\n1. [🔵] Structuring Prompts using the CO-STAR framework\\n\\nEffective prompt structuring is crucial for eliciting optimal responses from an LLM. The CO-STAR framework, a brainchild of GovTech Singapore’s Data Science & AI team, is a handy template for structuring prompts. It considers all the key aspects that influence the effectiveness and relevance of an LLM’s response, leading to more optimal responses.\\n\\nCO-STAR framework - Image by author\\n\\nHere’s how it works:\\n\\n(C) Context: Provide background information on the task\\n\\nThis helps the LLM understand the specific scenario being discussed, ensuring its response is relevant.\\n\\n(O) Objective: Define what the task is that you want the LLM to perform\\n\\nBeing clear about your objective helps the LLM to focus its response on meeting that specific goal.\\n\\n(S) Style: Specify the writing style you want the LLM to use\\n\\nThis could be a particular famous person’s style of writing, or a particular expert in a profession, like a business analyst expert or CEO. This guides the LLM to respond with the manner and choice of words aligned with your needs.\\n\\n(T) Tone: Set the attitude of the response\\n\\nThis ensures the LLM’s response resonates with the intended sentiment or emotional context required. Examples are formal, humorous, empathetic, among others.\\n\\n(A) Audience: Identify who the response is intended for\\n\\nTailoring the LLM’s response to an audience, such as experts in a field, beginners, children, and so on, ensures that it is appropriate and understandable in your required context.\\n\\n(R) Response: Provide the response format\\n\\nThis ensures that the LLM outputs in the exact format that you require for downstream tasks. Examples include a list, a JSON, a professional report, and so on. For most LLM applications which work on the LLM responses programmatically for downstream manipulations, a JSON output format would be ideal.\\n\\nA practical application of CO-STAR\\n\\nHere’s a real-world example of why the CO-STAR framework is useful. Let’s say you work as a social media manager, and you need help drafting a Facebook post to advertise your company’s new product.\\n\\nA quick prompt without CO-STAR might look something like this:\\n\\nWrite a facebook post to advertise my company’s new product. My company’s name is Alpha and the product is called Beta, a new ultra-fast hairdryer.\\n\\nHere’s the output from GPT-4:\\n\\nIntroducing the Revolutionary Beta Hairdryer by Alpha!\\n- Say goodbye to long, tedious hair drying sessions! Alpha is proud to unveil the Beta, our latest innovation in haircare technology.\\n- Ultra-Fast Drying: The Beta is designed to cut your drying time in half, thanks to its advanced, powerful motor. Get ready faster and enjoy more time doing what you love!\\nShop Now: [Link to product page]\\n\\nWhile adequate, this output is painfully generic, lacking the specific nuances and targeted appeal necessary to resonate with your company’s audience.\\n\\nHere’s an example of using the CO-STAR template instead, which reminds you to incorporate other aspects of your task into your prompt, specifically the STYLE, TONE, and AUDIENCE aspects that are missing from the previous quick prompt:\\n\\n# CONTEXT # \\nI want to advertise my company’s new product. My company’s name is Alpha and the product is called Beta, which is a new ultra-fast hairdryer.\\n\\n# OBJECTIVE #\\nCreate a Facebook post for me, which aims to get people to click on the product link to purchase it.\\n\\n# STYLE #\\nFollow the writing style of successful companies that advertise similar products, such as Dyson.\\n\\n# TONE #\\nPersuasive\\n\\n# AUDIENCE #\\nMy company’s audience profile on Facebook is typically the older generation. Tailor your post to target what this audience typically looks out for in hair products.\\n\\n# RESPONSE #\\nThe Facebook post, kept concise yet impactful.\\n\\nBy applying CO-STAR, GPT-4’s response becomes significantly more targeted and effective:\\n\\nEmbrace Effortless Elegance with Alpha Beta - The Ultra-Fast Hairdryer for the Wise Generation.\\n\\nRediscover the joy of simple, effective hair care with Alpha Beta. Our latest innovation is more than just a hairdryer; it’s a promise of swift, gentle, and \\nreliable hair styling for those who appreciate the finer things in life.\\n\\n- Easy and Intuitive Use: Say goodbye to complicated gadgets. Alpha Beta is \\ncrafted for comfort and simplicity, perfect for those who value straightforward,\\nhassle-free technology. \\n- Time-Saving Technology: We understand your time is precious. That’s why Alpha Beta cuts down drying time significantly, giving you more moments to enjoy life’s pleasures.\\n\\nMake every day a good hair day with Alpha Beta. Experience the blend of \\nsophistication and simplicity today.\\n\\n[Your Product Link Here]\\n\\nThe CO-STAR framework guides you to provide all of the crucial pieces of information about your task to the LLM in a structured manner, ensuring a tailored and optimized response to exactly what you need.\\n\\n2. [🔵] Sectioning Prompts Using Delimiters\\n\\nImage generated by DALL·E 3\\n\\nDelimiters are special tokens that help the LLM distinguish which parts of your prompt it should consider as a single unit of meaning. This is important because your entire prompt arrives to the LLM as a single long sequence of tokens. Delimiters provide structure to this sequence of tokens by fencing specific parts of your prompt to be treated differently.\\n\\nIt is noteworthy that delimiters may not make a difference to the quality of an LLM’s response for straightforward tasks. However, the more complex the task, the more impact the usage of delimiters for sectioning has on the LLM’s response.\\n\\nDelimiters as Special Characters\\n\\nA delimiter could be any sequence of special characters that usually wouldn’t appear together, for example:\\n\\n###\\n\\n===\\n\\n>>>\\n\\nThe number and type of special characters chosen is inconsequential, as long as they are unique enough for the LLM to understand them as content separators instead of normal punctuation.\\n\\nHere’s an example of how you might use such delimiters in a prompt:\\n\\nClassify the sentiment of each conversation in <<<CONVERSATIONS>>> as \\n‘Positive’ or ‘Negative’. Give the sentiment classifications without any other preamble text.\\n\\n###\\n\\nEXAMPLE CONVERSATIONS\\n\\n[Agent]: Good morning, how can I assist you today?\\n[Customer]: This product is terrible, nothing like what was advertised!\\n[Customer]: I’m extremely disappointed and expect a full refund.\\n\\n[Agent]: Good morning, how can I help you today?\\n[Customer]: Hi, I just wanted to say that I’m really impressed with your \\nproduct. It exceeded my expectations!\\n\\n###\\n\\nEXAMPLE OUTPUTS\\n\\nNegative\\n\\nPositive\\n\\n###\\n\\n<<<\\n[Agent]: Hello! Welcome to our support. How can I help you today?\\n[Customer]: Hi there! I just wanted to let you know I received my order, and \\nit’s fantastic!\\n[Agent]: That’s great to hear! We’re thrilled you’re happy with your purchase. \\nIs there anything else I can assist you with?\\n[Customer]: No, that’s it. Just wanted to give some positive feedback. Thanks \\nfor your excellent service!\\n\\n[Agent]: Hello, thank you for reaching out. How can I assist you today?\\n[Customer]: I’m very disappointed with my recent purchase. It’s not what I expected at all.\\n[Agent]: I’m sorry to hear that. Could you please provide more details so I can help?\\n[Customer]: The product is of poor quality and it arrived late. I’m really \\nunhappy with this experience.\\n>>>\\n\\nAbove, the examples are sectioned using the delimiter ###, with the section headings EXAMPLE CONVERSATIONS and EXAMPLE OUTPUTS in capital letters to differentiate them. The preamble states that the conversations to be classified are sectioned inside <<<CONVERSATIONS>>>, and these conversations are subsequently given to the LLM at the bottom of the prompt without any explanatory text, but the LLM understands that these are the conversations it should classify due to the presence of the delimiters <<< and >>>.\\n\\nHere is the output from GPT-4, with the sentiment classifications given without any other preamble text outputted, like what we asked for:\\n\\nPositive\\n\\nNegative\\n\\nDelimiters as XML Tags\\n\\nAnother approach to using delimiters is having them as XML tags. XML tags are tags enclosed in angle brackets, with opening and closing tags. An example is <tag> and </tag>. This is effective as LLMs have been trained on a lot of web content in XML, and have learned to understand its formatting.\\n\\nHere’s the same prompt above, but structured using XML tags as delimiters instead:\\n\\nClassify the sentiment of the following conversations into one of two classes, using the examples given. Give the sentiment classifications without any other\\npreamble text.\\n\\n<classes>\\nPositive\\nNegative\\n</classes>\\n\\n<example-conversations>\\n[Agent]: Good morning, how can I assist you today?\\n[Customer]: This product is terrible, nothing like what was advertised!\\n[Customer]: I’m extremely disappointed and expect a full refund.\\n\\n[Agent]: Good morning, how can I help you today?\\n[Customer]: Hi, I just wanted to say that I’m really impressed with your \\nproduct. It exceeded my expectations!\\n</example-conversations>\\n\\n<example-classes>\\nNegative\\n\\nPositive\\n</example-classes>\\n\\n<conversations>\\n[Agent]: Hello! Welcome to our support. How can I help you today?\\n[Customer]: Hi there! I just wanted to let you know I received my order, and \\nit’s fantastic!\\n[Agent]: That’s great to hear! We’re thrilled you’re happy with your purchase. \\nIs there anything else I can assist you with?\\n[Customer]: No, that’s it. Just wanted to give some positive feedback. Thanks \\nfor your excellent service!\\n\\n[Agent]: Hello, thank you for reaching out. How can I assist you today?\\n[Customer]: I’m very disappointed with my recent purchase. It’s not what I \\nexpected at all.\\n[Agent]: I’m sorry to hear that. Could you please provide more details so I \\ncan help?\\n[Customer]: The product is of poor quality and it arrived late. I’m really \\nunhappy with this experience.\\n</conversations>\\n\\nIt is beneficial to use the same noun for the XML tag as the words you have used to describe them in the instructions. The instructions we gave in the prompt above were:\\n\\nClassify the sentiment of the following conversations into one of two classes, using the examples given. Give the sentiment classifications without any other\\npreamble text.\\n\\nWhere we used the nouns conversations, classes, and examples. As such, the XML tags we use as delimiters are <conversations>, <classes>, <example-conversations>, and <example-classes>. This ensures that the LLM understands how your instructions relate to the XML tags used as delimiters.\\n\\nAgain, the sectioning of your instructions in a clear and structured manner through the use of delimiters ensures that GPT-4 responds exactly how you want it to:\\n\\nPositive\\n\\nNegative\\n\\n3. [🔴] Creating System Prompts With LLM Guardrails\\n\\nBefore diving in, it is important to note that this section is relevant only to LLMs that possess a System Prompt feature, unlike the other sections in this article which are relevant for any LLM. The most notable LLM with this feature is, of course, ChatGPT, and therefore we will use ChatGPT as the illustrating example for this section.\\n\\nImage generated by DALL·E 3\\n\\nTerminology surrounding System Prompts\\n\\nFirst, let’s iron out terminology: With regards to ChatGPT, there exists a plethora of resources using these 3 terms almost interchangeably: \"System Prompts\", \"System Messages\", and \"Custom Instructions\". This has proved confusing to many (including me!), so much so that OpenAI released an article explaining these terminologies. Here’s a quick summary of it:\\n\\n\"System Prompts\" and \"System Messages\" are terms used when interacting with ChatGPT programmatically over its Chat Completions API.\\n\\nOn the other hand, \"Custom Instructions\" is the term used when interacting with ChatGPT over its user interface at https://chat.openai.com/.\\n\\nImage from Enterprise DNA Blog\\n\\nOverall, though, the 3 terms refer to the same thing, so don’t let the terminology confuse you! Moving forward, this section will use the term \"System Prompts\". Now let’s dive in!\\n\\nWhat are System Prompts?\\n\\nSystem Prompts are an additional prompt where you provide instructions on how the LLM should behave. It is considered additional as it is outside of your \"normal\" prompts (better known as User Prompts) to the LLM.\\n\\nWithin a chat, every time you provide a new prompt, System Prompts act like a filter that the LLM automatically applies before giving its response to your new prompt. This means that the System Prompts are taken into account every time the LLM responds within the chat.\\n\\nWhen should System Prompts be used?\\n\\nThe first question on your mind might be: Why should I provide instructions inside the System Prompt when I can also provide them in my first prompt to a new chat, before further conversations with the LLM?\\n\\nThe answer is because LLMs have a limit to their conversational memory. In the latter case, as the conversation carries on, the LLM is likely to \"forget\" this first prompt you provided to the chat, making these instructions obsolete.\\n\\nOn the other hand, when instructions are provided in the System Prompt, these System Prompt instructions are automatically taken into account together with each new prompt provided to the chat. This ensures that the LLM continues to receive these instructions even as the conversation carries on, no matter how long the chat becomes.\\n\\nIn conclusion:\\n\\nUse System Prompts to provide instructions that you want the LLM to remember when responding throughout the entire chat.\\n\\nWhat should System Prompts include?\\n\\nInstructions in the System Prompt typically includes the following categories:\\n\\nTask definition, so the LLM will always remember what it has to do throughout the chat.\\n\\nOutput format, so the LLM will always remember how it should respond.\\n\\nGuardrails, so the LLM will always remember how it should *not* respond. Guardrails are emerging field in LLM governance, referring to configured boundaries that an LLM is allowed to operate in.\\n\\nFor example, a System Prompt might look like this:\\n\\nYou will answer questions using this text: [insert text]. \\nYou will respond with a JSON object in this format: {\"Question\": \"Answer\"}.\\nIf the text does not contain sufficient information to answer the question, do not make up information and give the answer as \"NA\". \\nYou are only allowed to answer questions related to [insert scope]. Never answer any questions related to demographic information such as age, gender, and religion.\\n\\nWhere each portion relates to the categories as follows:\\n\\nBreaking down a System Prompt - Image by author\\n\\nBut then what goes into the \"normal\" prompts to the chat?\\n\\nNow you might be thinking: That sounds like a lot of information already being given in the System Prompt. What do I put in my \"normal\" prompts (better known as User Prompts) to the chat then?\\n\\nThe System Prompt outlines the general task at hand. In the above System Prompt example, the task has been defined to only use a specific piece of text for question-answering, and the LLM is instructed to respond in the format {\"Question\": \"Answer\"}.\\n\\nYou will answer questions using this text: [insert text]. \\nYou will respond with a JSON object in this format: {\"Question\": \"Answer\"}.\\n\\nIn this case, each User Prompt to the chat would simply be the question that you want answered using the text. For example, a User Prompt might be \"What is the text about?\". And the LLM would respond with {\"What is the text about?\": \"The text is about...\"}.\\n\\nBut let’s generalize this task example further. In practice, it would be more likely that you have multiple pieces of text that you want to ask questions on, rather than just 1. In this case, we could edit the first line of the above System Prompt from\\n\\nYou will answer questions using this text: [insert text].\\n\\nto\\n\\nYou will answer questions using the provided text.\\n\\nNow, each User Prompt to the chat would include both the text to conduct question-answering over, and the question to be answered, such as:\\n\\n<text>\\n[insert text]\\n</text>\\n\\n<question>\\n[insert question]\\n</question>\\n\\nHere, we also use XML tags as delimiters in order to provide the 2 required pieces of information to the LLM in a structured manner. The nouns used in the XML tags, text and question, correspond to the nouns used in the System Prompt so that the LLM understands how the tags relate to the System Prompt instructions.\\n\\nIn conclusion, the System Prompt should give the overall task instructions, and each User Prompt should provide the exact specifics that you want the task to be executed using. In this case, for example, these exact specifics are the text and the question.\\n\\nExtra: Making LLM guardrails dynamic\\n\\nAbove, guardrails are added through a few sentences in the System Prompt. These guardrails are then set in stone and do not change for the entire chat. What if you wish to have different guardrails in place at different points of the conversation?\\n\\nUnfortunately for users of the ChatGPT user interface, there is no straightforward way to do this right now. However, if you’re interacting with ChatGPT programmatically, you’re in luck! The increasing focus on building effective LLM guardrails has seen the development of open-source packages that allow you to set up far more detailed and dynamic guardrails programmatically.\\n\\nA noteworthy one is NeMo Guardrails developed by the NVIDIA team, which allows you to configure the expected conversation flow between users and the LLM, and thus set up different guardrails at different points of the chat, allowing for dynamic guardrails that evolve as the chat progresses. I definitely recommend checking it out!\\n\\n4. [🔴] Analyzing datasets using only LLMs, without plugins or code\\n\\nImage generated by DALL·E 3\\n\\nYou might have heard of OpenAI’s Advanced Data Analysis plugin within ChatGPT’s GPT-4 that is available to premium (paid) accounts. It allows users to upload datasets to ChatGPT and run code directly on the dataset, allowing for accurate data analysis.\\n\\nBut did you know that you don’t always need such plugins to analyze datasets well with LLMs? Let’s first understand the strengths and limitations of purely using LLMs to analyze datasets.\\n\\nTypes of dataset analysis that LLMs are *not* great at\\n\\nAs you probably already know, LLMs are limited in their ability to perform accurate mathematical calculations, making them unsuitable for tasks requiring precise quantitative analysis on datasets, such as:\\n\\nDescriptive Statistics: Summarizing numerical columns quantitatively, through measures like the mean or variance.\\n\\nCorrelation Analysis: Obtaining the precise correlation coefficient between columns.\\n\\nStatistical Analysis: Such as hypothesis testing to determine if there are statistically significant differences between groups of data points.\\n\\nMachine Learning: Performing predictive modelling on a dataset such as using linear regressions, gradient boosted trees, or neural networks.\\n\\nPerforming such quantitative tasks on datasets is why OpenAI’s Advanced Data Analysis plugin exists, so that programming languages step in to run code for such tasks on a dataset.\\n\\nSo, why would anyone want to analyze datasets using only LLMs and without such plugins?\\n\\nTypes of dataset analysis that LLMs are great at\\n\\nLLMs are excellent at identifying patterns and trends. This capability stems from their extensive training on diverse and voluminous data, enabling them to discern intricate patterns that may not be immediately apparent.\\n\\nThis makes them well-suited for tasks based on pattern-finding within datasets, such as:\\n\\nAnomaly detection: Identifying unusual data points that deviate from the norm, based on one or more column values.\\n\\nClustering: Grouping data points with similar characteristics across columns.\\n\\nCross-Column Relationships: Identifying combined trends across columns.\\n\\nTextual Analysis (For text-based columns): Categorization based on topic or sentiment.\\n\\nTrend Analysis (For datasets with time aspects): Identifying patterns, seasonal variations, or trends within columns across time.\\n\\nFor such pattern-based tasks, using LLMs alone may in fact produce better results within a shorter timeframe than using code! Let’s illustrate this fully with an example.\\n\\nAnalyzing a Kaggle dataset using only LLMs\\n\\nWe’ll use a popular real-world Kaggle dataset curated for Customer Personality Analysis, wherein a company seeks to segment its customer base in order to understand its customers better.\\n\\nFor easier validation of the LLM’s analysis later, we’ll subset this dataset to 50 rows and retain only the most relevant columns. After which, the dataset for analysis looks like this, where each row represents a customer, and the columns depict customer information:\\n\\nFirst 3 rows of dataset - Image by author\\n\\nSay you work on the company’s marketing team. You are tasked to utilize this dataset of customer information to guide marketing efforts. This is a 2-step task: First, use the dataset to generate meaningful customer segments. Next, generate ideas on how to best market towards each segment. Now this is a practical business problem where the pattern-finding (for step 1) capability of LLMs can truly excel.\\n\\nLet’s craft a prompt for this task as follows, using 4 prompt engineering techniques (more on these later!):\\n1. Breaking down a complex task into simple steps\\n2. Referencing intermediate outputs from each step\\n3. Formatting the LLM’s response\\n4. Separating the instructions from the dataset\\n\\nSystem Prompt:\\nI want you to act as a data scientist to analyze datasets. Do not make up information that is not in the dataset. For each analysis I ask for, provide me with the exact and definitive answer and do not provide me with code or instructions to do the analysis on other platforms.\\n\\nPrompt:\\n# CONTEXT #\\nI sell wine. I have a dataset of information on my customers: [year of birth, marital status, income, number of children, days since last purchase, amount spent].\\n\\n#############\\n\\n# OBJECTIVE #\\nI want you use the dataset to cluster my customers into groups and then give me ideas on how to target my marketing efforts towards each group. Use this step-by-step process and do not use code:\\n\\n1. CLUSTERS: Use the columns of the dataset to cluster the rows of the dataset, such that customers within the same cluster have similar column values while customers in different clusters have distinctly different column values. Ensure that each row only belongs to 1 cluster.\\n \\nFor each cluster found,\\n2. CLUSTER_INFORMATION: Describe the cluster in terms of the dataset columns.\\n3. CLUSTER_NAME: Interpret [CLUSTER_INFORMATION] to obtain a short name for the customer group in this cluster.\\n4. MARKETING_IDEAS: Generate ideas to market my product to this customer group.\\n5. RATIONALE: Explain why [MARKETING_IDEAS] is relevant and effective for this customer group.\\n\\n#############\\n\\n# STYLE #\\nBusiness analytics report\\n\\n#############\\n\\n# TONE #\\nProfessional, technical\\n\\n#############\\n\\n# AUDIENCE #\\nMy business partners. Convince them that your marketing strategy is well thought-out and fully backed by data.\\n\\n#############\\n\\n# RESPONSE: MARKDOWN REPORT #\\n <For each cluster in [CLUSTERS]>\\n - Customer Group: [CLUSTER_NAME]\\n - Profile: [CLUSTER_INFORMATION]\\n - Marketing Ideas: [MARKETING_IDEAS]\\n - Rationale: [RATIONALE]\\n\\n<Annex>\\n Give a table of the list of row numbers belonging to each cluster, in order to back up your analysis. Use these table headers: [[CLUSTER_NAME], List of Rows].\\n\\n#############\\n\\n# START ANALYSIS #\\n If you understand, ask me for my dataset.\\n\\nBelow is GPT-4’s reply, and we proceed to pass the dataset to it in a CSV string.\\n\\nGPT-4\\'s response - Image by author\\n\\nFollowing which, GPT-4 replies with its analysis in the markdown report format we asked for:\\n\\nGPT-4\\'s response - Image by author\\n\\nGPT-4\\'s response - Image by author\\n\\nGPT-4\\'s response - Image by author\\n\\nValidating the LLM’s analysis\\n\\nFor the sake of brevity, we’ll pick 2 customer groups generated by the LLM for validation - say, Young Families and Discerning Enthusiasts.\\n\\nYoung Families\\n- Profile synthesized by LLM: Born after 1980, Married or Together, Moderate to low income, Have children, Frequent small purchases.\\n- Rows clustered into this group by LLM: 3, 4, 7, 10, 16, 20\\n- Digging into the dataset, the full data for these rows are:\\n\\nFull data for Young Families - Image by author\\n\\nWhich exactly correspond to the profile identified by the LLM. It was even able to cluster the row with a null value without us preprocessing it beforehand!\\n\\nDiscerning Enthusiasts\\n- Profile synthesized by LLM: Wide age range, Any marital status, High income, Varied children status, High spend on purchases.\\n- Rows clustered into this group by LLM: 2, 5, 18, 29, 34, 36\\n- Digging into the dataset, the full data for these rows are:\\n\\nFull data for Discerning Enthusiasts - Image by author\\n\\nWhich again align very well with the profile identified by the LLM!\\n\\nThis example showcases LLMs’ abilities in pattern-finding, interpreting and distilling multi-dimensional datasets into meaningful insights, while ensuring that its analysis is deeply rooted in the factual truth of the dataset.\\n\\nWhat if we used ChatGPT’s Advanced Data Analysis plugin?\\n\\nFor completeness, I attempted this same task with the same prompt, but asked ChatGPT to execute the analysis using code instead, which activated its Advanced Data Analysis plugin. The idea was for the plugin to run code using a clustering algorithm like K-Means directly on the dataset to obtain each customer group, before synthesizing the profile of each cluster to provide marketing strategies.\\n\\nHowever, multiple attempts resulted in the following error messages with no outputs, despite the dataset being only 50 rows:\\n\\nError and no output from Attempt 1 - Image by author\\n\\nError and no output from Attempt 2 - Image by author\\n\\nWith the Advanced Data Analysis plugin right now, it appears that executing simpler tasks on datasets such as calculating descriptive statistics or creating graphs can be easily achieved, but more advanced tasks that require computing of algorithms may sometimes result in errors and no outputs, due to computational limits or otherwise.\\n\\nSo…When to analyze datasets using LLMs?\\n\\nThe answer is it depends on the type of analysis.\\n\\nFor tasks requiring precise mathematical calculations or complex, rule-based processing, conventional programming methods remain superior.\\n\\nFor tasks based on pattern-recognition, it can be challenging or more time-consuming to execute using conventional programming and algorithmic approaches. LLMs, however, excel at such tasks, and can even provide additional outputs such as annexes to back up its analysis, and full analysis reports in markdown formatting.\\n\\nUltimately, the decision to utilize LLMs hinges on the nature of the task at hand, balancing the strengths of LLMs in pattern-recognition against the precision and specificity offered by traditional programming techniques.\\n\\nNow back to the prompt engineering!\\n\\nBefore this section ends, let’s go back to the prompt used to generate this dataset analysis and break down the key prompt engineering techniques used:\\n\\nPrompt:\\n# CONTEXT #\\nI sell wine. I have a dataset of information on my customers: [year of birth, marital status, income, number of children, days since last purchase, amount spent].\\n\\n#############\\n\\n# OBJECTIVE #\\nI want you use the dataset to cluster my customers into groups and then give me ideas on how to target my marketing efforts towards each group. Use this step-by-step process and do not use code:\\n\\n1. CLUSTERS: Use the columns of the dataset to cluster the rows of the dataset, such that customers within the same cluster have similar column values while customers in different clusters have distinctly different column values. Ensure that each row only belongs to 1 cluster.\\n \\nFor each cluster found,\\n2. CLUSTER_INFORMATION: Describe the cluster in terms of the dataset columns.\\n3. CLUSTER_NAME: Interpret [CLUSTER_INFORMATION] to obtain a short name for the customer group in this cluster.\\n4. MARKETING_IDEAS: Generate ideas to market my product to this customer group.\\n5. RATIONALE: Explain why [MARKETING_IDEAS] is relevant and effective for this customer group.\\n\\n#############\\n\\n# STYLE #\\nBusiness analytics report\\n\\n#############\\n\\n# TONE #\\nProfessional, technical\\n\\n#############\\n\\n# AUDIENCE #\\nMy business partners. Convince them that your marketing strategy is well thought-out and fully backed by data.\\n\\n#############\\n\\n# RESPONSE: MARKDOWN REPORT #\\n <For each cluster in [CLUSTERS]>\\n - Customer Group: [CLUSTER_NAME]\\n - Profile: [CLUSTER_INFORMATION]\\n - Marketing Ideas: [MARKETING_IDEAS]\\n - Rationale: [RATIONALE]\\n\\n<Annex>\\n Give a table of the list of row numbers belonging to each cluster, in order to back up your analysis. Use these table headers: [[CLUSTER_NAME], List of Rows].\\n\\n#############\\n\\n# START ANALYSIS #\\n If you understand, ask me for my dataset.\\n\\nTechnique 1: Breaking down a complex task into simple steps\\nLLMs are great at performing simple tasks, but not so great at complex ones. As such, with complex tasks like this one, it is important to break down the task into simple step-by-step instructions for the LLM to follow. The idea is to give the LLM the steps that you yourself would take to execute the task.\\n\\nIn this example, the steps are given as:\\n\\nUse this step-by-step process and do not use code:\\n\\n1. CLUSTERS: Use the columns of the dataset to cluster the rows of the dataset, such that customers within the same cluster have similar column values while customers in different clusters have distinctly different column values. Ensure that each row only belongs to 1 cluster.\\n \\nFor each cluster found,\\n2. CLUSTER_INFORMATION: Describe the cluster in terms of the dataset columns.\\n3. CLUSTER_NAME: Interpret [CLUSTER_INFORMATION] to obtain a short name for the customer group in this cluster.\\n4. MARKETING_IDEAS: Generate ideas to market my product to this customer group.\\n5. RATIONALE: Explain why [MARKETING_IDEAS] is relevant and effective for this customer group.\\n\\nAs opposed to simply giving the overall task to the LLM as \"Cluster the customers into groups and then give ideas on how to market to each group\".\\n\\nWith step-by-step instructions, LLMs are significantly more likely to deliver the correct results.\\n\\nTechnique 2: Referencing intermediate outputs from each step\\nWhen providing the step-by-step process to the LLM, we give the intermediate output from each step a capitalized VARIABLE_NAME, namely CLUSTERS, CLUSTER_INFORMATION, CLUSTER_NAME, MARKETING_IDEAS and RATIONALE.\\n\\nCapitalization is used to differentiate these variable names from the body of instructions given. These intermediate outputs can later be referenced using square brackets as [VARIABLE_NAME].\\n\\nTechnique 3: Formatting the LLM’s response\\nHere, we ask for a markdown report format, which beautifies the LLM’s response. Having variable names from intermediate outputs again comes in handy here to dictate the structure of the report.\\n\\n# RESPONSE: MARKDOWN REPORT #\\n <For each cluster in [CLUSTERS]>\\n - Customer Group: [CLUSTER_NAME]\\n - Profile: [CLUSTER_INFORMATION]\\n - Marketing Ideas: [MARKETING_IDEAS]\\n - Rationale: [RATIONALE]\\n\\n<Annex>\\n Give a table of the list of row numbers belonging to each cluster, in order to back up your analysis. Use these table headers: [[CLUSTER_NAME], List of Rows].\\n\\nIn fact, you could even subsequently ask ChatGPT to provide the report as a downloadable file, allowing you to work off of its response in writing your final report.\\n\\nSaving GPT-4\\'s response as a file - Image by author\\n\\nTechnique 4: Separating the task instructions from the dataset\\nYou’ll notice that we never gave the dataset to the LLM in our first prompt. Instead, the prompt gives only the task instructions for the dataset analysis, with this added to the bottom:\\n\\n# START ANALYSIS #\\nIf you understand, ask me for my dataset.\\n\\nChatGPT then responded that it understands, and we passed the dataset to it as a CSV string in our next prompt:\\n\\nGPT-4\\'s response - Image by author\\n\\nBut why separate the instructions from the dataset?\\n\\nThe straightforward answer is that LLMs have a limit to their context window, or the number of tokens they can take as input in 1 prompt. A long prompt combining both instructions and data might exceed this limit, leading to truncation and loss of information.\\n\\nThe more intricate answer is that separating the instructions and the dataset helps the LLM maintain clarity in understanding each, with lower likelihood of missing out information. You might have experienced scenarios where the LLM \"accidentally forgets\" a certain instruction you gave as part of a longer prompt - for example, if you asked for a 100-word response and the LLM gives you a longer paragraph back. By receiving the instructions first, before the dataset that the instructions are for, the LLM can first digest what it should do, before executing it on the dataset provided next.\\n\\nNote however that this separation of instructions and dataset can only be achieved with chat LLMs as they maintain a conversational memory, unlike completion LLMs which do not.\\n\\nClosing Thoughts\\n\\nBefore this article ends, I wanted to share some personal reflections on this incredible journey.\\n\\nFirst, a heartfelt thank you to GovTech Singapore for orchestrating such an amazing competition.\\n\\nA live on-stage battle in the final round!\\n\\nSecond, a big shout-out to my fellow phenomenal competitors, who each brought something special, making the competition as enriching as it was challenging! I’ll never forget the final round, with us battling it out on stage and a live audience cheering us on - an experience I’ll always remember fondly.\\n\\nFor me, this wasn’t just a competition; it was a celebration of talent, creativity, and the spirit of learning. And I’m beyond excited to see what comes next!\\n\\nI had a lot of fun writing this, and if you had fun reading, I would really appreciate if you took a second to leave some claps and a follow! You can also buy me a matcha latte 🍵 to fuel my next article :)\\n\\nSee you in the next one!\\nSheila'}},\n",
       " {'id': '8c339f8fb602',\n",
       "  'title': 'Stacked Ensembles for Advanced Predictive Modeling With H2O.ai and Optuna',\n",
       "  'subtitle': 'And how I placed top 10% in Europe’s largest machine learning competition with them!',\n",
       "  'author': 'fca9db1c7da0',\n",
       "  'publication_id': '7f60cf5620c9',\n",
       "  'published_at': '2023-12-18 16:05:44',\n",
       "  'last_modified_at': '2023-12-29 16:32:23',\n",
       "  'tags': ['machine-learning',\n",
       "   'data-science',\n",
       "   'deep-learning',\n",
       "   'ensemble-learning',\n",
       "   'python'],\n",
       "  'topics': ['machine-learning', 'data-science'],\n",
       "  'claps': 462,\n",
       "  'voters': 104,\n",
       "  'word_count': 3134,\n",
       "  'responses_count': 11,\n",
       "  'reading_time': 12.376415094339624,\n",
       "  'url': 'https://towardsdatascience.com/stacked-ensembles-for-advanced-predictive-modeling-with-h2o-ai-and-optuna-8c339f8fb602',\n",
       "  'unique_slug': 'stacked-ensembles-for-advanced-predictive-modeling-with-h2o-ai-and-optuna-8c339f8fb602',\n",
       "  'image_url': 'https://miro.medium.com/1*5FM14YZopRvGK9baJR0OtQ.png',\n",
       "  'lang': 'en',\n",
       "  'is_series': False,\n",
       "  'is_locked': True,\n",
       "  'is_shortform': False,\n",
       "  'top_highlight': '',\n",
       "  'content': {'id': '8c339f8fb602',\n",
       "   'content': \"How I Achieved Top 10% in Europe’s Largest Machine Learning Competition with Stacked Ensembles\\n\\nA conceptual and hands-on coding guide to training Stacked Ensembles with H2O.ai and Optuna\\n\\nImage generated by DALL·E 3\\n\\nWe all know that ensemble models outperform any singular model at predictive modeling. You’ve probably heard all about Bagging and Boosting as common ensemble methods, with Random Forests and Gradient Boosting Machines as respective examples.\\n\\nBut what about ensembling different models together under a separate higher-level model? This is where stacked ensembles comes in. This article is step-by-step guide on how to train stacked ensembles using the popular machine learning library, H2O.\\n\\nTo demonstrate the power of stacked ensembles, I will provide a walk-through of my full code for training a stacked ensemble of 40 Deep Neural Network, XGBoost and LightGBM models for the prediction task posed in the 2023 Cloudflight Coding Competition (AI Category), one of the largest coding competitions in Europe, where I placed top 10% on the competition leaderboard within a training time of 1 hour!\\n\\nThis guide will cover:\\n\\nWhat are stacked ensembles and how do they work?\\n\\nHow to train stacked ensembles with H2O.ai - \\nWith a full code walk-through in Python\\n\\nComparing the performance of a stacked ensemble versus standalone models\\n\\n1. What are Stacked Ensembles and how do they work?\\n\\nA stacked ensemble combines predictions from multiple models through another, higher-level model, with the aim being to increase overall predictive performance by capitalizing on the unique strengths of each constituent model. It involves 2 stages:\\n\\nStage 1: Multiple Base Models\\n\\nFirst, multiple base models are independently trained on the same training dataset. These models should ideally be diverse, ranging from simple linear regressions to complex deep learning models. The key is that they should differ from each other in some way, either in terms of using a different algorithm or using the same algorithm but with different hyperparameter settings.\\n\\nThe more diverse the base models are, the more powerful the eventual stacked ensemble. This is because different models are able to capture different patterns in the data. For example, a tree-based model might be good at capturing non-linear relationships, while a linear model excels at understanding linear trends. When these diverse base models are combined, the stacked ensemble can then leverage the different strengths of each base model, increasing predictive performance.\\n\\nStage 2: One Meta-Model\\n\\nAfter all the base models are trained, each base model’s predictions for the target is used as a feature for training a higher-level model, termed a meta-model. This means that the meta-model is not trained on the original dataset’s features, but instead on the predictions of the base models. If there are n base models, there are n predictions generated, and these are the n features used for training the meta-model.\\n\\nWhile the training features differ between the base models and the meta-model, the target however stays the same, which is the original target from the dataset.\\n\\nThe meta-model learns how to best combine the predictions from the base models to make a final, more accurate prediction.\\n\\nDetailed Steps for Training a Stacked Ensemble\\n\\nFor each base model:\\n1. Pick an algorithm (eg. Random Forest).\\n2. Use cross-validation to obtain the best set of hyperparameters for the algorithm.\\n3. Obtain cross-validation predictions for the target in the training set. These will be used to train the meta-model subsequently.\\n\\nTo illustrate this, say a Random Forest algorithm was chosen in Step 1, and its optimal hyperparameters were determined as h in Step 2.\\n\\nThe cross-validation predictions are obtained through the following, assuming 5-fold cross-validation:\\n1. Train a Random Forest with hyperparamters h on Folds 1–4.\\n2. Used the trained Random Forest to make predictions for Fold 5. These are the cross-validation predictions for Fold 5.\\n3. Repeat the above to obtain cross-validation predictions for each fold. After which, cross-validation predictions for the target will be obtained for the entire training set.\\n\\nFor the meta-model:\\n1. Obtain the features for training the meta-model. These are the predictions of each of the base models.\\n2. Obtain the target for training the meta-model. This is the original target from the training set.\\n3. Pick an algorithm (eg. Linear Regression).\\n4. Use cross-validation to obtain the best set of hyperparameters for the algorithm.\\n\\nAnd voila! You now have:\\n- Multiple base models that are trained with optimal hyperparameters\\n- One meta-model that is also trained with optimal hyperparameters\\n\\nWhich means you have successfully trained a stacked ensemble!\\n\\n2. How to Train Stacked Ensembles with H2O.ai\\n\\nNow, let’s jump into coding it out!\\n\\nAs mentioned, this section covers my full code for training a stacked ensemble for the prediction task posed in the 2023 Cloudflight Coding Competition (AI Category), which is a regression task using tabular data. Within the competition’s time constraints, I created a stacked ensemble from 40 base models of 3 algorithm types - Deep Neural Network, XGBoost, and LightGBM, with these specific algorithms chosen as they often achieve superior performance in practice.\\n\\n2.1. Data Preparation\\n\\nFirst, let’s import the necessary libraries.\\n\\nimport pandas as pd\\nimport h2o\\nfrom h2o.estimators.deeplearning import H2ODeepLearningEstimator\\nfrom h2o.estimators import H2OXGBoostEstimator\\nfrom h2o.estimators.stackedensemble import H2OStackedEnsembleEstimator\\nimport optuna\\nfrom tqdm import tqdm\\n\\nseed = 1\\n\\nAnd initialize the H2O cluster.\\n\\nh2o.init()\\n\\nNext, load in the dataset.\\n\\ndata = pd.read_csv('path_to_your_tabular_dataset')\\n\\nBefore moving on to model building using H2O, let’s first understand the following traits of H2O models:\\n\\nH2O models cannot take in Pandas DataFrame objects, so data must be converted from a Pandas DataFrame to its H2O equivalent, which is a H2OFrame.\\n\\nH2O models can encode categorical features automatically, which is great as it takes this preprocessing step out of our hands. To ensure that such features are understood by the models to be categorical, they must be explicitly converted into the factor (categorical) data type.\\n\\ndata_h2o = h2o.H2OFrame(data)\\n\\ncategorical_cols = [...]  #insert the names of the categorical features here\\nfor col in categorical_cols:\\n  data_h2o[col] = data_h2o[col].asfactor()\\n\\nNow we can proceed to split our dataset into train (90%) and validation (10%) sets, using the split_frame() method of H2OFrame objects.\\n\\nsplits = data_h2o.split_frame(ratios=[0.9], seed=seed)\\ntrain = splits[0]\\nval = splits[1]\\n\\nLastly, let’s obtain the features and target for modelling. Unlike Scikit-Learn models which take as input the values of the features and the target, H2O models take as input the names of the features and the target.\\n\\ny = '...'  #insert name of the target column here\\nx = list(train.columns)\\nx.remove(y) \\n\\nNow, let the model training fun begin!\\n\\n2.2. Training Deep Neural Networks (DNN) as Base Models\\n\\nLet’s start by training the DNNs that will form our set of base models for the stacked ensemble, using H2O’s H2ODeepLearningEstimator.\\n\\nAside: Why train DNNs in H2O, instead of Tensorflow, Keras, or PyTorch?\\n\\nBefore jumping into the code for this, you might be wondering why I chose to train DNNs using H2O’s H2ODeepLearningEstimator, as opposed to using Tensorflow, Keras, or PyTorch, which are the common libraries used to build DNNs.\\n\\nThe straightforward answer is that building a stacked ensemble in H2O uses the H2OStackedEnsembleEstimator, which can only accept base models that are part of the H2O model family. However, the more critical reason is that H2O’s H2ODeepLearningEstimator enables far easier tuning of DNNs than these other frameworks, and here’s why.\\n\\nIn TensorFlow, Keras, or PyTorch, regularization effects like dropout layers must be manually added into the model architecture, such as using keras.layers.Dropout(). This allows for greater customization, but also requires more detailed knowledge and effort. For example, you have to decide where and how many times to include the keras.layers.Dropout() layer within your model architecture.\\n\\nOn the other hand, H2O's H2ODeepLearningEstimator is more abstracted and accessible to the layman. Regularization can be enabled in a straightforward manner through model hyperparameters, reducing the need for manual setup of these components as layers. Furthermore, the default model hyperparameters already includes regularization. The common feature preprocessing steps, such as scaling of numerical features and encoding of categorical features, are also included as model hyperparameters for automatic feature preprocessing. These enable the tuning of DNNs to be a far more straightforward and easy process, without having to dive into the complexities of deep learning model architecture. In the context of a time crunch in the competition, this was extremely useful for me!\\n\\nBut which set of hyperparameters should we train H2ODeepLearningEstimator with? This is where optuna comes in. Optuna is a hyperparameter optimization framework, similar to the traditional grid search and random search approaches, but better in that it employs a more sophisticated approach.\\n\\nGrid search systematically explores a predefined range of hyperparameter values, while random search selects random combinations within these specified limits. However, optuna uses Bayesian optimization to learn from previous searches to propose better-performing hyperparameter sets in each subsequent search, increasing the efficiency of its search for the optimal model hyperparameters. This is especially effective in complex and large hyperparameter spaces where traditional search methods can be prohibitively time-consuming and may eventually still fail to locate the optimal set of hyperparameters.\\n\\nNow, let’s get into the code. We’ll use optuna to tune the hyperparameters of H2O’s H2ODeepLearningEstimator, and keep track of all the trained models inside the list dnn_models.\\n\\ndnn_models = []\\n\\ndef objective(trial):\\n    #params to tune\\n    num_hidden_layers = trial.suggest_int('num_hidden_layers', 1, 10)\\n    hidden_layer_size = trial.suggest_int('hidden_layer_size', 100, 300, step=50)\\n    \\n    params = {\\n        'hidden': [hidden_layer_size]*num_hidden_layers,\\n        'epochs': trial.suggest_int('epochs', 5, 100),\\n        'input_dropout_ratio': trial.suggest_float('input_dropout_ratio', 0.1, 0.3),  #dropout for input layer\\n        'l1': trial.suggest_float('l1', 1e-5, 1e-1, log=True),  #l1 regularization\\n        'l2': trial.suggest_float('l2', 1e-5, 1e-1, log=True),  #l2 regularization\\n        'activation': trial.suggest_categorical('activation', ['rectifier', 'rectifierwithdropout', 'tanh', 'tanh_with_dropout', 'maxout', 'maxout_with_dropout'])\\n}\\n    \\n    #param 'hidden_dropout_ratios' is applicable only if the activation type is rectifier_with_dropout, tanh_with_dropout, or maxout_with_dropout\\n    if params['activation'] in ['rectifierwithdropout', 'tanh_with_dropout', 'maxout_with_dropout']:\\n        hidden_dropout_ratio = trial.suggest_float('hidden_dropout_ratio', 0.1, 1.0)  \\n        params['hidden_dropout_ratios'] = [hidden_dropout_ratio]*num_hidden_layers  #dropout for hidden layers\\n\\n    #train model\\n    model = H2ODeepLearningEstimator(**params,\\n                                     standardize=True,  #h2o models can do this feature preprocessing automatically\\n                                     categorical_encoding='auto',  #h2o models can do this feature preprocessing automatically\\n                                     nfolds=5,\\n                                     keep_cross_validation_predictions=True,  #need this for training the meta-model later\\n                                     seed=seed)\\n    model.train(x=x, y=y, training_frame=train)\\n    \\n    #store model\\n    dnn_models.append(model)\\n\\n    #get cross-validation rmse \\n    cv_metrics_df = model.cross_validation_metrics_summary().as_data_frame()\\n    cv_rmse_index = cv_metrics_df[cv_metrics_df[''] == 'rmse'].index\\n    cv_rmse = cv_metrics_df['mean'].iloc[cv_rmse_index]\\n    return cv_rmse\\n\\nstudy = optuna.create_study(direction='minimize')\\nstudy.optimize(objective, n_trials=20)\\n\\nAbove, an optuna study is created to search for the best set of H2ODeepLearningEstimator hyperparameters that minimizes the cross-validation RMSE (as this is a regression task), with the optimization process running for 20 trials using the parameter n_trials=20. This means that 20 DNNs are trained and stored in the list dnn_models for usage as base models for the stacked ensemble later on, each with a different set of hyperparameters. In the interest of time under the competition’s time constraints, I chose to train 20 DNNs, but you can set n_trials to be however many DNNs you wish to train for your stacked ensemble.\\n\\nImportantly, the H2ODeepLearningEstimator must be trained with keep_cross_validation_predictions=True, as these cross-validation predictions will be used as features for training the meta-model later.\\n\\n2.3. Training XGBoost and LightGBM as Base Models\\n\\nNext, let’s train the XGBoost and LightGBM models that will also form our set of base models for the stacked ensemble. We’ll again use optuna to tune the hyperparameters of H2O’s H2OXGBoostEstimator, and keep track of all the trained models inside the list xgboost_lightgbm_models.\\n\\nBefore diving into the code for this, we must first understand that H2OXGBoostEstimator is the integration of the XGBoost framework from the popular xgboost library into H2O. On the other hand, H2O does not integrate the lightgbm library. However, it does provide a method for emulating the LightGBM framework using a certain set of parameters within H2OXGBoostEstimator- and this is exactly what we will implement in order to train both XGBoost and LightGBM models using H2OXGBoostEstimator.\\n\\nxgboost_lightgbm_models = []\\n\\ndef objective(trial):\\n    #common params between xgboost and lightgbm\\n    params = {\\n        'ntrees': trial.suggest_int('ntrees', 50, 5000),\\n        'max_depth': trial.suggest_int('max_depth', 1, 9),\\n        'min_rows': trial.suggest_int('min_rows', 1, 5),\\n        'sample_rate': trial.suggest_float('sample_rate', 0.8, 1.0),\\n        'col_sample_rate': trial.suggest_float('col_sample_rate', 0.2, 1.0),\\n        'col_sample_rate_per_tree': trial.suggest_float('col_sample_rate_per_tree', 0.5, 1.0)\\n    }\\n    \\n    grow_policy = trial.suggest_categorical('grow_policy', ['depthwise', 'lossguide'])\\n    \\n     #######################################################################################################################\\n     #from H2OXGBoostEstimator's documentation, (https://docs.h2o.ai/h2o/latest-stable/h2o-docs/data-science/xgboost.html) # \\n     #lightgbm is emulated when grow_policy=lossguide and tree_method=hist                                                 #\\n     #so we will tune lightgbm-specific hyperparameters when this set of hyperparameters is used                           #\\n     #and tune xgboost-specific hyperparameters otherwise                                                                  #\\n     #######################################################################################################################\\n\\n    #add lightgbm-specific params\\n    if grow_policy == 'lossguide':  \\n        tree_method = 'hist'  \\n        params['max_bins'] = trial.suggest_int('max_bins', 20, 256)\\n        params['max_leaves'] = trial.suggest_int('max_leaves', 31, 1024)\\n        \\n    #add xgboost-specific params\\n    else:\\n        tree_method = 'auto'\\n        params['booster'] = trial.suggest_categorical('booster', ['gbtree', 'gblinear', 'dart'])\\n        params['reg_alpha'] = trial.suggest_float('reg_alpha', 0.001, 1)\\n        params['reg_lambda'] = trial.suggest_float('reg_lambda', 0.001, 1)\\n        params['min_split_improvement'] = trial.suggest_float('min_split_improvement', 1e-10, 1e-3, log=True)\\n    \\n    #add grow_policy and tree_method into params dict\\n    params['grow_policy'] = grow_policy\\n    params['tree_method'] = tree_method\\n\\n    #train model\\n    model = H2OXGBoostEstimator(**params,\\n                                learn_rate=0.1,\\n                                categorical_encoding='auto',  #h2o models can do this feature preprocessing automatically\\n                                nfolds=5,\\n                                keep_cross_validation_predictions=True,  #need this for training the meta-model later\\n                                seed=seed) \\n    model.train(x=x, y=y, training_frame=train)\\n\\n    #store model\\n    xgboost_lightgbm_models.append(model)\\n\\n    #get cross-validation rmse\\n    cv_metrics_df = model.cross_validation_metrics_summary().as_data_frame()\\n    cv_rmse_index = cv_metrics_df[cv_metrics_df[''] == 'rmse'].index\\n    cv_rmse = cv_metrics_df['mean'].iloc[cv_rmse_index]\\n    return cv_rmse\\n\\nstudy = optuna.create_study(direction='minimize')\\nstudy.optimize(objective, n_trials=20)\\n\\nSimilarly, 20 XGBoost and LightGBM models are trained and stored in the list xgboost_lightgbm_models for usage as base models for the stacked ensemble later on, each with a different set of hyperparameters. You can set n_trials to be however many XGBoost/LightGBM models you wish to train for your stacked ensemble.\\n\\nImportantly, the H2OXGBoostEstimator must also be trained with keep_cross_validation_predictions=True, as these cross-validation predictions will be used as features for training the meta-model later.\\n\\n2.4. Training the Meta-Model\\n\\nWe will use all of the Deep Neural Network, XGBoost and LightGBM models trained above as base models. However, this does not mean that all of them will be used in the stacked ensemble, as we will perform automatic base model selection when tuning our meta-model (more on this later)!\\n\\nRecall that we had stored each trained base model inside the lists dnn_models (20 models) and xgboost_lightgbm_models (20 models), giving a total of 40 base models for our stacked ensemble. Let’s combine them into a final list of base models, base_models.\\n\\nbase_models = dnn_models + xgboost_lightgbm_models\\n\\nNow, we are ready to train the meta-model using these base models. But first, we have to decide on the meta-model algorithm, where a few concepts come into play:\\n\\nMost academic papers on stacked ensembles recommend choosing a simple linear-based algorithm for the meta-model. This is to avoid the meta-model overfitting to the predictions from the base models.\\n\\nH2O recommends the usage of a Generalized Linear Model (GLM) over a Linear Regression (for regression tasks) or Logistic Regression (for classification tasks). This is because the GLM is a flexible linear model that does not impose the key assumptions of normality and homoscedasticity that the latter do, allowing it to model the true behavior of the target values better, since such assumptions can be difficult to be met in practice. Further explanations on this can be found in this academic thesis, on which H2O’s work was based upon.\\n\\nAs such, we will instantiate the meta-model using H2OStackedEnsembleEstimator with metalearner_algorithm='glm', and use optuna to tune the hyperparameters of the GLM meta-model to optimize performance.\\n\\ndef objective(trial):\\n    #GLM params to tune\\n    meta_model_params = {\\n        'alpha': trial.suggest_float('alpha', 0, 1),  #regularization distribution between L1 and L2\\n        'family': trial.suggest_categorical('family', ['gaussian', 'tweedie']),  #read the documentation here on which family your target may fall into: https://docs.h2o.ai/h2o/latest-stable/h2o-docs/data-science/glm.html\\n        'standardize': trial.suggest_categorical('standardize', [True, False]),\\n        'non_negative': True  #predictions of each base model cannot be subtracted from one another\\n    }\\n\\n    ensemble = H2OStackedEnsembleEstimator(metalearner_algorithm='glm',\\n                                             metalearner_params=meta_model_params,\\n                                             metalearner_nfolds=5,\\n                                             base_models=base_models,  \\n                                             seed=seed)\\n\\n    ensemble.train(x=x, y=y, training_frame=train)\\n    \\n    #get cross-validation rmse\\n    cv_metrics_df = ensemble.cross_validation_metrics_summary().as_data_frame()\\n    cv_rmse_index = cv_metrics_df[cv_metrics_df[''] == 'rmse'].index\\n    cv_rmse = cv_metrics_df['mean'].iloc[cv_rmse_index]\\n    return cv_rmse\\n\\nstudy = optuna.create_study(direction='minimize')\\nstudy.optimize(objective, n_trials=20)\\n\\nNotice that the cross-validation predictions of each base model were not explicitly passed into H2OStackedEnsembleEstimator. This is because H2O does this automatically under the hood, making things easier for us! All we had to do was set keep_cross_validation_predictions=True when training our base models previously, and instantiate H2OStackedEnsembleEstimator with the parameter base_models=base_models.\\n\\nNow, we can finally build the best_ensemble model, using the optimal hyperparameters found by optuna.\\n\\nbest_meta_model_params = study.best_params\\nbest_ensemble = H2OStackedEnsembleEstimator(metalearner_algorithm='glm',\\n                                            metalearner_params=best_meta_model_params,\\n                                            base_models=base_models,\\n                                            seed=seed)\\n\\nbest_ensemble.train(x=x, y=y, training_frame=train)\\n\\nAnd voila, we have successfully trained a stacked ensemble in H2O! Let’s take a look at it.\\n\\nbest_ensemble.summary()\\n\\nImage by author\\n\\nNotice that the stacked ensemble uses only 16 out of the 40 base models we passed to it, of which 3 are XGBoost/LightGBM and 13 are Deep Neural Networks. This is due to the hyperparameter alpha that we tuned for the GLM meta-model, which represents the distribution of regularization between L1 (LASSO) and L2 (Ridge). A value of 1 entails only L1 regularization, while a value of 0 entails only L2 regularization.\\n\\nAs reflected above, its optimal value was found to be alpha=0.16, thus a mix of L1 and L2 was employed. Some of the base models’ predictions had their coefficients in the regression set to 0 under L1 regularization, meaning that these base models were not used in the stacked ensemble at all, therefore fewer than 40 base models ended up being used.\\n\\nThe key takeaway here is that our setup above also performs automatic selection of which base models to use for optimal performance, through the meta-model’s regularization hyperparameters, instead of simply using all 40 base models provided.\\n\\n3. Comparing Performance: Stacked Ensemble Versus Standalone Base Models\\n\\nTo demonstrate the power of stacked ensembles, let’s use it to generate predictions for the validation set, which was held out from the beginning. The RMSE figures below are specific only to the dataset I am using, but feel free to run this article’s codes on your own dataset too, and see the difference in model performance for yourself!\\n\\nensemble_val_rmse = best_ensemble.model_performance(val).rmse()\\nensemble_val_rmse   #0.31475634111745304\\n\\nThe stacked ensemble produces an RMSE of 0.31 on the validation set.\\n\\nNext, let’s dig into the performance of each of the base models on this same validation set.\\n\\nbase_val_rmse = []\\nfor i in range(len(base_models)):\\n    base_val_rmse = base_models[i].model_performance(val).rmse()\\n    \\nmodels = ['H2ODeepLearningEstimator'] * len(dnn_models) + ['H2OXGBoostEstimator'] * len(xgboost_lightgbm_models)\\n\\nbase_val_rmse_df = pd.DataFrame([models, base_val_rmse]).T\\nbase_val_rmse_df.columns = ['model', 'val_rmse']\\nbase_val_rmse_df = base_val_rmse_df.sort_values(by='val_rmse', ascending=True).reset_index(drop=True)\\nbase_val_rmse_df.head(15)  #show only the top 15 in terms of lowest val_rmse\\n\\nImage by author\\n\\nCompared to the stacked ensemble which achieved an RMSE of 0.31, the best-performing standalone base model achieved an RMSE of 0.35.\\n\\nThis means that Stacking was able to improve predictive performance by 11% on unseen data!\\n\\nNow that you’ve witnessed the power of stacked ensembles, it’s your turn to try them out!\\n\\nI had a lot of fun writing this, and if you had fun reading, I would really appreciate if you took a second to leave some claps and a follow! You can also buy me a matcha latte 🍵 to fuel my next article :)\\n\\nSee you in the next one!\\nSheila\"}}]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_writers[0]['top_articles']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert follower dictionary to json\n",
    "writer_json = json.dumps(top_writers)\n",
    "\n",
    "with open('writer_info.json', 'w') as json_file:\n",
    "\tjson_file.write(writer_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
